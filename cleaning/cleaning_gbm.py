# -*- coding: utf-8 -*-
"""Copy of cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DgmziRqQH2nihJVSt3ctR2C1D2QqPP8x
"""

import pandas as pd
import numpy as np

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

import os

path = '~/Master_Thesis/master-thesis-da/datasets'

folder_names = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]

#important info of the datasets
variable_dict = {
    "531-boston" : {'norm_cat' : ['CHAS'], 'ord_cat': None, 'target' : 'MEDV', 'drop_cols' : None},
    "541-socmob" : {'norm_cat' : ['fathers_occupation', 'sons_occupation', 'family_structure', 'race'],
                    'ord_cat': None,
                    'target' : 'counts_for_sons_current_occupation', 'drop_cols' : None},
    "546-sensory" : {'norm_cat' : ['Occasion', 'Judges', 'Interval', 'Sittings','Position', 'Squares',
                                    'Rows', 'Columns', 'Halfplot', 'Trellis', 'Method'],
                     'ord_cat': None, 'target' : 'Score', 'drop_cols' : None},
    #"3050-QSAR-TID-11" : {'norm_cat' : ['CHAS'], 'ord_cat': None, 'target' : 'MEDV','drop_cols' : None},
    #"3277-QSAR-TID-10980" : {'norm_cat' : ['CHAS'], 'ord_cat': None, 'target' : 'MEDV', 'drop_cols' : None},
    "41021-Moneyball" : {'norm_cat' : ['Team', 'League','Playoffs', 'G'],
                         'ord_cat': None, 'target' : 'RS',
                         'drop_cols' : ['RankSeason', 'RankPlayoffs', 'OOBP', 'OSLG']},
    "41540-black_friday" : {'norm_cat' : ['Gender', 'Occupation', 'City_Category', 'Marital_Status',
                                          'Product_Category_1','Product_Category_2', 'Product_Category_3'],
                            'ord_cat': ['Age'], 'target' : 'Purchase',
                            'drop_cols' : None},
    "41980-SAT11-HAND-runtime-regression" : {'norm_cat' : ['algorithm'], 'ord_cat': None,
                                             'target' : 'runtime', 'drop_cols': ['row_id']},
    "42225-diamonds" : {'norm_cat' : None, 'ord_cat': ['cut', 'color', 'clarity'], 'drop_cols': None,
                        'target' : 'price'},
    "42563-house_prices_nominal" : {'norm_cat' : ['MSZoning','LotShape', 'Neighborhood'],
                                    'ord_cat': ['Street', 'Alley', 'Utilities','LotConfig', 'LandSlope','LandContour','Condition1', 'Condition2',
                                                'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl','Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',
                                                'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',
                                                'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType','GarageFinish',
                                                'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',
                                                'SaleCondition'],
                                    'target' : 'SalePrice', 'drop_cols':['Id']},
    "42570-Mercedes_Benz_Greener_Manufacturing" : {'norm_cat' : ['X0','X1','X2','X3','X4','X5','X6','X8'],
                                                   'ord_cat': None,
                                                   'target' : 'y',
                                                   'drop_cols':['ID']},
    "42571-Allstate_Claims_Severity" : {'norm_cat' : [f'cat{i}' for i in range(1,117)], 'ord_cat': None,
                                        'target' : 'loss', 'drop_cols':['id']},
    "42688-Brazilian_houses" : {'norm_cat' : ['city', 'animal'], 'ord_cat': ['furniture'], 'target' : 'total_(BRL)', 'drop_cols': None},
    "42726-abalone" : {'norm_cat' : ['Sex'], 'ord_cat': None, 'target' : 'Class_number_of_rings', 'drop_cols': None},
    "42728-Airlines_DepDelay_10M" : {'norm_cat' : ['Month','DayOfWeek','UniqueCarrier', 'Origin', 'Dest'],
                                     'ord_cat': None, 'target' : 'DepDelay', 'drop_cols': None},
    "42729-nyc-taxi-green-dec-2016" : {'norm_cat' : ['VendorID', 'store_and_fwd_flag','PULocationID', 'DOLocationID', 'trip_type'],
                                       'ord_cat': None, 'target' : 'tip_amount', 'drop_cols': None},
    "42731-house_sales" : {'norm_cat' : ['zipcode'], 'ord_cat': None , 'target' : 'price', 'drop_cols':['id']},
    "43071-MIP-2016-regression" : {'norm_cat' : ['algorithm','runstatus'], 'ord_cat': None, 'target' : 'PAR10', 'drop_cols':['instance_id']},

}

class data_cleaning:
    def __init__(self, dataset_list, variable_dict):
        self.dataset_list = dataset_list
        self.variable_dict = variable_dict


    def missing_duplicates(self, data, dataset):
        """
            Function drops any duplicates or missing values in the dataset.

            Parameters:
            data (DataFrame): Data to be cleaned.
            dataset (str): Name of the dataset.

            Returns:
            DataFrame: Returns the cleaned dataset as a dataframe.
        """
        ## HANDLING NULLS

        ### @42563-house_prices_nominal
        if(dataset == '42563-house_prices_nominal'):
            #groups
            missing_categoricals = {
                                    'Alley' : 'None', 'MasVnrType': 'None','BsmtQual': 'None',
                                    'BsmtCond': 'None', 'BsmtExposure': 'None', 'BsmtFinType1': 'None',
                                    'BsmtFinType2': 'None', 'Electrical': 'None','FireplaceQu': 'None', 'GarageType': 'None',
                                    'GarageFinish' : 'None', 'GarageQual' : 'None', 'GarageCond' : 'None',
                                    'PoolQC' : 'None', 'Fence' : 'None', 'MiscFeature': 'None'
                                    }

            missing_numericals = {
                                'LotFrontage': data['LotFrontage'].median(),
                                'MasVnrArea': data['MasVnrArea'].median(),
                                'GarageYrBlt' : data['GarageYrBlt'].median()
                                 }

            #replacements
            data.fillna(missing_categoricals, inplace=True) #categoricals
            data.fillna(missing_numericals, inplace=True) #numericals

        else:
            #general care
            pass

        ### DROP UNIMPORTANT COLUMNS
        if(self.variable_dict[dataset]['drop_cols'] is not None):
            data.drop(self.variable_dict[dataset]['drop_cols'], axis=1, inplace=True)

        ##drop duplicates and nulls
        data.drop_duplicates(inplace=True)
        data.dropna(inplace=True)

        ## CHANGE COLUMN DTYPE 4 black friday
        if (dataset == '41540-black_friday'):
            data.loc[data['Stay_In_Current_City_Years'] == '4+', 'Stay_In_Current_City_Years'] = 4
            data['Stay_In_Current_City_Years'] = data['Stay_In_Current_City_Years'].astype(int)


        ##
        #get categoricals
        nominal_cat = self.variable_dict[dataset]['norm_cat']
        ordinal_cat = self.variable_dict[dataset]['ord_cat']

        try:
            if((nominal_cat is not None) & (ordinal_cat is not None)):
                categorical_cols = nominal_cat + ordinal_cat
            elif(nominal_cat is not None):
                categorical_cols = nominal_cat
            else:
                categorical_cols = ordinal_cat
        except:
            pass

        #turn data to categorical
        data[categorical_cols] = data[categorical_cols].astype('category')

        return data

    def fit(self):
        #dataset paths
        data_path = '/content/drive/MyDrive/Master Thesis/Benchmark Dataset V2/Mixed Variables'

        for dataset in self.dataset_list:
            print(f"We are in the dataset : {dataset}")

            #dataset
            data_df = pd.read_csv(f'{data_path}/{dataset}/raw_data.csv')

            #remove missing and general cleaning
            data_df = self.missing_duplicates(data_df,dataset)

            #X and y
            X = data_df.drop(self.variable_dict[dataset]['target'], axis=1)
            y = data_df[self.variable_dict[dataset]['target']]

            #train test split
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            #concat
            train_data = pd.concat([X_train, y_train], axis=1)
            test_data = pd.concat([X_test, y_test], axis=1)

            #save as csv
            train_data.to_csv(f'{data_path}/{dataset}/train_gbm.csv', index=False)
            test_data.to_csv(f'{data_path}/{dataset}/test_gbm.csv', index=False)

model = data_cleaning(folder_names, variable_dict)
model.fit()