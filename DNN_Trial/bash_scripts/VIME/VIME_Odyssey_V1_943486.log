

----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/brazillian_houses.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/brazillian_houses.yml', data_parallel=False, dataset='Brazillian_Houses', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=20, nominal_idx=[0, 6], num_classes=1, num_features=12, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[7], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Brazillian_Houses...
Dataset loaded!
(10692, 12)
Scaling the data...
args.num_features: 17
args.cat_idx: [0]
New Shape: (10692, 17)
A new study created in RDB with name: VIME_Brazillian_Houses
In get_device
On Device: cuda
In get_device
On Device: cuda
Trial 0 failed with parameters: {'p_m': 0.6422781390183327, 'alpha': 7.634675018494107, 'K': 20, 'beta': 6.318834199460037} because of the following error: ValueError("could not convert string to float: 'furnished'").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/vime.py", line 39, in fit
    X = X.astype(float)
ValueError: could not convert string to float: 'furnished'
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/abalone.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/abalone.yml', data_parallel=False, dataset='Abalone', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=20, nominal_idx=[0], num_classes=1, num_features=8, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Abalone...
Dataset loaded!
(4177, 8)
Scaling the data...
args.num_features: 10
args.cat_idx: []
New Shape: (4177, 10)
A new study created in RDB with name: VIME_Abalone
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.85443
Epoch 1, Val Loss: 10.57991
Epoch 2, Val Loss: 7.14710
Epoch 3, Val Loss: 6.64428
Epoch 4, Val Loss: 6.26861
Epoch 5, Val Loss: 6.15140
Epoch 6, Val Loss: 6.24756
Epoch 7, Val Loss: 6.08906
Epoch 8, Val Loss: 6.26728
Epoch 9, Val Loss: 6.12137
Epoch 10, Val Loss: 5.79709
Epoch 11, Val Loss: 5.87929
Epoch 12, Val Loss: 5.74549
Epoch 13, Val Loss: 5.86549
Epoch 14, Val Loss: 5.66767
Epoch 15, Val Loss: 5.82453
Epoch 16, Val Loss: 5.61712
Epoch 17, Val Loss: 5.70522
Epoch 18, Val Loss: 5.62435
Epoch 19, Val Loss: 5.67510
Epoch 20, Val Loss: 5.39324
Epoch 21, Val Loss: 5.40242
Epoch 22, Val Loss: 5.39866
Epoch 23, Val Loss: 5.29057
Epoch 24, Val Loss: 5.13240
Epoch 25, Val Loss: 5.10886
Epoch 26, Val Loss: 5.10727
Epoch 27, Val Loss: 5.18511
Epoch 28, Val Loss: 5.15445
Epoch 29, Val Loss: 5.11376
Epoch 30, Val Loss: 4.89593
Epoch 31, Val Loss: 5.05684
Epoch 32, Val Loss: 5.14096
Epoch 33, Val Loss: 4.90409
Epoch 34, Val Loss: 5.01317
Epoch 35, Val Loss: 5.06849
Epoch 36, Val Loss: 5.20883
Epoch 37, Val Loss: 4.90617
Epoch 38, Val Loss: 4.96121
Epoch 39, Val Loss: 5.02227
Epoch 40, Val Loss: 4.79040
Epoch 41, Val Loss: 4.93874
Epoch 42, Val Loss: 4.83154
Epoch 43, Val Loss: 5.07906
Epoch 44, Val Loss: 5.44499
Epoch 45, Val Loss: 5.28019
Epoch 46, Val Loss: 4.82823
Epoch 47, Val Loss: 4.79687
Epoch 48, Val Loss: 4.77199
Epoch 49, Val Loss: 4.85884
Epoch 50, Val Loss: 5.04121
Epoch 51, Val Loss: 4.92874
Epoch 52, Val Loss: 4.73952
Epoch 53, Val Loss: 4.81302
Epoch 54, Val Loss: 4.72182
Epoch 55, Val Loss: 4.72016
Epoch 56, Val Loss: 5.23941
Epoch 57, Val Loss: 4.62442
Epoch 58, Val Loss: 4.72700
Epoch 59, Val Loss: 4.75524
Epoch 60, Val Loss: 4.76048
Epoch 61, Val Loss: 5.00750
Epoch 62, Val Loss: 4.81897
Epoch 63, Val Loss: 4.86528
Epoch 64, Val Loss: 4.68170
Epoch 65, Val Loss: 4.98606
Epoch 66, Val Loss: 4.85820
Epoch 67, Val Loss: 4.76368
Epoch 68, Val Loss: 4.82311
Epoch 69, Val Loss: 4.78407
Epoch 70, Val Loss: 5.15030
Epoch 71, Val Loss: 4.89687
Epoch 72, Val Loss: 5.14409
Epoch 73, Val Loss: 4.72183
Epoch 74, Val Loss: 5.13222
Epoch 75, Val Loss: 4.79254
Epoch 76, Val Loss: 4.78857
Epoch 77, Val Loss: 4.86109
Epoch 78, Val Loss: 4.74205
Early stopping applies.
Saved Losses
{'MSE - mean': 4.762813880595046, 'MSE - std': 0.0, 'R2 - mean': 0.5656471120608346, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.58316
Epoch 1, Val Loss: 12.88228
Epoch 2, Val Loss: 7.17517
Epoch 3, Val Loss: 6.08995
Epoch 4, Val Loss: 5.71567
Epoch 5, Val Loss: 5.46259
Epoch 6, Val Loss: 4.94778
Epoch 7, Val Loss: 5.16193
Epoch 8, Val Loss: 5.38388
Epoch 9, Val Loss: 4.84380
Epoch 10, Val Loss: 4.96813
Epoch 11, Val Loss: 4.72658
Epoch 12, Val Loss: 4.68493
Epoch 13, Val Loss: 4.68319
Epoch 14, Val Loss: 4.89101
Epoch 15, Val Loss: 4.94128
Epoch 16, Val Loss: 4.94155
Epoch 17, Val Loss: 4.55221
Epoch 18, Val Loss: 4.67852
Epoch 19, Val Loss: 4.78180
Epoch 20, Val Loss: 4.49614
Epoch 21, Val Loss: 5.08121
Epoch 22, Val Loss: 4.48730
Epoch 23, Val Loss: 4.77789
Epoch 24, Val Loss: 4.86522
Epoch 25, Val Loss: 4.60374
Epoch 26, Val Loss: 4.47963
Epoch 27, Val Loss: 4.61491
Epoch 28, Val Loss: 4.95209
Epoch 29, Val Loss: 4.54570
Epoch 30, Val Loss: 4.44192
Epoch 31, Val Loss: 4.32306
Epoch 32, Val Loss: 4.67739
Epoch 33, Val Loss: 4.26188
Epoch 34, Val Loss: 4.29496
Epoch 35, Val Loss: 4.42134
Epoch 36, Val Loss: 4.71111
Epoch 37, Val Loss: 4.31044
Epoch 38, Val Loss: 4.58217
Epoch 39, Val Loss: 5.30939
Epoch 40, Val Loss: 4.74960
Epoch 41, Val Loss: 4.25299
Epoch 42, Val Loss: 4.51576
Epoch 43, Val Loss: 4.36785
Epoch 44, Val Loss: 4.60592
Epoch 45, Val Loss: 4.17556
Epoch 46, Val Loss: 4.49762
Epoch 47, Val Loss: 4.67597
Epoch 48, Val Loss: 4.18251
Epoch 49, Val Loss: 4.47567
Epoch 50, Val Loss: 4.31867
Epoch 51, Val Loss: 4.16669
Epoch 52, Val Loss: 4.35412
Epoch 53, Val Loss: 4.31443
Epoch 54, Val Loss: 4.77235
Epoch 55, Val Loss: 4.35797
Epoch 56, Val Loss: 4.12880
Epoch 57, Val Loss: 4.32249
Epoch 58, Val Loss: 4.10366
Epoch 59, Val Loss: 4.13404
Epoch 60, Val Loss: 4.36142
Epoch 61, Val Loss: 4.14191
Epoch 62, Val Loss: 4.38168
Epoch 63, Val Loss: 4.11337
Epoch 64, Val Loss: 4.23004
Epoch 65, Val Loss: 4.22545
Epoch 66, Val Loss: 4.13088
Epoch 67, Val Loss: 5.18046
Epoch 68, Val Loss: 4.40534
Epoch 69, Val Loss: 4.15597
Epoch 70, Val Loss: 4.13675
Epoch 71, Val Loss: 4.17456
Epoch 72, Val Loss: 4.07300
Epoch 73, Val Loss: 4.15980
Epoch 74, Val Loss: 4.15532
Epoch 75, Val Loss: 4.41234
Epoch 76, Val Loss: 4.19213
Epoch 77, Val Loss: 4.11855
Epoch 78, Val Loss: 4.16186
Epoch 79, Val Loss: 4.17146
Epoch 80, Val Loss: 4.52224
Epoch 81, Val Loss: 4.19741
Epoch 82, Val Loss: 4.19843
Epoch 83, Val Loss: 4.30382
Epoch 84, Val Loss: 4.17188
Epoch 85, Val Loss: 4.11668
Epoch 86, Val Loss: 4.10048
Epoch 87, Val Loss: 4.08664
Epoch 88, Val Loss: 4.42189
Epoch 89, Val Loss: 4.84112
Epoch 90, Val Loss: 4.53909
Epoch 91, Val Loss: 4.36511
Epoch 92, Val Loss: 4.15859
Epoch 93, Val Loss: 4.03491
Epoch 94, Val Loss: 4.11844
Epoch 95, Val Loss: 4.94728
Epoch 96, Val Loss: 4.13542
Epoch 97, Val Loss: 4.26977
Epoch 98, Val Loss: 4.11445
Epoch 99, Val Loss: 4.10975
Saved Losses
{'MSE - mean': 4.4861111127080004, 'MSE - std': 0.2767027678870462, 'R2 - mean': 0.5584693234666214, 'R2 - std': 0.0071777885942132524} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 43.58619
Epoch 1, Val Loss: 15.30551
Epoch 2, Val Loss: 7.10098
Epoch 3, Val Loss: 6.52217
Epoch 4, Val Loss: 6.36017
Epoch 5, Val Loss: 6.61804
Epoch 6, Val Loss: 5.75284
Epoch 7, Val Loss: 5.64562
Epoch 8, Val Loss: 5.57128
Epoch 9, Val Loss: 5.45628
Epoch 10, Val Loss: 5.38039
Epoch 11, Val Loss: 5.17464
Epoch 12, Val Loss: 5.28934
Epoch 13, Val Loss: 5.39255
Epoch 14, Val Loss: 5.21557
Epoch 15, Val Loss: 5.02504
Epoch 16, Val Loss: 5.24039
Epoch 17, Val Loss: 5.03115
Epoch 18, Val Loss: 4.94715
Epoch 19, Val Loss: 5.30487
Epoch 20, Val Loss: 5.13208
Epoch 21, Val Loss: 4.95220
Epoch 22, Val Loss: 5.13540
Epoch 23, Val Loss: 5.03542
Epoch 24, Val Loss: 4.86381
Epoch 25, Val Loss: 4.82712
Epoch 26, Val Loss: 4.83950
Epoch 27, Val Loss: 4.78116
Epoch 28, Val Loss: 4.74234
Epoch 29, Val Loss: 4.71663
Epoch 30, Val Loss: 4.70677
Epoch 31, Val Loss: 4.85581
Epoch 32, Val Loss: 4.72352
Epoch 33, Val Loss: 4.72790
Epoch 34, Val Loss: 4.80830
Epoch 35, Val Loss: 4.79432
Epoch 36, Val Loss: 4.75686
Epoch 37, Val Loss: 4.71176
Epoch 38, Val Loss: 4.78243
Epoch 39, Val Loss: 4.91715
Epoch 40, Val Loss: 4.82721
Epoch 41, Val Loss: 5.12789
Epoch 42, Val Loss: 4.99093
Epoch 43, Val Loss: 4.79412
Epoch 44, Val Loss: 4.74384
Epoch 45, Val Loss: 4.74966
Epoch 46, Val Loss: 4.82231
Epoch 47, Val Loss: 4.77073
Epoch 48, Val Loss: 4.70296
Epoch 49, Val Loss: 4.70620
Epoch 50, Val Loss: 4.64451
Epoch 51, Val Loss: 4.73187
Epoch 52, Val Loss: 4.67705
Epoch 53, Val Loss: 4.68051
Epoch 54, Val Loss: 4.63842
Epoch 55, Val Loss: 4.61758
Epoch 56, Val Loss: 4.64108
Epoch 57, Val Loss: 4.75629
Epoch 58, Val Loss: 4.77274
Epoch 59, Val Loss: 4.76806
Epoch 60, Val Loss: 4.83582
Epoch 61, Val Loss: 4.67642
Epoch 62, Val Loss: 4.79582
Epoch 63, Val Loss: 4.75115
Epoch 64, Val Loss: 4.70680
Epoch 65, Val Loss: 4.92300
Epoch 66, Val Loss: 4.76213
Epoch 67, Val Loss: 4.71016
Epoch 68, Val Loss: 4.77678
Epoch 69, Val Loss: 4.75347
Epoch 70, Val Loss: 4.64684
Epoch 71, Val Loss: 4.59503
Epoch 72, Val Loss: 4.67423
Epoch 73, Val Loss: 4.60423
Epoch 74, Val Loss: 4.69268
Epoch 75, Val Loss: 4.67136
Epoch 76, Val Loss: 4.65973
Epoch 77, Val Loss: 4.59104
Epoch 78, Val Loss: 4.67309
Epoch 79, Val Loss: 4.91121
Epoch 80, Val Loss: 4.62792
Epoch 81, Val Loss: 4.91705
Epoch 82, Val Loss: 4.74735
Epoch 83, Val Loss: 4.59294
Epoch 84, Val Loss: 4.68381
Epoch 85, Val Loss: 4.64010
Epoch 86, Val Loss: 4.91113
Epoch 87, Val Loss: 4.71604
Epoch 88, Val Loss: 4.83048
Epoch 89, Val Loss: 4.59132
Epoch 90, Val Loss: 4.53135
Epoch 91, Val Loss: 4.86763
Epoch 92, Val Loss: 4.65373
Epoch 93, Val Loss: 4.68907
Epoch 94, Val Loss: 4.66482
Epoch 95, Val Loss: 4.57611
Epoch 96, Val Loss: 4.61843
Epoch 97, Val Loss: 4.72404
Epoch 98, Val Loss: 4.84612
Epoch 99, Val Loss: 4.67438
Saved Losses
{'MSE - mean': 4.537048975366731, 'MSE - std': 0.23713346356439835, 'R2 - mean': 0.5534915057387018, 'R2 - std': 0.009159936575485987} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.90408
Epoch 1, Val Loss: 14.64918
Epoch 2, Val Loss: 5.36900
Epoch 3, Val Loss: 4.93360
Epoch 4, Val Loss: 4.93806
Epoch 5, Val Loss: 4.92290
Epoch 6, Val Loss: 4.90936
Epoch 7, Val Loss: 4.85167
Epoch 8, Val Loss: 5.12155
Epoch 9, Val Loss: 4.83038
Epoch 10, Val Loss: 4.71699
Epoch 11, Val Loss: 5.03116
Epoch 12, Val Loss: 6.00528
Epoch 13, Val Loss: 4.74225
Epoch 14, Val Loss: 4.60817
Epoch 15, Val Loss: 4.76551
Epoch 16, Val Loss: 4.64526
Epoch 17, Val Loss: 4.61550
Epoch 18, Val Loss: 4.56050
Epoch 19, Val Loss: 4.55854
Epoch 20, Val Loss: 4.47171
Epoch 21, Val Loss: 4.55328
Epoch 22, Val Loss: 4.51937
Epoch 23, Val Loss: 4.58482
Epoch 24, Val Loss: 4.75936
Epoch 25, Val Loss: 4.66891
Epoch 26, Val Loss: 5.18784
Epoch 27, Val Loss: 4.42575
Epoch 28, Val Loss: 4.51651
Epoch 29, Val Loss: 4.64520
Epoch 30, Val Loss: 4.38850
Epoch 31, Val Loss: 4.33408
Epoch 32, Val Loss: 4.38796
Epoch 33, Val Loss: 4.33280
Epoch 34, Val Loss: 4.29406
Epoch 35, Val Loss: 4.41672
Epoch 36, Val Loss: 4.59385
Epoch 37, Val Loss: 4.42678
Epoch 38, Val Loss: 4.63243
Epoch 39, Val Loss: 4.30564
Epoch 40, Val Loss: 4.39395
Epoch 41, Val Loss: 4.33584
Epoch 42, Val Loss: 4.28102
Epoch 43, Val Loss: 4.35798
Epoch 44, Val Loss: 4.43570
Epoch 45, Val Loss: 4.31327
Epoch 46, Val Loss: 4.14301
Epoch 47, Val Loss: 4.16171
Epoch 48, Val Loss: 4.32286
Epoch 49, Val Loss: 4.14119
Epoch 50, Val Loss: 4.33864
Epoch 51, Val Loss: 4.49063
Epoch 52, Val Loss: 4.16336
Epoch 53, Val Loss: 4.17493
Epoch 54, Val Loss: 4.26847
Epoch 55, Val Loss: 4.15185
Epoch 56, Val Loss: 4.22933
Epoch 57, Val Loss: 4.56290
Epoch 58, Val Loss: 4.22546
Epoch 59, Val Loss: 4.05907
Epoch 60, Val Loss: 4.17879
Epoch 61, Val Loss: 4.59599
Epoch 62, Val Loss: 4.07502
Epoch 63, Val Loss: 4.03038
Epoch 64, Val Loss: 4.13501
Epoch 65, Val Loss: 4.33314
Epoch 66, Val Loss: 4.15442
Epoch 67, Val Loss: 4.20384
Epoch 68, Val Loss: 4.26554
Epoch 69, Val Loss: 4.33835
Epoch 70, Val Loss: 4.28959
Epoch 71, Val Loss: 3.99569
Epoch 72, Val Loss: 4.04483
Epoch 73, Val Loss: 4.04525
Epoch 74, Val Loss: 4.13448
Epoch 75, Val Loss: 4.17683
Epoch 76, Val Loss: 4.00153
Epoch 77, Val Loss: 4.14336
Epoch 78, Val Loss: 4.05351
Epoch 79, Val Loss: 4.19768
Epoch 80, Val Loss: 3.97564
Epoch 81, Val Loss: 4.15926
Epoch 82, Val Loss: 4.21612
Epoch 83, Val Loss: 4.36341
Epoch 84, Val Loss: 3.97607
Epoch 85, Val Loss: 4.05161
Epoch 86, Val Loss: 4.19570
Epoch 87, Val Loss: 4.27517
Epoch 88, Val Loss: 4.00991
Epoch 89, Val Loss: 4.30792
Epoch 90, Val Loss: 4.07270
Epoch 91, Val Loss: 4.08875
Epoch 92, Val Loss: 4.04096
Epoch 93, Val Loss: 4.03735
Epoch 94, Val Loss: 4.15000
Epoch 95, Val Loss: 3.95270
Epoch 96, Val Loss: 3.99799
Epoch 97, Val Loss: 4.09430
Epoch 98, Val Loss: 4.06513
Epoch 99, Val Loss: 4.11783
Saved Losses
{'MSE - mean': 4.470935352200386, 'MSE - std': 0.23513239496309374, 'R2 - mean': 0.5509116357312394, 'R2 - std': 0.009104697486265363} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.51834
Epoch 1, Val Loss: 13.79670
Epoch 2, Val Loss: 9.10114
Epoch 3, Val Loss: 8.21434
Epoch 4, Val Loss: 7.91238
Epoch 5, Val Loss: 7.64531
Epoch 6, Val Loss: 7.23746
Epoch 7, Val Loss: 7.24001
Epoch 8, Val Loss: 7.22192
Epoch 9, Val Loss: 6.97693
Epoch 10, Val Loss: 7.02477
Epoch 11, Val Loss: 6.87828
Epoch 12, Val Loss: 7.01222
Epoch 13, Val Loss: 6.80619
Epoch 14, Val Loss: 6.58581
Epoch 15, Val Loss: 7.25221
Epoch 16, Val Loss: 6.59288
Epoch 17, Val Loss: 6.60799
Epoch 18, Val Loss: 6.34316
Epoch 19, Val Loss: 6.63902
Epoch 20, Val Loss: 6.38689
Epoch 21, Val Loss: 6.58920
Epoch 22, Val Loss: 6.31412
Epoch 23, Val Loss: 6.23827
Epoch 24, Val Loss: 6.90757
Epoch 25, Val Loss: 6.06546
Epoch 26, Val Loss: 6.27118
Epoch 27, Val Loss: 6.03916
Epoch 28, Val Loss: 5.92648
Epoch 29, Val Loss: 5.98792
Epoch 30, Val Loss: 6.54786
Epoch 31, Val Loss: 5.95773
Epoch 32, Val Loss: 5.89682
Epoch 33, Val Loss: 6.26112
Epoch 34, Val Loss: 5.90955
Epoch 35, Val Loss: 5.87494
Epoch 36, Val Loss: 5.76108
Epoch 37, Val Loss: 5.96924
Epoch 38, Val Loss: 6.05112
Epoch 39, Val Loss: 5.89831
Epoch 40, Val Loss: 5.74309
Epoch 41, Val Loss: 6.11278
Epoch 42, Val Loss: 7.06595
Epoch 43, Val Loss: 5.68683
Epoch 44, Val Loss: 5.80246
Epoch 45, Val Loss: 5.70602
Epoch 46, Val Loss: 5.98213
Epoch 47, Val Loss: 5.72580
Epoch 48, Val Loss: 6.33080
Epoch 49, Val Loss: 5.72251
Epoch 50, Val Loss: 5.76317
Epoch 51, Val Loss: 6.92320
Epoch 52, Val Loss: 6.01645
Epoch 53, Val Loss: 6.10659
Epoch 54, Val Loss: 5.68876
Epoch 55, Val Loss: 5.78952
Epoch 56, Val Loss: 5.69657
Epoch 57, Val Loss: 5.67081
Epoch 58, Val Loss: 5.73353
Epoch 59, Val Loss: 5.58772
Epoch 60, Val Loss: 5.63051
Epoch 61, Val Loss: 5.71040
Epoch 62, Val Loss: 5.57730
Epoch 63, Val Loss: 5.59461
Epoch 64, Val Loss: 5.59013
Epoch 65, Val Loss: 5.67580
Epoch 66, Val Loss: 5.71466
Epoch 67, Val Loss: 5.66745
Epoch 68, Val Loss: 5.62369
Epoch 69, Val Loss: 5.86790
Epoch 70, Val Loss: 5.79191
Epoch 71, Val Loss: 5.63728
Epoch 72, Val Loss: 5.53662
Epoch 73, Val Loss: 5.62693
Epoch 74, Val Loss: 5.78953
Epoch 75, Val Loss: 5.60564
Epoch 76, Val Loss: 5.65452
Epoch 77, Val Loss: 5.47993
Epoch 78, Val Loss: 5.66271
Epoch 79, Val Loss: 5.64734
Epoch 80, Val Loss: 5.45632
Epoch 81, Val Loss: 5.57304
Epoch 82, Val Loss: 5.63712
Epoch 83, Val Loss: 5.48592
Epoch 84, Val Loss: 5.60002
Epoch 85, Val Loss: 6.04212
Epoch 86, Val Loss: 5.82432
Epoch 87, Val Loss: 5.70806
Epoch 88, Val Loss: 5.35447
Epoch 89, Val Loss: 5.71197
Epoch 90, Val Loss: 5.77363
Epoch 91, Val Loss: 5.56227
Epoch 92, Val Loss: 5.53726
Epoch 93, Val Loss: 5.67397
Epoch 94, Val Loss: 5.55201
Epoch 95, Val Loss: 5.54073
Epoch 96, Val Loss: 5.46447
Epoch 97, Val Loss: 5.58701
Epoch 98, Val Loss: 6.02028
Epoch 99, Val Loss: 5.58942
Saved Losses
{'MSE - mean': 4.658108446368637, 'MSE - std': 0.4293772970837327, 'R2 - mean': 0.5513011636639671, 'R2 - std': 0.008180668743729096} 
 

Results After CV: {'MSE - mean': 4.658108446368637, 'MSE - std': 0.4293772970837327, 'R2 - mean': 0.5513011636639671, 'R2 - std': 0.008180668743729096}
Train time: 115.19798973860001
Inference time: 0.051428809999981694
Finished cross validation
Trial 0 finished with value: 4.658108446368637 and parameters: {'p_m': 0.4531104462670583, 'alpha': 1.0240583928858533, 'K': 20, 'beta': 0.2546447268684935}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.63127
Epoch 1, Val Loss: 13.67522
Epoch 2, Val Loss: 8.16858
Epoch 3, Val Loss: 7.18808
Epoch 4, Val Loss: 6.65364
Epoch 5, Val Loss: 6.50084
Epoch 6, Val Loss: 6.41529
Epoch 7, Val Loss: 6.26783
Epoch 8, Val Loss: 6.24471
Epoch 9, Val Loss: 6.65307
Epoch 10, Val Loss: 6.29318
Epoch 11, Val Loss: 6.16226
Epoch 12, Val Loss: 6.02015
Epoch 13, Val Loss: 6.33261
Epoch 14, Val Loss: 6.41665
Epoch 15, Val Loss: 6.42389
Epoch 16, Val Loss: 5.93712
Epoch 17, Val Loss: 6.23369
Epoch 18, Val Loss: 6.09823
Epoch 19, Val Loss: 5.75360
Epoch 20, Val Loss: 5.99787
Epoch 21, Val Loss: 5.48213
Epoch 22, Val Loss: 5.62827
Epoch 23, Val Loss: 5.55914
Epoch 24, Val Loss: 5.43448
Epoch 25, Val Loss: 5.75168
Epoch 26, Val Loss: 5.77862
Epoch 27, Val Loss: 5.36551
Epoch 28, Val Loss: 5.96206
Epoch 29, Val Loss: 5.30154
Epoch 30, Val Loss: 5.24108
Epoch 31, Val Loss: 5.37963
Epoch 32, Val Loss: 5.45419
Epoch 33, Val Loss: 5.44279
Epoch 34, Val Loss: 5.16777
Epoch 35, Val Loss: 5.38480
Epoch 36, Val Loss: 5.82477
Epoch 37, Val Loss: 5.38695
Epoch 38, Val Loss: 5.66983
Epoch 39, Val Loss: 5.54963
Epoch 40, Val Loss: 5.41311
Epoch 41, Val Loss: 5.12345
Epoch 42, Val Loss: 5.38750
Epoch 43, Val Loss: 5.16090
Epoch 44, Val Loss: 5.23131
Epoch 45, Val Loss: 4.97817
Epoch 46, Val Loss: 5.04839
Epoch 47, Val Loss: 5.14633
Epoch 48, Val Loss: 5.04640
Epoch 49, Val Loss: 5.08075
Epoch 50, Val Loss: 4.94169
Epoch 51, Val Loss: 4.96646
Epoch 52, Val Loss: 5.15748
Epoch 53, Val Loss: 4.87306
Epoch 54, Val Loss: 5.03720
Epoch 55, Val Loss: 5.21758
Epoch 56, Val Loss: 4.86883
Epoch 57, Val Loss: 5.25165
Epoch 58, Val Loss: 4.77169
Epoch 59, Val Loss: 4.93092
Epoch 60, Val Loss: 4.92463
Epoch 61, Val Loss: 4.85919
Epoch 62, Val Loss: 4.88800
Epoch 63, Val Loss: 4.68787
Epoch 64, Val Loss: 4.77073
Epoch 65, Val Loss: 4.93921
Epoch 66, Val Loss: 4.92550
Epoch 67, Val Loss: 4.78491
Epoch 68, Val Loss: 4.88848
Epoch 69, Val Loss: 4.92177
Epoch 70, Val Loss: 4.78952
Epoch 71, Val Loss: 5.03438
Epoch 72, Val Loss: 4.82752
Epoch 73, Val Loss: 4.93145
Epoch 74, Val Loss: 5.22442
Epoch 75, Val Loss: 4.86364
Epoch 76, Val Loss: 4.92883
Epoch 77, Val Loss: 5.15073
Epoch 78, Val Loss: 5.14431
Epoch 79, Val Loss: 4.76686
Epoch 80, Val Loss: 4.96347
Epoch 81, Val Loss: 4.78315
Epoch 82, Val Loss: 5.14302
Epoch 83, Val Loss: 4.90378
Epoch 84, Val Loss: 4.75628
Early stopping applies.
Saved Losses
{'MSE - mean': 4.863120661857354, 'MSE - std': 0.0, 'R2 - mean': 0.556499465057731, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.45282
Epoch 1, Val Loss: 9.71729
Epoch 2, Val Loss: 6.03644
Epoch 3, Val Loss: 5.90641
Epoch 4, Val Loss: 5.89702
Epoch 5, Val Loss: 6.02778
Epoch 6, Val Loss: 5.65353
Epoch 7, Val Loss: 5.32033
Epoch 8, Val Loss: 5.38448
Epoch 9, Val Loss: 5.19721
Epoch 10, Val Loss: 5.42604
Epoch 11, Val Loss: 5.18783
Epoch 12, Val Loss: 5.35590
Epoch 13, Val Loss: 5.24716
Epoch 14, Val Loss: 5.21608
Epoch 15, Val Loss: 5.14745
Epoch 16, Val Loss: 5.28328
Epoch 17, Val Loss: 5.52893
Epoch 18, Val Loss: 5.02672
Epoch 19, Val Loss: 5.06027
Epoch 20, Val Loss: 5.07983
Epoch 21, Val Loss: 5.14317
Epoch 22, Val Loss: 4.98501
Epoch 23, Val Loss: 4.98393
Epoch 24, Val Loss: 4.93108
Epoch 25, Val Loss: 5.04291
Epoch 26, Val Loss: 5.03973
Epoch 27, Val Loss: 5.47798
Epoch 28, Val Loss: 5.37035
Epoch 29, Val Loss: 5.11429
Epoch 30, Val Loss: 4.96552
Epoch 31, Val Loss: 5.18637
Epoch 32, Val Loss: 4.89978
Epoch 33, Val Loss: 4.92720
Epoch 34, Val Loss: 4.86584
Epoch 35, Val Loss: 5.15246
Epoch 36, Val Loss: 5.14116
Epoch 37, Val Loss: 4.89693
Epoch 38, Val Loss: 4.92468
Epoch 39, Val Loss: 5.05958
Epoch 40, Val Loss: 4.98133
Epoch 41, Val Loss: 4.94734
Epoch 42, Val Loss: 4.85356
Epoch 43, Val Loss: 4.72742
Epoch 44, Val Loss: 5.02380
Epoch 45, Val Loss: 4.71243
Epoch 46, Val Loss: 4.74248
Epoch 47, Val Loss: 4.99099
Epoch 48, Val Loss: 4.75065
Epoch 49, Val Loss: 4.92389
Epoch 50, Val Loss: 4.75223
Epoch 51, Val Loss: 4.72560
Epoch 52, Val Loss: 4.64222
Epoch 53, Val Loss: 4.99787
Epoch 54, Val Loss: 5.62560
Epoch 55, Val Loss: 4.85193
Epoch 56, Val Loss: 4.52454
Epoch 57, Val Loss: 5.09094
Epoch 58, Val Loss: 4.70849
Epoch 59, Val Loss: 4.72838
Epoch 60, Val Loss: 4.61007
Epoch 61, Val Loss: 4.46215
Epoch 62, Val Loss: 4.39083
Epoch 63, Val Loss: 4.49123
Epoch 64, Val Loss: 4.38030
Epoch 65, Val Loss: 4.44212
Epoch 66, Val Loss: 4.70306
Epoch 67, Val Loss: 4.39492
Epoch 68, Val Loss: 4.34004
Epoch 69, Val Loss: 4.31620
Epoch 70, Val Loss: 4.27585
Epoch 71, Val Loss: 4.42372
Epoch 72, Val Loss: 4.19149
Epoch 73, Val Loss: 4.55437
Epoch 74, Val Loss: 4.60791
Epoch 75, Val Loss: 4.23203
Epoch 76, Val Loss: 4.23038
Epoch 77, Val Loss: 4.21774
Epoch 78, Val Loss: 4.14304
Epoch 79, Val Loss: 4.26792
Epoch 80, Val Loss: 4.46317
Epoch 81, Val Loss: 4.25834
Epoch 82, Val Loss: 4.24606
Epoch 83, Val Loss: 4.12948
Epoch 84, Val Loss: 4.26020
Epoch 85, Val Loss: 4.30905
Epoch 86, Val Loss: 4.52051
Epoch 87, Val Loss: 4.18162
Epoch 88, Val Loss: 4.09263
Epoch 89, Val Loss: 4.50590
Epoch 90, Val Loss: 4.21357
Epoch 91, Val Loss: 4.44339
Epoch 92, Val Loss: 4.14272
Epoch 93, Val Loss: 4.03573
Epoch 94, Val Loss: 4.13014
Epoch 95, Val Loss: 4.11618
Epoch 96, Val Loss: 4.24744
Epoch 97, Val Loss: 4.18158
Epoch 98, Val Loss: 4.05783
Epoch 99, Val Loss: 3.96154
Saved Losses
{'MSE - mean': 4.4953597429762375, 'MSE - std': 0.36776091888111706, 'R2 - mean': 0.5582558068622225, 'R2 - std': 0.0017563418044916346} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.51313
Epoch 1, Val Loss: 16.32202
Epoch 2, Val Loss: 6.75305
Epoch 3, Val Loss: 6.15686
Epoch 4, Val Loss: 6.21345
Epoch 5, Val Loss: 5.96627
Epoch 6, Val Loss: 6.18352
Epoch 7, Val Loss: 6.15803
Epoch 8, Val Loss: 5.94598
Epoch 9, Val Loss: 5.97313
Epoch 10, Val Loss: 5.85953
Epoch 11, Val Loss: 5.73270
Epoch 12, Val Loss: 5.74949
Epoch 13, Val Loss: 5.59627
Epoch 14, Val Loss: 5.63625
Epoch 15, Val Loss: 5.56132
Epoch 16, Val Loss: 5.44341
Epoch 17, Val Loss: 5.56471
Epoch 18, Val Loss: 5.46418
Epoch 19, Val Loss: 5.40401
Epoch 20, Val Loss: 5.35298
Epoch 21, Val Loss: 5.45291
Epoch 22, Val Loss: 5.54798
Epoch 23, Val Loss: 5.34571
Epoch 24, Val Loss: 5.09349
Epoch 25, Val Loss: 5.19176
Epoch 26, Val Loss: 5.15284
Epoch 27, Val Loss: 5.27195
Epoch 28, Val Loss: 5.00937
Epoch 29, Val Loss: 5.25642
Epoch 30, Val Loss: 5.29967
Epoch 31, Val Loss: 5.12929
Epoch 32, Val Loss: 5.23079
Epoch 33, Val Loss: 4.96896
Epoch 34, Val Loss: 4.92611
Epoch 35, Val Loss: 5.06403
Epoch 36, Val Loss: 5.00760
Epoch 37, Val Loss: 4.87986
Epoch 38, Val Loss: 5.29617
Epoch 39, Val Loss: 5.03781
Epoch 40, Val Loss: 5.02818
Epoch 41, Val Loss: 5.14813
Epoch 42, Val Loss: 4.93277
Epoch 43, Val Loss: 4.98948
Epoch 44, Val Loss: 5.11569
Epoch 45, Val Loss: 5.11160
Epoch 46, Val Loss: 4.79147
Epoch 47, Val Loss: 4.83928
Epoch 48, Val Loss: 4.74050
Epoch 49, Val Loss: 4.99697
Epoch 50, Val Loss: 4.98019
Epoch 51, Val Loss: 4.82896
Epoch 52, Val Loss: 5.20960
Epoch 53, Val Loss: 4.80275
Epoch 54, Val Loss: 4.77898
Epoch 55, Val Loss: 4.79570
Epoch 56, Val Loss: 5.16315
Epoch 57, Val Loss: 4.69044
Epoch 58, Val Loss: 4.76915
Epoch 59, Val Loss: 4.73103
Epoch 60, Val Loss: 4.76837
Epoch 61, Val Loss: 4.91890
Epoch 62, Val Loss: 4.76092
Epoch 63, Val Loss: 4.81603
Epoch 64, Val Loss: 4.95775
Epoch 65, Val Loss: 4.77627
Epoch 66, Val Loss: 4.82398
Epoch 67, Val Loss: 4.92515
Epoch 68, Val Loss: 4.76671
Epoch 69, Val Loss: 4.66213
Epoch 70, Val Loss: 4.91281
Epoch 71, Val Loss: 4.66143
Epoch 72, Val Loss: 4.87273
Epoch 73, Val Loss: 4.64475
Epoch 74, Val Loss: 4.85300
Epoch 75, Val Loss: 4.85553
Epoch 76, Val Loss: 4.74323
Epoch 77, Val Loss: 4.72033
Epoch 78, Val Loss: 4.71210
Epoch 79, Val Loss: 4.68338
Epoch 80, Val Loss: 4.60862
Epoch 81, Val Loss: 4.70586
Epoch 82, Val Loss: 4.81384
Epoch 83, Val Loss: 4.88860
Epoch 84, Val Loss: 4.75107
Epoch 85, Val Loss: 4.77135
Epoch 86, Val Loss: 4.74262
Epoch 87, Val Loss: 4.69580
Epoch 88, Val Loss: 4.69951
Epoch 89, Val Loss: 4.62914
Epoch 90, Val Loss: 4.66832
Epoch 91, Val Loss: 4.73591
Epoch 92, Val Loss: 4.71549
Epoch 93, Val Loss: 4.64306
Epoch 94, Val Loss: 4.63384
Epoch 95, Val Loss: 4.54145
Epoch 96, Val Loss: 4.98321
Epoch 97, Val Loss: 4.68555
Epoch 98, Val Loss: 4.86994
Epoch 99, Val Loss: 4.66592
Saved Losses
{'MSE - mean': 4.5517515300902165, 'MSE - std': 0.31068547269761276, 'R2 - mean': 0.5525091512500436, 'R2 - std': 0.008252550664659993} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.61634
Epoch 1, Val Loss: 16.06639
Epoch 2, Val Loss: 5.84523
Epoch 3, Val Loss: 5.53166
Epoch 4, Val Loss: 5.32470
Epoch 5, Val Loss: 5.35923
Epoch 6, Val Loss: 5.46665
Epoch 7, Val Loss: 5.14668
Epoch 8, Val Loss: 5.17147
Epoch 9, Val Loss: 5.13873
Epoch 10, Val Loss: 5.07164
Epoch 11, Val Loss: 5.24499
Epoch 12, Val Loss: 5.35711
Epoch 13, Val Loss: 5.05466
Epoch 14, Val Loss: 5.13289
Epoch 15, Val Loss: 5.04485
Epoch 16, Val Loss: 5.24023
Epoch 17, Val Loss: 4.98887
Epoch 18, Val Loss: 4.99561
Epoch 19, Val Loss: 5.13620
Epoch 20, Val Loss: 4.91626
Epoch 21, Val Loss: 4.84406
Epoch 22, Val Loss: 4.95345
Epoch 23, Val Loss: 4.94468
Epoch 24, Val Loss: 5.09829
Epoch 25, Val Loss: 4.83894
Epoch 26, Val Loss: 4.88346
Epoch 27, Val Loss: 5.09175
Epoch 28, Val Loss: 4.78305
Epoch 29, Val Loss: 4.76013
Epoch 30, Val Loss: 5.12022
Epoch 31, Val Loss: 4.70882
Epoch 32, Val Loss: 4.78894
Epoch 33, Val Loss: 4.76816
Epoch 34, Val Loss: 4.93549
Epoch 35, Val Loss: 5.02012
Epoch 36, Val Loss: 4.82980
Epoch 37, Val Loss: 4.82130
Epoch 38, Val Loss: 4.64759
Epoch 39, Val Loss: 4.72096
Epoch 40, Val Loss: 4.76023
Epoch 41, Val Loss: 4.87821
Epoch 42, Val Loss: 4.61976
Epoch 43, Val Loss: 4.78866
Epoch 44, Val Loss: 4.78409
Epoch 45, Val Loss: 4.66533
Epoch 46, Val Loss: 4.55605
Epoch 47, Val Loss: 4.69756
Epoch 48, Val Loss: 4.75635
Epoch 49, Val Loss: 4.71030
Epoch 50, Val Loss: 4.71699
Epoch 51, Val Loss: 4.86089
Epoch 52, Val Loss: 5.20429
Epoch 53, Val Loss: 4.46634
Epoch 54, Val Loss: 4.72722
Epoch 55, Val Loss: 4.48944
Epoch 56, Val Loss: 4.54217
Epoch 57, Val Loss: 4.56156
Epoch 58, Val Loss: 4.71341
Epoch 59, Val Loss: 4.60192
Epoch 60, Val Loss: 4.45257
Epoch 61, Val Loss: 4.65172
Epoch 62, Val Loss: 4.42920
Epoch 63, Val Loss: 5.01034
Epoch 64, Val Loss: 4.48813
Epoch 65, Val Loss: 4.50032
Epoch 66, Val Loss: 4.46650
Epoch 67, Val Loss: 4.32815
Epoch 68, Val Loss: 4.40631
Epoch 69, Val Loss: 4.81173
Epoch 70, Val Loss: 4.62093
Epoch 71, Val Loss: 4.64979
Epoch 72, Val Loss: 4.41188
Epoch 73, Val Loss: 4.42283
Epoch 74, Val Loss: 4.31631
Epoch 75, Val Loss: 4.43978
Epoch 76, Val Loss: 4.47036
Epoch 77, Val Loss: 4.38711
Epoch 78, Val Loss: 4.53244
Epoch 79, Val Loss: 4.24343
Epoch 80, Val Loss: 4.56516
Epoch 81, Val Loss: 4.31211
Epoch 82, Val Loss: 4.46616
Epoch 83, Val Loss: 4.34126
Epoch 84, Val Loss: 4.39363
Epoch 85, Val Loss: 4.28647
Epoch 86, Val Loss: 4.34759
Epoch 87, Val Loss: 4.32164
Epoch 88, Val Loss: 4.31100
Epoch 89, Val Loss: 4.42193
Epoch 90, Val Loss: 4.40568
Epoch 91, Val Loss: 4.29434
Epoch 92, Val Loss: 4.25217
Epoch 93, Val Loss: 4.45410
Epoch 94, Val Loss: 4.32324
Epoch 95, Val Loss: 4.23618
Epoch 96, Val Loss: 4.25159
Epoch 97, Val Loss: 4.21317
Epoch 98, Val Loss: 4.60441
Epoch 99, Val Loss: 4.25254
Saved Losses
{'MSE - mean': 4.551476715183645, 'MSE - std': 0.26906193297957054, 'R2 - mean': 0.5427423498564845, 'R2 - std': 0.018364358761967924} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.33240
Epoch 1, Val Loss: 14.01553
Epoch 2, Val Loss: 8.88965
Epoch 3, Val Loss: 8.57914
Epoch 4, Val Loss: 7.44311
Epoch 5, Val Loss: 7.53038
Epoch 6, Val Loss: 7.70940
Epoch 7, Val Loss: 7.76587
Epoch 8, Val Loss: 8.54089
Epoch 9, Val Loss: 7.14916
Epoch 10, Val Loss: 7.11557
Epoch 11, Val Loss: 7.16802
Epoch 12, Val Loss: 7.04217
Epoch 13, Val Loss: 7.68387
Epoch 14, Val Loss: 7.29863
Epoch 15, Val Loss: 7.36442
Epoch 16, Val Loss: 7.33292
Epoch 17, Val Loss: 6.86558
Epoch 18, Val Loss: 6.84098
Epoch 19, Val Loss: 6.95553
Epoch 20, Val Loss: 7.00548
Epoch 21, Val Loss: 7.07824
Epoch 22, Val Loss: 7.03581
Epoch 23, Val Loss: 6.93381
Epoch 24, Val Loss: 6.83415
Epoch 25, Val Loss: 7.45853
Epoch 26, Val Loss: 6.97742
Epoch 27, Val Loss: 6.91028
Epoch 28, Val Loss: 6.89828
Epoch 29, Val Loss: 7.16297
Epoch 30, Val Loss: 6.47252
Epoch 31, Val Loss: 6.58550
Epoch 32, Val Loss: 6.50155
Epoch 33, Val Loss: 6.38920
Epoch 34, Val Loss: 6.90274
Epoch 35, Val Loss: 6.42764
Epoch 36, Val Loss: 6.65975
Epoch 37, Val Loss: 6.29849
Epoch 38, Val Loss: 6.82716
Epoch 39, Val Loss: 6.39890
Epoch 40, Val Loss: 6.62639
Epoch 41, Val Loss: 6.74588
Epoch 42, Val Loss: 6.64083
Epoch 43, Val Loss: 6.57492
Epoch 44, Val Loss: 6.27830
Epoch 45, Val Loss: 6.47165
Epoch 46, Val Loss: 6.50104
Epoch 47, Val Loss: 6.14590
Epoch 48, Val Loss: 6.35728
Epoch 49, Val Loss: 6.59944
Epoch 50, Val Loss: 6.22223
Epoch 51, Val Loss: 6.43428
Epoch 52, Val Loss: 6.13259
Epoch 53, Val Loss: 6.23989
Epoch 54, Val Loss: 6.67988
Epoch 55, Val Loss: 6.34229
Epoch 56, Val Loss: 6.01300
Epoch 57, Val Loss: 6.20635
Epoch 58, Val Loss: 6.08067
Epoch 59, Val Loss: 5.89989
Epoch 60, Val Loss: 6.37986
Epoch 61, Val Loss: 5.92611
Epoch 62, Val Loss: 6.18013
Epoch 63, Val Loss: 6.13413
Epoch 64, Val Loss: 5.96788
Epoch 65, Val Loss: 6.37468
Epoch 66, Val Loss: 6.02596
Epoch 67, Val Loss: 6.31517
Epoch 68, Val Loss: 6.11518
Epoch 69, Val Loss: 6.10624
Epoch 70, Val Loss: 6.13694
Epoch 71, Val Loss: 5.98298
Epoch 72, Val Loss: 6.03173
Epoch 73, Val Loss: 6.12199
Epoch 74, Val Loss: 5.76748
Epoch 75, Val Loss: 6.16160
Epoch 76, Val Loss: 5.99506
Epoch 77, Val Loss: 6.70500
Epoch 78, Val Loss: 6.10551
Epoch 79, Val Loss: 6.00781
Epoch 80, Val Loss: 5.92566
Epoch 81, Val Loss: 5.81958
Epoch 82, Val Loss: 5.83437
Epoch 83, Val Loss: 5.97523
Epoch 84, Val Loss: 6.16720
Epoch 85, Val Loss: 5.76240
Epoch 86, Val Loss: 5.96609
Epoch 87, Val Loss: 5.98827
Epoch 88, Val Loss: 5.93707
Epoch 89, Val Loss: 6.31238
Epoch 90, Val Loss: 5.75887
Epoch 91, Val Loss: 6.86890
Epoch 92, Val Loss: 5.73859
Epoch 93, Val Loss: 5.58457
Epoch 94, Val Loss: 6.01991
Epoch 95, Val Loss: 5.82037
Epoch 96, Val Loss: 5.91064
Epoch 97, Val Loss: 5.90303
Epoch 98, Val Loss: 5.65048
Epoch 99, Val Loss: 5.77841
Saved Losses
{'MSE - mean': 4.7697787464797265, 'MSE - std': 0.4985364244415285, 'R2 - mean': 0.5408592326024493, 'R2 - std': 0.016851832557926584} 
 

Results After CV: {'MSE - mean': 4.7697787464797265, 'MSE - std': 0.4985364244415285, 'R2 - mean': 0.5408592326024493, 'R2 - std': 0.016851832557926584}
Train time: 48.40510953620001
Inference time: 0.05274533579995477
Finished cross validation
Trial 1 finished with value: 4.7697787464797265 and parameters: {'p_m': 0.5317505982055122, 'alpha': 5.926016023637411, 'K': 5, 'beta': 1.3944781471916319}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.61128
Epoch 1, Val Loss: 11.05974
Epoch 2, Val Loss: 8.37803
Epoch 3, Val Loss: 6.91995
Epoch 4, Val Loss: 6.63003
Epoch 5, Val Loss: 6.55789
Epoch 6, Val Loss: 6.24524
Epoch 7, Val Loss: 7.12514
Epoch 8, Val Loss: 6.22608
Epoch 9, Val Loss: 6.14240
Epoch 10, Val Loss: 6.51808
Epoch 11, Val Loss: 6.11889
Epoch 12, Val Loss: 5.87781
Epoch 13, Val Loss: 5.95596
Epoch 14, Val Loss: 6.03739
Epoch 15, Val Loss: 5.70048
Epoch 16, Val Loss: 5.76379
Epoch 17, Val Loss: 6.01080
Epoch 18, Val Loss: 5.63030
Epoch 19, Val Loss: 5.53038
Epoch 20, Val Loss: 5.85229
Epoch 21, Val Loss: 5.50413
Epoch 22, Val Loss: 5.57629
Epoch 23, Val Loss: 5.40474
Epoch 24, Val Loss: 5.43241
Epoch 25, Val Loss: 5.50120
Epoch 26, Val Loss: 5.30794
Epoch 27, Val Loss: 5.41124
Epoch 28, Val Loss: 5.48072
Epoch 29, Val Loss: 5.42407
Epoch 30, Val Loss: 5.22914
Epoch 31, Val Loss: 5.23244
Epoch 32, Val Loss: 5.37047
Epoch 33, Val Loss: 5.67052
Epoch 34, Val Loss: 5.14454
Epoch 35, Val Loss: 5.18212
Epoch 36, Val Loss: 5.23070
Epoch 37, Val Loss: 5.11661
Epoch 38, Val Loss: 5.32541
Epoch 39, Val Loss: 5.29973
Epoch 40, Val Loss: 5.46122
Epoch 41, Val Loss: 5.21757
Epoch 42, Val Loss: 5.01489
Epoch 43, Val Loss: 5.59850
Epoch 44, Val Loss: 5.11109
Epoch 45, Val Loss: 5.26233
Epoch 46, Val Loss: 5.05321
Epoch 47, Val Loss: 5.93574
Epoch 48, Val Loss: 5.15261
Epoch 49, Val Loss: 5.10086
Epoch 50, Val Loss: 5.11727
Epoch 51, Val Loss: 4.95545
Epoch 52, Val Loss: 5.15721
Epoch 53, Val Loss: 5.06511
Epoch 54, Val Loss: 5.11040
Epoch 55, Val Loss: 5.06913
Epoch 56, Val Loss: 5.05847
Epoch 57, Val Loss: 5.27565
Epoch 58, Val Loss: 5.46219
Epoch 59, Val Loss: 5.35786
Epoch 60, Val Loss: 5.12524
Epoch 61, Val Loss: 5.04614
Epoch 62, Val Loss: 5.33779
Epoch 63, Val Loss: 5.18623
Epoch 64, Val Loss: 5.23725
Epoch 65, Val Loss: 5.08923
Epoch 66, Val Loss: 4.95090
Epoch 67, Val Loss: 5.00855
Epoch 68, Val Loss: 4.89002
Epoch 69, Val Loss: 5.49517
Epoch 70, Val Loss: 5.33576
Epoch 71, Val Loss: 5.24510
Epoch 72, Val Loss: 5.12734
Epoch 73, Val Loss: 5.05291
Epoch 74, Val Loss: 5.05709
Epoch 75, Val Loss: 5.68558
Epoch 76, Val Loss: 4.87817
Epoch 77, Val Loss: 5.25978
Epoch 78, Val Loss: 5.27373
Epoch 79, Val Loss: 4.97517
Epoch 80, Val Loss: 5.09072
Epoch 81, Val Loss: 4.89073
Epoch 82, Val Loss: 4.89111
Epoch 83, Val Loss: 5.08856
Epoch 84, Val Loss: 5.04257
Epoch 85, Val Loss: 5.15469
Epoch 86, Val Loss: 5.14472
Epoch 87, Val Loss: 4.88053
Epoch 88, Val Loss: 4.87721
Epoch 89, Val Loss: 5.05699
Epoch 90, Val Loss: 5.09225
Epoch 91, Val Loss: 5.33363
Epoch 92, Val Loss: 5.00363
Epoch 93, Val Loss: 4.99454
Epoch 94, Val Loss: 4.90999
Epoch 95, Val Loss: 4.92526
Epoch 96, Val Loss: 5.03944
Epoch 97, Val Loss: 5.10627
Epoch 98, Val Loss: 4.89364
Epoch 99, Val Loss: 4.86277
Saved Losses
{'MSE - mean': 4.989712179710662, 'MSE - std': 0.0, 'R2 - mean': 0.5449547369313157, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.60520
Epoch 1, Val Loss: 8.72092
Epoch 2, Val Loss: 6.13592
Epoch 3, Val Loss: 5.45312
Epoch 4, Val Loss: 5.11899
Epoch 5, Val Loss: 5.56401
Epoch 6, Val Loss: 5.54169
Epoch 7, Val Loss: 5.36431
Epoch 8, Val Loss: 4.99204
Epoch 9, Val Loss: 5.27870
Epoch 10, Val Loss: 4.78414
Epoch 11, Val Loss: 4.73936
Epoch 12, Val Loss: 4.70229
Epoch 13, Val Loss: 4.85456
Epoch 14, Val Loss: 4.91929
Epoch 15, Val Loss: 4.84615
Epoch 16, Val Loss: 4.75459
Epoch 17, Val Loss: 4.82528
Epoch 18, Val Loss: 4.82823
Epoch 19, Val Loss: 4.60616
Epoch 20, Val Loss: 4.57552
Epoch 21, Val Loss: 4.72160
Epoch 22, Val Loss: 4.72712
Epoch 23, Val Loss: 4.45184
Epoch 24, Val Loss: 4.80156
Epoch 25, Val Loss: 4.58368
Epoch 26, Val Loss: 4.54269
Epoch 27, Val Loss: 4.62826
Epoch 28, Val Loss: 4.50394
Epoch 29, Val Loss: 4.40258
Epoch 30, Val Loss: 4.45949
Epoch 31, Val Loss: 4.58495
Epoch 32, Val Loss: 4.57982
Epoch 33, Val Loss: 4.34097
Epoch 34, Val Loss: 4.64988
Epoch 35, Val Loss: 4.36045
Epoch 36, Val Loss: 4.32779
Epoch 37, Val Loss: 4.35134
Epoch 38, Val Loss: 4.31937
Epoch 39, Val Loss: 4.48705
Epoch 40, Val Loss: 4.58531
Epoch 41, Val Loss: 4.32389
Epoch 42, Val Loss: 4.39769
Epoch 43, Val Loss: 4.52097
Epoch 44, Val Loss: 4.40404
Epoch 45, Val Loss: 4.34382
Epoch 46, Val Loss: 4.28648
Epoch 47, Val Loss: 4.28487
Epoch 48, Val Loss: 4.44080
Epoch 49, Val Loss: 4.93763
Epoch 50, Val Loss: 4.45678
Epoch 51, Val Loss: 4.43567
Epoch 52, Val Loss: 4.31326
Epoch 53, Val Loss: 4.24628
Epoch 54, Val Loss: 4.34545
Epoch 55, Val Loss: 4.26368
Epoch 56, Val Loss: 4.59778
Epoch 57, Val Loss: 4.21669
Epoch 58, Val Loss: 4.30272
Epoch 59, Val Loss: 4.23808
Epoch 60, Val Loss: 4.30480
Epoch 61, Val Loss: 4.28881
Epoch 62, Val Loss: 4.32554
Epoch 63, Val Loss: 4.28160
Epoch 64, Val Loss: 4.19401
Epoch 65, Val Loss: 4.26125
Epoch 66, Val Loss: 4.13762
Epoch 67, Val Loss: 4.15574
Epoch 68, Val Loss: 4.15175
Epoch 69, Val Loss: 4.16784
Epoch 70, Val Loss: 4.34932
Epoch 71, Val Loss: 4.23367
Epoch 72, Val Loss: 4.16812
Epoch 73, Val Loss: 4.17929
Epoch 74, Val Loss: 4.21139
Epoch 75, Val Loss: 4.37373
Epoch 76, Val Loss: 4.21345
Epoch 77, Val Loss: 4.28685
Epoch 78, Val Loss: 4.14245
Epoch 79, Val Loss: 4.14531
Epoch 80, Val Loss: 4.28489
Epoch 81, Val Loss: 4.45422
Epoch 82, Val Loss: 4.19884
Epoch 83, Val Loss: 4.15677
Epoch 84, Val Loss: 4.43099
Epoch 85, Val Loss: 4.25338
Epoch 86, Val Loss: 4.27853
Epoch 87, Val Loss: 4.25095
Early stopping applies.
Saved Losses
{'MSE - mean': 4.667899393445756, 'MSE - std': 0.32181278626490606, 'R2 - mean': 0.5408384193459983, 'R2 - std': 0.004116317585317386} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.26429
Epoch 1, Val Loss: 9.31816
Epoch 2, Val Loss: 6.64539
Epoch 3, Val Loss: 6.19232
Epoch 4, Val Loss: 6.17650
Epoch 5, Val Loss: 6.30581
Epoch 6, Val Loss: 6.32222
Epoch 7, Val Loss: 6.78654
Epoch 8, Val Loss: 6.10918
Epoch 9, Val Loss: 6.08130
Epoch 10, Val Loss: 5.86502
Epoch 11, Val Loss: 6.10669
Epoch 12, Val Loss: 6.03084
Epoch 13, Val Loss: 5.82474
Epoch 14, Val Loss: 5.81032
Epoch 15, Val Loss: 5.82309
Epoch 16, Val Loss: 5.93395
Epoch 17, Val Loss: 5.83222
Epoch 18, Val Loss: 6.12571
Epoch 19, Val Loss: 5.62973
Epoch 20, Val Loss: 5.62255
Epoch 21, Val Loss: 5.73355
Epoch 22, Val Loss: 5.69594
Epoch 23, Val Loss: 5.49627
Epoch 24, Val Loss: 5.56503
Epoch 25, Val Loss: 5.45063
Epoch 26, Val Loss: 5.50520
Epoch 27, Val Loss: 6.15571
Epoch 28, Val Loss: 5.56372
Epoch 29, Val Loss: 5.35102
Epoch 30, Val Loss: 5.37179
Epoch 31, Val Loss: 5.51288
Epoch 32, Val Loss: 5.39453
Epoch 33, Val Loss: 5.36335
Epoch 34, Val Loss: 5.40645
Epoch 35, Val Loss: 5.33454
Epoch 36, Val Loss: 5.33466
Epoch 37, Val Loss: 5.45177
Epoch 38, Val Loss: 5.32460
Epoch 39, Val Loss: 5.24592
Epoch 40, Val Loss: 5.33749
Epoch 41, Val Loss: 5.22085
Epoch 42, Val Loss: 5.48350
Epoch 43, Val Loss: 5.32263
Epoch 44, Val Loss: 5.27739
Epoch 45, Val Loss: 5.52823
Epoch 46, Val Loss: 5.74484
Epoch 47, Val Loss: 5.50818
Epoch 48, Val Loss: 5.48111
Epoch 49, Val Loss: 5.19202
Epoch 50, Val Loss: 5.40437
Epoch 51, Val Loss: 5.29581
Epoch 52, Val Loss: 5.41675
Epoch 53, Val Loss: 5.27070
Epoch 54, Val Loss: 5.14184
Epoch 55, Val Loss: 5.23578
Epoch 56, Val Loss: 5.82240
Epoch 57, Val Loss: 5.11815
Epoch 58, Val Loss: 5.11213
Epoch 59, Val Loss: 5.73687
Epoch 60, Val Loss: 5.03354
Epoch 61, Val Loss: 5.39789
Epoch 62, Val Loss: 5.24235
Epoch 63, Val Loss: 5.12933
Epoch 64, Val Loss: 5.08727
Epoch 65, Val Loss: 5.34492
Epoch 66, Val Loss: 5.05764
Epoch 67, Val Loss: 5.45319
Epoch 68, Val Loss: 5.41955
Epoch 69, Val Loss: 5.02968
Epoch 70, Val Loss: 5.09057
Epoch 71, Val Loss: 4.98740
Epoch 72, Val Loss: 4.94119
Epoch 73, Val Loss: 5.36784
Epoch 74, Val Loss: 5.06444
Epoch 75, Val Loss: 5.25353
Epoch 76, Val Loss: 5.50254
Epoch 77, Val Loss: 5.18400
Epoch 78, Val Loss: 5.36699
Epoch 79, Val Loss: 5.14361
Epoch 80, Val Loss: 5.02788
Epoch 81, Val Loss: 5.09862
Epoch 82, Val Loss: 5.47017
Epoch 83, Val Loss: 5.12654
Epoch 84, Val Loss: 5.15713
Epoch 85, Val Loss: 5.14361
Epoch 86, Val Loss: 4.98454
Epoch 87, Val Loss: 4.92278
Epoch 88, Val Loss: 4.89739
Epoch 89, Val Loss: 4.86610
Epoch 90, Val Loss: 5.20201
Epoch 91, Val Loss: 5.19046
Epoch 92, Val Loss: 4.95044
Epoch 93, Val Loss: 4.89514
Epoch 94, Val Loss: 4.93203
Epoch 95, Val Loss: 4.91462
Epoch 96, Val Loss: 5.03903
Epoch 97, Val Loss: 4.91347
Epoch 98, Val Loss: 4.89424
Epoch 99, Val Loss: 5.48478
Saved Losses
{'MSE - mean': 4.789305179342811, 'MSE - std': 0.31388061844319803, 'R2 - mean': 0.5288410416406958, 'R2 - std': 0.017296536953472608} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.09476
Epoch 1, Val Loss: 9.43770
Epoch 2, Val Loss: 6.16134
Epoch 3, Val Loss: 5.27873
Epoch 4, Val Loss: 5.21361
Epoch 5, Val Loss: 5.41323
Epoch 6, Val Loss: 5.03845
Epoch 7, Val Loss: 5.07878
Epoch 8, Val Loss: 5.00449
Epoch 9, Val Loss: 5.04964
Epoch 10, Val Loss: 5.24707
Epoch 11, Val Loss: 5.08066
Epoch 12, Val Loss: 5.02553
Epoch 13, Val Loss: 5.06566
Epoch 14, Val Loss: 5.00971
Epoch 15, Val Loss: 4.87638
Epoch 16, Val Loss: 4.94448
Epoch 17, Val Loss: 5.01049
Epoch 18, Val Loss: 4.84958
Epoch 19, Val Loss: 4.96434
Epoch 20, Val Loss: 5.32606
Epoch 21, Val Loss: 4.90071
Epoch 22, Val Loss: 4.81849
Epoch 23, Val Loss: 4.82236
Epoch 24, Val Loss: 5.00481
Epoch 25, Val Loss: 4.89821
Epoch 26, Val Loss: 5.24130
Epoch 27, Val Loss: 5.16610
Epoch 28, Val Loss: 4.83162
Epoch 29, Val Loss: 4.87284
Epoch 30, Val Loss: 5.04937
Epoch 31, Val Loss: 4.77239
Epoch 32, Val Loss: 4.76627
Epoch 33, Val Loss: 5.08022
Epoch 34, Val Loss: 4.99459
Epoch 35, Val Loss: 4.83528
Epoch 36, Val Loss: 4.72292
Epoch 37, Val Loss: 4.76844
Epoch 38, Val Loss: 4.72812
Epoch 39, Val Loss: 4.74031
Epoch 40, Val Loss: 4.98579
Epoch 41, Val Loss: 4.75613
Epoch 42, Val Loss: 4.79188
Epoch 43, Val Loss: 4.72921
Epoch 44, Val Loss: 4.93796
Epoch 45, Val Loss: 4.65641
Epoch 46, Val Loss: 4.69043
Epoch 47, Val Loss: 4.67709
Epoch 48, Val Loss: 4.66358
Epoch 49, Val Loss: 4.69793
Epoch 50, Val Loss: 4.91775
Epoch 51, Val Loss: 4.62653
Epoch 52, Val Loss: 4.69372
Epoch 53, Val Loss: 4.88898
Epoch 54, Val Loss: 4.84572
Epoch 55, Val Loss: 4.57752
Epoch 56, Val Loss: 4.59209
Epoch 57, Val Loss: 4.62026
Epoch 58, Val Loss: 4.74466
Epoch 59, Val Loss: 4.57392
Epoch 60, Val Loss: 4.59258
Epoch 61, Val Loss: 4.57867
Epoch 62, Val Loss: 4.74119
Epoch 63, Val Loss: 4.69314
Epoch 64, Val Loss: 4.57398
Epoch 65, Val Loss: 4.53218
Epoch 66, Val Loss: 4.76322
Epoch 67, Val Loss: 4.46598
Epoch 68, Val Loss: 4.80784
Epoch 69, Val Loss: 4.47306
Epoch 70, Val Loss: 4.54929
Epoch 71, Val Loss: 4.43121
Epoch 72, Val Loss: 4.56706
Epoch 73, Val Loss: 4.47548
Epoch 74, Val Loss: 4.53321
Epoch 75, Val Loss: 4.54403
Epoch 76, Val Loss: 4.67525
Epoch 77, Val Loss: 4.39240
Epoch 78, Val Loss: 4.48218
Epoch 79, Val Loss: 4.49733
Epoch 80, Val Loss: 4.36910
Epoch 81, Val Loss: 4.45461
Epoch 82, Val Loss: 4.67800
Epoch 83, Val Loss: 4.33011
Epoch 84, Val Loss: 4.30000
Epoch 85, Val Loss: 4.34108
Epoch 86, Val Loss: 4.42941
Epoch 87, Val Loss: 4.44191
Epoch 88, Val Loss: 4.46547
Epoch 89, Val Loss: 4.35672
Epoch 90, Val Loss: 4.73008
Epoch 91, Val Loss: 4.67519
Epoch 92, Val Loss: 4.49072
Epoch 93, Val Loss: 4.30783
Epoch 94, Val Loss: 4.29911
Epoch 95, Val Loss: 4.26879
Epoch 96, Val Loss: 4.41431
Epoch 97, Val Loss: 4.24535
Epoch 98, Val Loss: 4.96728
Epoch 99, Val Loss: 4.26215
Saved Losses
{'MSE - mean': 4.737733099990081, 'MSE - std': 0.28612902698259474, 'R2 - mean': 0.5241261580059696, 'R2 - std': 0.017060715870213575} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.85666
Epoch 1, Val Loss: 10.81224
Epoch 2, Val Loss: 7.96230
Epoch 3, Val Loss: 7.37210
Epoch 4, Val Loss: 7.53069
Epoch 5, Val Loss: 7.15173
Epoch 6, Val Loss: 7.71021
Epoch 7, Val Loss: 7.29594
Epoch 8, Val Loss: 7.70653
Epoch 9, Val Loss: 7.21808
Epoch 10, Val Loss: 7.18689
Epoch 11, Val Loss: 7.11222
Epoch 12, Val Loss: 7.00905
Epoch 13, Val Loss: 7.02385
Epoch 14, Val Loss: 7.11343
Epoch 15, Val Loss: 6.90462
Epoch 16, Val Loss: 7.34897
Epoch 17, Val Loss: 6.85561
Epoch 18, Val Loss: 7.04232
Epoch 19, Val Loss: 6.90730
Epoch 20, Val Loss: 7.06102
Epoch 21, Val Loss: 7.08927
Epoch 22, Val Loss: 7.16339
Epoch 23, Val Loss: 7.07271
Epoch 24, Val Loss: 6.97979
Epoch 25, Val Loss: 7.31598
Epoch 26, Val Loss: 7.18695
Epoch 27, Val Loss: 6.71596
Epoch 28, Val Loss: 6.76737
Epoch 29, Val Loss: 6.80014
Epoch 30, Val Loss: 6.85240
Epoch 31, Val Loss: 6.62833
Epoch 32, Val Loss: 6.68715
Epoch 33, Val Loss: 6.63893
Epoch 34, Val Loss: 6.64591
Epoch 35, Val Loss: 6.77551
Epoch 36, Val Loss: 6.77621
Epoch 37, Val Loss: 6.85153
Epoch 38, Val Loss: 7.01661
Epoch 39, Val Loss: 6.61767
Epoch 40, Val Loss: 6.58204
Epoch 41, Val Loss: 6.51520
Epoch 42, Val Loss: 6.71832
Epoch 43, Val Loss: 6.55837
Epoch 44, Val Loss: 6.59098
Epoch 45, Val Loss: 6.63274
Epoch 46, Val Loss: 6.70215
Epoch 47, Val Loss: 6.53742
Epoch 48, Val Loss: 7.67241
Epoch 49, Val Loss: 6.52235
Epoch 50, Val Loss: 6.63022
Epoch 51, Val Loss: 6.82177
Epoch 52, Val Loss: 6.54080
Epoch 53, Val Loss: 6.53335
Epoch 54, Val Loss: 6.33309
Epoch 55, Val Loss: 6.73938
Epoch 56, Val Loss: 6.71302
Epoch 57, Val Loss: 6.43546
Epoch 58, Val Loss: 6.57580
Epoch 59, Val Loss: 7.13411
Epoch 60, Val Loss: 6.37194
Epoch 61, Val Loss: 6.58616
Epoch 62, Val Loss: 6.32309
Epoch 63, Val Loss: 6.71583
Epoch 64, Val Loss: 6.33305
Epoch 65, Val Loss: 6.53387
Epoch 66, Val Loss: 6.30707
Epoch 67, Val Loss: 6.80675
Epoch 68, Val Loss: 6.43536
Epoch 69, Val Loss: 6.21236
Epoch 70, Val Loss: 6.86796
Epoch 71, Val Loss: 6.31309
Epoch 72, Val Loss: 6.11217
Epoch 73, Val Loss: 6.28421
Epoch 74, Val Loss: 6.14201
Epoch 75, Val Loss: 6.13169
Epoch 76, Val Loss: 6.06947
Epoch 77, Val Loss: 6.22162
Epoch 78, Val Loss: 6.35507
Epoch 79, Val Loss: 6.17844
Epoch 80, Val Loss: 6.29629
Epoch 81, Val Loss: 6.35468
Epoch 82, Val Loss: 6.19691
Epoch 83, Val Loss: 6.22847
Epoch 84, Val Loss: 6.23966
Epoch 85, Val Loss: 6.34061
Epoch 86, Val Loss: 6.08219
Epoch 87, Val Loss: 6.18638
Epoch 88, Val Loss: 6.29249
Epoch 89, Val Loss: 6.21601
Epoch 90, Val Loss: 6.25108
Epoch 91, Val Loss: 6.19344
Epoch 92, Val Loss: 6.20877
Epoch 93, Val Loss: 6.40533
Epoch 94, Val Loss: 6.06384
Epoch 95, Val Loss: 5.99738
Epoch 96, Val Loss: 6.00701
Epoch 97, Val Loss: 5.92469
Epoch 98, Val Loss: 5.96249
Epoch 99, Val Loss: 6.15106
Saved Losses
{'MSE - mean': 4.9637164766771855, 'MSE - std': 0.5193936871210781, 'R2 - mean': 0.5222503654099214, 'R2 - std': 0.015713968698482333} 
 

Results After CV: {'MSE - mean': 4.9637164766771855, 'MSE - std': 0.5193936871210781, 'R2 - mean': 0.5222503654099214, 'R2 - std': 0.015713968698482333}
Train time: 81.48345460499999
Inference time: 0.05151723000003585
Finished cross validation
Trial 2 finished with value: 4.9637164766771855 and parameters: {'p_m': 0.17183836603187733, 'alpha': 5.978804038393941, 'K': 10, 'beta': 2.1314975559770803}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.14901
Epoch 1, Val Loss: 13.99817
Epoch 2, Val Loss: 7.37932
Epoch 3, Val Loss: 6.98661
Epoch 4, Val Loss: 6.75175
Epoch 5, Val Loss: 6.51753
Epoch 6, Val Loss: 6.61192
Epoch 7, Val Loss: 6.34205
Epoch 8, Val Loss: 6.55166
Epoch 9, Val Loss: 6.52729
Epoch 10, Val Loss: 6.56842
Epoch 11, Val Loss: 6.40877
Epoch 12, Val Loss: 6.56206
Epoch 13, Val Loss: 6.56120
Epoch 14, Val Loss: 6.38337
Epoch 15, Val Loss: 6.17455
Epoch 16, Val Loss: 6.10551
Epoch 17, Val Loss: 6.60163
Epoch 18, Val Loss: 6.50548
Epoch 19, Val Loss: 6.02802
Epoch 20, Val Loss: 6.27548
Epoch 21, Val Loss: 6.86941
Epoch 22, Val Loss: 5.95174
Epoch 23, Val Loss: 6.09681
Epoch 24, Val Loss: 6.10793
Epoch 25, Val Loss: 6.05115
Epoch 26, Val Loss: 5.82544
Epoch 27, Val Loss: 6.30420
Epoch 28, Val Loss: 5.97270
Epoch 29, Val Loss: 6.00622
Epoch 30, Val Loss: 6.04438
Epoch 31, Val Loss: 5.85952
Epoch 32, Val Loss: 5.64639
Epoch 33, Val Loss: 5.60058
Epoch 34, Val Loss: 5.61017
Epoch 35, Val Loss: 5.87213
Epoch 36, Val Loss: 5.91300
Epoch 37, Val Loss: 5.53439
Epoch 38, Val Loss: 5.57698
Epoch 39, Val Loss: 5.53376
Epoch 40, Val Loss: 5.64049
Epoch 41, Val Loss: 5.46587
Epoch 42, Val Loss: 5.79064
Epoch 43, Val Loss: 5.59770
Epoch 44, Val Loss: 5.52219
Epoch 45, Val Loss: 5.40485
Epoch 46, Val Loss: 5.47764
Epoch 47, Val Loss: 5.49436
Epoch 48, Val Loss: 5.47925
Epoch 49, Val Loss: 5.63063
Epoch 50, Val Loss: 5.36735
Epoch 51, Val Loss: 5.35378
Epoch 52, Val Loss: 5.53031
Epoch 53, Val Loss: 5.47057
Epoch 54, Val Loss: 5.48544
Epoch 55, Val Loss: 5.49926
Epoch 56, Val Loss: 5.51433
Epoch 57, Val Loss: 5.26099
Epoch 58, Val Loss: 5.28765
Epoch 59, Val Loss: 5.32697
Epoch 60, Val Loss: 5.31684
Epoch 61, Val Loss: 5.55160
Epoch 62, Val Loss: 5.29956
Epoch 63, Val Loss: 5.32774
Epoch 64, Val Loss: 5.30600
Epoch 65, Val Loss: 5.31660
Epoch 66, Val Loss: 5.45109
Epoch 67, Val Loss: 5.46148
Epoch 68, Val Loss: 5.22263
Epoch 69, Val Loss: 5.33727
Epoch 70, Val Loss: 5.83492
Epoch 71, Val Loss: 5.22752
Epoch 72, Val Loss: 5.26586
Epoch 73, Val Loss: 5.30877
Epoch 74, Val Loss: 5.58923
Epoch 75, Val Loss: 5.46286
Epoch 76, Val Loss: 5.24339
Epoch 77, Val Loss: 5.51425
Epoch 78, Val Loss: 5.31788
Epoch 79, Val Loss: 5.30049
Epoch 80, Val Loss: 5.17069
Epoch 81, Val Loss: 5.44630
Epoch 82, Val Loss: 5.15298
Epoch 83, Val Loss: 5.08864
Epoch 84, Val Loss: 5.34536
Epoch 85, Val Loss: 5.36988
Epoch 86, Val Loss: 5.33466
Epoch 87, Val Loss: 5.55008
Epoch 88, Val Loss: 5.49416
Epoch 89, Val Loss: 5.17763
Epoch 90, Val Loss: 5.28605
Epoch 91, Val Loss: 5.20768
Epoch 92, Val Loss: 5.34900
Epoch 93, Val Loss: 5.28163
Epoch 94, Val Loss: 5.11969
Epoch 95, Val Loss: 5.20731
Epoch 96, Val Loss: 5.35060
Epoch 97, Val Loss: 5.08259
Epoch 98, Val Loss: 5.08418
Epoch 99, Val Loss: 5.03366
Saved Losses
{'MSE - mean': 5.190874096746983, 'MSE - std': 0.0, 'R2 - mean': 0.5266094348055924, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.00446
Epoch 1, Val Loss: 5.30920
Epoch 2, Val Loss: 5.25473
Epoch 3, Val Loss: 5.42862
Epoch 4, Val Loss: 5.17984
Epoch 5, Val Loss: 5.11977
Epoch 6, Val Loss: 4.98198
Epoch 7, Val Loss: 5.10782
Epoch 8, Val Loss: 5.29959
Epoch 9, Val Loss: 5.26226
Epoch 10, Val Loss: 5.09863
Epoch 11, Val Loss: 5.25145
Epoch 12, Val Loss: 4.94605
Epoch 13, Val Loss: 4.92726
Epoch 14, Val Loss: 5.04880
Epoch 15, Val Loss: 5.02834
Epoch 16, Val Loss: 4.94674
Epoch 17, Val Loss: 4.87979
Epoch 18, Val Loss: 5.00264
Epoch 19, Val Loss: 4.95617
Epoch 20, Val Loss: 4.84230
Epoch 21, Val Loss: 4.80036
Epoch 22, Val Loss: 5.38904
Epoch 23, Val Loss: 4.87344
Epoch 24, Val Loss: 5.21742
Epoch 25, Val Loss: 4.88067
Epoch 26, Val Loss: 5.05804
Epoch 27, Val Loss: 4.87053
Epoch 28, Val Loss: 4.87385
Epoch 29, Val Loss: 5.11147
Epoch 30, Val Loss: 4.75091
Epoch 31, Val Loss: 5.02825
Epoch 32, Val Loss: 4.76146
Epoch 33, Val Loss: 4.78502
Epoch 34, Val Loss: 5.01205
Epoch 35, Val Loss: 5.00941
Epoch 36, Val Loss: 5.06133
Epoch 37, Val Loss: 4.85747
Epoch 38, Val Loss: 4.69067
Epoch 39, Val Loss: 5.11479
Epoch 40, Val Loss: 4.67513
Epoch 41, Val Loss: 4.71137
Epoch 42, Val Loss: 4.72891
Epoch 43, Val Loss: 5.02565
Epoch 44, Val Loss: 4.75182
Epoch 45, Val Loss: 4.74014
Epoch 46, Val Loss: 5.21879
Epoch 47, Val Loss: 4.75702
Epoch 48, Val Loss: 4.65939
Epoch 49, Val Loss: 4.66036
Epoch 50, Val Loss: 4.65823
Epoch 51, Val Loss: 4.65265
Epoch 52, Val Loss: 4.59094
Epoch 53, Val Loss: 4.56521
Epoch 54, Val Loss: 4.60391
Epoch 55, Val Loss: 4.56283
Epoch 56, Val Loss: 4.76944
Epoch 57, Val Loss: 4.62067
Epoch 58, Val Loss: 4.69561
Epoch 59, Val Loss: 4.72021
Epoch 60, Val Loss: 4.92596
Epoch 61, Val Loss: 4.87134
Epoch 62, Val Loss: 4.56837
Epoch 63, Val Loss: 4.96217
Epoch 64, Val Loss: 4.61022
Epoch 65, Val Loss: 4.64728
Epoch 66, Val Loss: 4.59000
Epoch 67, Val Loss: 4.57614
Epoch 68, Val Loss: 4.54717
Epoch 69, Val Loss: 4.52457
Epoch 70, Val Loss: 5.39895
Epoch 71, Val Loss: 4.54451
Epoch 72, Val Loss: 4.52430
Epoch 73, Val Loss: 4.70938
Epoch 74, Val Loss: 4.58387
Epoch 75, Val Loss: 4.53135
Epoch 76, Val Loss: 4.61546
Epoch 77, Val Loss: 4.66394
Epoch 78, Val Loss: 4.61673
Epoch 79, Val Loss: 4.50669
Epoch 80, Val Loss: 4.93660
Epoch 81, Val Loss: 4.57131
Epoch 82, Val Loss: 4.63066
Epoch 83, Val Loss: 4.77002
Epoch 84, Val Loss: 4.59404
Epoch 85, Val Loss: 4.53760
Epoch 86, Val Loss: 4.84319
Epoch 87, Val Loss: 4.61547
Epoch 88, Val Loss: 4.45616
Epoch 89, Val Loss: 4.40060
Epoch 90, Val Loss: 4.66011
Epoch 91, Val Loss: 4.57388
Epoch 92, Val Loss: 4.73723
Epoch 93, Val Loss: 4.42596
Epoch 94, Val Loss: 4.51367
Epoch 95, Val Loss: 4.47176
Epoch 96, Val Loss: 4.40889
Epoch 97, Val Loss: 4.36784
Epoch 98, Val Loss: 5.06342
Epoch 99, Val Loss: 4.43831
Saved Losses
{'MSE - mean': 4.918184765526059, 'MSE - std': 0.27268933122092465, 'R2 - mean': 0.5157077922139008, 'R2 - std': 0.01090164259169163} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.78628
Epoch 1, Val Loss: 9.53709
Epoch 2, Val Loss: 6.32356
Epoch 3, Val Loss: 6.35034
Epoch 4, Val Loss: 6.32582
Epoch 5, Val Loss: 6.04817
Epoch 6, Val Loss: 5.85290
Epoch 7, Val Loss: 6.05803
Epoch 8, Val Loss: 5.94655
Epoch 9, Val Loss: 5.72801
Epoch 10, Val Loss: 5.65616
Epoch 11, Val Loss: 5.51775
Epoch 12, Val Loss: 5.47919
Epoch 13, Val Loss: 5.45506
Epoch 14, Val Loss: 5.53241
Epoch 15, Val Loss: 5.44682
Epoch 16, Val Loss: 5.98853
Epoch 17, Val Loss: 5.54699
Epoch 18, Val Loss: 5.58159
Epoch 19, Val Loss: 5.32932
Epoch 20, Val Loss: 5.36142
Epoch 21, Val Loss: 5.34261
Epoch 22, Val Loss: 5.32886
Epoch 23, Val Loss: 5.46918
Epoch 24, Val Loss: 5.77326
Epoch 25, Val Loss: 5.64966
Epoch 26, Val Loss: 5.23116
Epoch 27, Val Loss: 5.23104
Epoch 28, Val Loss: 5.31938
Epoch 29, Val Loss: 5.48437
Epoch 30, Val Loss: 5.36776
Epoch 31, Val Loss: 5.24201
Epoch 32, Val Loss: 5.50901
Epoch 33, Val Loss: 5.30453
Epoch 34, Val Loss: 5.56198
Epoch 35, Val Loss: 5.23366
Epoch 36, Val Loss: 5.31791
Epoch 37, Val Loss: 5.13923
Epoch 38, Val Loss: 5.22600
Epoch 39, Val Loss: 5.15639
Epoch 40, Val Loss: 5.24767
Epoch 41, Val Loss: 5.21293
Epoch 42, Val Loss: 5.15760
Epoch 43, Val Loss: 5.38669
Epoch 44, Val Loss: 5.32066
Epoch 45, Val Loss: 5.19456
Epoch 46, Val Loss: 5.16027
Epoch 47, Val Loss: 5.23802
Epoch 48, Val Loss: 5.37315
Epoch 49, Val Loss: 5.14484
Epoch 50, Val Loss: 5.08971
Epoch 51, Val Loss: 5.17116
Epoch 52, Val Loss: 5.12059
Epoch 53, Val Loss: 5.18031
Epoch 54, Val Loss: 5.11444
Epoch 55, Val Loss: 5.29455
Epoch 56, Val Loss: 5.01875
Epoch 57, Val Loss: 5.08589
Epoch 58, Val Loss: 5.06124
Epoch 59, Val Loss: 5.04828
Epoch 60, Val Loss: 5.13570
Epoch 61, Val Loss: 5.05162
Epoch 62, Val Loss: 4.99642
Epoch 63, Val Loss: 5.09157
Epoch 64, Val Loss: 5.01377
Epoch 65, Val Loss: 4.99906
Epoch 66, Val Loss: 5.11972
Epoch 67, Val Loss: 5.21396
Epoch 68, Val Loss: 5.78454
Epoch 69, Val Loss: 5.12564
Epoch 70, Val Loss: 5.20564
Epoch 71, Val Loss: 5.20460
Epoch 72, Val Loss: 5.26710
Epoch 73, Val Loss: 4.97836
Epoch 74, Val Loss: 4.95566
Epoch 75, Val Loss: 5.01863
Epoch 76, Val Loss: 5.02927
Epoch 77, Val Loss: 4.92954
Epoch 78, Val Loss: 5.10868
Epoch 79, Val Loss: 5.13661
Epoch 80, Val Loss: 4.93683
Epoch 81, Val Loss: 5.33256
Epoch 82, Val Loss: 5.10659
Epoch 83, Val Loss: 4.90346
Epoch 84, Val Loss: 5.10424
Epoch 85, Val Loss: 4.88916
Epoch 86, Val Loss: 4.94453
Epoch 87, Val Loss: 4.99822
Epoch 88, Val Loss: 4.98482
Epoch 89, Val Loss: 4.94419
Epoch 90, Val Loss: 5.03672
Epoch 91, Val Loss: 5.50630
Epoch 92, Val Loss: 4.90605
Epoch 93, Val Loss: 5.06293
Epoch 94, Val Loss: 5.33006
Epoch 95, Val Loss: 5.18916
Epoch 96, Val Loss: 5.17781
Epoch 97, Val Loss: 4.93280
Epoch 98, Val Loss: 4.95254
Epoch 99, Val Loss: 4.95880
Saved Losses
{'MSE - mean': 4.957766224941756, 'MSE - std': 0.22957866792618864, 'R2 - mean': 0.511929445836652, 'R2 - std': 0.010381827560257828} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.07264
Epoch 1, Val Loss: 7.85028
Epoch 2, Val Loss: 6.07942
Epoch 3, Val Loss: 5.79533
Epoch 4, Val Loss: 5.66770
Epoch 5, Val Loss: 5.38323
Epoch 6, Val Loss: 5.25459
Epoch 7, Val Loss: 5.53661
Epoch 8, Val Loss: 5.21715
Epoch 9, Val Loss: 5.19809
Epoch 10, Val Loss: 5.32741
Epoch 11, Val Loss: 5.25366
Epoch 12, Val Loss: 5.19522
Epoch 13, Val Loss: 5.62582
Epoch 14, Val Loss: 5.39863
Epoch 15, Val Loss: 5.50182
Epoch 16, Val Loss: 5.42737
Epoch 17, Val Loss: 5.13710
Epoch 18, Val Loss: 5.05752
Epoch 19, Val Loss: 5.02871
Epoch 20, Val Loss: 5.30837
Epoch 21, Val Loss: 5.24376
Epoch 22, Val Loss: 5.35059
Epoch 23, Val Loss: 5.02162
Epoch 24, Val Loss: 5.14551
Epoch 25, Val Loss: 5.15984
Epoch 26, Val Loss: 5.17130
Epoch 27, Val Loss: 5.16381
Epoch 28, Val Loss: 4.84009
Epoch 29, Val Loss: 5.17031
Epoch 30, Val Loss: 4.94335
Epoch 31, Val Loss: 4.83414
Epoch 32, Val Loss: 5.05031
Epoch 33, Val Loss: 5.02260
Epoch 34, Val Loss: 4.80614
Epoch 35, Val Loss: 4.93824
Epoch 36, Val Loss: 4.76628
Epoch 37, Val Loss: 4.75951
Epoch 38, Val Loss: 4.86855
Epoch 39, Val Loss: 4.68879
Epoch 40, Val Loss: 4.89955
Epoch 41, Val Loss: 4.70970
Epoch 42, Val Loss: 4.91704
Epoch 43, Val Loss: 5.28896
Epoch 44, Val Loss: 4.72052
Epoch 45, Val Loss: 4.74717
Epoch 46, Val Loss: 4.65409
Epoch 47, Val Loss: 4.66016
Epoch 48, Val Loss: 4.87422
Epoch 49, Val Loss: 4.72824
Epoch 50, Val Loss: 5.05417
Epoch 51, Val Loss: 4.59897
Epoch 52, Val Loss: 4.76796
Epoch 53, Val Loss: 4.56920
Epoch 54, Val Loss: 4.68545
Epoch 55, Val Loss: 4.52632
Epoch 56, Val Loss: 4.69443
Epoch 57, Val Loss: 4.60574
Epoch 58, Val Loss: 4.60599
Epoch 59, Val Loss: 4.70174
Epoch 60, Val Loss: 4.78617
Epoch 61, Val Loss: 4.64324
Epoch 62, Val Loss: 4.56124
Epoch 63, Val Loss: 4.74575
Epoch 64, Val Loss: 4.93284
Epoch 65, Val Loss: 4.53899
Epoch 66, Val Loss: 4.44569
Epoch 67, Val Loss: 4.53307
Epoch 68, Val Loss: 4.59086
Epoch 69, Val Loss: 4.44819
Epoch 70, Val Loss: 4.45352
Epoch 71, Val Loss: 4.58846
Epoch 72, Val Loss: 4.54077
Epoch 73, Val Loss: 4.47902
Epoch 74, Val Loss: 4.44108
Epoch 75, Val Loss: 4.52066
Epoch 76, Val Loss: 4.63035
Epoch 77, Val Loss: 4.72556
Epoch 78, Val Loss: 4.63934
Epoch 79, Val Loss: 4.47305
Epoch 80, Val Loss: 4.45290
Epoch 81, Val Loss: 4.42755
Epoch 82, Val Loss: 4.40070
Epoch 83, Val Loss: 4.55352
Epoch 84, Val Loss: 4.73213
Epoch 85, Val Loss: 4.44422
Epoch 86, Val Loss: 4.51988
Epoch 87, Val Loss: 4.46401
Epoch 88, Val Loss: 4.31316
Epoch 89, Val Loss: 4.41708
Epoch 90, Val Loss: 4.52348
Epoch 91, Val Loss: 4.39599
Epoch 92, Val Loss: 4.51895
Epoch 93, Val Loss: 4.72164
Epoch 94, Val Loss: 4.34058
Epoch 95, Val Loss: 4.59430
Epoch 96, Val Loss: 4.35580
Epoch 97, Val Loss: 4.44418
Epoch 98, Val Loss: 4.38557
Epoch 99, Val Loss: 4.59235
Saved Losses
{'MSE - mean': 4.8788380173697865, 'MSE - std': 0.24128563866638295, 'R2 - mean': 0.5098644071296874, 'R2 - std': 0.009676255071151328} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.03572
Epoch 1, Val Loss: 10.92806
Epoch 2, Val Loss: 9.17006
Epoch 3, Val Loss: 8.29398
Epoch 4, Val Loss: 7.67982
Epoch 5, Val Loss: 7.50012
Epoch 6, Val Loss: 7.84384
Epoch 7, Val Loss: 7.46527
Epoch 8, Val Loss: 7.73549
Epoch 9, Val Loss: 7.51256
Epoch 10, Val Loss: 7.51954
Epoch 11, Val Loss: 7.99258
Epoch 12, Val Loss: 7.15285
Epoch 13, Val Loss: 7.51224
Epoch 14, Val Loss: 7.24356
Epoch 15, Val Loss: 7.09047
Epoch 16, Val Loss: 7.24019
Epoch 17, Val Loss: 7.16782
Epoch 18, Val Loss: 7.17800
Epoch 19, Val Loss: 7.19570
Epoch 20, Val Loss: 7.87101
Epoch 21, Val Loss: 7.12089
Epoch 22, Val Loss: 7.71311
Epoch 23, Val Loss: 7.17325
Epoch 24, Val Loss: 7.35905
Epoch 25, Val Loss: 7.00444
Epoch 26, Val Loss: 7.30809
Epoch 27, Val Loss: 7.09553
Epoch 28, Val Loss: 6.87233
Epoch 29, Val Loss: 7.02444
Epoch 30, Val Loss: 6.82786
Epoch 31, Val Loss: 7.44975
Epoch 32, Val Loss: 7.11152
Epoch 33, Val Loss: 6.93031
Epoch 34, Val Loss: 6.99806
Epoch 35, Val Loss: 6.88096
Epoch 36, Val Loss: 7.28081
Epoch 37, Val Loss: 6.98989
Epoch 38, Val Loss: 7.23815
Epoch 39, Val Loss: 7.23359
Epoch 40, Val Loss: 7.16358
Epoch 41, Val Loss: 6.80945
Epoch 42, Val Loss: 6.75391
Epoch 43, Val Loss: 7.09870
Epoch 44, Val Loss: 7.71007
Epoch 45, Val Loss: 7.18412
Epoch 46, Val Loss: 6.92323
Epoch 47, Val Loss: 7.20209
Epoch 48, Val Loss: 6.65461
Epoch 49, Val Loss: 6.81376
Epoch 50, Val Loss: 7.02028
Epoch 51, Val Loss: 7.06437
Epoch 52, Val Loss: 7.06590
Epoch 53, Val Loss: 6.76725
Epoch 54, Val Loss: 6.69111
Epoch 55, Val Loss: 6.90708
Epoch 56, Val Loss: 6.68536
Epoch 57, Val Loss: 6.90148
Epoch 58, Val Loss: 6.60992
Epoch 59, Val Loss: 7.21677
Epoch 60, Val Loss: 6.58374
Epoch 61, Val Loss: 6.68682
Epoch 62, Val Loss: 6.82107
Epoch 63, Val Loss: 7.49487
Epoch 64, Val Loss: 6.63502
Epoch 65, Val Loss: 7.25971
Epoch 66, Val Loss: 6.74114
Epoch 67, Val Loss: 7.29696
Epoch 68, Val Loss: 6.73399
Epoch 69, Val Loss: 6.69133
Epoch 70, Val Loss: 7.22404
Epoch 71, Val Loss: 6.69952
Epoch 72, Val Loss: 6.74144
Epoch 73, Val Loss: 7.08780
Epoch 74, Val Loss: 6.65666
Epoch 75, Val Loss: 6.81651
Epoch 76, Val Loss: 6.42572
Epoch 77, Val Loss: 6.47411
Epoch 78, Val Loss: 6.63743
Epoch 79, Val Loss: 7.12833
Epoch 80, Val Loss: 6.72017
Epoch 81, Val Loss: 6.53327
Epoch 82, Val Loss: 6.42741
Epoch 83, Val Loss: 6.47949
Epoch 84, Val Loss: 6.74882
Epoch 85, Val Loss: 6.54762
Epoch 86, Val Loss: 6.65379
Epoch 87, Val Loss: 6.73844
Epoch 88, Val Loss: 6.63050
Epoch 89, Val Loss: 6.60343
Epoch 90, Val Loss: 6.82893
Epoch 91, Val Loss: 6.48183
Epoch 92, Val Loss: 6.50474
Epoch 93, Val Loss: 6.37544
Epoch 94, Val Loss: 6.39530
Epoch 95, Val Loss: 6.49743
Epoch 96, Val Loss: 6.33469
Epoch 97, Val Loss: 6.67921
Epoch 98, Val Loss: 6.68306
Epoch 99, Val Loss: 6.45356
Saved Losses
{'MSE - mean': 5.171112939114873, 'MSE - std': 0.6231159820336024, 'R2 - mean': 0.5030248083761484, 'R2 - std': 0.0161871669602571} 
 

Results After CV: {'MSE - mean': 5.171112939114873, 'MSE - std': 0.6231159820336024, 'R2 - mean': 0.5030248083761484, 'R2 - std': 0.0161871669602571}
Train time: 117.94608972099995
Inference time: 0.050323904799961384
Finished cross validation
Trial 3 finished with value: 5.171112939114873 and parameters: {'p_m': 0.1581611555890941, 'alpha': 2.8377560547804483, 'K': 20, 'beta': 2.7818227115271834}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 23.97939
Epoch 1, Val Loss: 11.12089
Epoch 2, Val Loss: 7.70171
Epoch 3, Val Loss: 7.21144
Epoch 4, Val Loss: 6.95883
Epoch 5, Val Loss: 6.85416
Epoch 6, Val Loss: 6.73151
Epoch 7, Val Loss: 6.85013
Epoch 8, Val Loss: 6.61236
Epoch 9, Val Loss: 6.59553
Epoch 10, Val Loss: 6.57476
Epoch 11, Val Loss: 6.82858
Epoch 12, Val Loss: 6.89457
Epoch 13, Val Loss: 6.84658
Epoch 14, Val Loss: 6.36613
Epoch 15, Val Loss: 6.38311
Epoch 16, Val Loss: 6.30717
Epoch 17, Val Loss: 6.51961
Epoch 18, Val Loss: 6.38139
Epoch 19, Val Loss: 6.27711
Epoch 20, Val Loss: 6.17517
Epoch 21, Val Loss: 6.64731
Epoch 22, Val Loss: 6.19422
Epoch 23, Val Loss: 6.37403
Epoch 24, Val Loss: 6.07692
Epoch 25, Val Loss: 6.41267
Epoch 26, Val Loss: 6.04545
Epoch 27, Val Loss: 5.93953
Epoch 28, Val Loss: 5.88103
Epoch 29, Val Loss: 5.95054
Epoch 30, Val Loss: 5.79426
Epoch 31, Val Loss: 6.45903
Epoch 32, Val Loss: 5.90471
Epoch 33, Val Loss: 5.78206
Epoch 34, Val Loss: 5.66803
Epoch 35, Val Loss: 5.70416
Epoch 36, Val Loss: 5.62551
Epoch 37, Val Loss: 5.68532
Epoch 38, Val Loss: 5.75486
Epoch 39, Val Loss: 5.57412
Epoch 40, Val Loss: 5.82513
Epoch 41, Val Loss: 5.63871
Epoch 42, Val Loss: 5.49732
Epoch 43, Val Loss: 5.31995
Epoch 44, Val Loss: 5.41393
Epoch 45, Val Loss: 5.42655
Epoch 46, Val Loss: 5.35414
Epoch 47, Val Loss: 5.30120
Epoch 48, Val Loss: 5.17076
Epoch 49, Val Loss: 5.16114
Epoch 50, Val Loss: 5.27233
Epoch 51, Val Loss: 5.16079
Epoch 52, Val Loss: 5.17679
Epoch 53, Val Loss: 5.66442
Epoch 54, Val Loss: 5.06703
Epoch 55, Val Loss: 5.36987
Epoch 56, Val Loss: 4.97764
Epoch 57, Val Loss: 4.97136
Epoch 58, Val Loss: 4.88890
Epoch 59, Val Loss: 4.88216
Epoch 60, Val Loss: 5.16938
Epoch 61, Val Loss: 4.87162
Epoch 62, Val Loss: 5.46153
Epoch 63, Val Loss: 5.42947
Epoch 64, Val Loss: 4.61517
Epoch 65, Val Loss: 4.71351
Epoch 66, Val Loss: 4.73821
Epoch 67, Val Loss: 5.16128
Epoch 68, Val Loss: 4.55893
Epoch 69, Val Loss: 4.58949
Epoch 70, Val Loss: 4.66316
Epoch 71, Val Loss: 4.75505
Epoch 72, Val Loss: 4.87129
Epoch 73, Val Loss: 4.54081
Epoch 74, Val Loss: 4.77118
Epoch 75, Val Loss: 4.55324
Epoch 76, Val Loss: 4.53243
Epoch 77, Val Loss: 4.77720
Epoch 78, Val Loss: 4.57221
Epoch 79, Val Loss: 4.49334
Epoch 80, Val Loss: 4.65467
Epoch 81, Val Loss: 4.52428
Epoch 82, Val Loss: 4.66314
Epoch 83, Val Loss: 4.59803
Epoch 84, Val Loss: 4.69908
Epoch 85, Val Loss: 4.36670
Epoch 86, Val Loss: 4.44243
Epoch 87, Val Loss: 4.78596
Epoch 88, Val Loss: 5.02023
Epoch 89, Val Loss: 4.54607
Epoch 90, Val Loss: 4.55274
Epoch 91, Val Loss: 4.32061
Epoch 92, Val Loss: 4.86384
Epoch 93, Val Loss: 4.56764
Epoch 94, Val Loss: 4.63092
Epoch 95, Val Loss: 5.11446
Epoch 96, Val Loss: 4.43985
Epoch 97, Val Loss: 4.47112
Epoch 98, Val Loss: 4.56310
Epoch 99, Val Loss: 4.53551
Saved Losses
{'MSE - mean': 4.447975020890333, 'MSE - std': 0.0, 'R2 - mean': 0.5943593757302961, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.15718
Epoch 1, Val Loss: 11.36458
Epoch 2, Val Loss: 5.77135
Epoch 3, Val Loss: 6.05899
Epoch 4, Val Loss: 5.36918
Epoch 5, Val Loss: 5.19063
Epoch 6, Val Loss: 5.31136
Epoch 7, Val Loss: 4.94745
Epoch 8, Val Loss: 5.15973
Epoch 9, Val Loss: 5.10261
Epoch 10, Val Loss: 4.91783
Epoch 11, Val Loss: 4.89017
Epoch 12, Val Loss: 4.99672
Epoch 13, Val Loss: 5.09898
Epoch 14, Val Loss: 4.83299
Epoch 15, Val Loss: 4.74482
Epoch 16, Val Loss: 4.91416
Epoch 17, Val Loss: 4.65658
Epoch 18, Val Loss: 4.71398
Epoch 19, Val Loss: 5.01823
Epoch 20, Val Loss: 4.85497
Epoch 21, Val Loss: 5.24186
Epoch 22, Val Loss: 4.75301
Epoch 23, Val Loss: 4.62877
Epoch 24, Val Loss: 4.92364
Epoch 25, Val Loss: 4.69092
Epoch 26, Val Loss: 4.64572
Epoch 27, Val Loss: 4.56078
Epoch 28, Val Loss: 4.69571
Epoch 29, Val Loss: 4.90313
Epoch 30, Val Loss: 4.46351
Epoch 31, Val Loss: 4.50462
Epoch 32, Val Loss: 4.72423
Epoch 33, Val Loss: 4.46339
Epoch 34, Val Loss: 4.38996
Epoch 35, Val Loss: 4.61548
Epoch 36, Val Loss: 4.41875
Epoch 37, Val Loss: 4.46141
Epoch 38, Val Loss: 4.35271
Epoch 39, Val Loss: 4.31346
Epoch 40, Val Loss: 4.31273
Epoch 41, Val Loss: 4.32480
Epoch 42, Val Loss: 4.50363
Epoch 43, Val Loss: 4.27378
Epoch 44, Val Loss: 4.30514
Epoch 45, Val Loss: 4.33464
Epoch 46, Val Loss: 4.23948
Epoch 47, Val Loss: 4.14884
Epoch 48, Val Loss: 4.16259
Epoch 49, Val Loss: 4.26276
Epoch 50, Val Loss: 4.12604
Epoch 51, Val Loss: 4.06885
Epoch 52, Val Loss: 4.08762
Epoch 53, Val Loss: 4.34287
Epoch 54, Val Loss: 4.61382
Epoch 55, Val Loss: 4.61147
Epoch 56, Val Loss: 4.18259
Epoch 57, Val Loss: 4.14161
Epoch 58, Val Loss: 4.06297
Epoch 59, Val Loss: 4.42262
Epoch 60, Val Loss: 4.68887
Epoch 61, Val Loss: 4.15412
Epoch 62, Val Loss: 4.28289
Epoch 63, Val Loss: 4.09487
Epoch 64, Val Loss: 4.05713
Epoch 65, Val Loss: 4.02178
Epoch 66, Val Loss: 4.13482
Epoch 67, Val Loss: 4.07290
Epoch 68, Val Loss: 3.98868
Epoch 69, Val Loss: 4.10355
Epoch 70, Val Loss: 3.98769
Epoch 71, Val Loss: 4.11799
Epoch 72, Val Loss: 3.97168
Epoch 73, Val Loss: 4.17408
Epoch 74, Val Loss: 4.20590
Epoch 75, Val Loss: 3.94373
Epoch 76, Val Loss: 4.10028
Epoch 77, Val Loss: 3.97516
Epoch 78, Val Loss: 3.90323
Epoch 79, Val Loss: 3.99408
Epoch 80, Val Loss: 4.13851
Epoch 81, Val Loss: 4.06902
Epoch 82, Val Loss: 3.92456
Epoch 83, Val Loss: 4.09062
Epoch 84, Val Loss: 4.03996
Epoch 85, Val Loss: 3.89812
Epoch 86, Val Loss: 3.93071
Epoch 87, Val Loss: 3.90706
Epoch 88, Val Loss: 3.98435
Epoch 89, Val Loss: 3.94526
Epoch 90, Val Loss: 4.05285
Epoch 91, Val Loss: 3.95241
Epoch 92, Val Loss: 3.96894
Epoch 93, Val Loss: 3.85765
Epoch 94, Val Loss: 4.02380
Epoch 95, Val Loss: 3.96997
Epoch 96, Val Loss: 4.02533
Epoch 97, Val Loss: 4.18527
Epoch 98, Val Loss: 4.03256
Epoch 99, Val Loss: 4.03418
Saved Losses
{'MSE - mean': 4.234890955714581, 'MSE - std': 0.21308406517575174, 'R2 - mean': 0.5828242904951633, 'R2 - std': 0.011535085235132803} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.94960
Epoch 1, Val Loss: 14.41737
Epoch 2, Val Loss: 6.73425
Epoch 3, Val Loss: 6.59297
Epoch 4, Val Loss: 6.62347
Epoch 5, Val Loss: 6.42871
Epoch 6, Val Loss: 6.31867
Epoch 7, Val Loss: 6.18161
Epoch 8, Val Loss: 6.10556
Epoch 9, Val Loss: 6.23240
Epoch 10, Val Loss: 5.91751
Epoch 11, Val Loss: 5.84620
Epoch 12, Val Loss: 5.81880
Epoch 13, Val Loss: 5.91060
Epoch 14, Val Loss: 5.76219
Epoch 15, Val Loss: 5.79510
Epoch 16, Val Loss: 5.79490
Epoch 17, Val Loss: 5.96358
Epoch 18, Val Loss: 5.80597
Epoch 19, Val Loss: 5.90182
Epoch 20, Val Loss: 6.65522
Epoch 21, Val Loss: 5.63081
Epoch 22, Val Loss: 5.57867
Epoch 23, Val Loss: 5.77555
Epoch 24, Val Loss: 5.68857
Epoch 25, Val Loss: 5.69954
Epoch 26, Val Loss: 5.58203
Epoch 27, Val Loss: 5.65023
Epoch 28, Val Loss: 5.44384
Epoch 29, Val Loss: 5.44404
Epoch 30, Val Loss: 5.46354
Epoch 31, Val Loss: 5.41803
Epoch 32, Val Loss: 6.01209
Epoch 33, Val Loss: 5.46953
Epoch 34, Val Loss: 5.39892
Epoch 35, Val Loss: 5.34568
Epoch 36, Val Loss: 5.47637
Epoch 37, Val Loss: 5.40136
Epoch 38, Val Loss: 5.31466
Epoch 39, Val Loss: 5.32053
Epoch 40, Val Loss: 5.44438
Epoch 41, Val Loss: 5.24575
Epoch 42, Val Loss: 5.32631
Epoch 43, Val Loss: 5.31090
Epoch 44, Val Loss: 5.29879
Epoch 45, Val Loss: 5.31700
Epoch 46, Val Loss: 5.23227
Epoch 47, Val Loss: 5.23833
Epoch 48, Val Loss: 5.15356
Epoch 49, Val Loss: 5.38755
Epoch 50, Val Loss: 5.30702
Epoch 51, Val Loss: 5.12678
Epoch 52, Val Loss: 5.04951
Epoch 53, Val Loss: 4.97090
Epoch 54, Val Loss: 4.97565
Epoch 55, Val Loss: 5.05483
Epoch 56, Val Loss: 5.03459
Epoch 57, Val Loss: 5.33653
Epoch 58, Val Loss: 5.06118
Epoch 59, Val Loss: 5.10173
Epoch 60, Val Loss: 4.99552
Epoch 61, Val Loss: 5.02836
Epoch 62, Val Loss: 5.00154
Epoch 63, Val Loss: 5.18301
Epoch 64, Val Loss: 4.97097
Epoch 65, Val Loss: 5.05471
Epoch 66, Val Loss: 5.00562
Epoch 67, Val Loss: 4.98225
Epoch 68, Val Loss: 5.07483
Epoch 69, Val Loss: 4.99744
Epoch 70, Val Loss: 4.86804
Epoch 71, Val Loss: 4.88316
Epoch 72, Val Loss: 4.88050
Epoch 73, Val Loss: 4.90257
Epoch 74, Val Loss: 5.29982
Epoch 75, Val Loss: 5.13184
Epoch 76, Val Loss: 5.03511
Epoch 77, Val Loss: 4.88092
Epoch 78, Val Loss: 4.93083
Epoch 79, Val Loss: 5.02790
Epoch 80, Val Loss: 4.95561
Epoch 81, Val Loss: 5.40312
Epoch 82, Val Loss: 5.06394
Epoch 83, Val Loss: 5.28141
Epoch 84, Val Loss: 4.90433
Epoch 85, Val Loss: 5.00958
Epoch 86, Val Loss: 4.85463
Epoch 87, Val Loss: 5.08042
Epoch 88, Val Loss: 4.86086
Epoch 89, Val Loss: 5.05906
Epoch 90, Val Loss: 4.85240
Epoch 91, Val Loss: 4.84973
Epoch 92, Val Loss: 5.10385
Epoch 93, Val Loss: 5.16070
Epoch 94, Val Loss: 4.95936
Epoch 95, Val Loss: 4.92513
Epoch 96, Val Loss: 5.03064
Epoch 97, Val Loss: 5.04171
Epoch 98, Val Loss: 5.59664
Epoch 99, Val Loss: 5.33425
Saved Losses
{'MSE - mean': 4.466833593136571, 'MSE - std': 0.37130129723683175, 'R2 - mean': 0.5601574288150095, 'R2 - std': 0.03341075721643601} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.25479
Epoch 1, Val Loss: 9.76922
Epoch 2, Val Loss: 6.28626
Epoch 3, Val Loss: 5.88121
Epoch 4, Val Loss: 5.48590
Epoch 5, Val Loss: 5.55184
Epoch 6, Val Loss: 5.29028
Epoch 7, Val Loss: 5.37365
Epoch 8, Val Loss: 5.41085
Epoch 9, Val Loss: 5.25151
Epoch 10, Val Loss: 5.07716
Epoch 11, Val Loss: 5.41329
Epoch 12, Val Loss: 5.08885
Epoch 13, Val Loss: 5.01830
Epoch 14, Val Loss: 5.13448
Epoch 15, Val Loss: 5.01027
Epoch 16, Val Loss: 4.86307
Epoch 17, Val Loss: 4.80809
Epoch 18, Val Loss: 4.73897
Epoch 19, Val Loss: 4.87058
Epoch 20, Val Loss: 4.84749
Epoch 21, Val Loss: 4.74425
Epoch 22, Val Loss: 4.73270
Epoch 23, Val Loss: 4.67175
Epoch 24, Val Loss: 5.64024
Epoch 25, Val Loss: 4.66912
Epoch 26, Val Loss: 4.58064
Epoch 27, Val Loss: 4.60694
Epoch 28, Val Loss: 4.55730
Epoch 29, Val Loss: 4.60374
Epoch 30, Val Loss: 4.48582
Epoch 31, Val Loss: 4.40342
Epoch 32, Val Loss: 4.53327
Epoch 33, Val Loss: 4.57861
Epoch 34, Val Loss: 4.51248
Epoch 35, Val Loss: 4.54789
Epoch 36, Val Loss: 4.33353
Epoch 37, Val Loss: 4.36256
Epoch 38, Val Loss: 4.56342
Epoch 39, Val Loss: 4.32443
Epoch 40, Val Loss: 4.29899
Epoch 41, Val Loss: 4.43497
Epoch 42, Val Loss: 4.30876
Epoch 43, Val Loss: 4.18713
Epoch 44, Val Loss: 4.23272
Epoch 45, Val Loss: 4.18484
Epoch 46, Val Loss: 4.37019
Epoch 47, Val Loss: 4.19689
Epoch 48, Val Loss: 4.16645
Epoch 49, Val Loss: 4.14995
Epoch 50, Val Loss: 4.18306
Epoch 51, Val Loss: 4.32870
Epoch 52, Val Loss: 4.12025
Epoch 53, Val Loss: 4.75667
Epoch 54, Val Loss: 4.15690
Epoch 55, Val Loss: 4.22042
Epoch 56, Val Loss: 4.28734
Epoch 57, Val Loss: 4.14226
Epoch 58, Val Loss: 4.08415
Epoch 59, Val Loss: 4.22712
Epoch 60, Val Loss: 4.14609
Epoch 61, Val Loss: 4.24702
Epoch 62, Val Loss: 4.25224
Epoch 63, Val Loss: 4.16565
Epoch 64, Val Loss: 4.22140
Epoch 65, Val Loss: 4.07291
Epoch 66, Val Loss: 4.05715
Epoch 67, Val Loss: 4.07535
Epoch 68, Val Loss: 4.08987
Epoch 69, Val Loss: 4.25482
Epoch 70, Val Loss: 4.48472
Epoch 71, Val Loss: 4.07431
Epoch 72, Val Loss: 4.57820
Epoch 73, Val Loss: 4.10240
Epoch 74, Val Loss: 4.17921
Epoch 75, Val Loss: 4.43244
Epoch 76, Val Loss: 4.10373
Epoch 77, Val Loss: 4.03423
Epoch 78, Val Loss: 4.24383
Epoch 79, Val Loss: 4.40252
Epoch 80, Val Loss: 4.57514
Epoch 81, Val Loss: 4.19810
Epoch 82, Val Loss: 4.13942
Epoch 83, Val Loss: 4.12542
Epoch 84, Val Loss: 4.12511
Epoch 85, Val Loss: 4.06356
Epoch 86, Val Loss: 4.73075
Epoch 87, Val Loss: 4.17734
Epoch 88, Val Loss: 4.21735
Epoch 89, Val Loss: 4.12688
Epoch 90, Val Loss: 4.13506
Epoch 91, Val Loss: 4.05953
Epoch 92, Val Loss: 4.42724
Epoch 93, Val Loss: 4.06791
Epoch 94, Val Loss: 4.25685
Epoch 95, Val Loss: 4.16500
Epoch 96, Val Loss: 4.60528
Epoch 97, Val Loss: 4.13381
Epoch 98, Val Loss: 4.30020
Early stopping applies.
Saved Losses
{'MSE - mean': 4.435485788490472, 'MSE - std': 0.3261081792376659, 'R2 - mean': 0.5540707651386755, 'R2 - std': 0.030795315349223744} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.14772
Epoch 1, Val Loss: 13.55712
Epoch 2, Val Loss: 9.16979
Epoch 3, Val Loss: 8.22811
Epoch 4, Val Loss: 7.96589
Epoch 5, Val Loss: 7.74023
Epoch 6, Val Loss: 7.53939
Epoch 7, Val Loss: 7.78242
Epoch 8, Val Loss: 7.75249
Epoch 9, Val Loss: 7.49125
Epoch 10, Val Loss: 7.48980
Epoch 11, Val Loss: 7.29867
Epoch 12, Val Loss: 7.22611
Epoch 13, Val Loss: 7.47995
Epoch 14, Val Loss: 7.17742
Epoch 15, Val Loss: 7.20487
Epoch 16, Val Loss: 7.10462
Epoch 17, Val Loss: 7.20673
Epoch 18, Val Loss: 7.11333
Epoch 19, Val Loss: 7.01614
Epoch 20, Val Loss: 6.80680
Epoch 21, Val Loss: 6.86152
Epoch 22, Val Loss: 6.87562
Epoch 23, Val Loss: 6.90956
Epoch 24, Val Loss: 6.87176
Epoch 25, Val Loss: 6.82842
Epoch 26, Val Loss: 6.73411
Epoch 27, Val Loss: 6.83219
Epoch 28, Val Loss: 6.79725
Epoch 29, Val Loss: 6.76031
Epoch 30, Val Loss: 6.72489
Epoch 31, Val Loss: 6.76161
Epoch 32, Val Loss: 6.59040
Epoch 33, Val Loss: 6.94174
Epoch 34, Val Loss: 6.83927
Epoch 35, Val Loss: 6.55332
Epoch 36, Val Loss: 6.60264
Epoch 37, Val Loss: 6.64283
Epoch 38, Val Loss: 6.64699
Epoch 39, Val Loss: 6.51206
Epoch 40, Val Loss: 6.51690
Epoch 41, Val Loss: 6.46216
Epoch 42, Val Loss: 6.65250
Epoch 43, Val Loss: 6.60688
Epoch 44, Val Loss: 6.61395
Epoch 45, Val Loss: 6.43754
Epoch 46, Val Loss: 6.80236
Epoch 47, Val Loss: 6.90306
Epoch 48, Val Loss: 7.05552
Epoch 49, Val Loss: 6.34230
Epoch 50, Val Loss: 6.38886
Epoch 51, Val Loss: 7.62252
Epoch 52, Val Loss: 6.37393
Epoch 53, Val Loss: 6.50806
Epoch 54, Val Loss: 6.45601
Epoch 55, Val Loss: 6.39735
Epoch 56, Val Loss: 6.28308
Epoch 57, Val Loss: 6.43812
Epoch 58, Val Loss: 6.69443
Epoch 59, Val Loss: 6.53688
Epoch 60, Val Loss: 6.18410
Epoch 61, Val Loss: 6.22244
Epoch 62, Val Loss: 6.20915
Epoch 63, Val Loss: 6.29155
Epoch 64, Val Loss: 6.26819
Epoch 65, Val Loss: 6.20744
Epoch 66, Val Loss: 6.10249
Epoch 67, Val Loss: 6.31503
Epoch 68, Val Loss: 6.38284
Epoch 69, Val Loss: 6.10974
Epoch 70, Val Loss: 6.19037
Epoch 71, Val Loss: 6.16160
Epoch 72, Val Loss: 6.20928
Epoch 73, Val Loss: 6.18612
Epoch 74, Val Loss: 6.32689
Epoch 75, Val Loss: 6.17830
Epoch 76, Val Loss: 5.95387
Epoch 77, Val Loss: 5.97297
Epoch 78, Val Loss: 6.19514
Epoch 79, Val Loss: 6.37257
Epoch 80, Val Loss: 6.08234
Epoch 81, Val Loss: 6.27927
Epoch 82, Val Loss: 6.09473
Epoch 83, Val Loss: 6.28927
Epoch 84, Val Loss: 6.48837
Epoch 85, Val Loss: 6.01427
Epoch 86, Val Loss: 6.01582
Epoch 87, Val Loss: 6.10816
Epoch 88, Val Loss: 5.99899
Epoch 89, Val Loss: 5.97637
Epoch 90, Val Loss: 5.89966
Epoch 91, Val Loss: 5.85905
Epoch 92, Val Loss: 6.25460
Epoch 93, Val Loss: 6.25240
Epoch 94, Val Loss: 5.95501
Epoch 95, Val Loss: 5.91024
Epoch 96, Val Loss: 6.34039
Epoch 97, Val Loss: 6.13958
Epoch 98, Val Loss: 6.04154
Epoch 99, Val Loss: 5.93589
Saved Losses
{'MSE - mean': 4.7217326297072315, 'MSE - std': 0.64251556563157, 'R2 - mean': 0.546221433073087, 'R2 - std': 0.031703772858604935} 
 

Results After CV: {'MSE - mean': 4.7217326297072315, 'MSE - std': 0.64251556563157, 'R2 - mean': 0.546221433073087, 'R2 - std': 0.031703772858604935}
Train time: 81.9327850314
Inference time: 0.05099212640002406
Finished cross validation
Trial 4 finished with value: 4.7217326297072315 and parameters: {'p_m': 0.8074135374012863, 'alpha': 0.3500295554909527, 'K': 10, 'beta': 7.054364852950336}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.02003
Epoch 1, Val Loss: 12.85184
Epoch 2, Val Loss: 7.63710
Epoch 3, Val Loss: 7.30627
Epoch 4, Val Loss: 7.64129
Epoch 5, Val Loss: 7.32753
Epoch 6, Val Loss: 7.09440
Epoch 7, Val Loss: 7.25591
Epoch 8, Val Loss: 6.89227
Epoch 9, Val Loss: 7.01100
Epoch 10, Val Loss: 6.66819
Epoch 11, Val Loss: 6.68936
Epoch 12, Val Loss: 6.99068
Epoch 13, Val Loss: 6.58221
Epoch 14, Val Loss: 6.46913
Epoch 15, Val Loss: 6.99416
Epoch 16, Val Loss: 6.37282
Epoch 17, Val Loss: 6.62340
Epoch 18, Val Loss: 6.60637
Epoch 19, Val Loss: 6.44568
Epoch 20, Val Loss: 7.03499
Epoch 21, Val Loss: 6.55242
Epoch 22, Val Loss: 6.39978
Epoch 23, Val Loss: 6.58506
Epoch 24, Val Loss: 6.49273
Epoch 25, Val Loss: 6.62341
Epoch 26, Val Loss: 6.23871
Epoch 27, Val Loss: 6.37112
Epoch 28, Val Loss: 6.42328
Epoch 29, Val Loss: 6.23350
Epoch 30, Val Loss: 6.34343
Epoch 31, Val Loss: 6.53336
Epoch 32, Val Loss: 6.08017
Epoch 33, Val Loss: 6.76614
Epoch 34, Val Loss: 6.58927
Epoch 35, Val Loss: 5.98466
Epoch 36, Val Loss: 6.17450
Epoch 37, Val Loss: 6.04406
Epoch 38, Val Loss: 6.05328
Epoch 39, Val Loss: 6.18509
Epoch 40, Val Loss: 6.12549
Epoch 41, Val Loss: 6.23729
Epoch 42, Val Loss: 6.63064
Epoch 43, Val Loss: 5.77605
Epoch 44, Val Loss: 5.93591
Epoch 45, Val Loss: 5.97612
Epoch 46, Val Loss: 6.32117
Epoch 47, Val Loss: 5.77209
Epoch 48, Val Loss: 5.96342
Epoch 49, Val Loss: 5.94680
Epoch 50, Val Loss: 5.76428
Epoch 51, Val Loss: 5.83777
Epoch 52, Val Loss: 5.79995
Epoch 53, Val Loss: 5.76110
Epoch 54, Val Loss: 5.82879
Epoch 55, Val Loss: 6.03006
Epoch 56, Val Loss: 5.72011
Epoch 57, Val Loss: 5.68352
Epoch 58, Val Loss: 5.69131
Epoch 59, Val Loss: 5.80644
Epoch 60, Val Loss: 5.71405
Epoch 61, Val Loss: 5.92937
Epoch 62, Val Loss: 5.89128
Epoch 63, Val Loss: 5.66904
Epoch 64, Val Loss: 5.70398
Epoch 65, Val Loss: 5.87071
Epoch 66, Val Loss: 6.09448
Epoch 67, Val Loss: 5.54239
Epoch 68, Val Loss: 5.48129
Epoch 69, Val Loss: 5.67209
Epoch 70, Val Loss: 5.79029
Epoch 71, Val Loss: 5.62747
Epoch 72, Val Loss: 5.86558
Epoch 73, Val Loss: 5.40590
Epoch 74, Val Loss: 5.61636
Epoch 75, Val Loss: 5.45611
Epoch 76, Val Loss: 5.62100
Epoch 77, Val Loss: 5.53257
Epoch 78, Val Loss: 5.32672
Epoch 79, Val Loss: 5.36799
Epoch 80, Val Loss: 5.54328
Epoch 81, Val Loss: 5.16318
Epoch 82, Val Loss: 5.83041
Epoch 83, Val Loss: 5.33733
Epoch 84, Val Loss: 5.45702
Epoch 85, Val Loss: 5.14896
Epoch 86, Val Loss: 5.01363
Epoch 87, Val Loss: 5.21309
Epoch 88, Val Loss: 5.20870
Epoch 89, Val Loss: 5.05366
Epoch 90, Val Loss: 5.18270
Epoch 91, Val Loss: 5.30148
Epoch 92, Val Loss: 5.12019
Epoch 93, Val Loss: 5.20397
Epoch 94, Val Loss: 5.97015
Epoch 95, Val Loss: 5.05623
Epoch 96, Val Loss: 5.05167
Epoch 97, Val Loss: 5.06191
Epoch 98, Val Loss: 5.27609
Epoch 99, Val Loss: 4.99052
Saved Losses
{'MSE - mean': 5.189302782803142, 'MSE - std': 0.0, 'R2 - mean': 0.5267527334451103, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.55800
Epoch 1, Val Loss: 8.32625
Epoch 2, Val Loss: 6.28573
Epoch 3, Val Loss: 6.14165
Epoch 4, Val Loss: 5.83156
Epoch 5, Val Loss: 5.88035
Epoch 6, Val Loss: 5.77401
Epoch 7, Val Loss: 5.58981
Epoch 8, Val Loss: 6.31409
Epoch 9, Val Loss: 5.98791
Epoch 10, Val Loss: 5.80237
Epoch 11, Val Loss: 5.78970
Epoch 12, Val Loss: 5.87697
Epoch 13, Val Loss: 6.26464
Epoch 14, Val Loss: 5.61154
Epoch 15, Val Loss: 5.50800
Epoch 16, Val Loss: 5.86392
Epoch 17, Val Loss: 5.67010
Epoch 18, Val Loss: 5.38590
Epoch 19, Val Loss: 5.69963
Epoch 20, Val Loss: 5.45306
Epoch 21, Val Loss: 5.46763
Epoch 22, Val Loss: 5.45792
Epoch 23, Val Loss: 5.38044
Epoch 24, Val Loss: 5.62551
Epoch 25, Val Loss: 6.34771
Epoch 26, Val Loss: 5.49329
Epoch 27, Val Loss: 5.63355
Epoch 28, Val Loss: 5.31467
Epoch 29, Val Loss: 5.72256
Epoch 30, Val Loss: 5.29549
Epoch 31, Val Loss: 5.64379
Epoch 32, Val Loss: 5.61133
Epoch 33, Val Loss: 5.82422
Epoch 34, Val Loss: 5.46421
Epoch 35, Val Loss: 5.40213
Epoch 36, Val Loss: 5.37946
Epoch 37, Val Loss: 5.49837
Epoch 38, Val Loss: 5.20918
Epoch 39, Val Loss: 5.48574
Epoch 40, Val Loss: 5.46667
Epoch 41, Val Loss: 5.46266
Epoch 42, Val Loss: 5.57272
Epoch 43, Val Loss: 5.07647
Epoch 44, Val Loss: 5.13336
Epoch 45, Val Loss: 5.73246
Epoch 46, Val Loss: 5.83626
Epoch 47, Val Loss: 5.43289
Epoch 48, Val Loss: 5.13187
Epoch 49, Val Loss: 5.11158
Epoch 50, Val Loss: 5.55558
Epoch 51, Val Loss: 5.20304
Epoch 52, Val Loss: 5.33197
Epoch 53, Val Loss: 5.67808
Epoch 54, Val Loss: 5.13966
Epoch 55, Val Loss: 5.50436
Epoch 56, Val Loss: 5.10525
Epoch 57, Val Loss: 5.40186
Epoch 58, Val Loss: 5.65962
Epoch 59, Val Loss: 5.10831
Epoch 60, Val Loss: 5.04915
Epoch 61, Val Loss: 4.95861
Epoch 62, Val Loss: 4.94326
Epoch 63, Val Loss: 5.18647
Epoch 64, Val Loss: 5.11390
Epoch 65, Val Loss: 5.04914
Epoch 66, Val Loss: 4.97437
Epoch 67, Val Loss: 4.97269
Epoch 68, Val Loss: 4.89509
Epoch 69, Val Loss: 4.98182
Epoch 70, Val Loss: 4.99267
Epoch 71, Val Loss: 4.83377
Epoch 72, Val Loss: 4.86975
Epoch 73, Val Loss: 5.05490
Epoch 74, Val Loss: 4.96083
Epoch 75, Val Loss: 5.36518
Epoch 76, Val Loss: 5.04999
Epoch 77, Val Loss: 5.07198
Epoch 78, Val Loss: 4.73801
Epoch 79, Val Loss: 5.16812
Epoch 80, Val Loss: 4.96309
Epoch 81, Val Loss: 5.26525
Epoch 82, Val Loss: 5.22342
Epoch 83, Val Loss: 5.01083
Epoch 84, Val Loss: 4.80456
Epoch 85, Val Loss: 4.85609
Epoch 86, Val Loss: 4.69191
Epoch 87, Val Loss: 4.99808
Epoch 88, Val Loss: 4.72462
Epoch 89, Val Loss: 4.96196
Epoch 90, Val Loss: 4.81258
Epoch 91, Val Loss: 5.12328
Epoch 92, Val Loss: 4.71436
Epoch 93, Val Loss: 4.81263
Epoch 94, Val Loss: 4.87800
Epoch 95, Val Loss: 5.15049
Epoch 96, Val Loss: 4.72858
Epoch 97, Val Loss: 4.78860
Epoch 98, Val Loss: 4.66238
Epoch 99, Val Loss: 4.86097
Saved Losses
{'MSE - mean': 5.045434476336278, 'MSE - std': 0.14386830646686377, 'R2 - mean': 0.5021313112850809, 'R2 - std': 0.024621422160029438} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.78438
Epoch 1, Val Loss: 10.38723
Epoch 2, Val Loss: 7.12980
Epoch 3, Val Loss: 7.14079
Epoch 4, Val Loss: 7.56920
Epoch 5, Val Loss: 6.53178
Epoch 6, Val Loss: 6.55974
Epoch 7, Val Loss: 6.92930
Epoch 8, Val Loss: 6.64217
Epoch 9, Val Loss: 6.37416
Epoch 10, Val Loss: 6.74440
Epoch 11, Val Loss: 6.85404
Epoch 12, Val Loss: 7.05962
Epoch 13, Val Loss: 6.74339
Epoch 14, Val Loss: 6.62283
Epoch 15, Val Loss: 6.73743
Epoch 16, Val Loss: 6.64169
Epoch 17, Val Loss: 6.54211
Epoch 18, Val Loss: 6.50389
Epoch 19, Val Loss: 6.88293
Epoch 20, Val Loss: 6.54482
Epoch 21, Val Loss: 6.67697
Epoch 22, Val Loss: 6.53526
Epoch 23, Val Loss: 6.64927
Epoch 24, Val Loss: 6.50677
Epoch 25, Val Loss: 6.49955
Epoch 26, Val Loss: 6.60984
Epoch 27, Val Loss: 6.37142
Epoch 28, Val Loss: 6.55321
Epoch 29, Val Loss: 6.31054
Epoch 30, Val Loss: 6.48076
Epoch 31, Val Loss: 6.30992
Epoch 32, Val Loss: 6.34598
Epoch 33, Val Loss: 6.30590
Epoch 34, Val Loss: 6.09485
Epoch 35, Val Loss: 6.26819
Epoch 36, Val Loss: 6.35065
Epoch 37, Val Loss: 6.42536
Epoch 38, Val Loss: 6.54431
Epoch 39, Val Loss: 6.29230
Epoch 40, Val Loss: 6.09065
Epoch 41, Val Loss: 6.17210
Epoch 42, Val Loss: 6.64965
Epoch 43, Val Loss: 6.13633
Epoch 44, Val Loss: 6.32411
Epoch 45, Val Loss: 6.37548
Epoch 46, Val Loss: 6.20180
Epoch 47, Val Loss: 6.37182
Epoch 48, Val Loss: 6.68482
Epoch 49, Val Loss: 6.33362
Epoch 50, Val Loss: 6.09329
Epoch 51, Val Loss: 6.95993
Epoch 52, Val Loss: 6.39778
Epoch 53, Val Loss: 6.06735
Epoch 54, Val Loss: 6.21440
Epoch 55, Val Loss: 6.18859
Epoch 56, Val Loss: 5.93515
Epoch 57, Val Loss: 6.03766
Epoch 58, Val Loss: 6.00854
Epoch 59, Val Loss: 6.61400
Epoch 60, Val Loss: 6.02127
Epoch 61, Val Loss: 6.08755
Epoch 62, Val Loss: 6.26459
Epoch 63, Val Loss: 6.06002
Epoch 64, Val Loss: 6.12241
Epoch 65, Val Loss: 7.01464
Epoch 66, Val Loss: 6.04301
Epoch 67, Val Loss: 6.16297
Epoch 68, Val Loss: 6.08273
Epoch 69, Val Loss: 5.84890
Epoch 70, Val Loss: 5.97404
Epoch 71, Val Loss: 5.95052
Epoch 72, Val Loss: 5.81341
Epoch 73, Val Loss: 6.09941
Epoch 74, Val Loss: 5.84061
Epoch 75, Val Loss: 5.73530
Epoch 76, Val Loss: 6.15809
Epoch 77, Val Loss: 5.77546
Epoch 78, Val Loss: 5.89121
Epoch 79, Val Loss: 5.92528
Epoch 80, Val Loss: 6.56795
Epoch 81, Val Loss: 5.83077
Epoch 82, Val Loss: 6.17720
Epoch 83, Val Loss: 5.85368
Epoch 84, Val Loss: 5.95296
Epoch 85, Val Loss: 5.81032
Epoch 86, Val Loss: 6.02014
Epoch 87, Val Loss: 5.66293
Epoch 88, Val Loss: 6.97039
Epoch 89, Val Loss: 5.71878
Epoch 90, Val Loss: 5.71989
Epoch 91, Val Loss: 5.68199
Epoch 92, Val Loss: 5.56547
Epoch 93, Val Loss: 5.91405
Epoch 94, Val Loss: 5.68470
Epoch 95, Val Loss: 5.64661
Epoch 96, Val Loss: 5.91358
Epoch 97, Val Loss: 5.60171
Epoch 98, Val Loss: 5.66849
Epoch 99, Val Loss: 5.58283
Saved Losses
{'MSE - mean': 5.261402943045456, 'MSE - std': 0.327236128245628, 'R2 - mean': 0.48134847238893314, 'R2 - std': 0.03560892778440162} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.33808
Epoch 1, Val Loss: 10.14504
Epoch 2, Val Loss: 6.69027
Epoch 3, Val Loss: 6.46796
Epoch 4, Val Loss: 5.83195
Epoch 5, Val Loss: 6.18017
Epoch 6, Val Loss: 5.74394
Epoch 7, Val Loss: 5.92157
Epoch 8, Val Loss: 5.80630
Epoch 9, Val Loss: 5.83771
Epoch 10, Val Loss: 5.88905
Epoch 11, Val Loss: 5.68456
Epoch 12, Val Loss: 6.08224
Epoch 13, Val Loss: 5.77889
Epoch 14, Val Loss: 6.24465
Epoch 15, Val Loss: 6.06364
Epoch 16, Val Loss: 5.53502
Epoch 17, Val Loss: 5.63432
Epoch 18, Val Loss: 5.82180
Epoch 19, Val Loss: 5.50818
Epoch 20, Val Loss: 5.64396
Epoch 21, Val Loss: 5.94232
Epoch 22, Val Loss: 5.64004
Epoch 23, Val Loss: 5.77190
Epoch 24, Val Loss: 5.77938
Epoch 25, Val Loss: 5.68220
Epoch 26, Val Loss: 5.53282
Epoch 27, Val Loss: 5.61561
Epoch 28, Val Loss: 5.85892
Epoch 29, Val Loss: 5.52562
Epoch 30, Val Loss: 5.59890
Epoch 31, Val Loss: 5.49060
Epoch 32, Val Loss: 5.74615
Epoch 33, Val Loss: 5.38190
Epoch 34, Val Loss: 6.12583
Epoch 35, Val Loss: 5.49476
Epoch 36, Val Loss: 5.52371
Epoch 37, Val Loss: 6.28118
Epoch 38, Val Loss: 5.81618
Epoch 39, Val Loss: 5.46696
Epoch 40, Val Loss: 5.57885
Epoch 41, Val Loss: 5.70247
Epoch 42, Val Loss: 5.45158
Epoch 43, Val Loss: 5.31821
Epoch 44, Val Loss: 5.37445
Epoch 45, Val Loss: 5.66836
Epoch 46, Val Loss: 5.22120
Epoch 47, Val Loss: 5.36869
Epoch 48, Val Loss: 5.39746
Epoch 49, Val Loss: 5.30519
Epoch 50, Val Loss: 5.13398
Epoch 51, Val Loss: 5.51796
Epoch 52, Val Loss: 5.22074
Epoch 53, Val Loss: 5.18134
Epoch 54, Val Loss: 5.44850
Epoch 55, Val Loss: 5.19052
Epoch 56, Val Loss: 5.15580
Epoch 57, Val Loss: 5.24423
Epoch 58, Val Loss: 5.13933
Epoch 59, Val Loss: 5.25184
Epoch 60, Val Loss: 5.47492
Epoch 61, Val Loss: 5.00938
Epoch 62, Val Loss: 5.53457
Epoch 63, Val Loss: 5.22753
Epoch 64, Val Loss: 5.79867
Epoch 65, Val Loss: 5.02759
Epoch 66, Val Loss: 4.90667
Epoch 67, Val Loss: 5.07285
Epoch 68, Val Loss: 5.27940
Epoch 69, Val Loss: 4.88176
Epoch 70, Val Loss: 4.88506
Epoch 71, Val Loss: 5.30913
Epoch 72, Val Loss: 5.17411
Epoch 73, Val Loss: 5.16414
Epoch 74, Val Loss: 4.90670
Epoch 75, Val Loss: 5.06626
Epoch 76, Val Loss: 4.86377
Epoch 77, Val Loss: 5.01271
Epoch 78, Val Loss: 4.90246
Epoch 79, Val Loss: 4.66289
Epoch 80, Val Loss: 4.85112
Epoch 81, Val Loss: 5.11462
Epoch 82, Val Loss: 4.61767
Epoch 83, Val Loss: 4.72383
Epoch 84, Val Loss: 4.88097
Epoch 85, Val Loss: 4.72641
Epoch 86, Val Loss: 4.75224
Epoch 87, Val Loss: 5.05558
Epoch 88, Val Loss: 4.84305
Epoch 89, Val Loss: 5.06126
Epoch 90, Val Loss: 4.40322
Epoch 91, Val Loss: 4.88069
Epoch 92, Val Loss: 4.58660
Epoch 93, Val Loss: 4.70136
Epoch 94, Val Loss: 4.46268
Epoch 95, Val Loss: 4.48856
Epoch 96, Val Loss: 4.50006
Epoch 97, Val Loss: 4.41965
Epoch 98, Val Loss: 4.82483
Epoch 99, Val Loss: 4.41948
Saved Losses
{'MSE - mean': 5.128790135756894, 'MSE - std': 0.36478909343996463, 'R2 - mean': 0.4845524136716368, 'R2 - std': 0.031333568623683555} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 43.01440
Epoch 1, Val Loss: 14.91911
Epoch 2, Val Loss: 10.00679
Epoch 3, Val Loss: 8.36427
Epoch 4, Val Loss: 8.16652
Epoch 5, Val Loss: 8.53578
Epoch 6, Val Loss: 8.52694
Epoch 7, Val Loss: 8.34479
Epoch 8, Val Loss: 8.11382
Epoch 9, Val Loss: 8.26567
Epoch 10, Val Loss: 8.27906
Epoch 11, Val Loss: 8.06453
Epoch 12, Val Loss: 8.06650
Epoch 13, Val Loss: 8.09585
Epoch 14, Val Loss: 7.90218
Epoch 15, Val Loss: 7.91873
Epoch 16, Val Loss: 8.25018
Epoch 17, Val Loss: 8.44387
Epoch 18, Val Loss: 8.24645
Epoch 19, Val Loss: 8.43363
Epoch 20, Val Loss: 8.34527
Epoch 21, Val Loss: 7.93624
Epoch 22, Val Loss: 7.90331
Epoch 23, Val Loss: 8.02030
Epoch 24, Val Loss: 8.61078
Epoch 25, Val Loss: 8.23120
Epoch 26, Val Loss: 8.27385
Epoch 27, Val Loss: 7.95817
Epoch 28, Val Loss: 7.79658
Epoch 29, Val Loss: 8.03204
Epoch 30, Val Loss: 8.12547
Epoch 31, Val Loss: 7.76097
Epoch 32, Val Loss: 9.40054
Epoch 33, Val Loss: 8.14181
Epoch 34, Val Loss: 8.37951
Epoch 35, Val Loss: 8.18076
Epoch 36, Val Loss: 7.92067
Epoch 37, Val Loss: 7.73604
Epoch 38, Val Loss: 7.87876
Epoch 39, Val Loss: 7.98672
Epoch 40, Val Loss: 8.17111
Epoch 41, Val Loss: 7.94255
Epoch 42, Val Loss: 8.54263
Epoch 43, Val Loss: 8.00026
Epoch 44, Val Loss: 8.46219
Epoch 45, Val Loss: 7.80114
Epoch 46, Val Loss: 7.80219
Epoch 47, Val Loss: 8.37035
Epoch 48, Val Loss: 7.78123
Epoch 49, Val Loss: 8.08159
Epoch 50, Val Loss: 7.87695
Epoch 51, Val Loss: 7.66057
Epoch 52, Val Loss: 8.32792
Epoch 53, Val Loss: 8.01688
Epoch 54, Val Loss: 8.26762
Epoch 55, Val Loss: 7.68204
Epoch 56, Val Loss: 7.80205
Epoch 57, Val Loss: 7.71560
Epoch 58, Val Loss: 7.60064
Epoch 59, Val Loss: 7.47947
Epoch 60, Val Loss: 7.47856
Epoch 61, Val Loss: 7.77621
Epoch 62, Val Loss: 7.74159
Epoch 63, Val Loss: 7.96971
Epoch 64, Val Loss: 7.47043
Epoch 65, Val Loss: 8.23693
Epoch 66, Val Loss: 7.88161
Epoch 67, Val Loss: 7.83205
Epoch 68, Val Loss: 7.84672
Epoch 69, Val Loss: 7.75136
Epoch 70, Val Loss: 7.59806
Epoch 71, Val Loss: 7.81430
Epoch 72, Val Loss: 7.93642
Epoch 73, Val Loss: 7.58316
Epoch 74, Val Loss: 8.01905
Epoch 75, Val Loss: 7.62830
Epoch 76, Val Loss: 7.87079
Epoch 77, Val Loss: 7.51516
Epoch 78, Val Loss: 7.76116
Epoch 79, Val Loss: 8.22193
Epoch 80, Val Loss: 7.98090
Epoch 81, Val Loss: 7.54381
Epoch 82, Val Loss: 7.47649
Epoch 83, Val Loss: 7.86329
Epoch 84, Val Loss: 7.65762
Epoch 85, Val Loss: 7.74312
Early stopping applies.
Saved Losses
{'MSE - mean': 5.619606609185091, 'MSE - std': 1.0344370974149018, 'R2 - mean': 0.4622216975495889, 'R2 - std': 0.0527264406939253} 
 

Results After CV: {'MSE - mean': 5.619606609185091, 'MSE - std': 1.0344370974149018, 'R2 - mean': 0.4622216975495889, 'R2 - std': 0.0527264406939253}
Train time: 32.8215429937999
Inference time: 0.04980789619994539
Finished cross validation
Trial 5 finished with value: 5.619606609185091 and parameters: {'p_m': 0.644719770626321, 'alpha': 8.844225307513618, 'K': 3, 'beta': 7.998460278958792}. Best is trial 0 with value: 4.658108446368637.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 41.41600
Epoch 1, Val Loss: 17.01963
Epoch 2, Val Loss: 9.03304
Epoch 3, Val Loss: 7.17850
Epoch 4, Val Loss: 6.91057
Epoch 5, Val Loss: 6.75612
Epoch 6, Val Loss: 6.52562
Epoch 7, Val Loss: 6.29035
Epoch 8, Val Loss: 6.71558
Epoch 9, Val Loss: 6.16879
Epoch 10, Val Loss: 6.09681
Epoch 11, Val Loss: 6.23685
Epoch 12, Val Loss: 6.46343
Epoch 13, Val Loss: 6.00429
Epoch 14, Val Loss: 6.33982
Epoch 15, Val Loss: 6.16045
Epoch 16, Val Loss: 5.85262
Epoch 17, Val Loss: 5.94557
Epoch 18, Val Loss: 5.76237
Epoch 19, Val Loss: 6.12521
Epoch 20, Val Loss: 5.95006
Epoch 21, Val Loss: 5.61268
Epoch 22, Val Loss: 5.77640
Epoch 23, Val Loss: 5.78070
Epoch 24, Val Loss: 5.70864
Epoch 25, Val Loss: 5.56323
Epoch 26, Val Loss: 5.86625
Epoch 27, Val Loss: 5.94982
Epoch 28, Val Loss: 5.33607
Epoch 29, Val Loss: 5.26701
Epoch 30, Val Loss: 5.60726
Epoch 31, Val Loss: 5.77791
Epoch 32, Val Loss: 5.30133
Epoch 33, Val Loss: 5.16943
Epoch 34, Val Loss: 5.12398
Epoch 35, Val Loss: 5.62183
Epoch 36, Val Loss: 5.30871
Epoch 37, Val Loss: 5.10896
Epoch 38, Val Loss: 5.17996
Epoch 39, Val Loss: 5.35515
Epoch 40, Val Loss: 5.11033
Epoch 41, Val Loss: 5.04563
Epoch 42, Val Loss: 5.04808
Epoch 43, Val Loss: 4.99532
Epoch 44, Val Loss: 4.96382
Epoch 45, Val Loss: 5.12675
Epoch 46, Val Loss: 5.98444
Epoch 47, Val Loss: 4.86101
Epoch 48, Val Loss: 4.93107
Epoch 49, Val Loss: 4.88515
Epoch 50, Val Loss: 4.91971
Epoch 51, Val Loss: 5.01576
Epoch 52, Val Loss: 5.08878
Epoch 53, Val Loss: 4.99163
Epoch 54, Val Loss: 4.85484
Epoch 55, Val Loss: 5.12431
Epoch 56, Val Loss: 4.91378
Epoch 57, Val Loss: 5.51740
Epoch 58, Val Loss: 4.79644
Epoch 59, Val Loss: 4.81939
Epoch 60, Val Loss: 5.33887
Epoch 61, Val Loss: 5.01112
Epoch 62, Val Loss: 4.67330
Epoch 63, Val Loss: 4.87120
Epoch 64, Val Loss: 5.59757
Epoch 65, Val Loss: 5.08556
Epoch 66, Val Loss: 4.78992
Epoch 67, Val Loss: 4.76195
Epoch 68, Val Loss: 4.72413
Epoch 69, Val Loss: 4.66121
Epoch 70, Val Loss: 4.89130
Epoch 71, Val Loss: 4.83525
Epoch 72, Val Loss: 5.02801
Epoch 73, Val Loss: 5.18229
Epoch 74, Val Loss: 4.87487
Epoch 75, Val Loss: 4.66656
Epoch 76, Val Loss: 4.63559
Epoch 77, Val Loss: 5.00149
Epoch 78, Val Loss: 5.68431
Epoch 79, Val Loss: 4.89851
Epoch 80, Val Loss: 4.70126
Epoch 81, Val Loss: 4.65127
Epoch 82, Val Loss: 4.77502
Epoch 83, Val Loss: 4.63560
Epoch 84, Val Loss: 4.63998
Epoch 85, Val Loss: 5.21225
Epoch 86, Val Loss: 4.72120
Epoch 87, Val Loss: 5.04071
Epoch 88, Val Loss: 4.66841
Epoch 89, Val Loss: 5.12285
Epoch 90, Val Loss: 4.77624
Epoch 91, Val Loss: 4.79522
Epoch 92, Val Loss: 4.60133
Epoch 93, Val Loss: 4.87265
Epoch 94, Val Loss: 4.77438
Epoch 95, Val Loss: 4.68129
Epoch 96, Val Loss: 4.69688
Epoch 97, Val Loss: 4.64393
Epoch 98, Val Loss: 4.63444
Epoch 99, Val Loss: 4.82471
Saved Losses
{'MSE - mean': 4.674128870207653, 'MSE - std': 0.0, 'R2 - mean': 0.5737348919624643, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.20972
Epoch 1, Val Loss: 15.73791
Epoch 2, Val Loss: 6.34222
Epoch 3, Val Loss: 5.47616
Epoch 4, Val Loss: 5.36182
Epoch 5, Val Loss: 5.39134
Epoch 6, Val Loss: 5.06800
Epoch 7, Val Loss: 5.07829
Epoch 8, Val Loss: 4.96785
Epoch 9, Val Loss: 5.09808
Epoch 10, Val Loss: 4.83870
Epoch 11, Val Loss: 4.83946
Epoch 12, Val Loss: 4.76502
Epoch 13, Val Loss: 4.92972
Epoch 14, Val Loss: 4.77831
Epoch 15, Val Loss: 4.66993
Epoch 16, Val Loss: 4.57113
Epoch 17, Val Loss: 4.66167
Epoch 18, Val Loss: 4.50366
Epoch 19, Val Loss: 4.62567
Epoch 20, Val Loss: 4.58475
Epoch 21, Val Loss: 4.51687
Epoch 22, Val Loss: 4.83175
Epoch 23, Val Loss: 5.33617
Epoch 24, Val Loss: 4.77179
Epoch 25, Val Loss: 4.35630
Epoch 26, Val Loss: 4.42002
Epoch 27, Val Loss: 4.40452
Epoch 28, Val Loss: 4.33094
Epoch 29, Val Loss: 4.44715
Epoch 30, Val Loss: 4.30453
Epoch 31, Val Loss: 4.39827
Epoch 32, Val Loss: 4.54329
Epoch 33, Val Loss: 4.21572
Epoch 34, Val Loss: 4.32904
Epoch 35, Val Loss: 4.25669
Epoch 36, Val Loss: 4.23074
Epoch 37, Val Loss: 4.46048
Epoch 38, Val Loss: 4.14423
Epoch 39, Val Loss: 4.11654
Epoch 40, Val Loss: 4.48007
Epoch 41, Val Loss: 4.13165
Epoch 42, Val Loss: 4.67278
Epoch 43, Val Loss: 4.90661
Epoch 44, Val Loss: 4.21818
Epoch 45, Val Loss: 4.20702
Epoch 46, Val Loss: 4.53442
Epoch 47, Val Loss: 4.27126
Epoch 48, Val Loss: 4.14470
Epoch 49, Val Loss: 4.14284
Epoch 50, Val Loss: 4.30851
Epoch 51, Val Loss: 4.18686
Epoch 52, Val Loss: 4.07013
Epoch 53, Val Loss: 4.18767
Epoch 54, Val Loss: 4.46909
Epoch 55, Val Loss: 4.20710
Epoch 56, Val Loss: 4.26887
Epoch 57, Val Loss: 4.12339
Epoch 58, Val Loss: 4.15533
Epoch 59, Val Loss: 4.93467
Epoch 60, Val Loss: 4.12121
Epoch 61, Val Loss: 4.03289
Epoch 62, Val Loss: 4.33060
Epoch 63, Val Loss: 4.06402
Epoch 64, Val Loss: 4.48846
Epoch 65, Val Loss: 4.06977
Epoch 66, Val Loss: 4.15270
Epoch 67, Val Loss: 4.13722
Epoch 68, Val Loss: 4.23489
Epoch 69, Val Loss: 4.82425
Epoch 70, Val Loss: 4.01955
Epoch 71, Val Loss: 3.96838
Epoch 72, Val Loss: 4.10754
Epoch 73, Val Loss: 4.18155
Epoch 74, Val Loss: 3.97788
Epoch 75, Val Loss: 4.61600
Epoch 76, Val Loss: 4.11884
Epoch 77, Val Loss: 4.16619
Epoch 78, Val Loss: 3.99397
Epoch 79, Val Loss: 4.10836
Epoch 80, Val Loss: 3.99500
Epoch 81, Val Loss: 3.97073
Epoch 82, Val Loss: 4.17246
Epoch 83, Val Loss: 4.21272
Epoch 84, Val Loss: 3.89585
Epoch 85, Val Loss: 4.12529
Epoch 86, Val Loss: 4.07972
Epoch 87, Val Loss: 3.91813
Epoch 88, Val Loss: 4.07997
Epoch 89, Val Loss: 4.01896
Epoch 90, Val Loss: 4.14433
Epoch 91, Val Loss: 4.19579
Epoch 92, Val Loss: 4.16701
Epoch 93, Val Loss: 4.09628
Epoch 94, Val Loss: 4.23011
Epoch 95, Val Loss: 3.85683
Epoch 96, Val Loss: 3.90746
Epoch 97, Val Loss: 4.49339
Epoch 98, Val Loss: 4.23218
Epoch 99, Val Loss: 3.99374
Saved Losses
{'MSE - mean': 4.373734591785357, 'MSE - std': 0.30039427842229616, 'R2 - mean': 0.5697654057146653, 'R2 - std': 0.003969486247799026} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.64811
Epoch 1, Val Loss: 19.51212
Epoch 2, Val Loss: 6.34120
Epoch 3, Val Loss: 5.70433
Epoch 4, Val Loss: 5.58007
Epoch 5, Val Loss: 5.40976
Epoch 6, Val Loss: 5.35812
Epoch 7, Val Loss: 5.51195
Epoch 8, Val Loss: 5.28099
Epoch 9, Val Loss: 5.22524
Epoch 10, Val Loss: 5.25593
Epoch 11, Val Loss: 5.25576
Epoch 12, Val Loss: 5.73210
Epoch 13, Val Loss: 5.20399
Epoch 14, Val Loss: 5.40748
Epoch 15, Val Loss: 5.10026
Epoch 16, Val Loss: 5.24905
Epoch 17, Val Loss: 5.10340
Epoch 18, Val Loss: 5.05316
Epoch 19, Val Loss: 5.07579
Epoch 20, Val Loss: 5.61417
Epoch 21, Val Loss: 5.24157
Epoch 22, Val Loss: 5.07835
Epoch 23, Val Loss: 5.23747
Epoch 24, Val Loss: 5.04335
Epoch 25, Val Loss: 5.06847
Epoch 26, Val Loss: 4.92539
Epoch 27, Val Loss: 5.23483
Epoch 28, Val Loss: 5.31729
Epoch 29, Val Loss: 4.86410
Epoch 30, Val Loss: 4.88973
Epoch 31, Val Loss: 4.81098
Epoch 32, Val Loss: 4.95022
Epoch 33, Val Loss: 4.91549
Epoch 34, Val Loss: 4.67101
Epoch 35, Val Loss: 4.81665
Epoch 36, Val Loss: 4.72365
Epoch 37, Val Loss: 4.75262
Epoch 38, Val Loss: 4.75222
Epoch 39, Val Loss: 4.66442
Epoch 40, Val Loss: 4.67378
Epoch 41, Val Loss: 4.77471
Epoch 42, Val Loss: 4.75815
Epoch 43, Val Loss: 4.70733
Epoch 44, Val Loss: 4.81543
Epoch 45, Val Loss: 4.62271
Epoch 46, Val Loss: 4.60507
Epoch 47, Val Loss: 4.66522
Epoch 48, Val Loss: 4.67573
Epoch 49, Val Loss: 4.71366
Epoch 50, Val Loss: 4.59986
Epoch 51, Val Loss: 5.18481
Epoch 52, Val Loss: 4.89893
Epoch 53, Val Loss: 4.62855
Epoch 54, Val Loss: 4.77047
Epoch 55, Val Loss: 4.80288
Epoch 56, Val Loss: 4.97415
Epoch 57, Val Loss: 4.68824
Epoch 58, Val Loss: 4.59287
Epoch 59, Val Loss: 4.63170
Epoch 60, Val Loss: 4.59740
Epoch 61, Val Loss: 5.49970
Epoch 62, Val Loss: 4.62433
Epoch 63, Val Loss: 4.71286
Epoch 64, Val Loss: 4.63126
Epoch 65, Val Loss: 5.02192
Epoch 66, Val Loss: 4.65418
Epoch 67, Val Loss: 4.79731
Epoch 68, Val Loss: 4.56006
Epoch 69, Val Loss: 4.59514
Epoch 70, Val Loss: 4.60715
Epoch 71, Val Loss: 4.61560
Epoch 72, Val Loss: 4.60305
Epoch 73, Val Loss: 5.94225
Epoch 74, Val Loss: 4.57430
Epoch 75, Val Loss: 4.76905
Epoch 76, Val Loss: 4.79722
Epoch 77, Val Loss: 4.57491
Epoch 78, Val Loss: 4.95422
Epoch 79, Val Loss: 4.71046
Epoch 80, Val Loss: 4.55329
Epoch 81, Val Loss: 4.62079
Epoch 82, Val Loss: 4.58813
Epoch 83, Val Loss: 4.89084
Epoch 84, Val Loss: 4.67363
Epoch 85, Val Loss: 4.58933
Epoch 86, Val Loss: 4.54576
Epoch 87, Val Loss: 5.13525
Epoch 88, Val Loss: 4.61917
Epoch 89, Val Loss: 4.93241
Epoch 90, Val Loss: 4.61817
Epoch 91, Val Loss: 4.82414
Epoch 92, Val Loss: 4.60021
Epoch 93, Val Loss: 4.58716
Epoch 94, Val Loss: 4.69212
Epoch 95, Val Loss: 4.68218
Epoch 96, Val Loss: 4.54812
Epoch 97, Val Loss: 4.58742
Epoch 98, Val Loss: 4.91712
Epoch 99, Val Loss: 4.58031
Saved Losses
{'MSE - mean': 4.458323097906376, 'MSE - std': 0.27288870577851443, 'R2 - mean': 0.5613969488315005, 'R2 - std': 0.012270561869439936} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.17332
Epoch 1, Val Loss: 8.99405
Epoch 2, Val Loss: 6.02030
Epoch 3, Val Loss: 5.39153
Epoch 4, Val Loss: 5.11795
Epoch 5, Val Loss: 4.86072
Epoch 6, Val Loss: 4.68124
Epoch 7, Val Loss: 4.57121
Epoch 8, Val Loss: 5.50065
Epoch 9, Val Loss: 4.65731
Epoch 10, Val Loss: 4.49435
Epoch 11, Val Loss: 4.39112
Epoch 12, Val Loss: 4.41380
Epoch 13, Val Loss: 4.36002
Epoch 14, Val Loss: 4.36804
Epoch 15, Val Loss: 4.71838
Epoch 16, Val Loss: 4.35255
Epoch 17, Val Loss: 4.33100
Epoch 18, Val Loss: 4.36255
Epoch 19, Val Loss: 4.56200
Epoch 20, Val Loss: 4.26697
Epoch 21, Val Loss: 4.33127
Epoch 22, Val Loss: 4.18730
Epoch 23, Val Loss: 4.20581
Epoch 24, Val Loss: 4.41087
Epoch 25, Val Loss: 4.59117
Epoch 26, Val Loss: 4.08545
Epoch 27, Val Loss: 4.01022
Epoch 28, Val Loss: 4.04385
Epoch 29, Val Loss: 4.07772
Epoch 30, Val Loss: 4.03884
Epoch 31, Val Loss: 3.95619
Epoch 32, Val Loss: 4.06492
Epoch 33, Val Loss: 3.95134
Epoch 34, Val Loss: 4.13255
Epoch 35, Val Loss: 4.03525
Epoch 36, Val Loss: 3.92163
Epoch 37, Val Loss: 4.04523
Epoch 38, Val Loss: 4.25345
Epoch 39, Val Loss: 3.96436
Epoch 40, Val Loss: 4.01503
Epoch 41, Val Loss: 3.89308
Epoch 42, Val Loss: 4.01462
Epoch 43, Val Loss: 4.24678
Epoch 44, Val Loss: 4.01517
Epoch 45, Val Loss: 4.07990
Epoch 46, Val Loss: 3.86680
Epoch 47, Val Loss: 4.05355
Epoch 48, Val Loss: 4.21346
Epoch 49, Val Loss: 3.91763
Epoch 50, Val Loss: 4.00557
Epoch 51, Val Loss: 3.88399
Epoch 52, Val Loss: 4.09009
Epoch 53, Val Loss: 3.86146
Epoch 54, Val Loss: 4.06253
Epoch 55, Val Loss: 4.38582
Epoch 56, Val Loss: 4.05637
Epoch 57, Val Loss: 4.05859
Epoch 58, Val Loss: 4.05159
Epoch 59, Val Loss: 3.90800
Epoch 60, Val Loss: 4.22936
Epoch 61, Val Loss: 4.02705
Epoch 62, Val Loss: 4.11147
Epoch 63, Val Loss: 3.96902
Epoch 64, Val Loss: 3.95885
Epoch 65, Val Loss: 3.97313
Epoch 66, Val Loss: 3.89652
Epoch 67, Val Loss: 4.09037
Epoch 68, Val Loss: 3.94219
Epoch 69, Val Loss: 4.11873
Epoch 70, Val Loss: 3.88017
Epoch 71, Val Loss: 4.01357
Epoch 72, Val Loss: 3.99257
Epoch 73, Val Loss: 4.03323
Epoch 74, Val Loss: 4.94951
Early stopping applies.
Saved Losses
{'MSE - mean': 4.38767424667947, 'MSE - std': 0.2661296015950664, 'R2 - mean': 0.5594299796514354, 'R2 - std': 0.011159387066940252} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.53699
Epoch 1, Val Loss: 13.59019
Epoch 2, Val Loss: 8.27809
Epoch 3, Val Loss: 8.11377
Epoch 4, Val Loss: 8.05464
Epoch 5, Val Loss: 7.98877
Epoch 6, Val Loss: 7.65565
Epoch 7, Val Loss: 7.92579
Epoch 8, Val Loss: 7.13010
Epoch 9, Val Loss: 6.99938
Epoch 10, Val Loss: 7.08869
Epoch 11, Val Loss: 7.01120
Epoch 12, Val Loss: 6.74554
Epoch 13, Val Loss: 6.80738
Epoch 14, Val Loss: 7.02424
Epoch 15, Val Loss: 6.77892
Epoch 16, Val Loss: 6.35733
Epoch 17, Val Loss: 6.37664
Epoch 18, Val Loss: 6.34115
Epoch 19, Val Loss: 6.45054
Epoch 20, Val Loss: 6.57549
Epoch 21, Val Loss: 6.40846
Epoch 22, Val Loss: 6.26157
Epoch 23, Val Loss: 6.43521
Epoch 24, Val Loss: 6.29966
Epoch 25, Val Loss: 6.24324
Epoch 26, Val Loss: 6.07089
Epoch 27, Val Loss: 5.96580
Epoch 28, Val Loss: 6.40730
Epoch 29, Val Loss: 5.97950
Epoch 30, Val Loss: 6.00073
Epoch 31, Val Loss: 6.05892
Epoch 32, Val Loss: 6.07941
Epoch 33, Val Loss: 5.95147
Epoch 34, Val Loss: 6.24457
Epoch 35, Val Loss: 6.16639
Epoch 36, Val Loss: 5.90624
Epoch 37, Val Loss: 5.94079
Epoch 38, Val Loss: 6.01147
Epoch 39, Val Loss: 6.64366
Epoch 40, Val Loss: 6.01457
Epoch 41, Val Loss: 5.88290
Epoch 42, Val Loss: 6.16716
Epoch 43, Val Loss: 5.89418
Epoch 44, Val Loss: 6.34991
Epoch 45, Val Loss: 6.22343
Epoch 46, Val Loss: 5.86413
Epoch 47, Val Loss: 6.26712
Epoch 48, Val Loss: 6.19306
Epoch 49, Val Loss: 6.22027
Epoch 50, Val Loss: 5.88079
Epoch 51, Val Loss: 6.04632
Epoch 52, Val Loss: 5.81200
Epoch 53, Val Loss: 6.20776
Epoch 54, Val Loss: 6.47411
Epoch 55, Val Loss: 6.04595
Epoch 56, Val Loss: 6.07729
Epoch 57, Val Loss: 6.43524
Epoch 58, Val Loss: 5.95305
Epoch 59, Val Loss: 5.83315
Epoch 60, Val Loss: 5.94212
Epoch 61, Val Loss: 5.96120
Epoch 62, Val Loss: 5.77032
Epoch 63, Val Loss: 5.84839
Epoch 64, Val Loss: 6.02426
Epoch 65, Val Loss: 5.94772
Epoch 66, Val Loss: 6.18561
Epoch 67, Val Loss: 5.90970
Epoch 68, Val Loss: 5.95834
Epoch 69, Val Loss: 6.09005
Epoch 70, Val Loss: 5.97159
Epoch 71, Val Loss: 5.75280
Epoch 72, Val Loss: 5.93002
Epoch 73, Val Loss: 5.90635
Epoch 74, Val Loss: 6.07004
Epoch 75, Val Loss: 5.86281
Epoch 76, Val Loss: 5.77030
Epoch 77, Val Loss: 5.79637
Epoch 78, Val Loss: 7.17425
Epoch 79, Val Loss: 7.12264
Epoch 80, Val Loss: 5.88354
Epoch 81, Val Loss: 6.14645
Epoch 82, Val Loss: 6.09587
Epoch 83, Val Loss: 6.20889
Epoch 84, Val Loss: 5.96357
Epoch 85, Val Loss: 5.83082
Epoch 86, Val Loss: 5.94778
Epoch 87, Val Loss: 6.25692
Epoch 88, Val Loss: 5.90992
Epoch 89, Val Loss: 5.79432
Epoch 90, Val Loss: 6.00720
Epoch 91, Val Loss: 6.19303
Epoch 92, Val Loss: 5.90231
Early stopping applies.
Saved Losses
{'MSE - mean': 4.653930353089623, 'MSE - std': 0.5832917183356007, 'R2 - mean': 0.5529528320424075, 'R2 - std': 0.01635357148650938} 
 

Results After CV: {'MSE - mean': 4.653930353089623, 'MSE - std': 0.5832917183356007, 'R2 - mean': 0.5529528320424075, 'R2 - std': 0.01635357148650938}
Train time: 110.90488265599997
Inference time: 0.04823977799987915
Finished cross validation
Trial 6 finished with value: 4.653930353089623 and parameters: {'p_m': 0.2216265119455243, 'alpha': 6.434995260435152, 'K': 20, 'beta': 0.35076409509239115}. Best is trial 6 with value: 4.653930353089623.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.17255
Epoch 1, Val Loss: 11.94202
Epoch 2, Val Loss: 8.11756
Epoch 3, Val Loss: 6.85163
Epoch 4, Val Loss: 6.77176
Epoch 5, Val Loss: 6.62910
Epoch 6, Val Loss: 6.75505
Epoch 7, Val Loss: 6.54796
Epoch 8, Val Loss: 6.55819
Epoch 9, Val Loss: 6.43201
Epoch 10, Val Loss: 6.41500
Epoch 11, Val Loss: 6.65438
Epoch 12, Val Loss: 6.38511
Epoch 13, Val Loss: 6.68107
Epoch 14, Val Loss: 6.42711
Epoch 15, Val Loss: 6.47925
Epoch 16, Val Loss: 6.40496
Epoch 17, Val Loss: 6.47121
Epoch 18, Val Loss: 6.40343
Epoch 19, Val Loss: 7.24483
Epoch 20, Val Loss: 6.84645
Epoch 21, Val Loss: 6.36297
Epoch 22, Val Loss: 6.92285
Epoch 23, Val Loss: 6.73917
Epoch 24, Val Loss: 6.39227
Epoch 25, Val Loss: 6.36221
Epoch 26, Val Loss: 6.23563
Epoch 27, Val Loss: 6.17492
Epoch 28, Val Loss: 6.76066
Epoch 29, Val Loss: 6.25160
Epoch 30, Val Loss: 6.23720
Epoch 31, Val Loss: 6.23712
Epoch 32, Val Loss: 6.89466
Epoch 33, Val Loss: 6.33222
Epoch 34, Val Loss: 6.17102
Epoch 35, Val Loss: 6.54312
Epoch 36, Val Loss: 6.16334
Epoch 37, Val Loss: 6.08131
Epoch 38, Val Loss: 6.13820
Epoch 39, Val Loss: 6.30188
Epoch 40, Val Loss: 6.11665
Epoch 41, Val Loss: 6.39941
Epoch 42, Val Loss: 5.98696
Epoch 43, Val Loss: 6.11511
Epoch 44, Val Loss: 6.02981
Epoch 45, Val Loss: 6.79537
Epoch 46, Val Loss: 5.96226
Epoch 47, Val Loss: 6.24980
Epoch 48, Val Loss: 6.16434
Epoch 49, Val Loss: 6.12105
Epoch 50, Val Loss: 6.24258
Epoch 51, Val Loss: 6.16182
Epoch 52, Val Loss: 6.58609
Epoch 53, Val Loss: 5.94613
Epoch 54, Val Loss: 6.19091
Epoch 55, Val Loss: 6.29622
Epoch 56, Val Loss: 6.03305
Epoch 57, Val Loss: 6.30180
Epoch 58, Val Loss: 5.85719
Epoch 59, Val Loss: 6.09639
Epoch 60, Val Loss: 5.84197
Epoch 61, Val Loss: 6.26789
Epoch 62, Val Loss: 6.08268
Epoch 63, Val Loss: 5.95944
Epoch 64, Val Loss: 6.04155
Epoch 65, Val Loss: 6.38551
Epoch 66, Val Loss: 6.08104
Epoch 67, Val Loss: 6.23809
Epoch 68, Val Loss: 5.85951
Epoch 69, Val Loss: 6.25789
Epoch 70, Val Loss: 6.07750
Epoch 71, Val Loss: 5.77240
Epoch 72, Val Loss: 6.07218
Epoch 73, Val Loss: 5.90774
Epoch 74, Val Loss: 6.13391
Epoch 75, Val Loss: 5.95288
Epoch 76, Val Loss: 5.79543
Epoch 77, Val Loss: 6.48680
Epoch 78, Val Loss: 5.82580
Epoch 79, Val Loss: 5.96615
Epoch 80, Val Loss: 6.14294
Epoch 81, Val Loss: 5.85430
Epoch 82, Val Loss: 5.71663
Epoch 83, Val Loss: 5.83076
Epoch 84, Val Loss: 5.85735
Epoch 85, Val Loss: 6.61438
Epoch 86, Val Loss: 5.88964
Epoch 87, Val Loss: 5.70891
Epoch 88, Val Loss: 5.82963
Epoch 89, Val Loss: 5.72892
Epoch 90, Val Loss: 5.80221
Epoch 91, Val Loss: 5.53513
Epoch 92, Val Loss: 5.62960
Epoch 93, Val Loss: 5.69613
Epoch 94, Val Loss: 5.82269
Epoch 95, Val Loss: 5.88344
Epoch 96, Val Loss: 5.77625
Epoch 97, Val Loss: 5.95012
Epoch 98, Val Loss: 5.58882
Epoch 99, Val Loss: 6.02549
Saved Losses
{'MSE - mean': 5.737666500873482, 'MSE - std': 0.0, 'R2 - mean': 0.4767437743389542, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.30009
Epoch 1, Val Loss: 7.57791
Epoch 2, Val Loss: 5.77000
Epoch 3, Val Loss: 5.46520
Epoch 4, Val Loss: 5.41459
Epoch 5, Val Loss: 5.32229
Epoch 6, Val Loss: 5.28320
Epoch 7, Val Loss: 5.20444
Epoch 8, Val Loss: 5.89442
Epoch 9, Val Loss: 5.14185
Epoch 10, Val Loss: 5.09290
Epoch 11, Val Loss: 5.24774
Epoch 12, Val Loss: 5.17536
Epoch 13, Val Loss: 5.35968
Epoch 14, Val Loss: 5.41649
Epoch 15, Val Loss: 5.21087
Epoch 16, Val Loss: 5.53948
Epoch 17, Val Loss: 5.16694
Epoch 18, Val Loss: 4.97417
Epoch 19, Val Loss: 5.08511
Epoch 20, Val Loss: 5.66630
Epoch 21, Val Loss: 5.08169
Epoch 22, Val Loss: 6.25485
Epoch 23, Val Loss: 4.91808
Epoch 24, Val Loss: 5.07486
Epoch 25, Val Loss: 5.01616
Epoch 26, Val Loss: 4.97165
Epoch 27, Val Loss: 5.02873
Epoch 28, Val Loss: 4.90948
Epoch 29, Val Loss: 5.02871
Epoch 30, Val Loss: 4.85459
Epoch 31, Val Loss: 4.83725
Epoch 32, Val Loss: 4.91064
Epoch 33, Val Loss: 4.90711
Epoch 34, Val Loss: 5.22565
Epoch 35, Val Loss: 4.93496
Epoch 36, Val Loss: 4.88412
Epoch 37, Val Loss: 4.80976
Epoch 38, Val Loss: 4.80689
Epoch 39, Val Loss: 4.83653
Epoch 40, Val Loss: 4.96430
Epoch 41, Val Loss: 4.85222
Epoch 42, Val Loss: 4.80821
Epoch 43, Val Loss: 4.69923
Epoch 44, Val Loss: 5.01866
Epoch 45, Val Loss: 5.07729
Epoch 46, Val Loss: 4.92597
Epoch 47, Val Loss: 4.86330
Epoch 48, Val Loss: 4.64941
Epoch 49, Val Loss: 4.89927
Epoch 50, Val Loss: 5.07632
Epoch 51, Val Loss: 4.74621
Epoch 52, Val Loss: 4.72174
Epoch 53, Val Loss: 4.69745
Epoch 54, Val Loss: 4.63698
Epoch 55, Val Loss: 5.05559
Epoch 56, Val Loss: 4.68315
Epoch 57, Val Loss: 4.62727
Epoch 58, Val Loss: 4.68140
Epoch 59, Val Loss: 4.80337
Epoch 60, Val Loss: 4.85540
Epoch 61, Val Loss: 4.53605
Epoch 62, Val Loss: 4.95062
Epoch 63, Val Loss: 4.75485
Epoch 64, Val Loss: 4.52451
Epoch 65, Val Loss: 4.48909
Epoch 66, Val Loss: 4.53592
Epoch 67, Val Loss: 4.67818
Epoch 68, Val Loss: 4.57510
Epoch 69, Val Loss: 4.47434
Epoch 70, Val Loss: 4.88335
Epoch 71, Val Loss: 4.42424
Epoch 72, Val Loss: 4.52626
Epoch 73, Val Loss: 4.40180
Epoch 74, Val Loss: 5.33749
Epoch 75, Val Loss: 4.40013
Epoch 76, Val Loss: 4.42696
Epoch 77, Val Loss: 4.50441
Epoch 78, Val Loss: 4.71297
Epoch 79, Val Loss: 4.42373
Epoch 80, Val Loss: 4.38221
Epoch 81, Val Loss: 6.54175
Epoch 82, Val Loss: 4.53128
Epoch 83, Val Loss: 4.49611
Epoch 84, Val Loss: 4.40131
Epoch 85, Val Loss: 4.40042
Epoch 86, Val Loss: 4.57946
Epoch 87, Val Loss: 4.71596
Epoch 88, Val Loss: 4.36712
Epoch 89, Val Loss: 4.52284
Epoch 90, Val Loss: 4.84670
Epoch 91, Val Loss: 4.48855
Epoch 92, Val Loss: 4.65622
Epoch 93, Val Loss: 4.34618
Epoch 94, Val Loss: 4.89823
Epoch 95, Val Loss: 4.56714
Epoch 96, Val Loss: 4.49458
Epoch 97, Val Loss: 4.74761
Epoch 98, Val Loss: 4.42760
Epoch 99, Val Loss: 4.79238
Saved Losses
{'MSE - mean': 5.154461779078529, 'MSE - std': 0.5832047217949534, 'R2 - mean': 0.494731739926334, 'R2 - std': 0.017987965587379806} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.32546
Epoch 1, Val Loss: 9.44296
Epoch 2, Val Loss: 6.29859
Epoch 3, Val Loss: 6.13474
Epoch 4, Val Loss: 6.23091
Epoch 5, Val Loss: 6.32481
Epoch 6, Val Loss: 6.30432
Epoch 7, Val Loss: 5.97291
Epoch 8, Val Loss: 6.02875
Epoch 9, Val Loss: 6.00379
Epoch 10, Val Loss: 6.13390
Epoch 11, Val Loss: 5.98793
Epoch 12, Val Loss: 5.98286
Epoch 13, Val Loss: 5.92361
Epoch 14, Val Loss: 5.88893
Epoch 15, Val Loss: 6.98040
Epoch 16, Val Loss: 6.02265
Epoch 17, Val Loss: 6.20419
Epoch 18, Val Loss: 5.79423
Epoch 19, Val Loss: 6.00027
Epoch 20, Val Loss: 5.86620
Epoch 21, Val Loss: 5.80587
Epoch 22, Val Loss: 5.83976
Epoch 23, Val Loss: 5.70339
Epoch 24, Val Loss: 5.81510
Epoch 25, Val Loss: 5.87700
Epoch 26, Val Loss: 5.88765
Epoch 27, Val Loss: 5.74484
Epoch 28, Val Loss: 5.77088
Epoch 29, Val Loss: 5.80598
Epoch 30, Val Loss: 5.72556
Epoch 31, Val Loss: 5.75389
Epoch 32, Val Loss: 5.61743
Epoch 33, Val Loss: 5.55674
Epoch 34, Val Loss: 5.80702
Epoch 35, Val Loss: 5.65632
Epoch 36, Val Loss: 5.53965
Epoch 37, Val Loss: 5.60751
Epoch 38, Val Loss: 5.65598
Epoch 39, Val Loss: 5.63720
Epoch 40, Val Loss: 5.84638
Epoch 41, Val Loss: 5.52275
Epoch 42, Val Loss: 5.45391
Epoch 43, Val Loss: 5.74682
Epoch 44, Val Loss: 5.45992
Epoch 45, Val Loss: 5.47581
Epoch 46, Val Loss: 5.49891
Epoch 47, Val Loss: 5.45550
Epoch 48, Val Loss: 5.47882
Epoch 49, Val Loss: 5.51413
Epoch 50, Val Loss: 5.42751
Epoch 51, Val Loss: 5.51130
Epoch 52, Val Loss: 5.41786
Epoch 53, Val Loss: 5.47852
Epoch 54, Val Loss: 5.26934
Epoch 55, Val Loss: 5.30868
Epoch 56, Val Loss: 5.29405
Epoch 57, Val Loss: 5.44959
Epoch 58, Val Loss: 5.32506
Epoch 59, Val Loss: 5.51211
Epoch 60, Val Loss: 5.38304
Epoch 61, Val Loss: 5.42496
Epoch 62, Val Loss: 5.43177
Epoch 63, Val Loss: 5.56606
Epoch 64, Val Loss: 5.30204
Epoch 65, Val Loss: 5.28276
Epoch 66, Val Loss: 6.08466
Epoch 67, Val Loss: 5.39064
Epoch 68, Val Loss: 5.27787
Epoch 69, Val Loss: 5.42512
Epoch 70, Val Loss: 5.27921
Epoch 71, Val Loss: 5.37830
Epoch 72, Val Loss: 5.18915
Epoch 73, Val Loss: 5.37111
Epoch 74, Val Loss: 5.27208
Epoch 75, Val Loss: 5.18093
Epoch 76, Val Loss: 5.18234
Epoch 77, Val Loss: 5.25981
Epoch 78, Val Loss: 5.25971
Epoch 79, Val Loss: 5.25344
Epoch 80, Val Loss: 5.31140
Epoch 81, Val Loss: 5.23007
Epoch 82, Val Loss: 5.15211
Epoch 83, Val Loss: 5.20643
Epoch 84, Val Loss: 5.63921
Epoch 85, Val Loss: 5.21509
Epoch 86, Val Loss: 5.10773
Epoch 87, Val Loss: 5.19106
Epoch 88, Val Loss: 5.32321
Epoch 89, Val Loss: 5.55668
Epoch 90, Val Loss: 5.14713
Epoch 91, Val Loss: 5.24044
Epoch 92, Val Loss: 5.10666
Epoch 93, Val Loss: 5.30891
Epoch 94, Val Loss: 5.02195
Epoch 95, Val Loss: 5.20605
Epoch 96, Val Loss: 5.00948
Epoch 97, Val Loss: 5.05583
Epoch 98, Val Loss: 5.02750
Epoch 99, Val Loss: 5.21673
Saved Losses
{'MSE - mean': 5.163294585001612, 'MSE - std': 0.47634847391753976, 'R2 - mean': 0.4932212551637269, 'R2 - std': 0.014841644082939176} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.28465
Epoch 1, Val Loss: 12.26232
Epoch 2, Val Loss: 5.86139
Epoch 3, Val Loss: 5.58546
Epoch 4, Val Loss: 5.90643
Epoch 5, Val Loss: 5.46404
Epoch 6, Val Loss: 5.59511
Epoch 7, Val Loss: 5.63897
Epoch 8, Val Loss: 5.30515
Epoch 9, Val Loss: 5.29513
Epoch 10, Val Loss: 5.29429
Epoch 11, Val Loss: 5.24275
Epoch 12, Val Loss: 5.36348
Epoch 13, Val Loss: 5.18268
Epoch 14, Val Loss: 5.27429
Epoch 15, Val Loss: 5.11704
Epoch 16, Val Loss: 5.35676
Epoch 17, Val Loss: 5.15907
Epoch 18, Val Loss: 5.02547
Epoch 19, Val Loss: 5.17360
Epoch 20, Val Loss: 5.00247
Epoch 21, Val Loss: 5.04669
Epoch 22, Val Loss: 4.92948
Epoch 23, Val Loss: 5.01656
Epoch 24, Val Loss: 5.04457
Epoch 25, Val Loss: 4.92467
Epoch 26, Val Loss: 4.88669
Epoch 27, Val Loss: 4.94263
Epoch 28, Val Loss: 5.19489
Epoch 29, Val Loss: 5.06727
Epoch 30, Val Loss: 5.03032
Epoch 31, Val Loss: 4.92785
Epoch 32, Val Loss: 5.35757
Epoch 33, Val Loss: 4.82811
Epoch 34, Val Loss: 4.97274
Epoch 35, Val Loss: 4.72694
Epoch 36, Val Loss: 4.90297
Epoch 37, Val Loss: 5.23471
Epoch 38, Val Loss: 4.77616
Epoch 39, Val Loss: 5.20738
Epoch 40, Val Loss: 4.91981
Epoch 41, Val Loss: 5.04255
Epoch 42, Val Loss: 4.68942
Epoch 43, Val Loss: 4.76831
Epoch 44, Val Loss: 4.89209
Epoch 45, Val Loss: 4.69998
Epoch 46, Val Loss: 4.79073
Epoch 47, Val Loss: 4.84269
Epoch 48, Val Loss: 4.89659
Epoch 49, Val Loss: 4.77205
Epoch 50, Val Loss: 4.99305
Epoch 51, Val Loss: 4.64371
Epoch 52, Val Loss: 4.69412
Epoch 53, Val Loss: 4.79822
Epoch 54, Val Loss: 4.81239
Epoch 55, Val Loss: 5.22359
Epoch 56, Val Loss: 4.88357
Epoch 57, Val Loss: 4.76591
Epoch 58, Val Loss: 4.68037
Epoch 59, Val Loss: 4.64620
Epoch 60, Val Loss: 4.67413
Epoch 61, Val Loss: 4.62500
Epoch 62, Val Loss: 4.93129
Epoch 63, Val Loss: 4.69931
Epoch 64, Val Loss: 4.69574
Epoch 65, Val Loss: 4.66739
Epoch 66, Val Loss: 4.54082
Epoch 67, Val Loss: 4.86185
Epoch 68, Val Loss: 4.81821
Epoch 69, Val Loss: 4.60344
Epoch 70, Val Loss: 4.70943
Epoch 71, Val Loss: 4.71946
Epoch 72, Val Loss: 4.58418
Epoch 73, Val Loss: 4.64998
Epoch 74, Val Loss: 4.83021
Epoch 75, Val Loss: 4.76425
Epoch 76, Val Loss: 4.81584
Epoch 77, Val Loss: 4.51353
Epoch 78, Val Loss: 4.55836
Epoch 79, Val Loss: 4.68625
Epoch 80, Val Loss: 4.68809
Epoch 81, Val Loss: 4.58155
Epoch 82, Val Loss: 4.54218
Epoch 83, Val Loss: 4.57479
Epoch 84, Val Loss: 5.11334
Epoch 85, Val Loss: 4.82413
Epoch 86, Val Loss: 4.59408
Epoch 87, Val Loss: 4.69669
Epoch 88, Val Loss: 4.66323
Epoch 89, Val Loss: 4.53875
Epoch 90, Val Loss: 4.67904
Epoch 91, Val Loss: 4.76666
Epoch 92, Val Loss: 4.67045
Epoch 93, Val Loss: 4.48485
Epoch 94, Val Loss: 4.61767
Epoch 95, Val Loss: 4.59023
Epoch 96, Val Loss: 4.53988
Epoch 97, Val Loss: 4.54950
Epoch 98, Val Loss: 4.53392
Epoch 99, Val Loss: 4.86470
Saved Losses
{'MSE - mean': 5.087998095042803, 'MSE - std': 0.4326541178043128, 'R2 - mean': 0.4899511598441986, 'R2 - std': 0.01404586663434778} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.73870
Epoch 1, Val Loss: 10.80033
Epoch 2, Val Loss: 8.05435
Epoch 3, Val Loss: 7.60064
Epoch 4, Val Loss: 7.66189
Epoch 5, Val Loss: 7.32405
Epoch 6, Val Loss: 7.35826
Epoch 7, Val Loss: 7.29077
Epoch 8, Val Loss: 7.10799
Epoch 9, Val Loss: 7.33237
Epoch 10, Val Loss: 7.11432
Epoch 11, Val Loss: 7.10509
Epoch 12, Val Loss: 7.07170
Epoch 13, Val Loss: 7.03100
Epoch 14, Val Loss: 7.07296
Epoch 15, Val Loss: 7.02461
Epoch 16, Val Loss: 6.84148
Epoch 17, Val Loss: 6.97188
Epoch 18, Val Loss: 6.73002
Epoch 19, Val Loss: 6.72254
Epoch 20, Val Loss: 6.99514
Epoch 21, Val Loss: 6.79488
Epoch 22, Val Loss: 6.77251
Epoch 23, Val Loss: 6.76620
Epoch 24, Val Loss: 6.75937
Epoch 25, Val Loss: 6.95526
Epoch 26, Val Loss: 6.68038
Epoch 27, Val Loss: 6.58975
Epoch 28, Val Loss: 6.71124
Epoch 29, Val Loss: 6.62209
Epoch 30, Val Loss: 6.77761
Epoch 31, Val Loss: 6.69581
Epoch 32, Val Loss: 7.78760
Epoch 33, Val Loss: 6.62312
Epoch 34, Val Loss: 6.57618
Epoch 35, Val Loss: 6.49816
Epoch 36, Val Loss: 6.84755
Epoch 37, Val Loss: 6.61706
Epoch 38, Val Loss: 7.21547
Epoch 39, Val Loss: 6.71920
Epoch 40, Val Loss: 6.58527
Epoch 41, Val Loss: 6.72478
Epoch 42, Val Loss: 6.79481
Epoch 43, Val Loss: 6.43298
Epoch 44, Val Loss: 6.68270
Epoch 45, Val Loss: 6.95993
Epoch 46, Val Loss: 7.65313
Epoch 47, Val Loss: 6.74029
Epoch 48, Val Loss: 6.53782
Epoch 49, Val Loss: 7.07265
Epoch 50, Val Loss: 6.62785
Epoch 51, Val Loss: 6.61789
Epoch 52, Val Loss: 6.57960
Epoch 53, Val Loss: 6.84633
Epoch 54, Val Loss: 6.34305
Epoch 55, Val Loss: 6.43580
Epoch 56, Val Loss: 6.70526
Epoch 57, Val Loss: 6.41951
Epoch 58, Val Loss: 6.77331
Epoch 59, Val Loss: 6.92452
Epoch 60, Val Loss: 6.83684
Epoch 61, Val Loss: 6.87197
Epoch 62, Val Loss: 6.68881
Epoch 63, Val Loss: 6.74082
Epoch 64, Val Loss: 6.53725
Epoch 65, Val Loss: 6.42426
Epoch 66, Val Loss: 6.70229
Epoch 67, Val Loss: 6.61189
Epoch 68, Val Loss: 6.59370
Epoch 69, Val Loss: 6.99209
Epoch 70, Val Loss: 6.58652
Epoch 71, Val Loss: 6.46742
Epoch 72, Val Loss: 6.55838
Epoch 73, Val Loss: 6.44177
Epoch 74, Val Loss: 7.05094
Epoch 75, Val Loss: 6.85309
Early stopping applies.
Saved Losses
{'MSE - mean': 5.342299202594839, 'MSE - std': 0.6390836265553934, 'R2 - mean': 0.48677513851237125, 'R2 - std': 0.01407755453226155} 
 

Results After CV: {'MSE - mean': 5.342299202594839, 'MSE - std': 0.6390836265553934, 'R2 - mean': 0.48677513851237125, 'R2 - std': 0.01407755453226155}
Train time: 31.89215720020011
Inference time: 0.04863103440002305
Finished cross validation
Trial 7 finished with value: 5.342299202594839 and parameters: {'p_m': 0.17759750790688644, 'alpha': 5.463635342363056, 'K': 3, 'beta': 3.2864103093640207}. Best is trial 6 with value: 4.653930353089623.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.42138
Epoch 1, Val Loss: 9.79804
Epoch 2, Val Loss: 7.23570
Epoch 3, Val Loss: 7.41114
Epoch 4, Val Loss: 7.25411
Epoch 5, Val Loss: 7.17886
Epoch 6, Val Loss: 7.19439
Epoch 7, Val Loss: 7.09894
Epoch 8, Val Loss: 7.24947
Epoch 9, Val Loss: 7.14547
Epoch 10, Val Loss: 7.15920
Epoch 11, Val Loss: 6.98708
Epoch 12, Val Loss: 7.59088
Epoch 13, Val Loss: 7.14832
Epoch 14, Val Loss: 7.39189
Epoch 15, Val Loss: 6.99301
Epoch 16, Val Loss: 7.19528
Epoch 17, Val Loss: 7.39656
Epoch 18, Val Loss: 7.12038
Epoch 19, Val Loss: 7.17164
Epoch 20, Val Loss: 7.02586
Epoch 21, Val Loss: 6.84534
Epoch 22, Val Loss: 6.83012
Epoch 23, Val Loss: 6.86470
Epoch 24, Val Loss: 7.18237
Epoch 25, Val Loss: 6.76427
Epoch 26, Val Loss: 6.73335
Epoch 27, Val Loss: 6.76986
Epoch 28, Val Loss: 7.04267
Epoch 29, Val Loss: 6.58809
Epoch 30, Val Loss: 6.61244
Epoch 31, Val Loss: 6.55246
Epoch 32, Val Loss: 6.64213
Epoch 33, Val Loss: 6.99737
Epoch 34, Val Loss: 6.40151
Epoch 35, Val Loss: 6.53609
Epoch 36, Val Loss: 6.29147
Epoch 37, Val Loss: 6.54661
Epoch 38, Val Loss: 6.08246
Epoch 39, Val Loss: 6.27970
Epoch 40, Val Loss: 6.21296
Epoch 41, Val Loss: 6.12079
Epoch 42, Val Loss: 6.47684
Epoch 43, Val Loss: 6.02179
Epoch 44, Val Loss: 6.11332
Epoch 45, Val Loss: 6.24581
Epoch 46, Val Loss: 6.33939
Epoch 47, Val Loss: 5.77739
Epoch 48, Val Loss: 5.85788
Epoch 49, Val Loss: 5.72391
Epoch 50, Val Loss: 5.79569
Epoch 51, Val Loss: 5.56702
Epoch 52, Val Loss: 5.65963
Epoch 53, Val Loss: 5.52628
Epoch 54, Val Loss: 5.71989
Epoch 55, Val Loss: 5.23102
Epoch 56, Val Loss: 5.31668
Epoch 57, Val Loss: 5.86266
Epoch 58, Val Loss: 5.40977
Epoch 59, Val Loss: 5.21015
Epoch 60, Val Loss: 5.18367
Epoch 61, Val Loss: 5.42812
Epoch 62, Val Loss: 5.06165
Epoch 63, Val Loss: 4.97456
Epoch 64, Val Loss: 5.38755
Epoch 65, Val Loss: 4.93072
Epoch 66, Val Loss: 4.80389
Epoch 67, Val Loss: 4.88013
Epoch 68, Val Loss: 5.16170
Epoch 69, Val Loss: 5.11577
Epoch 70, Val Loss: 4.80489
Epoch 71, Val Loss: 4.80243
Epoch 72, Val Loss: 5.05492
Epoch 73, Val Loss: 4.79669
Epoch 74, Val Loss: 5.24743
Epoch 75, Val Loss: 4.74863
Epoch 76, Val Loss: 4.72215
Epoch 77, Val Loss: 4.87300
Epoch 78, Val Loss: 5.04241
Epoch 79, Val Loss: 4.79911
Epoch 80, Val Loss: 4.58545
Epoch 81, Val Loss: 4.72255
Epoch 82, Val Loss: 4.98121
Epoch 83, Val Loss: 4.59433
Epoch 84, Val Loss: 4.58206
Epoch 85, Val Loss: 4.84841
Epoch 86, Val Loss: 4.92023
Epoch 87, Val Loss: 4.72214
Epoch 88, Val Loss: 5.01395
Epoch 89, Val Loss: 4.68555
Epoch 90, Val Loss: 4.82118
Epoch 91, Val Loss: 4.80901
Epoch 92, Val Loss: 4.77312
Epoch 93, Val Loss: 4.67500
Epoch 94, Val Loss: 4.69450
Epoch 95, Val Loss: 4.75124
Epoch 96, Val Loss: 4.75612
Epoch 97, Val Loss: 4.61561
Epoch 98, Val Loss: 4.78485
Epoch 99, Val Loss: 4.66609
Saved Losses
{'MSE - mean': 4.655805130185034, 'MSE - std': 0.0, 'R2 - mean': 0.5754059565046035, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.74384
Epoch 1, Val Loss: 12.02544
Epoch 2, Val Loss: 5.82370
Epoch 3, Val Loss: 5.30825
Epoch 4, Val Loss: 5.29733
Epoch 5, Val Loss: 5.41621
Epoch 6, Val Loss: 5.25330
Epoch 7, Val Loss: 5.11040
Epoch 8, Val Loss: 4.87869
Epoch 9, Val Loss: 5.43457
Epoch 10, Val Loss: 5.04097
Epoch 11, Val Loss: 4.78494
Epoch 12, Val Loss: 4.73921
Epoch 13, Val Loss: 4.62567
Epoch 14, Val Loss: 4.62232
Epoch 15, Val Loss: 4.62819
Epoch 16, Val Loss: 4.87894
Epoch 17, Val Loss: 4.54359
Epoch 18, Val Loss: 4.74022
Epoch 19, Val Loss: 4.52770
Epoch 20, Val Loss: 4.69991
Epoch 21, Val Loss: 4.59953
Epoch 22, Val Loss: 4.46690
Epoch 23, Val Loss: 4.40505
Epoch 24, Val Loss: 4.40215
Epoch 25, Val Loss: 4.42655
Epoch 26, Val Loss: 4.30758
Epoch 27, Val Loss: 4.64072
Epoch 28, Val Loss: 4.52404
Epoch 29, Val Loss: 4.52895
Epoch 30, Val Loss: 4.45740
Epoch 31, Val Loss: 4.31153
Epoch 32, Val Loss: 4.78534
Epoch 33, Val Loss: 4.65150
Epoch 34, Val Loss: 4.47257
Epoch 35, Val Loss: 4.75135
Epoch 36, Val Loss: 4.29638
Epoch 37, Val Loss: 4.47154
Epoch 38, Val Loss: 4.59757
Epoch 39, Val Loss: 4.50072
Epoch 40, Val Loss: 4.60807
Epoch 41, Val Loss: 4.41964
Epoch 42, Val Loss: 4.36265
Epoch 43, Val Loss: 4.30767
Epoch 44, Val Loss: 4.44106
Epoch 45, Val Loss: 4.53195
Epoch 46, Val Loss: 4.31424
Epoch 47, Val Loss: 4.34384
Epoch 48, Val Loss: 4.34908
Epoch 49, Val Loss: 4.53503
Epoch 50, Val Loss: 4.30924
Epoch 51, Val Loss: 4.22810
Epoch 52, Val Loss: 4.23427
Epoch 53, Val Loss: 4.20606
Epoch 54, Val Loss: 4.32204
Epoch 55, Val Loss: 4.27379
Epoch 56, Val Loss: 4.42624
Epoch 57, Val Loss: 4.23459
Epoch 58, Val Loss: 4.35461
Epoch 59, Val Loss: 4.37003
Epoch 60, Val Loss: 4.29795
Epoch 61, Val Loss: 4.66076
Epoch 62, Val Loss: 4.17859
Epoch 63, Val Loss: 4.43497
Epoch 64, Val Loss: 4.24591
Epoch 65, Val Loss: 4.21818
Epoch 66, Val Loss: 4.41268
Epoch 67, Val Loss: 4.29470
Epoch 68, Val Loss: 4.17258
Epoch 69, Val Loss: 4.52627
Epoch 70, Val Loss: 4.11101
Epoch 71, Val Loss: 4.20968
Epoch 72, Val Loss: 4.27617
Epoch 73, Val Loss: 4.07359
Epoch 74, Val Loss: 4.10561
Epoch 75, Val Loss: 4.29218
Epoch 76, Val Loss: 4.20059
Epoch 77, Val Loss: 4.41403
Epoch 78, Val Loss: 4.31832
Epoch 79, Val Loss: 4.44160
Epoch 80, Val Loss: 4.12105
Epoch 81, Val Loss: 4.23867
Epoch 82, Val Loss: 4.28927
Epoch 83, Val Loss: 4.12520
Epoch 84, Val Loss: 4.41001
Epoch 85, Val Loss: 4.08973
Epoch 86, Val Loss: 4.38883
Epoch 87, Val Loss: 4.04497
Epoch 88, Val Loss: 4.10244
Epoch 89, Val Loss: 4.28962
Epoch 90, Val Loss: 4.08177
Epoch 91, Val Loss: 3.92702
Epoch 92, Val Loss: 4.07117
Epoch 93, Val Loss: 4.04152
Epoch 94, Val Loss: 3.96500
Epoch 95, Val Loss: 3.99660
Epoch 96, Val Loss: 4.02246
Epoch 97, Val Loss: 4.35548
Epoch 98, Val Loss: 4.35886
Epoch 99, Val Loss: 3.93256
Saved Losses
{'MSE - mean': 4.400843216175721, 'MSE - std': 0.2549619140093138, 'R2 - mean': 0.5667346279157182, 'R2 - std': 0.008671328588885308} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.76979
Epoch 1, Val Loss: 12.33009
Epoch 2, Val Loss: 6.82409
Epoch 3, Val Loss: 6.41751
Epoch 4, Val Loss: 6.31692
Epoch 5, Val Loss: 6.19447
Epoch 6, Val Loss: 6.24928
Epoch 7, Val Loss: 5.79195
Epoch 8, Val Loss: 5.61941
Epoch 9, Val Loss: 5.54006
Epoch 10, Val Loss: 5.33570
Epoch 11, Val Loss: 5.47161
Epoch 12, Val Loss: 5.24183
Epoch 13, Val Loss: 5.38232
Epoch 14, Val Loss: 5.20570
Epoch 15, Val Loss: 5.24233
Epoch 16, Val Loss: 5.14508
Epoch 17, Val Loss: 5.26142
Epoch 18, Val Loss: 5.28262
Epoch 19, Val Loss: 5.44054
Epoch 20, Val Loss: 5.09907
Epoch 21, Val Loss: 5.09088
Epoch 22, Val Loss: 5.01877
Epoch 23, Val Loss: 5.24496
Epoch 24, Val Loss: 5.22651
Epoch 25, Val Loss: 5.02962
Epoch 26, Val Loss: 5.09227
Epoch 27, Val Loss: 5.02166
Epoch 28, Val Loss: 4.86161
Epoch 29, Val Loss: 4.84086
Epoch 30, Val Loss: 4.85979
Epoch 31, Val Loss: 4.87168
Epoch 32, Val Loss: 5.29383
Epoch 33, Val Loss: 4.90534
Epoch 34, Val Loss: 4.96346
Epoch 35, Val Loss: 5.04764
Epoch 36, Val Loss: 4.79867
Epoch 37, Val Loss: 4.79543
Epoch 38, Val Loss: 4.93258
Epoch 39, Val Loss: 4.96615
Epoch 40, Val Loss: 4.88765
Epoch 41, Val Loss: 5.44170
Epoch 42, Val Loss: 4.92757
Epoch 43, Val Loss: 4.89915
Epoch 44, Val Loss: 4.82120
Epoch 45, Val Loss: 4.83708
Epoch 46, Val Loss: 4.65790
Epoch 47, Val Loss: 4.87161
Epoch 48, Val Loss: 4.66232
Epoch 49, Val Loss: 4.66874
Epoch 50, Val Loss: 5.00826
Epoch 51, Val Loss: 4.71898
Epoch 52, Val Loss: 4.69889
Epoch 53, Val Loss: 4.70498
Epoch 54, Val Loss: 4.64638
Epoch 55, Val Loss: 4.69402
Epoch 56, Val Loss: 4.65265
Epoch 57, Val Loss: 4.65156
Epoch 58, Val Loss: 4.64515
Epoch 59, Val Loss: 4.75026
Epoch 60, Val Loss: 4.56645
Epoch 61, Val Loss: 4.60520
Epoch 62, Val Loss: 4.87194
Epoch 63, Val Loss: 4.75564
Epoch 64, Val Loss: 4.76024
Epoch 65, Val Loss: 4.63484
Epoch 66, Val Loss: 4.99114
Epoch 67, Val Loss: 4.76680
Epoch 68, Val Loss: 4.57232
Epoch 69, Val Loss: 4.68184
Epoch 70, Val Loss: 4.88415
Epoch 71, Val Loss: 4.62209
Epoch 72, Val Loss: 4.62871
Epoch 73, Val Loss: 4.66374
Epoch 74, Val Loss: 4.85005
Epoch 75, Val Loss: 4.59775
Epoch 76, Val Loss: 4.61987
Epoch 77, Val Loss: 4.80499
Epoch 78, Val Loss: 4.60230
Epoch 79, Val Loss: 4.76961
Epoch 80, Val Loss: 4.66398
Epoch 81, Val Loss: 4.78704
Early stopping applies.
Saved Losses
{'MSE - mean': 4.52835590533644, 'MSE - std': 0.275419722467712, 'R2 - mean': 0.5542635956948505, 'R2 - std': 0.019004769111255152} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.32792
Epoch 1, Val Loss: 9.81988
Epoch 2, Val Loss: 5.77598
Epoch 3, Val Loss: 5.47933
Epoch 4, Val Loss: 5.32726
Epoch 5, Val Loss: 5.34436
Epoch 6, Val Loss: 5.17260
Epoch 7, Val Loss: 5.08171
Epoch 8, Val Loss: 4.83417
Epoch 9, Val Loss: 4.71389
Epoch 10, Val Loss: 4.63727
Epoch 11, Val Loss: 4.57269
Epoch 12, Val Loss: 4.51973
Epoch 13, Val Loss: 4.52681
Epoch 14, Val Loss: 4.37885
Epoch 15, Val Loss: 4.39959
Epoch 16, Val Loss: 4.55479
Epoch 17, Val Loss: 4.46561
Epoch 18, Val Loss: 4.62996
Epoch 19, Val Loss: 4.32895
Epoch 20, Val Loss: 4.26781
Epoch 21, Val Loss: 4.57086
Epoch 22, Val Loss: 4.22306
Epoch 23, Val Loss: 4.43166
Epoch 24, Val Loss: 4.27468
Epoch 25, Val Loss: 4.25970
Epoch 26, Val Loss: 4.25938
Epoch 27, Val Loss: 4.29297
Epoch 28, Val Loss: 4.11468
Epoch 29, Val Loss: 4.09875
Epoch 30, Val Loss: 4.17418
Epoch 31, Val Loss: 4.18189
Epoch 32, Val Loss: 4.24326
Epoch 33, Val Loss: 4.10160
Epoch 34, Val Loss: 4.10609
Epoch 35, Val Loss: 4.12026
Epoch 36, Val Loss: 4.15067
Epoch 37, Val Loss: 4.16084
Epoch 38, Val Loss: 4.45857
Epoch 39, Val Loss: 4.43029
Epoch 40, Val Loss: 4.24221
Epoch 41, Val Loss: 4.05631
Epoch 42, Val Loss: 4.40888
Epoch 43, Val Loss: 4.21867
Epoch 44, Val Loss: 4.07118
Epoch 45, Val Loss: 4.14080
Epoch 46, Val Loss: 4.05978
Epoch 47, Val Loss: 4.07745
Epoch 48, Val Loss: 4.08006
Epoch 49, Val Loss: 4.06435
Epoch 50, Val Loss: 4.52480
Epoch 51, Val Loss: 4.32841
Epoch 52, Val Loss: 4.07380
Epoch 53, Val Loss: 4.09588
Epoch 54, Val Loss: 4.51102
Epoch 55, Val Loss: 4.08334
Epoch 56, Val Loss: 4.03209
Epoch 57, Val Loss: 4.03632
Epoch 58, Val Loss: 4.00102
Epoch 59, Val Loss: 4.11907
Epoch 60, Val Loss: 4.24875
Epoch 61, Val Loss: 4.24226
Epoch 62, Val Loss: 4.06356
Epoch 63, Val Loss: 4.10417
Epoch 64, Val Loss: 3.96201
Epoch 65, Val Loss: 4.17140
Epoch 66, Val Loss: 4.25473
Epoch 67, Val Loss: 4.10703
Epoch 68, Val Loss: 3.97261
Epoch 69, Val Loss: 4.13025
Epoch 70, Val Loss: 3.99477
Epoch 71, Val Loss: 4.04141
Epoch 72, Val Loss: 4.40621
Epoch 73, Val Loss: 4.12168
Epoch 74, Val Loss: 4.37651
Epoch 75, Val Loss: 4.03987
Epoch 76, Val Loss: 3.99914
Epoch 77, Val Loss: 4.14597
Epoch 78, Val Loss: 3.96555
Epoch 79, Val Loss: 3.96333
Epoch 80, Val Loss: 4.17124
Epoch 81, Val Loss: 4.13656
Epoch 82, Val Loss: 3.99218
Epoch 83, Val Loss: 4.10319
Epoch 84, Val Loss: 3.89793
Epoch 85, Val Loss: 4.09937
Epoch 86, Val Loss: 3.96262
Epoch 87, Val Loss: 4.09991
Epoch 88, Val Loss: 3.96507
Epoch 89, Val Loss: 3.91888
Epoch 90, Val Loss: 4.01792
Epoch 91, Val Loss: 4.55944
Epoch 92, Val Loss: 4.12710
Epoch 93, Val Loss: 4.03205
Epoch 94, Val Loss: 4.20559
Epoch 95, Val Loss: 4.15726
Epoch 96, Val Loss: 3.96590
Epoch 97, Val Loss: 3.98251
Epoch 98, Val Loss: 4.10158
Epoch 99, Val Loss: 4.00056
Saved Losses
{'MSE - mean': 4.4374764933143185, 'MSE - std': 0.2857782710977221, 'R2 - mean': 0.5543710408006227, 'R2 - std': 0.016459664944383032} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.88707
Epoch 1, Val Loss: 15.96396
Epoch 2, Val Loss: 7.94931
Epoch 3, Val Loss: 6.96103
Epoch 4, Val Loss: 6.87745
Epoch 5, Val Loss: 6.76614
Epoch 6, Val Loss: 6.52158
Epoch 7, Val Loss: 6.43935
Epoch 8, Val Loss: 6.23975
Epoch 9, Val Loss: 6.65029
Epoch 10, Val Loss: 6.37198
Epoch 11, Val Loss: 6.48606
Epoch 12, Val Loss: 6.20362
Epoch 13, Val Loss: 6.18196
Epoch 14, Val Loss: 6.36547
Epoch 15, Val Loss: 5.96820
Epoch 16, Val Loss: 6.06939
Epoch 17, Val Loss: 6.21076
Epoch 18, Val Loss: 6.12472
Epoch 19, Val Loss: 6.08041
Epoch 20, Val Loss: 6.23766
Epoch 21, Val Loss: 5.96579
Epoch 22, Val Loss: 6.03519
Epoch 23, Val Loss: 5.91755
Epoch 24, Val Loss: 5.91559
Epoch 25, Val Loss: 5.87803
Epoch 26, Val Loss: 5.88336
Epoch 27, Val Loss: 5.76377
Epoch 28, Val Loss: 6.05040
Epoch 29, Val Loss: 5.90239
Epoch 30, Val Loss: 6.15442
Epoch 31, Val Loss: 5.75287
Epoch 32, Val Loss: 5.77523
Epoch 33, Val Loss: 5.69374
Epoch 34, Val Loss: 5.69486
Epoch 35, Val Loss: 5.70345
Epoch 36, Val Loss: 5.73110
Epoch 37, Val Loss: 5.67323
Epoch 38, Val Loss: 5.95878
Epoch 39, Val Loss: 5.84201
Epoch 40, Val Loss: 5.70983
Epoch 41, Val Loss: 6.11984
Epoch 42, Val Loss: 6.00910
Epoch 43, Val Loss: 6.07968
Epoch 44, Val Loss: 6.03779
Epoch 45, Val Loss: 5.95328
Epoch 46, Val Loss: 5.75269
Epoch 47, Val Loss: 5.63248
Epoch 48, Val Loss: 5.57281
Epoch 49, Val Loss: 5.78874
Epoch 50, Val Loss: 5.59915
Epoch 51, Val Loss: 5.89316
Epoch 52, Val Loss: 5.73587
Epoch 53, Val Loss: 5.62233
Epoch 54, Val Loss: 6.01446
Epoch 55, Val Loss: 5.89935
Epoch 56, Val Loss: 5.72186
Epoch 57, Val Loss: 5.84158
Epoch 58, Val Loss: 5.76957
Epoch 59, Val Loss: 5.73835
Epoch 60, Val Loss: 5.69667
Epoch 61, Val Loss: 5.67048
Epoch 62, Val Loss: 5.92959
Epoch 63, Val Loss: 5.86929
Epoch 64, Val Loss: 5.99815
Epoch 65, Val Loss: 5.72701
Epoch 66, Val Loss: 5.74345
Epoch 67, Val Loss: 5.57995
Epoch 68, Val Loss: 5.60289
Epoch 69, Val Loss: 5.73642
Early stopping applies.
Saved Losses
{'MSE - mean': 4.638784670488211, 'MSE - std': 0.4769017770711105, 'R2 - mean': 0.5534531282259639, 'R2 - std': 0.014835993732943824} 
 

Results After CV: {'MSE - mean': 4.638784670488211, 'MSE - std': 0.4769017770711105, 'R2 - mean': 0.5534531282259639, 'R2 - std': 0.014835993732943824}
Train time: 74.84727088239997
Inference time: 0.051461104399913894
Finished cross validation
Trial 8 finished with value: 4.638784670488211 and parameters: {'p_m': 0.13801609063901107, 'alpha': 3.6391053225232315, 'K': 10, 'beta': 0.33225973940697795}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.85376
Epoch 1, Val Loss: 14.45180
Epoch 2, Val Loss: 7.92519
Epoch 3, Val Loss: 7.59114
Epoch 4, Val Loss: 6.85652
Epoch 5, Val Loss: 7.34635
Epoch 6, Val Loss: 7.17295
Epoch 7, Val Loss: 6.92189
Epoch 8, Val Loss: 7.72969
Epoch 9, Val Loss: 7.27746
Epoch 10, Val Loss: 6.91230
Epoch 11, Val Loss: 7.11534
Epoch 12, Val Loss: 7.40712
Epoch 13, Val Loss: 6.82092
Epoch 14, Val Loss: 6.82151
Epoch 15, Val Loss: 6.74692
Epoch 16, Val Loss: 7.03704
Epoch 17, Val Loss: 6.74216
Epoch 18, Val Loss: 6.76491
Epoch 19, Val Loss: 6.69120
Epoch 20, Val Loss: 7.15212
Epoch 21, Val Loss: 6.73705
Epoch 22, Val Loss: 6.71506
Epoch 23, Val Loss: 6.90777
Epoch 24, Val Loss: 6.54291
Epoch 25, Val Loss: 6.55760
Epoch 26, Val Loss: 6.49690
Epoch 27, Val Loss: 6.54537
Epoch 28, Val Loss: 6.57096
Epoch 29, Val Loss: 6.62151
Epoch 30, Val Loss: 6.38297
Epoch 31, Val Loss: 6.79392
Epoch 32, Val Loss: 6.61773
Epoch 33, Val Loss: 6.57800
Epoch 34, Val Loss: 6.54673
Epoch 35, Val Loss: 6.53407
Epoch 36, Val Loss: 6.71602
Epoch 37, Val Loss: 6.84105
Epoch 38, Val Loss: 6.24891
Epoch 39, Val Loss: 6.47194
Epoch 40, Val Loss: 6.26724
Epoch 41, Val Loss: 6.50945
Epoch 42, Val Loss: 6.22726
Epoch 43, Val Loss: 6.62635
Epoch 44, Val Loss: 6.31502
Epoch 45, Val Loss: 6.91705
Epoch 46, Val Loss: 6.25152
Epoch 47, Val Loss: 6.26598
Epoch 48, Val Loss: 6.84177
Epoch 49, Val Loss: 6.60751
Epoch 50, Val Loss: 6.39640
Epoch 51, Val Loss: 6.14558
Epoch 52, Val Loss: 6.57955
Epoch 53, Val Loss: 6.16335
Epoch 54, Val Loss: 6.27114
Epoch 55, Val Loss: 6.06080
Epoch 56, Val Loss: 6.34792
Epoch 57, Val Loss: 6.44761
Epoch 58, Val Loss: 6.17389
Epoch 59, Val Loss: 6.03740
Epoch 60, Val Loss: 6.07069
Epoch 61, Val Loss: 5.98909
Epoch 62, Val Loss: 6.07841
Epoch 63, Val Loss: 6.00159
Epoch 64, Val Loss: 6.59417
Epoch 65, Val Loss: 5.90757
Epoch 66, Val Loss: 5.92081
Epoch 67, Val Loss: 6.07928
Epoch 68, Val Loss: 6.15521
Epoch 69, Val Loss: 5.95672
Epoch 70, Val Loss: 6.15989
Epoch 71, Val Loss: 5.90270
Epoch 72, Val Loss: 5.99683
Epoch 73, Val Loss: 6.23233
Epoch 74, Val Loss: 5.98013
Epoch 75, Val Loss: 6.15694
Epoch 76, Val Loss: 5.92320
Epoch 77, Val Loss: 5.86483
Epoch 78, Val Loss: 6.22693
Epoch 79, Val Loss: 6.21711
Epoch 80, Val Loss: 5.87877
Epoch 81, Val Loss: 5.79307
Epoch 82, Val Loss: 5.90130
Epoch 83, Val Loss: 5.72464
Epoch 84, Val Loss: 5.64330
Epoch 85, Val Loss: 5.88281
Epoch 86, Val Loss: 6.00914
Epoch 87, Val Loss: 5.66273
Epoch 88, Val Loss: 5.77769
Epoch 89, Val Loss: 5.77765
Epoch 90, Val Loss: 5.77990
Epoch 91, Val Loss: 5.54379
Epoch 92, Val Loss: 5.59809
Epoch 93, Val Loss: 5.55259
Epoch 94, Val Loss: 5.44350
Epoch 95, Val Loss: 5.38880
Epoch 96, Val Loss: 5.87736
Epoch 97, Val Loss: 5.71800
Epoch 98, Val Loss: 5.40746
Epoch 99, Val Loss: 5.39339
Saved Losses
{'MSE - mean': 5.587192366699809, 'MSE - std': 0.0, 'R2 - mean': 0.4904665181574287, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.71756
Epoch 1, Val Loss: 11.91168
Epoch 2, Val Loss: 6.20521
Epoch 3, Val Loss: 5.91626
Epoch 4, Val Loss: 6.16168
Epoch 5, Val Loss: 5.55752
Epoch 6, Val Loss: 5.94536
Epoch 7, Val Loss: 6.13333
Epoch 8, Val Loss: 5.72649
Epoch 9, Val Loss: 5.67883
Epoch 10, Val Loss: 5.81490
Epoch 11, Val Loss: 5.77638
Epoch 12, Val Loss: 5.87382
Epoch 13, Val Loss: 5.59567
Epoch 14, Val Loss: 5.69885
Epoch 15, Val Loss: 5.48835
Epoch 16, Val Loss: 5.70486
Epoch 17, Val Loss: 5.76985
Epoch 18, Val Loss: 5.70957
Epoch 19, Val Loss: 5.70678
Epoch 20, Val Loss: 5.75486
Epoch 21, Val Loss: 5.60250
Epoch 22, Val Loss: 5.62826
Epoch 23, Val Loss: 5.78978
Epoch 24, Val Loss: 5.61307
Epoch 25, Val Loss: 5.50408
Epoch 26, Val Loss: 5.53283
Epoch 27, Val Loss: 5.45046
Epoch 28, Val Loss: 5.41395
Epoch 29, Val Loss: 5.27637
Epoch 30, Val Loss: 5.22157
Epoch 31, Val Loss: 5.72347
Epoch 32, Val Loss: 5.56138
Epoch 33, Val Loss: 5.21208
Epoch 34, Val Loss: 5.89302
Epoch 35, Val Loss: 5.08350
Epoch 36, Val Loss: 5.07958
Epoch 37, Val Loss: 5.37581
Epoch 38, Val Loss: 5.24274
Epoch 39, Val Loss: 5.80057
Epoch 40, Val Loss: 5.15332
Epoch 41, Val Loss: 5.17022
Epoch 42, Val Loss: 5.12398
Epoch 43, Val Loss: 5.07210
Epoch 44, Val Loss: 5.34350
Epoch 45, Val Loss: 5.26393
Epoch 46, Val Loss: 5.07457
Epoch 47, Val Loss: 5.31808
Epoch 48, Val Loss: 4.99912
Epoch 49, Val Loss: 5.10636
Epoch 50, Val Loss: 5.11424
Epoch 51, Val Loss: 4.92963
Epoch 52, Val Loss: 5.13666
Epoch 53, Val Loss: 4.88974
Epoch 54, Val Loss: 5.60158
Epoch 55, Val Loss: 5.17637
Epoch 56, Val Loss: 5.09682
Epoch 57, Val Loss: 4.80496
Epoch 58, Val Loss: 5.10050
Epoch 59, Val Loss: 4.86120
Epoch 60, Val Loss: 4.85061
Epoch 61, Val Loss: 4.77482
Epoch 62, Val Loss: 4.76229
Epoch 63, Val Loss: 4.81917
Epoch 64, Val Loss: 4.95832
Epoch 65, Val Loss: 4.82333
Epoch 66, Val Loss: 4.83236
Epoch 67, Val Loss: 4.57486
Epoch 68, Val Loss: 4.74515
Epoch 69, Val Loss: 4.92499
Epoch 70, Val Loss: 4.88171
Epoch 71, Val Loss: 4.58155
Epoch 72, Val Loss: 5.14396
Epoch 73, Val Loss: 4.62478
Epoch 74, Val Loss: 4.81599
Epoch 75, Val Loss: 4.59970
Epoch 76, Val Loss: 4.61262
Epoch 77, Val Loss: 4.47147
Epoch 78, Val Loss: 4.58836
Epoch 79, Val Loss: 4.43033
Epoch 80, Val Loss: 4.71214
Epoch 81, Val Loss: 4.44687
Epoch 82, Val Loss: 4.42213
Epoch 83, Val Loss: 4.76847
Epoch 84, Val Loss: 4.45156
Epoch 85, Val Loss: 4.52989
Epoch 86, Val Loss: 4.37424
Epoch 87, Val Loss: 4.43848
Epoch 88, Val Loss: 4.47349
Epoch 89, Val Loss: 4.61888
Epoch 90, Val Loss: 4.43131
Epoch 91, Val Loss: 4.54140
Epoch 92, Val Loss: 4.31499
Epoch 93, Val Loss: 4.40788
Epoch 94, Val Loss: 4.40472
Epoch 95, Val Loss: 4.20670
Epoch 96, Val Loss: 4.45538
Epoch 97, Val Loss: 4.19407
Epoch 98, Val Loss: 4.23128
Epoch 99, Val Loss: 4.22504
Saved Losses
{'MSE - mean': 5.003778942567781, 'MSE - std': 0.5834134241320288, 'R2 - mean': 0.5096353716083075, 'R2 - std': 0.019168853450878764} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.12334
Epoch 1, Val Loss: 15.31554
Epoch 2, Val Loss: 8.27071
Epoch 3, Val Loss: 7.44891
Epoch 4, Val Loss: 7.07377
Epoch 5, Val Loss: 7.18014
Epoch 6, Val Loss: 6.62304
Epoch 7, Val Loss: 6.49838
Epoch 8, Val Loss: 6.73336
Epoch 9, Val Loss: 6.53081
Epoch 10, Val Loss: 6.76486
Epoch 11, Val Loss: 6.62742
Epoch 12, Val Loss: 6.66307
Epoch 13, Val Loss: 6.58338
Epoch 14, Val Loss: 7.11034
Epoch 15, Val Loss: 6.39352
Epoch 16, Val Loss: 6.43709
Epoch 17, Val Loss: 6.40186
Epoch 18, Val Loss: 6.34260
Epoch 19, Val Loss: 6.64413
Epoch 20, Val Loss: 6.26790
Epoch 21, Val Loss: 6.25133
Epoch 22, Val Loss: 6.27126
Epoch 23, Val Loss: 6.66305
Epoch 24, Val Loss: 6.54001
Epoch 25, Val Loss: 6.69638
Epoch 26, Val Loss: 6.58459
Epoch 27, Val Loss: 6.44986
Epoch 28, Val Loss: 6.34007
Epoch 29, Val Loss: 6.32063
Epoch 30, Val Loss: 6.82993
Epoch 31, Val Loss: 6.10349
Epoch 32, Val Loss: 6.45193
Epoch 33, Val Loss: 6.25663
Epoch 34, Val Loss: 6.13707
Epoch 35, Val Loss: 6.40499
Epoch 36, Val Loss: 6.38790
Epoch 37, Val Loss: 6.34584
Epoch 38, Val Loss: 6.06557
Epoch 39, Val Loss: 6.41602
Epoch 40, Val Loss: 6.12021
Epoch 41, Val Loss: 6.80847
Epoch 42, Val Loss: 6.08621
Epoch 43, Val Loss: 6.37964
Epoch 44, Val Loss: 5.89413
Epoch 45, Val Loss: 5.91168
Epoch 46, Val Loss: 6.03905
Epoch 47, Val Loss: 6.27035
Epoch 48, Val Loss: 5.95546
Epoch 49, Val Loss: 5.90288
Epoch 50, Val Loss: 5.98545
Epoch 51, Val Loss: 5.78287
Epoch 52, Val Loss: 6.10055
Epoch 53, Val Loss: 5.73959
Epoch 54, Val Loss: 5.77426
Epoch 55, Val Loss: 5.88002
Epoch 56, Val Loss: 5.66456
Epoch 57, Val Loss: 5.78968
Epoch 58, Val Loss: 6.09822
Epoch 59, Val Loss: 5.52959
Epoch 60, Val Loss: 5.62713
Epoch 61, Val Loss: 5.59048
Epoch 62, Val Loss: 5.48849
Epoch 63, Val Loss: 5.65362
Epoch 64, Val Loss: 5.69624
Epoch 65, Val Loss: 5.50186
Epoch 66, Val Loss: 5.48425
Epoch 67, Val Loss: 5.60956
Epoch 68, Val Loss: 5.55106
Epoch 69, Val Loss: 5.77823
Epoch 70, Val Loss: 5.75012
Epoch 71, Val Loss: 5.63784
Epoch 72, Val Loss: 5.40546
Epoch 73, Val Loss: 5.40237
Epoch 74, Val Loss: 5.63018
Epoch 75, Val Loss: 5.39740
Epoch 76, Val Loss: 5.36005
Epoch 77, Val Loss: 5.50201
Epoch 78, Val Loss: 5.46091
Epoch 79, Val Loss: 5.34908
Epoch 80, Val Loss: 5.38501
Epoch 81, Val Loss: 5.56263
Epoch 82, Val Loss: 5.47728
Epoch 83, Val Loss: 5.58521
Epoch 84, Val Loss: 5.48458
Epoch 85, Val Loss: 5.15637
Epoch 86, Val Loss: 5.46489
Epoch 87, Val Loss: 5.19734
Epoch 88, Val Loss: 5.21572
Epoch 89, Val Loss: 5.17387
Epoch 90, Val Loss: 5.29604
Epoch 91, Val Loss: 5.16862
Epoch 92, Val Loss: 5.12384
Epoch 93, Val Loss: 5.21668
Epoch 94, Val Loss: 5.10163
Epoch 95, Val Loss: 5.20562
Epoch 96, Val Loss: 5.29196
Epoch 97, Val Loss: 5.47255
Epoch 98, Val Loss: 5.15669
Epoch 99, Val Loss: 5.44773
Saved Losses
{'MSE - mean': 5.08791491617953, 'MSE - std': 0.4909907056990315, 'R2 - mean': 0.5006896077169828, 'R2 - std': 0.020125026168417902} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.54561
Epoch 1, Val Loss: 10.92619
Epoch 2, Val Loss: 6.45972
Epoch 3, Val Loss: 6.46501
Epoch 4, Val Loss: 6.03882
Epoch 5, Val Loss: 5.95157
Epoch 6, Val Loss: 5.92929
Epoch 7, Val Loss: 6.37614
Epoch 8, Val Loss: 5.73345
Epoch 9, Val Loss: 5.83962
Epoch 10, Val Loss: 5.49440
Epoch 11, Val Loss: 5.68749
Epoch 12, Val Loss: 5.74935
Epoch 13, Val Loss: 5.48656
Epoch 14, Val Loss: 5.78303
Epoch 15, Val Loss: 5.90973
Epoch 16, Val Loss: 5.88711
Epoch 17, Val Loss: 5.57585
Epoch 18, Val Loss: 5.92011
Epoch 19, Val Loss: 5.51881
Epoch 20, Val Loss: 5.62028
Epoch 21, Val Loss: 5.60313
Epoch 22, Val Loss: 5.29921
Epoch 23, Val Loss: 5.50092
Epoch 24, Val Loss: 5.44637
Epoch 25, Val Loss: 5.45721
Epoch 26, Val Loss: 5.36124
Epoch 27, Val Loss: 5.32561
Epoch 28, Val Loss: 5.39776
Epoch 29, Val Loss: 5.54912
Epoch 30, Val Loss: 5.67342
Epoch 31, Val Loss: 5.30526
Epoch 32, Val Loss: 5.39400
Epoch 33, Val Loss: 5.23676
Epoch 34, Val Loss: 5.44770
Epoch 35, Val Loss: 5.29931
Epoch 36, Val Loss: 5.65947
Epoch 37, Val Loss: 5.16758
Epoch 38, Val Loss: 5.37063
Epoch 39, Val Loss: 5.34447
Epoch 40, Val Loss: 5.35138
Epoch 41, Val Loss: 5.18257
Epoch 42, Val Loss: 5.28659
Epoch 43, Val Loss: 5.62143
Epoch 44, Val Loss: 5.21750
Epoch 45, Val Loss: 5.27438
Epoch 46, Val Loss: 5.34637
Epoch 47, Val Loss: 5.19875
Epoch 48, Val Loss: 5.52861
Epoch 49, Val Loss: 5.21377
Epoch 50, Val Loss: 5.06082
Epoch 51, Val Loss: 5.15899
Epoch 52, Val Loss: 5.03120
Epoch 53, Val Loss: 5.43406
Epoch 54, Val Loss: 5.39779
Epoch 55, Val Loss: 5.07905
Epoch 56, Val Loss: 5.78734
Epoch 57, Val Loss: 4.96082
Epoch 58, Val Loss: 5.05048
Epoch 59, Val Loss: 5.02765
Epoch 60, Val Loss: 4.95957
Epoch 61, Val Loss: 4.95360
Epoch 62, Val Loss: 5.27300
Epoch 63, Val Loss: 5.33519
Epoch 64, Val Loss: 4.97127
Epoch 65, Val Loss: 5.06235
Epoch 66, Val Loss: 5.13757
Epoch 67, Val Loss: 4.93227
Epoch 68, Val Loss: 4.99634
Epoch 69, Val Loss: 5.08123
Epoch 70, Val Loss: 5.49808
Epoch 71, Val Loss: 4.95029
Epoch 72, Val Loss: 4.93218
Epoch 73, Val Loss: 4.91986
Epoch 74, Val Loss: 4.99747
Epoch 75, Val Loss: 5.02440
Epoch 76, Val Loss: 5.00088
Epoch 77, Val Loss: 4.84100
Epoch 78, Val Loss: 4.93107
Epoch 79, Val Loss: 4.90027
Epoch 80, Val Loss: 5.11996
Epoch 81, Val Loss: 4.98224
Epoch 82, Val Loss: 4.81979
Epoch 83, Val Loss: 5.05560
Epoch 84, Val Loss: 4.84561
Epoch 85, Val Loss: 4.92554
Epoch 86, Val Loss: 4.75752
Epoch 87, Val Loss: 4.78395
Epoch 88, Val Loss: 5.05688
Epoch 89, Val Loss: 4.71089
Epoch 90, Val Loss: 4.81823
Epoch 91, Val Loss: 4.87353
Epoch 92, Val Loss: 4.76722
Epoch 93, Val Loss: 4.75891
Epoch 94, Val Loss: 4.75859
Epoch 95, Val Loss: 4.77110
Epoch 96, Val Loss: 4.75207
Epoch 97, Val Loss: 4.84663
Epoch 98, Val Loss: 4.75276
Epoch 99, Val Loss: 5.02271
Saved Losses
{'MSE - mean': 5.083753008369681, 'MSE - std': 0.4252715241372008, 'R2 - mean': 0.4899615866991548, 'R2 - std': 0.025476142046756307} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.30708
Epoch 1, Val Loss: 11.72118
Epoch 2, Val Loss: 8.76853
Epoch 3, Val Loss: 8.90031
Epoch 4, Val Loss: 7.90192
Epoch 5, Val Loss: 7.97208
Epoch 6, Val Loss: 8.18704
Epoch 7, Val Loss: 8.02535
Epoch 8, Val Loss: 8.01425
Epoch 9, Val Loss: 8.32990
Epoch 10, Val Loss: 8.53605
Epoch 11, Val Loss: 8.59702
Epoch 12, Val Loss: 8.18294
Epoch 13, Val Loss: 7.80033
Epoch 14, Val Loss: 8.16755
Epoch 15, Val Loss: 7.77329
Epoch 16, Val Loss: 7.76281
Epoch 17, Val Loss: 7.84839
Epoch 18, Val Loss: 7.80625
Epoch 19, Val Loss: 7.49326
Epoch 20, Val Loss: 7.56792
Epoch 21, Val Loss: 7.66383
Epoch 22, Val Loss: 7.57152
Epoch 23, Val Loss: 7.73135
Epoch 24, Val Loss: 8.34603
Epoch 25, Val Loss: 7.65470
Epoch 26, Val Loss: 7.47157
Epoch 27, Val Loss: 7.37200
Epoch 28, Val Loss: 7.95214
Epoch 29, Val Loss: 7.80975
Epoch 30, Val Loss: 7.36631
Epoch 31, Val Loss: 7.29716
Epoch 32, Val Loss: 7.71804
Epoch 33, Val Loss: 7.73953
Epoch 34, Val Loss: 7.53391
Epoch 35, Val Loss: 7.26705
Epoch 36, Val Loss: 7.62934
Epoch 37, Val Loss: 7.44156
Epoch 38, Val Loss: 7.27347
Epoch 39, Val Loss: 7.54996
Epoch 40, Val Loss: 7.58228
Epoch 41, Val Loss: 7.60396
Epoch 42, Val Loss: 7.77364
Epoch 43, Val Loss: 7.39248
Epoch 44, Val Loss: 7.63548
Epoch 45, Val Loss: 7.37299
Epoch 46, Val Loss: 7.31468
Epoch 47, Val Loss: 7.34459
Epoch 48, Val Loss: 7.71125
Epoch 49, Val Loss: 7.22854
Epoch 50, Val Loss: 7.20064
Epoch 51, Val Loss: 7.44730
Epoch 52, Val Loss: 7.05183
Epoch 53, Val Loss: 7.16257
Epoch 54, Val Loss: 6.98451
Epoch 55, Val Loss: 7.00537
Epoch 56, Val Loss: 7.32773
Epoch 57, Val Loss: 7.26515
Epoch 58, Val Loss: 6.99618
Epoch 59, Val Loss: 7.14678
Epoch 60, Val Loss: 6.97691
Epoch 61, Val Loss: 7.12127
Epoch 62, Val Loss: 7.06940
Epoch 63, Val Loss: 6.96988
Epoch 64, Val Loss: 7.45614
Epoch 65, Val Loss: 6.93782
Epoch 66, Val Loss: 6.91750
Epoch 67, Val Loss: 6.96005
Epoch 68, Val Loss: 6.77595
Epoch 69, Val Loss: 6.85840
Epoch 70, Val Loss: 6.98451
Epoch 71, Val Loss: 6.77995
Epoch 72, Val Loss: 7.19230
Epoch 73, Val Loss: 6.96617
Epoch 74, Val Loss: 6.81429
Epoch 75, Val Loss: 6.92440
Epoch 76, Val Loss: 7.10006
Epoch 77, Val Loss: 6.85613
Epoch 78, Val Loss: 6.96933
Epoch 79, Val Loss: 6.81641
Epoch 80, Val Loss: 6.88356
Epoch 81, Val Loss: 6.65646
Epoch 82, Val Loss: 6.77470
Epoch 83, Val Loss: 6.91963
Epoch 84, Val Loss: 6.90167
Epoch 85, Val Loss: 6.58024
Epoch 86, Val Loss: 6.81793
Epoch 87, Val Loss: 6.55837
Epoch 88, Val Loss: 6.65373
Epoch 89, Val Loss: 6.63818
Epoch 90, Val Loss: 6.77308
Epoch 91, Val Loss: 6.55883
Epoch 92, Val Loss: 6.44817
Epoch 93, Val Loss: 6.35278
Epoch 94, Val Loss: 6.57088
Epoch 95, Val Loss: 6.46753
Epoch 96, Val Loss: 6.62992
Epoch 97, Val Loss: 6.65929
Epoch 98, Val Loss: 6.40717
Epoch 99, Val Loss: 6.58872
Saved Losses
{'MSE - mean': 5.349329823187849, 'MSE - std': 0.6533061102342752, 'R2 - mean': 0.4859211960240214, 'R2 - std': 0.024176974130358502} 
 

Results After CV: {'MSE - mean': 5.349329823187849, 'MSE - std': 0.6533061102342752, 'R2 - mean': 0.4859211960240214, 'R2 - std': 0.024176974130358502}
Train time: 48.88070135220014
Inference time: 0.0512342890000582
Finished cross validation
Trial 9 finished with value: 5.349329823187849 and parameters: {'p_m': 0.6810422299582659, 'alpha': 9.599174184794848, 'K': 5, 'beta': 7.616667096548424}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.90145
Epoch 1, Val Loss: 11.58881
Epoch 2, Val Loss: 8.96766
Epoch 3, Val Loss: 7.52142
Epoch 4, Val Loss: 7.27069
Epoch 5, Val Loss: 8.32760
Epoch 6, Val Loss: 7.47545
Epoch 7, Val Loss: 7.18503
Epoch 8, Val Loss: 7.06309
Epoch 9, Val Loss: 7.68655
Epoch 10, Val Loss: 6.86621
Epoch 11, Val Loss: 6.88216
Epoch 12, Val Loss: 7.43788
Epoch 13, Val Loss: 7.37187
Epoch 14, Val Loss: 6.87572
Epoch 15, Val Loss: 6.75316
Epoch 16, Val Loss: 7.32599
Epoch 17, Val Loss: 6.66763
Epoch 18, Val Loss: 6.48596
Epoch 19, Val Loss: 7.45698
Epoch 20, Val Loss: 6.58080
Epoch 21, Val Loss: 6.59338
Epoch 22, Val Loss: 6.69714
Epoch 23, Val Loss: 6.37016
Epoch 24, Val Loss: 6.31599
Epoch 25, Val Loss: 6.59322
Epoch 26, Val Loss: 6.37678
Epoch 27, Val Loss: 6.39508
Epoch 28, Val Loss: 6.35185
Epoch 29, Val Loss: 6.22502
Epoch 30, Val Loss: 7.11428
Epoch 31, Val Loss: 6.59738
Epoch 32, Val Loss: 6.16993
Epoch 33, Val Loss: 6.49197
Epoch 34, Val Loss: 6.71507
Epoch 35, Val Loss: 6.21380
Epoch 36, Val Loss: 6.37430
Epoch 37, Val Loss: 6.97556
Epoch 38, Val Loss: 6.31784
Epoch 39, Val Loss: 6.13543
Epoch 40, Val Loss: 6.28519
Epoch 41, Val Loss: 6.28919
Epoch 42, Val Loss: 6.44500
Epoch 43, Val Loss: 6.31743
Epoch 44, Val Loss: 6.68170
Epoch 45, Val Loss: 6.27834
Epoch 46, Val Loss: 6.31970
Epoch 47, Val Loss: 6.00938
Epoch 48, Val Loss: 6.14595
Epoch 49, Val Loss: 6.32219
Epoch 50, Val Loss: 6.20768
Epoch 51, Val Loss: 6.08195
Epoch 52, Val Loss: 5.98947
Epoch 53, Val Loss: 6.15653
Epoch 54, Val Loss: 6.01881
Epoch 55, Val Loss: 6.07365
Epoch 56, Val Loss: 6.25278
Epoch 57, Val Loss: 6.00441
Epoch 58, Val Loss: 6.49849
Epoch 59, Val Loss: 6.28384
Epoch 60, Val Loss: 6.06183
Epoch 61, Val Loss: 6.07318
Epoch 62, Val Loss: 6.53916
Epoch 63, Val Loss: 6.22155
Epoch 64, Val Loss: 5.97426
Epoch 65, Val Loss: 6.30198
Epoch 66, Val Loss: 6.14745
Epoch 67, Val Loss: 5.85992
Epoch 68, Val Loss: 6.04623
Epoch 69, Val Loss: 5.78634
Epoch 70, Val Loss: 6.06985
Epoch 71, Val Loss: 5.83052
Epoch 72, Val Loss: 6.13783
Epoch 73, Val Loss: 5.76712
Epoch 74, Val Loss: 6.48557
Epoch 75, Val Loss: 5.80430
Epoch 76, Val Loss: 5.85358
Epoch 77, Val Loss: 5.94394
Epoch 78, Val Loss: 5.88319
Epoch 79, Val Loss: 5.98295
Epoch 80, Val Loss: 6.09530
Epoch 81, Val Loss: 5.80346
Epoch 82, Val Loss: 5.62760
Epoch 83, Val Loss: 6.51928
Epoch 84, Val Loss: 6.01437
Epoch 85, Val Loss: 5.47645
Epoch 86, Val Loss: 6.06104
Epoch 87, Val Loss: 6.79658
Epoch 88, Val Loss: 5.94995
Epoch 89, Val Loss: 5.84180
Epoch 90, Val Loss: 6.39737
Epoch 91, Val Loss: 5.70520
Epoch 92, Val Loss: 6.12270
Epoch 93, Val Loss: 6.04341
Epoch 94, Val Loss: 5.52959
Epoch 95, Val Loss: 6.55643
Epoch 96, Val Loss: 5.70758
Epoch 97, Val Loss: 5.66743
Epoch 98, Val Loss: 5.53287
Epoch 99, Val Loss: 5.66623
Saved Losses
{'MSE - mean': 5.697819564325537, 'MSE - std': 0.0, 'R2 - mean': 0.4803776832841776, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.71877
Epoch 1, Val Loss: 7.43681
Epoch 2, Val Loss: 6.17583
Epoch 3, Val Loss: 5.68701
Epoch 4, Val Loss: 6.20054
Epoch 5, Val Loss: 5.36363
Epoch 6, Val Loss: 5.32922
Epoch 7, Val Loss: 5.18773
Epoch 8, Val Loss: 5.50747
Epoch 9, Val Loss: 5.32596
Epoch 10, Val Loss: 5.68024
Epoch 11, Val Loss: 5.45851
Epoch 12, Val Loss: 5.27794
Epoch 13, Val Loss: 5.64337
Epoch 14, Val Loss: 5.33626
Epoch 15, Val Loss: 5.68608
Epoch 16, Val Loss: 5.73451
Epoch 17, Val Loss: 5.41961
Epoch 18, Val Loss: 5.35636
Epoch 19, Val Loss: 5.43868
Epoch 20, Val Loss: 5.38751
Epoch 21, Val Loss: 5.11508
Epoch 22, Val Loss: 5.02278
Epoch 23, Val Loss: 5.14998
Epoch 24, Val Loss: 5.14848
Epoch 25, Val Loss: 5.18019
Epoch 26, Val Loss: 5.39602
Epoch 27, Val Loss: 5.35340
Epoch 28, Val Loss: 5.19785
Epoch 29, Val Loss: 5.34189
Epoch 30, Val Loss: 5.10436
Epoch 31, Val Loss: 5.47074
Epoch 32, Val Loss: 4.94738
Epoch 33, Val Loss: 5.19004
Epoch 34, Val Loss: 5.63577
Epoch 35, Val Loss: 4.99401
Epoch 36, Val Loss: 5.16515
Epoch 37, Val Loss: 4.94376
Epoch 38, Val Loss: 4.90207
Epoch 39, Val Loss: 4.84508
Epoch 40, Val Loss: 5.35481
Epoch 41, Val Loss: 4.89614
Epoch 42, Val Loss: 5.27090
Epoch 43, Val Loss: 5.59677
Epoch 44, Val Loss: 4.83234
Epoch 45, Val Loss: 5.10176
Epoch 46, Val Loss: 4.88895
Epoch 47, Val Loss: 4.92363
Epoch 48, Val Loss: 4.81940
Epoch 49, Val Loss: 4.85852
Epoch 50, Val Loss: 4.86315
Epoch 51, Val Loss: 4.93251
Epoch 52, Val Loss: 4.89700
Epoch 53, Val Loss: 5.94572
Epoch 54, Val Loss: 5.25830
Epoch 55, Val Loss: 4.90323
Epoch 56, Val Loss: 5.00380
Epoch 57, Val Loss: 4.90801
Epoch 58, Val Loss: 4.63466
Epoch 59, Val Loss: 4.92353
Epoch 60, Val Loss: 4.87962
Epoch 61, Val Loss: 5.01665
Epoch 62, Val Loss: 5.03660
Epoch 63, Val Loss: 4.69295
Epoch 64, Val Loss: 4.64862
Epoch 65, Val Loss: 4.79584
Epoch 66, Val Loss: 4.96126
Epoch 67, Val Loss: 5.03208
Epoch 68, Val Loss: 4.86001
Epoch 69, Val Loss: 5.10784
Epoch 70, Val Loss: 4.74827
Epoch 71, Val Loss: 4.81189
Epoch 72, Val Loss: 4.96079
Epoch 73, Val Loss: 4.88828
Epoch 74, Val Loss: 4.62606
Epoch 75, Val Loss: 4.67228
Epoch 76, Val Loss: 4.81028
Epoch 77, Val Loss: 4.58836
Epoch 78, Val Loss: 4.99574
Epoch 79, Val Loss: 4.80439
Epoch 80, Val Loss: 5.01296
Epoch 81, Val Loss: 5.11645
Epoch 82, Val Loss: 5.03414
Epoch 83, Val Loss: 5.19776
Epoch 84, Val Loss: 4.53780
Epoch 85, Val Loss: 5.07821
Epoch 86, Val Loss: 4.82488
Epoch 87, Val Loss: 4.88719
Epoch 88, Val Loss: 4.76370
Epoch 89, Val Loss: 4.54694
Epoch 90, Val Loss: 4.71730
Epoch 91, Val Loss: 4.53282
Epoch 92, Val Loss: 5.29379
Epoch 93, Val Loss: 4.62564
Epoch 94, Val Loss: 4.62534
Epoch 95, Val Loss: 4.52007
Epoch 96, Val Loss: 4.55333
Epoch 97, Val Loss: 4.85860
Epoch 98, Val Loss: 4.65106
Epoch 99, Val Loss: 4.71196
Saved Losses
{'MSE - mean': 5.267849152434967, 'MSE - std': 0.4299704118905705, 'R2 - mean': 0.4823382167658014, 'R2 - std': 0.001960533481623783} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.13615
Epoch 1, Val Loss: 8.75552
Epoch 2, Val Loss: 7.30387
Epoch 3, Val Loss: 6.67374
Epoch 4, Val Loss: 6.42245
Epoch 5, Val Loss: 6.54025
Epoch 6, Val Loss: 6.61736
Epoch 7, Val Loss: 6.64664
Epoch 8, Val Loss: 6.19868
Epoch 9, Val Loss: 6.36779
Epoch 10, Val Loss: 6.29563
Epoch 11, Val Loss: 6.21061
Epoch 12, Val Loss: 6.58500
Epoch 13, Val Loss: 7.12710
Epoch 14, Val Loss: 6.13623
Epoch 15, Val Loss: 6.18354
Epoch 16, Val Loss: 6.19022
Epoch 17, Val Loss: 6.60998
Epoch 18, Val Loss: 6.90778
Epoch 19, Val Loss: 6.50614
Epoch 20, Val Loss: 6.47141
Epoch 21, Val Loss: 5.98142
Epoch 22, Val Loss: 6.06847
Epoch 23, Val Loss: 6.40934
Epoch 24, Val Loss: 6.19162
Epoch 25, Val Loss: 6.57721
Epoch 26, Val Loss: 5.96871
Epoch 27, Val Loss: 6.20522
Epoch 28, Val Loss: 6.08173
Epoch 29, Val Loss: 6.39917
Epoch 30, Val Loss: 6.62499
Epoch 31, Val Loss: 5.85928
Epoch 32, Val Loss: 6.19584
Epoch 33, Val Loss: 6.94965
Epoch 34, Val Loss: 5.90752
Epoch 35, Val Loss: 5.95869
Epoch 36, Val Loss: 6.10929
Epoch 37, Val Loss: 5.74664
Epoch 38, Val Loss: 6.12081
Epoch 39, Val Loss: 6.22745
Epoch 40, Val Loss: 6.05739
Epoch 41, Val Loss: 5.81721
Epoch 42, Val Loss: 5.96289
Epoch 43, Val Loss: 6.01153
Epoch 44, Val Loss: 5.86648
Epoch 45, Val Loss: 5.86509
Epoch 46, Val Loss: 6.61076
Epoch 47, Val Loss: 6.52506
Epoch 48, Val Loss: 6.39936
Epoch 49, Val Loss: 5.72399
Epoch 50, Val Loss: 5.81326
Epoch 51, Val Loss: 6.00500
Epoch 52, Val Loss: 5.98343
Epoch 53, Val Loss: 5.77106
Epoch 54, Val Loss: 5.61062
Epoch 55, Val Loss: 6.24994
Epoch 56, Val Loss: 5.67821
Epoch 57, Val Loss: 5.85988
Epoch 58, Val Loss: 5.63965
Epoch 59, Val Loss: 5.64072
Epoch 60, Val Loss: 5.89853
Epoch 61, Val Loss: 6.25288
Epoch 62, Val Loss: 5.63946
Epoch 63, Val Loss: 5.60297
Epoch 64, Val Loss: 5.86966
Epoch 65, Val Loss: 5.57695
Epoch 66, Val Loss: 5.74614
Epoch 67, Val Loss: 5.56624
Epoch 68, Val Loss: 5.85786
Epoch 69, Val Loss: 5.85807
Epoch 70, Val Loss: 5.82616
Epoch 71, Val Loss: 6.15378
Epoch 72, Val Loss: 5.61513
Epoch 73, Val Loss: 5.91464
Epoch 74, Val Loss: 5.56826
Epoch 75, Val Loss: 5.85377
Epoch 76, Val Loss: 5.59399
Epoch 77, Val Loss: 5.40781
Epoch 78, Val Loss: 5.84779
Epoch 79, Val Loss: 5.70810
Epoch 80, Val Loss: 5.66592
Epoch 81, Val Loss: 5.84548
Epoch 82, Val Loss: 5.72598
Epoch 83, Val Loss: 5.87385
Epoch 84, Val Loss: 5.55630
Epoch 85, Val Loss: 5.61632
Epoch 86, Val Loss: 5.44126
Epoch 87, Val Loss: 5.89613
Epoch 88, Val Loss: 5.56271
Epoch 89, Val Loss: 5.41328
Epoch 90, Val Loss: 5.71860
Epoch 91, Val Loss: 5.95369
Epoch 92, Val Loss: 5.58833
Epoch 93, Val Loss: 5.46736
Epoch 94, Val Loss: 5.62450
Epoch 95, Val Loss: 5.50556
Epoch 96, Val Loss: 5.53606
Epoch 97, Val Loss: 5.45155
Epoch 98, Val Loss: 5.31384
Epoch 99, Val Loss: 5.61537
Saved Losses
{'MSE - mean': 5.336086495238621, 'MSE - std': 0.36409116070938113, 'R2 - mean': 0.4753945211087007, 'R2 - std': 0.009949486407779632} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.64638
Epoch 1, Val Loss: 7.39646
Epoch 2, Val Loss: 5.98207
Epoch 3, Val Loss: 5.76891
Epoch 4, Val Loss: 5.63684
Epoch 5, Val Loss: 5.59332
Epoch 6, Val Loss: 5.54893
Epoch 7, Val Loss: 5.47928
Epoch 8, Val Loss: 6.06525
Epoch 9, Val Loss: 5.78187
Epoch 10, Val Loss: 6.06837
Epoch 11, Val Loss: 5.50084
Epoch 12, Val Loss: 5.32040
Epoch 13, Val Loss: 5.47687
Epoch 14, Val Loss: 5.51628
Epoch 15, Val Loss: 5.65343
Epoch 16, Val Loss: 5.49201
Epoch 17, Val Loss: 5.48282
Epoch 18, Val Loss: 5.46939
Epoch 19, Val Loss: 5.71939
Epoch 20, Val Loss: 5.35730
Epoch 21, Val Loss: 5.38430
Epoch 22, Val Loss: 5.24779
Epoch 23, Val Loss: 5.29380
Epoch 24, Val Loss: 5.21133
Epoch 25, Val Loss: 5.63914
Epoch 26, Val Loss: 5.46020
Epoch 27, Val Loss: 5.28352
Epoch 28, Val Loss: 5.28400
Epoch 29, Val Loss: 5.33671
Epoch 30, Val Loss: 5.25038
Epoch 31, Val Loss: 5.43543
Epoch 32, Val Loss: 5.20019
Epoch 33, Val Loss: 5.21356
Epoch 34, Val Loss: 5.14938
Epoch 35, Val Loss: 5.60253
Epoch 36, Val Loss: 5.39881
Epoch 37, Val Loss: 5.11271
Epoch 38, Val Loss: 5.16141
Epoch 39, Val Loss: 5.15434
Epoch 40, Val Loss: 5.09931
Epoch 41, Val Loss: 5.41013
Epoch 42, Val Loss: 5.39191
Epoch 43, Val Loss: 5.09265
Epoch 44, Val Loss: 5.38966
Epoch 45, Val Loss: 5.23899
Epoch 46, Val Loss: 5.12903
Epoch 47, Val Loss: 5.38848
Epoch 48, Val Loss: 5.32701
Epoch 49, Val Loss: 4.98634
Epoch 50, Val Loss: 4.95228
Epoch 51, Val Loss: 5.06754
Epoch 52, Val Loss: 4.98003
Epoch 53, Val Loss: 4.97925
Epoch 54, Val Loss: 5.27481
Epoch 55, Val Loss: 4.88313
Epoch 56, Val Loss: 4.92966
Epoch 57, Val Loss: 5.42588
Epoch 58, Val Loss: 4.94385
Epoch 59, Val Loss: 5.22227
Epoch 60, Val Loss: 4.98452
Epoch 61, Val Loss: 5.12570
Epoch 62, Val Loss: 5.07272
Epoch 63, Val Loss: 5.17917
Epoch 64, Val Loss: 5.04293
Epoch 65, Val Loss: 5.10523
Epoch 66, Val Loss: 4.95079
Epoch 67, Val Loss: 4.89977
Epoch 68, Val Loss: 5.09934
Epoch 69, Val Loss: 4.82231
Epoch 70, Val Loss: 4.86457
Epoch 71, Val Loss: 4.90479
Epoch 72, Val Loss: 5.10148
Epoch 73, Val Loss: 4.97304
Epoch 74, Val Loss: 4.66560
Epoch 75, Val Loss: 5.03828
Epoch 76, Val Loss: 5.07154
Epoch 77, Val Loss: 5.20802
Epoch 78, Val Loss: 4.84452
Epoch 79, Val Loss: 4.80273
Epoch 80, Val Loss: 4.85334
Epoch 81, Val Loss: 4.69539
Epoch 82, Val Loss: 4.77549
Epoch 83, Val Loss: 4.68962
Epoch 84, Val Loss: 4.79742
Epoch 85, Val Loss: 4.95371
Epoch 86, Val Loss: 4.86606
Epoch 87, Val Loss: 4.82238
Epoch 88, Val Loss: 4.76905
Epoch 89, Val Loss: 5.02043
Epoch 90, Val Loss: 5.28820
Epoch 91, Val Loss: 4.99530
Epoch 92, Val Loss: 4.80978
Epoch 93, Val Loss: 4.91387
Epoch 94, Val Loss: 4.60291
Epoch 95, Val Loss: 4.60440
Epoch 96, Val Loss: 5.10862
Epoch 97, Val Loss: 4.67933
Epoch 98, Val Loss: 4.95110
Epoch 99, Val Loss: 4.56199
Saved Losses
{'MSE - mean': 5.237512861592114, 'MSE - std': 0.3585694684867287, 'R2 - mean': 0.47445116361756645, 'R2 - std': 0.008770061567753137} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.11597
Epoch 1, Val Loss: 11.37437
Epoch 2, Val Loss: 8.47766
Epoch 3, Val Loss: 7.84673
Epoch 4, Val Loss: 7.97007
Epoch 5, Val Loss: 8.29221
Epoch 6, Val Loss: 8.14676
Epoch 7, Val Loss: 8.18728
Epoch 8, Val Loss: 7.82282
Epoch 9, Val Loss: 8.25159
Epoch 10, Val Loss: 8.29210
Epoch 11, Val Loss: 7.71328
Epoch 12, Val Loss: 8.06849
Epoch 13, Val Loss: 8.25227
Epoch 14, Val Loss: 7.61997
Epoch 15, Val Loss: 8.55154
Epoch 16, Val Loss: 7.95485
Epoch 17, Val Loss: 8.26374
Epoch 18, Val Loss: 8.01143
Epoch 19, Val Loss: 7.48068
Epoch 20, Val Loss: 8.27663
Epoch 21, Val Loss: 7.81622
Epoch 22, Val Loss: 7.64641
Epoch 23, Val Loss: 8.05686
Epoch 24, Val Loss: 8.60429
Epoch 25, Val Loss: 7.67581
Epoch 26, Val Loss: 7.59395
Epoch 27, Val Loss: 7.96660
Epoch 28, Val Loss: 7.32011
Epoch 29, Val Loss: 7.89939
Epoch 30, Val Loss: 7.65016
Epoch 31, Val Loss: 7.73934
Epoch 32, Val Loss: 7.73319
Epoch 33, Val Loss: 7.71390
Epoch 34, Val Loss: 7.89002
Epoch 35, Val Loss: 8.03966
Epoch 36, Val Loss: 7.54770
Epoch 37, Val Loss: 7.33861
Epoch 38, Val Loss: 7.56542
Epoch 39, Val Loss: 7.54608
Epoch 40, Val Loss: 7.39476
Epoch 41, Val Loss: 7.43194
Epoch 42, Val Loss: 7.81732
Epoch 43, Val Loss: 8.09316
Epoch 44, Val Loss: 7.22263
Epoch 45, Val Loss: 7.53693
Epoch 46, Val Loss: 7.55525
Epoch 47, Val Loss: 7.57150
Epoch 48, Val Loss: 7.12471
Epoch 49, Val Loss: 7.72117
Epoch 50, Val Loss: 7.28593
Epoch 51, Val Loss: 7.59266
Epoch 52, Val Loss: 7.29793
Epoch 53, Val Loss: 7.25681
Epoch 54, Val Loss: 7.31115
Epoch 55, Val Loss: 7.24962
Epoch 56, Val Loss: 7.30098
Epoch 57, Val Loss: 7.77129
Epoch 58, Val Loss: 7.24212
Epoch 59, Val Loss: 7.39147
Epoch 60, Val Loss: 7.22798
Epoch 61, Val Loss: 7.36373
Epoch 62, Val Loss: 7.70269
Epoch 63, Val Loss: 7.05479
Epoch 64, Val Loss: 8.09522
Epoch 65, Val Loss: 7.43930
Epoch 66, Val Loss: 6.90074
Epoch 67, Val Loss: 7.36632
Epoch 68, Val Loss: 7.19634
Epoch 69, Val Loss: 7.11100
Epoch 70, Val Loss: 7.17966
Epoch 71, Val Loss: 7.09196
Epoch 72, Val Loss: 7.81023
Epoch 73, Val Loss: 7.30525
Epoch 74, Val Loss: 6.88372
Epoch 75, Val Loss: 7.29136
Epoch 76, Val Loss: 7.52716
Epoch 77, Val Loss: 6.98078
Epoch 78, Val Loss: 7.22162
Epoch 79, Val Loss: 7.09107
Epoch 80, Val Loss: 7.36122
Epoch 81, Val Loss: 7.24827
Epoch 82, Val Loss: 7.34189
Epoch 83, Val Loss: 7.30638
Epoch 84, Val Loss: 7.19292
Epoch 85, Val Loss: 7.18959
Epoch 86, Val Loss: 6.95922
Epoch 87, Val Loss: 7.19206
Epoch 88, Val Loss: 6.88536
Epoch 89, Val Loss: 6.97071
Epoch 90, Val Loss: 6.76271
Epoch 91, Val Loss: 7.42016
Epoch 92, Val Loss: 6.97021
Epoch 93, Val Loss: 7.51596
Epoch 94, Val Loss: 7.08408
Epoch 95, Val Loss: 6.93690
Epoch 96, Val Loss: 6.81644
Epoch 97, Val Loss: 7.36743
Epoch 98, Val Loss: 6.96174
Epoch 99, Val Loss: 6.66705
Saved Losses
{'MSE - mean': 5.521143770829427, 'MSE - std': 0.6516468535056583, 'R2 - mean': 0.4694766113547709, 'R2 - std': 0.01266948557688441} 
 

Results After CV: {'MSE - mean': 5.521143770829427, 'MSE - std': 0.6516468535056583, 'R2 - mean': 0.4694766113547709, 'R2 - std': 0.01266948557688441}
Train time: 100.6331507506001
Inference time: 0.054641310600072754
Finished cross validation
Trial 10 finished with value: 5.521143770829427 and parameters: {'p_m': 0.35392444876692686, 'alpha': 3.54231377116261, 'K': 15, 'beta': 5.260919507227925}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.36165
Epoch 1, Val Loss: 15.61637
Epoch 2, Val Loss: 7.54632
Epoch 3, Val Loss: 7.07410
Epoch 4, Val Loss: 6.90073
Epoch 5, Val Loss: 6.81709
Epoch 6, Val Loss: 6.67704
Epoch 7, Val Loss: 6.57689
Epoch 8, Val Loss: 6.45032
Epoch 9, Val Loss: 6.47119
Epoch 10, Val Loss: 6.50635
Epoch 11, Val Loss: 6.35456
Epoch 12, Val Loss: 6.21771
Epoch 13, Val Loss: 6.80690
Epoch 14, Val Loss: 6.17307
Epoch 15, Val Loss: 6.17398
Epoch 16, Val Loss: 5.90836
Epoch 17, Val Loss: 6.03594
Epoch 18, Val Loss: 6.01031
Epoch 19, Val Loss: 5.96026
Epoch 20, Val Loss: 5.87226
Epoch 21, Val Loss: 5.75740
Epoch 22, Val Loss: 5.98546
Epoch 23, Val Loss: 5.90629
Epoch 24, Val Loss: 5.84376
Epoch 25, Val Loss: 5.79916
Epoch 26, Val Loss: 5.61406
Epoch 27, Val Loss: 5.64242
Epoch 28, Val Loss: 5.80936
Epoch 29, Val Loss: 5.63792
Epoch 30, Val Loss: 5.87876
Epoch 31, Val Loss: 5.57812
Epoch 32, Val Loss: 5.42940
Epoch 33, Val Loss: 5.29364
Epoch 34, Val Loss: 5.28691
Epoch 35, Val Loss: 5.83647
Epoch 36, Val Loss: 5.26378
Epoch 37, Val Loss: 5.17918
Epoch 38, Val Loss: 5.10147
Epoch 39, Val Loss: 5.28979
Epoch 40, Val Loss: 5.66492
Epoch 41, Val Loss: 5.62366
Epoch 42, Val Loss: 5.92104
Epoch 43, Val Loss: 5.28889
Epoch 44, Val Loss: 5.18476
Epoch 45, Val Loss: 5.17210
Epoch 46, Val Loss: 5.48961
Epoch 47, Val Loss: 5.33431
Epoch 48, Val Loss: 5.18694
Epoch 49, Val Loss: 5.31384
Epoch 50, Val Loss: 5.23823
Epoch 51, Val Loss: 5.00393
Epoch 52, Val Loss: 5.23173
Epoch 53, Val Loss: 4.95267
Epoch 54, Val Loss: 5.17626
Epoch 55, Val Loss: 4.98701
Epoch 56, Val Loss: 4.94365
Epoch 57, Val Loss: 4.84823
Epoch 58, Val Loss: 5.26145
Epoch 59, Val Loss: 5.29091
Epoch 60, Val Loss: 5.15682
Epoch 61, Val Loss: 5.20236
Epoch 62, Val Loss: 5.64265
Epoch 63, Val Loss: 4.95505
Epoch 64, Val Loss: 4.92438
Epoch 65, Val Loss: 5.15587
Epoch 66, Val Loss: 5.04117
Epoch 67, Val Loss: 4.98818
Epoch 68, Val Loss: 5.55948
Epoch 69, Val Loss: 4.83679
Epoch 70, Val Loss: 5.29478
Epoch 71, Val Loss: 5.00104
Epoch 72, Val Loss: 4.89643
Epoch 73, Val Loss: 4.94956
Epoch 74, Val Loss: 4.75447
Epoch 75, Val Loss: 4.87479
Epoch 76, Val Loss: 4.76910
Epoch 77, Val Loss: 4.96787
Epoch 78, Val Loss: 4.77186
Epoch 79, Val Loss: 4.97776
Epoch 80, Val Loss: 4.82690
Epoch 81, Val Loss: 4.78431
Epoch 82, Val Loss: 4.85708
Epoch 83, Val Loss: 4.81734
Epoch 84, Val Loss: 4.78619
Epoch 85, Val Loss: 4.73504
Epoch 86, Val Loss: 4.82941
Epoch 87, Val Loss: 4.67861
Epoch 88, Val Loss: 4.71965
Epoch 89, Val Loss: 4.68978
Epoch 90, Val Loss: 4.92464
Epoch 91, Val Loss: 5.20082
Epoch 92, Val Loss: 4.79803
Epoch 93, Val Loss: 4.81215
Epoch 94, Val Loss: 4.69045
Epoch 95, Val Loss: 4.79040
Epoch 96, Val Loss: 4.79618
Epoch 97, Val Loss: 4.65583
Epoch 98, Val Loss: 4.85639
Epoch 99, Val Loss: 5.13405
Saved Losses
{'MSE - mean': 4.768020204710211, 'MSE - std': 0.0, 'R2 - mean': 0.5651723125050127, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.60873
Epoch 1, Val Loss: 8.68556
Epoch 2, Val Loss: 5.64661
Epoch 3, Val Loss: 5.09464
Epoch 4, Val Loss: 5.00127
Epoch 5, Val Loss: 4.97949
Epoch 6, Val Loss: 4.92237
Epoch 7, Val Loss: 4.87459
Epoch 8, Val Loss: 4.77640
Epoch 9, Val Loss: 4.71379
Epoch 10, Val Loss: 4.64439
Epoch 11, Val Loss: 4.70918
Epoch 12, Val Loss: 4.49434
Epoch 13, Val Loss: 4.40270
Epoch 14, Val Loss: 4.38523
Epoch 15, Val Loss: 4.33107
Epoch 16, Val Loss: 4.33875
Epoch 17, Val Loss: 4.41893
Epoch 18, Val Loss: 4.64412
Epoch 19, Val Loss: 4.31921
Epoch 20, Val Loss: 4.22037
Epoch 21, Val Loss: 4.17241
Epoch 22, Val Loss: 4.17800
Epoch 23, Val Loss: 4.44464
Epoch 24, Val Loss: 4.18049
Epoch 25, Val Loss: 4.26847
Epoch 26, Val Loss: 4.13840
Epoch 27, Val Loss: 4.19013
Epoch 28, Val Loss: 4.22970
Epoch 29, Val Loss: 4.07088
Epoch 30, Val Loss: 4.68572
Epoch 31, Val Loss: 4.10962
Epoch 32, Val Loss: 4.04445
Epoch 33, Val Loss: 4.51163
Epoch 34, Val Loss: 4.21845
Epoch 35, Val Loss: 3.96513
Epoch 36, Val Loss: 4.04705
Epoch 37, Val Loss: 3.98267
Epoch 38, Val Loss: 3.95204
Epoch 39, Val Loss: 4.00537
Epoch 40, Val Loss: 4.67450
Epoch 41, Val Loss: 4.35490
Epoch 42, Val Loss: 3.90574
Epoch 43, Val Loss: 4.71379
Epoch 44, Val Loss: 4.33333
Epoch 45, Val Loss: 3.88739
Epoch 46, Val Loss: 3.95626
Epoch 47, Val Loss: 3.88939
Epoch 48, Val Loss: 3.96750
Epoch 49, Val Loss: 3.96395
Epoch 50, Val Loss: 3.99210
Epoch 51, Val Loss: 3.95200
Epoch 52, Val Loss: 3.92265
Epoch 53, Val Loss: 4.03177
Epoch 54, Val Loss: 3.92000
Epoch 55, Val Loss: 4.08597
Epoch 56, Val Loss: 3.92016
Epoch 57, Val Loss: 4.02466
Epoch 58, Val Loss: 3.97737
Epoch 59, Val Loss: 3.83253
Epoch 60, Val Loss: 4.08729
Epoch 61, Val Loss: 4.06117
Epoch 62, Val Loss: 3.86577
Epoch 63, Val Loss: 3.96183
Epoch 64, Val Loss: 3.86693
Epoch 65, Val Loss: 4.17617
Epoch 66, Val Loss: 3.82536
Epoch 67, Val Loss: 4.15652
Epoch 68, Val Loss: 4.26224
Epoch 69, Val Loss: 4.11480
Epoch 70, Val Loss: 3.77988
Epoch 71, Val Loss: 3.85032
Epoch 72, Val Loss: 4.04419
Epoch 73, Val Loss: 3.87508
Epoch 74, Val Loss: 3.86517
Epoch 75, Val Loss: 3.87367
Epoch 76, Val Loss: 4.35716
Epoch 77, Val Loss: 3.91149
Epoch 78, Val Loss: 3.82316
Epoch 79, Val Loss: 4.15713
Epoch 80, Val Loss: 3.86349
Epoch 81, Val Loss: 4.05623
Epoch 82, Val Loss: 4.09436
Epoch 83, Val Loss: 3.80548
Epoch 84, Val Loss: 3.97077
Epoch 85, Val Loss: 3.98800
Epoch 86, Val Loss: 3.80537
Epoch 87, Val Loss: 3.88972
Epoch 88, Val Loss: 3.80578
Epoch 89, Val Loss: 3.93676
Epoch 90, Val Loss: 3.90364
Epoch 91, Val Loss: 4.17492
Early stopping applies.
Saved Losses
{'MSE - mean': 4.38008122671782, 'MSE - std': 0.38793897799239097, 'R2 - mean': 0.5698118333241384, 'R2 - std': 0.004639520819125831} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.04669
Epoch 1, Val Loss: 13.76546
Epoch 2, Val Loss: 6.76582
Epoch 3, Val Loss: 5.94435
Epoch 4, Val Loss: 5.61252
Epoch 5, Val Loss: 5.98712
Epoch 6, Val Loss: 5.48969
Epoch 7, Val Loss: 5.35632
Epoch 8, Val Loss: 5.38685
Epoch 9, Val Loss: 5.23361
Epoch 10, Val Loss: 5.18825
Epoch 11, Val Loss: 5.19628
Epoch 12, Val Loss: 5.17713
Epoch 13, Val Loss: 5.10577
Epoch 14, Val Loss: 5.08075
Epoch 15, Val Loss: 5.15363
Epoch 16, Val Loss: 5.19320
Epoch 17, Val Loss: 5.11457
Epoch 18, Val Loss: 4.99108
Epoch 19, Val Loss: 5.09060
Epoch 20, Val Loss: 4.96781
Epoch 21, Val Loss: 5.18050
Epoch 22, Val Loss: 5.09116
Epoch 23, Val Loss: 4.95831
Epoch 24, Val Loss: 4.97009
Epoch 25, Val Loss: 4.94056
Epoch 26, Val Loss: 4.92801
Epoch 27, Val Loss: 4.90082
Epoch 28, Val Loss: 5.02214
Epoch 29, Val Loss: 5.04636
Epoch 30, Val Loss: 4.95109
Epoch 31, Val Loss: 4.84681
Epoch 32, Val Loss: 4.88675
Epoch 33, Val Loss: 4.97069
Epoch 34, Val Loss: 4.83008
Epoch 35, Val Loss: 4.80032
Epoch 36, Val Loss: 4.85339
Epoch 37, Val Loss: 4.82231
Epoch 38, Val Loss: 4.79815
Epoch 39, Val Loss: 5.01260
Epoch 40, Val Loss: 4.94632
Epoch 41, Val Loss: 4.80238
Epoch 42, Val Loss: 4.76968
Epoch 43, Val Loss: 4.83161
Epoch 44, Val Loss: 5.12998
Epoch 45, Val Loss: 5.01071
Epoch 46, Val Loss: 4.84242
Epoch 47, Val Loss: 4.87552
Epoch 48, Val Loss: 4.73282
Epoch 49, Val Loss: 4.91482
Epoch 50, Val Loss: 4.72452
Epoch 51, Val Loss: 4.77728
Epoch 52, Val Loss: 4.84323
Epoch 53, Val Loss: 4.89469
Epoch 54, Val Loss: 4.70569
Epoch 55, Val Loss: 4.77394
Epoch 56, Val Loss: 4.72367
Epoch 57, Val Loss: 4.81557
Epoch 58, Val Loss: 4.91736
Epoch 59, Val Loss: 5.38338
Epoch 60, Val Loss: 4.67857
Epoch 61, Val Loss: 4.93756
Epoch 62, Val Loss: 4.87668
Epoch 63, Val Loss: 5.33046
Epoch 64, Val Loss: 4.68365
Epoch 65, Val Loss: 4.85641
Epoch 66, Val Loss: 4.61007
Epoch 67, Val Loss: 4.66935
Epoch 68, Val Loss: 4.75532
Epoch 69, Val Loss: 4.86103
Epoch 70, Val Loss: 4.75412
Epoch 71, Val Loss: 4.65568
Epoch 72, Val Loss: 4.69055
Epoch 73, Val Loss: 4.65026
Epoch 74, Val Loss: 4.74374
Epoch 75, Val Loss: 4.59469
Epoch 76, Val Loss: 4.89221
Epoch 77, Val Loss: 4.69363
Epoch 78, Val Loss: 4.59297
Epoch 79, Val Loss: 4.59866
Epoch 80, Val Loss: 4.89480
Epoch 81, Val Loss: 4.58485
Epoch 82, Val Loss: 4.62508
Epoch 83, Val Loss: 4.87050
Epoch 84, Val Loss: 4.84241
Epoch 85, Val Loss: 4.76228
Epoch 86, Val Loss: 4.69079
Epoch 87, Val Loss: 4.57466
Epoch 88, Val Loss: 4.72228
Epoch 89, Val Loss: 4.60145
Epoch 90, Val Loss: 4.57105
Epoch 91, Val Loss: 4.86187
Epoch 92, Val Loss: 4.78081
Epoch 93, Val Loss: 4.71709
Epoch 94, Val Loss: 4.55220
Epoch 95, Val Loss: 4.76996
Epoch 96, Val Loss: 5.09481
Epoch 97, Val Loss: 4.62007
Epoch 98, Val Loss: 4.54438
Epoch 99, Val Loss: 4.62836
Saved Losses
{'MSE - mean': 4.477529707006249, 'MSE - std': 0.3454323566945765, 'R2 - mean': 0.5599543290530494, 'R2 - std': 0.014446137310591987} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.41255
Epoch 1, Val Loss: 8.52666
Epoch 2, Val Loss: 6.08650
Epoch 3, Val Loss: 5.72616
Epoch 4, Val Loss: 5.48618
Epoch 5, Val Loss: 5.55085
Epoch 6, Val Loss: 5.29681
Epoch 7, Val Loss: 5.14629
Epoch 8, Val Loss: 5.28146
Epoch 9, Val Loss: 4.77985
Epoch 10, Val Loss: 5.08899
Epoch 11, Val Loss: 4.68024
Epoch 12, Val Loss: 5.03944
Epoch 13, Val Loss: 4.81909
Epoch 14, Val Loss: 4.73890
Epoch 15, Val Loss: 4.67143
Epoch 16, Val Loss: 4.55436
Epoch 17, Val Loss: 4.43691
Epoch 18, Val Loss: 4.45548
Epoch 19, Val Loss: 4.51444
Epoch 20, Val Loss: 4.39516
Epoch 21, Val Loss: 4.38106
Epoch 22, Val Loss: 4.35968
Epoch 23, Val Loss: 4.39141
Epoch 24, Val Loss: 4.64923
Epoch 25, Val Loss: 4.36591
Epoch 26, Val Loss: 4.63011
Epoch 27, Val Loss: 4.31135
Epoch 28, Val Loss: 4.42694
Epoch 29, Val Loss: 4.42556
Epoch 30, Val Loss: 4.25927
Epoch 31, Val Loss: 4.25152
Epoch 32, Val Loss: 4.28116
Epoch 33, Val Loss: 4.37896
Epoch 34, Val Loss: 4.37253
Epoch 35, Val Loss: 4.44128
Epoch 36, Val Loss: 4.23309
Epoch 37, Val Loss: 4.47632
Epoch 38, Val Loss: 5.64018
Epoch 39, Val Loss: 4.37506
Epoch 40, Val Loss: 5.00234
Epoch 41, Val Loss: 4.28753
Epoch 42, Val Loss: 4.28438
Epoch 43, Val Loss: 4.23034
Epoch 44, Val Loss: 4.44886
Epoch 45, Val Loss: 4.15741
Epoch 46, Val Loss: 4.24439
Epoch 47, Val Loss: 4.20931
Epoch 48, Val Loss: 4.24756
Epoch 49, Val Loss: 4.32549
Epoch 50, Val Loss: 4.67499
Epoch 51, Val Loss: 4.12491
Epoch 52, Val Loss: 4.30446
Epoch 53, Val Loss: 4.42073
Epoch 54, Val Loss: 4.20876
Epoch 55, Val Loss: 4.14245
Epoch 56, Val Loss: 4.42578
Epoch 57, Val Loss: 4.33574
Epoch 58, Val Loss: 4.18289
Epoch 59, Val Loss: 4.17956
Epoch 60, Val Loss: 4.17758
Epoch 61, Val Loss: 4.34761
Epoch 62, Val Loss: 4.15612
Epoch 63, Val Loss: 4.35908
Epoch 64, Val Loss: 4.22567
Epoch 65, Val Loss: 4.40214
Epoch 66, Val Loss: 4.41041
Epoch 67, Val Loss: 4.14634
Epoch 68, Val Loss: 4.19118
Epoch 69, Val Loss: 4.25675
Epoch 70, Val Loss: 4.36426
Epoch 71, Val Loss: 4.19799
Epoch 72, Val Loss: 4.19947
Early stopping applies.
Saved Losses
{'MSE - mean': 4.478340037174851, 'MSE - std': 0.2991564886370063, 'R2 - mean': 0.5501941677102977, 'R2 - std': 0.021030939368154596} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.59431
Epoch 1, Val Loss: 18.77133
Epoch 2, Val Loss: 8.36548
Epoch 3, Val Loss: 7.89252
Epoch 4, Val Loss: 7.90586
Epoch 5, Val Loss: 7.67424
Epoch 6, Val Loss: 7.73850
Epoch 7, Val Loss: 7.57613
Epoch 8, Val Loss: 7.63630
Epoch 9, Val Loss: 7.18287
Epoch 10, Val Loss: 7.25020
Epoch 11, Val Loss: 7.01424
Epoch 12, Val Loss: 7.13375
Epoch 13, Val Loss: 6.98751
Epoch 14, Val Loss: 7.28850
Epoch 15, Val Loss: 7.03648
Epoch 16, Val Loss: 7.05514
Epoch 17, Val Loss: 6.95858
Epoch 18, Val Loss: 6.75311
Epoch 19, Val Loss: 6.98180
Epoch 20, Val Loss: 6.45647
Epoch 21, Val Loss: 6.54207
Epoch 22, Val Loss: 6.52458
Epoch 23, Val Loss: 6.40696
Epoch 24, Val Loss: 6.42392
Epoch 25, Val Loss: 6.32683
Epoch 26, Val Loss: 6.65345
Epoch 27, Val Loss: 6.26842
Epoch 28, Val Loss: 6.36584
Epoch 29, Val Loss: 6.19383
Epoch 30, Val Loss: 6.46763
Epoch 31, Val Loss: 6.57401
Epoch 32, Val Loss: 6.08313
Epoch 33, Val Loss: 6.27410
Epoch 34, Val Loss: 6.12991
Epoch 35, Val Loss: 6.78730
Epoch 36, Val Loss: 6.28004
Epoch 37, Val Loss: 6.09805
Epoch 38, Val Loss: 6.33812
Epoch 39, Val Loss: 6.38848
Epoch 40, Val Loss: 6.04531
Epoch 41, Val Loss: 6.55517
Epoch 42, Val Loss: 6.70510
Epoch 43, Val Loss: 6.29436
Epoch 44, Val Loss: 6.14081
Epoch 45, Val Loss: 6.38633
Epoch 46, Val Loss: 5.97272
Epoch 47, Val Loss: 6.00989
Epoch 48, Val Loss: 6.00421
Epoch 49, Val Loss: 6.18274
Epoch 50, Val Loss: 5.96699
Epoch 51, Val Loss: 5.90438
Epoch 52, Val Loss: 5.92667
Epoch 53, Val Loss: 6.41645
Epoch 54, Val Loss: 6.06782
Epoch 55, Val Loss: 6.02940
Epoch 56, Val Loss: 5.96835
Epoch 57, Val Loss: 6.48152
Epoch 58, Val Loss: 5.96243
Epoch 59, Val Loss: 5.95721
Epoch 60, Val Loss: 5.95545
Epoch 61, Val Loss: 5.90888
Epoch 62, Val Loss: 5.82887
Epoch 63, Val Loss: 5.87626
Epoch 64, Val Loss: 6.21861
Epoch 65, Val Loss: 6.51313
Epoch 66, Val Loss: 6.00892
Epoch 67, Val Loss: 6.21784
Epoch 68, Val Loss: 5.93737
Epoch 69, Val Loss: 6.23497
Epoch 70, Val Loss: 5.89061
Epoch 71, Val Loss: 5.88732
Epoch 72, Val Loss: 5.96019
Epoch 73, Val Loss: 5.90499
Epoch 74, Val Loss: 5.89010
Epoch 75, Val Loss: 6.04131
Epoch 76, Val Loss: 6.05272
Epoch 77, Val Loss: 5.96394
Epoch 78, Val Loss: 6.18439
Epoch 79, Val Loss: 6.01775
Epoch 80, Val Loss: 6.28203
Epoch 81, Val Loss: 5.94646
Epoch 82, Val Loss: 6.09634
Epoch 83, Val Loss: 6.02219
Early stopping applies.
Saved Losses
{'MSE - mean': 4.740651709632754, 'MSE - std': 0.5889187870882945, 'R2 - mean': 0.544390779472838, 'R2 - std': 0.022103338858741276} 
 

Results After CV: {'MSE - mean': 4.740651709632754, 'MSE - std': 0.5889187870882945, 'R2 - mean': 0.544390779472838, 'R2 - std': 0.022103338858741276}
Train time: 25.499647568600086
Inference time: 0.04804133399993589
Finished cross validation
Trial 11 finished with value: 4.740651709632754 and parameters: {'p_m': 0.3102789862681707, 'alpha': 7.469432086359561, 'K': 2, 'beta': 0.21158197373663873}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.26388
Epoch 1, Val Loss: 12.08888
Epoch 2, Val Loss: 6.93102
Epoch 3, Val Loss: 6.80717
Epoch 4, Val Loss: 6.69337
Epoch 5, Val Loss: 6.52036
Epoch 6, Val Loss: 6.30642
Epoch 7, Val Loss: 6.55063
Epoch 8, Val Loss: 6.29144
Epoch 9, Val Loss: 6.35924
Epoch 10, Val Loss: 6.03643
Epoch 11, Val Loss: 6.13574
Epoch 12, Val Loss: 6.46054
Epoch 13, Val Loss: 5.98900
Epoch 14, Val Loss: 6.02338
Epoch 15, Val Loss: 6.09252
Epoch 16, Val Loss: 5.88593
Epoch 17, Val Loss: 5.81537
Epoch 18, Val Loss: 5.82082
Epoch 19, Val Loss: 5.92018
Epoch 20, Val Loss: 5.87414
Epoch 21, Val Loss: 5.83427
Epoch 22, Val Loss: 5.74156
Epoch 23, Val Loss: 5.73401
Epoch 24, Val Loss: 6.13419
Epoch 25, Val Loss: 5.82492
Epoch 26, Val Loss: 5.74663
Epoch 27, Val Loss: 5.74464
Epoch 28, Val Loss: 5.73248
Epoch 29, Val Loss: 5.75721
Epoch 30, Val Loss: 5.66941
Epoch 31, Val Loss: 5.66935
Epoch 32, Val Loss: 5.70691
Epoch 33, Val Loss: 5.82547
Epoch 34, Val Loss: 5.97431
Epoch 35, Val Loss: 5.63740
Epoch 36, Val Loss: 5.64320
Epoch 37, Val Loss: 5.75614
Epoch 38, Val Loss: 5.60331
Epoch 39, Val Loss: 5.80845
Epoch 40, Val Loss: 5.77682
Epoch 41, Val Loss: 5.74038
Epoch 42, Val Loss: 5.68048
Epoch 43, Val Loss: 5.75240
Epoch 44, Val Loss: 5.58302
Epoch 45, Val Loss: 5.61233
Epoch 46, Val Loss: 5.66145
Epoch 47, Val Loss: 5.65076
Epoch 48, Val Loss: 5.84429
Epoch 49, Val Loss: 5.69519
Epoch 50, Val Loss: 5.75849
Epoch 51, Val Loss: 5.70349
Epoch 52, Val Loss: 5.59760
Epoch 53, Val Loss: 5.54824
Epoch 54, Val Loss: 5.57029
Epoch 55, Val Loss: 5.67506
Epoch 56, Val Loss: 5.77088
Epoch 57, Val Loss: 5.61924
Epoch 58, Val Loss: 5.72948
Epoch 59, Val Loss: 5.97527
Epoch 60, Val Loss: 5.73700
Epoch 61, Val Loss: 5.83804
Epoch 62, Val Loss: 5.61410
Epoch 63, Val Loss: 5.54351
Epoch 64, Val Loss: 5.61235
Epoch 65, Val Loss: 5.51210
Epoch 66, Val Loss: 5.77844
Epoch 67, Val Loss: 5.50911
Epoch 68, Val Loss: 5.60216
Epoch 69, Val Loss: 5.48816
Epoch 70, Val Loss: 5.56326
Epoch 71, Val Loss: 5.90727
Epoch 72, Val Loss: 5.63987
Epoch 73, Val Loss: 5.53801
Epoch 74, Val Loss: 5.43068
Epoch 75, Val Loss: 6.08771
Epoch 76, Val Loss: 5.65076
Epoch 77, Val Loss: 5.68075
Epoch 78, Val Loss: 5.47922
Epoch 79, Val Loss: 5.47098
Epoch 80, Val Loss: 5.45661
Epoch 81, Val Loss: 5.47721
Epoch 82, Val Loss: 5.53474
Epoch 83, Val Loss: 5.50929
Epoch 84, Val Loss: 5.41793
Epoch 85, Val Loss: 5.52276
Epoch 86, Val Loss: 5.48072
Epoch 87, Val Loss: 5.73173
Epoch 88, Val Loss: 6.44954
Epoch 89, Val Loss: 5.54562
Epoch 90, Val Loss: 5.76145
Epoch 91, Val Loss: 5.62912
Epoch 92, Val Loss: 5.59262
Epoch 93, Val Loss: 5.44816
Epoch 94, Val Loss: 5.48244
Epoch 95, Val Loss: 5.48078
Epoch 96, Val Loss: 5.55312
Epoch 97, Val Loss: 5.56702
Epoch 98, Val Loss: 5.86963
Epoch 99, Val Loss: 5.46702
Saved Losses
{'MSE - mean': 5.630656855329834, 'MSE - std': 0.0, 'R2 - mean': 0.4865027004159528, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.98230
Epoch 1, Val Loss: 9.46169
Epoch 2, Val Loss: 5.85961
Epoch 3, Val Loss: 6.32236
Epoch 4, Val Loss: 5.46160
Epoch 5, Val Loss: 5.38029
Epoch 6, Val Loss: 5.52234
Epoch 7, Val Loss: 5.23382
Epoch 8, Val Loss: 5.22115
Epoch 9, Val Loss: 5.17733
Epoch 10, Val Loss: 5.25003
Epoch 11, Val Loss: 5.22380
Epoch 12, Val Loss: 5.19343
Epoch 13, Val Loss: 5.27262
Epoch 14, Val Loss: 5.57216
Epoch 15, Val Loss: 5.08585
Epoch 16, Val Loss: 5.52239
Epoch 17, Val Loss: 5.38233
Epoch 18, Val Loss: 5.18174
Epoch 19, Val Loss: 5.20454
Epoch 20, Val Loss: 5.22239
Epoch 21, Val Loss: 5.04660
Epoch 22, Val Loss: 5.07987
Epoch 23, Val Loss: 4.95473
Epoch 24, Val Loss: 5.07663
Epoch 25, Val Loss: 4.97425
Epoch 26, Val Loss: 5.15825
Epoch 27, Val Loss: 4.95583
Epoch 28, Val Loss: 4.92667
Epoch 29, Val Loss: 4.93683
Epoch 30, Val Loss: 4.90241
Epoch 31, Val Loss: 4.88208
Epoch 32, Val Loss: 4.96351
Epoch 33, Val Loss: 5.20162
Epoch 34, Val Loss: 4.84320
Epoch 35, Val Loss: 4.76565
Epoch 36, Val Loss: 5.11764
Epoch 37, Val Loss: 4.72481
Epoch 38, Val Loss: 5.05883
Epoch 39, Val Loss: 4.81714
Epoch 40, Val Loss: 5.13365
Epoch 41, Val Loss: 4.88821
Epoch 42, Val Loss: 4.76217
Epoch 43, Val Loss: 5.11592
Epoch 44, Val Loss: 4.87969
Epoch 45, Val Loss: 4.69492
Epoch 46, Val Loss: 4.71813
Epoch 47, Val Loss: 4.60553
Epoch 48, Val Loss: 4.64567
Epoch 49, Val Loss: 4.57918
Epoch 50, Val Loss: 4.75802
Epoch 51, Val Loss: 4.63790
Epoch 52, Val Loss: 4.57854
Epoch 53, Val Loss: 4.73253
Epoch 54, Val Loss: 4.53649
Epoch 55, Val Loss: 4.55395
Epoch 56, Val Loss: 5.29815
Epoch 57, Val Loss: 4.84881
Epoch 58, Val Loss: 4.82475
Epoch 59, Val Loss: 4.67122
Epoch 60, Val Loss: 4.63751
Epoch 61, Val Loss: 4.91858
Epoch 62, Val Loss: 4.49590
Epoch 63, Val Loss: 4.84586
Epoch 64, Val Loss: 4.80984
Epoch 65, Val Loss: 4.57702
Epoch 66, Val Loss: 4.52083
Epoch 67, Val Loss: 4.52222
Epoch 68, Val Loss: 4.73240
Epoch 69, Val Loss: 4.70335
Epoch 70, Val Loss: 4.56939
Epoch 71, Val Loss: 4.41516
Epoch 72, Val Loss: 4.54534
Epoch 73, Val Loss: 4.66714
Epoch 74, Val Loss: 4.54554
Epoch 75, Val Loss: 4.48413
Epoch 76, Val Loss: 4.52840
Epoch 77, Val Loss: 4.43402
Epoch 78, Val Loss: 4.54107
Epoch 79, Val Loss: 4.52421
Epoch 80, Val Loss: 4.44578
Epoch 81, Val Loss: 4.96048
Epoch 82, Val Loss: 4.37879
Epoch 83, Val Loss: 4.56559
Epoch 84, Val Loss: 4.73408
Epoch 85, Val Loss: 4.56572
Epoch 86, Val Loss: 4.36928
Epoch 87, Val Loss: 4.43863
Epoch 88, Val Loss: 4.31691
Epoch 89, Val Loss: 4.41176
Epoch 90, Val Loss: 4.39700
Epoch 91, Val Loss: 4.66457
Epoch 92, Val Loss: 4.43954
Epoch 93, Val Loss: 4.58897
Epoch 94, Val Loss: 4.37019
Epoch 95, Val Loss: 4.49246
Epoch 96, Val Loss: 4.38041
Epoch 97, Val Loss: 4.35926
Epoch 98, Val Loss: 4.53267
Epoch 99, Val Loss: 4.85681
Saved Losses
{'MSE - mean': 5.111390308988002, 'MSE - std': 0.5192665463418313, 'R2 - mean': 0.49849904342024554, 'R2 - std': 0.011996343004292753} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.85570
Epoch 1, Val Loss: 10.94914
Epoch 2, Val Loss: 7.09195
Epoch 3, Val Loss: 6.62523
Epoch 4, Val Loss: 6.27103
Epoch 5, Val Loss: 6.05381
Epoch 6, Val Loss: 5.96748
Epoch 7, Val Loss: 5.99721
Epoch 8, Val Loss: 5.86668
Epoch 9, Val Loss: 6.24756
Epoch 10, Val Loss: 6.44851
Epoch 11, Val Loss: 6.37689
Epoch 12, Val Loss: 5.86309
Epoch 13, Val Loss: 5.84899
Epoch 14, Val Loss: 5.70219
Epoch 15, Val Loss: 5.99655
Epoch 16, Val Loss: 6.47369
Epoch 17, Val Loss: 5.66361
Epoch 18, Val Loss: 5.63892
Epoch 19, Val Loss: 5.75848
Epoch 20, Val Loss: 5.55868
Epoch 21, Val Loss: 5.81846
Epoch 22, Val Loss: 5.53695
Epoch 23, Val Loss: 6.35010
Epoch 24, Val Loss: 5.60641
Epoch 25, Val Loss: 5.73057
Epoch 26, Val Loss: 5.44262
Epoch 27, Val Loss: 5.94355
Epoch 28, Val Loss: 5.81752
Epoch 29, Val Loss: 5.55816
Epoch 30, Val Loss: 5.88576
Epoch 31, Val Loss: 5.38798
Epoch 32, Val Loss: 5.53011
Epoch 33, Val Loss: 5.62331
Epoch 34, Val Loss: 5.34316
Epoch 35, Val Loss: 5.38546
Epoch 36, Val Loss: 5.42051
Epoch 37, Val Loss: 5.35816
Epoch 38, Val Loss: 5.46762
Epoch 39, Val Loss: 5.66590
Epoch 40, Val Loss: 5.41772
Epoch 41, Val Loss: 5.32950
Epoch 42, Val Loss: 5.40290
Epoch 43, Val Loss: 5.27564
Epoch 44, Val Loss: 5.35982
Epoch 45, Val Loss: 5.52536
Epoch 46, Val Loss: 5.55319
Epoch 47, Val Loss: 5.51504
Epoch 48, Val Loss: 5.32533
Epoch 49, Val Loss: 5.29975
Epoch 50, Val Loss: 5.43758
Epoch 51, Val Loss: 5.31199
Epoch 52, Val Loss: 5.30570
Epoch 53, Val Loss: 5.31275
Epoch 54, Val Loss: 5.41327
Epoch 55, Val Loss: 5.54731
Epoch 56, Val Loss: 5.30161
Epoch 57, Val Loss: 5.30073
Epoch 58, Val Loss: 5.23986
Epoch 59, Val Loss: 5.30276
Epoch 60, Val Loss: 5.31090
Epoch 61, Val Loss: 5.27492
Epoch 62, Val Loss: 5.54310
Epoch 63, Val Loss: 5.29162
Epoch 64, Val Loss: 5.24306
Epoch 65, Val Loss: 5.23488
Epoch 66, Val Loss: 5.72938
Epoch 67, Val Loss: 5.35577
Epoch 68, Val Loss: 5.29667
Epoch 69, Val Loss: 5.15688
Epoch 70, Val Loss: 5.32162
Epoch 71, Val Loss: 5.42627
Epoch 72, Val Loss: 5.21058
Epoch 73, Val Loss: 5.25613
Epoch 74, Val Loss: 5.26585
Epoch 75, Val Loss: 5.19127
Epoch 76, Val Loss: 5.31096
Epoch 77, Val Loss: 5.15757
Epoch 78, Val Loss: 5.15532
Epoch 79, Val Loss: 5.13125
Epoch 80, Val Loss: 5.25008
Epoch 81, Val Loss: 5.33384
Epoch 82, Val Loss: 5.54042
Epoch 83, Val Loss: 5.35443
Epoch 84, Val Loss: 5.24796
Epoch 85, Val Loss: 5.17671
Epoch 86, Val Loss: 5.16838
Epoch 87, Val Loss: 5.22006
Epoch 88, Val Loss: 5.31733
Epoch 89, Val Loss: 5.25446
Epoch 90, Val Loss: 5.17393
Epoch 91, Val Loss: 5.15731
Epoch 92, Val Loss: 5.06331
Epoch 93, Val Loss: 5.31973
Epoch 94, Val Loss: 5.10916
Epoch 95, Val Loss: 5.10151
Epoch 96, Val Loss: 5.83706
Epoch 97, Val Loss: 5.16485
Epoch 98, Val Loss: 5.34549
Epoch 99, Val Loss: 5.41633
Saved Losses
{'MSE - mean': 5.147501166115766, 'MSE - std': 0.427043891699888, 'R2 - mean': 0.4944613916881211, 'R2 - std': 0.01133784635653016} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.83736
Epoch 1, Val Loss: 9.40603
Epoch 2, Val Loss: 6.33889
Epoch 3, Val Loss: 5.78709
Epoch 4, Val Loss: 5.47559
Epoch 5, Val Loss: 5.36273
Epoch 6, Val Loss: 5.42451
Epoch 7, Val Loss: 5.29892
Epoch 8, Val Loss: 5.40777
Epoch 9, Val Loss: 5.25494
Epoch 10, Val Loss: 5.14484
Epoch 11, Val Loss: 5.16414
Epoch 12, Val Loss: 5.45694
Epoch 13, Val Loss: 5.10207
Epoch 14, Val Loss: 5.34303
Epoch 15, Val Loss: 5.27509
Epoch 16, Val Loss: 5.08064
Epoch 17, Val Loss: 5.24926
Epoch 18, Val Loss: 5.47144
Epoch 19, Val Loss: 5.09205
Epoch 20, Val Loss: 5.15338
Epoch 21, Val Loss: 5.05342
Epoch 22, Val Loss: 5.11938
Epoch 23, Val Loss: 5.21653
Epoch 24, Val Loss: 5.21071
Epoch 25, Val Loss: 5.16671
Epoch 26, Val Loss: 5.05989
Epoch 27, Val Loss: 5.24373
Epoch 28, Val Loss: 4.99873
Epoch 29, Val Loss: 5.04081
Epoch 30, Val Loss: 5.00318
Epoch 31, Val Loss: 5.07471
Epoch 32, Val Loss: 5.19228
Epoch 33, Val Loss: 5.17453
Epoch 34, Val Loss: 5.32605
Epoch 35, Val Loss: 4.94806
Epoch 36, Val Loss: 5.04575
Epoch 37, Val Loss: 5.00079
Epoch 38, Val Loss: 4.85486
Epoch 39, Val Loss: 5.10232
Epoch 40, Val Loss: 4.95529
Epoch 41, Val Loss: 5.09735
Epoch 42, Val Loss: 4.77782
Epoch 43, Val Loss: 4.87696
Epoch 44, Val Loss: 4.97093
Epoch 45, Val Loss: 4.89124
Epoch 46, Val Loss: 4.72027
Epoch 47, Val Loss: 4.89570
Epoch 48, Val Loss: 4.73743
Epoch 49, Val Loss: 4.73333
Epoch 50, Val Loss: 4.84159
Epoch 51, Val Loss: 4.95450
Epoch 52, Val Loss: 4.79968
Epoch 53, Val Loss: 4.66115
Epoch 54, Val Loss: 4.63777
Epoch 55, Val Loss: 5.56022
Epoch 56, Val Loss: 4.67234
Epoch 57, Val Loss: 4.99631
Epoch 58, Val Loss: 4.66738
Epoch 59, Val Loss: 4.84394
Epoch 60, Val Loss: 4.85943
Epoch 61, Val Loss: 4.57242
Epoch 62, Val Loss: 4.95232
Epoch 63, Val Loss: 4.81557
Epoch 64, Val Loss: 4.63711
Epoch 65, Val Loss: 5.42251
Epoch 66, Val Loss: 4.55739
Epoch 67, Val Loss: 4.58412
Epoch 68, Val Loss: 4.62496
Epoch 69, Val Loss: 4.52446
Epoch 70, Val Loss: 4.58235
Epoch 71, Val Loss: 4.68876
Epoch 72, Val Loss: 4.98073
Epoch 73, Val Loss: 4.49580
Epoch 74, Val Loss: 4.51435
Epoch 75, Val Loss: 4.50042
Epoch 76, Val Loss: 5.04313
Epoch 77, Val Loss: 4.71840
Epoch 78, Val Loss: 4.47278
Epoch 79, Val Loss: 4.60865
Epoch 80, Val Loss: 5.13102
Epoch 81, Val Loss: 4.71847
Epoch 82, Val Loss: 4.61538
Epoch 83, Val Loss: 4.42491
Epoch 84, Val Loss: 4.94153
Epoch 85, Val Loss: 4.46959
Epoch 86, Val Loss: 4.49903
Epoch 87, Val Loss: 4.59958
Epoch 88, Val Loss: 4.45498
Epoch 89, Val Loss: 4.49434
Epoch 90, Val Loss: 4.49372
Epoch 91, Val Loss: 4.58324
Epoch 92, Val Loss: 4.43341
Epoch 93, Val Loss: 4.43352
Epoch 94, Val Loss: 4.43531
Epoch 95, Val Loss: 4.36360
Epoch 96, Val Loss: 4.38901
Epoch 97, Val Loss: 4.48498
Epoch 98, Val Loss: 4.44685
Epoch 99, Val Loss: 4.50806
Saved Losses
{'MSE - mean': 5.035533923521468, 'MSE - std': 0.417594126301065, 'R2 - mean': 0.49522427784698353, 'R2 - std': 0.00990737381334554} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.46603
Epoch 1, Val Loss: 11.23619
Epoch 2, Val Loss: 10.21646
Epoch 3, Val Loss: 7.73311
Epoch 4, Val Loss: 7.69409
Epoch 5, Val Loss: 7.81324
Epoch 6, Val Loss: 7.23166
Epoch 7, Val Loss: 7.28460
Epoch 8, Val Loss: 7.20230
Epoch 9, Val Loss: 7.07304
Epoch 10, Val Loss: 8.05376
Epoch 11, Val Loss: 7.06304
Epoch 12, Val Loss: 7.73851
Epoch 13, Val Loss: 7.09974
Epoch 14, Val Loss: 7.32671
Epoch 15, Val Loss: 7.25212
Epoch 16, Val Loss: 7.09676
Epoch 17, Val Loss: 6.98350
Epoch 18, Val Loss: 7.16520
Epoch 19, Val Loss: 7.53797
Epoch 20, Val Loss: 7.34629
Epoch 21, Val Loss: 7.18223
Epoch 22, Val Loss: 7.20654
Epoch 23, Val Loss: 6.98323
Epoch 24, Val Loss: 6.85819
Epoch 25, Val Loss: 7.05427
Epoch 26, Val Loss: 7.15793
Epoch 27, Val Loss: 6.91984
Epoch 28, Val Loss: 6.84001
Epoch 29, Val Loss: 6.67588
Epoch 30, Val Loss: 7.04899
Epoch 31, Val Loss: 6.64180
Epoch 32, Val Loss: 6.99549
Epoch 33, Val Loss: 7.03185
Epoch 34, Val Loss: 6.81993
Epoch 35, Val Loss: 6.69746
Epoch 36, Val Loss: 6.58668
Epoch 37, Val Loss: 7.00209
Epoch 38, Val Loss: 6.71292
Epoch 39, Val Loss: 6.50532
Epoch 40, Val Loss: 6.51877
Epoch 41, Val Loss: 6.47474
Epoch 42, Val Loss: 6.49044
Epoch 43, Val Loss: 6.91582
Epoch 44, Val Loss: 6.64706
Epoch 45, Val Loss: 6.56850
Epoch 46, Val Loss: 6.43476
Epoch 47, Val Loss: 6.50350
Epoch 48, Val Loss: 6.91398
Epoch 49, Val Loss: 7.17309
Epoch 50, Val Loss: 6.54299
Epoch 51, Val Loss: 6.61124
Epoch 52, Val Loss: 6.46779
Epoch 53, Val Loss: 6.64482
Epoch 54, Val Loss: 6.50548
Epoch 55, Val Loss: 6.45418
Epoch 56, Val Loss: 6.42827
Epoch 57, Val Loss: 6.50252
Epoch 58, Val Loss: 6.31130
Epoch 59, Val Loss: 6.33964
Epoch 60, Val Loss: 6.33703
Epoch 61, Val Loss: 6.28484
Epoch 62, Val Loss: 6.57455
Epoch 63, Val Loss: 6.33982
Epoch 64, Val Loss: 6.52436
Epoch 65, Val Loss: 6.35110
Epoch 66, Val Loss: 6.46046
Epoch 67, Val Loss: 6.40112
Epoch 68, Val Loss: 6.27121
Epoch 69, Val Loss: 6.21120
Epoch 70, Val Loss: 8.04130
Epoch 71, Val Loss: 6.99319
Epoch 72, Val Loss: 6.67830
Epoch 73, Val Loss: 6.48271
Epoch 74, Val Loss: 6.27513
Epoch 75, Val Loss: 6.40052
Epoch 76, Val Loss: 6.21663
Epoch 77, Val Loss: 6.54214
Epoch 78, Val Loss: 6.25242
Epoch 79, Val Loss: 6.28356
Epoch 80, Val Loss: 6.63421
Epoch 81, Val Loss: 6.12255
Epoch 82, Val Loss: 6.43131
Epoch 83, Val Loss: 6.02893
Epoch 84, Val Loss: 6.16864
Epoch 85, Val Loss: 6.69377
Epoch 86, Val Loss: 6.05224
Epoch 87, Val Loss: 6.07593
Epoch 88, Val Loss: 6.34976
Epoch 89, Val Loss: 6.26056
Epoch 90, Val Loss: 6.01532
Epoch 91, Val Loss: 6.19705
Epoch 92, Val Loss: 6.21882
Epoch 93, Val Loss: 6.57121
Epoch 94, Val Loss: 6.10321
Epoch 95, Val Loss: 6.06283
Epoch 96, Val Loss: 6.15421
Epoch 97, Val Loss: 6.05109
Epoch 98, Val Loss: 6.14946
Epoch 99, Val Loss: 5.94715
Saved Losses
{'MSE - mean': 5.2148739078377, 'MSE - std': 0.5178409054479035, 'R2 - mean': 0.498060648280138, 'R2 - std': 0.01052163645248129} 
 

Results After CV: {'MSE - mean': 5.2148739078377, 'MSE - std': 0.5178409054479035, 'R2 - mean': 0.498060648280138, 'R2 - std': 0.01052163645248129}
Train time: 82.8297292088002
Inference time: 0.05274033220011916
Finished cross validation
Trial 12 finished with value: 5.2148739078377 and parameters: {'p_m': 0.10759987069285776, 'alpha': 3.9340566729927966, 'K': 10, 'beta': 4.190888213251094}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.93702
Epoch 1, Val Loss: 8.47935
Epoch 2, Val Loss: 7.82151
Epoch 3, Val Loss: 7.33202
Epoch 4, Val Loss: 7.06782
Epoch 5, Val Loss: 7.21489
Epoch 6, Val Loss: 7.25809
Epoch 7, Val Loss: 6.81289
Epoch 8, Val Loss: 6.79562
Epoch 9, Val Loss: 6.90071
Epoch 10, Val Loss: 7.53463
Epoch 11, Val Loss: 7.01754
Epoch 12, Val Loss: 7.00116
Epoch 13, Val Loss: 6.83522
Epoch 14, Val Loss: 6.63487
Epoch 15, Val Loss: 6.53515
Epoch 16, Val Loss: 7.15150
Epoch 17, Val Loss: 6.83981
Epoch 18, Val Loss: 6.93764
Epoch 19, Val Loss: 6.71870
Epoch 20, Val Loss: 6.54587
Epoch 21, Val Loss: 6.76299
Epoch 22, Val Loss: 6.43389
Epoch 23, Val Loss: 6.82022
Epoch 24, Val Loss: 6.67053
Epoch 25, Val Loss: 6.59267
Epoch 26, Val Loss: 6.50044
Epoch 27, Val Loss: 6.61169
Epoch 28, Val Loss: 6.76178
Epoch 29, Val Loss: 6.52607
Epoch 30, Val Loss: 6.45358
Epoch 31, Val Loss: 6.54662
Epoch 32, Val Loss: 6.32075
Epoch 33, Val Loss: 6.48574
Epoch 34, Val Loss: 6.47741
Epoch 35, Val Loss: 6.90429
Epoch 36, Val Loss: 6.47258
Epoch 37, Val Loss: 6.81297
Epoch 38, Val Loss: 6.96422
Epoch 39, Val Loss: 6.41470
Epoch 40, Val Loss: 6.38661
Epoch 41, Val Loss: 6.62564
Epoch 42, Val Loss: 6.26884
Epoch 43, Val Loss: 6.38839
Epoch 44, Val Loss: 6.27577
Epoch 45, Val Loss: 6.30284
Epoch 46, Val Loss: 6.53045
Epoch 47, Val Loss: 6.41843
Epoch 48, Val Loss: 6.31239
Epoch 49, Val Loss: 6.28239
Epoch 50, Val Loss: 6.07917
Epoch 51, Val Loss: 6.32898
Epoch 52, Val Loss: 6.52485
Epoch 53, Val Loss: 6.39536
Epoch 54, Val Loss: 6.57108
Epoch 55, Val Loss: 6.09985
Epoch 56, Val Loss: 6.92751
Epoch 57, Val Loss: 6.41893
Epoch 58, Val Loss: 6.54722
Epoch 59, Val Loss: 6.34942
Epoch 60, Val Loss: 6.33760
Epoch 61, Val Loss: 6.10510
Epoch 62, Val Loss: 6.05901
Epoch 63, Val Loss: 6.34229
Epoch 64, Val Loss: 6.93976
Epoch 65, Val Loss: 6.09287
Epoch 66, Val Loss: 6.46092
Epoch 67, Val Loss: 6.45383
Epoch 68, Val Loss: 6.70930
Epoch 69, Val Loss: 6.21479
Epoch 70, Val Loss: 6.15515
Epoch 71, Val Loss: 5.92035
Epoch 72, Val Loss: 6.12984
Epoch 73, Val Loss: 6.06872
Epoch 74, Val Loss: 6.05345
Epoch 75, Val Loss: 6.20676
Epoch 76, Val Loss: 6.02496
Epoch 77, Val Loss: 6.44265
Epoch 78, Val Loss: 6.13141
Epoch 79, Val Loss: 6.35470
Epoch 80, Val Loss: 6.30904
Epoch 81, Val Loss: 6.08959
Epoch 82, Val Loss: 6.29062
Epoch 83, Val Loss: 6.16185
Epoch 84, Val Loss: 5.94831
Epoch 85, Val Loss: 5.99757
Epoch 86, Val Loss: 6.06982
Epoch 87, Val Loss: 6.40707
Epoch 88, Val Loss: 6.14119
Epoch 89, Val Loss: 6.08662
Epoch 90, Val Loss: 6.39510
Epoch 91, Val Loss: 6.03576
Epoch 92, Val Loss: 6.17784
Early stopping applies.
Saved Losses
{'MSE - mean': 6.110858870734032, 'MSE - std': 0.0, 'R2 - mean': 0.4427098633632981, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.28604
Epoch 1, Val Loss: 9.13380
Epoch 2, Val Loss: 6.20814
Epoch 3, Val Loss: 5.87343
Epoch 4, Val Loss: 5.72579
Epoch 5, Val Loss: 5.47497
Epoch 6, Val Loss: 5.78979
Epoch 7, Val Loss: 5.37675
Epoch 8, Val Loss: 6.09359
Epoch 9, Val Loss: 5.64410
Epoch 10, Val Loss: 5.79422
Epoch 11, Val Loss: 5.36388
Epoch 12, Val Loss: 5.13499
Epoch 13, Val Loss: 5.18682
Epoch 14, Val Loss: 5.13658
Epoch 15, Val Loss: 5.20772
Epoch 16, Val Loss: 4.99884
Epoch 17, Val Loss: 5.61547
Epoch 18, Val Loss: 5.27442
Epoch 19, Val Loss: 5.22403
Epoch 20, Val Loss: 6.02200
Epoch 21, Val Loss: 5.61868
Epoch 22, Val Loss: 5.79885
Epoch 23, Val Loss: 5.21733
Epoch 24, Val Loss: 5.12679
Epoch 25, Val Loss: 4.96744
Epoch 26, Val Loss: 5.31152
Epoch 27, Val Loss: 5.01835
Epoch 28, Val Loss: 5.24902
Epoch 29, Val Loss: 4.98917
Epoch 30, Val Loss: 5.27877
Epoch 31, Val Loss: 5.12670
Epoch 32, Val Loss: 5.03605
Epoch 33, Val Loss: 5.01952
Epoch 34, Val Loss: 4.97615
Epoch 35, Val Loss: 4.83946
Epoch 36, Val Loss: 4.90257
Epoch 37, Val Loss: 5.34546
Epoch 38, Val Loss: 4.84899
Epoch 39, Val Loss: 5.16309
Epoch 40, Val Loss: 4.90736
Epoch 41, Val Loss: 5.58240
Epoch 42, Val Loss: 4.94230
Epoch 43, Val Loss: 5.15130
Epoch 44, Val Loss: 5.20838
Epoch 45, Val Loss: 4.78373
Epoch 46, Val Loss: 4.93039
Epoch 47, Val Loss: 4.96048
Epoch 48, Val Loss: 4.73286
Epoch 49, Val Loss: 5.10303
Epoch 50, Val Loss: 5.17057
Epoch 51, Val Loss: 5.17099
Epoch 52, Val Loss: 5.04424
Epoch 53, Val Loss: 5.02316
Epoch 54, Val Loss: 4.82702
Epoch 55, Val Loss: 5.21431
Epoch 56, Val Loss: 5.03283
Epoch 57, Val Loss: 4.71835
Epoch 58, Val Loss: 4.91903
Epoch 59, Val Loss: 5.04125
Epoch 60, Val Loss: 4.69809
Epoch 61, Val Loss: 4.88830
Epoch 62, Val Loss: 4.94714
Epoch 63, Val Loss: 4.88885
Epoch 64, Val Loss: 4.69490
Epoch 65, Val Loss: 4.90845
Epoch 66, Val Loss: 4.89893
Epoch 67, Val Loss: 5.06909
Epoch 68, Val Loss: 4.65124
Epoch 69, Val Loss: 4.94558
Epoch 70, Val Loss: 5.25092
Epoch 71, Val Loss: 4.62989
Epoch 72, Val Loss: 4.69303
Epoch 73, Val Loss: 5.06360
Epoch 74, Val Loss: 4.77828
Epoch 75, Val Loss: 5.19443
Epoch 76, Val Loss: 4.65891
Epoch 77, Val Loss: 4.72413
Epoch 78, Val Loss: 5.06692
Epoch 79, Val Loss: 4.60816
Epoch 80, Val Loss: 5.01952
Epoch 81, Val Loss: 4.83008
Epoch 82, Val Loss: 4.66937
Epoch 83, Val Loss: 4.72837
Epoch 84, Val Loss: 4.69795
Epoch 85, Val Loss: 4.60726
Epoch 86, Val Loss: 5.05007
Epoch 87, Val Loss: 4.57729
Epoch 88, Val Loss: 4.70512
Epoch 89, Val Loss: 4.76794
Epoch 90, Val Loss: 4.61786
Epoch 91, Val Loss: 4.75213
Epoch 92, Val Loss: 4.64654
Epoch 93, Val Loss: 4.54857
Epoch 94, Val Loss: 4.47981
Epoch 95, Val Loss: 4.64996
Epoch 96, Val Loss: 4.65805
Epoch 97, Val Loss: 4.50114
Epoch 98, Val Loss: 4.39524
Epoch 99, Val Loss: 4.57645
Saved Losses
{'MSE - mean': 5.375517847702072, 'MSE - std': 0.7353410230319595, 'R2 - mean': 0.4740414792483582, 'R2 - std': 0.031331615885060116} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.49966
Epoch 1, Val Loss: 9.84971
Epoch 2, Val Loss: 7.73941
Epoch 3, Val Loss: 6.59511
Epoch 4, Val Loss: 6.43606
Epoch 5, Val Loss: 6.59474
Epoch 6, Val Loss: 6.34812
Epoch 7, Val Loss: 6.50656
Epoch 8, Val Loss: 6.24742
Epoch 9, Val Loss: 6.37783
Epoch 10, Val Loss: 7.08961
Epoch 11, Val Loss: 6.27089
Epoch 12, Val Loss: 6.13090
Epoch 13, Val Loss: 6.64664
Epoch 14, Val Loss: 6.33302
Epoch 15, Val Loss: 6.09676
Epoch 16, Val Loss: 6.60512
Epoch 17, Val Loss: 6.05721
Epoch 18, Val Loss: 6.11599
Epoch 19, Val Loss: 6.13860
Epoch 20, Val Loss: 6.34849
Epoch 21, Val Loss: 6.13120
Epoch 22, Val Loss: 5.87426
Epoch 23, Val Loss: 5.96115
Epoch 24, Val Loss: 6.38204
Epoch 25, Val Loss: 6.26690
Epoch 26, Val Loss: 5.79169
Epoch 27, Val Loss: 5.99124
Epoch 28, Val Loss: 5.90282
Epoch 29, Val Loss: 5.93749
Epoch 30, Val Loss: 5.64451
Epoch 31, Val Loss: 5.76667
Epoch 32, Val Loss: 6.25573
Epoch 33, Val Loss: 5.84109
Epoch 34, Val Loss: 5.63721
Epoch 35, Val Loss: 6.04716
Epoch 36, Val Loss: 5.96981
Epoch 37, Val Loss: 5.65009
Epoch 38, Val Loss: 5.81203
Epoch 39, Val Loss: 5.67959
Epoch 40, Val Loss: 6.17759
Epoch 41, Val Loss: 5.54037
Epoch 42, Val Loss: 5.68430
Epoch 43, Val Loss: 5.88968
Epoch 44, Val Loss: 5.72571
Epoch 45, Val Loss: 5.92542
Epoch 46, Val Loss: 5.67854
Epoch 47, Val Loss: 5.51571
Epoch 48, Val Loss: 5.56807
Epoch 49, Val Loss: 5.67372
Epoch 50, Val Loss: 6.29002
Epoch 51, Val Loss: 5.73226
Epoch 52, Val Loss: 5.77993
Epoch 53, Val Loss: 5.63575
Epoch 54, Val Loss: 5.55184
Epoch 55, Val Loss: 5.49100
Epoch 56, Val Loss: 5.90043
Epoch 57, Val Loss: 5.51155
Epoch 58, Val Loss: 5.48240
Epoch 59, Val Loss: 5.69939
Epoch 60, Val Loss: 5.90589
Epoch 61, Val Loss: 5.36217
Epoch 62, Val Loss: 5.41853
Epoch 63, Val Loss: 5.77443
Epoch 64, Val Loss: 5.42049
Epoch 65, Val Loss: 5.56971
Epoch 66, Val Loss: 5.75279
Epoch 67, Val Loss: 5.64852
Epoch 68, Val Loss: 5.39076
Epoch 69, Val Loss: 5.34392
Epoch 70, Val Loss: 5.93854
Epoch 71, Val Loss: 5.40386
Epoch 72, Val Loss: 5.31513
Epoch 73, Val Loss: 5.67012
Epoch 74, Val Loss: 5.39603
Epoch 75, Val Loss: 5.50383
Epoch 76, Val Loss: 5.76402
Epoch 77, Val Loss: 5.84050
Epoch 78, Val Loss: 5.83260
Epoch 79, Val Loss: 5.56194
Epoch 80, Val Loss: 5.51469
Epoch 81, Val Loss: 5.23587
Epoch 82, Val Loss: 5.30643
Epoch 83, Val Loss: 5.24918
Epoch 84, Val Loss: 5.86026
Epoch 85, Val Loss: 5.16274
Epoch 86, Val Loss: 5.53330
Epoch 87, Val Loss: 5.30070
Epoch 88, Val Loss: 5.22136
Epoch 89, Val Loss: 5.34415
Epoch 90, Val Loss: 5.48843
Epoch 91, Val Loss: 5.07248
Epoch 92, Val Loss: 5.08282
Epoch 93, Val Loss: 5.38762
Epoch 94, Val Loss: 5.06240
Epoch 95, Val Loss: 5.40952
Epoch 96, Val Loss: 5.04554
Epoch 97, Val Loss: 5.20762
Epoch 98, Val Loss: 5.08702
Epoch 99, Val Loss: 5.10964
Saved Losses
{'MSE - mean': 5.324091915108558, 'MSE - std': 0.6047921404819051, 'R2 - mean': 0.47810658640635056, 'R2 - std': 0.026220163266550342} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.72072
Epoch 1, Val Loss: 7.87973
Epoch 2, Val Loss: 5.99746
Epoch 3, Val Loss: 5.85807
Epoch 4, Val Loss: 5.73100
Epoch 5, Val Loss: 5.91009
Epoch 6, Val Loss: 5.72656
Epoch 7, Val Loss: 5.74535
Epoch 8, Val Loss: 5.49419
Epoch 9, Val Loss: 5.50302
Epoch 10, Val Loss: 5.74831
Epoch 11, Val Loss: 5.69462
Epoch 12, Val Loss: 6.40337
Epoch 13, Val Loss: 5.84473
Epoch 14, Val Loss: 5.64793
Epoch 15, Val Loss: 5.71001
Epoch 16, Val Loss: 5.58862
Epoch 17, Val Loss: 5.72562
Epoch 18, Val Loss: 5.36305
Epoch 19, Val Loss: 5.56962
Epoch 20, Val Loss: 5.61490
Epoch 21, Val Loss: 5.79975
Epoch 22, Val Loss: 5.63490
Epoch 23, Val Loss: 5.80167
Epoch 24, Val Loss: 5.86741
Epoch 25, Val Loss: 5.75068
Epoch 26, Val Loss: 5.68496
Epoch 27, Val Loss: 5.73333
Epoch 28, Val Loss: 5.98762
Epoch 29, Val Loss: 5.49801
Epoch 30, Val Loss: 5.99837
Epoch 31, Val Loss: 5.45281
Epoch 32, Val Loss: 5.37237
Epoch 33, Val Loss: 5.52996
Epoch 34, Val Loss: 5.49238
Epoch 35, Val Loss: 5.82791
Epoch 36, Val Loss: 5.70617
Epoch 37, Val Loss: 5.37281
Epoch 38, Val Loss: 5.66791
Epoch 39, Val Loss: 5.52915
Early stopping applies.
Saved Losses
{'MSE - mean': 5.448271671559664, 'MSE - std': 0.5662084294924273, 'R2 - mean': 0.4529889235244276, 'R2 - std': 0.04907457271584962} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.67826
Epoch 1, Val Loss: 15.56160
Epoch 2, Val Loss: 12.16216
Epoch 3, Val Loss: 9.83738
Epoch 4, Val Loss: 8.63893
Epoch 5, Val Loss: 8.22271
Epoch 6, Val Loss: 8.34482
Epoch 7, Val Loss: 8.06857
Epoch 8, Val Loss: 7.84940
Epoch 9, Val Loss: 7.89410
Epoch 10, Val Loss: 8.22060
Epoch 11, Val Loss: 8.04090
Epoch 12, Val Loss: 8.41067
Epoch 13, Val Loss: 8.24282
Epoch 14, Val Loss: 8.25673
Epoch 15, Val Loss: 8.09649
Epoch 16, Val Loss: 7.81984
Epoch 17, Val Loss: 8.31380
Epoch 18, Val Loss: 8.48545
Epoch 19, Val Loss: 7.67573
Epoch 20, Val Loss: 7.83403
Epoch 21, Val Loss: 8.14308
Epoch 22, Val Loss: 7.83605
Epoch 23, Val Loss: 7.65818
Epoch 24, Val Loss: 7.80902
Epoch 25, Val Loss: 7.82755
Epoch 26, Val Loss: 7.62987
Epoch 27, Val Loss: 7.67894
Epoch 28, Val Loss: 7.62394
Epoch 29, Val Loss: 7.90166
Epoch 30, Val Loss: 8.62389
Epoch 31, Val Loss: 7.96365
Epoch 32, Val Loss: 8.09062
Epoch 33, Val Loss: 7.68392
Epoch 34, Val Loss: 7.63177
Epoch 35, Val Loss: 7.54474
Epoch 36, Val Loss: 7.75319
Epoch 37, Val Loss: 7.60953
Epoch 38, Val Loss: 8.09973
Epoch 39, Val Loss: 7.70111
Epoch 40, Val Loss: 7.61787
Epoch 41, Val Loss: 8.15789
Epoch 42, Val Loss: 7.30497
Epoch 43, Val Loss: 7.68830
Epoch 44, Val Loss: 7.56696
Epoch 45, Val Loss: 8.15258
Epoch 46, Val Loss: 8.14250
Epoch 47, Val Loss: 7.97947
Epoch 48, Val Loss: 7.34896
Epoch 49, Val Loss: 7.27794
Epoch 50, Val Loss: 7.64096
Epoch 51, Val Loss: 7.41117
Epoch 52, Val Loss: 8.40949
Epoch 53, Val Loss: 7.18749
Epoch 54, Val Loss: 7.46402
Epoch 55, Val Loss: 7.87797
Epoch 56, Val Loss: 8.08986
Epoch 57, Val Loss: 7.52795
Epoch 58, Val Loss: 7.56151
Epoch 59, Val Loss: 7.43575
Epoch 60, Val Loss: 7.96543
Epoch 61, Val Loss: 7.38206
Epoch 62, Val Loss: 7.42872
Epoch 63, Val Loss: 7.32081
Epoch 64, Val Loss: 7.49951
Epoch 65, Val Loss: 7.42768
Epoch 66, Val Loss: 7.27870
Epoch 67, Val Loss: 7.91976
Epoch 68, Val Loss: 7.04668
Epoch 69, Val Loss: 7.26956
Epoch 70, Val Loss: 6.99512
Epoch 71, Val Loss: 7.43706
Epoch 72, Val Loss: 7.36561
Epoch 73, Val Loss: 7.26008
Epoch 74, Val Loss: 7.53022
Epoch 75, Val Loss: 7.53611
Epoch 76, Val Loss: 7.66486
Epoch 77, Val Loss: 7.64365
Epoch 78, Val Loss: 7.28565
Epoch 79, Val Loss: 7.56154
Epoch 80, Val Loss: 7.00162
Epoch 81, Val Loss: 7.33016
Epoch 82, Val Loss: 7.46717
Epoch 83, Val Loss: 7.20600
Epoch 84, Val Loss: 7.23889
Epoch 85, Val Loss: 7.52021
Epoch 86, Val Loss: 7.11364
Epoch 87, Val Loss: 7.03645
Epoch 88, Val Loss: 7.55324
Epoch 89, Val Loss: 7.01720
Epoch 90, Val Loss: 7.12858
Epoch 91, Val Loss: 7.37313
Early stopping applies.
Saved Losses
{'MSE - mean': 5.756367410381448, 'MSE - std': 0.7975998530737002, 'R2 - mean': 0.4467976481449073, 'R2 - std': 0.04560678143757558} 
 

Results After CV: {'MSE - mean': 5.756367410381448, 'MSE - std': 0.7975998530737002, 'R2 - mean': 0.4467976481449073, 'R2 - std': 0.04560678143757558}
Train time: 103.16592205959986
Inference time: 0.0509683952002888
Finished cross validation
Trial 13 finished with value: 5.756367410381448 and parameters: {'p_m': 0.33023182629869097, 'alpha': 2.171196496984105, 'K': 20, 'beta': 5.97439842666519}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.97187
Epoch 1, Val Loss: 8.37613
Epoch 2, Val Loss: 7.78946
Epoch 3, Val Loss: 7.51906
Epoch 4, Val Loss: 7.50536
Epoch 5, Val Loss: 7.22516
Epoch 6, Val Loss: 7.26153
Epoch 7, Val Loss: 7.56026
Epoch 8, Val Loss: 7.39829
Epoch 9, Val Loss: 7.76853
Epoch 10, Val Loss: 7.11879
Epoch 11, Val Loss: 7.52959
Epoch 12, Val Loss: 7.07019
Epoch 13, Val Loss: 7.62832
Epoch 14, Val Loss: 7.24262
Epoch 15, Val Loss: 7.60726
Epoch 16, Val Loss: 7.01278
Epoch 17, Val Loss: 6.92588
Epoch 18, Val Loss: 7.16881
Epoch 19, Val Loss: 6.72742
Epoch 20, Val Loss: 6.91235
Epoch 21, Val Loss: 7.08681
Epoch 22, Val Loss: 6.95315
Epoch 23, Val Loss: 7.14911
Epoch 24, Val Loss: 6.95020
Epoch 25, Val Loss: 7.03073
Epoch 26, Val Loss: 7.65780
Epoch 27, Val Loss: 7.28598
Epoch 28, Val Loss: 6.99623
Epoch 29, Val Loss: 6.79229
Epoch 30, Val Loss: 6.73848
Epoch 31, Val Loss: 6.68942
Epoch 32, Val Loss: 7.26615
Epoch 33, Val Loss: 6.99523
Epoch 34, Val Loss: 7.02673
Epoch 35, Val Loss: 6.76620
Epoch 36, Val Loss: 6.51415
Epoch 37, Val Loss: 6.85249
Epoch 38, Val Loss: 6.71414
Epoch 39, Val Loss: 6.68174
Epoch 40, Val Loss: 6.70412
Epoch 41, Val Loss: 7.09490
Epoch 42, Val Loss: 7.24018
Epoch 43, Val Loss: 6.97932
Epoch 44, Val Loss: 6.69320
Epoch 45, Val Loss: 6.69849
Epoch 46, Val Loss: 6.72814
Epoch 47, Val Loss: 6.77166
Epoch 48, Val Loss: 6.67793
Epoch 49, Val Loss: 6.67700
Epoch 50, Val Loss: 6.29710
Epoch 51, Val Loss: 6.68721
Epoch 52, Val Loss: 6.32171
Epoch 53, Val Loss: 6.61114
Epoch 54, Val Loss: 6.67425
Epoch 55, Val Loss: 6.43716
Epoch 56, Val Loss: 6.50193
Epoch 57, Val Loss: 7.44634
Epoch 58, Val Loss: 6.36870
Epoch 59, Val Loss: 6.80019
Epoch 60, Val Loss: 6.31803
Epoch 61, Val Loss: 7.04335
Epoch 62, Val Loss: 6.43598
Epoch 63, Val Loss: 6.41654
Epoch 64, Val Loss: 6.53895
Epoch 65, Val Loss: 6.58858
Epoch 66, Val Loss: 7.32840
Epoch 67, Val Loss: 6.41865
Epoch 68, Val Loss: 6.82634
Epoch 69, Val Loss: 6.85926
Epoch 70, Val Loss: 6.35565
Epoch 71, Val Loss: 6.36318
Early stopping applies.
Saved Losses
{'MSE - mean': 6.545216688937328, 'MSE - std': 0.0, 'R2 - mean': 0.4030978656104096, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.91856
Epoch 1, Val Loss: 11.07990
Epoch 2, Val Loss: 6.44473
Epoch 3, Val Loss: 6.11080
Epoch 4, Val Loss: 5.95146
Epoch 5, Val Loss: 6.13803
Epoch 6, Val Loss: 5.94336
Epoch 7, Val Loss: 5.71973
Epoch 8, Val Loss: 5.71521
Epoch 9, Val Loss: 5.63582
Epoch 10, Val Loss: 5.80676
Epoch 11, Val Loss: 5.56603
Epoch 12, Val Loss: 5.53088
Epoch 13, Val Loss: 5.84603
Epoch 14, Val Loss: 5.61555
Epoch 15, Val Loss: 5.58851
Epoch 16, Val Loss: 5.92063
Epoch 17, Val Loss: 5.70591
Epoch 18, Val Loss: 6.29007
Epoch 19, Val Loss: 6.25783
Epoch 20, Val Loss: 5.51422
Epoch 21, Val Loss: 5.77137
Epoch 22, Val Loss: 5.75926
Epoch 23, Val Loss: 5.88749
Epoch 24, Val Loss: 5.86182
Epoch 25, Val Loss: 5.39678
Epoch 26, Val Loss: 5.61821
Epoch 27, Val Loss: 5.46154
Epoch 28, Val Loss: 5.91991
Epoch 29, Val Loss: 5.73095
Epoch 30, Val Loss: 5.52572
Epoch 31, Val Loss: 5.44772
Epoch 32, Val Loss: 5.18912
Epoch 33, Val Loss: 5.63570
Epoch 34, Val Loss: 5.45848
Epoch 35, Val Loss: 5.50574
Epoch 36, Val Loss: 5.36316
Epoch 37, Val Loss: 5.76631
Epoch 38, Val Loss: 6.08918
Epoch 39, Val Loss: 5.71921
Epoch 40, Val Loss: 5.53177
Epoch 41, Val Loss: 5.50079
Epoch 42, Val Loss: 5.61840
Epoch 43, Val Loss: 6.39663
Epoch 44, Val Loss: 5.36598
Epoch 45, Val Loss: 5.63843
Epoch 46, Val Loss: 5.18792
Epoch 47, Val Loss: 5.31208
Epoch 48, Val Loss: 5.15312
Epoch 49, Val Loss: 5.98531
Epoch 50, Val Loss: 5.18904
Epoch 51, Val Loss: 5.51237
Epoch 52, Val Loss: 5.31592
Epoch 53, Val Loss: 5.28246
Epoch 54, Val Loss: 5.42009
Epoch 55, Val Loss: 5.80889
Epoch 56, Val Loss: 5.24017
Epoch 57, Val Loss: 5.16836
Epoch 58, Val Loss: 5.10572
Epoch 59, Val Loss: 5.36077
Epoch 60, Val Loss: 5.65203
Epoch 61, Val Loss: 5.47750
Epoch 62, Val Loss: 5.13376
Epoch 63, Val Loss: 5.33386
Epoch 64, Val Loss: 5.44776
Epoch 65, Val Loss: 5.36161
Epoch 66, Val Loss: 5.34796
Epoch 67, Val Loss: 5.52106
Epoch 68, Val Loss: 5.18946
Epoch 69, Val Loss: 5.30803
Epoch 70, Val Loss: 5.23820
Epoch 71, Val Loss: 5.34217
Epoch 72, Val Loss: 5.17531
Epoch 73, Val Loss: 5.27586
Epoch 74, Val Loss: 5.00389
Epoch 75, Val Loss: 5.56335
Epoch 76, Val Loss: 5.09503
Epoch 77, Val Loss: 5.33258
Epoch 78, Val Loss: 5.52599
Epoch 79, Val Loss: 5.00461
Epoch 80, Val Loss: 5.35130
Epoch 81, Val Loss: 5.33685
Epoch 82, Val Loss: 5.30392
Epoch 83, Val Loss: 5.38050
Epoch 84, Val Loss: 5.35170
Epoch 85, Val Loss: 5.32171
Epoch 86, Val Loss: 5.67969
Epoch 87, Val Loss: 5.04956
Epoch 88, Val Loss: 5.20352
Epoch 89, Val Loss: 5.22707
Epoch 90, Val Loss: 5.19310
Epoch 91, Val Loss: 5.04694
Epoch 92, Val Loss: 5.02417
Epoch 93, Val Loss: 5.40224
Epoch 94, Val Loss: 5.40521
Epoch 95, Val Loss: 5.00752
Early stopping applies.
Saved Losses
{'MSE - mean': 5.963897424171524, 'MSE - std': 0.581319264765805, 'R2 - mean': 0.414666764755651, 'R2 - std': 0.011568899145241396} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.71818
Epoch 1, Val Loss: 9.41437
Epoch 2, Val Loss: 7.15329
Epoch 3, Val Loss: 7.09635
Epoch 4, Val Loss: 7.14432
Epoch 5, Val Loss: 7.11651
Epoch 6, Val Loss: 7.17676
Epoch 7, Val Loss: 6.73158
Epoch 8, Val Loss: 7.09180
Epoch 9, Val Loss: 6.62299
Epoch 10, Val Loss: 6.61825
Epoch 11, Val Loss: 6.46986
Epoch 12, Val Loss: 6.79138
Epoch 13, Val Loss: 7.05070
Epoch 14, Val Loss: 7.19377
Epoch 15, Val Loss: 6.68196
Epoch 16, Val Loss: 7.20123
Epoch 17, Val Loss: 7.12462
Epoch 18, Val Loss: 6.49474
Epoch 19, Val Loss: 7.14755
Epoch 20, Val Loss: 6.30162
Epoch 21, Val Loss: 6.27697
Epoch 22, Val Loss: 6.47163
Epoch 23, Val Loss: 6.57257
Epoch 24, Val Loss: 6.59019
Epoch 25, Val Loss: 6.26400
Epoch 26, Val Loss: 6.42184
Epoch 27, Val Loss: 6.87009
Epoch 28, Val Loss: 6.28870
Epoch 29, Val Loss: 6.58198
Epoch 30, Val Loss: 6.18175
Epoch 31, Val Loss: 6.39772
Epoch 32, Val Loss: 7.45122
Epoch 33, Val Loss: 6.26324
Epoch 34, Val Loss: 6.52837
Epoch 35, Val Loss: 6.70527
Epoch 36, Val Loss: 6.66674
Epoch 37, Val Loss: 6.47995
Epoch 38, Val Loss: 6.43837
Epoch 39, Val Loss: 6.31657
Epoch 40, Val Loss: 7.29447
Epoch 41, Val Loss: 6.10441
Epoch 42, Val Loss: 6.31837
Epoch 43, Val Loss: 6.64151
Epoch 44, Val Loss: 6.31344
Epoch 45, Val Loss: 6.37411
Epoch 46, Val Loss: 6.44952
Epoch 47, Val Loss: 6.34929
Epoch 48, Val Loss: 6.29617
Epoch 49, Val Loss: 6.08902
Epoch 50, Val Loss: 6.38037
Epoch 51, Val Loss: 6.26760
Epoch 52, Val Loss: 6.30340
Epoch 53, Val Loss: 6.57360
Epoch 54, Val Loss: 6.40810
Epoch 55, Val Loss: 6.26253
Epoch 56, Val Loss: 6.39595
Epoch 57, Val Loss: 6.53720
Epoch 58, Val Loss: 6.18692
Epoch 59, Val Loss: 6.38670
Epoch 60, Val Loss: 6.24508
Epoch 61, Val Loss: 6.21348
Epoch 62, Val Loss: 6.15478
Epoch 63, Val Loss: 6.55721
Epoch 64, Val Loss: 6.29601
Epoch 65, Val Loss: 6.26564
Epoch 66, Val Loss: 6.01264
Epoch 67, Val Loss: 6.13897
Epoch 68, Val Loss: 6.04930
Epoch 69, Val Loss: 6.83357
Epoch 70, Val Loss: 6.41514
Epoch 71, Val Loss: 6.27573
Epoch 72, Val Loss: 5.93640
Epoch 73, Val Loss: 6.02615
Epoch 74, Val Loss: 6.13448
Epoch 75, Val Loss: 6.64644
Epoch 76, Val Loss: 5.96108
Epoch 77, Val Loss: 5.98400
Epoch 78, Val Loss: 6.29082
Epoch 79, Val Loss: 6.24119
Epoch 80, Val Loss: 6.12847
Epoch 81, Val Loss: 6.48209
Epoch 82, Val Loss: 5.99454
Epoch 83, Val Loss: 6.16652
Epoch 84, Val Loss: 6.01287
Epoch 85, Val Loss: 6.03091
Epoch 86, Val Loss: 5.93316
Epoch 87, Val Loss: 6.31680
Epoch 88, Val Loss: 6.10596
Epoch 89, Val Loss: 6.80769
Epoch 90, Val Loss: 5.97088
Epoch 91, Val Loss: 6.01084
Epoch 92, Val Loss: 5.80856
Epoch 93, Val Loss: 6.42159
Epoch 94, Val Loss: 5.96159
Epoch 95, Val Loss: 6.29794
Epoch 96, Val Loss: 5.90032
Epoch 97, Val Loss: 6.01041
Epoch 98, Val Loss: 6.25211
Epoch 99, Val Loss: 6.11151
Saved Losses
{'MSE - mean': 5.967033872379179, 'MSE - std': 0.4746659172582572, 'R2 - mean': 0.413855982561292, 'R2 - std': 0.009515304539979647} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.67967
Epoch 1, Val Loss: 6.22190
Epoch 2, Val Loss: 6.17835
Epoch 3, Val Loss: 7.07915
Epoch 4, Val Loss: 5.84721
Epoch 5, Val Loss: 6.33375
Epoch 6, Val Loss: 5.60590
Epoch 7, Val Loss: 5.75990
Epoch 8, Val Loss: 6.05283
Epoch 9, Val Loss: 5.80616
Epoch 10, Val Loss: 5.72014
Epoch 11, Val Loss: 5.76559
Epoch 12, Val Loss: 5.56528
Epoch 13, Val Loss: 6.27440
Epoch 14, Val Loss: 5.83586
Epoch 15, Val Loss: 5.96130
Epoch 16, Val Loss: 5.74886
Epoch 17, Val Loss: 5.52957
Epoch 18, Val Loss: 5.65996
Epoch 19, Val Loss: 5.55659
Epoch 20, Val Loss: 5.96905
Epoch 21, Val Loss: 5.69867
Epoch 22, Val Loss: 5.56455
Epoch 23, Val Loss: 5.50676
Epoch 24, Val Loss: 6.56856
Epoch 25, Val Loss: 6.14228
Epoch 26, Val Loss: 6.21686
Epoch 27, Val Loss: 5.76124
Epoch 28, Val Loss: 5.64013
Epoch 29, Val Loss: 5.48941
Epoch 30, Val Loss: 6.00469
Epoch 31, Val Loss: 5.76147
Epoch 32, Val Loss: 5.85861
Epoch 33, Val Loss: 5.33197
Epoch 34, Val Loss: 5.35263
Epoch 35, Val Loss: 5.62141
Epoch 36, Val Loss: 5.77416
Epoch 37, Val Loss: 5.62413
Epoch 38, Val Loss: 5.55030
Epoch 39, Val Loss: 6.00685
Epoch 40, Val Loss: 5.70189
Epoch 41, Val Loss: 5.43091
Epoch 42, Val Loss: 5.50967
Epoch 43, Val Loss: 5.73795
Epoch 44, Val Loss: 5.25703
Epoch 45, Val Loss: 5.58405
Epoch 46, Val Loss: 5.86880
Epoch 47, Val Loss: 5.48454
Epoch 48, Val Loss: 5.42599
Epoch 49, Val Loss: 5.57676
Epoch 50, Val Loss: 5.76103
Epoch 51, Val Loss: 5.30567
Epoch 52, Val Loss: 5.35688
Epoch 53, Val Loss: 5.54138
Epoch 54, Val Loss: 5.72631
Epoch 55, Val Loss: 5.28451
Epoch 56, Val Loss: 5.87607
Epoch 57, Val Loss: 5.59231
Epoch 58, Val Loss: 5.41744
Epoch 59, Val Loss: 5.91199
Epoch 60, Val Loss: 5.32518
Epoch 61, Val Loss: 5.31476
Epoch 62, Val Loss: 5.39840
Epoch 63, Val Loss: 5.79627
Epoch 64, Val Loss: 5.45105
Epoch 65, Val Loss: 5.78649
Early stopping applies.
Saved Losses
{'MSE - mean': 5.903507351092169, 'MSE - std': 0.42554395363517256, 'R2 - mean': 0.4076847010505845, 'R2 - std': 0.013496662988295225} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.25272
Epoch 1, Val Loss: 11.73945
Epoch 2, Val Loss: 8.89835
Epoch 3, Val Loss: 8.29368
Epoch 4, Val Loss: 8.29405
Epoch 5, Val Loss: 8.69936
Epoch 6, Val Loss: 8.17949
Epoch 7, Val Loss: 8.78496
Epoch 8, Val Loss: 8.38682
Epoch 9, Val Loss: 8.31001
Epoch 10, Val Loss: 8.52678
Epoch 11, Val Loss: 8.49629
Epoch 12, Val Loss: 8.56950
Epoch 13, Val Loss: 8.66605
Epoch 14, Val Loss: 7.85099
Epoch 15, Val Loss: 7.83926
Epoch 16, Val Loss: 8.64895
Epoch 17, Val Loss: 8.68095
Epoch 18, Val Loss: 8.17021
Epoch 19, Val Loss: 8.75077
Epoch 20, Val Loss: 8.05124
Epoch 21, Val Loss: 7.98166
Epoch 22, Val Loss: 8.15611
Epoch 23, Val Loss: 8.49745
Epoch 24, Val Loss: 8.75456
Epoch 25, Val Loss: 8.71114
Epoch 26, Val Loss: 7.97748
Epoch 27, Val Loss: 8.39024
Epoch 28, Val Loss: 8.15372
Epoch 29, Val Loss: 8.33792
Epoch 30, Val Loss: 8.51303
Epoch 31, Val Loss: 7.83241
Epoch 32, Val Loss: 8.13641
Epoch 33, Val Loss: 7.96330
Epoch 34, Val Loss: 8.20711
Epoch 35, Val Loss: 8.12638
Epoch 36, Val Loss: 8.19269
Epoch 37, Val Loss: 7.83269
Epoch 38, Val Loss: 8.21061
Epoch 39, Val Loss: 7.90206
Epoch 40, Val Loss: 8.16208
Epoch 41, Val Loss: 7.73055
Epoch 42, Val Loss: 8.15077
Epoch 43, Val Loss: 7.66200
Epoch 44, Val Loss: 8.40345
Epoch 45, Val Loss: 8.27600
Epoch 46, Val Loss: 8.44941
Epoch 47, Val Loss: 7.77842
Epoch 48, Val Loss: 8.97369
Epoch 49, Val Loss: 7.69010
Epoch 50, Val Loss: 8.28581
Epoch 51, Val Loss: 7.45115
Epoch 52, Val Loss: 8.04235
Epoch 53, Val Loss: 7.93615
Epoch 54, Val Loss: 7.89303
Epoch 55, Val Loss: 7.92245
Epoch 56, Val Loss: 7.99521
Epoch 57, Val Loss: 7.61461
Epoch 58, Val Loss: 8.06242
Epoch 59, Val Loss: 7.88624
Epoch 60, Val Loss: 7.97733
Epoch 61, Val Loss: 7.64440
Epoch 62, Val Loss: 8.05920
Epoch 63, Val Loss: 7.89807
Epoch 64, Val Loss: 7.92112
Epoch 65, Val Loss: 7.92198
Epoch 66, Val Loss: 7.59013
Epoch 67, Val Loss: 7.74517
Epoch 68, Val Loss: 7.69446
Epoch 69, Val Loss: 8.27131
Epoch 70, Val Loss: 7.54088
Epoch 71, Val Loss: 7.75887
Epoch 72, Val Loss: 7.87594
Early stopping applies.
Saved Losses
{'MSE - mean': 6.2180184422996865, 'MSE - std': 0.7352135955969101, 'R2 - mean': 0.4024941530904839, 'R2 - std': 0.015921528882620262} 
 

Results After CV: {'MSE - mean': 6.2180184422996865, 'MSE - std': 0.7352135955969101, 'R2 - mean': 0.4024941530904839, 'R2 - std': 0.015921528882620262}
Train time: 82.06092458040003
Inference time: 0.0546998704001453
Finished cross validation
Trial 14 finished with value: 6.2180184422996865 and parameters: {'p_m': 0.2651624187933001, 'alpha': 7.384992856737775, 'K': 15, 'beta': 9.920799102743363}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 41.45127
Epoch 1, Val Loss: 14.24498
Epoch 2, Val Loss: 7.87506
Epoch 3, Val Loss: 7.47171
Epoch 4, Val Loss: 8.04169
Epoch 5, Val Loss: 7.46684
Epoch 6, Val Loss: 7.01544
Epoch 7, Val Loss: 6.81177
Epoch 8, Val Loss: 6.84125
Epoch 9, Val Loss: 6.63028
Epoch 10, Val Loss: 6.65006
Epoch 11, Val Loss: 6.44823
Epoch 12, Val Loss: 6.69209
Epoch 13, Val Loss: 6.34598
Epoch 14, Val Loss: 6.29644
Epoch 15, Val Loss: 6.35570
Epoch 16, Val Loss: 6.26809
Epoch 17, Val Loss: 6.41619
Epoch 18, Val Loss: 6.27144
Epoch 19, Val Loss: 6.42955
Epoch 20, Val Loss: 6.23610
Epoch 21, Val Loss: 6.11867
Epoch 22, Val Loss: 6.15334
Epoch 23, Val Loss: 6.19246
Epoch 24, Val Loss: 6.24089
Epoch 25, Val Loss: 6.20004
Epoch 26, Val Loss: 6.01212
Epoch 27, Val Loss: 6.30417
Epoch 28, Val Loss: 5.95821
Epoch 29, Val Loss: 6.04580
Epoch 30, Val Loss: 6.20383
Epoch 31, Val Loss: 5.95249
Epoch 32, Val Loss: 5.92451
Epoch 33, Val Loss: 6.00465
Epoch 34, Val Loss: 6.11877
Epoch 35, Val Loss: 5.78114
Epoch 36, Val Loss: 5.97211
Epoch 37, Val Loss: 5.87663
Epoch 38, Val Loss: 5.95170
Epoch 39, Val Loss: 5.83493
Epoch 40, Val Loss: 5.93996
Epoch 41, Val Loss: 5.73680
Epoch 42, Val Loss: 5.74636
Epoch 43, Val Loss: 5.62691
Epoch 44, Val Loss: 5.52010
Epoch 45, Val Loss: 5.98081
Epoch 46, Val Loss: 5.46103
Epoch 47, Val Loss: 5.48230
Epoch 48, Val Loss: 5.29556
Epoch 49, Val Loss: 5.38170
Epoch 50, Val Loss: 5.47677
Epoch 51, Val Loss: 5.25519
Epoch 52, Val Loss: 5.30832
Epoch 53, Val Loss: 5.32043
Epoch 54, Val Loss: 5.52644
Epoch 55, Val Loss: 5.29342
Epoch 56, Val Loss: 5.52412
Epoch 57, Val Loss: 5.16602
Epoch 58, Val Loss: 5.27852
Epoch 59, Val Loss: 5.11992
Epoch 60, Val Loss: 5.13746
Epoch 61, Val Loss: 5.20084
Epoch 62, Val Loss: 5.03719
Epoch 63, Val Loss: 5.31916
Epoch 64, Val Loss: 5.07877
Epoch 65, Val Loss: 5.59371
Epoch 66, Val Loss: 5.45134
Epoch 67, Val Loss: 5.11742
Epoch 68, Val Loss: 5.12260
Epoch 69, Val Loss: 5.50393
Epoch 70, Val Loss: 5.36974
Epoch 71, Val Loss: 5.08349
Epoch 72, Val Loss: 5.03111
Epoch 73, Val Loss: 4.95819
Epoch 74, Val Loss: 4.85284
Epoch 75, Val Loss: 5.24359
Epoch 76, Val Loss: 5.13847
Epoch 77, Val Loss: 5.38598
Epoch 78, Val Loss: 5.31184
Epoch 79, Val Loss: 5.03430
Epoch 80, Val Loss: 5.07124
Epoch 81, Val Loss: 4.97295
Epoch 82, Val Loss: 4.99774
Epoch 83, Val Loss: 5.10680
Epoch 84, Val Loss: 5.23501
Epoch 85, Val Loss: 5.49004
Epoch 86, Val Loss: 5.06281
Epoch 87, Val Loss: 5.63474
Epoch 88, Val Loss: 5.06302
Epoch 89, Val Loss: 4.79566
Epoch 90, Val Loss: 5.21424
Epoch 91, Val Loss: 5.12032
Epoch 92, Val Loss: 4.96254
Epoch 93, Val Loss: 5.03947
Epoch 94, Val Loss: 5.34824
Epoch 95, Val Loss: 4.75642
Epoch 96, Val Loss: 5.51990
Epoch 97, Val Loss: 4.87725
Epoch 98, Val Loss: 4.94142
Epoch 99, Val Loss: 4.94030
Saved Losses
{'MSE - mean': 4.892154026495616, 'MSE - std': 0.0, 'R2 - mean': 0.5538517181389191, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.77738
Epoch 1, Val Loss: 7.00894
Epoch 2, Val Loss: 5.71819
Epoch 3, Val Loss: 5.29251
Epoch 4, Val Loss: 5.26007
Epoch 5, Val Loss: 5.49672
Epoch 6, Val Loss: 5.03388
Epoch 7, Val Loss: 5.26829
Epoch 8, Val Loss: 5.17164
Epoch 9, Val Loss: 4.95822
Epoch 10, Val Loss: 5.03877
Epoch 11, Val Loss: 5.13395
Epoch 12, Val Loss: 5.53680
Epoch 13, Val Loss: 4.98912
Epoch 14, Val Loss: 4.91529
Epoch 15, Val Loss: 4.83632
Epoch 16, Val Loss: 4.89685
Epoch 17, Val Loss: 4.79282
Epoch 18, Val Loss: 4.83542
Epoch 19, Val Loss: 5.08082
Epoch 20, Val Loss: 5.00254
Epoch 21, Val Loss: 4.72291
Epoch 22, Val Loss: 4.75348
Epoch 23, Val Loss: 4.76418
Epoch 24, Val Loss: 4.65652
Epoch 25, Val Loss: 4.79144
Epoch 26, Val Loss: 4.60239
Epoch 27, Val Loss: 4.55144
Epoch 28, Val Loss: 4.60139
Epoch 29, Val Loss: 4.60512
Epoch 30, Val Loss: 4.54555
Epoch 31, Val Loss: 4.91429
Epoch 32, Val Loss: 4.49190
Epoch 33, Val Loss: 4.36221
Epoch 34, Val Loss: 4.50288
Epoch 35, Val Loss: 4.56863
Epoch 36, Val Loss: 4.65126
Epoch 37, Val Loss: 4.60162
Epoch 38, Val Loss: 4.35314
Epoch 39, Val Loss: 4.36500
Epoch 40, Val Loss: 4.55794
Epoch 41, Val Loss: 4.80017
Epoch 42, Val Loss: 4.39383
Epoch 43, Val Loss: 4.21541
Epoch 44, Val Loss: 4.26668
Epoch 45, Val Loss: 4.41709
Epoch 46, Val Loss: 4.42929
Epoch 47, Val Loss: 4.22738
Epoch 48, Val Loss: 4.12265
Epoch 49, Val Loss: 4.30543
Epoch 50, Val Loss: 4.19659
Epoch 51, Val Loss: 4.22429
Epoch 52, Val Loss: 4.07641
Epoch 53, Val Loss: 4.20288
Epoch 54, Val Loss: 4.96309
Epoch 55, Val Loss: 4.59022
Epoch 56, Val Loss: 4.18789
Epoch 57, Val Loss: 4.02965
Epoch 58, Val Loss: 4.02195
Epoch 59, Val Loss: 4.10717
Epoch 60, Val Loss: 4.06423
Epoch 61, Val Loss: 4.30433
Epoch 62, Val Loss: 4.37778
Epoch 63, Val Loss: 4.24955
Epoch 64, Val Loss: 4.49981
Epoch 65, Val Loss: 4.14937
Epoch 66, Val Loss: 4.05409
Epoch 67, Val Loss: 4.26409
Epoch 68, Val Loss: 4.01173
Epoch 69, Val Loss: 4.12868
Epoch 70, Val Loss: 4.08194
Epoch 71, Val Loss: 4.01013
Epoch 72, Val Loss: 4.18545
Epoch 73, Val Loss: 4.09596
Epoch 74, Val Loss: 4.22360
Epoch 75, Val Loss: 3.96708
Epoch 76, Val Loss: 4.14472
Epoch 77, Val Loss: 4.01462
Epoch 78, Val Loss: 4.04332
Epoch 79, Val Loss: 4.04755
Epoch 80, Val Loss: 3.91077
Epoch 81, Val Loss: 3.96107
Epoch 82, Val Loss: 4.41028
Epoch 83, Val Loss: 4.08609
Epoch 84, Val Loss: 4.00493
Epoch 85, Val Loss: 5.26875
Epoch 86, Val Loss: 4.11122
Epoch 87, Val Loss: 4.03034
Epoch 88, Val Loss: 4.26875
Epoch 89, Val Loss: 3.88797
Epoch 90, Val Loss: 4.70537
Epoch 91, Val Loss: 5.42482
Epoch 92, Val Loss: 3.95994
Epoch 93, Val Loss: 4.24473
Epoch 94, Val Loss: 4.08056
Epoch 95, Val Loss: 4.03141
Epoch 96, Val Loss: 4.00131
Epoch 97, Val Loss: 4.06881
Epoch 98, Val Loss: 3.93502
Epoch 99, Val Loss: 3.89124
Saved Losses
{'MSE - mean': 4.504737240261868, 'MSE - std': 0.38741678623374787, 'R2 - mean': 0.5574797528680453, 'R2 - std': 0.0036280347291261505} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.75788
Epoch 1, Val Loss: 15.95654
Epoch 2, Val Loss: 6.00795
Epoch 3, Val Loss: 5.94838
Epoch 4, Val Loss: 6.08536
Epoch 5, Val Loss: 6.21112
Epoch 6, Val Loss: 5.76337
Epoch 7, Val Loss: 5.80965
Epoch 8, Val Loss: 5.70220
Epoch 9, Val Loss: 5.74028
Epoch 10, Val Loss: 6.33010
Epoch 11, Val Loss: 5.59821
Epoch 12, Val Loss: 5.85102
Epoch 13, Val Loss: 5.73126
Epoch 14, Val Loss: 5.62903
Epoch 15, Val Loss: 5.66436
Epoch 16, Val Loss: 5.59144
Epoch 17, Val Loss: 5.60921
Epoch 18, Val Loss: 5.56347
Epoch 19, Val Loss: 5.59934
Epoch 20, Val Loss: 5.50938
Epoch 21, Val Loss: 5.48723
Epoch 22, Val Loss: 5.50905
Epoch 23, Val Loss: 5.47756
Epoch 24, Val Loss: 5.45936
Epoch 25, Val Loss: 5.43560
Epoch 26, Val Loss: 5.66236
Epoch 27, Val Loss: 5.60547
Epoch 28, Val Loss: 6.03066
Epoch 29, Val Loss: 5.61852
Epoch 30, Val Loss: 5.36470
Epoch 31, Val Loss: 5.41548
Epoch 32, Val Loss: 5.37579
Epoch 33, Val Loss: 5.37664
Epoch 34, Val Loss: 5.50370
Epoch 35, Val Loss: 5.60392
Epoch 36, Val Loss: 5.55788
Epoch 37, Val Loss: 5.62016
Epoch 38, Val Loss: 5.28140
Epoch 39, Val Loss: 5.47641
Epoch 40, Val Loss: 5.36873
Epoch 41, Val Loss: 5.29989
Epoch 42, Val Loss: 5.21900
Epoch 43, Val Loss: 5.28325
Epoch 44, Val Loss: 5.34956
Epoch 45, Val Loss: 5.51159
Epoch 46, Val Loss: 5.23902
Epoch 47, Val Loss: 5.32532
Epoch 48, Val Loss: 5.32792
Epoch 49, Val Loss: 5.46841
Epoch 50, Val Loss: 5.38296
Epoch 51, Val Loss: 5.16551
Epoch 52, Val Loss: 5.45709
Epoch 53, Val Loss: 5.27950
Epoch 54, Val Loss: 5.29248
Epoch 55, Val Loss: 5.33700
Epoch 56, Val Loss: 5.24062
Epoch 57, Val Loss: 5.21389
Epoch 58, Val Loss: 5.11883
Epoch 59, Val Loss: 5.39343
Epoch 60, Val Loss: 5.16649
Epoch 61, Val Loss: 5.09436
Epoch 62, Val Loss: 5.42426
Epoch 63, Val Loss: 5.28844
Epoch 64, Val Loss: 5.17778
Epoch 65, Val Loss: 5.21464
Epoch 66, Val Loss: 5.39151
Epoch 67, Val Loss: 5.14589
Epoch 68, Val Loss: 5.12678
Epoch 69, Val Loss: 5.15860
Epoch 70, Val Loss: 5.59311
Epoch 71, Val Loss: 5.22720
Epoch 72, Val Loss: 5.10064
Epoch 73, Val Loss: 5.49861
Epoch 74, Val Loss: 5.05772
Epoch 75, Val Loss: 5.10402
Epoch 76, Val Loss: 5.43403
Epoch 77, Val Loss: 5.20872
Epoch 78, Val Loss: 5.25874
Epoch 79, Val Loss: 5.34135
Epoch 80, Val Loss: 5.08403
Epoch 81, Val Loss: 5.23901
Epoch 82, Val Loss: 5.21360
Epoch 83, Val Loss: 5.29899
Epoch 84, Val Loss: 5.32496
Epoch 85, Val Loss: 5.18015
Epoch 86, Val Loss: 5.33074
Epoch 87, Val Loss: 5.13593
Epoch 88, Val Loss: 5.11332
Epoch 89, Val Loss: 5.01709
Epoch 90, Val Loss: 5.31094
Epoch 91, Val Loss: 4.99364
Epoch 92, Val Loss: 5.13927
Epoch 93, Val Loss: 5.27908
Epoch 94, Val Loss: 5.12447
Epoch 95, Val Loss: 5.21715
Epoch 96, Val Loss: 5.07321
Epoch 97, Val Loss: 5.08760
Epoch 98, Val Loss: 5.09956
Epoch 99, Val Loss: 4.98301
Saved Losses
{'MSE - mean': 4.707191377307221, 'MSE - std': 0.4266573950107358, 'R2 - mean': 0.5373118596931507, 'R2 - std': 0.028675127216662107} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.48249
Epoch 1, Val Loss: 9.49239
Epoch 2, Val Loss: 7.20580
Epoch 3, Val Loss: 5.56421
Epoch 4, Val Loss: 5.22853
Epoch 5, Val Loss: 5.25470
Epoch 6, Val Loss: 5.17271
Epoch 7, Val Loss: 5.10647
Epoch 8, Val Loss: 5.16357
Epoch 9, Val Loss: 5.21591
Epoch 10, Val Loss: 5.14661
Epoch 11, Val Loss: 5.06641
Epoch 12, Val Loss: 5.02812
Epoch 13, Val Loss: 5.06750
Epoch 14, Val Loss: 4.98303
Epoch 15, Val Loss: 5.00045
Epoch 16, Val Loss: 4.95647
Epoch 17, Val Loss: 5.44867
Epoch 18, Val Loss: 4.97953
Epoch 19, Val Loss: 5.01747
Epoch 20, Val Loss: 4.96247
Epoch 21, Val Loss: 5.10988
Epoch 22, Val Loss: 4.76225
Epoch 23, Val Loss: 4.69572
Epoch 24, Val Loss: 4.72414
Epoch 25, Val Loss: 4.73431
Epoch 26, Val Loss: 4.88934
Epoch 27, Val Loss: 4.61072
Epoch 28, Val Loss: 4.82377
Epoch 29, Val Loss: 4.63125
Epoch 30, Val Loss: 4.56119
Epoch 31, Val Loss: 4.71520
Epoch 32, Val Loss: 4.60267
Epoch 33, Val Loss: 4.89516
Epoch 34, Val Loss: 4.64273
Epoch 35, Val Loss: 4.77586
Epoch 36, Val Loss: 4.44326
Epoch 37, Val Loss: 4.51359
Epoch 38, Val Loss: 4.77003
Epoch 39, Val Loss: 4.36195
Epoch 40, Val Loss: 4.54335
Epoch 41, Val Loss: 4.41308
Epoch 42, Val Loss: 4.40136
Epoch 43, Val Loss: 4.57183
Epoch 44, Val Loss: 4.33005
Epoch 45, Val Loss: 4.36481
Epoch 46, Val Loss: 4.56052
Epoch 47, Val Loss: 4.53490
Epoch 48, Val Loss: 4.34512
Epoch 49, Val Loss: 4.56129
Epoch 50, Val Loss: 4.56128
Epoch 51, Val Loss: 4.54059
Epoch 52, Val Loss: 4.47846
Epoch 53, Val Loss: 4.35421
Epoch 54, Val Loss: 4.44032
Epoch 55, Val Loss: 4.47400
Epoch 56, Val Loss: 4.29414
Epoch 57, Val Loss: 4.53153
Epoch 58, Val Loss: 4.36490
Epoch 59, Val Loss: 4.29524
Epoch 60, Val Loss: 4.33806
Epoch 61, Val Loss: 4.22838
Epoch 62, Val Loss: 4.63595
Epoch 63, Val Loss: 4.21677
Epoch 64, Val Loss: 4.25250
Epoch 65, Val Loss: 4.51700
Epoch 66, Val Loss: 4.21733
Epoch 67, Val Loss: 4.47952
Epoch 68, Val Loss: 4.27377
Epoch 69, Val Loss: 4.21120
Epoch 70, Val Loss: 4.43882
Epoch 71, Val Loss: 4.39021
Epoch 72, Val Loss: 4.32152
Epoch 73, Val Loss: 4.30497
Epoch 74, Val Loss: 4.35619
Epoch 75, Val Loss: 4.31716
Epoch 76, Val Loss: 4.10484
Epoch 77, Val Loss: 4.26776
Epoch 78, Val Loss: 4.21195
Epoch 79, Val Loss: 4.26675
Epoch 80, Val Loss: 4.31764
Epoch 81, Val Loss: 4.23060
Epoch 82, Val Loss: 4.28294
Epoch 83, Val Loss: 4.22064
Epoch 84, Val Loss: 4.20879
Epoch 85, Val Loss: 4.15151
Epoch 86, Val Loss: 4.51412
Epoch 87, Val Loss: 4.27401
Epoch 88, Val Loss: 4.46276
Epoch 89, Val Loss: 4.17144
Epoch 90, Val Loss: 4.20283
Epoch 91, Val Loss: 4.20627
Epoch 92, Val Loss: 4.35400
Epoch 93, Val Loss: 4.15369
Epoch 94, Val Loss: 4.09208
Epoch 95, Val Loss: 4.69928
Epoch 96, Val Loss: 4.26609
Epoch 97, Val Loss: 4.26587
Epoch 98, Val Loss: 4.12743
Epoch 99, Val Loss: 4.09856
Saved Losses
{'MSE - mean': 4.622836454865341, 'MSE - std': 0.397334441445159, 'R2 - mean': 0.5361793421604462, 'R2 - std': 0.024910740224940435} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.81849
Epoch 1, Val Loss: 14.50023
Epoch 2, Val Loss: 10.35868
Epoch 3, Val Loss: 7.76001
Epoch 4, Val Loss: 7.15848
Epoch 5, Val Loss: 7.15730
Epoch 6, Val Loss: 7.25922
Epoch 7, Val Loss: 7.42517
Epoch 8, Val Loss: 7.30710
Epoch 9, Val Loss: 7.32107
Epoch 10, Val Loss: 7.08849
Epoch 11, Val Loss: 7.09439
Epoch 12, Val Loss: 6.98194
Epoch 13, Val Loss: 6.92086
Epoch 14, Val Loss: 7.18225
Epoch 15, Val Loss: 6.72923
Epoch 16, Val Loss: 6.79119
Epoch 17, Val Loss: 6.64629
Epoch 18, Val Loss: 6.74074
Epoch 19, Val Loss: 6.60491
Epoch 20, Val Loss: 7.04153
Epoch 21, Val Loss: 6.86829
Epoch 22, Val Loss: 6.48182
Epoch 23, Val Loss: 6.57153
Epoch 24, Val Loss: 6.55879
Epoch 25, Val Loss: 6.61170
Epoch 26, Val Loss: 6.67403
Epoch 27, Val Loss: 6.35193
Epoch 28, Val Loss: 7.07832
Epoch 29, Val Loss: 6.29412
Epoch 30, Val Loss: 6.13273
Epoch 31, Val Loss: 6.20497
Epoch 32, Val Loss: 6.25124
Epoch 33, Val Loss: 6.10744
Epoch 34, Val Loss: 6.29819
Epoch 35, Val Loss: 6.42178
Epoch 36, Val Loss: 6.27037
Epoch 37, Val Loss: 6.45424
Epoch 38, Val Loss: 6.15422
Epoch 39, Val Loss: 6.31739
Epoch 40, Val Loss: 6.32771
Epoch 41, Val Loss: 6.43471
Epoch 42, Val Loss: 6.14675
Epoch 43, Val Loss: 6.16328
Epoch 44, Val Loss: 6.22730
Epoch 45, Val Loss: 6.06321
Epoch 46, Val Loss: 6.09496
Epoch 47, Val Loss: 6.49222
Epoch 48, Val Loss: 6.08172
Epoch 49, Val Loss: 6.27752
Epoch 50, Val Loss: 6.78546
Epoch 51, Val Loss: 6.19828
Epoch 52, Val Loss: 6.09944
Epoch 53, Val Loss: 6.25252
Epoch 54, Val Loss: 6.08871
Epoch 55, Val Loss: 5.96002
Epoch 56, Val Loss: 6.53837
Epoch 57, Val Loss: 5.99089
Epoch 58, Val Loss: 6.03281
Epoch 59, Val Loss: 5.90834
Epoch 60, Val Loss: 6.38244
Epoch 61, Val Loss: 6.04560
Epoch 62, Val Loss: 5.85935
Epoch 63, Val Loss: 6.34327
Epoch 64, Val Loss: 6.02477
Epoch 65, Val Loss: 6.27708
Epoch 66, Val Loss: 5.96354
Epoch 67, Val Loss: 6.27131
Epoch 68, Val Loss: 5.93820
Epoch 69, Val Loss: 5.94232
Epoch 70, Val Loss: 6.06105
Epoch 71, Val Loss: 6.11531
Epoch 72, Val Loss: 5.88871
Epoch 73, Val Loss: 6.14959
Epoch 74, Val Loss: 6.55240
Epoch 75, Val Loss: 6.34747
Epoch 76, Val Loss: 6.26614
Epoch 77, Val Loss: 5.87478
Epoch 78, Val Loss: 5.75818
Epoch 79, Val Loss: 5.99506
Epoch 80, Val Loss: 5.95385
Epoch 81, Val Loss: 5.91058
Epoch 82, Val Loss: 6.04404
Epoch 83, Val Loss: 5.90002
Epoch 84, Val Loss: 6.04307
Epoch 85, Val Loss: 5.91408
Epoch 86, Val Loss: 5.87704
Epoch 87, Val Loss: 6.10804
Epoch 88, Val Loss: 6.19539
Epoch 89, Val Loss: 6.23769
Epoch 90, Val Loss: 5.85430
Epoch 91, Val Loss: 5.95954
Epoch 92, Val Loss: 5.89126
Epoch 93, Val Loss: 6.10534
Epoch 94, Val Loss: 5.97944
Epoch 95, Val Loss: 5.85135
Epoch 96, Val Loss: 5.94764
Epoch 97, Val Loss: 5.95998
Epoch 98, Val Loss: 5.86282
Epoch 99, Val Loss: 5.79903
Early stopping applies.
Saved Losses
{'MSE - mean': 4.829543967908213, 'MSE - std': 0.5451712671081498, 'R2 - mean': 0.5353874038543717, 'R2 - std': 0.02233706892065485} 
 

Results After CV: {'MSE - mean': 4.829543967908213, 'MSE - std': 0.5451712671081498, 'R2 - mean': 0.5353874038543717, 'R2 - std': 0.02233706892065485}
Train time: 28.38567151419993
Inference time: 0.050341160000061794
Finished cross validation
Trial 15 finished with value: 4.829543967908213 and parameters: {'p_m': 0.42946034533185884, 'alpha': 4.80387322934304, 'K': 2, 'beta': 1.1970781831283466}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.84039
Epoch 1, Val Loss: 11.42627
Epoch 2, Val Loss: 8.68389
Epoch 3, Val Loss: 7.39848
Epoch 4, Val Loss: 7.02625
Epoch 5, Val Loss: 7.01678
Epoch 6, Val Loss: 6.83214
Epoch 7, Val Loss: 6.81738
Epoch 8, Val Loss: 6.66292
Epoch 9, Val Loss: 6.54290
Epoch 10, Val Loss: 6.34136
Epoch 11, Val Loss: 6.59906
Epoch 12, Val Loss: 6.16155
Epoch 13, Val Loss: 6.22908
Epoch 14, Val Loss: 6.30317
Epoch 15, Val Loss: 6.53628
Epoch 16, Val Loss: 6.37603
Epoch 17, Val Loss: 6.16182
Epoch 18, Val Loss: 6.23364
Epoch 19, Val Loss: 6.19393
Epoch 20, Val Loss: 6.07825
Epoch 21, Val Loss: 6.34988
Epoch 22, Val Loss: 6.39958
Epoch 23, Val Loss: 6.19596
Epoch 24, Val Loss: 6.08403
Epoch 25, Val Loss: 6.09510
Epoch 26, Val Loss: 6.05695
Epoch 27, Val Loss: 5.90814
Epoch 28, Val Loss: 6.02180
Epoch 29, Val Loss: 6.52767
Epoch 30, Val Loss: 5.96699
Epoch 31, Val Loss: 6.07787
Epoch 32, Val Loss: 5.95699
Epoch 33, Val Loss: 5.91112
Epoch 34, Val Loss: 6.09062
Epoch 35, Val Loss: 5.92336
Epoch 36, Val Loss: 5.90204
Epoch 37, Val Loss: 5.92581
Epoch 38, Val Loss: 6.20205
Epoch 39, Val Loss: 6.01409
Epoch 40, Val Loss: 5.76139
Epoch 41, Val Loss: 5.99282
Epoch 42, Val Loss: 5.94855
Epoch 43, Val Loss: 6.26169
Epoch 44, Val Loss: 5.78349
Epoch 45, Val Loss: 5.76981
Epoch 46, Val Loss: 6.11389
Epoch 47, Val Loss: 5.73098
Epoch 48, Val Loss: 5.75454
Epoch 49, Val Loss: 5.75353
Epoch 50, Val Loss: 5.95429
Epoch 51, Val Loss: 5.71253
Epoch 52, Val Loss: 5.83335
Epoch 53, Val Loss: 5.72080
Epoch 54, Val Loss: 5.66247
Epoch 55, Val Loss: 5.78890
Epoch 56, Val Loss: 6.01760
Epoch 57, Val Loss: 5.79136
Epoch 58, Val Loss: 5.83361
Epoch 59, Val Loss: 5.76378
Epoch 60, Val Loss: 6.03252
Epoch 61, Val Loss: 5.69894
Epoch 62, Val Loss: 5.76814
Epoch 63, Val Loss: 6.23992
Epoch 64, Val Loss: 5.77632
Epoch 65, Val Loss: 5.77695
Epoch 66, Val Loss: 5.86583
Epoch 67, Val Loss: 5.86585
Epoch 68, Val Loss: 5.67755
Epoch 69, Val Loss: 5.68804
Epoch 70, Val Loss: 5.78639
Epoch 71, Val Loss: 5.72793
Epoch 72, Val Loss: 5.88556
Epoch 73, Val Loss: 5.74544
Epoch 74, Val Loss: 5.89668
Epoch 75, Val Loss: 5.61149
Epoch 76, Val Loss: 6.11828
Epoch 77, Val Loss: 5.62370
Epoch 78, Val Loss: 5.65215
Epoch 79, Val Loss: 5.57488
Epoch 80, Val Loss: 5.51989
Epoch 81, Val Loss: 5.89791
Epoch 82, Val Loss: 5.75592
Epoch 83, Val Loss: 5.66937
Epoch 84, Val Loss: 5.82674
Epoch 85, Val Loss: 5.85139
Epoch 86, Val Loss: 5.73343
Epoch 87, Val Loss: 5.45359
Epoch 88, Val Loss: 5.51055
Epoch 89, Val Loss: 5.61008
Epoch 90, Val Loss: 5.43501
Epoch 91, Val Loss: 5.68180
Epoch 92, Val Loss: 5.48494
Epoch 93, Val Loss: 5.49108
Epoch 94, Val Loss: 5.67030
Epoch 95, Val Loss: 5.81905
Epoch 96, Val Loss: 5.70139
Epoch 97, Val Loss: 5.44616
Epoch 98, Val Loss: 5.37593
Epoch 99, Val Loss: 5.45221
Saved Losses
{'MSE - mean': 5.565729258624352, 'MSE - std': 0.0, 'R2 - mean': 0.49242388269243764, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.37899
Epoch 1, Val Loss: 8.65079
Epoch 2, Val Loss: 6.42229
Epoch 3, Val Loss: 5.93147
Epoch 4, Val Loss: 6.27545
Epoch 5, Val Loss: 6.03828
Epoch 6, Val Loss: 5.32294
Epoch 7, Val Loss: 5.38521
Epoch 8, Val Loss: 5.24878
Epoch 9, Val Loss: 5.39881
Epoch 10, Val Loss: 5.32221
Epoch 11, Val Loss: 5.15304
Epoch 12, Val Loss: 5.60508
Epoch 13, Val Loss: 5.13155
Epoch 14, Val Loss: 5.20984
Epoch 15, Val Loss: 5.09696
Epoch 16, Val Loss: 5.09635
Epoch 17, Val Loss: 5.05361
Epoch 18, Val Loss: 4.95415
Epoch 19, Val Loss: 4.99911
Epoch 20, Val Loss: 5.02022
Epoch 21, Val Loss: 4.98920
Epoch 22, Val Loss: 5.13229
Epoch 23, Val Loss: 4.94871
Epoch 24, Val Loss: 4.91661
Epoch 25, Val Loss: 5.20953
Epoch 26, Val Loss: 4.96833
Epoch 27, Val Loss: 4.94231
Epoch 28, Val Loss: 5.12708
Epoch 29, Val Loss: 5.06568
Epoch 30, Val Loss: 4.96140
Epoch 31, Val Loss: 5.02054
Epoch 32, Val Loss: 4.89716
Epoch 33, Val Loss: 4.98747
Epoch 34, Val Loss: 4.90816
Epoch 35, Val Loss: 4.84664
Epoch 36, Val Loss: 4.85973
Epoch 37, Val Loss: 5.07576
Epoch 38, Val Loss: 5.11433
Epoch 39, Val Loss: 5.27166
Epoch 40, Val Loss: 4.87579
Epoch 41, Val Loss: 5.76941
Epoch 42, Val Loss: 4.81788
Epoch 43, Val Loss: 4.85041
Epoch 44, Val Loss: 5.12747
Epoch 45, Val Loss: 4.78381
Epoch 46, Val Loss: 5.19940
Epoch 47, Val Loss: 4.87933
Epoch 48, Val Loss: 5.37284
Epoch 49, Val Loss: 4.94888
Epoch 50, Val Loss: 4.87644
Epoch 51, Val Loss: 5.06871
Epoch 52, Val Loss: 4.81636
Epoch 53, Val Loss: 5.25733
Epoch 54, Val Loss: 4.74164
Epoch 55, Val Loss: 4.98150
Epoch 56, Val Loss: 4.98500
Epoch 57, Val Loss: 5.04935
Epoch 58, Val Loss: 4.80094
Epoch 59, Val Loss: 4.89955
Epoch 60, Val Loss: 5.06948
Epoch 61, Val Loss: 4.84338
Epoch 62, Val Loss: 5.05137
Epoch 63, Val Loss: 5.27097
Epoch 64, Val Loss: 4.81967
Epoch 65, Val Loss: 4.87559
Epoch 66, Val Loss: 5.26033
Epoch 67, Val Loss: 4.89079
Epoch 68, Val Loss: 4.68708
Epoch 69, Val Loss: 4.85852
Epoch 70, Val Loss: 4.80797
Epoch 71, Val Loss: 4.78301
Epoch 72, Val Loss: 5.37215
Epoch 73, Val Loss: 4.78911
Epoch 74, Val Loss: 4.64233
Epoch 75, Val Loss: 4.78799
Epoch 76, Val Loss: 4.73878
Epoch 77, Val Loss: 4.76625
Epoch 78, Val Loss: 4.65896
Epoch 79, Val Loss: 4.81860
Epoch 80, Val Loss: 5.38847
Epoch 81, Val Loss: 4.73590
Epoch 82, Val Loss: 4.93229
Epoch 83, Val Loss: 4.87461
Epoch 84, Val Loss: 4.82956
Epoch 85, Val Loss: 4.90518
Epoch 86, Val Loss: 5.02936
Epoch 87, Val Loss: 4.65268
Epoch 88, Val Loss: 4.63535
Epoch 89, Val Loss: 4.70714
Epoch 90, Val Loss: 4.66838
Epoch 91, Val Loss: 4.90636
Epoch 92, Val Loss: 4.73907
Epoch 93, Val Loss: 4.90065
Epoch 94, Val Loss: 4.70140
Epoch 95, Val Loss: 4.60703
Epoch 96, Val Loss: 4.61952
Epoch 97, Val Loss: 4.79817
Epoch 98, Val Loss: 4.69226
Epoch 99, Val Loss: 5.04474
Saved Losses
{'MSE - mean': 5.224345389558259, 'MSE - std': 0.3413838690660933, 'R2 - mean': 0.4859584817557682, 'R2 - std': 0.006465400936669419} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.58613
Epoch 1, Val Loss: 12.93446
Epoch 2, Val Loss: 7.25413
Epoch 3, Val Loss: 6.37230
Epoch 4, Val Loss: 6.33286
Epoch 5, Val Loss: 7.08451
Epoch 6, Val Loss: 6.56091
Epoch 7, Val Loss: 6.21861
Epoch 8, Val Loss: 6.23966
Epoch 9, Val Loss: 6.18094
Epoch 10, Val Loss: 6.40619
Epoch 11, Val Loss: 6.19408
Epoch 12, Val Loss: 6.29368
Epoch 13, Val Loss: 6.78377
Epoch 14, Val Loss: 6.09345
Epoch 15, Val Loss: 6.22915
Epoch 16, Val Loss: 6.15141
Epoch 17, Val Loss: 6.09745
Epoch 18, Val Loss: 6.16753
Epoch 19, Val Loss: 6.45266
Epoch 20, Val Loss: 6.23062
Epoch 21, Val Loss: 6.45519
Epoch 22, Val Loss: 6.18777
Epoch 23, Val Loss: 6.04783
Epoch 24, Val Loss: 6.06931
Epoch 25, Val Loss: 6.08264
Epoch 26, Val Loss: 5.93688
Epoch 27, Val Loss: 6.04422
Epoch 28, Val Loss: 6.00005
Epoch 29, Val Loss: 5.95032
Epoch 30, Val Loss: 6.21885
Epoch 31, Val Loss: 5.93444
Epoch 32, Val Loss: 5.89511
Epoch 33, Val Loss: 6.07917
Epoch 34, Val Loss: 6.16305
Epoch 35, Val Loss: 5.89276
Epoch 36, Val Loss: 5.86027
Epoch 37, Val Loss: 6.32148
Epoch 38, Val Loss: 6.41763
Epoch 39, Val Loss: 5.89453
Epoch 40, Val Loss: 5.83444
Epoch 41, Val Loss: 5.86510
Epoch 42, Val Loss: 6.38996
Epoch 43, Val Loss: 5.83716
Epoch 44, Val Loss: 5.75991
Epoch 45, Val Loss: 5.73855
Epoch 46, Val Loss: 5.75751
Epoch 47, Val Loss: 5.71170
Epoch 48, Val Loss: 5.80172
Epoch 49, Val Loss: 5.82418
Epoch 50, Val Loss: 5.66463
Epoch 51, Val Loss: 5.93698
Epoch 52, Val Loss: 5.79763
Epoch 53, Val Loss: 5.64395
Epoch 54, Val Loss: 6.09988
Epoch 55, Val Loss: 6.04208
Epoch 56, Val Loss: 5.79937
Epoch 57, Val Loss: 5.83232
Epoch 58, Val Loss: 5.76398
Epoch 59, Val Loss: 5.75500
Epoch 60, Val Loss: 5.91550
Epoch 61, Val Loss: 5.88702
Epoch 62, Val Loss: 5.68392
Epoch 63, Val Loss: 5.68176
Epoch 64, Val Loss: 5.47844
Epoch 65, Val Loss: 5.61921
Epoch 66, Val Loss: 5.51348
Epoch 67, Val Loss: 5.70281
Epoch 68, Val Loss: 5.77300
Epoch 69, Val Loss: 5.52169
Epoch 70, Val Loss: 5.54170
Epoch 71, Val Loss: 5.91084
Epoch 72, Val Loss: 5.75505
Epoch 73, Val Loss: 5.50438
Epoch 74, Val Loss: 5.57299
Epoch 75, Val Loss: 5.51603
Epoch 76, Val Loss: 5.44236
Epoch 77, Val Loss: 5.77479
Epoch 78, Val Loss: 5.42975
Epoch 79, Val Loss: 5.45306
Epoch 80, Val Loss: 5.87093
Epoch 81, Val Loss: 5.70711
Epoch 82, Val Loss: 5.49355
Epoch 83, Val Loss: 5.94958
Epoch 84, Val Loss: 5.97448
Epoch 85, Val Loss: 5.46998
Epoch 86, Val Loss: 5.56909
Epoch 87, Val Loss: 5.33232
Epoch 88, Val Loss: 5.52182
Epoch 89, Val Loss: 5.39220
Epoch 90, Val Loss: 5.33502
Epoch 91, Val Loss: 5.36715
Epoch 92, Val Loss: 5.27726
Epoch 93, Val Loss: 5.63197
Epoch 94, Val Loss: 5.39042
Epoch 95, Val Loss: 5.47375
Epoch 96, Val Loss: 5.31856
Epoch 97, Val Loss: 5.41540
Epoch 98, Val Loss: 5.19250
Epoch 99, Val Loss: 5.57567
Saved Losses
{'MSE - mean': 5.270711010577371, 'MSE - std': 0.28634740962218047, 'R2 - mean': 0.48138708442608485, 'R2 - std': 0.00834643356607651} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.03082
Epoch 1, Val Loss: 6.72153
Epoch 2, Val Loss: 6.53074
Epoch 3, Val Loss: 5.80834
Epoch 4, Val Loss: 5.72692
Epoch 5, Val Loss: 5.54430
Epoch 6, Val Loss: 5.45137
Epoch 7, Val Loss: 5.46114
Epoch 8, Val Loss: 5.39509
Epoch 9, Val Loss: 5.46508
Epoch 10, Val Loss: 5.95965
Epoch 11, Val Loss: 5.37743
Epoch 12, Val Loss: 5.27673
Epoch 13, Val Loss: 5.14689
Epoch 14, Val Loss: 5.69119
Epoch 15, Val Loss: 5.40153
Epoch 16, Val Loss: 5.22461
Epoch 17, Val Loss: 5.13722
Epoch 18, Val Loss: 5.10677
Epoch 19, Val Loss: 5.07041
Epoch 20, Val Loss: 5.54487
Epoch 21, Val Loss: 5.26160
Epoch 22, Val Loss: 4.96984
Epoch 23, Val Loss: 5.02542
Epoch 24, Val Loss: 5.32703
Epoch 25, Val Loss: 5.19851
Epoch 26, Val Loss: 4.98045
Epoch 27, Val Loss: 5.16874
Epoch 28, Val Loss: 5.03159
Epoch 29, Val Loss: 4.84978
Epoch 30, Val Loss: 4.84256
Epoch 31, Val Loss: 4.77669
Epoch 32, Val Loss: 4.85901
Epoch 33, Val Loss: 4.84817
Epoch 34, Val Loss: 4.90594
Epoch 35, Val Loss: 4.76796
Epoch 36, Val Loss: 4.75139
Epoch 37, Val Loss: 4.89081
Epoch 38, Val Loss: 4.74035
Epoch 39, Val Loss: 4.83249
Epoch 40, Val Loss: 5.02231
Epoch 41, Val Loss: 4.85912
Epoch 42, Val Loss: 5.00972
Epoch 43, Val Loss: 4.71214
Epoch 44, Val Loss: 4.68455
Epoch 45, Val Loss: 4.70862
Epoch 46, Val Loss: 5.37304
Epoch 47, Val Loss: 4.88205
Epoch 48, Val Loss: 4.75915
Epoch 49, Val Loss: 4.81448
Epoch 50, Val Loss: 4.98659
Epoch 51, Val Loss: 5.08271
Epoch 52, Val Loss: 4.60977
Epoch 53, Val Loss: 4.70436
Epoch 54, Val Loss: 4.69512
Epoch 55, Val Loss: 4.70391
Epoch 56, Val Loss: 4.79030
Epoch 57, Val Loss: 4.80404
Epoch 58, Val Loss: 4.83976
Epoch 59, Val Loss: 4.57415
Epoch 60, Val Loss: 4.85585
Epoch 61, Val Loss: 4.64244
Epoch 62, Val Loss: 4.60007
Epoch 63, Val Loss: 4.62011
Epoch 64, Val Loss: 4.65578
Epoch 65, Val Loss: 4.60393
Epoch 66, Val Loss: 4.66878
Epoch 67, Val Loss: 4.73766
Epoch 68, Val Loss: 4.55718
Epoch 69, Val Loss: 4.81226
Epoch 70, Val Loss: 4.70123
Epoch 71, Val Loss: 4.65123
Epoch 72, Val Loss: 4.63456
Epoch 73, Val Loss: 4.65893
Epoch 74, Val Loss: 4.65241
Epoch 75, Val Loss: 4.76702
Epoch 76, Val Loss: 4.77950
Epoch 77, Val Loss: 4.46847
Epoch 78, Val Loss: 4.63312
Epoch 79, Val Loss: 4.60716
Epoch 80, Val Loss: 4.74009
Epoch 81, Val Loss: 4.49831
Epoch 82, Val Loss: 4.59692
Epoch 83, Val Loss: 5.04090
Epoch 84, Val Loss: 4.73609
Epoch 85, Val Loss: 4.74249
Epoch 86, Val Loss: 4.60126
Epoch 87, Val Loss: 4.60799
Epoch 88, Val Loss: 4.54255
Epoch 89, Val Loss: 5.21848
Epoch 90, Val Loss: 4.71573
Epoch 91, Val Loss: 4.56228
Epoch 92, Val Loss: 4.47869
Epoch 93, Val Loss: 4.52133
Epoch 94, Val Loss: 4.37732
Epoch 95, Val Loss: 4.59614
Epoch 96, Val Loss: 4.49893
Epoch 97, Val Loss: 4.39609
Epoch 98, Val Loss: 4.52784
Epoch 99, Val Loss: 4.46535
Saved Losses
{'MSE - mean': 5.143537351424031, 'MSE - std': 0.33168591769224914, 'R2 - mean': 0.48375101038741153, 'R2 - std': 0.00830732524983817} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.68633
Epoch 1, Val Loss: 11.57708
Epoch 2, Val Loss: 8.86330
Epoch 3, Val Loss: 7.80103
Epoch 4, Val Loss: 8.57470
Epoch 5, Val Loss: 7.53816
Epoch 6, Val Loss: 7.45522
Epoch 7, Val Loss: 8.14138
Epoch 8, Val Loss: 7.33898
Epoch 9, Val Loss: 7.85627
Epoch 10, Val Loss: 7.38187
Epoch 11, Val Loss: 7.55971
Epoch 12, Val Loss: 7.34474
Epoch 13, Val Loss: 7.31616
Epoch 14, Val Loss: 8.11180
Epoch 15, Val Loss: 7.54536
Epoch 16, Val Loss: 7.39280
Epoch 17, Val Loss: 7.72198
Epoch 18, Val Loss: 7.01162
Epoch 19, Val Loss: 7.43898
Epoch 20, Val Loss: 7.34106
Epoch 21, Val Loss: 7.23066
Epoch 22, Val Loss: 6.98716
Epoch 23, Val Loss: 7.44870
Epoch 24, Val Loss: 6.83873
Epoch 25, Val Loss: 6.98427
Epoch 26, Val Loss: 7.04849
Epoch 27, Val Loss: 7.17530
Epoch 28, Val Loss: 6.92964
Epoch 29, Val Loss: 6.96620
Epoch 30, Val Loss: 7.88205
Epoch 31, Val Loss: 6.97444
Epoch 32, Val Loss: 6.72061
Epoch 33, Val Loss: 6.87215
Epoch 34, Val Loss: 7.50435
Epoch 35, Val Loss: 6.68286
Epoch 36, Val Loss: 6.83042
Epoch 37, Val Loss: 6.90957
Epoch 38, Val Loss: 6.87949
Epoch 39, Val Loss: 6.66334
Epoch 40, Val Loss: 6.67844
Epoch 41, Val Loss: 6.93278
Epoch 42, Val Loss: 6.78923
Epoch 43, Val Loss: 7.08865
Epoch 44, Val Loss: 6.87626
Epoch 45, Val Loss: 7.14677
Epoch 46, Val Loss: 6.60560
Epoch 47, Val Loss: 6.85454
Epoch 48, Val Loss: 7.17008
Epoch 49, Val Loss: 6.86556
Epoch 50, Val Loss: 6.63702
Epoch 51, Val Loss: 6.88832
Epoch 52, Val Loss: 6.61416
Epoch 53, Val Loss: 6.64202
Epoch 54, Val Loss: 6.96060
Epoch 55, Val Loss: 6.82974
Epoch 56, Val Loss: 7.06477
Epoch 57, Val Loss: 6.52329
Epoch 58, Val Loss: 6.58701
Epoch 59, Val Loss: 7.15809
Epoch 60, Val Loss: 6.82947
Epoch 61, Val Loss: 6.70597
Epoch 62, Val Loss: 6.64541
Epoch 63, Val Loss: 6.47287
Epoch 64, Val Loss: 6.87293
Epoch 65, Val Loss: 6.62007
Epoch 66, Val Loss: 7.19683
Epoch 67, Val Loss: 6.71489
Epoch 68, Val Loss: 6.57514
Epoch 69, Val Loss: 6.65648
Epoch 70, Val Loss: 7.98892
Epoch 71, Val Loss: 6.48715
Epoch 72, Val Loss: 6.62036
Epoch 73, Val Loss: 6.37993
Epoch 74, Val Loss: 6.56129
Epoch 75, Val Loss: 6.52325
Epoch 76, Val Loss: 6.82946
Epoch 77, Val Loss: 6.45752
Epoch 78, Val Loss: 6.46993
Epoch 79, Val Loss: 7.51022
Epoch 80, Val Loss: 6.29101
Epoch 81, Val Loss: 6.59018
Epoch 82, Val Loss: 6.46428
Epoch 83, Val Loss: 6.68716
Epoch 84, Val Loss: 6.52222
Epoch 85, Val Loss: 6.86996
Epoch 86, Val Loss: 6.94185
Epoch 87, Val Loss: 6.50824
Epoch 88, Val Loss: 6.65852
Epoch 89, Val Loss: 6.51488
Epoch 90, Val Loss: 6.49750
Epoch 91, Val Loss: 6.81264
Epoch 92, Val Loss: 6.52389
Epoch 93, Val Loss: 6.71105
Epoch 94, Val Loss: 6.55015
Epoch 95, Val Loss: 6.43102
Epoch 96, Val Loss: 6.49690
Epoch 97, Val Loss: 6.58902
Epoch 98, Val Loss: 6.52088
Epoch 99, Val Loss: 7.05760
Saved Losses
{'MSE - mean': 5.367898394734232, 'MSE - std': 0.5379255984030217, 'R2 - mean': 0.48337243702594057, 'R2 - std': 0.007468774558476164} 
 

Results After CV: {'MSE - mean': 5.367898394734232, 'MSE - std': 0.5379255984030217, 'R2 - mean': 0.48337243702594057, 'R2 - std': 0.007468774558476164}
Train time: 83.24867963020006
Inference time: 0.05185766979993787
Finished cross validation
Trial 16 finished with value: 5.367898394734232 and parameters: {'p_m': 0.2339789696290297, 'alpha': 6.909364712262136, 'K': 10, 'beta': 3.807288008420391}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.17454
Epoch 1, Val Loss: 13.77365
Epoch 2, Val Loss: 8.03734
Epoch 3, Val Loss: 7.61096
Epoch 4, Val Loss: 7.22142
Epoch 5, Val Loss: 7.03807
Epoch 6, Val Loss: 6.79032
Epoch 7, Val Loss: 6.67645
Epoch 8, Val Loss: 6.85153
Epoch 9, Val Loss: 6.86827
Epoch 10, Val Loss: 6.88918
Epoch 11, Val Loss: 6.71777
Epoch 12, Val Loss: 6.46358
Epoch 13, Val Loss: 6.97363
Epoch 14, Val Loss: 6.42122
Epoch 15, Val Loss: 6.26871
Epoch 16, Val Loss: 6.27342
Epoch 17, Val Loss: 6.26213
Epoch 18, Val Loss: 6.49825
Epoch 19, Val Loss: 6.24459
Epoch 20, Val Loss: 7.14744
Epoch 21, Val Loss: 6.24595
Epoch 22, Val Loss: 6.69587
Epoch 23, Val Loss: 6.18462
Epoch 24, Val Loss: 6.13997
Epoch 25, Val Loss: 6.00308
Epoch 26, Val Loss: 6.12415
Epoch 27, Val Loss: 6.04721
Epoch 28, Val Loss: 6.19092
Epoch 29, Val Loss: 5.87479
Epoch 30, Val Loss: 5.78825
Epoch 31, Val Loss: 5.80309
Epoch 32, Val Loss: 5.88751
Epoch 33, Val Loss: 5.77441
Epoch 34, Val Loss: 5.92647
Epoch 35, Val Loss: 5.84596
Epoch 36, Val Loss: 5.66451
Epoch 37, Val Loss: 5.75855
Epoch 38, Val Loss: 5.87114
Epoch 39, Val Loss: 5.89580
Epoch 40, Val Loss: 5.44616
Epoch 41, Val Loss: 6.02022
Epoch 42, Val Loss: 5.84751
Epoch 43, Val Loss: 5.74089
Epoch 44, Val Loss: 5.26341
Epoch 45, Val Loss: 5.39550
Epoch 46, Val Loss: 5.47020
Epoch 47, Val Loss: 5.32415
Epoch 48, Val Loss: 5.77422
Epoch 49, Val Loss: 5.17979
Epoch 50, Val Loss: 5.26167
Epoch 51, Val Loss: 5.17570
Epoch 52, Val Loss: 5.12902
Epoch 53, Val Loss: 5.31624
Epoch 54, Val Loss: 5.24569
Epoch 55, Val Loss: 5.04782
Epoch 56, Val Loss: 5.08231
Epoch 57, Val Loss: 5.00017
Epoch 58, Val Loss: 5.09045
Epoch 59, Val Loss: 5.32727
Epoch 60, Val Loss: 4.98093
Epoch 61, Val Loss: 4.97513
Epoch 62, Val Loss: 5.01544
Epoch 63, Val Loss: 5.13388
Epoch 64, Val Loss: 5.20386
Epoch 65, Val Loss: 4.93202
Epoch 66, Val Loss: 5.14494
Epoch 67, Val Loss: 5.01411
Epoch 68, Val Loss: 4.86276
Epoch 69, Val Loss: 4.81031
Epoch 70, Val Loss: 4.87487
Epoch 71, Val Loss: 5.35170
Epoch 72, Val Loss: 5.19311
Epoch 73, Val Loss: 4.87979
Epoch 74, Val Loss: 4.89668
Epoch 75, Val Loss: 4.74660
Epoch 76, Val Loss: 5.01215
Epoch 77, Val Loss: 4.79225
Epoch 78, Val Loss: 4.85734
Epoch 79, Val Loss: 5.01184
Epoch 80, Val Loss: 4.87167
Epoch 81, Val Loss: 4.76487
Epoch 82, Val Loss: 4.77295
Epoch 83, Val Loss: 4.74211
Epoch 84, Val Loss: 4.65343
Epoch 85, Val Loss: 4.78009
Epoch 86, Val Loss: 4.74698
Epoch 87, Val Loss: 4.66933
Epoch 88, Val Loss: 4.72763
Epoch 89, Val Loss: 4.82649
Epoch 90, Val Loss: 4.84570
Epoch 91, Val Loss: 4.64397
Epoch 92, Val Loss: 4.92016
Epoch 93, Val Loss: 5.54639
Epoch 94, Val Loss: 4.91412
Epoch 95, Val Loss: 4.59450
Epoch 96, Val Loss: 4.70273
Epoch 97, Val Loss: 4.67016
Epoch 98, Val Loss: 4.82452
Epoch 99, Val Loss: 4.60661
Saved Losses
{'MSE - mean': 4.739665553642305, 'MSE - std': 0.0, 'R2 - mean': 0.5677581629889106, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.39486
Epoch 1, Val Loss: 8.26636
Epoch 2, Val Loss: 6.19469
Epoch 3, Val Loss: 5.60477
Epoch 4, Val Loss: 5.10877
Epoch 5, Val Loss: 5.21404
Epoch 6, Val Loss: 5.28601
Epoch 7, Val Loss: 5.09748
Epoch 8, Val Loss: 4.94226
Epoch 9, Val Loss: 4.90586
Epoch 10, Val Loss: 4.84305
Epoch 11, Val Loss: 4.79717
Epoch 12, Val Loss: 4.72256
Epoch 13, Val Loss: 4.71159
Epoch 14, Val Loss: 4.69423
Epoch 15, Val Loss: 4.81369
Epoch 16, Val Loss: 4.63751
Epoch 17, Val Loss: 4.80619
Epoch 18, Val Loss: 4.99861
Epoch 19, Val Loss: 4.53811
Epoch 20, Val Loss: 4.49445
Epoch 21, Val Loss: 4.84047
Epoch 22, Val Loss: 5.08556
Epoch 23, Val Loss: 4.78899
Epoch 24, Val Loss: 4.83786
Epoch 25, Val Loss: 4.59861
Epoch 26, Val Loss: 4.48315
Epoch 27, Val Loss: 4.49844
Epoch 28, Val Loss: 4.57744
Epoch 29, Val Loss: 4.41546
Epoch 30, Val Loss: 4.34448
Epoch 31, Val Loss: 4.48051
Epoch 32, Val Loss: 4.70814
Epoch 33, Val Loss: 4.37265
Epoch 34, Val Loss: 4.38442
Epoch 35, Val Loss: 4.44262
Epoch 36, Val Loss: 4.38210
Epoch 37, Val Loss: 4.48726
Epoch 38, Val Loss: 4.34966
Epoch 39, Val Loss: 4.32031
Epoch 40, Val Loss: 4.29437
Epoch 41, Val Loss: 4.24581
Epoch 42, Val Loss: 5.17233
Epoch 43, Val Loss: 4.36538
Epoch 44, Val Loss: 4.54408
Epoch 45, Val Loss: 4.58577
Epoch 46, Val Loss: 4.29880
Epoch 47, Val Loss: 4.33126
Epoch 48, Val Loss: 4.36991
Epoch 49, Val Loss: 4.30923
Epoch 50, Val Loss: 4.23505
Epoch 51, Val Loss: 4.38897
Epoch 52, Val Loss: 4.27796
Epoch 53, Val Loss: 4.62162
Epoch 54, Val Loss: 4.26305
Epoch 55, Val Loss: 4.44037
Epoch 56, Val Loss: 4.34109
Epoch 57, Val Loss: 4.65734
Epoch 58, Val Loss: 4.61749
Epoch 59, Val Loss: 4.29310
Epoch 60, Val Loss: 4.13898
Epoch 61, Val Loss: 4.20145
Epoch 62, Val Loss: 4.29022
Epoch 63, Val Loss: 4.19865
Epoch 64, Val Loss: 4.19438
Epoch 65, Val Loss: 4.10862
Epoch 66, Val Loss: 4.70080
Epoch 67, Val Loss: 4.07574
Epoch 68, Val Loss: 4.18842
Epoch 69, Val Loss: 4.24466
Epoch 70, Val Loss: 4.82140
Epoch 71, Val Loss: 4.12234
Epoch 72, Val Loss: 4.13871
Epoch 73, Val Loss: 4.47791
Epoch 74, Val Loss: 4.09405
Epoch 75, Val Loss: 4.11990
Epoch 76, Val Loss: 4.27510
Epoch 77, Val Loss: 4.14553
Epoch 78, Val Loss: 4.24358
Epoch 79, Val Loss: 4.28574
Epoch 80, Val Loss: 4.39179
Epoch 81, Val Loss: 4.31628
Epoch 82, Val Loss: 4.09168
Epoch 83, Val Loss: 4.04073
Epoch 84, Val Loss: 4.14366
Epoch 85, Val Loss: 4.34714
Epoch 86, Val Loss: 3.99439
Epoch 87, Val Loss: 4.36859
Epoch 88, Val Loss: 4.05913
Epoch 89, Val Loss: 4.06496
Epoch 90, Val Loss: 4.24389
Epoch 91, Val Loss: 4.04894
Epoch 92, Val Loss: 4.04712
Epoch 93, Val Loss: 4.04696
Epoch 94, Val Loss: 4.08319
Epoch 95, Val Loss: 4.20322
Epoch 96, Val Loss: 4.22232
Epoch 97, Val Loss: 4.09275
Epoch 98, Val Loss: 4.05703
Epoch 99, Val Loss: 3.98216
Saved Losses
{'MSE - mean': 4.457690888802259, 'MSE - std': 0.2819746648400461, 'R2 - mean': 0.5613205810857519, 'R2 - std': 0.0064375819031586845} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.15270
Epoch 1, Val Loss: 7.81296
Epoch 2, Val Loss: 6.91994
Epoch 3, Val Loss: 6.25242
Epoch 4, Val Loss: 6.07423
Epoch 5, Val Loss: 5.92183
Epoch 6, Val Loss: 5.89590
Epoch 7, Val Loss: 5.77461
Epoch 8, Val Loss: 6.30127
Epoch 9, Val Loss: 5.73236
Epoch 10, Val Loss: 5.84088
Epoch 11, Val Loss: 5.75138
Epoch 12, Val Loss: 5.77428
Epoch 13, Val Loss: 5.73634
Epoch 14, Val Loss: 5.87092
Epoch 15, Val Loss: 5.66506
Epoch 16, Val Loss: 5.64283
Epoch 17, Val Loss: 5.57765
Epoch 18, Val Loss: 5.57354
Epoch 19, Val Loss: 5.41476
Epoch 20, Val Loss: 6.03838
Epoch 21, Val Loss: 5.77952
Epoch 22, Val Loss: 5.47528
Epoch 23, Val Loss: 6.00477
Epoch 24, Val Loss: 5.36457
Epoch 25, Val Loss: 5.46084
Epoch 26, Val Loss: 5.34477
Epoch 27, Val Loss: 5.29951
Epoch 28, Val Loss: 5.27992
Epoch 29, Val Loss: 5.33739
Epoch 30, Val Loss: 5.37155
Epoch 31, Val Loss: 5.31666
Epoch 32, Val Loss: 5.17367
Epoch 33, Val Loss: 5.27638
Epoch 34, Val Loss: 5.23287
Epoch 35, Val Loss: 5.24141
Epoch 36, Val Loss: 5.12254
Epoch 37, Val Loss: 5.31907
Epoch 38, Val Loss: 5.18779
Epoch 39, Val Loss: 4.99636
Epoch 40, Val Loss: 5.07905
Epoch 41, Val Loss: 5.36597
Epoch 42, Val Loss: 5.29309
Epoch 43, Val Loss: 5.27891
Epoch 44, Val Loss: 5.03119
Epoch 45, Val Loss: 5.15263
Epoch 46, Val Loss: 5.06018
Epoch 47, Val Loss: 5.04599
Epoch 48, Val Loss: 5.03943
Epoch 49, Val Loss: 5.19998
Epoch 50, Val Loss: 5.06830
Epoch 51, Val Loss: 4.89794
Epoch 52, Val Loss: 4.97701
Epoch 53, Val Loss: 5.04997
Epoch 54, Val Loss: 5.17066
Epoch 55, Val Loss: 4.85128
Epoch 56, Val Loss: 4.91714
Epoch 57, Val Loss: 4.88888
Epoch 58, Val Loss: 5.06552
Epoch 59, Val Loss: 5.12170
Epoch 60, Val Loss: 4.90333
Epoch 61, Val Loss: 4.92851
Epoch 62, Val Loss: 4.88098
Epoch 63, Val Loss: 4.81260
Epoch 64, Val Loss: 5.01976
Epoch 65, Val Loss: 4.85627
Epoch 66, Val Loss: 4.72065
Epoch 67, Val Loss: 4.86084
Epoch 68, Val Loss: 4.96421
Epoch 69, Val Loss: 4.84334
Epoch 70, Val Loss: 4.71529
Epoch 71, Val Loss: 4.87907
Epoch 72, Val Loss: 4.69876
Epoch 73, Val Loss: 4.85609
Epoch 74, Val Loss: 4.93858
Epoch 75, Val Loss: 4.82324
Epoch 76, Val Loss: 4.76758
Epoch 77, Val Loss: 4.70531
Epoch 78, Val Loss: 5.04054
Epoch 79, Val Loss: 4.89979
Epoch 80, Val Loss: 4.87283
Epoch 81, Val Loss: 4.69948
Epoch 82, Val Loss: 4.90216
Epoch 83, Val Loss: 4.58096
Epoch 84, Val Loss: 4.70638
Epoch 85, Val Loss: 4.69508
Epoch 86, Val Loss: 4.65449
Epoch 87, Val Loss: 4.90442
Epoch 88, Val Loss: 4.56015
Epoch 89, Val Loss: 4.55061
Epoch 90, Val Loss: 4.68853
Epoch 91, Val Loss: 4.71010
Epoch 92, Val Loss: 4.57208
Epoch 93, Val Loss: 4.70641
Epoch 94, Val Loss: 4.68355
Epoch 95, Val Loss: 4.62770
Epoch 96, Val Loss: 4.96636
Epoch 97, Val Loss: 4.97364
Epoch 98, Val Loss: 4.50453
Epoch 99, Val Loss: 4.81837
Saved Losses
{'MSE - mean': 4.491496703700254, 'MSE - std': 0.23514280905357487, 'R2 - mean': 0.5580102862347617, 'R2 - std': 0.007038779096848753} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.71981
Epoch 1, Val Loss: 10.36384
Epoch 2, Val Loss: 6.41673
Epoch 3, Val Loss: 5.39060
Epoch 4, Val Loss: 5.91636
Epoch 5, Val Loss: 5.11215
Epoch 6, Val Loss: 5.07375
Epoch 7, Val Loss: 4.93769
Epoch 8, Val Loss: 5.33172
Epoch 9, Val Loss: 4.93463
Epoch 10, Val Loss: 4.97915
Epoch 11, Val Loss: 4.95564
Epoch 12, Val Loss: 5.50530
Epoch 13, Val Loss: 5.03299
Epoch 14, Val Loss: 4.92597
Epoch 15, Val Loss: 4.73302
Epoch 16, Val Loss: 4.73911
Epoch 17, Val Loss: 4.92509
Epoch 18, Val Loss: 4.74038
Epoch 19, Val Loss: 4.68349
Epoch 20, Val Loss: 4.72367
Epoch 21, Val Loss: 4.66538
Epoch 22, Val Loss: 4.64306
Epoch 23, Val Loss: 4.66664
Epoch 24, Val Loss: 4.64785
Epoch 25, Val Loss: 4.71722
Epoch 26, Val Loss: 4.82899
Epoch 27, Val Loss: 4.50347
Epoch 28, Val Loss: 4.44248
Epoch 29, Val Loss: 4.65906
Epoch 30, Val Loss: 4.85075
Epoch 31, Val Loss: 4.43305
Epoch 32, Val Loss: 4.46420
Epoch 33, Val Loss: 4.50066
Epoch 34, Val Loss: 4.78387
Epoch 35, Val Loss: 4.54260
Epoch 36, Val Loss: 4.51786
Epoch 37, Val Loss: 4.59379
Epoch 38, Val Loss: 4.32482
Epoch 39, Val Loss: 4.32847
Epoch 40, Val Loss: 4.28346
Epoch 41, Val Loss: 4.41855
Epoch 42, Val Loss: 4.37950
Epoch 43, Val Loss: 4.48707
Epoch 44, Val Loss: 4.37173
Epoch 45, Val Loss: 4.33852
Epoch 46, Val Loss: 4.30235
Epoch 47, Val Loss: 4.56329
Epoch 48, Val Loss: 4.28404
Epoch 49, Val Loss: 4.24146
Epoch 50, Val Loss: 4.50499
Epoch 51, Val Loss: 4.26859
Epoch 52, Val Loss: 4.66107
Epoch 53, Val Loss: 4.40676
Epoch 54, Val Loss: 4.16973
Epoch 55, Val Loss: 4.13122
Epoch 56, Val Loss: 4.17123
Epoch 57, Val Loss: 4.25236
Epoch 58, Val Loss: 4.31765
Epoch 59, Val Loss: 4.15588
Epoch 60, Val Loss: 4.21983
Epoch 61, Val Loss: 4.30612
Epoch 62, Val Loss: 4.15380
Epoch 63, Val Loss: 4.09002
Epoch 64, Val Loss: 4.43999
Epoch 65, Val Loss: 4.25303
Epoch 66, Val Loss: 4.60982
Epoch 67, Val Loss: 4.32572
Epoch 68, Val Loss: 4.63495
Epoch 69, Val Loss: 4.35625
Epoch 70, Val Loss: 4.42303
Epoch 71, Val Loss: 4.81593
Epoch 72, Val Loss: 4.24025
Epoch 73, Val Loss: 4.62851
Epoch 74, Val Loss: 4.13665
Epoch 75, Val Loss: 4.40273
Epoch 76, Val Loss: 4.59188
Epoch 77, Val Loss: 4.35369
Epoch 78, Val Loss: 4.21730
Epoch 79, Val Loss: 4.17713
Epoch 80, Val Loss: 4.15013
Epoch 81, Val Loss: 4.25135
Epoch 82, Val Loss: 4.23967
Epoch 83, Val Loss: 4.16280
Epoch 84, Val Loss: 4.39255
Early stopping applies.
Saved Losses
{'MSE - mean': 4.482948126202816, 'MSE - std': 0.20417722698404359, 'R2 - mean': 0.5493634551654865, 'R2 - std': 0.016169767190730645} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 45.62219
Epoch 1, Val Loss: 18.81718
Epoch 2, Val Loss: 9.34524
Epoch 3, Val Loss: 8.22510
Epoch 4, Val Loss: 7.96461
Epoch 5, Val Loss: 7.96269
Epoch 6, Val Loss: 7.84894
Epoch 7, Val Loss: 7.70992
Epoch 8, Val Loss: 7.56222
Epoch 9, Val Loss: 7.67408
Epoch 10, Val Loss: 7.67478
Epoch 11, Val Loss: 7.76281
Epoch 12, Val Loss: 7.72431
Epoch 13, Val Loss: 7.38752
Epoch 14, Val Loss: 7.71841
Epoch 15, Val Loss: 7.59546
Epoch 16, Val Loss: 7.57627
Epoch 17, Val Loss: 7.50826
Epoch 18, Val Loss: 7.74615
Epoch 19, Val Loss: 7.16351
Epoch 20, Val Loss: 7.69323
Epoch 21, Val Loss: 7.10141
Epoch 22, Val Loss: 7.05951
Epoch 23, Val Loss: 7.40718
Epoch 24, Val Loss: 8.05145
Epoch 25, Val Loss: 7.03956
Epoch 26, Val Loss: 6.99446
Epoch 27, Val Loss: 7.03174
Epoch 28, Val Loss: 7.01645
Epoch 29, Val Loss: 6.80503
Epoch 30, Val Loss: 6.87776
Epoch 31, Val Loss: 6.98788
Epoch 32, Val Loss: 6.79967
Epoch 33, Val Loss: 6.90983
Epoch 34, Val Loss: 6.76119
Epoch 35, Val Loss: 6.74635
Epoch 36, Val Loss: 7.01977
Epoch 37, Val Loss: 7.04139
Epoch 38, Val Loss: 7.07216
Epoch 39, Val Loss: 6.81316
Epoch 40, Val Loss: 6.81616
Epoch 41, Val Loss: 6.54643
Epoch 42, Val Loss: 6.96712
Epoch 43, Val Loss: 6.71779
Epoch 44, Val Loss: 6.76396
Epoch 45, Val Loss: 6.83195
Epoch 46, Val Loss: 7.52518
Epoch 47, Val Loss: 6.66171
Epoch 48, Val Loss: 6.44520
Epoch 49, Val Loss: 6.69228
Epoch 50, Val Loss: 6.57017
Epoch 51, Val Loss: 7.24765
Epoch 52, Val Loss: 7.06583
Epoch 53, Val Loss: 6.99368
Epoch 54, Val Loss: 6.41062
Epoch 55, Val Loss: 6.41335
Epoch 56, Val Loss: 6.39147
Epoch 57, Val Loss: 6.67355
Epoch 58, Val Loss: 6.58739
Epoch 59, Val Loss: 6.49155
Epoch 60, Val Loss: 6.40383
Epoch 61, Val Loss: 6.22223
Epoch 62, Val Loss: 6.51913
Epoch 63, Val Loss: 6.20363
Epoch 64, Val Loss: 6.08133
Epoch 65, Val Loss: 6.14188
Epoch 66, Val Loss: 6.27621
Epoch 67, Val Loss: 6.14408
Epoch 68, Val Loss: 6.22869
Epoch 69, Val Loss: 6.04646
Epoch 70, Val Loss: 6.45596
Epoch 71, Val Loss: 6.46398
Epoch 72, Val Loss: 6.07477
Epoch 73, Val Loss: 6.23893
Epoch 74, Val Loss: 6.40754
Epoch 75, Val Loss: 6.12008
Epoch 76, Val Loss: 5.91742
Epoch 77, Val Loss: 6.11021
Epoch 78, Val Loss: 5.98790
Epoch 79, Val Loss: 5.93986
Epoch 80, Val Loss: 5.96011
Epoch 81, Val Loss: 5.96016
Epoch 82, Val Loss: 5.87933
Epoch 83, Val Loss: 6.47624
Epoch 84, Val Loss: 5.95925
Epoch 85, Val Loss: 5.81894
Epoch 86, Val Loss: 6.68781
Epoch 87, Val Loss: 6.17147
Epoch 88, Val Loss: 6.03419
Epoch 89, Val Loss: 5.88794
Epoch 90, Val Loss: 6.08394
Epoch 91, Val Loss: 6.00793
Epoch 92, Val Loss: 5.90153
Epoch 93, Val Loss: 5.85560
Epoch 94, Val Loss: 6.16787
Epoch 95, Val Loss: 5.73256
Epoch 96, Val Loss: 5.64119
Epoch 97, Val Loss: 5.78668
Epoch 98, Val Loss: 5.87605
Epoch 99, Val Loss: 6.36698
Saved Losses
{'MSE - mean': 4.708403722609195, 'MSE - std': 0.48648902949495176, 'R2 - mean': 0.5466979778124585, 'R2 - std': 0.0154138955128145} 
 

Results After CV: {'MSE - mean': 4.708403722609195, 'MSE - std': 0.48648902949495176, 'R2 - mean': 0.5466979778124585, 'R2 - std': 0.0154138955128145}
Train time: 117.50960589540027
Inference time: 0.05308954240008461
Finished cross validation
Trial 17 finished with value: 4.708403722609195 and parameters: {'p_m': 0.5505665746705423, 'alpha': 4.456081714779138, 'K': 20, 'beta': 1.6724818756238964}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 43.47855
Epoch 1, Val Loss: 15.76493
Epoch 2, Val Loss: 6.84995
Epoch 3, Val Loss: 6.59046
Epoch 4, Val Loss: 6.12540
Epoch 5, Val Loss: 5.96243
Epoch 6, Val Loss: 5.86875
Epoch 7, Val Loss: 5.98682
Epoch 8, Val Loss: 5.68826
Epoch 9, Val Loss: 5.52372
Epoch 10, Val Loss: 5.85975
Epoch 11, Val Loss: 5.49375
Epoch 12, Val Loss: 5.73595
Epoch 13, Val Loss: 5.64562
Epoch 14, Val Loss: 5.60275
Epoch 15, Val Loss: 5.54524
Epoch 16, Val Loss: 5.51629
Epoch 17, Val Loss: 5.76757
Epoch 18, Val Loss: 5.56637
Epoch 19, Val Loss: 5.60443
Epoch 20, Val Loss: 5.57896
Epoch 21, Val Loss: 5.55828
Epoch 22, Val Loss: 5.63000
Epoch 23, Val Loss: 5.72757
Epoch 24, Val Loss: 5.84418
Epoch 25, Val Loss: 5.60307
Epoch 26, Val Loss: 5.57527
Epoch 27, Val Loss: 5.59042
Epoch 28, Val Loss: 5.60865
Epoch 29, Val Loss: 5.74398
Epoch 30, Val Loss: 5.62194
Epoch 31, Val Loss: 5.74829
Epoch 32, Val Loss: 5.53786
Early stopping applies.
Saved Losses
{'MSE - mean': 5.772358603327134, 'MSE - std': 0.0, 'R2 - mean': 0.47357996922978995, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.90197
Epoch 1, Val Loss: 7.31818
Epoch 2, Val Loss: 5.66470
Epoch 3, Val Loss: 5.54850
Epoch 4, Val Loss: 5.38699
Epoch 5, Val Loss: 5.66750
Epoch 6, Val Loss: 5.57589
Epoch 7, Val Loss: 5.20950
Epoch 8, Val Loss: 5.20474
Epoch 9, Val Loss: 5.37755
Epoch 10, Val Loss: 5.09456
Epoch 11, Val Loss: 5.09290
Epoch 12, Val Loss: 4.99167
Epoch 13, Val Loss: 5.05234
Epoch 14, Val Loss: 4.86258
Epoch 15, Val Loss: 4.76174
Epoch 16, Val Loss: 4.64825
Epoch 17, Val Loss: 4.62736
Epoch 18, Val Loss: 4.63136
Epoch 19, Val Loss: 4.70128
Epoch 20, Val Loss: 4.42778
Epoch 21, Val Loss: 4.79976
Epoch 22, Val Loss: 5.13768
Epoch 23, Val Loss: 4.65396
Epoch 24, Val Loss: 4.27020
Epoch 25, Val Loss: 4.25931
Epoch 26, Val Loss: 4.64660
Epoch 27, Val Loss: 4.27357
Epoch 28, Val Loss: 4.19341
Epoch 29, Val Loss: 4.72034
Epoch 30, Val Loss: 4.16189
Epoch 31, Val Loss: 4.16890
Epoch 32, Val Loss: 4.32291
Epoch 33, Val Loss: 4.16608
Epoch 34, Val Loss: 4.14996
Epoch 35, Val Loss: 4.17161
Epoch 36, Val Loss: 4.20334
Epoch 37, Val Loss: 4.20884
Epoch 38, Val Loss: 4.40310
Epoch 39, Val Loss: 4.62500
Epoch 40, Val Loss: 4.12397
Epoch 41, Val Loss: 4.10401
Epoch 42, Val Loss: 4.12056
Epoch 43, Val Loss: 4.25751
Epoch 44, Val Loss: 4.10876
Epoch 45, Val Loss: 4.11131
Epoch 46, Val Loss: 4.18409
Epoch 47, Val Loss: 4.09067
Epoch 48, Val Loss: 5.00111
Epoch 49, Val Loss: 4.11475
Epoch 50, Val Loss: 4.04161
Epoch 51, Val Loss: 4.04578
Epoch 52, Val Loss: 4.27876
Epoch 53, Val Loss: 4.69489
Epoch 54, Val Loss: 4.08777
Epoch 55, Val Loss: 4.07356
Epoch 56, Val Loss: 4.14695
Epoch 57, Val Loss: 4.03355
Epoch 58, Val Loss: 4.14090
Epoch 59, Val Loss: 4.07451
Epoch 60, Val Loss: 4.66967
Epoch 61, Val Loss: 4.22371
Epoch 62, Val Loss: 4.18112
Epoch 63, Val Loss: 4.76849
Epoch 64, Val Loss: 4.91829
Epoch 65, Val Loss: 4.16996
Epoch 66, Val Loss: 4.03987
Epoch 67, Val Loss: 4.04838
Epoch 68, Val Loss: 4.04076
Epoch 69, Val Loss: 4.03056
Epoch 70, Val Loss: 4.20515
Epoch 71, Val Loss: 4.02150
Epoch 72, Val Loss: 3.99870
Epoch 73, Val Loss: 3.96288
Epoch 74, Val Loss: 4.04696
Epoch 75, Val Loss: 4.10017
Epoch 76, Val Loss: 4.05649
Epoch 77, Val Loss: 4.14077
Epoch 78, Val Loss: 3.98084
Epoch 79, Val Loss: 3.99465
Epoch 80, Val Loss: 4.10323
Epoch 81, Val Loss: 4.11406
Epoch 82, Val Loss: 3.95495
Epoch 83, Val Loss: 4.09494
Epoch 84, Val Loss: 3.96572
Epoch 85, Val Loss: 4.20456
Epoch 86, Val Loss: 4.32364
Epoch 87, Val Loss: 4.64197
Epoch 88, Val Loss: 4.00512
Epoch 89, Val Loss: 4.01028
Epoch 90, Val Loss: 3.93599
Epoch 91, Val Loss: 4.51634
Epoch 92, Val Loss: 4.14590
Epoch 93, Val Loss: 3.99160
Epoch 94, Val Loss: 4.14913
Epoch 95, Val Loss: 4.10041
Epoch 96, Val Loss: 3.96201
Epoch 97, Val Loss: 3.99971
Epoch 98, Val Loss: 3.96031
Epoch 99, Val Loss: 4.04399
Saved Losses
{'MSE - mean': 4.962548534749798, 'MSE - std': 0.809810068577336, 'R2 - mean': 0.5154561592181321, 'R2 - std': 0.04187618998834214} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.17490
Epoch 1, Val Loss: 13.01973
Epoch 2, Val Loss: 6.45959
Epoch 3, Val Loss: 6.05121
Epoch 4, Val Loss: 5.86548
Epoch 5, Val Loss: 5.65298
Epoch 6, Val Loss: 5.70028
Epoch 7, Val Loss: 5.50493
Epoch 8, Val Loss: 5.39419
Epoch 9, Val Loss: 5.41774
Epoch 10, Val Loss: 5.47488
Epoch 11, Val Loss: 5.50313
Epoch 12, Val Loss: 5.17630
Epoch 13, Val Loss: 5.57494
Epoch 14, Val Loss: 5.29440
Epoch 15, Val Loss: 5.43114
Epoch 16, Val Loss: 5.12049
Epoch 17, Val Loss: 5.03037
Epoch 18, Val Loss: 5.23158
Epoch 19, Val Loss: 5.15191
Epoch 20, Val Loss: 4.94480
Epoch 21, Val Loss: 4.93929
Epoch 22, Val Loss: 4.99259
Epoch 23, Val Loss: 4.96622
Epoch 24, Val Loss: 5.41993
Epoch 25, Val Loss: 5.33527
Epoch 26, Val Loss: 5.79164
Epoch 27, Val Loss: 4.99410
Epoch 28, Val Loss: 5.20887
Epoch 29, Val Loss: 4.96305
Epoch 30, Val Loss: 5.17997
Epoch 31, Val Loss: 5.07006
Epoch 32, Val Loss: 4.89775
Epoch 33, Val Loss: 4.81530
Epoch 34, Val Loss: 5.12747
Epoch 35, Val Loss: 5.44865
Epoch 36, Val Loss: 4.84279
Epoch 37, Val Loss: 4.87023
Epoch 38, Val Loss: 4.86344
Epoch 39, Val Loss: 4.87983
Epoch 40, Val Loss: 4.81499
Epoch 41, Val Loss: 4.85845
Epoch 42, Val Loss: 4.87862
Epoch 43, Val Loss: 4.77050
Epoch 44, Val Loss: 5.10167
Epoch 45, Val Loss: 4.82273
Epoch 46, Val Loss: 5.00173
Epoch 47, Val Loss: 4.86153
Epoch 48, Val Loss: 4.76591
Epoch 49, Val Loss: 4.93914
Epoch 50, Val Loss: 4.73025
Epoch 51, Val Loss: 4.76133
Epoch 52, Val Loss: 4.95598
Epoch 53, Val Loss: 4.96234
Epoch 54, Val Loss: 5.41368
Epoch 55, Val Loss: 5.02847
Epoch 56, Val Loss: 4.80081
Epoch 57, Val Loss: 4.99072
Epoch 58, Val Loss: 5.29596
Epoch 59, Val Loss: 4.83302
Epoch 60, Val Loss: 4.98994
Epoch 61, Val Loss: 4.73530
Epoch 62, Val Loss: 4.71105
Epoch 63, Val Loss: 4.72039
Epoch 64, Val Loss: 4.75073
Epoch 65, Val Loss: 4.76159
Epoch 66, Val Loss: 4.71973
Epoch 67, Val Loss: 4.86298
Epoch 68, Val Loss: 4.91280
Epoch 69, Val Loss: 5.03666
Epoch 70, Val Loss: 4.75471
Epoch 71, Val Loss: 4.97427
Epoch 72, Val Loss: 4.81647
Epoch 73, Val Loss: 4.80698
Epoch 74, Val Loss: 4.78418
Epoch 75, Val Loss: 4.91210
Epoch 76, Val Loss: 4.75837
Epoch 77, Val Loss: 4.89117
Epoch 78, Val Loss: 4.86640
Epoch 79, Val Loss: 4.80317
Epoch 80, Val Loss: 4.74401
Epoch 81, Val Loss: 4.77883
Epoch 82, Val Loss: 4.74282
Epoch 83, Val Loss: 4.67650
Epoch 84, Val Loss: 4.82895
Epoch 85, Val Loss: 5.10395
Epoch 86, Val Loss: 4.86737
Epoch 87, Val Loss: 5.31795
Epoch 88, Val Loss: 4.68064
Epoch 89, Val Loss: 4.74222
Epoch 90, Val Loss: 4.84162
Epoch 91, Val Loss: 4.65436
Epoch 92, Val Loss: 4.96036
Epoch 93, Val Loss: 4.89045
Epoch 94, Val Loss: 4.85813
Epoch 95, Val Loss: 4.73607
Epoch 96, Val Loss: 5.04733
Epoch 97, Val Loss: 4.86850
Epoch 98, Val Loss: 4.67578
Epoch 99, Val Loss: 4.71336
Saved Losses
{'MSE - mean': 4.88119618779007, 'MSE - std': 0.671141793382391, 'R2 - mean': 0.5222063067416287, 'R2 - std': 0.03549937804813513} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.57711
Epoch 1, Val Loss: 7.93088
Epoch 2, Val Loss: 5.89845
Epoch 3, Val Loss: 5.47826
Epoch 4, Val Loss: 5.52289
Epoch 5, Val Loss: 5.22356
Epoch 6, Val Loss: 5.13582
Epoch 7, Val Loss: 4.88074
Epoch 8, Val Loss: 5.20119
Epoch 9, Val Loss: 4.78661
Epoch 10, Val Loss: 4.71162
Epoch 11, Val Loss: 4.87127
Epoch 12, Val Loss: 4.62227
Epoch 13, Val Loss: 4.60302
Epoch 14, Val Loss: 4.62029
Epoch 15, Val Loss: 4.67473
Epoch 16, Val Loss: 4.51069
Epoch 17, Val Loss: 4.85438
Epoch 18, Val Loss: 4.57945
Epoch 19, Val Loss: 4.44654
Epoch 20, Val Loss: 4.44683
Epoch 21, Val Loss: 4.64192
Epoch 22, Val Loss: 4.48381
Epoch 23, Val Loss: 4.40518
Epoch 24, Val Loss: 4.41146
Epoch 25, Val Loss: 4.55181
Epoch 26, Val Loss: 4.37415
Epoch 27, Val Loss: 4.41524
Epoch 28, Val Loss: 4.30405
Epoch 29, Val Loss: 4.29321
Epoch 30, Val Loss: 4.36213
Epoch 31, Val Loss: 4.31707
Epoch 32, Val Loss: 4.43551
Epoch 33, Val Loss: 4.31982
Epoch 34, Val Loss: 4.68521
Epoch 35, Val Loss: 4.47379
Epoch 36, Val Loss: 4.63725
Epoch 37, Val Loss: 4.28468
Epoch 38, Val Loss: 4.24194
Epoch 39, Val Loss: 4.31809
Epoch 40, Val Loss: 4.23187
Epoch 41, Val Loss: 4.14847
Epoch 42, Val Loss: 4.26598
Epoch 43, Val Loss: 4.56059
Epoch 44, Val Loss: 4.55171
Epoch 45, Val Loss: 4.31447
Epoch 46, Val Loss: 4.29204
Epoch 47, Val Loss: 4.18805
Epoch 48, Val Loss: 4.38350
Epoch 49, Val Loss: 4.93254
Epoch 50, Val Loss: 4.26678
Epoch 51, Val Loss: 4.11799
Epoch 52, Val Loss: 4.24772
Epoch 53, Val Loss: 4.15948
Epoch 54, Val Loss: 4.04785
Epoch 55, Val Loss: 4.60201
Epoch 56, Val Loss: 4.26276
Epoch 57, Val Loss: 4.16857
Epoch 58, Val Loss: 4.09277
Epoch 59, Val Loss: 4.18260
Epoch 60, Val Loss: 4.03533
Epoch 61, Val Loss: 4.15636
Epoch 62, Val Loss: 4.11595
Epoch 63, Val Loss: 4.07471
Epoch 64, Val Loss: 4.22003
Epoch 65, Val Loss: 4.06368
Epoch 66, Val Loss: 4.24917
Epoch 67, Val Loss: 4.21968
Epoch 68, Val Loss: 4.04525
Epoch 69, Val Loss: 4.01986
Epoch 70, Val Loss: 4.14741
Epoch 71, Val Loss: 4.15420
Epoch 72, Val Loss: 4.20983
Epoch 73, Val Loss: 4.24711
Epoch 74, Val Loss: 4.03373
Epoch 75, Val Loss: 4.06030
Epoch 76, Val Loss: 4.19387
Epoch 77, Val Loss: 4.27898
Epoch 78, Val Loss: 4.11621
Epoch 79, Val Loss: 4.27496
Epoch 80, Val Loss: 4.08968
Epoch 81, Val Loss: 4.18167
Epoch 82, Val Loss: 4.06228
Epoch 83, Val Loss: 4.17458
Epoch 84, Val Loss: 4.21951
Epoch 85, Val Loss: 4.17480
Epoch 86, Val Loss: 4.23353
Epoch 87, Val Loss: 4.00574
Epoch 88, Val Loss: 4.64330
Epoch 89, Val Loss: 4.06923
Epoch 90, Val Loss: 4.34365
Epoch 91, Val Loss: 4.33375
Epoch 92, Val Loss: 4.19492
Epoch 93, Val Loss: 4.23783
Epoch 94, Val Loss: 4.09159
Epoch 95, Val Loss: 4.04492
Epoch 96, Val Loss: 4.15518
Epoch 97, Val Loss: 4.17209
Epoch 98, Val Loss: 4.33254
Epoch 99, Val Loss: 4.34696
Saved Losses
{'MSE - mean': 4.733313383500094, 'MSE - std': 0.635162539459311, 'R2 - mean': 0.5269914401714246, 'R2 - std': 0.03184096240970372} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.78124
Epoch 1, Val Loss: 14.69434
Epoch 2, Val Loss: 7.63459
Epoch 3, Val Loss: 7.45275
Epoch 4, Val Loss: 7.29155
Epoch 5, Val Loss: 7.02330
Epoch 6, Val Loss: 6.82551
Epoch 7, Val Loss: 6.56721
Epoch 8, Val Loss: 6.26884
Epoch 9, Val Loss: 6.53707
Epoch 10, Val Loss: 6.06050
Epoch 11, Val Loss: 6.00601
Epoch 12, Val Loss: 6.09275
Epoch 13, Val Loss: 5.98725
Epoch 14, Val Loss: 6.46321
Epoch 15, Val Loss: 5.69300
Epoch 16, Val Loss: 5.76000
Epoch 17, Val Loss: 5.88094
Epoch 18, Val Loss: 5.58107
Epoch 19, Val Loss: 5.54689
Epoch 20, Val Loss: 5.53499
Epoch 21, Val Loss: 5.57977
Epoch 22, Val Loss: 5.69827
Epoch 23, Val Loss: 5.55229
Epoch 24, Val Loss: 5.63071
Epoch 25, Val Loss: 5.72660
Epoch 26, Val Loss: 5.73189
Epoch 27, Val Loss: 5.63261
Epoch 28, Val Loss: 5.46730
Epoch 29, Val Loss: 5.48136
Epoch 30, Val Loss: 5.95575
Epoch 31, Val Loss: 5.58117
Epoch 32, Val Loss: 5.53917
Epoch 33, Val Loss: 5.47103
Epoch 34, Val Loss: 5.47173
Epoch 35, Val Loss: 5.50795
Epoch 36, Val Loss: 5.38554
Epoch 37, Val Loss: 5.44830
Epoch 38, Val Loss: 5.42979
Epoch 39, Val Loss: 5.77048
Epoch 40, Val Loss: 5.76396
Epoch 41, Val Loss: 5.36541
Epoch 42, Val Loss: 5.52076
Epoch 43, Val Loss: 5.46491
Epoch 44, Val Loss: 5.40209
Epoch 45, Val Loss: 5.37142
Epoch 46, Val Loss: 5.31135
Epoch 47, Val Loss: 5.42613
Epoch 48, Val Loss: 5.26621
Epoch 49, Val Loss: 5.51483
Epoch 50, Val Loss: 5.44453
Epoch 51, Val Loss: 5.57669
Epoch 52, Val Loss: 6.34121
Epoch 53, Val Loss: 5.40438
Epoch 54, Val Loss: 5.56867
Epoch 55, Val Loss: 5.47212
Epoch 56, Val Loss: 5.31595
Epoch 57, Val Loss: 5.26115
Epoch 58, Val Loss: 5.43883
Epoch 59, Val Loss: 5.36902
Epoch 60, Val Loss: 5.39786
Epoch 61, Val Loss: 5.48423
Epoch 62, Val Loss: 5.74409
Epoch 63, Val Loss: 5.38513
Epoch 64, Val Loss: 5.31882
Epoch 65, Val Loss: 5.39147
Epoch 66, Val Loss: 5.61711
Epoch 67, Val Loss: 5.45922
Epoch 68, Val Loss: 5.44450
Epoch 69, Val Loss: 5.31125
Epoch 70, Val Loss: 5.41315
Epoch 71, Val Loss: 5.23013
Epoch 72, Val Loss: 5.64414
Epoch 73, Val Loss: 5.46310
Epoch 74, Val Loss: 5.38621
Epoch 75, Val Loss: 5.62672
Epoch 76, Val Loss: 5.46547
Epoch 77, Val Loss: 5.32299
Epoch 78, Val Loss: 5.39729
Epoch 79, Val Loss: 5.34547
Epoch 80, Val Loss: 5.33413
Epoch 81, Val Loss: 5.34564
Epoch 82, Val Loss: 5.83188
Epoch 83, Val Loss: 5.41403
Epoch 84, Val Loss: 5.65197
Epoch 85, Val Loss: 5.22084
Epoch 86, Val Loss: 5.32407
Epoch 87, Val Loss: 5.38022
Epoch 88, Val Loss: 5.46552
Epoch 89, Val Loss: 5.61407
Epoch 90, Val Loss: 5.16054
Epoch 91, Val Loss: 5.46458
Epoch 92, Val Loss: 5.23655
Epoch 93, Val Loss: 5.98119
Epoch 94, Val Loss: 5.54055
Epoch 95, Val Loss: 5.62763
Epoch 96, Val Loss: 5.38569
Epoch 97, Val Loss: 5.61311
Epoch 98, Val Loss: 5.66292
Epoch 99, Val Loss: 5.51261
Saved Losses
{'MSE - mean': 4.820015590628351, 'MSE - std': 0.5939816934128239, 'R2 - mean': 0.5361342018152879, 'R2 - std': 0.033844318158989764} 
 

Results After CV: {'MSE - mean': 4.820015590628351, 'MSE - std': 0.5939816934128239, 'R2 - mean': 0.5361342018152879, 'R2 - std': 0.033844318158989764}
Train time: 103.68471905900006
Inference time: 0.05135503519995836
Finished cross validation
Trial 18 finished with value: 4.820015590628351 and parameters: {'p_m': 0.1134404859052685, 'alpha': 8.465967055223135, 'K': 20, 'beta': 0.15271067626602453}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.00117
Epoch 1, Val Loss: 10.45214
Epoch 2, Val Loss: 6.78558
Epoch 3, Val Loss: 6.66745
Epoch 4, Val Loss: 6.09432
Epoch 5, Val Loss: 5.78246
Epoch 6, Val Loss: 6.25190
Epoch 7, Val Loss: 5.89765
Epoch 8, Val Loss: 5.44369
Epoch 9, Val Loss: 5.38607
Epoch 10, Val Loss: 5.91965
Epoch 11, Val Loss: 5.50646
Epoch 12, Val Loss: 5.57021
Epoch 13, Val Loss: 5.35383
Epoch 14, Val Loss: 5.16032
Epoch 15, Val Loss: 5.52780
Epoch 16, Val Loss: 5.04281
Epoch 17, Val Loss: 5.03408
Epoch 18, Val Loss: 5.18001
Epoch 19, Val Loss: 5.18727
Epoch 20, Val Loss: 4.95015
Epoch 21, Val Loss: 5.09447
Epoch 22, Val Loss: 4.90407
Epoch 23, Val Loss: 5.31105
Epoch 24, Val Loss: 4.93861
Epoch 25, Val Loss: 5.18609
Epoch 26, Val Loss: 5.08367
Epoch 27, Val Loss: 5.04419
Epoch 28, Val Loss: 4.90813
Epoch 29, Val Loss: 4.84879
Epoch 30, Val Loss: 4.90072
Epoch 31, Val Loss: 4.85426
Epoch 32, Val Loss: 5.03158
Epoch 33, Val Loss: 4.92979
Epoch 34, Val Loss: 5.02867
Epoch 35, Val Loss: 4.82672
Epoch 36, Val Loss: 4.92567
Epoch 37, Val Loss: 4.82967
Epoch 38, Val Loss: 4.75776
Epoch 39, Val Loss: 5.02429
Epoch 40, Val Loss: 4.73919
Epoch 41, Val Loss: 5.07598
Epoch 42, Val Loss: 5.21961
Epoch 43, Val Loss: 4.82612
Epoch 44, Val Loss: 4.85720
Epoch 45, Val Loss: 4.84625
Epoch 46, Val Loss: 4.83560
Epoch 47, Val Loss: 4.89877
Epoch 48, Val Loss: 4.86949
Epoch 49, Val Loss: 4.79930
Epoch 50, Val Loss: 4.70441
Epoch 51, Val Loss: 4.73271
Epoch 52, Val Loss: 4.98630
Epoch 53, Val Loss: 5.58694
Epoch 54, Val Loss: 4.69700
Epoch 55, Val Loss: 4.70184
Epoch 56, Val Loss: 4.58458
Epoch 57, Val Loss: 4.61293
Epoch 58, Val Loss: 4.65975
Epoch 59, Val Loss: 4.68231
Epoch 60, Val Loss: 4.71589
Epoch 61, Val Loss: 4.67064
Epoch 62, Val Loss: 4.77742
Epoch 63, Val Loss: 4.71979
Epoch 64, Val Loss: 4.69771
Epoch 65, Val Loss: 4.60510
Epoch 66, Val Loss: 4.58419
Epoch 67, Val Loss: 4.72795
Epoch 68, Val Loss: 4.58386
Epoch 69, Val Loss: 4.61203
Epoch 70, Val Loss: 4.57942
Epoch 71, Val Loss: 4.62412
Epoch 72, Val Loss: 4.78862
Epoch 73, Val Loss: 4.62017
Epoch 74, Val Loss: 4.68267
Epoch 75, Val Loss: 4.86358
Epoch 76, Val Loss: 4.75469
Epoch 77, Val Loss: 4.51769
Epoch 78, Val Loss: 4.56871
Epoch 79, Val Loss: 4.70208
Epoch 80, Val Loss: 4.49081
Epoch 81, Val Loss: 4.72505
Epoch 82, Val Loss: 4.53821
Epoch 83, Val Loss: 4.69555
Epoch 84, Val Loss: 4.77588
Epoch 85, Val Loss: 4.77302
Epoch 86, Val Loss: 4.70477
Epoch 87, Val Loss: 4.63425
Epoch 88, Val Loss: 4.61393
Epoch 89, Val Loss: 4.80366
Epoch 90, Val Loss: 4.82147
Epoch 91, Val Loss: 4.74842
Epoch 92, Val Loss: 4.87666
Epoch 93, Val Loss: 4.69554
Epoch 94, Val Loss: 4.67786
Epoch 95, Val Loss: 4.66407
Epoch 96, Val Loss: 4.55422
Epoch 97, Val Loss: 4.96978
Epoch 98, Val Loss: 4.71492
Epoch 99, Val Loss: 4.60194
Saved Losses
{'MSE - mean': 4.64570651491416, 'MSE - std': 0.0, 'R2 - mean': 0.5763269168480176, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.66951
Epoch 1, Val Loss: 8.61666
Epoch 2, Val Loss: 5.30070
Epoch 3, Val Loss: 5.17589
Epoch 4, Val Loss: 5.08840
Epoch 5, Val Loss: 5.52073
Epoch 6, Val Loss: 5.04307
Epoch 7, Val Loss: 5.42099
Epoch 8, Val Loss: 4.76143
Epoch 9, Val Loss: 5.16436
Epoch 10, Val Loss: 4.58562
Epoch 11, Val Loss: 4.59080
Epoch 12, Val Loss: 4.70990
Epoch 13, Val Loss: 4.47637
Epoch 14, Val Loss: 4.43640
Epoch 15, Val Loss: 4.72639
Epoch 16, Val Loss: 4.45481
Epoch 17, Val Loss: 4.34646
Epoch 18, Val Loss: 4.57172
Epoch 19, Val Loss: 4.42600
Epoch 20, Val Loss: 4.29788
Epoch 21, Val Loss: 4.26970
Epoch 22, Val Loss: 4.27035
Epoch 23, Val Loss: 4.35980
Epoch 24, Val Loss: 4.24556
Epoch 25, Val Loss: 4.43239
Epoch 26, Val Loss: 4.45100
Epoch 27, Val Loss: 4.15259
Epoch 28, Val Loss: 4.15407
Epoch 29, Val Loss: 4.49888
Epoch 30, Val Loss: 4.16915
Epoch 31, Val Loss: 4.15175
Epoch 32, Val Loss: 4.21732
Epoch 33, Val Loss: 4.23144
Epoch 34, Val Loss: 4.15642
Epoch 35, Val Loss: 4.19679
Epoch 36, Val Loss: 4.33632
Epoch 37, Val Loss: 4.52980
Epoch 38, Val Loss: 4.11853
Epoch 39, Val Loss: 4.14874
Epoch 40, Val Loss: 4.11933
Epoch 41, Val Loss: 4.17382
Epoch 42, Val Loss: 4.65868
Epoch 43, Val Loss: 4.10814
Epoch 44, Val Loss: 4.13330
Epoch 45, Val Loss: 4.10594
Epoch 46, Val Loss: 4.20126
Epoch 47, Val Loss: 4.16572
Epoch 48, Val Loss: 4.44647
Epoch 49, Val Loss: 4.14142
Epoch 50, Val Loss: 4.09896
Epoch 51, Val Loss: 4.16437
Epoch 52, Val Loss: 4.07548
Epoch 53, Val Loss: 4.18231
Epoch 54, Val Loss: 4.34318
Epoch 55, Val Loss: 4.27361
Epoch 56, Val Loss: 4.08228
Epoch 57, Val Loss: 4.05609
Epoch 58, Val Loss: 4.11624
Epoch 59, Val Loss: 4.13264
Epoch 60, Val Loss: 4.21180
Epoch 61, Val Loss: 4.03059
Epoch 62, Val Loss: 4.15630
Epoch 63, Val Loss: 4.12113
Epoch 64, Val Loss: 4.09842
Epoch 65, Val Loss: 4.19184
Epoch 66, Val Loss: 5.33903
Epoch 67, Val Loss: 4.86187
Epoch 68, Val Loss: 4.20762
Epoch 69, Val Loss: 4.19610
Epoch 70, Val Loss: 4.22708
Epoch 71, Val Loss: 4.05607
Epoch 72, Val Loss: 4.34041
Epoch 73, Val Loss: 4.11142
Epoch 74, Val Loss: 4.20293
Epoch 75, Val Loss: 4.04755
Epoch 76, Val Loss: 4.20885
Epoch 77, Val Loss: 4.76566
Epoch 78, Val Loss: 4.19616
Epoch 79, Val Loss: 4.38132
Epoch 80, Val Loss: 4.08195
Epoch 81, Val Loss: 4.21695
Epoch 82, Val Loss: 4.39824
Early stopping applies.
Saved Losses
{'MSE - mean': 4.383725650131584, 'MSE - std': 0.2619808647825761, 'R2 - mean': 0.5684815429646671, 'R2 - std': 0.007845373883350493} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.84186
Epoch 1, Val Loss: 12.23091
Epoch 2, Val Loss: 6.39963
Epoch 3, Val Loss: 6.21472
Epoch 4, Val Loss: 6.06847
Epoch 5, Val Loss: 6.04868
Epoch 6, Val Loss: 5.93175
Epoch 7, Val Loss: 5.84297
Epoch 8, Val Loss: 5.70266
Epoch 9, Val Loss: 5.63384
Epoch 10, Val Loss: 5.64500
Epoch 11, Val Loss: 5.66128
Epoch 12, Val Loss: 5.72178
Epoch 13, Val Loss: 5.43831
Epoch 14, Val Loss: 5.48970
Epoch 15, Val Loss: 5.30462
Epoch 16, Val Loss: 5.49437
Epoch 17, Val Loss: 5.35721
Epoch 18, Val Loss: 5.23065
Epoch 19, Val Loss: 5.83546
Epoch 20, Val Loss: 5.36091
Epoch 21, Val Loss: 5.19545
Epoch 22, Val Loss: 5.19610
Epoch 23, Val Loss: 5.35544
Epoch 24, Val Loss: 5.40657
Epoch 25, Val Loss: 5.19849
Epoch 26, Val Loss: 5.74248
Epoch 27, Val Loss: 5.45161
Epoch 28, Val Loss: 5.18716
Epoch 29, Val Loss: 5.27802
Epoch 30, Val Loss: 5.51508
Epoch 31, Val Loss: 5.27578
Epoch 32, Val Loss: 5.12162
Epoch 33, Val Loss: 5.10361
Epoch 34, Val Loss: 5.04991
Epoch 35, Val Loss: 5.13783
Epoch 36, Val Loss: 5.21095
Epoch 37, Val Loss: 5.11246
Epoch 38, Val Loss: 5.20202
Epoch 39, Val Loss: 5.18763
Epoch 40, Val Loss: 5.20578
Epoch 41, Val Loss: 5.19266
Epoch 42, Val Loss: 5.37321
Epoch 43, Val Loss: 5.02883
Epoch 44, Val Loss: 5.15945
Epoch 45, Val Loss: 5.14217
Epoch 46, Val Loss: 5.13025
Epoch 47, Val Loss: 5.28776
Epoch 48, Val Loss: 5.48784
Epoch 49, Val Loss: 4.98506
Epoch 50, Val Loss: 4.96655
Epoch 51, Val Loss: 5.01126
Epoch 52, Val Loss: 5.03335
Epoch 53, Val Loss: 5.39228
Epoch 54, Val Loss: 4.97241
Epoch 55, Val Loss: 5.09323
Epoch 56, Val Loss: 4.94901
Epoch 57, Val Loss: 4.95114
Epoch 58, Val Loss: 5.14320
Epoch 59, Val Loss: 5.02710
Epoch 60, Val Loss: 4.99804
Epoch 61, Val Loss: 4.96230
Epoch 62, Val Loss: 4.94917
Epoch 63, Val Loss: 4.95481
Epoch 64, Val Loss: 5.04919
Epoch 65, Val Loss: 4.90862
Epoch 66, Val Loss: 5.24145
Epoch 67, Val Loss: 5.05303
Epoch 68, Val Loss: 4.88094
Epoch 69, Val Loss: 5.07790
Epoch 70, Val Loss: 4.92655
Epoch 71, Val Loss: 4.95983
Epoch 72, Val Loss: 5.36080
Epoch 73, Val Loss: 4.90858
Epoch 74, Val Loss: 4.86846
Epoch 75, Val Loss: 5.10167
Epoch 76, Val Loss: 5.27075
Epoch 77, Val Loss: 5.04938
Epoch 78, Val Loss: 4.85800
Epoch 79, Val Loss: 5.37260
Epoch 80, Val Loss: 4.94894
Epoch 81, Val Loss: 4.96099
Epoch 82, Val Loss: 4.95796
Epoch 83, Val Loss: 4.94962
Epoch 84, Val Loss: 4.92479
Epoch 85, Val Loss: 5.04478
Epoch 86, Val Loss: 4.94411
Epoch 87, Val Loss: 4.96284
Epoch 88, Val Loss: 4.98185
Epoch 89, Val Loss: 5.05245
Epoch 90, Val Loss: 4.96962
Epoch 91, Val Loss: 5.08933
Epoch 92, Val Loss: 5.06548
Epoch 93, Val Loss: 5.01293
Epoch 94, Val Loss: 5.03465
Epoch 95, Val Loss: 4.96543
Epoch 96, Val Loss: 5.36459
Epoch 97, Val Loss: 5.10402
Epoch 98, Val Loss: 4.95239
Epoch 99, Val Loss: 4.88523
Early stopping applies.
Saved Losses
{'MSE - mean': 4.576021818046957, 'MSE - std': 0.3459936628485546, 'R2 - mean': 0.5496150447701439, 'R2 - std': 0.02743943820782304} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.54696
Epoch 1, Val Loss: 7.68861
Epoch 2, Val Loss: 6.06113
Epoch 3, Val Loss: 5.40805
Epoch 4, Val Loss: 5.28522
Epoch 5, Val Loss: 5.29140
Epoch 6, Val Loss: 5.36461
Epoch 7, Val Loss: 5.56335
Epoch 8, Val Loss: 5.17562
Epoch 9, Val Loss: 5.08015
Epoch 10, Val Loss: 5.29183
Epoch 11, Val Loss: 4.98721
Epoch 12, Val Loss: 5.27922
Epoch 13, Val Loss: 5.05027
Epoch 14, Val Loss: 5.02141
Epoch 15, Val Loss: 4.89299
Epoch 16, Val Loss: 4.91562
Epoch 17, Val Loss: 4.88351
Epoch 18, Val Loss: 4.92252
Epoch 19, Val Loss: 4.79623
Epoch 20, Val Loss: 4.83537
Epoch 21, Val Loss: 4.86299
Epoch 22, Val Loss: 4.92269
Epoch 23, Val Loss: 4.87275
Epoch 24, Val Loss: 4.64318
Epoch 25, Val Loss: 4.75783
Epoch 26, Val Loss: 4.62133
Epoch 27, Val Loss: 4.57712
Epoch 28, Val Loss: 4.56540
Epoch 29, Val Loss: 4.63311
Epoch 30, Val Loss: 4.55901
Epoch 31, Val Loss: 4.49917
Epoch 32, Val Loss: 4.48326
Epoch 33, Val Loss: 4.57612
Epoch 34, Val Loss: 4.50253
Epoch 35, Val Loss: 4.53516
Epoch 36, Val Loss: 4.53809
Epoch 37, Val Loss: 4.88821
Epoch 38, Val Loss: 4.28627
Epoch 39, Val Loss: 4.26386
Epoch 40, Val Loss: 4.33012
Epoch 41, Val Loss: 4.30174
Epoch 42, Val Loss: 4.56218
Epoch 43, Val Loss: 4.21860
Epoch 44, Val Loss: 4.40506
Epoch 45, Val Loss: 4.15293
Epoch 46, Val Loss: 4.28558
Epoch 47, Val Loss: 4.20076
Epoch 48, Val Loss: 4.19986
Epoch 49, Val Loss: 4.26317
Epoch 50, Val Loss: 4.19024
Epoch 51, Val Loss: 4.33465
Epoch 52, Val Loss: 4.31215
Epoch 53, Val Loss: 4.32763
Epoch 54, Val Loss: 4.11657
Epoch 55, Val Loss: 4.23836
Epoch 56, Val Loss: 4.12763
Epoch 57, Val Loss: 4.43457
Epoch 58, Val Loss: 4.19272
Epoch 59, Val Loss: 4.08626
Epoch 60, Val Loss: 4.10200
Epoch 61, Val Loss: 4.16212
Epoch 62, Val Loss: 4.54419
Epoch 63, Val Loss: 4.24153
Epoch 64, Val Loss: 4.19755
Epoch 65, Val Loss: 4.15768
Epoch 66, Val Loss: 4.70930
Epoch 67, Val Loss: 4.07466
Epoch 68, Val Loss: 4.05057
Epoch 69, Val Loss: 4.08239
Epoch 70, Val Loss: 4.52906
Epoch 71, Val Loss: 4.05593
Epoch 72, Val Loss: 4.41716
Epoch 73, Val Loss: 4.15390
Epoch 74, Val Loss: 4.09842
Epoch 75, Val Loss: 4.15059
Epoch 76, Val Loss: 4.16764
Epoch 77, Val Loss: 4.13349
Epoch 78, Val Loss: 4.12957
Epoch 79, Val Loss: 4.22862
Epoch 80, Val Loss: 4.27807
Epoch 81, Val Loss: 4.11951
Epoch 82, Val Loss: 5.71009
Epoch 83, Val Loss: 4.38508
Epoch 84, Val Loss: 4.06826
Epoch 85, Val Loss: 4.03157
Epoch 86, Val Loss: 4.06150
Epoch 87, Val Loss: 4.03354
Epoch 88, Val Loss: 4.15207
Epoch 89, Val Loss: 4.04469
Epoch 90, Val Loss: 4.19691
Epoch 91, Val Loss: 4.20075
Epoch 92, Val Loss: 4.04794
Epoch 93, Val Loss: 4.01291
Epoch 94, Val Loss: 4.06548
Epoch 95, Val Loss: 4.04132
Epoch 96, Val Loss: 4.31191
Epoch 97, Val Loss: 3.98937
Epoch 98, Val Loss: 4.00102
Epoch 99, Val Loss: 3.99069
Saved Losses
{'MSE - mean': 4.50506450698936, 'MSE - std': 0.3238649888859448, 'R2 - mean': 0.547480430538378, 'R2 - std': 0.02404915405219226} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.04399
Epoch 1, Val Loss: 17.96520
Epoch 2, Val Loss: 9.48176
Epoch 3, Val Loss: 7.61349
Epoch 4, Val Loss: 7.73537
Epoch 5, Val Loss: 7.12463
Epoch 6, Val Loss: 7.00826
Epoch 7, Val Loss: 7.10369
Epoch 8, Val Loss: 6.83547
Epoch 9, Val Loss: 6.78698
Epoch 10, Val Loss: 6.79283
Epoch 11, Val Loss: 6.66865
Epoch 12, Val Loss: 6.62997
Epoch 13, Val Loss: 6.57786
Epoch 14, Val Loss: 6.51351
Epoch 15, Val Loss: 6.95565
Epoch 16, Val Loss: 6.64007
Epoch 17, Val Loss: 6.45535
Epoch 18, Val Loss: 6.98650
Epoch 19, Val Loss: 6.52048
Epoch 20, Val Loss: 6.21742
Epoch 21, Val Loss: 6.69957
Epoch 22, Val Loss: 6.30577
Epoch 23, Val Loss: 6.45817
Epoch 24, Val Loss: 6.31258
Epoch 25, Val Loss: 6.39821
Epoch 26, Val Loss: 6.20575
Epoch 27, Val Loss: 6.20146
Epoch 28, Val Loss: 6.12834
Epoch 29, Val Loss: 6.60615
Epoch 30, Val Loss: 6.24006
Epoch 31, Val Loss: 6.65347
Epoch 32, Val Loss: 6.15052
Epoch 33, Val Loss: 6.17074
Epoch 34, Val Loss: 6.06085
Epoch 35, Val Loss: 6.15009
Epoch 36, Val Loss: 6.26359
Epoch 37, Val Loss: 6.08088
Epoch 38, Val Loss: 5.96601
Epoch 39, Val Loss: 6.19635
Epoch 40, Val Loss: 6.03150
Epoch 41, Val Loss: 5.97194
Epoch 42, Val Loss: 6.09530
Epoch 43, Val Loss: 6.11667
Epoch 44, Val Loss: 6.03848
Epoch 45, Val Loss: 6.10045
Epoch 46, Val Loss: 5.90670
Epoch 47, Val Loss: 6.03936
Epoch 48, Val Loss: 6.07154
Epoch 49, Val Loss: 6.12200
Epoch 50, Val Loss: 6.03693
Epoch 51, Val Loss: 6.11146
Epoch 52, Val Loss: 6.05444
Epoch 53, Val Loss: 5.98897
Epoch 54, Val Loss: 5.85850
Epoch 55, Val Loss: 5.96296
Epoch 56, Val Loss: 6.25818
Epoch 57, Val Loss: 5.96325
Epoch 58, Val Loss: 6.06765
Epoch 59, Val Loss: 6.07271
Epoch 60, Val Loss: 6.00759
Epoch 61, Val Loss: 5.93908
Epoch 62, Val Loss: 5.82851
Epoch 63, Val Loss: 5.92921
Epoch 64, Val Loss: 5.91327
Epoch 65, Val Loss: 6.63060
Epoch 66, Val Loss: 5.97461
Epoch 67, Val Loss: 5.95236
Epoch 68, Val Loss: 5.79389
Epoch 69, Val Loss: 5.78390
Epoch 70, Val Loss: 5.84255
Epoch 71, Val Loss: 6.44370
Epoch 72, Val Loss: 6.00388
Epoch 73, Val Loss: 6.29090
Epoch 74, Val Loss: 6.03527
Epoch 75, Val Loss: 5.93748
Epoch 76, Val Loss: 5.84078
Epoch 77, Val Loss: 6.01017
Epoch 78, Val Loss: 5.84644
Epoch 79, Val Loss: 5.82447
Epoch 80, Val Loss: 6.04042
Epoch 81, Val Loss: 5.84940
Epoch 82, Val Loss: 6.01041
Epoch 83, Val Loss: 5.76973
Epoch 84, Val Loss: 5.92213
Epoch 85, Val Loss: 6.00127
Epoch 86, Val Loss: 5.76680
Epoch 87, Val Loss: 6.10710
Epoch 88, Val Loss: 6.11334
Epoch 89, Val Loss: 5.78574
Epoch 90, Val Loss: 5.69172
Epoch 91, Val Loss: 5.73053
Epoch 92, Val Loss: 5.70263
Epoch 93, Val Loss: 6.01947
Epoch 94, Val Loss: 6.00711
Epoch 95, Val Loss: 5.90256
Epoch 96, Val Loss: 5.80973
Epoch 97, Val Loss: 5.70080
Epoch 98, Val Loss: 6.15161
Epoch 99, Val Loss: 5.75073
Saved Losses
{'MSE - mean': 4.741498013148487, 'MSE - std': 0.5545394811550088, 'R2 - mean': 0.54391788488829, 'R2 - std': 0.022659575780157655} 
 

Results After CV: {'MSE - mean': 4.741498013148487, 'MSE - std': 0.5545394811550088, 'R2 - mean': 0.54391788488829, 'R2 - std': 0.022659575780157655}
Train time: 79.65792263780004
Inference time: 0.05162380839992693
Finished cross validation
Trial 19 finished with value: 4.741498013148487 and parameters: {'p_m': 0.8908751528421193, 'alpha': 2.5850908012809475, 'K': 10, 'beta': 2.3015367211286875}. Best is trial 8 with value: 4.638784670488211.
Best parameters: {'p_m': 0.13801609063901107, 'alpha': 3.6391053225232315, 'K': 10, 'beta': 0.33225973940697795}
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 41.66764
Epoch 1, Val Loss: 12.46088
Epoch 2, Val Loss: 7.06280
Epoch 3, Val Loss: 6.70739
Epoch 4, Val Loss: 6.35693
Epoch 5, Val Loss: 6.23828
Epoch 6, Val Loss: 5.91378
Epoch 7, Val Loss: 5.78069
Epoch 8, Val Loss: 5.70763
Epoch 9, Val Loss: 5.55655
Epoch 10, Val Loss: 5.61365
Epoch 11, Val Loss: 5.50338
Epoch 12, Val Loss: 5.86036
Epoch 13, Val Loss: 5.46545
Epoch 14, Val Loss: 5.34362
Epoch 15, Val Loss: 5.70266
Epoch 16, Val Loss: 5.33241
Epoch 17, Val Loss: 5.38679
Epoch 18, Val Loss: 5.36820
Epoch 19, Val Loss: 5.41809
Epoch 20, Val Loss: 5.46461
Epoch 21, Val Loss: 5.25216
Epoch 22, Val Loss: 5.18995
Epoch 23, Val Loss: 5.13224
Epoch 24, Val Loss: 5.30472
Epoch 25, Val Loss: 5.19985
Epoch 26, Val Loss: 5.32795
Epoch 27, Val Loss: 5.00860
Epoch 28, Val Loss: 4.98244
Epoch 29, Val Loss: 4.96500
Epoch 30, Val Loss: 5.12198
Epoch 31, Val Loss: 4.94524
Epoch 32, Val Loss: 5.00197
Epoch 33, Val Loss: 4.88839
Epoch 34, Val Loss: 4.83495
Epoch 35, Val Loss: 4.91584
Epoch 36, Val Loss: 4.91670
Epoch 37, Val Loss: 4.83574
Epoch 38, Val Loss: 4.84077
Epoch 39, Val Loss: 4.86514
Epoch 40, Val Loss: 4.78180
Epoch 41, Val Loss: 5.11983
Epoch 42, Val Loss: 4.89237
Epoch 43, Val Loss: 4.98896
Epoch 44, Val Loss: 4.79402
Epoch 45, Val Loss: 4.78067
Epoch 46, Val Loss: 4.83732
Epoch 47, Val Loss: 4.81859
Epoch 48, Val Loss: 4.94636
Epoch 49, Val Loss: 4.87361
Epoch 50, Val Loss: 4.72573
Epoch 51, Val Loss: 4.99750
Epoch 52, Val Loss: 4.85052
Epoch 53, Val Loss: 4.71001
Epoch 54, Val Loss: 4.72209
Epoch 55, Val Loss: 4.75300
Epoch 56, Val Loss: 4.93734
Epoch 57, Val Loss: 5.22229
Epoch 58, Val Loss: 4.81779
Epoch 59, Val Loss: 4.78529
Epoch 60, Val Loss: 4.82450
Epoch 61, Val Loss: 4.83499
Epoch 62, Val Loss: 4.76747
Epoch 63, Val Loss: 4.73755
Epoch 64, Val Loss: 4.97567
Epoch 65, Val Loss: 4.83290
Epoch 66, Val Loss: 4.94379
Epoch 67, Val Loss: 4.70104
Epoch 68, Val Loss: 4.74497
Epoch 69, Val Loss: 4.96889
Epoch 70, Val Loss: 5.12103
Epoch 71, Val Loss: 5.22622
Epoch 72, Val Loss: 4.77856
Epoch 73, Val Loss: 4.93992
Epoch 74, Val Loss: 4.69781
Epoch 75, Val Loss: 4.82504
Epoch 76, Val Loss: 4.91004
Epoch 77, Val Loss: 4.93701
Epoch 78, Val Loss: 5.27057
Epoch 79, Val Loss: 4.76588
Epoch 80, Val Loss: 4.75392
Epoch 81, Val Loss: 4.95442
Epoch 82, Val Loss: 4.70392
Epoch 83, Val Loss: 4.85422
Epoch 84, Val Loss: 4.90669
Epoch 85, Val Loss: 5.31270
Epoch 86, Val Loss: 4.80315
Epoch 87, Val Loss: 4.78066
Epoch 88, Val Loss: 4.78250
Epoch 89, Val Loss: 4.83628
Epoch 90, Val Loss: 4.67172
Epoch 91, Val Loss: 4.88473
Epoch 92, Val Loss: 4.92805
Epoch 93, Val Loss: 4.76755
Epoch 94, Val Loss: 5.11404
Epoch 95, Val Loss: 5.21710
Epoch 96, Val Loss: 4.82427
Epoch 97, Val Loss: 5.17382
Epoch 98, Val Loss: 4.72084
Epoch 99, Val Loss: 4.80554
Saved Losses
{'MSE - mean': 4.799487612417023, 'MSE - std': 0.0, 'R2 - mean': 0.5623025889012624, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.06131
Epoch 1, Val Loss: 7.77588
Epoch 2, Val Loss: 5.22149
Epoch 3, Val Loss: 5.43278
Epoch 4, Val Loss: 5.06067
Epoch 5, Val Loss: 5.14959
Epoch 6, Val Loss: 5.06992
Epoch 7, Val Loss: 5.32065
Epoch 8, Val Loss: 5.39803
Epoch 9, Val Loss: 4.98957
Epoch 10, Val Loss: 4.94174
Epoch 11, Val Loss: 5.85092
Epoch 12, Val Loss: 4.91602
Epoch 13, Val Loss: 4.91860
Epoch 14, Val Loss: 5.19496
Epoch 15, Val Loss: 5.02778
Epoch 16, Val Loss: 4.96459
Epoch 17, Val Loss: 4.82718
Epoch 18, Val Loss: 4.94968
Epoch 19, Val Loss: 4.85257
Epoch 20, Val Loss: 4.76309
Epoch 21, Val Loss: 4.57466
Epoch 22, Val Loss: 4.55770
Epoch 23, Val Loss: 4.54000
Epoch 24, Val Loss: 4.73255
Epoch 25, Val Loss: 4.47233
Epoch 26, Val Loss: 4.71674
Epoch 27, Val Loss: 4.45913
Epoch 28, Val Loss: 4.38863
Epoch 29, Val Loss: 4.44462
Epoch 30, Val Loss: 4.43294
Epoch 31, Val Loss: 4.43415
Epoch 32, Val Loss: 4.29863
Epoch 33, Val Loss: 4.37717
Epoch 34, Val Loss: 4.61636
Epoch 35, Val Loss: 4.38190
Epoch 36, Val Loss: 4.25210
Epoch 37, Val Loss: 4.38714
Epoch 38, Val Loss: 4.32162
Epoch 39, Val Loss: 4.48142
Epoch 40, Val Loss: 4.60847
Epoch 41, Val Loss: 4.37712
Epoch 42, Val Loss: 4.69299
Epoch 43, Val Loss: 4.31758
Epoch 44, Val Loss: 4.31382
Epoch 45, Val Loss: 4.53164
Epoch 46, Val Loss: 4.29552
Epoch 47, Val Loss: 4.23698
Epoch 48, Val Loss: 4.32566
Epoch 49, Val Loss: 4.37194
Epoch 50, Val Loss: 4.20561
Epoch 51, Val Loss: 4.09124
Epoch 52, Val Loss: 4.22703
Epoch 53, Val Loss: 5.24070
Epoch 54, Val Loss: 4.37929
Epoch 55, Val Loss: 4.17441
Epoch 56, Val Loss: 4.23258
Epoch 57, Val Loss: 4.13260
Epoch 58, Val Loss: 4.07170
Epoch 59, Val Loss: 4.24914
Epoch 60, Val Loss: 4.05841
Epoch 61, Val Loss: 4.06182
Epoch 62, Val Loss: 4.54342
Epoch 63, Val Loss: 4.48552
Epoch 64, Val Loss: 4.08633
Epoch 65, Val Loss: 4.09044
Epoch 66, Val Loss: 4.23404
Epoch 67, Val Loss: 4.20830
Epoch 68, Val Loss: 4.38191
Epoch 69, Val Loss: 4.28100
Epoch 70, Val Loss: 5.06442
Epoch 71, Val Loss: 4.52000
Epoch 72, Val Loss: 4.59058
Epoch 73, Val Loss: 4.00051
Epoch 74, Val Loss: 4.17499
Epoch 75, Val Loss: 4.11178
Epoch 76, Val Loss: 4.88735
Epoch 77, Val Loss: 4.24138
Epoch 78, Val Loss: 4.00110
Epoch 79, Val Loss: 4.16073
Epoch 80, Val Loss: 4.08600
Epoch 81, Val Loss: 4.68423
Epoch 82, Val Loss: 4.46819
Epoch 83, Val Loss: 4.30427
Epoch 84, Val Loss: 4.12818
Epoch 85, Val Loss: 3.99160
Epoch 86, Val Loss: 4.27409
Epoch 87, Val Loss: 4.14898
Epoch 88, Val Loss: 4.15290
Epoch 89, Val Loss: 3.97668
Epoch 90, Val Loss: 4.38186
Epoch 91, Val Loss: 4.07781
Epoch 92, Val Loss: 3.95093
Epoch 93, Val Loss: 4.16862
Epoch 94, Val Loss: 4.24548
Epoch 95, Val Loss: 3.98357
Epoch 96, Val Loss: 3.98575
Epoch 97, Val Loss: 4.22204
Epoch 98, Val Loss: 3.95712
Epoch 99, Val Loss: 3.95910
Saved Losses
{'MSE - mean': 4.522669435270071, 'MSE - std': 0.2768181771469522, 'R2 - mean': 0.5548547172206649, 'R2 - std': 0.007447871680597462} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.43016
Epoch 1, Val Loss: 11.90500
Epoch 2, Val Loss: 6.45539
Epoch 3, Val Loss: 5.75950
Epoch 4, Val Loss: 5.68934
Epoch 5, Val Loss: 5.40149
Epoch 6, Val Loss: 5.77590
Epoch 7, Val Loss: 5.31493
Epoch 8, Val Loss: 5.25558
Epoch 9, Val Loss: 5.15501
Epoch 10, Val Loss: 5.11522
Epoch 11, Val Loss: 5.10979
Epoch 12, Val Loss: 5.07092
Epoch 13, Val Loss: 5.21625
Epoch 14, Val Loss: 5.30610
Epoch 15, Val Loss: 5.16605
Epoch 16, Val Loss: 5.18027
Epoch 17, Val Loss: 5.25812
Epoch 18, Val Loss: 4.91890
Epoch 19, Val Loss: 4.87376
Epoch 20, Val Loss: 4.91875
Epoch 21, Val Loss: 4.96311
Epoch 22, Val Loss: 5.03890
Epoch 23, Val Loss: 5.18418
Epoch 24, Val Loss: 4.86644
Epoch 25, Val Loss: 4.94664
Epoch 26, Val Loss: 4.99872
Epoch 27, Val Loss: 5.22810
Epoch 28, Val Loss: 4.82398
Epoch 29, Val Loss: 4.82390
Epoch 30, Val Loss: 4.95600
Epoch 31, Val Loss: 4.74686
Epoch 32, Val Loss: 4.74914
Epoch 33, Val Loss: 4.83033
Epoch 34, Val Loss: 4.90342
Epoch 35, Val Loss: 5.09998
Epoch 36, Val Loss: 5.13232
Epoch 37, Val Loss: 4.72809
Epoch 38, Val Loss: 4.68342
Epoch 39, Val Loss: 4.77807
Epoch 40, Val Loss: 4.76814
Epoch 41, Val Loss: 5.09379
Epoch 42, Val Loss: 4.71299
Epoch 43, Val Loss: 4.65508
Epoch 44, Val Loss: 4.79092
Epoch 45, Val Loss: 4.87644
Epoch 46, Val Loss: 4.74629
Epoch 47, Val Loss: 4.88006
Epoch 48, Val Loss: 4.65420
Epoch 49, Val Loss: 4.72905
Epoch 50, Val Loss: 4.82890
Epoch 51, Val Loss: 4.62431
Epoch 52, Val Loss: 4.65505
Epoch 53, Val Loss: 4.96426
Epoch 54, Val Loss: 4.68988
Epoch 55, Val Loss: 4.66712
Epoch 56, Val Loss: 5.00612
Epoch 57, Val Loss: 4.64191
Epoch 58, Val Loss: 4.64681
Epoch 59, Val Loss: 4.63177
Epoch 60, Val Loss: 4.58686
Epoch 61, Val Loss: 4.70026
Epoch 62, Val Loss: 4.75217
Epoch 63, Val Loss: 4.63389
Epoch 64, Val Loss: 4.63315
Epoch 65, Val Loss: 4.62071
Epoch 66, Val Loss: 4.65897
Epoch 67, Val Loss: 4.73258
Epoch 68, Val Loss: 4.78403
Epoch 69, Val Loss: 4.76471
Epoch 70, Val Loss: 5.20321
Epoch 71, Val Loss: 5.12438
Epoch 72, Val Loss: 4.66112
Epoch 73, Val Loss: 5.43975
Epoch 74, Val Loss: 4.63646
Epoch 75, Val Loss: 4.66134
Epoch 76, Val Loss: 4.65698
Epoch 77, Val Loss: 4.74707
Epoch 78, Val Loss: 4.78401
Epoch 79, Val Loss: 4.58487
Epoch 80, Val Loss: 4.69498
Epoch 81, Val Loss: 4.58432
Epoch 82, Val Loss: 5.08838
Epoch 83, Val Loss: 4.58719
Epoch 84, Val Loss: 4.62825
Epoch 85, Val Loss: 4.62473
Epoch 86, Val Loss: 4.74660
Epoch 87, Val Loss: 4.62745
Epoch 88, Val Loss: 4.85100
Epoch 89, Val Loss: 4.78573
Epoch 90, Val Loss: 4.69919
Epoch 91, Val Loss: 4.54092
Epoch 92, Val Loss: 5.04004
Epoch 93, Val Loss: 4.65149
Epoch 94, Val Loss: 4.68854
Epoch 95, Val Loss: 4.59976
Epoch 96, Val Loss: 4.72762
Epoch 97, Val Loss: 4.71708
Epoch 98, Val Loss: 4.55885
Epoch 99, Val Loss: 4.67777
Saved Losses
{'MSE - mean': 4.567683743439397, 'MSE - std': 0.23481505774949882, 'R2 - mean': 0.5504655412052458, 'R2 - std': 0.008689664007836578} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.66307
Epoch 1, Val Loss: 9.50438
Epoch 2, Val Loss: 5.89422
Epoch 3, Val Loss: 5.62115
Epoch 4, Val Loss: 5.72512
Epoch 5, Val Loss: 5.32529
Epoch 6, Val Loss: 5.38253
Epoch 7, Val Loss: 5.11097
Epoch 8, Val Loss: 5.12233
Epoch 9, Val Loss: 5.06815
Epoch 10, Val Loss: 4.87634
Epoch 11, Val Loss: 4.78196
Epoch 12, Val Loss: 5.09085
Epoch 13, Val Loss: 4.73481
Epoch 14, Val Loss: 4.70754
Epoch 15, Val Loss: 4.59407
Epoch 16, Val Loss: 4.57576
Epoch 17, Val Loss: 4.45657
Epoch 18, Val Loss: 4.49297
Epoch 19, Val Loss: 4.48358
Epoch 20, Val Loss: 5.18564
Epoch 21, Val Loss: 4.52615
Epoch 22, Val Loss: 4.42952
Epoch 23, Val Loss: 4.42386
Epoch 24, Val Loss: 4.45106
Epoch 25, Val Loss: 4.25548
Epoch 26, Val Loss: 4.23234
Epoch 27, Val Loss: 4.50454
Epoch 28, Val Loss: 4.40520
Epoch 29, Val Loss: 4.43211
Epoch 30, Val Loss: 4.38692
Epoch 31, Val Loss: 4.17954
Epoch 32, Val Loss: 4.37517
Epoch 33, Val Loss: 4.45402
Epoch 34, Val Loss: 4.28258
Epoch 35, Val Loss: 4.15762
Epoch 36, Val Loss: 4.40424
Epoch 37, Val Loss: 4.21753
Epoch 38, Val Loss: 4.13059
Epoch 39, Val Loss: 4.15721
Epoch 40, Val Loss: 4.38112
Epoch 41, Val Loss: 4.11992
Epoch 42, Val Loss: 4.97894
Epoch 43, Val Loss: 4.02364
Epoch 44, Val Loss: 4.18797
Epoch 45, Val Loss: 4.01168
Epoch 46, Val Loss: 4.38221
Epoch 47, Val Loss: 4.14475
Epoch 48, Val Loss: 4.37393
Epoch 49, Val Loss: 3.95563
Epoch 50, Val Loss: 4.06881
Epoch 51, Val Loss: 4.04215
Epoch 52, Val Loss: 3.95942
Epoch 53, Val Loss: 4.07917
Epoch 54, Val Loss: 4.16717
Epoch 55, Val Loss: 4.13986
Epoch 56, Val Loss: 3.97835
Epoch 57, Val Loss: 4.06214
Epoch 58, Val Loss: 4.36924
Epoch 59, Val Loss: 4.02874
Epoch 60, Val Loss: 4.11332
Epoch 61, Val Loss: 3.92771
Epoch 62, Val Loss: 4.29731
Epoch 63, Val Loss: 4.11434
Epoch 64, Val Loss: 3.89014
Epoch 65, Val Loss: 3.90512
Epoch 66, Val Loss: 4.04554
Epoch 67, Val Loss: 3.98045
Epoch 68, Val Loss: 4.24305
Epoch 69, Val Loss: 3.85229
Epoch 70, Val Loss: 4.02862
Epoch 71, Val Loss: 3.86465
Epoch 72, Val Loss: 3.95300
Epoch 73, Val Loss: 4.31515
Epoch 74, Val Loss: 4.24265
Epoch 75, Val Loss: 4.16948
Epoch 76, Val Loss: 3.86164
Epoch 77, Val Loss: 4.06061
Epoch 78, Val Loss: 3.84012
Epoch 79, Val Loss: 3.84712
Epoch 80, Val Loss: 4.14253
Epoch 81, Val Loss: 3.88517
Epoch 82, Val Loss: 4.14491
Epoch 83, Val Loss: 3.80265
Epoch 84, Val Loss: 3.95196
Epoch 85, Val Loss: 3.87973
Epoch 86, Val Loss: 3.95069
Epoch 87, Val Loss: 3.83490
Epoch 88, Val Loss: 3.85445
Epoch 89, Val Loss: 3.83407
Epoch 90, Val Loss: 3.90368
Epoch 91, Val Loss: 3.82484
Epoch 92, Val Loss: 4.02210
Epoch 93, Val Loss: 3.86230
Epoch 94, Val Loss: 3.82149
Epoch 95, Val Loss: 4.12932
Epoch 96, Val Loss: 3.83624
Epoch 97, Val Loss: 4.12149
Epoch 98, Val Loss: 3.88624
Epoch 99, Val Loss: 4.18093
Saved Losses
{'MSE - mean': 4.44536046846648, 'MSE - std': 0.29367079240150024, 'R2 - mean': 0.5538332556351873, 'R2 - std': 0.009521407294708241} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 40.77234
Epoch 1, Val Loss: 15.62359
Epoch 2, Val Loss: 8.83988
Epoch 3, Val Loss: 7.93642
Epoch 4, Val Loss: 7.31829
Epoch 5, Val Loss: 7.10584
Epoch 6, Val Loss: 7.07248
Epoch 7, Val Loss: 6.95113
Epoch 8, Val Loss: 6.95633
Epoch 9, Val Loss: 7.06790
Epoch 10, Val Loss: 6.87752
Epoch 11, Val Loss: 7.13294
Epoch 12, Val Loss: 6.84811
Epoch 13, Val Loss: 7.03943
Epoch 14, Val Loss: 6.73787
Epoch 15, Val Loss: 6.64450
Epoch 16, Val Loss: 7.14767
Epoch 17, Val Loss: 6.79033
Epoch 18, Val Loss: 6.65400
Epoch 19, Val Loss: 6.66555
Epoch 20, Val Loss: 6.63500
Epoch 21, Val Loss: 7.25801
Epoch 22, Val Loss: 6.57052
Epoch 23, Val Loss: 6.60930
Epoch 24, Val Loss: 6.60275
Epoch 25, Val Loss: 6.47822
Epoch 26, Val Loss: 6.44958
Epoch 27, Val Loss: 6.40574
Epoch 28, Val Loss: 6.37611
Epoch 29, Val Loss: 6.54286
Epoch 30, Val Loss: 6.33148
Epoch 31, Val Loss: 6.39071
Epoch 32, Val Loss: 6.21533
Epoch 33, Val Loss: 6.85385
Epoch 34, Val Loss: 6.19439
Epoch 35, Val Loss: 6.40319
Epoch 36, Val Loss: 6.91687
Epoch 37, Val Loss: 6.36457
Epoch 38, Val Loss: 6.40943
Epoch 39, Val Loss: 6.76494
Epoch 40, Val Loss: 6.40972
Epoch 41, Val Loss: 6.11824
Epoch 42, Val Loss: 6.12484
Epoch 43, Val Loss: 6.17201
Epoch 44, Val Loss: 6.11019
Epoch 45, Val Loss: 6.28576
Epoch 46, Val Loss: 6.09930
Epoch 47, Val Loss: 6.38051
Epoch 48, Val Loss: 6.04297
Epoch 49, Val Loss: 6.27553
Epoch 50, Val Loss: 6.14898
Epoch 51, Val Loss: 5.94254
Epoch 52, Val Loss: 6.32919
Epoch 53, Val Loss: 6.36963
Epoch 54, Val Loss: 6.53976
Epoch 55, Val Loss: 6.49564
Epoch 56, Val Loss: 6.22901
Epoch 57, Val Loss: 6.16307
Epoch 58, Val Loss: 5.93049
Epoch 59, Val Loss: 6.13371
Epoch 60, Val Loss: 5.83399
Epoch 61, Val Loss: 5.75793
Epoch 62, Val Loss: 6.08512
Epoch 63, Val Loss: 6.18298
Epoch 64, Val Loss: 5.93068
Epoch 65, Val Loss: 6.15294
Epoch 66, Val Loss: 5.93847
Epoch 67, Val Loss: 5.93202
Epoch 68, Val Loss: 5.99156
Epoch 69, Val Loss: 6.04685
Epoch 70, Val Loss: 6.19577
Epoch 71, Val Loss: 5.76346
Epoch 72, Val Loss: 6.23107
Epoch 73, Val Loss: 5.92475
Epoch 74, Val Loss: 6.11123
Epoch 75, Val Loss: 5.95313
Epoch 76, Val Loss: 5.83268
Epoch 77, Val Loss: 6.27168
Epoch 78, Val Loss: 5.74790
Epoch 79, Val Loss: 5.82685
Epoch 80, Val Loss: 5.74080
Epoch 81, Val Loss: 5.90905
Epoch 82, Val Loss: 5.84997
Epoch 83, Val Loss: 5.75281
Epoch 84, Val Loss: 5.89288
Epoch 85, Val Loss: 6.12635
Epoch 86, Val Loss: 5.73395
Epoch 87, Val Loss: 6.07406
Epoch 88, Val Loss: 5.95179
Epoch 89, Val Loss: 6.15204
Epoch 90, Val Loss: 5.74982
Epoch 91, Val Loss: 5.90245
Epoch 92, Val Loss: 5.77410
Epoch 93, Val Loss: 5.85570
Epoch 94, Val Loss: 5.78210
Epoch 95, Val Loss: 5.81041
Epoch 96, Val Loss: 5.88158
Epoch 97, Val Loss: 5.97190
Epoch 98, Val Loss: 5.55918
Epoch 99, Val Loss: 5.69604
Saved Losses
{'MSE - mean': 4.655327508541439, 'MSE - std': 0.49531672606438215, 'R2 - mean': 0.5521764144075151, 'R2 - std': 0.009138175360116222} 
 

Results After CV: {'MSE - mean': 4.655327508541439, 'MSE - std': 0.49531672606438215, 'R2 - mean': 0.5521764144075151, 'R2 - std': 0.009138175360116222}
Train time: 82.20782529940007
Inference time: 0.05065965880003205
Finished cross validation
