

----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/brazillian_houses.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/brazillian_houses.yml', data_parallel=False, dataset='Brazillian_Houses', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=50, nominal_idx=[0, 6], num_classes=1, num_features=12, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[7], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Brazillian_Houses...


----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/abalone.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/abalone.yml', data_parallel=False, dataset='Abalone', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=50, nominal_idx=[0], num_classes=1, num_features=8, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Abalone...
Dataset loaded! 

X b4 encoding : ['M' 0.455 0.365 0.095 0.514 0.2245 0.101 0.15] 

(4177, 8)
Data Type of X: <class 'numpy.ndarray'>
Nominal Idx: [0]
Ordinal Idx: None
Cat Dims: None 
 

Normonal Idx: [0]
Cat Idx Part II: [0] 
ENDE 
 

Scaling the data...
One Hot Encoding...
args.num_features: 10
args.cat_idx: None
New Shape: (4177, 10)
Using an existing study with name 'VIME_Abalone' instead of creating a new one.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.62237
Epoch 1, Val Loss: 10.43836
Epoch 2, Val Loss: 8.17795
Epoch 3, Val Loss: 7.20358
Epoch 4, Val Loss: 7.13516
Epoch 5, Val Loss: 7.09973
Epoch 6, Val Loss: 7.23842
Epoch 7, Val Loss: 6.84146
Epoch 8, Val Loss: 6.92743
Epoch 9, Val Loss: 6.98459
Epoch 10, Val Loss: 6.71728
Epoch 11, Val Loss: 7.02683
Epoch 12, Val Loss: 6.79445
Epoch 13, Val Loss: 6.65660
Epoch 14, Val Loss: 6.64861
Epoch 15, Val Loss: 7.10428
Epoch 16, Val Loss: 6.80479
Epoch 17, Val Loss: 6.65817
Epoch 18, Val Loss: 6.54005
Epoch 19, Val Loss: 6.52618
Epoch 20, Val Loss: 7.39014
Epoch 21, Val Loss: 6.42213
Epoch 22, Val Loss: 6.48538
Epoch 23, Val Loss: 6.61336
Epoch 24, Val Loss: 6.88933
Epoch 25, Val Loss: 6.46561
Epoch 26, Val Loss: 6.43825
Epoch 27, Val Loss: 6.51308
Epoch 28, Val Loss: 6.76036
Epoch 29, Val Loss: 6.52644
Epoch 30, Val Loss: 6.33009
Epoch 31, Val Loss: 6.61274
Epoch 32, Val Loss: 6.47884
Epoch 33, Val Loss: 6.33066
Epoch 34, Val Loss: 6.45754
Epoch 35, Val Loss: 6.88005
Epoch 36, Val Loss: 6.44014
Epoch 37, Val Loss: 6.32974
Epoch 38, Val Loss: 6.22598
Epoch 39, Val Loss: 6.25385
Epoch 40, Val Loss: 6.16442
Epoch 41, Val Loss: 6.28892
Epoch 42, Val Loss: 6.67159
Epoch 43, Val Loss: 6.35699
Epoch 44, Val Loss: 6.17380
Epoch 45, Val Loss: 6.80585
Epoch 46, Val Loss: 6.26583
Epoch 47, Val Loss: 6.12987
Epoch 48, Val Loss: 6.29979
Epoch 49, Val Loss: 6.32719
Epoch 50, Val Loss: 6.10635
Epoch 51, Val Loss: 6.71526
Epoch 52, Val Loss: 5.95573
Epoch 53, Val Loss: 5.97321
Epoch 54, Val Loss: 5.96723
Epoch 55, Val Loss: 6.33122
Epoch 56, Val Loss: 6.08650
Epoch 57, Val Loss: 6.02111
Epoch 58, Val Loss: 5.97677
Epoch 59, Val Loss: 6.09373
Epoch 60, Val Loss: 6.52792
Epoch 61, Val Loss: 5.90335
Epoch 62, Val Loss: 6.13234
Epoch 63, Val Loss: 6.02832
Epoch 64, Val Loss: 6.06960
Epoch 65, Val Loss: 6.26365
Epoch 66, Val Loss: 6.16518
Epoch 67, Val Loss: 6.12061
Epoch 68, Val Loss: 6.14589
Epoch 69, Val Loss: 6.00357
Epoch 70, Val Loss: 5.99921
Epoch 71, Val Loss: 6.55796
Epoch 72, Val Loss: 6.08606
Epoch 73, Val Loss: 6.10808
Epoch 74, Val Loss: 6.10760
Epoch 75, Val Loss: 5.98781
Epoch 76, Val Loss: 5.84006
Epoch 77, Val Loss: 6.04163
Epoch 78, Val Loss: 5.78055
Epoch 79, Val Loss: 5.94617
Epoch 80, Val Loss: 6.01885
Epoch 81, Val Loss: 6.05848
Epoch 82, Val Loss: 6.28977
Epoch 83, Val Loss: 5.79528
Epoch 84, Val Loss: 5.90461
Epoch 85, Val Loss: 6.14462
Epoch 86, Val Loss: 5.76846
Epoch 87, Val Loss: 5.78996
Epoch 88, Val Loss: 6.05537
Epoch 89, Val Loss: 5.77605
Epoch 90, Val Loss: 5.80094
Epoch 91, Val Loss: 6.28447
Epoch 92, Val Loss: 5.85237
Epoch 93, Val Loss: 5.69277
Epoch 94, Val Loss: 5.81263
Epoch 95, Val Loss: 5.97949
Epoch 96, Val Loss: 5.88451
Epoch 97, Val Loss: 5.91511
Epoch 98, Val Loss: 5.75425
Epoch 99, Val Loss: 5.80277
DID NOT SAVE RESULTS
{'MSE - mean': 5.900328413285335, 'MSE - std': 0.0, 'R2 - mean': 0.4619095454177584, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.40886
Epoch 1, Val Loss: 9.96208
Epoch 2, Val Loss: 6.10597
Epoch 3, Val Loss: 5.65212
Epoch 4, Val Loss: 5.77644
Epoch 5, Val Loss: 5.66082
Epoch 6, Val Loss: 5.67247
Epoch 7, Val Loss: 5.57094
Epoch 8, Val Loss: 5.87660
Epoch 9, Val Loss: 5.71215
Epoch 10, Val Loss: 5.48098
Epoch 11, Val Loss: 5.52345
Epoch 12, Val Loss: 5.69373
Epoch 13, Val Loss: 5.96642
Epoch 14, Val Loss: 5.72807
Epoch 15, Val Loss: 5.76975
Epoch 16, Val Loss: 6.04831
Epoch 17, Val Loss: 5.66411
Epoch 18, Val Loss: 5.88595
Epoch 19, Val Loss: 5.50208
Epoch 20, Val Loss: 5.36037
Epoch 21, Val Loss: 5.37481
Epoch 22, Val Loss: 5.50417
Epoch 23, Val Loss: 5.49873
Epoch 24, Val Loss: 5.88037
Epoch 25, Val Loss: 5.41835
Epoch 26, Val Loss: 5.62114
Epoch 27, Val Loss: 5.52683
Epoch 28, Val Loss: 5.30699
Epoch 29, Val Loss: 5.48131
Epoch 30, Val Loss: 5.90362
Epoch 31, Val Loss: 5.52934
Epoch 32, Val Loss: 5.25152
Epoch 33, Val Loss: 5.29220
Epoch 34, Val Loss: 6.02539
Epoch 35, Val Loss: 5.33079
Epoch 36, Val Loss: 5.48119
Epoch 37, Val Loss: 5.46823
Epoch 38, Val Loss: 5.79207
Epoch 39, Val Loss: 5.41217
Epoch 40, Val Loss: 5.53985
Epoch 41, Val Loss: 5.21318
Epoch 42, Val Loss: 5.21310
Epoch 43, Val Loss: 5.18466
Epoch 44, Val Loss: 5.43623
Epoch 45, Val Loss: 5.32037
Epoch 46, Val Loss: 5.19501
Epoch 47, Val Loss: 5.52538
Epoch 48, Val Loss: 5.19292
Epoch 49, Val Loss: 5.17958
Epoch 50, Val Loss: 5.08979
Epoch 51, Val Loss: 5.41084
Epoch 52, Val Loss: 5.30588
Epoch 53, Val Loss: 5.26570
Epoch 54, Val Loss: 5.20446
Epoch 55, Val Loss: 5.20345
Epoch 56, Val Loss: 5.37510
Epoch 57, Val Loss: 5.36163
Epoch 58, Val Loss: 5.44762
Epoch 59, Val Loss: 5.37285
Epoch 60, Val Loss: 5.60512
Epoch 61, Val Loss: 5.88300
Epoch 62, Val Loss: 5.33452
Epoch 63, Val Loss: 5.10859
Epoch 64, Val Loss: 5.16553
Epoch 65, Val Loss: 5.33182
Epoch 66, Val Loss: 5.35214
Epoch 67, Val Loss: 5.20802
Epoch 68, Val Loss: 5.04697
Epoch 69, Val Loss: 5.16056
Epoch 70, Val Loss: 5.18422
Epoch 71, Val Loss: 5.39715
Epoch 72, Val Loss: 5.04826
Epoch 73, Val Loss: 5.18119
Epoch 74, Val Loss: 5.07179
Epoch 75, Val Loss: 5.07698
Epoch 76, Val Loss: 5.71259
Epoch 77, Val Loss: 5.55102
Epoch 78, Val Loss: 4.97770
Epoch 79, Val Loss: 5.82945
Epoch 80, Val Loss: 5.00872
Epoch 81, Val Loss: 5.17589
Epoch 82, Val Loss: 5.06574
Epoch 83, Val Loss: 5.48451
Epoch 84, Val Loss: 5.01792
Epoch 85, Val Loss: 5.20973
Epoch 86, Val Loss: 4.94848
Epoch 87, Val Loss: 5.04189
Epoch 88, Val Loss: 4.91327
Epoch 89, Val Loss: 5.09296
Epoch 90, Val Loss: 5.31861
Epoch 91, Val Loss: 5.03351
Epoch 92, Val Loss: 4.87222
Epoch 93, Val Loss: 5.31951
Epoch 94, Val Loss: 5.52163
Epoch 95, Val Loss: 5.28432
Epoch 96, Val Loss: 5.07046
Epoch 97, Val Loss: 4.85190
Epoch 98, Val Loss: 5.34206
Epoch 99, Val Loss: 5.02094
DID NOT SAVE RESULTS
{'MSE - mean': 5.563634267872247, 'MSE - std': 0.3366941454130883, 'R2 - mean': 0.45236784462573126, 'R2 - std': 0.009541700792027152} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.11718
Epoch 1, Val Loss: 12.34344
Epoch 2, Val Loss: 7.50213
Epoch 3, Val Loss: 6.64334
Epoch 4, Val Loss: 6.50697
Epoch 5, Val Loss: 6.71056
Epoch 6, Val Loss: 6.50081
Epoch 7, Val Loss: 6.33584
Epoch 8, Val Loss: 6.52354
Epoch 9, Val Loss: 6.53953
Epoch 10, Val Loss: 6.16101
Epoch 11, Val Loss: 6.28791
Epoch 12, Val Loss: 6.22865
Epoch 13, Val Loss: 6.58523
Epoch 14, Val Loss: 6.29302
Epoch 15, Val Loss: 6.07547
Epoch 16, Val Loss: 6.64253
Epoch 17, Val Loss: 6.11874
Epoch 18, Val Loss: 6.09201
Epoch 19, Val Loss: 6.10234
Epoch 20, Val Loss: 6.22515
Epoch 21, Val Loss: 6.41597
Epoch 22, Val Loss: 6.28657
Epoch 23, Val Loss: 6.20616
Epoch 24, Val Loss: 6.30523
Epoch 25, Val Loss: 6.09705
Epoch 26, Val Loss: 6.26919
Epoch 27, Val Loss: 6.16086
Epoch 28, Val Loss: 6.28839
Epoch 29, Val Loss: 6.63535
Epoch 30, Val Loss: 6.54892
Epoch 31, Val Loss: 6.15188
Epoch 32, Val Loss: 6.31883
Epoch 33, Val Loss: 6.19110
Epoch 34, Val Loss: 6.14082
Epoch 35, Val Loss: 6.17706
Epoch 36, Val Loss: 6.07864
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 5.795983479415802, 'MSE - std': 0.4284245681332047, 'R2 - mean': 0.42956425657579683, 'R2 - std': 0.033176848733797455} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.62671
Epoch 1, Val Loss: 8.82477
Epoch 2, Val Loss: 6.51993
Epoch 3, Val Loss: 5.63547
Epoch 4, Val Loss: 5.53257
Epoch 5, Val Loss: 5.54552
Epoch 6, Val Loss: 5.50177
Epoch 7, Val Loss: 5.54867
Epoch 8, Val Loss: 5.57120
Epoch 9, Val Loss: 5.38642
Epoch 10, Val Loss: 5.49058
Epoch 11, Val Loss: 5.51745
Epoch 12, Val Loss: 5.57737
Epoch 13, Val Loss: 5.37256
Epoch 14, Val Loss: 5.53402
Epoch 15, Val Loss: 5.35485
Epoch 16, Val Loss: 5.80285
Epoch 17, Val Loss: 5.31743
Epoch 18, Val Loss: 5.35534
Epoch 19, Val Loss: 5.54572
Epoch 20, Val Loss: 5.33006
Epoch 21, Val Loss: 5.45975
Epoch 22, Val Loss: 5.78686
Epoch 23, Val Loss: 5.50936
Epoch 24, Val Loss: 5.25645
Epoch 25, Val Loss: 5.23585
Epoch 26, Val Loss: 5.43404
Epoch 27, Val Loss: 5.28370
Epoch 28, Val Loss: 5.20334
Epoch 29, Val Loss: 5.38961
Epoch 30, Val Loss: 5.31051
Epoch 31, Val Loss: 5.20277
Epoch 32, Val Loss: 5.49651
Epoch 33, Val Loss: 5.48859
Epoch 34, Val Loss: 5.25550
Epoch 35, Val Loss: 5.25552
Epoch 36, Val Loss: 5.39058
Epoch 37, Val Loss: 5.20068
Epoch 38, Val Loss: 5.30696
Epoch 39, Val Loss: 5.27955
Epoch 40, Val Loss: 5.28425
Epoch 41, Val Loss: 5.21169
Epoch 42, Val Loss: 5.59711
Epoch 43, Val Loss: 5.17207
Epoch 44, Val Loss: 5.21204
Epoch 45, Val Loss: 5.58022
Epoch 46, Val Loss: 5.59272
Epoch 47, Val Loss: 5.26381
Epoch 48, Val Loss: 5.33882
Epoch 49, Val Loss: 5.32379
Epoch 50, Val Loss: 5.41184
Epoch 51, Val Loss: 5.27808
Epoch 52, Val Loss: 5.28793
Epoch 53, Val Loss: 5.43065
Epoch 54, Val Loss: 5.30543
Epoch 55, Val Loss: 5.17581
Epoch 56, Val Loss: 5.44033
Epoch 57, Val Loss: 5.44543
Epoch 58, Val Loss: 5.06320
Epoch 59, Val Loss: 5.07260
Epoch 60, Val Loss: 5.23504
Epoch 61, Val Loss: 5.15721
Epoch 62, Val Loss: 5.23839
Epoch 63, Val Loss: 5.17418
Epoch 64, Val Loss: 5.17991
Epoch 65, Val Loss: 5.28676
Epoch 66, Val Loss: 5.26800
Epoch 67, Val Loss: 5.49133
Epoch 68, Val Loss: 5.06352
Epoch 69, Val Loss: 5.61945
Epoch 70, Val Loss: 5.08051
Epoch 71, Val Loss: 5.19988
Epoch 72, Val Loss: 5.07439
Epoch 73, Val Loss: 5.12195
Epoch 74, Val Loss: 5.11879
Epoch 75, Val Loss: 5.15662
Epoch 76, Val Loss: 5.17183
Epoch 77, Val Loss: 5.04747
Epoch 78, Val Loss: 5.08249
Epoch 79, Val Loss: 5.34590
Epoch 80, Val Loss: 5.59948
Epoch 81, Val Loss: 5.01481
Epoch 82, Val Loss: 6.04077
Epoch 83, Val Loss: 5.05473
Epoch 84, Val Loss: 5.14113
Epoch 85, Val Loss: 5.23454
Epoch 86, Val Loss: 5.30053
Epoch 87, Val Loss: 5.50988
Epoch 88, Val Loss: 4.98043
Epoch 89, Val Loss: 4.97839
Epoch 90, Val Loss: 5.04155
Epoch 91, Val Loss: 4.96233
Epoch 92, Val Loss: 5.08480
Epoch 93, Val Loss: 5.05320
Epoch 94, Val Loss: 5.14359
Epoch 95, Val Loss: 4.94555
Epoch 96, Val Loss: 5.03346
Epoch 97, Val Loss: 5.20118
Epoch 98, Val Loss: 5.21779
Epoch 99, Val Loss: 5.33681
DID NOT SAVE RESULTS
{'MSE - mean': 5.688298536578788, 'MSE - std': 0.41526960962310316, 'R2 - mean': 0.4287595461884254, 'R2 - std': 0.02876578080552636} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.79845
Epoch 1, Val Loss: 9.77375
Epoch 2, Val Loss: 9.34813
Epoch 3, Val Loss: 9.56825
Epoch 4, Val Loss: 7.63692
Epoch 5, Val Loss: 7.56793
Epoch 6, Val Loss: 7.70207
Epoch 7, Val Loss: 7.52934
Epoch 8, Val Loss: 8.28260
Epoch 9, Val Loss: 7.39539
Epoch 10, Val Loss: 7.49707
Epoch 11, Val Loss: 7.53261
Epoch 12, Val Loss: 7.58419
Epoch 13, Val Loss: 7.27092
Epoch 14, Val Loss: 7.71618
Epoch 15, Val Loss: 7.56395
Epoch 16, Val Loss: 7.50164
Epoch 17, Val Loss: 7.95596
Epoch 18, Val Loss: 7.09578
Epoch 19, Val Loss: 7.44573
Epoch 20, Val Loss: 7.12889
Epoch 21, Val Loss: 7.08646
Epoch 22, Val Loss: 7.73043
Epoch 23, Val Loss: 7.19259
Epoch 24, Val Loss: 7.27826
Epoch 25, Val Loss: 7.29759
Epoch 26, Val Loss: 7.47201
Epoch 27, Val Loss: 6.99221
Epoch 28, Val Loss: 7.37053
Epoch 29, Val Loss: 7.79747
Epoch 30, Val Loss: 7.73424
Epoch 31, Val Loss: 7.15533
Epoch 32, Val Loss: 7.46592
Epoch 33, Val Loss: 7.02157
Epoch 34, Val Loss: 7.31564
Epoch 35, Val Loss: 7.20247
Epoch 36, Val Loss: 7.28841
Epoch 37, Val Loss: 7.56405
Epoch 38, Val Loss: 7.16744
Epoch 39, Val Loss: 7.16093
Epoch 40, Val Loss: 7.10641
Epoch 41, Val Loss: 7.23850
Epoch 42, Val Loss: 7.38412
Epoch 43, Val Loss: 7.09654
Epoch 44, Val Loss: 7.11821
Epoch 45, Val Loss: 7.19509
Epoch 46, Val Loss: 7.51825
Epoch 47, Val Loss: 7.43003
Epoch 48, Val Loss: 6.89751
Epoch 49, Val Loss: 6.98595
Epoch 50, Val Loss: 7.01097
Epoch 51, Val Loss: 6.91166
Epoch 52, Val Loss: 7.27500
Epoch 53, Val Loss: 6.97689
Epoch 54, Val Loss: 7.05662
Epoch 55, Val Loss: 6.95091
Epoch 56, Val Loss: 6.98387
Epoch 57, Val Loss: 7.13194
Epoch 58, Val Loss: 7.24864
Epoch 59, Val Loss: 7.17576
Epoch 60, Val Loss: 7.05404
Epoch 61, Val Loss: 7.08513
Epoch 62, Val Loss: 7.90568
Epoch 63, Val Loss: 7.54273
Epoch 64, Val Loss: 6.89368
Epoch 65, Val Loss: 7.39942
Epoch 66, Val Loss: 7.37125
Epoch 67, Val Loss: 6.92395
Epoch 68, Val Loss: 7.54824
Epoch 69, Val Loss: 6.85325
Epoch 70, Val Loss: 7.19574
Epoch 71, Val Loss: 7.11787
Epoch 72, Val Loss: 7.16581
Epoch 73, Val Loss: 6.97015
Epoch 74, Val Loss: 6.92060
Epoch 75, Val Loss: 7.00905
Epoch 76, Val Loss: 7.03873
Epoch 77, Val Loss: 7.09046
Epoch 78, Val Loss: 6.79649
Epoch 79, Val Loss: 6.90436
Epoch 80, Val Loss: 7.01390
Epoch 81, Val Loss: 7.35369
Epoch 82, Val Loss: 7.04501
Epoch 83, Val Loss: 6.82332
Epoch 84, Val Loss: 6.97325
Epoch 85, Val Loss: 7.07442
Epoch 86, Val Loss: 6.81212
Epoch 87, Val Loss: 6.93447
Epoch 88, Val Loss: 6.98025
Epoch 89, Val Loss: 6.78813
Epoch 90, Val Loss: 6.86940
Epoch 91, Val Loss: 6.73174
Epoch 92, Val Loss: 6.82571
Epoch 93, Val Loss: 6.99282
Epoch 94, Val Loss: 6.81686
Epoch 95, Val Loss: 7.12143
Epoch 96, Val Loss: 6.97808
Epoch 97, Val Loss: 6.84712
Epoch 98, Val Loss: 8.08238
Epoch 99, Val Loss: 7.12778
DID NOT SAVE RESULTS
{'MSE - mean': 5.903332949471248, 'MSE - std': 0.5682589848416298, 'R2 - mean': 0.4311402593877677, 'R2 - std': 0.026165765756640164} 
 

Results After CV: {'MSE - mean': 5.903332949471248, 'MSE - std': 0.5682589848416298, 'R2 - mean': 0.4311402593877677, 'R2 - std': 0.026165765756640164}
Train time: 42.3047600602
Inference time: 0.053877261399998135
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 20 finished with value: 5.903332949471248 and parameters: {'p_m': 0.23710681707608086, 'alpha': 1.3599714159014447, 'K': 5, 'beta': 4.907845333067837}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.81445
Epoch 1, Val Loss: 12.89684
Epoch 2, Val Loss: 6.99763
Epoch 3, Val Loss: 6.54392
Epoch 4, Val Loss: 6.41456
Epoch 5, Val Loss: 6.54532
Epoch 6, Val Loss: 6.66076
Epoch 7, Val Loss: 6.20187
Epoch 8, Val Loss: 6.41760
Epoch 9, Val Loss: 6.46186
Epoch 10, Val Loss: 6.28363
Epoch 11, Val Loss: 6.25728
Epoch 12, Val Loss: 6.17337
Epoch 13, Val Loss: 6.14552
Epoch 14, Val Loss: 6.16193
Epoch 15, Val Loss: 6.12261
Epoch 16, Val Loss: 6.00527
Epoch 17, Val Loss: 6.00094
Epoch 18, Val Loss: 6.05587
Epoch 19, Val Loss: 6.12552
Epoch 20, Val Loss: 6.06402
Epoch 21, Val Loss: 6.10521
Epoch 22, Val Loss: 6.01781
Epoch 23, Val Loss: 5.93164
Epoch 24, Val Loss: 5.59307
Epoch 25, Val Loss: 5.70785
Epoch 26, Val Loss: 5.63105
Epoch 27, Val Loss: 6.31933
Epoch 28, Val Loss: 5.54725
Epoch 29, Val Loss: 5.36469
Epoch 30, Val Loss: 5.51673
Epoch 31, Val Loss: 5.41624
Epoch 32, Val Loss: 5.15366
Epoch 33, Val Loss: 5.18764
Epoch 34, Val Loss: 5.25799
Epoch 35, Val Loss: 5.29987
Epoch 36, Val Loss: 5.29799
Epoch 37, Val Loss: 5.39499
Epoch 38, Val Loss: 5.59604
Epoch 39, Val Loss: 5.35115
Epoch 40, Val Loss: 5.08138
Epoch 41, Val Loss: 5.02541
Epoch 42, Val Loss: 5.00570
Epoch 43, Val Loss: 4.93762
Epoch 44, Val Loss: 5.00713
Epoch 45, Val Loss: 5.34187
Epoch 46, Val Loss: 5.35268
Epoch 47, Val Loss: 4.91103
Epoch 48, Val Loss: 4.81825
Epoch 49, Val Loss: 5.05011
Epoch 50, Val Loss: 4.91084
Epoch 51, Val Loss: 4.89224
Epoch 52, Val Loss: 4.86646
Epoch 53, Val Loss: 4.89844
Epoch 54, Val Loss: 5.37254
Epoch 55, Val Loss: 4.89666
Epoch 56, Val Loss: 4.76750
Epoch 57, Val Loss: 4.76286
Epoch 58, Val Loss: 4.74048
Epoch 59, Val Loss: 4.86728
Epoch 60, Val Loss: 4.94171
Epoch 61, Val Loss: 5.09675
Epoch 62, Val Loss: 5.35143
Epoch 63, Val Loss: 4.81214
Epoch 64, Val Loss: 4.90079
Epoch 65, Val Loss: 4.76847
Epoch 66, Val Loss: 4.95745
Epoch 67, Val Loss: 5.06747
Epoch 68, Val Loss: 4.83127
Epoch 69, Val Loss: 5.11915
Epoch 70, Val Loss: 4.72540
Epoch 71, Val Loss: 4.73669
Epoch 72, Val Loss: 4.99941
Epoch 73, Val Loss: 4.96583
Epoch 74, Val Loss: 4.86664
Epoch 75, Val Loss: 5.21242
Epoch 76, Val Loss: 4.92561
Epoch 77, Val Loss: 4.93524
Epoch 78, Val Loss: 4.76837
Epoch 79, Val Loss: 4.84711
Epoch 80, Val Loss: 4.72875
Epoch 81, Val Loss: 4.69143
Epoch 82, Val Loss: 5.02341
Epoch 83, Val Loss: 4.95744
Epoch 84, Val Loss: 4.75867
Epoch 85, Val Loss: 4.98987
Epoch 86, Val Loss: 4.73812
Epoch 87, Val Loss: 4.74949
Epoch 88, Val Loss: 4.68266
Epoch 89, Val Loss: 4.72735
Epoch 90, Val Loss: 4.87906
Epoch 91, Val Loss: 4.82611
Epoch 92, Val Loss: 4.77486
Epoch 93, Val Loss: 4.93268
Epoch 94, Val Loss: 4.98698
Epoch 95, Val Loss: 4.80587
Epoch 96, Val Loss: 4.79136
Epoch 97, Val Loss: 4.82034
Epoch 98, Val Loss: 4.67641
Epoch 99, Val Loss: 4.69633
DID NOT SAVE RESULTS
{'MSE - mean': 4.732572553693961, 'MSE - std': 0.0, 'R2 - mean': 0.5684050211464942, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.50241
Epoch 1, Val Loss: 9.21862
Epoch 2, Val Loss: 6.17008
Epoch 3, Val Loss: 6.00948
Epoch 4, Val Loss: 5.83756
Epoch 5, Val Loss: 5.60712
Epoch 6, Val Loss: 5.36409
Epoch 7, Val Loss: 5.20649
Epoch 8, Val Loss: 5.18981
Epoch 9, Val Loss: 5.16772
Epoch 10, Val Loss: 5.06543
Epoch 11, Val Loss: 5.25919
Epoch 12, Val Loss: 4.94712
Epoch 13, Val Loss: 4.92957
Epoch 14, Val Loss: 5.37353
Epoch 15, Val Loss: 5.18328
Epoch 16, Val Loss: 5.04629
Epoch 17, Val Loss: 4.84893
Epoch 18, Val Loss: 4.83944
Epoch 19, Val Loss: 5.48006
Epoch 20, Val Loss: 5.05466
Epoch 21, Val Loss: 4.82431
Epoch 22, Val Loss: 4.84994
Epoch 23, Val Loss: 4.93579
Epoch 24, Val Loss: 4.96183
Epoch 25, Val Loss: 4.76178
Epoch 26, Val Loss: 5.17509
Epoch 27, Val Loss: 4.82579
Epoch 28, Val Loss: 4.83887
Epoch 29, Val Loss: 4.88086
Epoch 30, Val Loss: 4.86568
Epoch 31, Val Loss: 4.65859
Epoch 32, Val Loss: 4.80470
Epoch 33, Val Loss: 5.52687
Epoch 34, Val Loss: 4.73842
Epoch 35, Val Loss: 4.74649
Epoch 36, Val Loss: 4.69041
Epoch 37, Val Loss: 5.03184
Epoch 38, Val Loss: 4.53297
Epoch 39, Val Loss: 4.72728
Epoch 40, Val Loss: 5.10168
Epoch 41, Val Loss: 4.48463
Epoch 42, Val Loss: 4.43984
Epoch 43, Val Loss: 4.43934
Epoch 44, Val Loss: 4.69109
Epoch 45, Val Loss: 4.61975
Epoch 46, Val Loss: 4.55828
Epoch 47, Val Loss: 4.44138
Epoch 48, Val Loss: 4.57935
Epoch 49, Val Loss: 4.48314
Epoch 50, Val Loss: 4.40851
Epoch 51, Val Loss: 4.39932
Epoch 52, Val Loss: 4.62953
Epoch 53, Val Loss: 4.73481
Epoch 54, Val Loss: 4.50581
Epoch 55, Val Loss: 4.36579
Epoch 56, Val Loss: 4.38163
Epoch 57, Val Loss: 4.53997
Epoch 58, Val Loss: 4.31169
Epoch 59, Val Loss: 4.91565
Epoch 60, Val Loss: 4.24444
Epoch 61, Val Loss: 4.90907
Epoch 62, Val Loss: 4.33536
Epoch 63, Val Loss: 4.23849
Epoch 64, Val Loss: 4.34752
Epoch 65, Val Loss: 4.22721
Epoch 66, Val Loss: 4.38604
Epoch 67, Val Loss: 4.25469
Epoch 68, Val Loss: 4.45796
Epoch 69, Val Loss: 4.26724
Epoch 70, Val Loss: 4.20043
Epoch 71, Val Loss: 4.30234
Epoch 72, Val Loss: 4.26437
Epoch 73, Val Loss: 4.28512
Epoch 74, Val Loss: 4.27528
Epoch 75, Val Loss: 4.16545
Epoch 76, Val Loss: 4.16314
Epoch 77, Val Loss: 4.34273
Epoch 78, Val Loss: 4.31541
Epoch 79, Val Loss: 4.24091
Epoch 80, Val Loss: 4.08860
Epoch 81, Val Loss: 4.13001
Epoch 82, Val Loss: 4.17740
Epoch 83, Val Loss: 4.14449
Epoch 84, Val Loss: 4.30563
Epoch 85, Val Loss: 4.41812
Epoch 86, Val Loss: 4.29148
Epoch 87, Val Loss: 4.21790
Epoch 88, Val Loss: 4.17507
Epoch 89, Val Loss: 4.21982
Epoch 90, Val Loss: 4.09519
Epoch 91, Val Loss: 4.17992
Epoch 92, Val Loss: 4.35513
Epoch 93, Val Loss: 4.99107
Epoch 94, Val Loss: 5.17978
Epoch 95, Val Loss: 4.23067
Epoch 96, Val Loss: 4.22554
Epoch 97, Val Loss: 4.15522
Epoch 98, Val Loss: 4.05949
Epoch 99, Val Loss: 4.26730
DID NOT SAVE RESULTS
{'MSE - mean': 4.45105003351067, 'MSE - std': 0.2815225201832905, 'R2 - mean': 0.5619738578085114, 'R2 - std': 0.006431163337982826} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.50965
Epoch 1, Val Loss: 11.01105
Epoch 2, Val Loss: 6.18893
Epoch 3, Val Loss: 6.02243
Epoch 4, Val Loss: 5.81931
Epoch 5, Val Loss: 5.65032
Epoch 6, Val Loss: 5.66806
Epoch 7, Val Loss: 5.54084
Epoch 8, Val Loss: 5.52952
Epoch 9, Val Loss: 5.49914
Epoch 10, Val Loss: 5.37653
Epoch 11, Val Loss: 5.34031
Epoch 12, Val Loss: 5.59034
Epoch 13, Val Loss: 5.21331
Epoch 14, Val Loss: 5.21433
Epoch 15, Val Loss: 5.18522
Epoch 16, Val Loss: 5.12063
Epoch 17, Val Loss: 5.32032
Epoch 18, Val Loss: 4.99114
Epoch 19, Val Loss: 5.15409
Epoch 20, Val Loss: 4.97395
Epoch 21, Val Loss: 4.90411
Epoch 22, Val Loss: 4.85536
Epoch 23, Val Loss: 5.15140
Epoch 24, Val Loss: 4.73497
Epoch 25, Val Loss: 4.87322
Epoch 26, Val Loss: 4.93009
Epoch 27, Val Loss: 4.90104
Epoch 28, Val Loss: 4.72584
Epoch 29, Val Loss: 4.82135
Epoch 30, Val Loss: 4.91675
Epoch 31, Val Loss: 4.69176
Epoch 32, Val Loss: 4.77800
Epoch 33, Val Loss: 4.62612
Epoch 34, Val Loss: 4.68107
Epoch 35, Val Loss: 4.77298
Epoch 36, Val Loss: 4.71761
Epoch 37, Val Loss: 4.64595
Epoch 38, Val Loss: 4.95193
Epoch 39, Val Loss: 4.70083
Epoch 40, Val Loss: 4.56794
Epoch 41, Val Loss: 4.56204
Epoch 42, Val Loss: 4.95184
Epoch 43, Val Loss: 4.67220
Epoch 44, Val Loss: 4.57728
Epoch 45, Val Loss: 4.53609
Epoch 46, Val Loss: 4.57594
Epoch 47, Val Loss: 5.04679
Epoch 48, Val Loss: 4.46499
Epoch 49, Val Loss: 4.69124
Epoch 50, Val Loss: 4.65530
Epoch 51, Val Loss: 4.50518
Epoch 52, Val Loss: 4.59953
Epoch 53, Val Loss: 5.17720
Epoch 54, Val Loss: 4.42862
Epoch 55, Val Loss: 4.55986
Epoch 56, Val Loss: 4.57146
Epoch 57, Val Loss: 4.60835
Epoch 58, Val Loss: 4.50289
Epoch 59, Val Loss: 4.89610
Epoch 60, Val Loss: 4.67191
Epoch 61, Val Loss: 4.57493
Epoch 62, Val Loss: 4.49210
Epoch 63, Val Loss: 4.61093
Epoch 64, Val Loss: 4.69570
Epoch 65, Val Loss: 4.60933
Epoch 66, Val Loss: 4.62674
Epoch 67, Val Loss: 4.44380
Epoch 68, Val Loss: 4.61043
Epoch 69, Val Loss: 4.45565
Epoch 70, Val Loss: 4.44492
Epoch 71, Val Loss: 4.79621
Epoch 72, Val Loss: 4.45582
Epoch 73, Val Loss: 4.38700
Epoch 74, Val Loss: 4.69972
Epoch 75, Val Loss: 4.39086
Epoch 76, Val Loss: 4.44274
Epoch 77, Val Loss: 4.55538
Epoch 78, Val Loss: 4.51025
Epoch 79, Val Loss: 4.46755
Epoch 80, Val Loss: 5.10947
Epoch 81, Val Loss: 5.03492
Epoch 82, Val Loss: 4.40340
Epoch 83, Val Loss: 4.46258
Epoch 84, Val Loss: 4.47322
Epoch 85, Val Loss: 4.49287
Epoch 86, Val Loss: 4.57513
Epoch 87, Val Loss: 4.76823
Epoch 88, Val Loss: 4.47690
Epoch 89, Val Loss: 4.69454
Epoch 90, Val Loss: 4.42410
Epoch 91, Val Loss: 4.67198
Epoch 92, Val Loss: 4.61509
Epoch 93, Val Loss: 4.51498
Epoch 94, Val Loss: 4.51681
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.457414367771147, 'MSE - std': 0.23003832089761106, 'R2 - mean': 0.561363827053364, 'R2 - std': 0.005321420515018637} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.17926
Epoch 1, Val Loss: 13.66239
Epoch 2, Val Loss: 6.18472
Epoch 3, Val Loss: 5.60320
Epoch 4, Val Loss: 5.38140
Epoch 5, Val Loss: 5.15852
Epoch 6, Val Loss: 5.12086
Epoch 7, Val Loss: 5.09977
Epoch 8, Val Loss: 4.98887
Epoch 9, Val Loss: 4.90878
Epoch 10, Val Loss: 4.95880
Epoch 11, Val Loss: 5.12440
Epoch 12, Val Loss: 5.01380
Epoch 13, Val Loss: 4.77465
Epoch 14, Val Loss: 4.89106
Epoch 15, Val Loss: 4.78139
Epoch 16, Val Loss: 4.74609
Epoch 17, Val Loss: 4.82437
Epoch 18, Val Loss: 4.61639
Epoch 19, Val Loss: 4.61757
Epoch 20, Val Loss: 5.00190
Epoch 21, Val Loss: 4.59093
Epoch 22, Val Loss: 4.55650
Epoch 23, Val Loss: 4.66799
Epoch 24, Val Loss: 4.61862
Epoch 25, Val Loss: 4.69209
Epoch 26, Val Loss: 4.75379
Epoch 27, Val Loss: 4.71749
Epoch 28, Val Loss: 4.81060
Epoch 29, Val Loss: 4.60770
Epoch 30, Val Loss: 4.45484
Epoch 31, Val Loss: 4.39992
Epoch 32, Val Loss: 4.53442
Epoch 33, Val Loss: 4.43820
Epoch 34, Val Loss: 4.67386
Epoch 35, Val Loss: 4.42125
Epoch 36, Val Loss: 4.38818
Epoch 37, Val Loss: 4.36764
Epoch 38, Val Loss: 4.47643
Epoch 39, Val Loss: 4.26195
Epoch 40, Val Loss: 4.22056
Epoch 41, Val Loss: 4.32795
Epoch 42, Val Loss: 4.33746
Epoch 43, Val Loss: 4.71011
Epoch 44, Val Loss: 4.80629
Epoch 45, Val Loss: 4.43728
Epoch 46, Val Loss: 4.27223
Epoch 47, Val Loss: 4.35283
Epoch 48, Val Loss: 4.19710
Epoch 49, Val Loss: 4.16739
Epoch 50, Val Loss: 4.30854
Epoch 51, Val Loss: 4.19575
Epoch 52, Val Loss: 4.17759
Epoch 53, Val Loss: 4.13170
Epoch 54, Val Loss: 4.29637
Epoch 55, Val Loss: 4.27086
Epoch 56, Val Loss: 4.29051
Epoch 57, Val Loss: 4.28820
Epoch 58, Val Loss: 4.16575
Epoch 59, Val Loss: 4.25502
Epoch 60, Val Loss: 4.26357
Epoch 61, Val Loss: 4.33812
Epoch 62, Val Loss: 4.07624
Epoch 63, Val Loss: 4.31067
Epoch 64, Val Loss: 4.47861
Epoch 65, Val Loss: 4.41243
Epoch 66, Val Loss: 4.05280
Epoch 67, Val Loss: 4.10606
Epoch 68, Val Loss: 4.24926
Epoch 69, Val Loss: 4.09893
Epoch 70, Val Loss: 4.07501
Epoch 71, Val Loss: 4.13963
Epoch 72, Val Loss: 4.19119
Epoch 73, Val Loss: 4.21963
Epoch 74, Val Loss: 4.31809
Epoch 75, Val Loss: 4.43025
Epoch 76, Val Loss: 4.34762
Epoch 77, Val Loss: 4.02643
Epoch 78, Val Loss: 4.69577
Epoch 79, Val Loss: 4.18930
Epoch 80, Val Loss: 4.03071
Epoch 81, Val Loss: 4.13381
Epoch 82, Val Loss: 4.01367
Epoch 83, Val Loss: 4.23247
Epoch 84, Val Loss: 4.06370
Epoch 85, Val Loss: 4.27104
Epoch 86, Val Loss: 4.12241
Epoch 87, Val Loss: 4.21049
Epoch 88, Val Loss: 4.02808
Epoch 89, Val Loss: 4.30674
Epoch 90, Val Loss: 4.53781
Epoch 91, Val Loss: 4.16630
Epoch 92, Val Loss: 4.05228
Epoch 93, Val Loss: 4.00648
Epoch 94, Val Loss: 3.97654
Epoch 95, Val Loss: 4.37973
Epoch 96, Val Loss: 4.40860
Epoch 97, Val Loss: 4.23988
Epoch 98, Val Loss: 4.09042
Epoch 99, Val Loss: 4.04149
DID NOT SAVE RESULTS
{'MSE - mean': 4.418273029025307, 'MSE - std': 0.210438482715244, 'R2 - mean': 0.5560606295368522, 'R2 - std': 0.010276665262654777} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.47285
Epoch 1, Val Loss: 14.06527
Epoch 2, Val Loss: 8.18939
Epoch 3, Val Loss: 8.06540
Epoch 4, Val Loss: 7.80382
Epoch 5, Val Loss: 7.72891
Epoch 6, Val Loss: 7.34467
Epoch 7, Val Loss: 7.23421
Epoch 8, Val Loss: 6.96468
Epoch 9, Val Loss: 6.62212
Epoch 10, Val Loss: 7.47224
Epoch 11, Val Loss: 6.94499
Epoch 12, Val Loss: 6.77148
Epoch 13, Val Loss: 6.56584
Epoch 14, Val Loss: 6.44823
Epoch 15, Val Loss: 6.42111
Epoch 16, Val Loss: 6.51309
Epoch 17, Val Loss: 6.63735
Epoch 18, Val Loss: 6.41007
Epoch 19, Val Loss: 6.55446
Epoch 20, Val Loss: 6.46929
Epoch 21, Val Loss: 6.49470
Epoch 22, Val Loss: 6.26789
Epoch 23, Val Loss: 6.62838
Epoch 24, Val Loss: 6.37431
Epoch 25, Val Loss: 6.25908
Epoch 26, Val Loss: 6.30103
Epoch 27, Val Loss: 6.66848
Epoch 28, Val Loss: 6.11936
Epoch 29, Val Loss: 6.40386
Epoch 30, Val Loss: 6.23414
Epoch 31, Val Loss: 6.36213
Epoch 32, Val Loss: 6.23253
Epoch 33, Val Loss: 6.21313
Epoch 34, Val Loss: 6.50421
Epoch 35, Val Loss: 6.15691
Epoch 36, Val Loss: 6.56564
Epoch 37, Val Loss: 6.13961
Epoch 38, Val Loss: 6.20815
Epoch 39, Val Loss: 6.27537
Epoch 40, Val Loss: 6.30070
Epoch 41, Val Loss: 6.26102
Epoch 42, Val Loss: 6.31538
Epoch 43, Val Loss: 6.29027
Epoch 44, Val Loss: 6.12345
Epoch 45, Val Loss: 6.01073
Epoch 46, Val Loss: 6.14034
Epoch 47, Val Loss: 5.88981
Epoch 48, Val Loss: 6.01558
Epoch 49, Val Loss: 6.34348
Epoch 50, Val Loss: 6.05923
Epoch 51, Val Loss: 6.32264
Epoch 52, Val Loss: 5.86904
Epoch 53, Val Loss: 6.13427
Epoch 54, Val Loss: 6.44081
Epoch 55, Val Loss: 5.90862
Epoch 56, Val Loss: 6.14542
Epoch 57, Val Loss: 5.95418
Epoch 58, Val Loss: 6.06107
Epoch 59, Val Loss: 6.02642
Epoch 60, Val Loss: 5.76030
Epoch 61, Val Loss: 5.76332
Epoch 62, Val Loss: 6.36066
Epoch 63, Val Loss: 5.83434
Epoch 64, Val Loss: 6.14516
Epoch 65, Val Loss: 5.88881
Epoch 66, Val Loss: 6.44702
Epoch 67, Val Loss: 5.92012
Epoch 68, Val Loss: 5.85356
Epoch 69, Val Loss: 5.84419
Epoch 70, Val Loss: 6.37427
Epoch 71, Val Loss: 5.87048
Epoch 72, Val Loss: 5.86093
Epoch 73, Val Loss: 5.87507
Epoch 74, Val Loss: 5.79388
Epoch 75, Val Loss: 6.04139
Epoch 76, Val Loss: 5.88733
Epoch 77, Val Loss: 6.10667
Epoch 78, Val Loss: 5.71564
Epoch 79, Val Loss: 5.92773
Epoch 80, Val Loss: 5.64579
Epoch 81, Val Loss: 5.94291
Epoch 82, Val Loss: 5.68844
Epoch 83, Val Loss: 5.98673
Epoch 84, Val Loss: 5.80941
Epoch 85, Val Loss: 5.85724
Epoch 86, Val Loss: 5.88065
Epoch 87, Val Loss: 6.10228
Epoch 88, Val Loss: 5.76773
Epoch 89, Val Loss: 5.85494
Epoch 90, Val Loss: 6.30555
Epoch 91, Val Loss: 5.68169
Epoch 92, Val Loss: 5.80096
Epoch 93, Val Loss: 5.88192
Epoch 94, Val Loss: 5.63810
Epoch 95, Val Loss: 5.89114
Epoch 96, Val Loss: 6.01102
Epoch 97, Val Loss: 5.68904
Epoch 98, Val Loss: 6.24867
Epoch 99, Val Loss: 5.83276
DID NOT SAVE RESULTS
{'MSE - mean': 4.6644478138228616, 'MSE - std': 0.5271011123935188, 'R2 - mean': 0.5514119689893882, 'R2 - std': 0.013073945796075428} 
 

Results After CV: {'MSE - mean': 4.6644478138228616, 'MSE - std': 0.5271011123935188, 'R2 - mean': 0.5514119689893882, 'R2 - std': 0.013073945796075428}
Train time: 113.35992546900002
Inference time: 0.051854426400029754
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 21 finished with value: 4.6644478138228616 and parameters: {'p_m': 0.40442234712278835, 'alpha': 0.7683856919108543, 'K': 20, 'beta': 0.6717872506980473}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.84658
Epoch 1, Val Loss: 11.27092
Epoch 2, Val Loss: 7.02831
Epoch 3, Val Loss: 7.08536
Epoch 4, Val Loss: 7.27144
Epoch 5, Val Loss: 6.96426
Epoch 6, Val Loss: 7.06782
Epoch 7, Val Loss: 6.74445
Epoch 8, Val Loss: 6.48426
Epoch 9, Val Loss: 6.33356
Epoch 10, Val Loss: 6.23503
Epoch 11, Val Loss: 6.31161
Epoch 12, Val Loss: 6.51899
Epoch 13, Val Loss: 6.16801
Epoch 14, Val Loss: 6.21923
Epoch 15, Val Loss: 6.16761
Epoch 16, Val Loss: 6.06385
Epoch 17, Val Loss: 6.26048
Epoch 18, Val Loss: 6.03995
Epoch 19, Val Loss: 5.84126
Epoch 20, Val Loss: 6.20379
Epoch 21, Val Loss: 5.90552
Epoch 22, Val Loss: 5.65607
Epoch 23, Val Loss: 5.88247
Epoch 24, Val Loss: 5.54200
Epoch 25, Val Loss: 5.55709
Epoch 26, Val Loss: 5.53712
Epoch 27, Val Loss: 5.82583
Epoch 28, Val Loss: 5.72593
Epoch 29, Val Loss: 6.08861
Epoch 30, Val Loss: 5.37719
Epoch 31, Val Loss: 5.36841
Epoch 32, Val Loss: 5.39656
Epoch 33, Val Loss: 5.42301
Epoch 34, Val Loss: 5.22538
Epoch 35, Val Loss: 5.40454
Epoch 36, Val Loss: 5.20480
Epoch 37, Val Loss: 5.21835
Epoch 38, Val Loss: 5.07899
Epoch 39, Val Loss: 5.59148
Epoch 40, Val Loss: 5.22773
Epoch 41, Val Loss: 5.10205
Epoch 42, Val Loss: 5.29279
Epoch 43, Val Loss: 5.09422
Epoch 44, Val Loss: 5.11010
Epoch 45, Val Loss: 5.29035
Epoch 46, Val Loss: 5.65206
Epoch 47, Val Loss: 5.04295
Epoch 48, Val Loss: 4.94863
Epoch 49, Val Loss: 4.93649
Epoch 50, Val Loss: 5.00987
Epoch 51, Val Loss: 5.01490
Epoch 52, Val Loss: 5.01318
Epoch 53, Val Loss: 5.08328
Epoch 54, Val Loss: 5.04531
Epoch 55, Val Loss: 4.87522
Epoch 56, Val Loss: 5.01517
Epoch 57, Val Loss: 5.22004
Epoch 58, Val Loss: 5.07062
Epoch 59, Val Loss: 5.11307
Epoch 60, Val Loss: 4.98643
Epoch 61, Val Loss: 4.79091
Epoch 62, Val Loss: 4.92507
Epoch 63, Val Loss: 4.79991
Epoch 64, Val Loss: 5.32467
Epoch 65, Val Loss: 4.76562
Epoch 66, Val Loss: 4.83198
Epoch 67, Val Loss: 4.93538
Epoch 68, Val Loss: 4.95842
Epoch 69, Val Loss: 5.21676
Epoch 70, Val Loss: 4.87995
Epoch 71, Val Loss: 4.81213
Epoch 72, Val Loss: 5.27676
Epoch 73, Val Loss: 4.89737
Epoch 74, Val Loss: 4.80458
Epoch 75, Val Loss: 4.73570
Epoch 76, Val Loss: 5.06901
Epoch 77, Val Loss: 4.83803
Epoch 78, Val Loss: 4.75212
Epoch 79, Val Loss: 4.80342
Epoch 80, Val Loss: 4.63620
Epoch 81, Val Loss: 4.97024
Epoch 82, Val Loss: 4.99034
Epoch 83, Val Loss: 4.74258
Epoch 84, Val Loss: 4.88405
Epoch 85, Val Loss: 5.19410
Epoch 86, Val Loss: 4.68595
Epoch 87, Val Loss: 4.93331
Epoch 88, Val Loss: 4.72732
Epoch 89, Val Loss: 4.62469
Epoch 90, Val Loss: 4.80609
Epoch 91, Val Loss: 4.62266
Epoch 92, Val Loss: 4.91944
Epoch 93, Val Loss: 4.62698
Epoch 94, Val Loss: 4.62588
Epoch 95, Val Loss: 5.36290
Epoch 96, Val Loss: 4.61021
Epoch 97, Val Loss: 4.82088
Epoch 98, Val Loss: 4.67446
Epoch 99, Val Loss: 4.64375
DID NOT SAVE RESULTS
{'MSE - mean': 4.755523269820107, 'MSE - std': 0.0, 'R2 - mean': 0.5663119916728298, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.66866
Epoch 1, Val Loss: 8.48425
Epoch 2, Val Loss: 5.22054
Epoch 3, Val Loss: 5.59223
Epoch 4, Val Loss: 5.33910
Epoch 5, Val Loss: 5.09812
Epoch 6, Val Loss: 5.66382
Epoch 7, Val Loss: 5.08888
Epoch 8, Val Loss: 5.13539
Epoch 9, Val Loss: 5.02452
Epoch 10, Val Loss: 4.97593
Epoch 11, Val Loss: 4.97286
Epoch 12, Val Loss: 5.08842
Epoch 13, Val Loss: 5.05684
Epoch 14, Val Loss: 4.95536
Epoch 15, Val Loss: 5.11487
Epoch 16, Val Loss: 5.15866
Epoch 17, Val Loss: 4.91034
Epoch 18, Val Loss: 4.97463
Epoch 19, Val Loss: 4.96773
Epoch 20, Val Loss: 5.06821
Epoch 21, Val Loss: 4.96173
Epoch 22, Val Loss: 4.97938
Epoch 23, Val Loss: 4.90751
Epoch 24, Val Loss: 5.09655
Epoch 25, Val Loss: 4.85701
Epoch 26, Val Loss: 4.81489
Epoch 27, Val Loss: 4.88731
Epoch 28, Val Loss: 4.90293
Epoch 29, Val Loss: 5.03477
Epoch 30, Val Loss: 4.70591
Epoch 31, Val Loss: 4.69763
Epoch 32, Val Loss: 4.64779
Epoch 33, Val Loss: 4.99268
Epoch 34, Val Loss: 4.72780
Epoch 35, Val Loss: 4.73950
Epoch 36, Val Loss: 4.65904
Epoch 37, Val Loss: 4.59733
Epoch 38, Val Loss: 4.69553
Epoch 39, Val Loss: 4.81188
Epoch 40, Val Loss: 4.53330
Epoch 41, Val Loss: 4.61000
Epoch 42, Val Loss: 4.57616
Epoch 43, Val Loss: 4.61933
Epoch 44, Val Loss: 4.50867
Epoch 45, Val Loss: 4.53586
Epoch 46, Val Loss: 4.67013
Epoch 47, Val Loss: 4.39736
Epoch 48, Val Loss: 4.71964
Epoch 49, Val Loss: 4.66874
Epoch 50, Val Loss: 4.40683
Epoch 51, Val Loss: 4.28931
Epoch 52, Val Loss: 4.34536
Epoch 53, Val Loss: 4.38365
Epoch 54, Val Loss: 4.24209
Epoch 55, Val Loss: 4.21483
Epoch 56, Val Loss: 4.29227
Epoch 57, Val Loss: 4.62676
Epoch 58, Val Loss: 4.28566
Epoch 59, Val Loss: 4.85625
Epoch 60, Val Loss: 4.30188
Epoch 61, Val Loss: 4.31222
Epoch 62, Val Loss: 4.73563
Epoch 63, Val Loss: 4.19619
Epoch 64, Val Loss: 4.17018
Epoch 65, Val Loss: 4.25541
Epoch 66, Val Loss: 4.28873
Epoch 67, Val Loss: 4.41585
Epoch 68, Val Loss: 4.43210
Epoch 69, Val Loss: 4.25917
Epoch 70, Val Loss: 4.24565
Epoch 71, Val Loss: 4.37411
Epoch 72, Val Loss: 4.21073
Epoch 73, Val Loss: 4.14487
Epoch 74, Val Loss: 4.73715
Epoch 75, Val Loss: 4.25081
Epoch 76, Val Loss: 4.39239
Epoch 77, Val Loss: 4.24201
Epoch 78, Val Loss: 4.53908
Epoch 79, Val Loss: 4.73680
Epoch 80, Val Loss: 4.28516
Epoch 81, Val Loss: 4.10020
Epoch 82, Val Loss: 4.45916
Epoch 83, Val Loss: 4.09002
Epoch 84, Val Loss: 4.09498
Epoch 85, Val Loss: 4.15885
Epoch 86, Val Loss: 4.48806
Epoch 87, Val Loss: 4.20069
Epoch 88, Val Loss: 4.08413
Epoch 89, Val Loss: 4.10442
Epoch 90, Val Loss: 4.04217
Epoch 91, Val Loss: 4.64855
Epoch 92, Val Loss: 4.04756
Epoch 93, Val Loss: 4.24664
Epoch 94, Val Loss: 4.16052
Epoch 95, Val Loss: 4.03110
Epoch 96, Val Loss: 4.05012
Epoch 97, Val Loss: 4.07334
Epoch 98, Val Loss: 4.14795
Epoch 99, Val Loss: 4.04185
DID NOT SAVE RESULTS
{'MSE - mean': 4.518757549183313, 'MSE - std': 0.2367657206367939, 'R2 - mean': 0.5549331882962588, 'R2 - std': 0.011378803376570934} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.46777
Epoch 1, Val Loss: 9.01793
Epoch 2, Val Loss: 7.39428
Epoch 3, Val Loss: 6.46399
Epoch 4, Val Loss: 6.25325
Epoch 5, Val Loss: 6.20718
Epoch 6, Val Loss: 5.99520
Epoch 7, Val Loss: 6.08787
Epoch 8, Val Loss: 5.98191
Epoch 9, Val Loss: 5.88346
Epoch 10, Val Loss: 5.83818
Epoch 11, Val Loss: 5.77915
Epoch 12, Val Loss: 5.84925
Epoch 13, Val Loss: 5.67232
Epoch 14, Val Loss: 5.55657
Epoch 15, Val Loss: 5.48565
Epoch 16, Val Loss: 5.37173
Epoch 17, Val Loss: 5.38951
Epoch 18, Val Loss: 5.32279
Epoch 19, Val Loss: 5.32358
Epoch 20, Val Loss: 5.50029
Epoch 21, Val Loss: 5.38781
Epoch 22, Val Loss: 5.45885
Epoch 23, Val Loss: 5.29200
Epoch 24, Val Loss: 5.14486
Epoch 25, Val Loss: 5.69338
Epoch 26, Val Loss: 5.21308
Epoch 27, Val Loss: 5.25364
Epoch 28, Val Loss: 5.31334
Epoch 29, Val Loss: 5.19038
Epoch 30, Val Loss: 5.30088
Epoch 31, Val Loss: 5.15304
Epoch 32, Val Loss: 4.94836
Epoch 33, Val Loss: 5.06375
Epoch 34, Val Loss: 5.09604
Epoch 35, Val Loss: 5.03702
Epoch 36, Val Loss: 5.00637
Epoch 37, Val Loss: 5.39027
Epoch 38, Val Loss: 5.17937
Epoch 39, Val Loss: 5.06830
Epoch 40, Val Loss: 5.01309
Epoch 41, Val Loss: 5.09715
Epoch 42, Val Loss: 5.02160
Epoch 43, Val Loss: 5.16138
Epoch 44, Val Loss: 4.94438
Epoch 45, Val Loss: 5.10162
Epoch 46, Val Loss: 4.90728
Epoch 47, Val Loss: 5.07491
Epoch 48, Val Loss: 4.99789
Epoch 49, Val Loss: 5.12167
Epoch 50, Val Loss: 5.31209
Epoch 51, Val Loss: 4.98155
Epoch 52, Val Loss: 5.27490
Epoch 53, Val Loss: 4.83773
Epoch 54, Val Loss: 5.03394
Epoch 55, Val Loss: 4.91860
Epoch 56, Val Loss: 4.96156
Epoch 57, Val Loss: 5.21504
Epoch 58, Val Loss: 4.87397
Epoch 59, Val Loss: 4.92396
Epoch 60, Val Loss: 4.95986
Epoch 61, Val Loss: 4.75959
Epoch 62, Val Loss: 4.95447
Epoch 63, Val Loss: 5.14639
Epoch 64, Val Loss: 5.07685
Epoch 65, Val Loss: 4.92774
Epoch 66, Val Loss: 4.83920
Epoch 67, Val Loss: 4.84737
Epoch 68, Val Loss: 4.85928
Epoch 69, Val Loss: 5.02042
Epoch 70, Val Loss: 4.89519
Epoch 71, Val Loss: 4.76737
Epoch 72, Val Loss: 4.76342
Epoch 73, Val Loss: 4.88056
Epoch 74, Val Loss: 4.81802
Epoch 75, Val Loss: 4.87855
Epoch 76, Val Loss: 4.82571
Epoch 77, Val Loss: 4.92321
Epoch 78, Val Loss: 4.78140
Epoch 79, Val Loss: 4.91147
Epoch 80, Val Loss: 4.88508
Epoch 81, Val Loss: 4.85661
Epoch 82, Val Loss: 4.88757
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.644470880934908, 'MSE - std': 0.2626398444117223, 'R2 - mean': 0.5427054849297248, 'R2 - std': 0.019630373661624533} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.89478
Epoch 1, Val Loss: 7.65683
Epoch 2, Val Loss: 6.15264
Epoch 3, Val Loss: 5.56903
Epoch 4, Val Loss: 5.66839
Epoch 5, Val Loss: 5.29313
Epoch 6, Val Loss: 5.43488
Epoch 7, Val Loss: 5.35984
Epoch 8, Val Loss: 5.12006
Epoch 9, Val Loss: 5.07265
Epoch 10, Val Loss: 5.07539
Epoch 11, Val Loss: 5.07350
Epoch 12, Val Loss: 5.00554
Epoch 13, Val Loss: 4.97873
Epoch 14, Val Loss: 5.04579
Epoch 15, Val Loss: 5.43804
Epoch 16, Val Loss: 5.04883
Epoch 17, Val Loss: 4.95117
Epoch 18, Val Loss: 4.96362
Epoch 19, Val Loss: 5.37365
Epoch 20, Val Loss: 4.80978
Epoch 21, Val Loss: 4.90017
Epoch 22, Val Loss: 4.71424
Epoch 23, Val Loss: 4.77152
Epoch 24, Val Loss: 4.68452
Epoch 25, Val Loss: 4.89652
Epoch 26, Val Loss: 4.86746
Epoch 27, Val Loss: 4.78027
Epoch 28, Val Loss: 4.74355
Epoch 29, Val Loss: 4.90979
Epoch 30, Val Loss: 4.60167
Epoch 31, Val Loss: 4.87246
Epoch 32, Val Loss: 4.59666
Epoch 33, Val Loss: 4.63741
Epoch 34, Val Loss: 4.68919
Epoch 35, Val Loss: 4.58347
Epoch 36, Val Loss: 5.04966
Epoch 37, Val Loss: 4.67619
Epoch 38, Val Loss: 4.49054
Epoch 39, Val Loss: 4.55143
Epoch 40, Val Loss: 4.49349
Epoch 41, Val Loss: 4.54197
Epoch 42, Val Loss: 4.59605
Epoch 43, Val Loss: 4.39721
Epoch 44, Val Loss: 4.42004
Epoch 45, Val Loss: 4.42527
Epoch 46, Val Loss: 4.62402
Epoch 47, Val Loss: 4.35631
Epoch 48, Val Loss: 4.42185
Epoch 49, Val Loss: 4.62834
Epoch 50, Val Loss: 4.55027
Epoch 51, Val Loss: 4.33710
Epoch 52, Val Loss: 4.55755
Epoch 53, Val Loss: 4.47170
Epoch 54, Val Loss: 4.39077
Epoch 55, Val Loss: 4.33659
Epoch 56, Val Loss: 4.59442
Epoch 57, Val Loss: 5.31067
Epoch 58, Val Loss: 4.24850
Epoch 59, Val Loss: 4.51447
Epoch 60, Val Loss: 4.25942
Epoch 61, Val Loss: 5.01983
Epoch 62, Val Loss: 4.25862
Epoch 63, Val Loss: 4.28013
Epoch 64, Val Loss: 4.17783
Epoch 65, Val Loss: 4.51281
Epoch 66, Val Loss: 4.39087
Epoch 67, Val Loss: 4.25037
Epoch 68, Val Loss: 4.54217
Epoch 69, Val Loss: 4.32918
Epoch 70, Val Loss: 4.27633
Epoch 71, Val Loss: 4.25525
Epoch 72, Val Loss: 4.28421
Epoch 73, Val Loss: 4.34952
Epoch 74, Val Loss: 4.43717
Epoch 75, Val Loss: 4.33144
Epoch 76, Val Loss: 4.26468
Epoch 77, Val Loss: 4.27523
Epoch 78, Val Loss: 4.18107
Epoch 79, Val Loss: 4.26712
Epoch 80, Val Loss: 4.18821
Epoch 81, Val Loss: 4.86056
Epoch 82, Val Loss: 4.20513
Epoch 83, Val Loss: 4.36498
Epoch 84, Val Loss: 4.34115
Epoch 85, Val Loss: 4.16740
Epoch 86, Val Loss: 4.38547
Epoch 87, Val Loss: 4.36712
Epoch 88, Val Loss: 4.27762
Epoch 89, Val Loss: 4.93178
Epoch 90, Val Loss: 4.74327
Epoch 91, Val Loss: 4.28168
Epoch 92, Val Loss: 4.31909
Epoch 93, Val Loss: 4.81626
Epoch 94, Val Loss: 4.18715
Epoch 95, Val Loss: 4.16069
Epoch 96, Val Loss: 4.33558
Epoch 97, Val Loss: 4.38247
Epoch 98, Val Loss: 4.27273
Epoch 99, Val Loss: 4.21118
DID NOT SAVE RESULTS
{'MSE - mean': 4.604677335238039, 'MSE - std': 0.2376664569135637, 'R2 - mean': 0.5371365628710111, 'R2 - std': 0.019546159629434543} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.93655
Epoch 1, Val Loss: 16.85122
Epoch 2, Val Loss: 8.43818
Epoch 3, Val Loss: 8.35349
Epoch 4, Val Loss: 7.88995
Epoch 5, Val Loss: 7.45345
Epoch 6, Val Loss: 7.34436
Epoch 7, Val Loss: 7.55142
Epoch 8, Val Loss: 7.65274
Epoch 9, Val Loss: 7.33780
Epoch 10, Val Loss: 7.63446
Epoch 11, Val Loss: 7.31948
Epoch 12, Val Loss: 7.31032
Epoch 13, Val Loss: 7.25869
Epoch 14, Val Loss: 7.25318
Epoch 15, Val Loss: 7.16333
Epoch 16, Val Loss: 7.30524
Epoch 17, Val Loss: 7.26711
Epoch 18, Val Loss: 7.23477
Epoch 19, Val Loss: 7.20123
Epoch 20, Val Loss: 7.16100
Epoch 21, Val Loss: 7.11520
Epoch 22, Val Loss: 7.30378
Epoch 23, Val Loss: 7.16063
Epoch 24, Val Loss: 7.41427
Epoch 25, Val Loss: 7.22864
Epoch 26, Val Loss: 7.14658
Epoch 27, Val Loss: 7.51146
Epoch 28, Val Loss: 7.27133
Epoch 29, Val Loss: 7.31567
Epoch 30, Val Loss: 7.17410
Epoch 31, Val Loss: 7.17443
Epoch 32, Val Loss: 7.51587
Epoch 33, Val Loss: 7.05126
Epoch 34, Val Loss: 6.99495
Epoch 35, Val Loss: 6.98477
Epoch 36, Val Loss: 6.96956
Epoch 37, Val Loss: 7.78657
Epoch 38, Val Loss: 7.02624
Epoch 39, Val Loss: 7.16515
Epoch 40, Val Loss: 6.98005
Epoch 41, Val Loss: 6.80959
Epoch 42, Val Loss: 6.97356
Epoch 43, Val Loss: 7.12067
Epoch 44, Val Loss: 7.03345
Epoch 45, Val Loss: 6.81022
Epoch 46, Val Loss: 6.93974
Epoch 47, Val Loss: 6.71724
Epoch 48, Val Loss: 6.61718
Epoch 49, Val Loss: 6.87182
Epoch 50, Val Loss: 6.48704
Epoch 51, Val Loss: 6.48041
Epoch 52, Val Loss: 6.45759
Epoch 53, Val Loss: 6.56955
Epoch 54, Val Loss: 6.59979
Epoch 55, Val Loss: 6.35816
Epoch 56, Val Loss: 6.53264
Epoch 57, Val Loss: 6.50876
Epoch 58, Val Loss: 6.55441
Epoch 59, Val Loss: 6.37862
Epoch 60, Val Loss: 6.87136
Epoch 61, Val Loss: 6.32301
Epoch 62, Val Loss: 6.24709
Epoch 63, Val Loss: 6.53331
Epoch 64, Val Loss: 6.91698
Epoch 65, Val Loss: 6.15233
Epoch 66, Val Loss: 7.07629
Epoch 67, Val Loss: 6.32312
Epoch 68, Val Loss: 6.21053
Epoch 69, Val Loss: 6.42062
Epoch 70, Val Loss: 6.65180
Epoch 71, Val Loss: 6.41034
Epoch 72, Val Loss: 6.35199
Epoch 73, Val Loss: 6.17380
Epoch 74, Val Loss: 6.27853
Epoch 75, Val Loss: 6.50907
Epoch 76, Val Loss: 6.22298
Epoch 77, Val Loss: 6.12968
Epoch 78, Val Loss: 6.27539
Epoch 79, Val Loss: 6.15913
Epoch 80, Val Loss: 6.08896
Epoch 81, Val Loss: 6.20612
Epoch 82, Val Loss: 6.06611
Epoch 83, Val Loss: 6.28293
Epoch 84, Val Loss: 6.14944
Epoch 85, Val Loss: 6.07372
Epoch 86, Val Loss: 6.69671
Epoch 87, Val Loss: 6.35524
Epoch 88, Val Loss: 6.11568
Epoch 89, Val Loss: 6.07215
Epoch 90, Val Loss: 6.30436
Epoch 91, Val Loss: 6.18195
Epoch 92, Val Loss: 6.10642
Epoch 93, Val Loss: 6.08633
Epoch 94, Val Loss: 5.98455
Epoch 95, Val Loss: 6.11574
Epoch 96, Val Loss: 6.06323
Epoch 97, Val Loss: 6.65366
Epoch 98, Val Loss: 6.01907
Epoch 99, Val Loss: 6.03903
DID NOT SAVE RESULTS
{'MSE - mean': 4.868502463789626, 'MSE - std': 0.5688612041742015, 'R2 - mean': 0.5317299223100602, 'R2 - std': 0.020556481547890085} 
 

Results After CV: {'MSE - mean': 4.868502463789626, 'MSE - std': 0.5688612041742015, 'R2 - mean': 0.5317299223100602, 'R2 - std': 0.020556481547890085}
Train time: 109.69166409880006
Inference time: 0.05165639900003498
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 22 finished with value: 4.868502463789626 and parameters: {'p_m': 0.4586883625346406, 'alpha': 1.6789504967213569, 'K': 20, 'beta': 0.9972543736912765}. Best is trial 8 with value: 4.638784670488211.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.06034
Epoch 1, Val Loss: 10.92047
Epoch 2, Val Loss: 6.34617
Epoch 3, Val Loss: 6.16872
Epoch 4, Val Loss: 6.04477
Epoch 5, Val Loss: 6.23717
Epoch 6, Val Loss: 5.92487
Epoch 7, Val Loss: 6.02264
Epoch 8, Val Loss: 5.91069
Epoch 9, Val Loss: 5.82000
Epoch 10, Val Loss: 6.27592
Epoch 11, Val Loss: 5.76394
Epoch 12, Val Loss: 6.08237
Epoch 13, Val Loss: 6.24597
Epoch 14, Val Loss: 5.82577
Epoch 15, Val Loss: 5.46739
Epoch 16, Val Loss: 5.38249
Epoch 17, Val Loss: 5.58250
Epoch 18, Val Loss: 5.32700
Epoch 19, Val Loss: 5.31258
Epoch 20, Val Loss: 5.31019
Epoch 21, Val Loss: 5.25365
Epoch 22, Val Loss: 5.68503
Epoch 23, Val Loss: 5.23261
Epoch 24, Val Loss: 5.07889
Epoch 25, Val Loss: 5.19235
Epoch 26, Val Loss: 5.43273
Epoch 27, Val Loss: 5.10628
Epoch 28, Val Loss: 5.41171
Epoch 29, Val Loss: 4.96265
Epoch 30, Val Loss: 5.69316
Epoch 31, Val Loss: 5.22094
Epoch 32, Val Loss: 4.96218
Epoch 33, Val Loss: 4.99161
Epoch 34, Val Loss: 4.87296
Epoch 35, Val Loss: 4.83532
Epoch 36, Val Loss: 5.07977
Epoch 37, Val Loss: 4.90770
Epoch 38, Val Loss: 5.10664
Epoch 39, Val Loss: 5.01228
Epoch 40, Val Loss: 4.78159
Epoch 41, Val Loss: 4.74782
Epoch 42, Val Loss: 4.96185
Epoch 43, Val Loss: 4.80673
Epoch 44, Val Loss: 4.76985
Epoch 45, Val Loss: 4.70705
Epoch 46, Val Loss: 5.01185
Epoch 47, Val Loss: 4.65042
Epoch 48, Val Loss: 4.77693
Epoch 49, Val Loss: 4.68297
Epoch 50, Val Loss: 4.86132
Epoch 51, Val Loss: 4.85499
Epoch 52, Val Loss: 4.78978
Epoch 53, Val Loss: 4.82124
Epoch 54, Val Loss: 5.10246
Epoch 55, Val Loss: 4.76204
Epoch 56, Val Loss: 4.66561
Epoch 57, Val Loss: 4.71719
Epoch 58, Val Loss: 4.83910
Epoch 59, Val Loss: 4.74853
Epoch 60, Val Loss: 4.81989
Epoch 61, Val Loss: 4.61457
Epoch 62, Val Loss: 4.59050
Epoch 63, Val Loss: 4.70957
Epoch 64, Val Loss: 4.65491
Epoch 65, Val Loss: 4.57115
Epoch 66, Val Loss: 4.73210
Epoch 67, Val Loss: 4.64054
Epoch 68, Val Loss: 4.67965
Epoch 69, Val Loss: 4.89554
Epoch 70, Val Loss: 4.67742
Epoch 71, Val Loss: 4.75276
Epoch 72, Val Loss: 4.62892
Epoch 73, Val Loss: 4.51264
Epoch 74, Val Loss: 4.77800
Epoch 75, Val Loss: 4.51699
Epoch 76, Val Loss: 4.66984
Epoch 77, Val Loss: 4.66811
Epoch 78, Val Loss: 4.69484
Epoch 79, Val Loss: 4.66880
Epoch 80, Val Loss: 4.94943
Epoch 81, Val Loss: 4.49571
Epoch 82, Val Loss: 4.54735
Epoch 83, Val Loss: 4.69774
Epoch 84, Val Loss: 4.50979
Epoch 85, Val Loss: 4.62378
Epoch 86, Val Loss: 4.86119
Epoch 87, Val Loss: 4.66243
Epoch 88, Val Loss: 4.78694
Epoch 89, Val Loss: 4.72196
Epoch 90, Val Loss: 4.46260
Epoch 91, Val Loss: 4.49550
Epoch 92, Val Loss: 4.49190
Epoch 93, Val Loss: 4.63095
Epoch 94, Val Loss: 4.49937
Epoch 95, Val Loss: 4.67222
Epoch 96, Val Loss: 4.51361
Epoch 97, Val Loss: 4.49880
Epoch 98, Val Loss: 4.66712
Epoch 99, Val Loss: 4.51681
DID NOT SAVE RESULTS
{'MSE - mean': 4.565866705915203, 'MSE - std': 0.0, 'R2 - mean': 0.5836080436106019, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.36568
Epoch 1, Val Loss: 13.01547
Epoch 2, Val Loss: 6.60754
Epoch 3, Val Loss: 6.18349
Epoch 4, Val Loss: 4.99754
Epoch 5, Val Loss: 4.74204
Epoch 6, Val Loss: 4.74942
Epoch 7, Val Loss: 4.53299
Epoch 8, Val Loss: 4.46351
Epoch 9, Val Loss: 4.68636
Epoch 10, Val Loss: 4.35666
Epoch 11, Val Loss: 4.24377
Epoch 12, Val Loss: 4.67381
Epoch 13, Val Loss: 4.31788
Epoch 14, Val Loss: 4.41225
Epoch 15, Val Loss: 4.23350
Epoch 16, Val Loss: 4.13768
Epoch 17, Val Loss: 4.03347
Epoch 18, Val Loss: 4.16001
Epoch 19, Val Loss: 4.08112
Epoch 20, Val Loss: 4.03333
Epoch 21, Val Loss: 3.94609
Epoch 22, Val Loss: 3.99982
Epoch 23, Val Loss: 4.42692
Epoch 24, Val Loss: 3.92037
Epoch 25, Val Loss: 4.23128
Epoch 26, Val Loss: 4.19664
Epoch 27, Val Loss: 3.90817
Epoch 28, Val Loss: 3.86143
Epoch 29, Val Loss: 4.12531
Epoch 30, Val Loss: 3.85364
Epoch 31, Val Loss: 4.02261
Epoch 32, Val Loss: 5.05340
Epoch 33, Val Loss: 3.98007
Epoch 34, Val Loss: 3.95647
Epoch 35, Val Loss: 4.00285
Epoch 36, Val Loss: 4.16693
Epoch 37, Val Loss: 3.91404
Epoch 38, Val Loss: 4.16680
Epoch 39, Val Loss: 3.91663
Epoch 40, Val Loss: 3.86783
Epoch 41, Val Loss: 3.95821
Epoch 42, Val Loss: 4.28731
Epoch 43, Val Loss: 3.88418
Epoch 44, Val Loss: 3.96262
Epoch 45, Val Loss: 4.08377
Epoch 46, Val Loss: 4.49319
Epoch 47, Val Loss: 3.97940
Epoch 48, Val Loss: 3.92491
Epoch 49, Val Loss: 3.83725
Epoch 50, Val Loss: 3.98467
Epoch 51, Val Loss: 3.88158
Epoch 52, Val Loss: 4.00977
Epoch 53, Val Loss: 3.86453
Epoch 54, Val Loss: 3.86886
Epoch 55, Val Loss: 4.29608
Epoch 56, Val Loss: 4.00127
Epoch 57, Val Loss: 4.32606
Epoch 58, Val Loss: 3.95420
Epoch 59, Val Loss: 4.21690
Epoch 60, Val Loss: 3.89274
Epoch 61, Val Loss: 3.91666
Epoch 62, Val Loss: 4.04989
Epoch 63, Val Loss: 3.95025
Epoch 64, Val Loss: 4.02143
Epoch 65, Val Loss: 4.22328
Epoch 66, Val Loss: 3.91495
Epoch 67, Val Loss: 3.86597
Epoch 68, Val Loss: 3.87434
Epoch 69, Val Loss: 4.16622
Epoch 70, Val Loss: 4.04664
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.304118379025459, 'MSE - std': 0.2617483268897449, 'R2 - mean': 0.5763526432519201, 'R2 - std': 0.007255400358681829} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.97855
Epoch 1, Val Loss: 16.57758
Epoch 2, Val Loss: 6.42340
Epoch 3, Val Loss: 6.75091
Epoch 4, Val Loss: 5.80116
Epoch 5, Val Loss: 5.49586
Epoch 6, Val Loss: 5.47079
Epoch 7, Val Loss: 5.64276
Epoch 8, Val Loss: 5.23222
Epoch 9, Val Loss: 5.39181
Epoch 10, Val Loss: 5.14420
Epoch 11, Val Loss: 5.17555
Epoch 12, Val Loss: 5.24792
Epoch 13, Val Loss: 5.02031
Epoch 14, Val Loss: 5.33713
Epoch 15, Val Loss: 5.31261
Epoch 16, Val Loss: 5.08275
Epoch 17, Val Loss: 4.95061
Epoch 18, Val Loss: 5.00922
Epoch 19, Val Loss: 5.08303
Epoch 20, Val Loss: 4.95084
Epoch 21, Val Loss: 4.92513
Epoch 22, Val Loss: 4.96047
Epoch 23, Val Loss: 4.80389
Epoch 24, Val Loss: 5.49446
Epoch 25, Val Loss: 5.02293
Epoch 26, Val Loss: 4.76811
Epoch 27, Val Loss: 4.71243
Epoch 28, Val Loss: 4.71378
Epoch 29, Val Loss: 4.88072
Epoch 30, Val Loss: 4.78486
Epoch 31, Val Loss: 4.65003
Epoch 32, Val Loss: 4.77273
Epoch 33, Val Loss: 4.66479
Epoch 34, Val Loss: 4.73613
Epoch 35, Val Loss: 4.89283
Epoch 36, Val Loss: 4.74418
Epoch 37, Val Loss: 4.87792
Epoch 38, Val Loss: 4.96009
Epoch 39, Val Loss: 4.98579
Epoch 40, Val Loss: 4.58234
Epoch 41, Val Loss: 4.81938
Epoch 42, Val Loss: 4.56239
Epoch 43, Val Loss: 4.55047
Epoch 44, Val Loss: 4.71721
Epoch 45, Val Loss: 5.02019
Epoch 46, Val Loss: 4.67198
Epoch 47, Val Loss: 4.60617
Epoch 48, Val Loss: 4.59762
Epoch 49, Val Loss: 4.75472
Epoch 50, Val Loss: 5.08537
Epoch 51, Val Loss: 4.58146
Epoch 52, Val Loss: 4.58933
Epoch 53, Val Loss: 4.65310
Epoch 54, Val Loss: 4.68529
Epoch 55, Val Loss: 4.70053
Epoch 56, Val Loss: 4.58487
Epoch 57, Val Loss: 5.22182
Epoch 58, Val Loss: 4.62647
Epoch 59, Val Loss: 4.65901
Epoch 60, Val Loss: 4.79045
Epoch 61, Val Loss: 4.82056
Epoch 62, Val Loss: 4.58444
Epoch 63, Val Loss: 4.58975
Epoch 64, Val Loss: 4.61285
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.419274037155962, 'MSE - std': 0.2686939565478272, 'R2 - mean': 0.5650640541620378, 'R2 - std': 0.017028164224511397} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.80270
Epoch 1, Val Loss: 13.21853
Epoch 2, Val Loss: 6.25430
Epoch 3, Val Loss: 5.69438
Epoch 4, Val Loss: 5.50033
Epoch 5, Val Loss: 5.16313
Epoch 6, Val Loss: 5.44054
Epoch 7, Val Loss: 5.54494
Epoch 8, Val Loss: 4.78788
Epoch 9, Val Loss: 4.63829
Epoch 10, Val Loss: 4.68042
Epoch 11, Val Loss: 4.54922
Epoch 12, Val Loss: 4.55051
Epoch 13, Val Loss: 4.54019
Epoch 14, Val Loss: 4.57019
Epoch 15, Val Loss: 4.40947
Epoch 16, Val Loss: 4.67697
Epoch 17, Val Loss: 4.53900
Epoch 18, Val Loss: 5.13951
Epoch 19, Val Loss: 4.39894
Epoch 20, Val Loss: 4.39159
Epoch 21, Val Loss: 4.97425
Epoch 22, Val Loss: 4.31524
Epoch 23, Val Loss: 4.45210
Epoch 24, Val Loss: 4.31251
Epoch 25, Val Loss: 4.35026
Epoch 26, Val Loss: 4.54000
Epoch 27, Val Loss: 4.27035
Epoch 28, Val Loss: 4.80167
Epoch 29, Val Loss: 5.18446
Epoch 30, Val Loss: 4.22846
Epoch 31, Val Loss: 4.17018
Epoch 32, Val Loss: 4.24255
Epoch 33, Val Loss: 4.23021
Epoch 34, Val Loss: 4.81938
Epoch 35, Val Loss: 4.60267
Epoch 36, Val Loss: 4.46278
Epoch 37, Val Loss: 4.14501
Epoch 38, Val Loss: 4.21524
Epoch 39, Val Loss: 4.37146
Epoch 40, Val Loss: 4.62348
Epoch 41, Val Loss: 4.37098
Epoch 42, Val Loss: 4.37341
Epoch 43, Val Loss: 4.28482
Epoch 44, Val Loss: 4.35618
Epoch 45, Val Loss: 4.25347
Epoch 46, Val Loss: 4.23223
Epoch 47, Val Loss: 4.21926
Epoch 48, Val Loss: 4.19587
Epoch 49, Val Loss: 4.11346
Epoch 50, Val Loss: 4.28584
Epoch 51, Val Loss: 4.14239
Epoch 52, Val Loss: 4.32699
Epoch 53, Val Loss: 4.22009
Epoch 54, Val Loss: 4.17014
Epoch 55, Val Loss: 4.30635
Epoch 56, Val Loss: 4.20237
Epoch 57, Val Loss: 4.14382
Epoch 58, Val Loss: 4.28344
Epoch 59, Val Loss: 4.42972
Epoch 60, Val Loss: 4.27879
Epoch 61, Val Loss: 4.10465
Epoch 62, Val Loss: 4.23024
Epoch 63, Val Loss: 4.19349
Epoch 64, Val Loss: 4.38765
Epoch 65, Val Loss: 4.16506
Epoch 66, Val Loss: 4.45586
Epoch 67, Val Loss: 4.12019
Epoch 68, Val Loss: 4.07732
Epoch 69, Val Loss: 4.11260
Epoch 70, Val Loss: 4.15702
Epoch 71, Val Loss: 4.19664
Epoch 72, Val Loss: 4.51692
Epoch 73, Val Loss: 4.47352
Epoch 74, Val Loss: 4.15354
Epoch 75, Val Loss: 4.31383
Epoch 76, Val Loss: 4.11321
Epoch 77, Val Loss: 4.21059
Epoch 78, Val Loss: 4.09165
Epoch 79, Val Loss: 4.12315
Epoch 80, Val Loss: 4.38155
Epoch 81, Val Loss: 4.17697
Epoch 82, Val Loss: 4.18887
Epoch 83, Val Loss: 4.47604
Epoch 84, Val Loss: 4.09269
Epoch 85, Val Loss: 4.75076
Epoch 86, Val Loss: 4.71233
Epoch 87, Val Loss: 4.19667
Epoch 88, Val Loss: 4.10202
Epoch 89, Val Loss: 4.16732
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.417210996484965, 'MSE - std': 0.23272322643953008, 'R2 - mean': 0.5558908652724802, 'R2 - std': 0.021677429871947512} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 46.22615
Epoch 1, Val Loss: 20.07960
Epoch 2, Val Loss: 7.36728
Epoch 3, Val Loss: 6.83320
Epoch 4, Val Loss: 6.86543
Epoch 5, Val Loss: 6.92114
Epoch 6, Val Loss: 6.71858
Epoch 7, Val Loss: 6.56308
Epoch 8, Val Loss: 6.52110
Epoch 9, Val Loss: 6.49806
Epoch 10, Val Loss: 6.52439
Epoch 11, Val Loss: 6.73603
Epoch 12, Val Loss: 6.39490
Epoch 13, Val Loss: 6.47116
Epoch 14, Val Loss: 6.51064
Epoch 15, Val Loss: 6.33513
Epoch 16, Val Loss: 6.27147
Epoch 17, Val Loss: 6.18024
Epoch 18, Val Loss: 6.70647
Epoch 19, Val Loss: 6.47329
Epoch 20, Val Loss: 6.22188
Epoch 21, Val Loss: 6.22148
Epoch 22, Val Loss: 5.95795
Epoch 23, Val Loss: 6.49161
Epoch 24, Val Loss: 6.24887
Epoch 25, Val Loss: 5.84758
Epoch 26, Val Loss: 5.77775
Epoch 27, Val Loss: 5.77201
Epoch 28, Val Loss: 5.92547
Epoch 29, Val Loss: 5.82127
Epoch 30, Val Loss: 5.66028
Epoch 31, Val Loss: 5.79314
Epoch 32, Val Loss: 5.62189
Epoch 33, Val Loss: 6.08130
Epoch 34, Val Loss: 5.78711
Epoch 35, Val Loss: 5.74437
Epoch 36, Val Loss: 5.85551
Epoch 37, Val Loss: 5.58444
Epoch 38, Val Loss: 5.57445
Epoch 39, Val Loss: 5.52171
Epoch 40, Val Loss: 5.69384
Epoch 41, Val Loss: 5.58106
Epoch 42, Val Loss: 5.48383
Epoch 43, Val Loss: 5.77383
Epoch 44, Val Loss: 5.60426
Epoch 45, Val Loss: 5.50193
Epoch 46, Val Loss: 5.57197
Epoch 47, Val Loss: 6.14579
Epoch 48, Val Loss: 5.52977
Epoch 49, Val Loss: 5.73815
Epoch 50, Val Loss: 5.49711
Epoch 51, Val Loss: 5.54350
Epoch 52, Val Loss: 5.58374
Epoch 53, Val Loss: 5.52663
Epoch 54, Val Loss: 5.41285
Epoch 55, Val Loss: 5.75992
Epoch 56, Val Loss: 5.39691
Epoch 57, Val Loss: 5.87030
Epoch 58, Val Loss: 5.38627
Epoch 59, Val Loss: 5.47280
Epoch 60, Val Loss: 5.65498
Epoch 61, Val Loss: 5.64466
Epoch 62, Val Loss: 5.68155
Epoch 63, Val Loss: 5.55771
Epoch 64, Val Loss: 5.39428
Epoch 65, Val Loss: 5.87876
Epoch 66, Val Loss: 5.63692
Epoch 67, Val Loss: 5.65348
Epoch 68, Val Loss: 5.64717
Epoch 69, Val Loss: 5.42113
Epoch 70, Val Loss: 5.72495
Epoch 71, Val Loss: 5.39198
Epoch 72, Val Loss: 5.53090
Epoch 73, Val Loss: 5.73698
Epoch 74, Val Loss: 5.93593
Epoch 75, Val Loss: 5.66526
Epoch 76, Val Loss: 5.84164
Epoch 77, Val Loss: 5.40422
Epoch 78, Val Loss: 5.47746
Epoch 79, Val Loss: 5.56072
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.602941213165306, 'MSE - std': 0.4258062160796221, 'R2 - mean': 0.556292470268885, 'R2 - std': 0.019405512592433914} 
 

Results After CV: {'MSE - mean': 4.602941213165306, 'MSE - std': 0.4258062160796221, 'R2 - mean': 0.556292470268885, 'R2 - std': 0.019405512592433914}
Train time: 93.54846379119999
Inference time: 0.05153948980000678
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 23 finished with value: 4.602941213165306 and parameters: {'p_m': 0.6487856156108985, 'alpha': 3.357727134862121, 'K': 20, 'beta': 0.16867169474637234}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.10698
Epoch 1, Val Loss: 13.84663
Epoch 2, Val Loss: 7.88447
Epoch 3, Val Loss: 7.22720
Epoch 4, Val Loss: 7.44956
Epoch 5, Val Loss: 7.09400
Epoch 6, Val Loss: 6.66339
Epoch 7, Val Loss: 7.67850
Epoch 8, Val Loss: 6.47107
Epoch 9, Val Loss: 6.46862
Epoch 10, Val Loss: 6.34486
Epoch 11, Val Loss: 6.31054
Epoch 12, Val Loss: 6.26506
Epoch 13, Val Loss: 6.22690
Epoch 14, Val Loss: 6.18664
Epoch 15, Val Loss: 6.10971
Epoch 16, Val Loss: 5.93771
Epoch 17, Val Loss: 6.46757
Epoch 18, Val Loss: 5.89011
Epoch 19, Val Loss: 5.88513
Epoch 20, Val Loss: 6.29964
Epoch 21, Val Loss: 5.79257
Epoch 22, Val Loss: 5.65776
Epoch 23, Val Loss: 5.73509
Epoch 24, Val Loss: 5.91142
Epoch 25, Val Loss: 5.58449
Epoch 26, Val Loss: 5.46836
Epoch 27, Val Loss: 5.60320
Epoch 28, Val Loss: 5.40034
Epoch 29, Val Loss: 5.85997
Epoch 30, Val Loss: 5.34465
Epoch 31, Val Loss: 5.57521
Epoch 32, Val Loss: 5.27574
Epoch 33, Val Loss: 5.45326
Epoch 34, Val Loss: 5.34097
Epoch 35, Val Loss: 5.20119
Epoch 36, Val Loss: 5.28916
Epoch 37, Val Loss: 5.15671
Epoch 38, Val Loss: 5.20418
Epoch 39, Val Loss: 5.02271
Epoch 40, Val Loss: 5.00654
Epoch 41, Val Loss: 5.29560
Epoch 42, Val Loss: 5.01277
Epoch 43, Val Loss: 4.96144
Epoch 44, Val Loss: 4.97062
Epoch 45, Val Loss: 5.04916
Epoch 46, Val Loss: 5.03824
Epoch 47, Val Loss: 5.24833
Epoch 48, Val Loss: 4.95620
Epoch 49, Val Loss: 4.86169
Epoch 50, Val Loss: 4.80592
Epoch 51, Val Loss: 4.94795
Epoch 52, Val Loss: 4.87357
Epoch 53, Val Loss: 5.01937
Epoch 54, Val Loss: 4.76871
Epoch 55, Val Loss: 4.87749
Epoch 56, Val Loss: 5.10563
Epoch 57, Val Loss: 5.11782
Epoch 58, Val Loss: 5.01330
Epoch 59, Val Loss: 4.88369
Epoch 60, Val Loss: 5.11581
Epoch 61, Val Loss: 4.77421
Epoch 62, Val Loss: 4.79146
Epoch 63, Val Loss: 4.88412
Epoch 64, Val Loss: 4.78165
Epoch 65, Val Loss: 4.71149
Epoch 66, Val Loss: 5.30739
Epoch 67, Val Loss: 4.78417
Epoch 68, Val Loss: 4.73433
Epoch 69, Val Loss: 5.31284
Epoch 70, Val Loss: 4.91782
Epoch 71, Val Loss: 4.97438
Epoch 72, Val Loss: 4.62838
Epoch 73, Val Loss: 4.76202
Epoch 74, Val Loss: 4.74189
Epoch 75, Val Loss: 5.15115
Epoch 76, Val Loss: 4.85768
Epoch 77, Val Loss: 4.91574
Epoch 78, Val Loss: 4.89454
Epoch 79, Val Loss: 4.83245
Epoch 80, Val Loss: 4.58483
Epoch 81, Val Loss: 4.76896
Epoch 82, Val Loss: 4.62438
Epoch 83, Val Loss: 4.75019
Epoch 84, Val Loss: 4.60507
Epoch 85, Val Loss: 4.78709
Epoch 86, Val Loss: 4.62830
Epoch 87, Val Loss: 4.78042
Epoch 88, Val Loss: 5.04632
Epoch 89, Val Loss: 4.52751
Epoch 90, Val Loss: 4.54366
Epoch 91, Val Loss: 4.94237
Epoch 92, Val Loss: 4.60543
Epoch 93, Val Loss: 4.62666
Epoch 94, Val Loss: 4.86192
Epoch 95, Val Loss: 4.60331
Epoch 96, Val Loss: 4.89126
Epoch 97, Val Loss: 4.71436
Epoch 98, Val Loss: 4.60263
Epoch 99, Val Loss: 4.75118
DID NOT SAVE RESULTS
{'MSE - mean': 4.7031512527782, 'MSE - std': 0.0, 'R2 - mean': 0.5710881465719394, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.82115
Epoch 1, Val Loss: 7.88553
Epoch 2, Val Loss: 5.60093
Epoch 3, Val Loss: 5.38915
Epoch 4, Val Loss: 5.50931
Epoch 5, Val Loss: 5.68589
Epoch 6, Val Loss: 5.38433
Epoch 7, Val Loss: 5.52719
Epoch 8, Val Loss: 5.21289
Epoch 9, Val Loss: 6.10864
Epoch 10, Val Loss: 5.29490
Epoch 11, Val Loss: 5.19406
Epoch 12, Val Loss: 5.21561
Epoch 13, Val Loss: 5.23821
Epoch 14, Val Loss: 5.64133
Epoch 15, Val Loss: 5.04681
Epoch 16, Val Loss: 5.39844
Epoch 17, Val Loss: 5.23707
Epoch 18, Val Loss: 5.28404
Epoch 19, Val Loss: 5.33266
Epoch 20, Val Loss: 5.41204
Epoch 21, Val Loss: 4.98849
Epoch 22, Val Loss: 5.07321
Epoch 23, Val Loss: 4.96149
Epoch 24, Val Loss: 4.94445
Epoch 25, Val Loss: 4.95140
Epoch 26, Val Loss: 4.97902
Epoch 27, Val Loss: 5.08696
Epoch 28, Val Loss: 4.86578
Epoch 29, Val Loss: 4.91945
Epoch 30, Val Loss: 4.86417
Epoch 31, Val Loss: 4.86803
Epoch 32, Val Loss: 5.92881
Epoch 33, Val Loss: 5.21676
Epoch 34, Val Loss: 4.75270
Epoch 35, Val Loss: 4.81193
Epoch 36, Val Loss: 4.66614
Epoch 37, Val Loss: 4.91632
Epoch 38, Val Loss: 4.73160
Epoch 39, Val Loss: 4.64052
Epoch 40, Val Loss: 4.62035
Epoch 41, Val Loss: 4.65273
Epoch 42, Val Loss: 4.71407
Epoch 43, Val Loss: 4.63708
Epoch 44, Val Loss: 4.43956
Epoch 45, Val Loss: 4.96894
Epoch 46, Val Loss: 5.01379
Epoch 47, Val Loss: 4.45516
Epoch 48, Val Loss: 4.38582
Epoch 49, Val Loss: 4.45528
Epoch 50, Val Loss: 4.51851
Epoch 51, Val Loss: 4.49947
Epoch 52, Val Loss: 4.37129
Epoch 53, Val Loss: 4.50034
Epoch 54, Val Loss: 4.34741
Epoch 55, Val Loss: 4.50698
Epoch 56, Val Loss: 4.57848
Epoch 57, Val Loss: 4.28040
Epoch 58, Val Loss: 4.35772
Epoch 59, Val Loss: 4.63407
Epoch 60, Val Loss: 4.53310
Epoch 61, Val Loss: 4.41952
Epoch 62, Val Loss: 4.28891
Epoch 63, Val Loss: 4.95020
Epoch 64, Val Loss: 4.31095
Epoch 65, Val Loss: 4.20027
Epoch 66, Val Loss: 4.20131
Epoch 67, Val Loss: 4.16317
Epoch 68, Val Loss: 4.29810
Epoch 69, Val Loss: 4.31926
Epoch 70, Val Loss: 4.39433
Epoch 71, Val Loss: 4.99992
Epoch 72, Val Loss: 4.63226
Epoch 73, Val Loss: 4.27314
Epoch 74, Val Loss: 4.23782
Epoch 75, Val Loss: 4.36049
Epoch 76, Val Loss: 4.15087
Epoch 77, Val Loss: 4.11150
Epoch 78, Val Loss: 4.39557
Epoch 79, Val Loss: 4.32214
Epoch 80, Val Loss: 4.58100
Epoch 81, Val Loss: 4.48120
Epoch 82, Val Loss: 4.41803
Epoch 83, Val Loss: 4.22394
Epoch 84, Val Loss: 4.31814
Epoch 85, Val Loss: 4.04404
Epoch 86, Val Loss: 4.25415
Epoch 87, Val Loss: 4.37091
Epoch 88, Val Loss: 4.10066
Epoch 89, Val Loss: 4.16569
Epoch 90, Val Loss: 4.21356
Epoch 91, Val Loss: 4.01920
Epoch 92, Val Loss: 4.53738
Epoch 93, Val Loss: 4.66728
Epoch 94, Val Loss: 4.47914
Epoch 95, Val Loss: 4.53974
Epoch 96, Val Loss: 4.29798
Epoch 97, Val Loss: 4.35928
Epoch 98, Val Loss: 4.06761
Epoch 99, Val Loss: 4.19670
DID NOT SAVE RESULTS
{'MSE - mean': 4.411081608258934, 'MSE - std': 0.29206964451926565, 'R2 - mean': 0.566007812523125, 'R2 - std': 0.005080334048814361} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.62496
Epoch 1, Val Loss: 9.76570
Epoch 2, Val Loss: 7.67346
Epoch 3, Val Loss: 6.74826
Epoch 4, Val Loss: 6.25757
Epoch 5, Val Loss: 6.30331
Epoch 6, Val Loss: 7.06787
Epoch 7, Val Loss: 6.05658
Epoch 8, Val Loss: 6.09831
Epoch 9, Val Loss: 6.26677
Epoch 10, Val Loss: 5.97974
Epoch 11, Val Loss: 6.00108
Epoch 12, Val Loss: 5.89581
Epoch 13, Val Loss: 5.80066
Epoch 14, Val Loss: 5.97618
Epoch 15, Val Loss: 5.78085
Epoch 16, Val Loss: 5.75720
Epoch 17, Val Loss: 5.85655
Epoch 18, Val Loss: 5.85067
Epoch 19, Val Loss: 5.52546
Epoch 20, Val Loss: 5.52014
Epoch 21, Val Loss: 5.53984
Epoch 22, Val Loss: 5.38336
Epoch 23, Val Loss: 5.41503
Epoch 24, Val Loss: 5.25139
Epoch 25, Val Loss: 5.28651
Epoch 26, Val Loss: 5.40811
Epoch 27, Val Loss: 5.20761
Epoch 28, Val Loss: 5.40636
Epoch 29, Val Loss: 5.37400
Epoch 30, Val Loss: 5.25745
Epoch 31, Val Loss: 5.21513
Epoch 32, Val Loss: 5.26539
Epoch 33, Val Loss: 5.29993
Epoch 34, Val Loss: 5.24473
Epoch 35, Val Loss: 5.11023
Epoch 36, Val Loss: 5.09339
Epoch 37, Val Loss: 5.11266
Epoch 38, Val Loss: 4.94862
Epoch 39, Val Loss: 4.90563
Epoch 40, Val Loss: 4.91882
Epoch 41, Val Loss: 4.89180
Epoch 42, Val Loss: 4.93148
Epoch 43, Val Loss: 5.22673
Epoch 44, Val Loss: 5.21320
Epoch 45, Val Loss: 4.87942
Epoch 46, Val Loss: 4.90759
Epoch 47, Val Loss: 4.76803
Epoch 48, Val Loss: 5.03415
Epoch 49, Val Loss: 5.21386
Epoch 50, Val Loss: 4.90842
Epoch 51, Val Loss: 4.94436
Epoch 52, Val Loss: 4.77425
Epoch 53, Val Loss: 4.85945
Epoch 54, Val Loss: 4.86610
Epoch 55, Val Loss: 4.78645
Epoch 56, Val Loss: 5.17425
Epoch 57, Val Loss: 4.60322
Epoch 58, Val Loss: 4.72007
Epoch 59, Val Loss: 4.80197
Epoch 60, Val Loss: 4.62364
Epoch 61, Val Loss: 4.73678
Epoch 62, Val Loss: 4.68917
Epoch 63, Val Loss: 5.20626
Epoch 64, Val Loss: 4.99221
Epoch 65, Val Loss: 4.68037
Epoch 66, Val Loss: 4.75446
Epoch 67, Val Loss: 4.62508
Epoch 68, Val Loss: 4.70548
Epoch 69, Val Loss: 4.61988
Epoch 70, Val Loss: 4.69239
Epoch 71, Val Loss: 4.60662
Epoch 72, Val Loss: 4.58462
Epoch 73, Val Loss: 4.89793
Epoch 74, Val Loss: 4.71532
Epoch 75, Val Loss: 4.73656
Epoch 76, Val Loss: 4.62509
Epoch 77, Val Loss: 4.57731
Epoch 78, Val Loss: 4.92276
Epoch 79, Val Loss: 5.14458
Epoch 80, Val Loss: 4.84537
Epoch 81, Val Loss: 4.73068
Epoch 82, Val Loss: 4.75442
Epoch 83, Val Loss: 4.83509
Epoch 84, Val Loss: 4.50763
Epoch 85, Val Loss: 4.55362
Epoch 86, Val Loss: 4.65454
Epoch 87, Val Loss: 4.51653
Epoch 88, Val Loss: 4.65990
Epoch 89, Val Loss: 4.55926
Epoch 90, Val Loss: 4.62743
Epoch 91, Val Loss: 4.52903
Epoch 92, Val Loss: 4.61022
Epoch 93, Val Loss: 4.54426
Epoch 94, Val Loss: 4.63368
Epoch 95, Val Loss: 4.66253
Epoch 96, Val Loss: 5.18480
Epoch 97, Val Loss: 4.58841
Epoch 98, Val Loss: 4.85804
Epoch 99, Val Loss: 4.70752
DID NOT SAVE RESULTS
{'MSE - mean': 4.481485078163007, 'MSE - std': 0.258424228705709, 'R2 - mean': 0.5590627098590689, 'R2 - std': 0.010661868100552793} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.03253
Epoch 1, Val Loss: 18.43059
Epoch 2, Val Loss: 5.85032
Epoch 3, Val Loss: 5.70710
Epoch 4, Val Loss: 6.04221
Epoch 5, Val Loss: 5.51630
Epoch 6, Val Loss: 5.45155
Epoch 7, Val Loss: 5.59375
Epoch 8, Val Loss: 5.45441
Epoch 9, Val Loss: 5.32173
Epoch 10, Val Loss: 5.30808
Epoch 11, Val Loss: 5.28571
Epoch 12, Val Loss: 5.39698
Epoch 13, Val Loss: 5.23931
Epoch 14, Val Loss: 5.55328
Epoch 15, Val Loss: 5.17242
Epoch 16, Val Loss: 5.15254
Epoch 17, Val Loss: 5.24618
Epoch 18, Val Loss: 5.22018
Epoch 19, Val Loss: 5.11854
Epoch 20, Val Loss: 5.11878
Epoch 21, Val Loss: 5.28440
Epoch 22, Val Loss: 5.16537
Epoch 23, Val Loss: 5.28584
Epoch 24, Val Loss: 5.45485
Epoch 25, Val Loss: 5.13040
Epoch 26, Val Loss: 5.02974
Epoch 27, Val Loss: 5.38993
Epoch 28, Val Loss: 5.25918
Epoch 29, Val Loss: 5.14723
Epoch 30, Val Loss: 5.04391
Epoch 31, Val Loss: 5.35018
Epoch 32, Val Loss: 5.01496
Epoch 33, Val Loss: 4.85096
Epoch 34, Val Loss: 4.90704
Epoch 35, Val Loss: 4.83488
Epoch 36, Val Loss: 4.91906
Epoch 37, Val Loss: 4.87634
Epoch 38, Val Loss: 4.92143
Epoch 39, Val Loss: 5.06737
Epoch 40, Val Loss: 4.75722
Epoch 41, Val Loss: 4.65911
Epoch 42, Val Loss: 4.74295
Epoch 43, Val Loss: 4.92834
Epoch 44, Val Loss: 4.68659
Epoch 45, Val Loss: 4.61979
Epoch 46, Val Loss: 5.29036
Epoch 47, Val Loss: 4.63455
Epoch 48, Val Loss: 4.57632
Epoch 49, Val Loss: 4.75386
Epoch 50, Val Loss: 4.74685
Epoch 51, Val Loss: 4.54491
Epoch 52, Val Loss: 4.56557
Epoch 53, Val Loss: 4.49615
Epoch 54, Val Loss: 4.71904
Epoch 55, Val Loss: 4.79138
Epoch 56, Val Loss: 4.72225
Epoch 57, Val Loss: 4.76774
Epoch 58, Val Loss: 4.96259
Epoch 59, Val Loss: 4.42105
Epoch 60, Val Loss: 4.50747
Epoch 61, Val Loss: 4.45901
Epoch 62, Val Loss: 4.58529
Epoch 63, Val Loss: 4.51959
Epoch 64, Val Loss: 4.40514
Epoch 65, Val Loss: 4.31086
Epoch 66, Val Loss: 4.28624
Epoch 67, Val Loss: 4.22928
Epoch 68, Val Loss: 4.39341
Epoch 69, Val Loss: 4.45656
Epoch 70, Val Loss: 4.56486
Epoch 71, Val Loss: 4.28482
Epoch 72, Val Loss: 4.45331
Epoch 73, Val Loss: 4.32307
Epoch 74, Val Loss: 4.33127
Epoch 75, Val Loss: 4.28280
Epoch 76, Val Loss: 4.19593
Epoch 77, Val Loss: 4.30919
Epoch 78, Val Loss: 4.48951
Epoch 79, Val Loss: 4.17432
Epoch 80, Val Loss: 4.51110
Epoch 81, Val Loss: 4.27050
Epoch 82, Val Loss: 4.20379
Epoch 83, Val Loss: 4.10052
Epoch 84, Val Loss: 4.38253
Epoch 85, Val Loss: 4.21821
Epoch 86, Val Loss: 4.33051
Epoch 87, Val Loss: 4.28156
Epoch 88, Val Loss: 4.20409
Epoch 89, Val Loss: 4.29974
Epoch 90, Val Loss: 4.42197
Epoch 91, Val Loss: 4.06843
Epoch 92, Val Loss: 4.38156
Epoch 93, Val Loss: 4.12442
Epoch 94, Val Loss: 4.09037
Epoch 95, Val Loss: 4.16776
Epoch 96, Val Loss: 4.35150
Epoch 97, Val Loss: 4.38093
Epoch 98, Val Loss: 4.42644
Epoch 99, Val Loss: 4.12588
DID NOT SAVE RESULTS
{'MSE - mean': 4.454936255676238, 'MSE - std': 0.2284772010790295, 'R2 - mean': 0.5523449802524544, 'R2 - std': 0.014853964007898578} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.56744
Epoch 1, Val Loss: 11.77278
Epoch 2, Val Loss: 9.20232
Epoch 3, Val Loss: 7.92269
Epoch 4, Val Loss: 7.70021
Epoch 5, Val Loss: 7.68324
Epoch 6, Val Loss: 7.57412
Epoch 7, Val Loss: 7.57995
Epoch 8, Val Loss: 7.81439
Epoch 9, Val Loss: 7.40173
Epoch 10, Val Loss: 7.17310
Epoch 11, Val Loss: 7.15615
Epoch 12, Val Loss: 7.08114
Epoch 13, Val Loss: 7.10283
Epoch 14, Val Loss: 7.18052
Epoch 15, Val Loss: 7.38533
Epoch 16, Val Loss: 7.34313
Epoch 17, Val Loss: 7.11026
Epoch 18, Val Loss: 7.14812
Epoch 19, Val Loss: 6.97258
Epoch 20, Val Loss: 7.01179
Epoch 21, Val Loss: 6.99289
Epoch 22, Val Loss: 6.95945
Epoch 23, Val Loss: 6.77370
Epoch 24, Val Loss: 7.01835
Epoch 25, Val Loss: 7.18746
Epoch 26, Val Loss: 6.64320
Epoch 27, Val Loss: 7.01182
Epoch 28, Val Loss: 6.84349
Epoch 29, Val Loss: 7.43157
Epoch 30, Val Loss: 6.70700
Epoch 31, Val Loss: 6.66043
Epoch 32, Val Loss: 6.51207
Epoch 33, Val Loss: 6.65421
Epoch 34, Val Loss: 6.90722
Epoch 35, Val Loss: 6.59106
Epoch 36, Val Loss: 6.60118
Epoch 37, Val Loss: 6.74243
Epoch 38, Val Loss: 6.56003
Epoch 39, Val Loss: 6.55984
Epoch 40, Val Loss: 6.56449
Epoch 41, Val Loss: 6.36335
Epoch 42, Val Loss: 6.63153
Epoch 43, Val Loss: 6.39326
Epoch 44, Val Loss: 6.72817
Epoch 45, Val Loss: 6.66957
Epoch 46, Val Loss: 6.67462
Epoch 47, Val Loss: 6.32559
Epoch 48, Val Loss: 6.47556
Epoch 49, Val Loss: 6.91130
Epoch 50, Val Loss: 6.29110
Epoch 51, Val Loss: 6.29375
Epoch 52, Val Loss: 6.50986
Epoch 53, Val Loss: 6.49337
Epoch 54, Val Loss: 6.16960
Epoch 55, Val Loss: 6.16908
Epoch 56, Val Loss: 6.31329
Epoch 57, Val Loss: 6.11515
Epoch 58, Val Loss: 6.23844
Epoch 59, Val Loss: 6.20172
Epoch 60, Val Loss: 6.38610
Epoch 61, Val Loss: 6.09375
Epoch 62, Val Loss: 6.20612
Epoch 63, Val Loss: 6.08745
Epoch 64, Val Loss: 6.09916
Epoch 65, Val Loss: 5.90144
Epoch 66, Val Loss: 6.13741
Epoch 67, Val Loss: 6.09763
Epoch 68, Val Loss: 6.14676
Epoch 69, Val Loss: 6.33413
Epoch 70, Val Loss: 6.26142
Epoch 71, Val Loss: 6.29281
Epoch 72, Val Loss: 5.98795
Epoch 73, Val Loss: 6.19350
Epoch 74, Val Loss: 5.93160
Epoch 75, Val Loss: 5.99907
Epoch 76, Val Loss: 6.00691
Epoch 77, Val Loss: 5.92801
Epoch 78, Val Loss: 6.07348
Epoch 79, Val Loss: 6.18853
Epoch 80, Val Loss: 6.08091
Epoch 81, Val Loss: 5.96891
Epoch 82, Val Loss: 5.95596
Epoch 83, Val Loss: 5.99821
Epoch 84, Val Loss: 6.37710
Epoch 85, Val Loss: 6.06150
Epoch 86, Val Loss: 6.01664
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.735775303795814, 'MSE - std': 0.597698710827756, 'R2 - mean': 0.54496631844783, 'R2 - std': 0.019856756973545595} 
 

Results After CV: {'MSE - mean': 4.735775303795814, 'MSE - std': 0.597698710827756, 'R2 - mean': 0.54496631844783, 'R2 - std': 0.019856756973545595}
Train time: 111.13453028919999
Inference time: 0.052217503600013516
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 24 finished with value: 4.735775303795814 and parameters: {'p_m': 0.6472085285377506, 'alpha': 3.311726782711502, 'K': 20, 'beta': 2.0951611682637488}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.72869
Epoch 1, Val Loss: 12.14536
Epoch 2, Val Loss: 7.43280
Epoch 3, Val Loss: 7.01512
Epoch 4, Val Loss: 6.95371
Epoch 5, Val Loss: 6.74709
Epoch 6, Val Loss: 7.02773
Epoch 7, Val Loss: 6.75462
Epoch 8, Val Loss: 6.63717
Epoch 9, Val Loss: 6.61358
Epoch 10, Val Loss: 6.35223
Epoch 11, Val Loss: 7.36536
Epoch 12, Val Loss: 6.57710
Epoch 13, Val Loss: 6.32448
Epoch 14, Val Loss: 6.54967
Epoch 15, Val Loss: 6.26833
Epoch 16, Val Loss: 6.27375
Epoch 17, Val Loss: 6.35216
Epoch 18, Val Loss: 6.64648
Epoch 19, Val Loss: 6.29706
Epoch 20, Val Loss: 6.31668
Epoch 21, Val Loss: 6.37294
Epoch 22, Val Loss: 6.13486
Epoch 23, Val Loss: 6.38382
Epoch 24, Val Loss: 6.17830
Epoch 25, Val Loss: 6.12873
Epoch 26, Val Loss: 6.09140
Epoch 27, Val Loss: 6.45080
Epoch 28, Val Loss: 6.00417
Epoch 29, Val Loss: 6.14707
Epoch 30, Val Loss: 6.30023
Epoch 31, Val Loss: 5.98982
Epoch 32, Val Loss: 6.12428
Epoch 33, Val Loss: 6.26396
Epoch 34, Val Loss: 6.49172
Epoch 35, Val Loss: 5.97114
Epoch 36, Val Loss: 6.56096
Epoch 37, Val Loss: 6.54029
Epoch 38, Val Loss: 6.16325
Epoch 39, Val Loss: 6.14007
Epoch 40, Val Loss: 5.87924
Epoch 41, Val Loss: 6.74160
Epoch 42, Val Loss: 5.84854
Epoch 43, Val Loss: 6.31119
Epoch 44, Val Loss: 6.03731
Epoch 45, Val Loss: 5.85938
Epoch 46, Val Loss: 6.08748
Epoch 47, Val Loss: 5.84678
Epoch 48, Val Loss: 5.98044
Epoch 49, Val Loss: 5.96031
Epoch 50, Val Loss: 5.78098
Epoch 51, Val Loss: 5.88514
Epoch 52, Val Loss: 5.80478
Epoch 53, Val Loss: 5.88095
Epoch 54, Val Loss: 5.83320
Epoch 55, Val Loss: 6.38431
Epoch 56, Val Loss: 5.96498
Epoch 57, Val Loss: 5.70573
Epoch 58, Val Loss: 5.99237
Epoch 59, Val Loss: 6.11310
Epoch 60, Val Loss: 5.90008
Epoch 61, Val Loss: 6.01079
Epoch 62, Val Loss: 5.72909
Epoch 63, Val Loss: 5.70663
Epoch 64, Val Loss: 5.65248
Epoch 65, Val Loss: 5.72834
Epoch 66, Val Loss: 5.85096
Epoch 67, Val Loss: 6.37376
Epoch 68, Val Loss: 6.42761
Epoch 69, Val Loss: 5.76288
Epoch 70, Val Loss: 5.90346
Epoch 71, Val Loss: 5.90074
Epoch 72, Val Loss: 5.80900
Epoch 73, Val Loss: 5.56078
Epoch 74, Val Loss: 5.57413
Epoch 75, Val Loss: 5.61723
Epoch 76, Val Loss: 5.91216
Epoch 77, Val Loss: 5.59157
Epoch 78, Val Loss: 5.65051
Epoch 79, Val Loss: 5.47355
Epoch 80, Val Loss: 5.61551
Epoch 81, Val Loss: 5.49840
Epoch 82, Val Loss: 5.60972
Epoch 83, Val Loss: 5.41288
Epoch 84, Val Loss: 5.51797
Epoch 85, Val Loss: 5.59348
Epoch 86, Val Loss: 5.61821
Epoch 87, Val Loss: 5.59819
Epoch 88, Val Loss: 5.36493
Epoch 89, Val Loss: 5.36288
Epoch 90, Val Loss: 5.39147
Epoch 91, Val Loss: 5.92089
Epoch 92, Val Loss: 5.37013
Epoch 93, Val Loss: 5.38668
Epoch 94, Val Loss: 5.60097
Epoch 95, Val Loss: 5.34402
Epoch 96, Val Loss: 5.29300
Epoch 97, Val Loss: 5.65949
Epoch 98, Val Loss: 5.22467
Epoch 99, Val Loss: 5.61940
DID NOT SAVE RESULTS
{'MSE - mean': 5.464996494355172, 'MSE - std': 0.0, 'R2 - mean': 0.501610377938174, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.65496
Epoch 1, Val Loss: 11.16016
Epoch 2, Val Loss: 6.01401
Epoch 3, Val Loss: 5.30166
Epoch 4, Val Loss: 5.34000
Epoch 5, Val Loss: 5.69750
Epoch 6, Val Loss: 5.38050
Epoch 7, Val Loss: 5.39975
Epoch 8, Val Loss: 5.24387
Epoch 9, Val Loss: 5.30908
Epoch 10, Val Loss: 5.10974
Epoch 11, Val Loss: 5.31078
Epoch 12, Val Loss: 5.14765
Epoch 13, Val Loss: 5.22083
Epoch 14, Val Loss: 4.89777
Epoch 15, Val Loss: 5.27104
Epoch 16, Val Loss: 4.95967
Epoch 17, Val Loss: 4.85371
Epoch 18, Val Loss: 5.30891
Epoch 19, Val Loss: 5.16815
Epoch 20, Val Loss: 4.94910
Epoch 21, Val Loss: 4.89765
Epoch 22, Val Loss: 4.90900
Epoch 23, Val Loss: 4.99072
Epoch 24, Val Loss: 4.85376
Epoch 25, Val Loss: 4.80039
Epoch 26, Val Loss: 4.78443
Epoch 27, Val Loss: 4.81322
Epoch 28, Val Loss: 5.31942
Epoch 29, Val Loss: 5.41866
Epoch 30, Val Loss: 4.84755
Epoch 31, Val Loss: 4.82438
Epoch 32, Val Loss: 4.85003
Epoch 33, Val Loss: 4.76557
Epoch 34, Val Loss: 4.84181
Epoch 35, Val Loss: 4.75980
Epoch 36, Val Loss: 4.71005
Epoch 37, Val Loss: 4.71449
Epoch 38, Val Loss: 4.68890
Epoch 39, Val Loss: 4.94065
Epoch 40, Val Loss: 4.77369
Epoch 41, Val Loss: 4.66426
Epoch 42, Val Loss: 4.95758
Epoch 43, Val Loss: 4.64428
Epoch 44, Val Loss: 4.70994
Epoch 45, Val Loss: 4.76490
Epoch 46, Val Loss: 5.03969
Epoch 47, Val Loss: 4.70525
Epoch 48, Val Loss: 5.37181
Epoch 49, Val Loss: 4.60650
Epoch 50, Val Loss: 4.72553
Epoch 51, Val Loss: 4.63689
Epoch 52, Val Loss: 4.98855
Epoch 53, Val Loss: 4.85269
Epoch 54, Val Loss: 4.82654
Epoch 55, Val Loss: 4.80971
Epoch 56, Val Loss: 4.55463
Epoch 57, Val Loss: 4.56944
Epoch 58, Val Loss: 4.92607
Epoch 59, Val Loss: 4.65107
Epoch 60, Val Loss: 4.83200
Epoch 61, Val Loss: 4.56540
Epoch 62, Val Loss: 4.72326
Epoch 63, Val Loss: 4.47594
Epoch 64, Val Loss: 4.66438
Epoch 65, Val Loss: 4.90273
Epoch 66, Val Loss: 4.72744
Epoch 67, Val Loss: 5.12899
Epoch 68, Val Loss: 4.72789
Epoch 69, Val Loss: 4.55141
Epoch 70, Val Loss: 4.75852
Epoch 71, Val Loss: 4.55063
Epoch 72, Val Loss: 4.60360
Epoch 73, Val Loss: 4.54872
Epoch 74, Val Loss: 4.56051
Epoch 75, Val Loss: 4.45492
Epoch 76, Val Loss: 4.38872
Epoch 77, Val Loss: 4.31568
Epoch 78, Val Loss: 4.58913
Epoch 79, Val Loss: 4.39867
Epoch 80, Val Loss: 4.96041
Epoch 81, Val Loss: 4.48623
Epoch 82, Val Loss: 4.33249
Epoch 83, Val Loss: 4.44019
Epoch 84, Val Loss: 4.54428
Epoch 85, Val Loss: 4.52774
Epoch 86, Val Loss: 4.44912
Epoch 87, Val Loss: 4.45163
Epoch 88, Val Loss: 4.64562
Epoch 89, Val Loss: 4.36953
Epoch 90, Val Loss: 4.40055
Epoch 91, Val Loss: 4.62102
Epoch 92, Val Loss: 4.30250
Epoch 93, Val Loss: 4.42003
Epoch 94, Val Loss: 4.24905
Epoch 95, Val Loss: 4.81612
Epoch 96, Val Loss: 4.41928
Epoch 97, Val Loss: 4.54771
Epoch 98, Val Loss: 4.31990
Epoch 99, Val Loss: 4.25476
DID NOT SAVE RESULTS
{'MSE - mean': 4.949380813611672, 'MSE - std': 0.5156156807434997, 'R2 - mean': 0.5144931250714073, 'R2 - std': 0.012882747133233341} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.62782
Epoch 1, Val Loss: 11.39603
Epoch 2, Val Loss: 6.52813
Epoch 3, Val Loss: 6.21962
Epoch 4, Val Loss: 6.37656
Epoch 5, Val Loss: 6.67149
Epoch 6, Val Loss: 6.52240
Epoch 7, Val Loss: 6.50114
Epoch 8, Val Loss: 6.44707
Epoch 9, Val Loss: 6.56700
Epoch 10, Val Loss: 6.62427
Epoch 11, Val Loss: 6.17652
Epoch 12, Val Loss: 6.03707
Epoch 13, Val Loss: 6.41675
Epoch 14, Val Loss: 5.96878
Epoch 15, Val Loss: 6.06637
Epoch 16, Val Loss: 6.09682
Epoch 17, Val Loss: 6.10667
Epoch 18, Val Loss: 6.09642
Epoch 19, Val Loss: 6.15193
Epoch 20, Val Loss: 5.92348
Epoch 21, Val Loss: 6.01226
Epoch 22, Val Loss: 5.85898
Epoch 23, Val Loss: 6.28624
Epoch 24, Val Loss: 5.91638
Epoch 25, Val Loss: 6.18406
Epoch 26, Val Loss: 5.93554
Epoch 27, Val Loss: 6.18291
Epoch 28, Val Loss: 5.95830
Epoch 29, Val Loss: 5.70301
Epoch 30, Val Loss: 5.95522
Epoch 31, Val Loss: 5.89599
Epoch 32, Val Loss: 6.00946
Epoch 33, Val Loss: 5.73646
Epoch 34, Val Loss: 5.85722
Epoch 35, Val Loss: 5.96089
Epoch 36, Val Loss: 5.93080
Epoch 37, Val Loss: 6.32539
Epoch 38, Val Loss: 5.98158
Epoch 39, Val Loss: 5.99204
Epoch 40, Val Loss: 5.82953
Epoch 41, Val Loss: 5.82827
Epoch 42, Val Loss: 5.87264
Epoch 43, Val Loss: 5.82146
Epoch 44, Val Loss: 5.73353
Epoch 45, Val Loss: 5.79377
Epoch 46, Val Loss: 5.67872
Epoch 47, Val Loss: 5.63736
Epoch 48, Val Loss: 5.75672
Epoch 49, Val Loss: 5.62013
Epoch 50, Val Loss: 5.91043
Epoch 51, Val Loss: 5.69307
Epoch 52, Val Loss: 5.64267
Epoch 53, Val Loss: 5.53995
Epoch 54, Val Loss: 5.61967
Epoch 55, Val Loss: 6.08025
Epoch 56, Val Loss: 5.75943
Epoch 57, Val Loss: 5.66731
Epoch 58, Val Loss: 5.64488
Epoch 59, Val Loss: 5.76811
Epoch 60, Val Loss: 5.81940
Epoch 61, Val Loss: 5.67108
Epoch 62, Val Loss: 5.77057
Epoch 63, Val Loss: 5.57357
Epoch 64, Val Loss: 5.59648
Epoch 65, Val Loss: 5.57174
Epoch 66, Val Loss: 6.12739
Epoch 67, Val Loss: 5.48139
Epoch 68, Val Loss: 5.60498
Epoch 69, Val Loss: 5.49971
Epoch 70, Val Loss: 5.88851
Epoch 71, Val Loss: 6.29845
Epoch 72, Val Loss: 5.76516
Epoch 73, Val Loss: 5.60072
Epoch 74, Val Loss: 5.55530
Epoch 75, Val Loss: 5.49516
Epoch 76, Val Loss: 5.76828
Epoch 77, Val Loss: 5.71450
Epoch 78, Val Loss: 5.65492
Epoch 79, Val Loss: 5.50113
Epoch 80, Val Loss: 5.36414
Epoch 81, Val Loss: 5.42481
Epoch 82, Val Loss: 5.55146
Epoch 83, Val Loss: 5.77314
Epoch 84, Val Loss: 5.80195
Epoch 85, Val Loss: 5.39560
Epoch 86, Val Loss: 5.42631
Epoch 87, Val Loss: 5.47830
Epoch 88, Val Loss: 5.70477
Epoch 89, Val Loss: 5.42462
Epoch 90, Val Loss: 5.84689
Epoch 91, Val Loss: 5.40399
Epoch 92, Val Loss: 5.68443
Epoch 93, Val Loss: 5.41691
Epoch 94, Val Loss: 5.67381
Epoch 95, Val Loss: 5.65224
Epoch 96, Val Loss: 5.57748
Epoch 97, Val Loss: 5.32932
Epoch 98, Val Loss: 5.36094
Epoch 99, Val Loss: 5.42177
DID NOT SAVE RESULTS
{'MSE - mean': 5.137514500144764, 'MSE - std': 0.49802435164971437, 'R2 - mean': 0.4954791058880324, 'R2 - std': 0.028874024661346608} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.03941
Epoch 1, Val Loss: 10.42414
Epoch 2, Val Loss: 6.96566
Epoch 3, Val Loss: 5.84562
Epoch 4, Val Loss: 5.66837
Epoch 5, Val Loss: 5.70626
Epoch 6, Val Loss: 5.55682
Epoch 7, Val Loss: 5.36925
Epoch 8, Val Loss: 5.61954
Epoch 9, Val Loss: 5.54459
Epoch 10, Val Loss: 5.53225
Epoch 11, Val Loss: 5.35102
Epoch 12, Val Loss: 5.29320
Epoch 13, Val Loss: 5.59893
Epoch 14, Val Loss: 5.32581
Epoch 15, Val Loss: 5.25503
Epoch 16, Val Loss: 5.40680
Epoch 17, Val Loss: 5.58035
Epoch 18, Val Loss: 5.25253
Epoch 19, Val Loss: 5.27014
Epoch 20, Val Loss: 5.60320
Epoch 21, Val Loss: 5.16069
Epoch 22, Val Loss: 5.60119
Epoch 23, Val Loss: 5.42564
Epoch 24, Val Loss: 5.15115
Epoch 25, Val Loss: 5.24530
Epoch 26, Val Loss: 5.25140
Epoch 27, Val Loss: 5.20796
Epoch 28, Val Loss: 5.16791
Epoch 29, Val Loss: 5.16968
Epoch 30, Val Loss: 5.15636
Epoch 31, Val Loss: 5.10606
Epoch 32, Val Loss: 5.05492
Epoch 33, Val Loss: 5.02763
Epoch 34, Val Loss: 5.04430
Epoch 35, Val Loss: 5.01279
Epoch 36, Val Loss: 5.03347
Epoch 37, Val Loss: 5.04976
Epoch 38, Val Loss: 5.16059
Epoch 39, Val Loss: 4.96495
Epoch 40, Val Loss: 5.01768
Epoch 41, Val Loss: 5.13853
Epoch 42, Val Loss: 5.24658
Epoch 43, Val Loss: 5.05590
Epoch 44, Val Loss: 5.20197
Epoch 45, Val Loss: 4.88432
Epoch 46, Val Loss: 5.03809
Epoch 47, Val Loss: 4.92703
Epoch 48, Val Loss: 4.90464
Epoch 49, Val Loss: 5.01940
Epoch 50, Val Loss: 4.98507
Epoch 51, Val Loss: 4.84608
Epoch 52, Val Loss: 5.20597
Epoch 53, Val Loss: 4.79941
Epoch 54, Val Loss: 5.08527
Epoch 55, Val Loss: 4.85054
Epoch 56, Val Loss: 4.87872
Epoch 57, Val Loss: 4.74132
Epoch 58, Val Loss: 4.77252
Epoch 59, Val Loss: 5.01423
Epoch 60, Val Loss: 4.75054
Epoch 61, Val Loss: 4.65238
Epoch 62, Val Loss: 4.71950
Epoch 63, Val Loss: 4.67046
Epoch 64, Val Loss: 4.65476
Epoch 65, Val Loss: 4.67206
Epoch 66, Val Loss: 4.70241
Epoch 67, Val Loss: 4.77052
Epoch 68, Val Loss: 4.48772
Epoch 69, Val Loss: 5.03182
Epoch 70, Val Loss: 4.80689
Epoch 71, Val Loss: 4.46864
Epoch 72, Val Loss: 4.49162
Epoch 73, Val Loss: 4.55930
Epoch 74, Val Loss: 4.43447
Epoch 75, Val Loss: 4.89014
Epoch 76, Val Loss: 4.46444
Epoch 77, Val Loss: 4.50644
Epoch 78, Val Loss: 5.30131
Epoch 79, Val Loss: 4.57842
Epoch 80, Val Loss: 4.31460
Epoch 81, Val Loss: 4.44297
Epoch 82, Val Loss: 4.41264
Epoch 83, Val Loss: 4.55418
Epoch 84, Val Loss: 4.43801
Epoch 85, Val Loss: 4.76102
Epoch 86, Val Loss: 4.61283
Epoch 87, Val Loss: 4.51927
Epoch 88, Val Loss: 4.25819
Epoch 89, Val Loss: 4.46640
Epoch 90, Val Loss: 4.31645
Epoch 91, Val Loss: 4.26009
Epoch 92, Val Loss: 4.34328
Epoch 93, Val Loss: 4.68691
Epoch 94, Val Loss: 4.30136
Epoch 95, Val Loss: 4.65693
Epoch 96, Val Loss: 4.24566
Epoch 97, Val Loss: 4.23691
Epoch 98, Val Loss: 4.22326
Epoch 99, Val Loss: 4.26898
DID NOT SAVE RESULTS
{'MSE - mean': 5.000583310979362, 'MSE - std': 0.49221097389822854, 'R2 - mean': 0.4989236662067681, 'R2 - std': 0.02570752735049143} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.76237
Epoch 1, Val Loss: 12.34552
Epoch 2, Val Loss: 9.27992
Epoch 3, Val Loss: 8.32576
Epoch 4, Val Loss: 8.52335
Epoch 5, Val Loss: 7.87268
Epoch 6, Val Loss: 7.93894
Epoch 7, Val Loss: 8.27267
Epoch 8, Val Loss: 7.79874
Epoch 9, Val Loss: 7.75965
Epoch 10, Val Loss: 7.97262
Epoch 11, Val Loss: 7.75602
Epoch 12, Val Loss: 8.10463
Epoch 13, Val Loss: 7.48020
Epoch 14, Val Loss: 7.33610
Epoch 15, Val Loss: 7.65162
Epoch 16, Val Loss: 7.51179
Epoch 17, Val Loss: 7.33852
Epoch 18, Val Loss: 7.41643
Epoch 19, Val Loss: 7.43091
Epoch 20, Val Loss: 7.22671
Epoch 21, Val Loss: 7.51115
Epoch 22, Val Loss: 7.24018
Epoch 23, Val Loss: 7.54808
Epoch 24, Val Loss: 7.97422
Epoch 25, Val Loss: 7.03403
Epoch 26, Val Loss: 7.26685
Epoch 27, Val Loss: 7.09531
Epoch 28, Val Loss: 7.12219
Epoch 29, Val Loss: 7.20102
Epoch 30, Val Loss: 7.07386
Epoch 31, Val Loss: 6.90954
Epoch 32, Val Loss: 7.66975
Epoch 33, Val Loss: 7.16084
Epoch 34, Val Loss: 7.09678
Epoch 35, Val Loss: 7.13715
Epoch 36, Val Loss: 7.44645
Epoch 37, Val Loss: 7.33244
Epoch 38, Val Loss: 6.90924
Epoch 39, Val Loss: 7.16620
Epoch 40, Val Loss: 6.59389
Epoch 41, Val Loss: 6.66697
Epoch 42, Val Loss: 6.97905
Epoch 43, Val Loss: 6.67339
Epoch 44, Val Loss: 6.67468
Epoch 45, Val Loss: 6.71120
Epoch 46, Val Loss: 7.51459
Epoch 47, Val Loss: 6.81100
Epoch 48, Val Loss: 7.20413
Epoch 49, Val Loss: 6.66671
Epoch 50, Val Loss: 7.30150
Epoch 51, Val Loss: 6.70643
Epoch 52, Val Loss: 6.42867
Epoch 53, Val Loss: 6.61495
Epoch 54, Val Loss: 6.53854
Epoch 55, Val Loss: 6.62726
Epoch 56, Val Loss: 6.80042
Epoch 57, Val Loss: 7.14354
Epoch 58, Val Loss: 6.28863
Epoch 59, Val Loss: 6.86409
Epoch 60, Val Loss: 6.95856
Epoch 61, Val Loss: 6.51355
Epoch 62, Val Loss: 6.43263
Epoch 63, Val Loss: 6.34812
Epoch 64, Val Loss: 6.40656
Epoch 65, Val Loss: 6.35035
Epoch 66, Val Loss: 6.37825
Epoch 67, Val Loss: 6.25709
Epoch 68, Val Loss: 6.24973
Epoch 69, Val Loss: 6.35059
Epoch 70, Val Loss: 6.31477
Epoch 71, Val Loss: 6.34356
Epoch 72, Val Loss: 6.46843
Epoch 73, Val Loss: 6.66420
Epoch 74, Val Loss: 6.38742
Epoch 75, Val Loss: 6.33467
Epoch 76, Val Loss: 6.34810
Epoch 77, Val Loss: 6.12420
Epoch 78, Val Loss: 6.88838
Epoch 79, Val Loss: 6.54977
Epoch 80, Val Loss: 6.28487
Epoch 81, Val Loss: 6.42334
Epoch 82, Val Loss: 6.30326
Epoch 83, Val Loss: 6.16856
Epoch 84, Val Loss: 6.42777
Epoch 85, Val Loss: 6.26102
Epoch 86, Val Loss: 5.94505
Epoch 87, Val Loss: 6.31229
Epoch 88, Val Loss: 6.14163
Epoch 89, Val Loss: 6.36686
Epoch 90, Val Loss: 6.18559
Epoch 91, Val Loss: 6.36293
Epoch 92, Val Loss: 6.06743
Epoch 93, Val Loss: 6.17899
Epoch 94, Val Loss: 5.91332
Epoch 95, Val Loss: 6.30935
Epoch 96, Val Loss: 6.22153
Epoch 97, Val Loss: 6.13557
Epoch 98, Val Loss: 6.09809
Epoch 99, Val Loss: 6.28315
DID NOT SAVE RESULTS
{'MSE - mean': 5.175801367910346, 'MSE - std': 0.5626924418893071, 'R2 - mean': 0.5019391219932225, 'R2 - std': 0.023771273932653617} 
 

Results After CV: {'MSE - mean': 5.175801367910346, 'MSE - std': 0.5626924418893071, 'R2 - mean': 0.5019391219932225, 'R2 - std': 0.023771273932653617}
Train time: 28.025655879000077
Inference time: 0.04868235580006512
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 25 finished with value: 5.175801367910346 and parameters: {'p_m': 0.5837529386952998, 'alpha': 4.003408572697181, 'K': 2, 'beta': 2.949933886526654}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.24597
Epoch 1, Val Loss: 9.02169
Epoch 2, Val Loss: 7.62863
Epoch 3, Val Loss: 6.96970
Epoch 4, Val Loss: 6.74342
Epoch 5, Val Loss: 6.53365
Epoch 6, Val Loss: 6.47207
Epoch 7, Val Loss: 6.27425
Epoch 8, Val Loss: 6.25448
Epoch 9, Val Loss: 6.19445
Epoch 10, Val Loss: 6.44953
Epoch 11, Val Loss: 6.05493
Epoch 12, Val Loss: 6.19003
Epoch 13, Val Loss: 5.88281
Epoch 14, Val Loss: 5.95614
Epoch 15, Val Loss: 5.83119
Epoch 16, Val Loss: 5.78959
Epoch 17, Val Loss: 5.66142
Epoch 18, Val Loss: 6.42309
Epoch 19, Val Loss: 5.53806
Epoch 20, Val Loss: 6.18624
Epoch 21, Val Loss: 5.56372
Epoch 22, Val Loss: 5.47648
Epoch 23, Val Loss: 5.47558
Epoch 24, Val Loss: 5.50943
Epoch 25, Val Loss: 5.47355
Epoch 26, Val Loss: 5.41412
Epoch 27, Val Loss: 5.68895
Epoch 28, Val Loss: 5.24761
Epoch 29, Val Loss: 5.60974
Epoch 30, Val Loss: 5.48704
Epoch 31, Val Loss: 5.25116
Epoch 32, Val Loss: 5.25740
Epoch 33, Val Loss: 5.29845
Epoch 34, Val Loss: 5.78213
Epoch 35, Val Loss: 5.52316
Epoch 36, Val Loss: 5.29524
Epoch 37, Val Loss: 5.41481
Epoch 38, Val Loss: 5.31590
Epoch 39, Val Loss: 5.24994
Epoch 40, Val Loss: 5.25392
Epoch 41, Val Loss: 5.07472
Epoch 42, Val Loss: 5.04917
Epoch 43, Val Loss: 5.14550
Epoch 44, Val Loss: 5.18540
Epoch 45, Val Loss: 5.01527
Epoch 46, Val Loss: 5.48892
Epoch 47, Val Loss: 5.52358
Epoch 48, Val Loss: 5.20003
Epoch 49, Val Loss: 5.21549
Epoch 50, Val Loss: 5.65693
Epoch 51, Val Loss: 5.15770
Epoch 52, Val Loss: 5.22500
Epoch 53, Val Loss: 5.18901
Epoch 54, Val Loss: 4.92506
Epoch 55, Val Loss: 4.98498
Epoch 56, Val Loss: 5.27854
Epoch 57, Val Loss: 5.25025
Epoch 58, Val Loss: 5.09041
Epoch 59, Val Loss: 5.07025
Epoch 60, Val Loss: 5.33531
Epoch 61, Val Loss: 4.97440
Epoch 62, Val Loss: 4.88294
Epoch 63, Val Loss: 4.93027
Epoch 64, Val Loss: 5.21210
Epoch 65, Val Loss: 4.89679
Epoch 66, Val Loss: 4.85174
Epoch 67, Val Loss: 4.89435
Epoch 68, Val Loss: 5.20448
Epoch 69, Val Loss: 5.26932
Epoch 70, Val Loss: 5.08150
Epoch 71, Val Loss: 5.28739
Epoch 72, Val Loss: 5.02476
Epoch 73, Val Loss: 4.88295
Epoch 74, Val Loss: 4.87743
Epoch 75, Val Loss: 5.09736
Epoch 76, Val Loss: 5.04193
Epoch 77, Val Loss: 4.86694
Epoch 78, Val Loss: 4.96271
Epoch 79, Val Loss: 4.84159
Epoch 80, Val Loss: 4.84487
Epoch 81, Val Loss: 4.86367
Epoch 82, Val Loss: 4.87079
Epoch 83, Val Loss: 4.82645
Epoch 84, Val Loss: 5.07595
Epoch 85, Val Loss: 4.95865
Epoch 86, Val Loss: 4.84122
Epoch 87, Val Loss: 4.88891
Epoch 88, Val Loss: 4.80739
Epoch 89, Val Loss: 4.83293
Epoch 90, Val Loss: 4.91321
Epoch 91, Val Loss: 5.22841
Epoch 92, Val Loss: 4.72522
Epoch 93, Val Loss: 4.96105
Epoch 94, Val Loss: 4.83995
Epoch 95, Val Loss: 4.85315
Epoch 96, Val Loss: 4.78337
Epoch 97, Val Loss: 4.79992
Epoch 98, Val Loss: 5.00119
Epoch 99, Val Loss: 4.78715
DID NOT SAVE RESULTS
{'MSE - mean': 4.92781995383455, 'MSE - std': 0.0, 'R2 - mean': 0.5505991034180686, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.75650
Epoch 1, Val Loss: 10.50774
Epoch 2, Val Loss: 5.45931
Epoch 3, Val Loss: 5.69572
Epoch 4, Val Loss: 5.61643
Epoch 5, Val Loss: 5.38919
Epoch 6, Val Loss: 5.43791
Epoch 7, Val Loss: 5.41641
Epoch 8, Val Loss: 5.20117
Epoch 9, Val Loss: 5.57641
Epoch 10, Val Loss: 5.20985
Epoch 11, Val Loss: 5.26452
Epoch 12, Val Loss: 4.98534
Epoch 13, Val Loss: 5.09614
Epoch 14, Val Loss: 4.87968
Epoch 15, Val Loss: 5.14898
Epoch 16, Val Loss: 5.30814
Epoch 17, Val Loss: 4.81053
Epoch 18, Val Loss: 4.73637
Epoch 19, Val Loss: 4.81540
Epoch 20, Val Loss: 4.95260
Epoch 21, Val Loss: 4.67553
Epoch 22, Val Loss: 5.13789
Epoch 23, Val Loss: 4.72180
Epoch 24, Val Loss: 4.44980
Epoch 25, Val Loss: 4.59268
Epoch 26, Val Loss: 4.66076
Epoch 27, Val Loss: 4.41012
Epoch 28, Val Loss: 4.47571
Epoch 29, Val Loss: 4.48080
Epoch 30, Val Loss: 4.40438
Epoch 31, Val Loss: 4.43625
Epoch 32, Val Loss: 4.69288
Epoch 33, Val Loss: 4.46194
Epoch 34, Val Loss: 4.79683
Epoch 35, Val Loss: 4.38449
Epoch 36, Val Loss: 4.17243
Epoch 37, Val Loss: 4.11885
Epoch 38, Val Loss: 4.41607
Epoch 39, Val Loss: 4.22129
Epoch 40, Val Loss: 4.30026
Epoch 41, Val Loss: 4.11996
Epoch 42, Val Loss: 4.11793
Epoch 43, Val Loss: 4.94960
Epoch 44, Val Loss: 4.23439
Epoch 45, Val Loss: 4.31756
Epoch 46, Val Loss: 4.05813
Epoch 47, Val Loss: 4.15126
Epoch 48, Val Loss: 4.16731
Epoch 49, Val Loss: 4.09727
Epoch 50, Val Loss: 4.11533
Epoch 51, Val Loss: 4.20187
Epoch 52, Val Loss: 4.09051
Epoch 53, Val Loss: 4.10006
Epoch 54, Val Loss: 4.57059
Epoch 55, Val Loss: 4.18669
Epoch 56, Val Loss: 4.06471
Epoch 57, Val Loss: 4.22578
Epoch 58, Val Loss: 4.08845
Epoch 59, Val Loss: 4.12077
Epoch 60, Val Loss: 4.07025
Epoch 61, Val Loss: 4.20357
Epoch 62, Val Loss: 4.13751
Epoch 63, Val Loss: 4.03301
Epoch 64, Val Loss: 4.38719
Epoch 65, Val Loss: 4.18074
Epoch 66, Val Loss: 4.06853
Epoch 67, Val Loss: 4.54897
Epoch 68, Val Loss: 4.07452
Epoch 69, Val Loss: 4.01279
Epoch 70, Val Loss: 4.25428
Epoch 71, Val Loss: 4.14927
Epoch 72, Val Loss: 3.98843
Epoch 73, Val Loss: 4.77146
Epoch 74, Val Loss: 4.05600
Epoch 75, Val Loss: 4.07452
Epoch 76, Val Loss: 4.55613
Epoch 77, Val Loss: 4.07727
Epoch 78, Val Loss: 4.32820
Epoch 79, Val Loss: 3.98715
Epoch 80, Val Loss: 4.12047
Epoch 81, Val Loss: 4.25944
Epoch 82, Val Loss: 4.10736
Epoch 83, Val Loss: 4.04882
Epoch 84, Val Loss: 4.03164
Epoch 85, Val Loss: 4.10558
Epoch 86, Val Loss: 4.18877
Epoch 87, Val Loss: 4.12550
Epoch 88, Val Loss: 4.18466
Epoch 89, Val Loss: 4.23699
Epoch 90, Val Loss: 4.19332
Epoch 91, Val Loss: 4.51534
Epoch 92, Val Loss: 4.17566
Epoch 93, Val Loss: 4.30474
Epoch 94, Val Loss: 3.98901
Epoch 95, Val Loss: 3.94726
Epoch 96, Val Loss: 4.70358
Epoch 97, Val Loss: 3.94442
Epoch 98, Val Loss: 4.21267
Epoch 99, Val Loss: 4.08592
DID NOT SAVE RESULTS
{'MSE - mean': 4.527954023400863, 'MSE - std': 0.39986593043368757, 'R2 - mean': 0.5552795488521273, 'R2 - std': 0.004680445434058655} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.12774
Epoch 1, Val Loss: 12.02726
Epoch 2, Val Loss: 6.73580
Epoch 3, Val Loss: 6.63754
Epoch 4, Val Loss: 6.70542
Epoch 5, Val Loss: 6.23837
Epoch 6, Val Loss: 6.24309
Epoch 7, Val Loss: 6.21600
Epoch 8, Val Loss: 6.00481
Epoch 9, Val Loss: 5.97764
Epoch 10, Val Loss: 5.94681
Epoch 11, Val Loss: 5.83549
Epoch 12, Val Loss: 5.96751
Epoch 13, Val Loss: 5.76869
Epoch 14, Val Loss: 5.97029
Epoch 15, Val Loss: 5.73272
Epoch 16, Val Loss: 5.61927
Epoch 17, Val Loss: 5.57878
Epoch 18, Val Loss: 5.49953
Epoch 19, Val Loss: 5.54719
Epoch 20, Val Loss: 5.41001
Epoch 21, Val Loss: 5.44046
Epoch 22, Val Loss: 5.32839
Epoch 23, Val Loss: 5.52853
Epoch 24, Val Loss: 5.57185
Epoch 25, Val Loss: 5.34752
Epoch 26, Val Loss: 5.24206
Epoch 27, Val Loss: 6.13521
Epoch 28, Val Loss: 5.71183
Epoch 29, Val Loss: 5.34885
Epoch 30, Val Loss: 5.68564
Epoch 31, Val Loss: 5.29089
Epoch 32, Val Loss: 5.31160
Epoch 33, Val Loss: 5.20021
Epoch 34, Val Loss: 5.33770
Epoch 35, Val Loss: 5.14437
Epoch 36, Val Loss: 5.37275
Epoch 37, Val Loss: 5.56642
Epoch 38, Val Loss: 5.27914
Epoch 39, Val Loss: 5.46254
Epoch 40, Val Loss: 5.08840
Epoch 41, Val Loss: 5.38374
Epoch 42, Val Loss: 5.08145
Epoch 43, Val Loss: 5.17531
Epoch 44, Val Loss: 5.20217
Epoch 45, Val Loss: 5.21937
Epoch 46, Val Loss: 5.04537
Epoch 47, Val Loss: 5.04509
Epoch 48, Val Loss: 5.19372
Epoch 49, Val Loss: 5.49081
Epoch 50, Val Loss: 5.16907
Epoch 51, Val Loss: 5.11780
Epoch 52, Val Loss: 5.39716
Epoch 53, Val Loss: 5.02648
Epoch 54, Val Loss: 5.17041
Epoch 55, Val Loss: 5.06167
Epoch 56, Val Loss: 5.29107
Epoch 57, Val Loss: 4.97413
Epoch 58, Val Loss: 5.19547
Epoch 59, Val Loss: 5.02685
Epoch 60, Val Loss: 5.13540
Epoch 61, Val Loss: 5.30279
Epoch 62, Val Loss: 5.07518
Epoch 63, Val Loss: 5.04201
Epoch 64, Val Loss: 5.15851
Epoch 65, Val Loss: 5.04672
Epoch 66, Val Loss: 5.01463
Epoch 67, Val Loss: 5.01434
Epoch 68, Val Loss: 5.36529
Epoch 69, Val Loss: 5.34458
Epoch 70, Val Loss: 5.00675
Epoch 71, Val Loss: 4.91734
Epoch 72, Val Loss: 4.94007
Epoch 73, Val Loss: 5.01583
Epoch 74, Val Loss: 4.93827
Epoch 75, Val Loss: 5.10089
Epoch 76, Val Loss: 5.12222
Epoch 77, Val Loss: 5.27542
Epoch 78, Val Loss: 4.99631
Epoch 79, Val Loss: 5.15525
Epoch 80, Val Loss: 5.01501
Epoch 81, Val Loss: 5.31247
Epoch 82, Val Loss: 4.95287
Epoch 83, Val Loss: 4.90189
Epoch 84, Val Loss: 5.11657
Epoch 85, Val Loss: 4.89890
Epoch 86, Val Loss: 5.14238
Epoch 87, Val Loss: 5.08899
Epoch 88, Val Loss: 4.96108
Epoch 89, Val Loss: 5.48950
Epoch 90, Val Loss: 4.90279
Epoch 91, Val Loss: 5.28301
Epoch 92, Val Loss: 4.88607
Epoch 93, Val Loss: 5.05819
Epoch 94, Val Loss: 5.14389
Epoch 95, Val Loss: 4.91340
Epoch 96, Val Loss: 4.82682
Epoch 97, Val Loss: 4.93990
Epoch 98, Val Loss: 5.21950
Epoch 99, Val Loss: 4.84223
DID NOT SAVE RESULTS
{'MSE - mean': 4.644945342072394, 'MSE - std': 0.36601791236232356, 'R2 - mean': 0.543492986309376, 'R2 - std': 0.017101183958696344} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.06137
Epoch 1, Val Loss: 8.77200
Epoch 2, Val Loss: 5.86944
Epoch 3, Val Loss: 5.50099
Epoch 4, Val Loss: 5.26340
Epoch 5, Val Loss: 5.45590
Epoch 6, Val Loss: 5.51963
Epoch 7, Val Loss: 5.23450
Epoch 8, Val Loss: 5.18182
Epoch 9, Val Loss: 5.02637
Epoch 10, Val Loss: 5.24257
Epoch 11, Val Loss: 4.93958
Epoch 12, Val Loss: 5.04163
Epoch 13, Val Loss: 4.94864
Epoch 14, Val Loss: 5.03664
Epoch 15, Val Loss: 4.83331
Epoch 16, Val Loss: 4.74144
Epoch 17, Val Loss: 4.67779
Epoch 18, Val Loss: 4.80304
Epoch 19, Val Loss: 4.61335
Epoch 20, Val Loss: 4.64893
Epoch 21, Val Loss: 4.79946
Epoch 22, Val Loss: 4.64204
Epoch 23, Val Loss: 4.55666
Epoch 24, Val Loss: 4.56992
Epoch 25, Val Loss: 4.37185
Epoch 26, Val Loss: 4.47094
Epoch 27, Val Loss: 4.41767
Epoch 28, Val Loss: 4.60514
Epoch 29, Val Loss: 4.59847
Epoch 30, Val Loss: 4.45944
Epoch 31, Val Loss: 4.90876
Epoch 32, Val Loss: 4.61487
Epoch 33, Val Loss: 4.24532
Epoch 34, Val Loss: 4.30787
Epoch 35, Val Loss: 4.25629
Epoch 36, Val Loss: 4.28436
Epoch 37, Val Loss: 4.44408
Epoch 38, Val Loss: 4.20869
Epoch 39, Val Loss: 4.20319
Epoch 40, Val Loss: 4.16792
Epoch 41, Val Loss: 4.51182
Epoch 42, Val Loss: 4.45464
Epoch 43, Val Loss: 4.34640
Epoch 44, Val Loss: 4.10538
Epoch 45, Val Loss: 4.14230
Epoch 46, Val Loss: 4.06500
Epoch 47, Val Loss: 4.63549
Epoch 48, Val Loss: 4.21173
Epoch 49, Val Loss: 4.16486
Epoch 50, Val Loss: 4.07258
Epoch 51, Val Loss: 4.11441
Epoch 52, Val Loss: 4.10888
Epoch 53, Val Loss: 3.98732
Epoch 54, Val Loss: 4.16489
Epoch 55, Val Loss: 3.95338
Epoch 56, Val Loss: 4.18474
Epoch 57, Val Loss: 4.16723
Epoch 58, Val Loss: 4.04480
Epoch 59, Val Loss: 4.05088
Epoch 60, Val Loss: 4.18895
Epoch 61, Val Loss: 4.22510
Epoch 62, Val Loss: 4.02555
Epoch 63, Val Loss: 4.11379
Epoch 64, Val Loss: 4.02990
Epoch 65, Val Loss: 4.03095
Epoch 66, Val Loss: 3.93276
Epoch 67, Val Loss: 3.96172
Epoch 68, Val Loss: 3.90701
Epoch 69, Val Loss: 4.06984
Epoch 70, Val Loss: 3.97636
Epoch 71, Val Loss: 3.88828
Epoch 72, Val Loss: 3.96526
Epoch 73, Val Loss: 3.80494
Epoch 74, Val Loss: 3.87341
Epoch 75, Val Loss: 3.93096
Epoch 76, Val Loss: 4.16506
Epoch 77, Val Loss: 4.05978
Epoch 78, Val Loss: 3.94740
Epoch 79, Val Loss: 3.95236
Epoch 80, Val Loss: 3.92579
Epoch 81, Val Loss: 4.18019
Epoch 82, Val Loss: 3.91115
Epoch 83, Val Loss: 4.04531
Epoch 84, Val Loss: 4.59636
Epoch 85, Val Loss: 4.04246
Epoch 86, Val Loss: 4.02699
Epoch 87, Val Loss: 4.06797
Epoch 88, Val Loss: 4.08084
Epoch 89, Val Loss: 3.78881
Epoch 90, Val Loss: 4.14260
Epoch 91, Val Loss: 3.84870
Epoch 92, Val Loss: 4.00768
Epoch 93, Val Loss: 3.89179
Epoch 94, Val Loss: 4.02801
Epoch 95, Val Loss: 3.81645
Epoch 96, Val Loss: 3.83721
Epoch 97, Val Loss: 4.10146
Epoch 98, Val Loss: 3.96996
Epoch 99, Val Loss: 3.87748
DID NOT SAVE RESULTS
{'MSE - mean': 4.516973764419903, 'MSE - std': 0.3867906516297393, 'R2 - mean': 0.547142546505929, 'R2 - std': 0.016102662465464265} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.72874
Epoch 1, Val Loss: 17.02417
Epoch 2, Val Loss: 8.16891
Epoch 3, Val Loss: 8.16341
Epoch 4, Val Loss: 7.64908
Epoch 5, Val Loss: 7.55061
Epoch 6, Val Loss: 7.38502
Epoch 7, Val Loss: 7.37015
Epoch 8, Val Loss: 7.41167
Epoch 9, Val Loss: 7.22878
Epoch 10, Val Loss: 7.18603
Epoch 11, Val Loss: 7.49577
Epoch 12, Val Loss: 7.08589
Epoch 13, Val Loss: 7.16380
Epoch 14, Val Loss: 7.14845
Epoch 15, Val Loss: 7.16725
Epoch 16, Val Loss: 6.85115
Epoch 17, Val Loss: 7.04316
Epoch 18, Val Loss: 6.89856
Epoch 19, Val Loss: 6.70926
Epoch 20, Val Loss: 6.73131
Epoch 21, Val Loss: 7.08539
Epoch 22, Val Loss: 6.62896
Epoch 23, Val Loss: 6.92168
Epoch 24, Val Loss: 6.70968
Epoch 25, Val Loss: 6.50277
Epoch 26, Val Loss: 6.52020
Epoch 27, Val Loss: 6.80874
Epoch 28, Val Loss: 6.30220
Epoch 29, Val Loss: 6.45813
Epoch 30, Val Loss: 6.64048
Epoch 31, Val Loss: 6.45218
Epoch 32, Val Loss: 6.28856
Epoch 33, Val Loss: 6.41784
Epoch 34, Val Loss: 6.21389
Epoch 35, Val Loss: 6.36849
Epoch 36, Val Loss: 6.24699
Epoch 37, Val Loss: 6.27800
Epoch 38, Val Loss: 6.84142
Epoch 39, Val Loss: 6.13228
Epoch 40, Val Loss: 5.98383
Epoch 41, Val Loss: 6.11653
Epoch 42, Val Loss: 6.02697
Epoch 43, Val Loss: 6.01918
Epoch 44, Val Loss: 6.57120
Epoch 45, Val Loss: 6.39654
Epoch 46, Val Loss: 5.83647
Epoch 47, Val Loss: 5.88767
Epoch 48, Val Loss: 6.31177
Epoch 49, Val Loss: 6.71058
Epoch 50, Val Loss: 5.84186
Epoch 51, Val Loss: 6.47288
Epoch 52, Val Loss: 6.08166
Epoch 53, Val Loss: 6.17926
Epoch 54, Val Loss: 5.94895
Epoch 55, Val Loss: 5.82822
Epoch 56, Val Loss: 5.80195
Epoch 57, Val Loss: 5.70992
Epoch 58, Val Loss: 5.85486
Epoch 59, Val Loss: 5.81682
Epoch 60, Val Loss: 5.75624
Epoch 61, Val Loss: 5.87047
Epoch 62, Val Loss: 6.08303
Epoch 63, Val Loss: 6.17454
Epoch 64, Val Loss: 5.51587
Epoch 65, Val Loss: 5.71492
Epoch 66, Val Loss: 6.16210
Epoch 67, Val Loss: 5.79770
Epoch 68, Val Loss: 5.74793
Epoch 69, Val Loss: 5.90147
Epoch 70, Val Loss: 6.04767
Epoch 71, Val Loss: 5.69064
Epoch 72, Val Loss: 5.87239
Epoch 73, Val Loss: 5.64025
Epoch 74, Val Loss: 5.60985
Epoch 75, Val Loss: 5.58832
Epoch 76, Val Loss: 5.80834
Epoch 77, Val Loss: 5.66198
Epoch 78, Val Loss: 5.52321
Epoch 79, Val Loss: 5.82399
Epoch 80, Val Loss: 5.55570
Epoch 81, Val Loss: 5.94811
Epoch 82, Val Loss: 5.81254
Epoch 83, Val Loss: 5.99433
Epoch 84, Val Loss: 6.20527
Epoch 85, Val Loss: 5.49056
Epoch 86, Val Loss: 5.80973
Epoch 87, Val Loss: 5.72692
Epoch 88, Val Loss: 5.70973
Epoch 89, Val Loss: 5.55500
Epoch 90, Val Loss: 5.55619
Epoch 91, Val Loss: 5.72365
Epoch 92, Val Loss: 5.77863
Epoch 93, Val Loss: 5.55494
Epoch 94, Val Loss: 5.65550
Epoch 95, Val Loss: 5.62965
Epoch 96, Val Loss: 5.43253
Epoch 97, Val Loss: 5.92862
Epoch 98, Val Loss: 6.56448
Epoch 99, Val Loss: 5.82071
DID NOT SAVE RESULTS
{'MSE - mean': 4.702653405740002, 'MSE - std': 0.5075365241571977, 'R2 - mean': 0.5476479279265865, 'R2 - std': 0.014438082708681242} 
 

Results After CV: {'MSE - mean': 4.702653405740002, 'MSE - std': 0.5075365241571977, 'R2 - mean': 0.5476479279265865, 'R2 - std': 0.014438082708681242}
Train time: 33.34773543319998
Inference time: 0.05160154400000465
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 26 finished with value: 4.702653405740002 and parameters: {'p_m': 0.7423102053060935, 'alpha': 6.699006588784169, 'K': 3, 'beta': 1.355493842268489}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 48.51852
Epoch 1, Val Loss: 17.51158
Epoch 2, Val Loss: 7.63413
Epoch 3, Val Loss: 6.85806
Epoch 4, Val Loss: 6.72402
Epoch 5, Val Loss: 6.36204
Epoch 6, Val Loss: 6.13349
Epoch 7, Val Loss: 6.16178
Epoch 8, Val Loss: 5.94536
Epoch 9, Val Loss: 5.79500
Epoch 10, Val Loss: 5.99611
Epoch 11, Val Loss: 5.59118
Epoch 12, Val Loss: 5.78434
Epoch 13, Val Loss: 5.50370
Epoch 14, Val Loss: 5.77117
Epoch 15, Val Loss: 5.55868
Epoch 16, Val Loss: 5.75806
Epoch 17, Val Loss: 5.54935
Epoch 18, Val Loss: 5.48902
Epoch 19, Val Loss: 5.43793
Epoch 20, Val Loss: 5.34253
Epoch 21, Val Loss: 5.19783
Epoch 22, Val Loss: 5.24457
Epoch 23, Val Loss: 5.44210
Epoch 24, Val Loss: 5.64639
Epoch 25, Val Loss: 5.24901
Epoch 26, Val Loss: 5.11458
Epoch 27, Val Loss: 5.09382
Epoch 28, Val Loss: 5.35296
Epoch 29, Val Loss: 5.45922
Epoch 30, Val Loss: 5.09727
Epoch 31, Val Loss: 5.09079
Epoch 32, Val Loss: 5.15979
Epoch 33, Val Loss: 5.24109
Epoch 34, Val Loss: 4.92441
Epoch 35, Val Loss: 4.95943
Epoch 36, Val Loss: 5.44213
Epoch 37, Val Loss: 5.16129
Epoch 38, Val Loss: 4.98956
Epoch 39, Val Loss: 4.98260
Epoch 40, Val Loss: 4.86352
Epoch 41, Val Loss: 5.15505
Epoch 42, Val Loss: 4.95891
Epoch 43, Val Loss: 5.00798
Epoch 44, Val Loss: 4.89241
Epoch 45, Val Loss: 4.77227
Epoch 46, Val Loss: 4.97623
Epoch 47, Val Loss: 4.84851
Epoch 48, Val Loss: 5.11099
Epoch 49, Val Loss: 5.35178
Epoch 50, Val Loss: 4.71317
Epoch 51, Val Loss: 4.74471
Epoch 52, Val Loss: 4.67161
Epoch 53, Val Loss: 4.84330
Epoch 54, Val Loss: 4.67325
Epoch 55, Val Loss: 4.72453
Epoch 56, Val Loss: 4.72981
Epoch 57, Val Loss: 5.19330
Epoch 58, Val Loss: 4.91948
Epoch 59, Val Loss: 4.81954
Epoch 60, Val Loss: 4.92816
Epoch 61, Val Loss: 4.71803
Epoch 62, Val Loss: 4.75330
Epoch 63, Val Loss: 4.68735
Epoch 64, Val Loss: 4.65919
Epoch 65, Val Loss: 4.68367
Epoch 66, Val Loss: 4.69274
Epoch 67, Val Loss: 4.99677
Epoch 68, Val Loss: 4.79785
Epoch 69, Val Loss: 4.75091
Epoch 70, Val Loss: 4.86457
Epoch 71, Val Loss: 4.82161
Epoch 72, Val Loss: 4.83765
Epoch 73, Val Loss: 4.59818
Epoch 74, Val Loss: 4.69890
Epoch 75, Val Loss: 5.91423
Epoch 76, Val Loss: 4.86513
Epoch 77, Val Loss: 5.10925
Epoch 78, Val Loss: 4.68869
Epoch 79, Val Loss: 4.79359
Epoch 80, Val Loss: 4.84991
Epoch 81, Val Loss: 5.22684
Epoch 82, Val Loss: 4.77202
Epoch 83, Val Loss: 4.80661
Epoch 84, Val Loss: 4.79750
Epoch 85, Val Loss: 4.75007
Epoch 86, Val Loss: 4.75346
Epoch 87, Val Loss: 4.93356
Epoch 88, Val Loss: 4.62546
Epoch 89, Val Loss: 5.10743
Epoch 90, Val Loss: 4.76661
Epoch 91, Val Loss: 4.98811
Epoch 92, Val Loss: 4.77202
Epoch 93, Val Loss: 5.22952
Epoch 94, Val Loss: 4.69879
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.826421229841994, 'MSE - std': 0.0, 'R2 - mean': 0.5598463319900174, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.73994
Epoch 1, Val Loss: 12.08669
Epoch 2, Val Loss: 6.19474
Epoch 3, Val Loss: 5.56845
Epoch 4, Val Loss: 5.47628
Epoch 5, Val Loss: 5.23581
Epoch 6, Val Loss: 5.26502
Epoch 7, Val Loss: 5.11990
Epoch 8, Val Loss: 5.15587
Epoch 9, Val Loss: 5.08977
Epoch 10, Val Loss: 5.25654
Epoch 11, Val Loss: 4.99881
Epoch 12, Val Loss: 5.02373
Epoch 13, Val Loss: 4.88031
Epoch 14, Val Loss: 4.94208
Epoch 15, Val Loss: 4.89878
Epoch 16, Val Loss: 4.74963
Epoch 17, Val Loss: 4.83011
Epoch 18, Val Loss: 4.66101
Epoch 19, Val Loss: 5.10273
Epoch 20, Val Loss: 4.99755
Epoch 21, Val Loss: 4.59293
Epoch 22, Val Loss: 4.53812
Epoch 23, Val Loss: 5.05394
Epoch 24, Val Loss: 4.72026
Epoch 25, Val Loss: 4.60553
Epoch 26, Val Loss: 4.40373
Epoch 27, Val Loss: 4.80258
Epoch 28, Val Loss: 4.91556
Epoch 29, Val Loss: 4.39227
Epoch 30, Val Loss: 4.28534
Epoch 31, Val Loss: 4.28786
Epoch 32, Val Loss: 4.29268
Epoch 33, Val Loss: 4.17734
Epoch 34, Val Loss: 4.20647
Epoch 35, Val Loss: 4.43012
Epoch 36, Val Loss: 4.58756
Epoch 37, Val Loss: 4.25362
Epoch 38, Val Loss: 4.20726
Epoch 39, Val Loss: 4.40134
Epoch 40, Val Loss: 4.25509
Epoch 41, Val Loss: 3.99321
Epoch 42, Val Loss: 4.16734
Epoch 43, Val Loss: 4.08254
Epoch 44, Val Loss: 4.17459
Epoch 45, Val Loss: 4.01493
Epoch 46, Val Loss: 4.07316
Epoch 47, Val Loss: 4.28293
Epoch 48, Val Loss: 4.03918
Epoch 49, Val Loss: 3.99645
Epoch 50, Val Loss: 4.20149
Epoch 51, Val Loss: 4.01326
Epoch 52, Val Loss: 4.26359
Epoch 53, Val Loss: 4.32220
Epoch 54, Val Loss: 4.06280
Epoch 55, Val Loss: 4.22577
Epoch 56, Val Loss: 4.21248
Epoch 57, Val Loss: 4.08118
Epoch 58, Val Loss: 3.98323
Epoch 59, Val Loss: 4.11117
Epoch 60, Val Loss: 4.10769
Epoch 61, Val Loss: 4.08969
Epoch 62, Val Loss: 4.54573
Epoch 63, Val Loss: 4.21532
Epoch 64, Val Loss: 4.35353
Epoch 65, Val Loss: 4.16219
Epoch 66, Val Loss: 4.12418
Epoch 67, Val Loss: 4.55587
Epoch 68, Val Loss: 4.01174
Epoch 69, Val Loss: 4.08462
Epoch 70, Val Loss: 4.02339
Epoch 71, Val Loss: 4.33740
Epoch 72, Val Loss: 3.98225
Epoch 73, Val Loss: 4.01475
Epoch 74, Val Loss: 4.00299
Epoch 75, Val Loss: 4.05193
Epoch 76, Val Loss: 4.09608
Epoch 77, Val Loss: 3.95675
Epoch 78, Val Loss: 4.20766
Epoch 79, Val Loss: 3.96975
Epoch 80, Val Loss: 4.34971
Epoch 81, Val Loss: 4.16194
Epoch 82, Val Loss: 4.15227
Epoch 83, Val Loss: 4.22055
Epoch 84, Val Loss: 4.98061
Epoch 85, Val Loss: 3.98506
Epoch 86, Val Loss: 3.99338
Epoch 87, Val Loss: 4.05931
Epoch 88, Val Loss: 4.01705
Epoch 89, Val Loss: 4.03538
Epoch 90, Val Loss: 4.48456
Epoch 91, Val Loss: 4.08529
Epoch 92, Val Loss: 4.00343
Epoch 93, Val Loss: 3.99277
Epoch 94, Val Loss: 4.39818
Epoch 95, Val Loss: 4.11586
Epoch 96, Val Loss: 4.41115
Epoch 97, Val Loss: 4.00515
Epoch 98, Val Loss: 4.01398
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.489468853372875, 'MSE - std': 0.3369523764691187, 'R2 - mean': 0.5586011722448665, 'R2 - std': 0.0012451597451509921} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.82138
Epoch 1, Val Loss: 12.29186
Epoch 2, Val Loss: 6.27184
Epoch 3, Val Loss: 6.36036
Epoch 4, Val Loss: 6.13790
Epoch 5, Val Loss: 5.99487
Epoch 6, Val Loss: 5.94655
Epoch 7, Val Loss: 5.94609
Epoch 8, Val Loss: 5.83641
Epoch 9, Val Loss: 5.79030
Epoch 10, Val Loss: 5.67273
Epoch 11, Val Loss: 6.02284
Epoch 12, Val Loss: 5.60271
Epoch 13, Val Loss: 5.69784
Epoch 14, Val Loss: 5.55806
Epoch 15, Val Loss: 5.66642
Epoch 16, Val Loss: 5.60269
Epoch 17, Val Loss: 5.43776
Epoch 18, Val Loss: 5.33787
Epoch 19, Val Loss: 5.23959
Epoch 20, Val Loss: 5.21995
Epoch 21, Val Loss: 5.26025
Epoch 22, Val Loss: 5.17433
Epoch 23, Val Loss: 5.12114
Epoch 24, Val Loss: 5.16438
Epoch 25, Val Loss: 5.25497
Epoch 26, Val Loss: 5.14749
Epoch 27, Val Loss: 5.07793
Epoch 28, Val Loss: 4.93267
Epoch 29, Val Loss: 5.23133
Epoch 30, Val Loss: 5.05544
Epoch 31, Val Loss: 5.01858
Epoch 32, Val Loss: 5.23582
Epoch 33, Val Loss: 5.00726
Epoch 34, Val Loss: 5.17309
Epoch 35, Val Loss: 4.92704
Epoch 36, Val Loss: 4.83378
Epoch 37, Val Loss: 4.88970
Epoch 38, Val Loss: 5.08041
Epoch 39, Val Loss: 4.86169
Epoch 40, Val Loss: 4.83011
Epoch 41, Val Loss: 4.91977
Epoch 42, Val Loss: 4.80728
Epoch 43, Val Loss: 4.96672
Epoch 44, Val Loss: 4.78888
Epoch 45, Val Loss: 4.79175
Epoch 46, Val Loss: 4.74473
Epoch 47, Val Loss: 4.82898
Epoch 48, Val Loss: 5.05963
Epoch 49, Val Loss: 4.90449
Epoch 50, Val Loss: 4.80122
Epoch 51, Val Loss: 4.76801
Epoch 52, Val Loss: 4.77371
Epoch 53, Val Loss: 5.00346
Epoch 54, Val Loss: 4.91691
Epoch 55, Val Loss: 4.86869
Epoch 56, Val Loss: 5.12668
Epoch 57, Val Loss: 4.78647
Epoch 58, Val Loss: 4.78759
Epoch 59, Val Loss: 4.73247
Epoch 60, Val Loss: 4.71776
Epoch 61, Val Loss: 5.04559
Epoch 62, Val Loss: 4.62722
Epoch 63, Val Loss: 5.24146
Epoch 64, Val Loss: 4.69751
Epoch 65, Val Loss: 4.77006
Epoch 66, Val Loss: 4.77601
Epoch 67, Val Loss: 4.76090
Epoch 68, Val Loss: 4.61423
Epoch 69, Val Loss: 4.85859
Epoch 70, Val Loss: 4.99696
Epoch 71, Val Loss: 4.98665
Epoch 72, Val Loss: 4.80240
Epoch 73, Val Loss: 4.73402
Epoch 74, Val Loss: 4.83191
Epoch 75, Val Loss: 4.74952
Epoch 76, Val Loss: 4.80834
Epoch 77, Val Loss: 4.68916
Epoch 78, Val Loss: 4.77878
Epoch 79, Val Loss: 4.67810
Epoch 80, Val Loss: 5.07876
Epoch 81, Val Loss: 4.88693
Epoch 82, Val Loss: 4.64187
Epoch 83, Val Loss: 4.70177
Epoch 84, Val Loss: 4.97172
Epoch 85, Val Loss: 5.00636
Epoch 86, Val Loss: 4.57856
Epoch 87, Val Loss: 4.75059
Epoch 88, Val Loss: 4.64342
Epoch 89, Val Loss: 4.82039
Epoch 90, Val Loss: 4.76857
Epoch 91, Val Loss: 5.11403
Epoch 92, Val Loss: 4.63953
Epoch 93, Val Loss: 4.70804
Epoch 94, Val Loss: 4.56708
Epoch 95, Val Loss: 4.92088
Epoch 96, Val Loss: 4.67466
Epoch 97, Val Loss: 4.77139
Epoch 98, Val Loss: 4.66735
Epoch 99, Val Loss: 4.68773
DID NOT SAVE RESULTS
{'MSE - mean': 4.5359375703453395, 'MSE - std': 0.2828603058983799, 'R2 - mean': 0.5539090305892224, 'R2 - std': 0.006713121615703463} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.64719
Epoch 1, Val Loss: 15.79628
Epoch 2, Val Loss: 5.66552
Epoch 3, Val Loss: 5.39653
Epoch 4, Val Loss: 5.34173
Epoch 5, Val Loss: 5.29403
Epoch 6, Val Loss: 4.97393
Epoch 7, Val Loss: 5.05044
Epoch 8, Val Loss: 4.88794
Epoch 9, Val Loss: 4.85996
Epoch 10, Val Loss: 5.32581
Epoch 11, Val Loss: 4.75054
Epoch 12, Val Loss: 4.67378
Epoch 13, Val Loss: 4.67972
Epoch 14, Val Loss: 4.43421
Epoch 15, Val Loss: 4.40059
Epoch 16, Val Loss: 4.40069
Epoch 17, Val Loss: 4.44380
Epoch 18, Val Loss: 4.65851
Epoch 19, Val Loss: 4.37753
Epoch 20, Val Loss: 4.40966
Epoch 21, Val Loss: 4.25318
Epoch 22, Val Loss: 4.19556
Epoch 23, Val Loss: 4.24605
Epoch 24, Val Loss: 4.32072
Epoch 25, Val Loss: 4.77687
Epoch 26, Val Loss: 4.64633
Epoch 27, Val Loss: 4.23921
Epoch 28, Val Loss: 4.08871
Epoch 29, Val Loss: 4.25491
Epoch 30, Val Loss: 4.30912
Epoch 31, Val Loss: 4.07731
Epoch 32, Val Loss: 4.06155
Epoch 33, Val Loss: 4.01901
Epoch 34, Val Loss: 4.14611
Epoch 35, Val Loss: 3.96677
Epoch 36, Val Loss: 4.07672
Epoch 37, Val Loss: 4.17566
Epoch 38, Val Loss: 4.12125
Epoch 39, Val Loss: 3.98817
Epoch 40, Val Loss: 4.24651
Epoch 41, Val Loss: 4.01239
Epoch 42, Val Loss: 3.92791
Epoch 43, Val Loss: 3.99914
Epoch 44, Val Loss: 4.04854
Epoch 45, Val Loss: 4.07006
Epoch 46, Val Loss: 4.62943
Epoch 47, Val Loss: 3.91390
Epoch 48, Val Loss: 4.29088
Epoch 49, Val Loss: 4.01355
Epoch 50, Val Loss: 4.01777
Epoch 51, Val Loss: 4.00478
Epoch 52, Val Loss: 4.15920
Epoch 53, Val Loss: 3.99032
Epoch 54, Val Loss: 4.09012
Epoch 55, Val Loss: 4.02897
Epoch 56, Val Loss: 3.96128
Epoch 57, Val Loss: 4.12004
Epoch 58, Val Loss: 4.00755
Epoch 59, Val Loss: 3.87078
Epoch 60, Val Loss: 3.97281
Epoch 61, Val Loss: 3.88723
Epoch 62, Val Loss: 3.99343
Epoch 63, Val Loss: 4.01504
Epoch 64, Val Loss: 3.89538
Epoch 65, Val Loss: 4.22846
Epoch 66, Val Loss: 4.07668
Epoch 67, Val Loss: 4.03556
Epoch 68, Val Loss: 4.05080
Epoch 69, Val Loss: 4.15072
Epoch 70, Val Loss: 3.99832
Epoch 71, Val Loss: 3.97015
Epoch 72, Val Loss: 3.91116
Epoch 73, Val Loss: 4.04780
Epoch 74, Val Loss: 3.97723
Epoch 75, Val Loss: 4.04470
Epoch 76, Val Loss: 4.11547
Epoch 77, Val Loss: 4.12836
Epoch 78, Val Loss: 4.00273
Epoch 79, Val Loss: 3.92486
Epoch 80, Val Loss: 4.15777
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.4390500362176075, 'MSE - std': 0.29693273194067193, 'R2 - mean': 0.5545448495721583, 'R2 - std': 0.005917119122309806} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 40.16867
Epoch 1, Val Loss: 18.16172
Epoch 2, Val Loss: 8.90943
Epoch 3, Val Loss: 7.28827
Epoch 4, Val Loss: 7.07706
Epoch 5, Val Loss: 6.94595
Epoch 6, Val Loss: 7.49904
Epoch 7, Val Loss: 6.99860
Epoch 8, Val Loss: 6.97112
Epoch 9, Val Loss: 6.83494
Epoch 10, Val Loss: 7.15433
Epoch 11, Val Loss: 6.72334
Epoch 12, Val Loss: 6.86229
Epoch 13, Val Loss: 6.68536
Epoch 14, Val Loss: 7.10303
Epoch 15, Val Loss: 6.56570
Epoch 16, Val Loss: 6.46742
Epoch 17, Val Loss: 6.59427
Epoch 18, Val Loss: 6.57557
Epoch 19, Val Loss: 6.54697
Epoch 20, Val Loss: 6.44427
Epoch 21, Val Loss: 6.29608
Epoch 22, Val Loss: 6.57696
Epoch 23, Val Loss: 6.55222
Epoch 24, Val Loss: 6.48617
Epoch 25, Val Loss: 6.18735
Epoch 26, Val Loss: 6.12883
Epoch 27, Val Loss: 6.34330
Epoch 28, Val Loss: 6.32954
Epoch 29, Val Loss: 6.09706
Epoch 30, Val Loss: 6.40001
Epoch 31, Val Loss: 5.99174
Epoch 32, Val Loss: 6.09786
Epoch 33, Val Loss: 6.12916
Epoch 34, Val Loss: 6.08115
Epoch 35, Val Loss: 5.92626
Epoch 36, Val Loss: 6.04261
Epoch 37, Val Loss: 6.27914
Epoch 38, Val Loss: 5.98734
Epoch 39, Val Loss: 6.47347
Epoch 40, Val Loss: 6.27964
Epoch 41, Val Loss: 6.39715
Epoch 42, Val Loss: 5.97699
Epoch 43, Val Loss: 5.75879
Epoch 44, Val Loss: 5.82971
Epoch 45, Val Loss: 6.07832
Epoch 46, Val Loss: 5.96920
Epoch 47, Val Loss: 5.99495
Epoch 48, Val Loss: 5.98563
Epoch 49, Val Loss: 6.24952
Epoch 50, Val Loss: 5.84075
Epoch 51, Val Loss: 5.77548
Epoch 52, Val Loss: 5.92055
Epoch 53, Val Loss: 6.07560
Epoch 54, Val Loss: 5.90728
Epoch 55, Val Loss: 5.92566
Epoch 56, Val Loss: 5.81363
Epoch 57, Val Loss: 5.79954
Epoch 58, Val Loss: 5.97905
Epoch 59, Val Loss: 5.89550
Epoch 60, Val Loss: 5.89996
Epoch 61, Val Loss: 5.82222
Epoch 62, Val Loss: 5.79142
Epoch 63, Val Loss: 5.88034
Epoch 64, Val Loss: 5.76112
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.69977849731846, 'MSE - std': 0.585194463020864, 'R2 - mean': 0.5486521101828501, 'R2 - std': 0.012919262711443903} 
 

Results After CV: {'MSE - mean': 4.69977849731846, 'MSE - std': 0.585194463020864, 'R2 - mean': 0.5486521101828501, 'R2 - std': 0.012919262711443903}
Train time: 88.16276466999997
Inference time: 0.0547801642000195
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 27 finished with value: 4.69977849731846 and parameters: {'p_m': 0.7699830535857163, 'alpha': 5.369729738720173, 'K': 15, 'beta': 0.8805316037841042}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.92470
Epoch 1, Val Loss: 12.52327
Epoch 2, Val Loss: 7.42365
Epoch 3, Val Loss: 6.92679
Epoch 4, Val Loss: 6.74093
Epoch 5, Val Loss: 6.95195
Epoch 6, Val Loss: 6.81389
Epoch 7, Val Loss: 6.84621
Epoch 8, Val Loss: 6.73014
Epoch 9, Val Loss: 6.48231
Epoch 10, Val Loss: 6.42724
Epoch 11, Val Loss: 6.34604
Epoch 12, Val Loss: 6.40928
Epoch 13, Val Loss: 6.43398
Epoch 14, Val Loss: 6.37180
Epoch 15, Val Loss: 7.20536
Epoch 16, Val Loss: 6.59237
Epoch 17, Val Loss: 6.01549
Epoch 18, Val Loss: 6.37945
Epoch 19, Val Loss: 6.58746
Epoch 20, Val Loss: 6.00365
Epoch 21, Val Loss: 5.94955
Epoch 22, Val Loss: 6.11055
Epoch 23, Val Loss: 5.97789
Epoch 24, Val Loss: 6.32363
Epoch 25, Val Loss: 5.84511
Epoch 26, Val Loss: 5.91737
Epoch 27, Val Loss: 5.75540
Epoch 28, Val Loss: 5.87789
Epoch 29, Val Loss: 5.69041
Epoch 30, Val Loss: 6.02116
Epoch 31, Val Loss: 5.96675
Epoch 32, Val Loss: 6.15694
Epoch 33, Val Loss: 5.62474
Epoch 34, Val Loss: 5.70114
Epoch 35, Val Loss: 5.76865
Epoch 36, Val Loss: 5.76297
Epoch 37, Val Loss: 6.00779
Epoch 38, Val Loss: 5.68726
Epoch 39, Val Loss: 5.54449
Epoch 40, Val Loss: 5.82496
Epoch 41, Val Loss: 5.65868
Epoch 42, Val Loss: 5.53603
Epoch 43, Val Loss: 5.66985
Epoch 44, Val Loss: 5.83935
Epoch 45, Val Loss: 5.63856
Epoch 46, Val Loss: 5.62623
Epoch 47, Val Loss: 5.78623
Epoch 48, Val Loss: 5.40700
Epoch 49, Val Loss: 5.47640
Epoch 50, Val Loss: 5.90548
Epoch 51, Val Loss: 5.53683
Epoch 52, Val Loss: 5.36467
Epoch 53, Val Loss: 5.36023
Epoch 54, Val Loss: 5.26396
Epoch 55, Val Loss: 5.54421
Epoch 56, Val Loss: 5.44816
Epoch 57, Val Loss: 5.55131
Epoch 58, Val Loss: 5.25164
Epoch 59, Val Loss: 5.31104
Epoch 60, Val Loss: 5.55463
Epoch 61, Val Loss: 5.49955
Epoch 62, Val Loss: 5.24313
Epoch 63, Val Loss: 5.23953
Epoch 64, Val Loss: 5.17177
Epoch 65, Val Loss: 5.38982
Epoch 66, Val Loss: 5.17853
Epoch 67, Val Loss: 5.38254
Epoch 68, Val Loss: 5.77645
Epoch 69, Val Loss: 5.29097
Epoch 70, Val Loss: 5.43736
Epoch 71, Val Loss: 5.13810
Epoch 72, Val Loss: 5.26774
Epoch 73, Val Loss: 5.39830
Epoch 74, Val Loss: 5.23239
Epoch 75, Val Loss: 5.16092
Epoch 76, Val Loss: 5.11069
Epoch 77, Val Loss: 5.01232
Epoch 78, Val Loss: 5.08002
Epoch 79, Val Loss: 5.28951
Epoch 80, Val Loss: 5.16514
Epoch 81, Val Loss: 5.01154
Epoch 82, Val Loss: 5.28019
Epoch 83, Val Loss: 4.95706
Epoch 84, Val Loss: 5.13908
Epoch 85, Val Loss: 5.12311
Epoch 86, Val Loss: 4.90059
Epoch 87, Val Loss: 5.09610
Epoch 88, Val Loss: 5.26339
Epoch 89, Val Loss: 4.92331
Epoch 90, Val Loss: 5.02419
Epoch 91, Val Loss: 4.95795
Epoch 92, Val Loss: 4.97027
Epoch 93, Val Loss: 4.98140
Epoch 94, Val Loss: 4.93157
Epoch 95, Val Loss: 5.01744
Epoch 96, Val Loss: 5.13961
Epoch 97, Val Loss: 4.87362
Epoch 98, Val Loss: 5.01718
Epoch 99, Val Loss: 5.13707
DID NOT SAVE RESULTS
{'MSE - mean': 5.018531422861287, 'MSE - std': 0.0, 'R2 - mean': 0.5423265171846454, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.20229
Epoch 1, Val Loss: 6.39456
Epoch 2, Val Loss: 6.51442
Epoch 3, Val Loss: 5.60274
Epoch 4, Val Loss: 5.53632
Epoch 5, Val Loss: 5.32815
Epoch 6, Val Loss: 5.28924
Epoch 7, Val Loss: 5.25586
Epoch 8, Val Loss: 5.14633
Epoch 9, Val Loss: 5.19612
Epoch 10, Val Loss: 5.42048
Epoch 11, Val Loss: 5.63093
Epoch 12, Val Loss: 5.16580
Epoch 13, Val Loss: 5.32568
Epoch 14, Val Loss: 4.96840
Epoch 15, Val Loss: 5.07904
Epoch 16, Val Loss: 5.01491
Epoch 17, Val Loss: 5.09629
Epoch 18, Val Loss: 6.17151
Epoch 19, Val Loss: 4.94798
Epoch 20, Val Loss: 5.30895
Epoch 21, Val Loss: 4.95117
Epoch 22, Val Loss: 4.92331
Epoch 23, Val Loss: 5.34515
Epoch 24, Val Loss: 4.88538
Epoch 25, Val Loss: 5.88558
Epoch 26, Val Loss: 4.93032
Epoch 27, Val Loss: 5.00776
Epoch 28, Val Loss: 4.73792
Epoch 29, Val Loss: 4.88671
Epoch 30, Val Loss: 5.18449
Epoch 31, Val Loss: 4.69427
Epoch 32, Val Loss: 5.19726
Epoch 33, Val Loss: 4.65537
Epoch 34, Val Loss: 5.06823
Epoch 35, Val Loss: 4.76771
Epoch 36, Val Loss: 5.30721
Epoch 37, Val Loss: 4.97941
Epoch 38, Val Loss: 4.74517
Epoch 39, Val Loss: 4.69461
Epoch 40, Val Loss: 4.61980
Epoch 41, Val Loss: 4.94868
Epoch 42, Val Loss: 4.61700
Epoch 43, Val Loss: 4.76087
Epoch 44, Val Loss: 5.08466
Epoch 45, Val Loss: 4.53497
Epoch 46, Val Loss: 4.78685
Epoch 47, Val Loss: 4.98285
Epoch 48, Val Loss: 4.51142
Epoch 49, Val Loss: 4.83016
Epoch 50, Val Loss: 4.57321
Epoch 51, Val Loss: 4.58921
Epoch 52, Val Loss: 4.56832
Epoch 53, Val Loss: 4.43886
Epoch 54, Val Loss: 4.70149
Epoch 55, Val Loss: 5.18655
Epoch 56, Val Loss: 4.64121
Epoch 57, Val Loss: 4.52236
Epoch 58, Val Loss: 4.50726
Epoch 59, Val Loss: 4.41740
Epoch 60, Val Loss: 4.49257
Epoch 61, Val Loss: 4.57300
Epoch 62, Val Loss: 4.34913
Epoch 63, Val Loss: 4.70180
Epoch 64, Val Loss: 4.67469
Epoch 65, Val Loss: 4.48415
Epoch 66, Val Loss: 4.29639
Epoch 67, Val Loss: 4.32296
Epoch 68, Val Loss: 4.25506
Epoch 69, Val Loss: 4.39631
Epoch 70, Val Loss: 4.42706
Epoch 71, Val Loss: 4.38023
Epoch 72, Val Loss: 4.62317
Epoch 73, Val Loss: 4.47499
Epoch 74, Val Loss: 4.59638
Epoch 75, Val Loss: 4.32701
Epoch 76, Val Loss: 4.30906
Epoch 77, Val Loss: 4.61730
Epoch 78, Val Loss: 4.39168
Epoch 79, Val Loss: 4.22821
Epoch 80, Val Loss: 4.52296
Epoch 81, Val Loss: 4.29336
Epoch 82, Val Loss: 4.56400
Epoch 83, Val Loss: 4.31073
Epoch 84, Val Loss: 4.25898
Epoch 85, Val Loss: 4.26638
Epoch 86, Val Loss: 4.24803
Epoch 87, Val Loss: 4.54144
Epoch 88, Val Loss: 4.39395
Epoch 89, Val Loss: 4.32424
Epoch 90, Val Loss: 4.23095
Epoch 91, Val Loss: 4.28694
Epoch 92, Val Loss: 4.79487
Epoch 93, Val Loss: 4.43095
Epoch 94, Val Loss: 4.27139
Epoch 95, Val Loss: 4.22839
Epoch 96, Val Loss: 4.16992
Epoch 97, Val Loss: 4.16556
Epoch 98, Val Loss: 4.29071
Epoch 99, Val Loss: 4.25971
DID NOT SAVE RESULTS
{'MSE - mean': 4.666958914529394, 'MSE - std': 0.3515725083318926, 'R2 - mean': 0.5411605774388366, 'R2 - std': 0.0011659397458088083} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.57293
Epoch 1, Val Loss: 12.54925
Epoch 2, Val Loss: 6.95639
Epoch 3, Val Loss: 6.34747
Epoch 4, Val Loss: 6.15184
Epoch 5, Val Loss: 6.60796
Epoch 6, Val Loss: 6.10320
Epoch 7, Val Loss: 6.24978
Epoch 8, Val Loss: 6.30437
Epoch 9, Val Loss: 6.38006
Epoch 10, Val Loss: 6.26206
Epoch 11, Val Loss: 6.21156
Epoch 12, Val Loss: 5.91039
Epoch 13, Val Loss: 5.89214
Epoch 14, Val Loss: 5.85501
Epoch 15, Val Loss: 5.86692
Epoch 16, Val Loss: 5.86594
Epoch 17, Val Loss: 6.11777
Epoch 18, Val Loss: 5.88308
Epoch 19, Val Loss: 6.09233
Epoch 20, Val Loss: 5.74421
Epoch 21, Val Loss: 5.75249
Epoch 22, Val Loss: 5.83725
Epoch 23, Val Loss: 5.76381
Epoch 24, Val Loss: 5.85779
Epoch 25, Val Loss: 6.22480
Epoch 26, Val Loss: 6.07981
Epoch 27, Val Loss: 6.45250
Epoch 28, Val Loss: 6.12224
Epoch 29, Val Loss: 5.64968
Epoch 30, Val Loss: 5.72222
Epoch 31, Val Loss: 5.56209
Epoch 32, Val Loss: 5.58687
Epoch 33, Val Loss: 5.64609
Epoch 34, Val Loss: 5.94659
Epoch 35, Val Loss: 5.93394
Epoch 36, Val Loss: 5.50145
Epoch 37, Val Loss: 5.77125
Epoch 38, Val Loss: 5.79218
Epoch 39, Val Loss: 5.42250
Epoch 40, Val Loss: 5.88787
Epoch 41, Val Loss: 5.40694
Epoch 42, Val Loss: 5.92572
Epoch 43, Val Loss: 5.50680
Epoch 44, Val Loss: 5.33703
Epoch 45, Val Loss: 5.50059
Epoch 46, Val Loss: 5.23528
Epoch 47, Val Loss: 5.33545
Epoch 48, Val Loss: 5.13361
Epoch 49, Val Loss: 5.18938
Epoch 50, Val Loss: 5.42227
Epoch 51, Val Loss: 5.91347
Epoch 52, Val Loss: 5.32413
Epoch 53, Val Loss: 5.13358
Epoch 54, Val Loss: 5.18279
Epoch 55, Val Loss: 5.83543
Epoch 56, Val Loss: 5.08636
Epoch 57, Val Loss: 5.57430
Epoch 58, Val Loss: 5.16417
Epoch 59, Val Loss: 5.49869
Epoch 60, Val Loss: 5.15069
Epoch 61, Val Loss: 5.51107
Epoch 62, Val Loss: 5.21652
Epoch 63, Val Loss: 5.10063
Epoch 64, Val Loss: 5.07778
Epoch 65, Val Loss: 5.08856
Epoch 66, Val Loss: 4.98903
Epoch 67, Val Loss: 5.01222
Epoch 68, Val Loss: 4.90822
Epoch 69, Val Loss: 4.95284
Epoch 70, Val Loss: 5.14505
Epoch 71, Val Loss: 4.88455
Epoch 72, Val Loss: 4.97613
Epoch 73, Val Loss: 5.03642
Epoch 74, Val Loss: 5.08345
Epoch 75, Val Loss: 4.91905
Epoch 76, Val Loss: 5.20240
Epoch 77, Val Loss: 4.82853
Epoch 78, Val Loss: 4.88011
Epoch 79, Val Loss: 4.99794
Epoch 80, Val Loss: 4.84734
Epoch 81, Val Loss: 5.04278
Epoch 82, Val Loss: 4.92386
Epoch 83, Val Loss: 4.73587
Epoch 84, Val Loss: 5.54375
Epoch 85, Val Loss: 4.86730
Epoch 86, Val Loss: 4.92076
Epoch 87, Val Loss: 4.76749
Epoch 88, Val Loss: 4.81617
Epoch 89, Val Loss: 4.99495
Epoch 90, Val Loss: 5.02135
Epoch 91, Val Loss: 4.83729
Epoch 92, Val Loss: 4.91823
Epoch 93, Val Loss: 4.71370
Epoch 94, Val Loss: 4.96626
Epoch 95, Val Loss: 5.16478
Epoch 96, Val Loss: 4.70355
Epoch 97, Val Loss: 4.86261
Epoch 98, Val Loss: 4.70554
Epoch 99, Val Loss: 4.69212
DID NOT SAVE RESULTS
{'MSE - mean': 4.73348106055439, 'MSE - std': 0.30208036055558846, 'R2 - mean': 0.5344871394585079, 'R2 - std': 0.009485558810554651} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.94820
Epoch 1, Val Loss: 13.27314
Epoch 2, Val Loss: 6.21617
Epoch 3, Val Loss: 6.38393
Epoch 4, Val Loss: 6.48395
Epoch 5, Val Loss: 5.60433
Epoch 6, Val Loss: 5.13945
Epoch 7, Val Loss: 5.14037
Epoch 8, Val Loss: 5.35557
Epoch 9, Val Loss: 5.45733
Epoch 10, Val Loss: 5.05383
Epoch 11, Val Loss: 4.96547
Epoch 12, Val Loss: 5.07007
Epoch 13, Val Loss: 5.30502
Epoch 14, Val Loss: 4.92263
Epoch 15, Val Loss: 4.97617
Epoch 16, Val Loss: 4.82527
Epoch 17, Val Loss: 4.87080
Epoch 18, Val Loss: 5.11426
Epoch 19, Val Loss: 4.83621
Epoch 20, Val Loss: 4.91922
Epoch 21, Val Loss: 4.72634
Epoch 22, Val Loss: 4.79766
Epoch 23, Val Loss: 4.83146
Epoch 24, Val Loss: 4.63727
Epoch 25, Val Loss: 4.77624
Epoch 26, Val Loss: 4.66855
Epoch 27, Val Loss: 5.17306
Epoch 28, Val Loss: 4.57522
Epoch 29, Val Loss: 4.60569
Epoch 30, Val Loss: 4.63533
Epoch 31, Val Loss: 5.21939
Epoch 32, Val Loss: 4.85497
Epoch 33, Val Loss: 4.59865
Epoch 34, Val Loss: 4.55956
Epoch 35, Val Loss: 4.66424
Epoch 36, Val Loss: 4.88197
Epoch 37, Val Loss: 4.59530
Epoch 38, Val Loss: 4.57830
Epoch 39, Val Loss: 4.81953
Epoch 40, Val Loss: 4.47528
Epoch 41, Val Loss: 4.57717
Epoch 42, Val Loss: 4.46320
Epoch 43, Val Loss: 4.99617
Epoch 44, Val Loss: 4.68240
Epoch 45, Val Loss: 4.43142
Epoch 46, Val Loss: 4.47832
Epoch 47, Val Loss: 4.49997
Epoch 48, Val Loss: 4.43999
Epoch 49, Val Loss: 4.40855
Epoch 50, Val Loss: 4.44558
Epoch 51, Val Loss: 4.49575
Epoch 52, Val Loss: 5.03990
Epoch 53, Val Loss: 4.38809
Epoch 54, Val Loss: 4.53980
Epoch 55, Val Loss: 4.41052
Epoch 56, Val Loss: 4.48205
Epoch 57, Val Loss: 4.67503
Epoch 58, Val Loss: 4.40098
Epoch 59, Val Loss: 4.51254
Epoch 60, Val Loss: 4.51681
Epoch 61, Val Loss: 4.34853
Epoch 62, Val Loss: 4.32507
Epoch 63, Val Loss: 4.40711
Epoch 64, Val Loss: 4.29331
Epoch 65, Val Loss: 4.57813
Epoch 66, Val Loss: 4.36681
Epoch 67, Val Loss: 4.39012
Epoch 68, Val Loss: 4.38892
Epoch 69, Val Loss: 4.39509
Epoch 70, Val Loss: 4.96668
Epoch 71, Val Loss: 4.31664
Epoch 72, Val Loss: 4.43303
Epoch 73, Val Loss: 4.61327
Epoch 74, Val Loss: 4.27787
Epoch 75, Val Loss: 4.32249
Epoch 76, Val Loss: 4.61615
Epoch 77, Val Loss: 4.54633
Epoch 78, Val Loss: 4.42265
Epoch 79, Val Loss: 4.91660
Epoch 80, Val Loss: 4.38518
Epoch 81, Val Loss: 4.30560
Epoch 82, Val Loss: 4.37595
Epoch 83, Val Loss: 4.43839
Epoch 84, Val Loss: 4.42952
Epoch 85, Val Loss: 4.36276
Epoch 86, Val Loss: 4.38337
Epoch 87, Val Loss: 4.30862
Epoch 88, Val Loss: 4.47682
Epoch 89, Val Loss: 4.79592
Epoch 90, Val Loss: 4.60050
Epoch 91, Val Loss: 4.23834
Epoch 92, Val Loss: 4.45586
Epoch 93, Val Loss: 4.44112
Epoch 94, Val Loss: 4.29004
Epoch 95, Val Loss: 4.36269
Epoch 96, Val Loss: 4.33246
Epoch 97, Val Loss: 4.42613
Epoch 98, Val Loss: 4.27678
Epoch 99, Val Loss: 4.29024
DID NOT SAVE RESULTS
{'MSE - mean': 4.702313706950923, 'MSE - std': 0.26712098376386795, 'R2 - mean': 0.5276712335088943, 'R2 - std': 0.014382336082963106} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.47881
Epoch 1, Val Loss: 15.53748
Epoch 2, Val Loss: 8.52945
Epoch 3, Val Loss: 7.78584
Epoch 4, Val Loss: 7.83177
Epoch 5, Val Loss: 7.42417
Epoch 6, Val Loss: 7.52557
Epoch 7, Val Loss: 7.20695
Epoch 8, Val Loss: 7.28999
Epoch 9, Val Loss: 7.22991
Epoch 10, Val Loss: 7.39210
Epoch 11, Val Loss: 6.96507
Epoch 12, Val Loss: 7.12760
Epoch 13, Val Loss: 7.08559
Epoch 14, Val Loss: 7.21185
Epoch 15, Val Loss: 7.07587
Epoch 16, Val Loss: 7.14767
Epoch 17, Val Loss: 7.57856
Epoch 18, Val Loss: 6.84161
Epoch 19, Val Loss: 6.92715
Epoch 20, Val Loss: 6.95345
Epoch 21, Val Loss: 7.14870
Epoch 22, Val Loss: 6.82945
Epoch 23, Val Loss: 7.31900
Epoch 24, Val Loss: 6.80417
Epoch 25, Val Loss: 6.81128
Epoch 26, Val Loss: 6.56701
Epoch 27, Val Loss: 6.74069
Epoch 28, Val Loss: 6.45383
Epoch 29, Val Loss: 6.80157
Epoch 30, Val Loss: 6.64985
Epoch 31, Val Loss: 6.55025
Epoch 32, Val Loss: 6.41738
Epoch 33, Val Loss: 7.00166
Epoch 34, Val Loss: 6.38467
Epoch 35, Val Loss: 6.48155
Epoch 36, Val Loss: 6.69229
Epoch 37, Val Loss: 6.47893
Epoch 38, Val Loss: 6.56015
Epoch 39, Val Loss: 6.69038
Epoch 40, Val Loss: 6.36798
Epoch 41, Val Loss: 6.33927
Epoch 42, Val Loss: 6.58604
Epoch 43, Val Loss: 6.57114
Epoch 44, Val Loss: 6.62980
Epoch 45, Val Loss: 6.38214
Epoch 46, Val Loss: 6.91862
Epoch 47, Val Loss: 6.56502
Epoch 48, Val Loss: 6.30774
Epoch 49, Val Loss: 6.77025
Epoch 50, Val Loss: 6.27574
Epoch 51, Val Loss: 6.49744
Epoch 52, Val Loss: 6.30509
Epoch 53, Val Loss: 6.59639
Epoch 54, Val Loss: 6.20479
Epoch 55, Val Loss: 6.67847
Epoch 56, Val Loss: 6.48276
Epoch 57, Val Loss: 6.43018
Epoch 58, Val Loss: 6.20009
Epoch 59, Val Loss: 6.27944
Epoch 60, Val Loss: 6.31640
Epoch 61, Val Loss: 6.29030
Epoch 62, Val Loss: 6.43397
Epoch 63, Val Loss: 6.32743
Epoch 64, Val Loss: 6.32780
Epoch 65, Val Loss: 6.00893
Epoch 66, Val Loss: 6.05733
Epoch 67, Val Loss: 5.91687
Epoch 68, Val Loss: 6.75381
Epoch 69, Val Loss: 6.31648
Epoch 70, Val Loss: 6.28266
Epoch 71, Val Loss: 6.09805
Epoch 72, Val Loss: 6.30218
Epoch 73, Val Loss: 5.99008
Epoch 74, Val Loss: 6.22116
Epoch 75, Val Loss: 6.19131
Epoch 76, Val Loss: 6.25803
Epoch 77, Val Loss: 6.25006
Epoch 78, Val Loss: 6.08077
Epoch 79, Val Loss: 5.95318
Epoch 80, Val Loss: 6.52208
Epoch 81, Val Loss: 6.07907
Epoch 82, Val Loss: 5.99551
Epoch 83, Val Loss: 6.23155
Epoch 84, Val Loss: 5.97561
Epoch 85, Val Loss: 6.37275
Epoch 86, Val Loss: 6.03719
Epoch 87, Val Loss: 6.03265
Epoch 88, Val Loss: 6.15487
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.937449078665585, 'MSE - std': 0.5274821969499556, 'R2 - mean': 0.5249153932359282, 'R2 - std': 0.013994995369883132} 
 

Results After CV: {'MSE - mean': 4.937449078665585, 'MSE - std': 0.5274821969499556, 'R2 - mean': 0.5249153932359282, 'R2 - std': 0.013994995369883132}
Train time: 78.4374659184
Inference time: 0.04940675319994625
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 28 finished with value: 4.937449078665585 and parameters: {'p_m': 0.37058466669360635, 'alpha': 4.533631877077995, 'K': 10, 'beta': 1.8977386521290007}. Best is trial 23 with value: 4.602941213165306.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.51245
Epoch 1, Val Loss: 11.57194
Epoch 2, Val Loss: 6.93513
Epoch 3, Val Loss: 6.91050
Epoch 4, Val Loss: 6.94106
Epoch 5, Val Loss: 6.42706
Epoch 6, Val Loss: 6.55366
Epoch 7, Val Loss: 6.36098
Epoch 8, Val Loss: 6.24892
Epoch 9, Val Loss: 6.14645
Epoch 10, Val Loss: 5.91582
Epoch 11, Val Loss: 5.96934
Epoch 12, Val Loss: 5.80716
Epoch 13, Val Loss: 5.80127
Epoch 14, Val Loss: 5.68399
Epoch 15, Val Loss: 5.72048
Epoch 16, Val Loss: 5.80560
Epoch 17, Val Loss: 5.65068
Epoch 18, Val Loss: 5.44403
Epoch 19, Val Loss: 6.09184
Epoch 20, Val Loss: 5.22182
Epoch 21, Val Loss: 5.52543
Epoch 22, Val Loss: 5.30297
Epoch 23, Val Loss: 5.14725
Epoch 24, Val Loss: 5.13366
Epoch 25, Val Loss: 5.10241
Epoch 26, Val Loss: 5.17204
Epoch 27, Val Loss: 4.97139
Epoch 28, Val Loss: 5.62478
Epoch 29, Val Loss: 5.05506
Epoch 30, Val Loss: 5.22234
Epoch 31, Val Loss: 5.91515
Epoch 32, Val Loss: 4.97931
Epoch 33, Val Loss: 4.72711
Epoch 34, Val Loss: 4.75743
Epoch 35, Val Loss: 4.76637
Epoch 36, Val Loss: 4.88097
Epoch 37, Val Loss: 4.85599
Epoch 38, Val Loss: 4.71674
Epoch 39, Val Loss: 4.70042
Epoch 40, Val Loss: 4.99591
Epoch 41, Val Loss: 5.13155
Epoch 42, Val Loss: 4.77730
Epoch 43, Val Loss: 5.19291
Epoch 44, Val Loss: 4.69788
Epoch 45, Val Loss: 4.61424
Epoch 46, Val Loss: 4.54793
Epoch 47, Val Loss: 4.73896
Epoch 48, Val Loss: 4.69279
Epoch 49, Val Loss: 4.55101
Epoch 50, Val Loss: 4.57163
Epoch 51, Val Loss: 4.73969
Epoch 52, Val Loss: 4.55319
Epoch 53, Val Loss: 4.53495
Epoch 54, Val Loss: 5.23810
Epoch 55, Val Loss: 4.52743
Epoch 56, Val Loss: 4.92067
Epoch 57, Val Loss: 4.45561
Epoch 58, Val Loss: 4.64655
Epoch 59, Val Loss: 4.42199
Epoch 60, Val Loss: 4.96190
Epoch 61, Val Loss: 4.60886
Epoch 62, Val Loss: 4.63009
Epoch 63, Val Loss: 4.51487
Epoch 64, Val Loss: 4.67098
Epoch 65, Val Loss: 4.53168
Epoch 66, Val Loss: 4.50127
Epoch 67, Val Loss: 4.55367
Epoch 68, Val Loss: 4.44724
Epoch 69, Val Loss: 4.43178
Epoch 70, Val Loss: 4.53228
Epoch 71, Val Loss: 4.57632
Epoch 72, Val Loss: 4.53634
Epoch 73, Val Loss: 4.73794
Epoch 74, Val Loss: 5.27662
Epoch 75, Val Loss: 4.55629
Epoch 76, Val Loss: 4.79911
Epoch 77, Val Loss: 4.75994
Epoch 78, Val Loss: 4.67142
Epoch 79, Val Loss: 4.71048
Epoch 80, Val Loss: 4.55585
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.591880160184225, 'MSE - std': 0.0, 'R2 - mean': 0.5812357025386448, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.72173
Epoch 1, Val Loss: 11.76727
Epoch 2, Val Loss: 7.27341
Epoch 3, Val Loss: 6.80926
Epoch 4, Val Loss: 5.97784
Epoch 5, Val Loss: 5.53311
Epoch 6, Val Loss: 5.26701
Epoch 7, Val Loss: 5.46396
Epoch 8, Val Loss: 4.93107
Epoch 9, Val Loss: 4.76831
Epoch 10, Val Loss: 4.95691
Epoch 11, Val Loss: 4.63208
Epoch 12, Val Loss: 4.48467
Epoch 13, Val Loss: 4.46492
Epoch 14, Val Loss: 5.28813
Epoch 15, Val Loss: 4.56929
Epoch 16, Val Loss: 4.29597
Epoch 17, Val Loss: 4.16665
Epoch 18, Val Loss: 4.22466
Epoch 19, Val Loss: 4.42986
Epoch 20, Val Loss: 4.46659
Epoch 21, Val Loss: 4.30448
Epoch 22, Val Loss: 4.17995
Epoch 23, Val Loss: 4.15435
Epoch 24, Val Loss: 4.49904
Epoch 25, Val Loss: 4.16724
Epoch 26, Val Loss: 4.04328
Epoch 27, Val Loss: 4.11353
Epoch 28, Val Loss: 4.04968
Epoch 29, Val Loss: 4.22727
Epoch 30, Val Loss: 4.13751
Epoch 31, Val Loss: 3.98902
Epoch 32, Val Loss: 4.32913
Epoch 33, Val Loss: 3.96758
Epoch 34, Val Loss: 4.00687
Epoch 35, Val Loss: 3.98484
Epoch 36, Val Loss: 4.06282
Epoch 37, Val Loss: 3.99526
Epoch 38, Val Loss: 4.08482
Epoch 39, Val Loss: 4.65857
Epoch 40, Val Loss: 4.18972
Epoch 41, Val Loss: 4.42393
Epoch 42, Val Loss: 4.13947
Epoch 43, Val Loss: 4.48308
Epoch 44, Val Loss: 4.10997
Epoch 45, Val Loss: 3.96571
Epoch 46, Val Loss: 4.24145
Epoch 47, Val Loss: 4.12907
Epoch 48, Val Loss: 4.22990
Epoch 49, Val Loss: 4.42098
Epoch 50, Val Loss: 3.96605
Epoch 51, Val Loss: 4.07093
Epoch 52, Val Loss: 3.94491
Epoch 53, Val Loss: 3.91609
Epoch 54, Val Loss: 4.00113
Epoch 55, Val Loss: 4.00717
Epoch 56, Val Loss: 3.95750
Epoch 57, Val Loss: 4.08929
Epoch 58, Val Loss: 4.24804
Epoch 59, Val Loss: 4.16635
Epoch 60, Val Loss: 4.01183
Epoch 61, Val Loss: 4.06812
Epoch 62, Val Loss: 4.20987
Epoch 63, Val Loss: 4.41012
Epoch 64, Val Loss: 3.95757
Epoch 65, Val Loss: 4.12982
Epoch 66, Val Loss: 3.91460
Epoch 67, Val Loss: 3.94766
Epoch 68, Val Loss: 4.18833
Epoch 69, Val Loss: 3.99981
Epoch 70, Val Loss: 3.99486
Epoch 71, Val Loss: 4.32646
Epoch 72, Val Loss: 4.07467
Epoch 73, Val Loss: 3.99745
Epoch 74, Val Loss: 3.98028
Epoch 75, Val Loss: 4.02807
Epoch 76, Val Loss: 4.47094
Epoch 77, Val Loss: 4.52771
Epoch 78, Val Loss: 3.99536
Epoch 79, Val Loss: 4.02523
Epoch 80, Val Loss: 4.07125
Epoch 81, Val Loss: 4.09735
Epoch 82, Val Loss: 4.06683
Epoch 83, Val Loss: 3.94707
Epoch 84, Val Loss: 3.97716
Epoch 85, Val Loss: 3.99948
Epoch 86, Val Loss: 3.92262
Epoch 87, Val Loss: 4.12978
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.338758855490562, 'MSE - std': 0.2531213046936629, 'R2 - mean': 0.5728603893755052, 'R2 - std': 0.008375313163139553} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.08660
Epoch 1, Val Loss: 16.36178
Epoch 2, Val Loss: 6.33987
Epoch 3, Val Loss: 5.85291
Epoch 4, Val Loss: 5.70972
Epoch 5, Val Loss: 5.71072
Epoch 6, Val Loss: 5.69057
Epoch 7, Val Loss: 5.62216
Epoch 8, Val Loss: 5.56996
Epoch 9, Val Loss: 5.75285
Epoch 10, Val Loss: 5.59347
Epoch 11, Val Loss: 5.45096
Epoch 12, Val Loss: 5.41827
Epoch 13, Val Loss: 5.35871
Epoch 14, Val Loss: 5.78485
Epoch 15, Val Loss: 5.26452
Epoch 16, Val Loss: 5.37662
Epoch 17, Val Loss: 5.11609
Epoch 18, Val Loss: 5.21119
Epoch 19, Val Loss: 5.03078
Epoch 20, Val Loss: 4.99454
Epoch 21, Val Loss: 5.03619
Epoch 22, Val Loss: 5.02571
Epoch 23, Val Loss: 5.02275
Epoch 24, Val Loss: 4.90897
Epoch 25, Val Loss: 5.00953
Epoch 26, Val Loss: 5.27096
Epoch 27, Val Loss: 4.85954
Epoch 28, Val Loss: 4.91453
Epoch 29, Val Loss: 4.78823
Epoch 30, Val Loss: 4.79244
Epoch 31, Val Loss: 5.06935
Epoch 32, Val Loss: 5.08093
Epoch 33, Val Loss: 4.78333
Epoch 34, Val Loss: 5.07509
Epoch 35, Val Loss: 4.79344
Epoch 36, Val Loss: 5.08185
Epoch 37, Val Loss: 4.81509
Epoch 38, Val Loss: 4.73281
Epoch 39, Val Loss: 4.78005
Epoch 40, Val Loss: 5.01179
Epoch 41, Val Loss: 4.68245
Epoch 42, Val Loss: 4.70731
Epoch 43, Val Loss: 4.73732
Epoch 44, Val Loss: 4.84651
Epoch 45, Val Loss: 4.85216
Epoch 46, Val Loss: 4.67420
Epoch 47, Val Loss: 4.66885
Epoch 48, Val Loss: 4.94009
Epoch 49, Val Loss: 4.69324
Epoch 50, Val Loss: 4.57418
Epoch 51, Val Loss: 4.76592
Epoch 52, Val Loss: 4.61107
Epoch 53, Val Loss: 4.66401
Epoch 54, Val Loss: 4.93757
Epoch 55, Val Loss: 4.94648
Epoch 56, Val Loss: 4.64817
Epoch 57, Val Loss: 4.71533
Epoch 58, Val Loss: 4.60385
Epoch 59, Val Loss: 4.74807
Epoch 60, Val Loss: 4.91400
Epoch 61, Val Loss: 4.53212
Epoch 62, Val Loss: 4.58973
Epoch 63, Val Loss: 4.60723
Epoch 64, Val Loss: 4.49484
Epoch 65, Val Loss: 4.65071
Epoch 66, Val Loss: 4.96420
Epoch 67, Val Loss: 4.66791
Epoch 68, Val Loss: 4.87630
Epoch 69, Val Loss: 4.48923
Epoch 70, Val Loss: 4.57177
Epoch 71, Val Loss: 4.46086
Epoch 72, Val Loss: 4.60527
Epoch 73, Val Loss: 4.79564
Epoch 74, Val Loss: 4.91665
Epoch 75, Val Loss: 4.65542
Epoch 76, Val Loss: 4.58893
Epoch 77, Val Loss: 4.58239
Epoch 78, Val Loss: 4.50932
Epoch 79, Val Loss: 4.44128
Epoch 80, Val Loss: 4.70006
Epoch 81, Val Loss: 4.73786
Epoch 82, Val Loss: 4.46670
Epoch 83, Val Loss: 4.47698
Epoch 84, Val Loss: 4.44736
Epoch 85, Val Loss: 4.54479
Epoch 86, Val Loss: 4.42253
Epoch 87, Val Loss: 4.39983
Epoch 88, Val Loss: 4.80031
Epoch 89, Val Loss: 4.55149
Epoch 90, Val Loss: 4.78460
Epoch 91, Val Loss: 4.49318
Epoch 92, Val Loss: 4.50687
Epoch 93, Val Loss: 4.77028
Epoch 94, Val Loss: 4.48224
Epoch 95, Val Loss: 4.57623
Epoch 96, Val Loss: 4.61427
Epoch 97, Val Loss: 4.44454
Epoch 98, Val Loss: 4.54317
Epoch 99, Val Loss: 4.72460
DID NOT SAVE RESULTS
{'MSE - mean': 4.396968965994149, 'MSE - std': 0.22246444777288435, 'R2 - mean': 0.5672030598553625, 'R2 - std': 0.01052495455189216} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.15728
Epoch 1, Val Loss: 15.18772
Epoch 2, Val Loss: 5.69413
Epoch 3, Val Loss: 5.27324
Epoch 4, Val Loss: 5.10703
Epoch 5, Val Loss: 4.95948
Epoch 6, Val Loss: 5.22493
Epoch 7, Val Loss: 5.09895
Epoch 8, Val Loss: 4.90940
Epoch 9, Val Loss: 4.97613
Epoch 10, Val Loss: 5.04197
Epoch 11, Val Loss: 5.11425
Epoch 12, Val Loss: 5.56422
Epoch 13, Val Loss: 4.75329
Epoch 14, Val Loss: 4.72405
Epoch 15, Val Loss: 4.70828
Epoch 16, Val Loss: 4.74327
Epoch 17, Val Loss: 4.80936
Epoch 18, Val Loss: 4.77234
Epoch 19, Val Loss: 4.58188
Epoch 20, Val Loss: 4.62682
Epoch 21, Val Loss: 5.00732
Epoch 22, Val Loss: 4.67741
Epoch 23, Val Loss: 4.84188
Epoch 24, Val Loss: 4.51455
Epoch 25, Val Loss: 4.75543
Epoch 26, Val Loss: 4.63777
Epoch 27, Val Loss: 4.57272
Epoch 28, Val Loss: 4.46275
Epoch 29, Val Loss: 4.60496
Epoch 30, Val Loss: 4.63469
Epoch 31, Val Loss: 4.44772
Epoch 32, Val Loss: 4.78004
Epoch 33, Val Loss: 4.35595
Epoch 34, Val Loss: 4.28348
Epoch 35, Val Loss: 4.76671
Epoch 36, Val Loss: 4.56684
Epoch 37, Val Loss: 4.33127
Epoch 38, Val Loss: 4.33631
Epoch 39, Val Loss: 4.36703
Epoch 40, Val Loss: 4.65726
Epoch 41, Val Loss: 4.25901
Epoch 42, Val Loss: 4.36595
Epoch 43, Val Loss: 4.29575
Epoch 44, Val Loss: 4.68946
Epoch 45, Val Loss: 4.27688
Epoch 46, Val Loss: 4.28072
Epoch 47, Val Loss: 4.24175
Epoch 48, Val Loss: 4.33480
Epoch 49, Val Loss: 4.30639
Epoch 50, Val Loss: 4.26724
Epoch 51, Val Loss: 4.27448
Epoch 52, Val Loss: 4.27241
Epoch 53, Val Loss: 4.23887
Epoch 54, Val Loss: 4.29188
Epoch 55, Val Loss: 4.32464
Epoch 56, Val Loss: 4.28736
Epoch 57, Val Loss: 4.46456
Epoch 58, Val Loss: 4.47832
Epoch 59, Val Loss: 4.11175
Epoch 60, Val Loss: 4.21171
Epoch 61, Val Loss: 4.14113
Epoch 62, Val Loss: 4.12365
Epoch 63, Val Loss: 4.10387
Epoch 64, Val Loss: 4.22324
Epoch 65, Val Loss: 4.11853
Epoch 66, Val Loss: 4.14348
Epoch 67, Val Loss: 4.08357
Epoch 68, Val Loss: 4.11208
Epoch 69, Val Loss: 4.16971
Epoch 70, Val Loss: 4.06310
Epoch 71, Val Loss: 4.21249
Epoch 72, Val Loss: 4.37119
Epoch 73, Val Loss: 4.05490
Epoch 74, Val Loss: 4.07615
Epoch 75, Val Loss: 4.60986
Epoch 76, Val Loss: 4.15446
Epoch 77, Val Loss: 4.29514
Epoch 78, Val Loss: 4.21582
Epoch 79, Val Loss: 4.03092
Epoch 80, Val Loss: 4.16916
Epoch 81, Val Loss: 4.09164
Epoch 82, Val Loss: 4.38261
Epoch 83, Val Loss: 4.05393
Epoch 84, Val Loss: 4.10971
Epoch 85, Val Loss: 4.10333
Epoch 86, Val Loss: 4.00318
Epoch 87, Val Loss: 4.10362
Epoch 88, Val Loss: 4.20498
Epoch 89, Val Loss: 4.10268
Epoch 90, Val Loss: 4.08341
Epoch 91, Val Loss: 4.04449
Epoch 92, Val Loss: 4.03407
Epoch 93, Val Loss: 4.08184
Epoch 94, Val Loss: 4.19324
Epoch 95, Val Loss: 3.97223
Epoch 96, Val Loss: 4.00277
Epoch 97, Val Loss: 4.04686
Epoch 98, Val Loss: 4.01610
Epoch 99, Val Loss: 3.98919
DID NOT SAVE RESULTS
{'MSE - mean': 4.365932752080263, 'MSE - std': 0.20001890564268246, 'R2 - mean': 0.5611891633428052, 'R2 - std': 0.013841309729602552} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.28046
Epoch 1, Val Loss: 14.11583
Epoch 2, Val Loss: 7.83484
Epoch 3, Val Loss: 7.71919
Epoch 4, Val Loss: 7.41579
Epoch 5, Val Loss: 7.63898
Epoch 6, Val Loss: 7.21629
Epoch 7, Val Loss: 7.05137
Epoch 8, Val Loss: 6.87559
Epoch 9, Val Loss: 7.11428
Epoch 10, Val Loss: 6.88003
Epoch 11, Val Loss: 6.60584
Epoch 12, Val Loss: 6.91469
Epoch 13, Val Loss: 6.97247
Epoch 14, Val Loss: 6.51351
Epoch 15, Val Loss: 6.44436
Epoch 16, Val Loss: 6.27783
Epoch 17, Val Loss: 6.31956
Epoch 18, Val Loss: 6.43518
Epoch 19, Val Loss: 6.12014
Epoch 20, Val Loss: 6.23974
Epoch 21, Val Loss: 6.62012
Epoch 22, Val Loss: 6.21730
Epoch 23, Val Loss: 6.15227
Epoch 24, Val Loss: 6.08957
Epoch 25, Val Loss: 6.03194
Epoch 26, Val Loss: 6.07208
Epoch 27, Val Loss: 6.01539
Epoch 28, Val Loss: 5.96352
Epoch 29, Val Loss: 5.90369
Epoch 30, Val Loss: 5.78725
Epoch 31, Val Loss: 5.82370
Epoch 32, Val Loss: 5.90519
Epoch 33, Val Loss: 5.89646
Epoch 34, Val Loss: 5.77235
Epoch 35, Val Loss: 5.74299
Epoch 36, Val Loss: 5.81266
Epoch 37, Val Loss: 5.69316
Epoch 38, Val Loss: 5.42178
Epoch 39, Val Loss: 5.58908
Epoch 40, Val Loss: 5.58058
Epoch 41, Val Loss: 5.49175
Epoch 42, Val Loss: 5.51714
Epoch 43, Val Loss: 5.47393
Epoch 44, Val Loss: 5.75533
Epoch 45, Val Loss: 5.47167
Epoch 46, Val Loss: 5.59336
Epoch 47, Val Loss: 5.50340
Epoch 48, Val Loss: 5.84039
Epoch 49, Val Loss: 5.68936
Epoch 50, Val Loss: 5.37725
Epoch 51, Val Loss: 5.77126
Epoch 52, Val Loss: 5.40680
Epoch 53, Val Loss: 5.69706
Epoch 54, Val Loss: 5.86067
Epoch 55, Val Loss: 5.50584
Epoch 56, Val Loss: 5.39626
Epoch 57, Val Loss: 5.32003
Epoch 58, Val Loss: 5.73461
Epoch 59, Val Loss: 5.40533
Epoch 60, Val Loss: 5.34689
Epoch 61, Val Loss: 5.49607
Epoch 62, Val Loss: 5.28846
Epoch 63, Val Loss: 5.37296
Epoch 64, Val Loss: 5.31918
Epoch 65, Val Loss: 5.38388
Epoch 66, Val Loss: 5.61166
Epoch 67, Val Loss: 5.75823
Epoch 68, Val Loss: 5.44480
Epoch 69, Val Loss: 5.29192
Epoch 70, Val Loss: 5.50348
Epoch 71, Val Loss: 5.58807
Epoch 72, Val Loss: 5.42646
Epoch 73, Val Loss: 5.36154
Epoch 74, Val Loss: 5.85107
Epoch 75, Val Loss: 5.60718
Epoch 76, Val Loss: 5.32744
Epoch 77, Val Loss: 5.44819
Epoch 78, Val Loss: 6.34685
Epoch 79, Val Loss: 5.35339
Epoch 80, Val Loss: 5.58317
Epoch 81, Val Loss: 5.68334
Epoch 82, Val Loss: 5.52031
Epoch 83, Val Loss: 5.34878
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.543469724668304, 'MSE - std': 0.3975972291584856, 'R2 - mean': 0.5620568263615451, 'R2 - std': 0.012501073573137117} 
 

Results After CV: {'MSE - mean': 4.543469724668304, 'MSE - std': 0.3975972291584856, 'R2 - mean': 0.5620568263615451, 'R2 - std': 0.012501073573137117}
Train time: 99.80771739420007
Inference time: 0.04879395479993036
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 29 finished with value: 4.543469724668304 and parameters: {'p_m': 0.4865172654422525, 'alpha': 2.2025639381097686, 'K': 20, 'beta': 0.22034881046573626}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 40.57804
Epoch 1, Val Loss: 15.31706
Epoch 2, Val Loss: 7.54254
Epoch 3, Val Loss: 7.28800
Epoch 4, Val Loss: 7.25761
Epoch 5, Val Loss: 6.89222
Epoch 6, Val Loss: 7.18592
Epoch 7, Val Loss: 6.96656
Epoch 8, Val Loss: 7.08053
Epoch 9, Val Loss: 6.70626
Epoch 10, Val Loss: 6.38186
Epoch 11, Val Loss: 6.40574
Epoch 12, Val Loss: 6.14628
Epoch 13, Val Loss: 6.46347
Epoch 14, Val Loss: 6.01199
Epoch 15, Val Loss: 5.93684
Epoch 16, Val Loss: 5.92618
Epoch 17, Val Loss: 5.93296
Epoch 18, Val Loss: 5.88159
Epoch 19, Val Loss: 5.91777
Epoch 20, Val Loss: 5.73347
Epoch 21, Val Loss: 5.65773
Epoch 22, Val Loss: 6.02508
Epoch 23, Val Loss: 5.96056
Epoch 24, Val Loss: 5.83407
Epoch 25, Val Loss: 5.61623
Epoch 26, Val Loss: 5.51047
Epoch 27, Val Loss: 5.56775
Epoch 28, Val Loss: 5.49682
Epoch 29, Val Loss: 5.54317
Epoch 30, Val Loss: 5.47517
Epoch 31, Val Loss: 5.61513
Epoch 32, Val Loss: 5.73547
Epoch 33, Val Loss: 5.30644
Epoch 34, Val Loss: 5.20921
Epoch 35, Val Loss: 5.30543
Epoch 36, Val Loss: 5.16232
Epoch 37, Val Loss: 5.21860
Epoch 38, Val Loss: 5.41721
Epoch 39, Val Loss: 5.09177
Epoch 40, Val Loss: 5.13586
Epoch 41, Val Loss: 5.43593
Epoch 42, Val Loss: 5.57721
Epoch 43, Val Loss: 5.12552
Epoch 44, Val Loss: 5.15786
Epoch 45, Val Loss: 5.13449
Epoch 46, Val Loss: 5.13411
Epoch 47, Val Loss: 5.16317
Epoch 48, Val Loss: 5.51150
Epoch 49, Val Loss: 5.31133
Epoch 50, Val Loss: 4.85228
Epoch 51, Val Loss: 4.96297
Epoch 52, Val Loss: 5.27837
Epoch 53, Val Loss: 4.93979
Epoch 54, Val Loss: 4.93452
Epoch 55, Val Loss: 4.96468
Epoch 56, Val Loss: 5.14956
Epoch 57, Val Loss: 4.82592
Epoch 58, Val Loss: 4.92318
Epoch 59, Val Loss: 5.03863
Epoch 60, Val Loss: 5.16311
Epoch 61, Val Loss: 4.92992
Epoch 62, Val Loss: 5.07067
Epoch 63, Val Loss: 5.07845
Epoch 64, Val Loss: 4.83090
Epoch 65, Val Loss: 4.97467
Epoch 66, Val Loss: 4.77488
Epoch 67, Val Loss: 5.00843
Epoch 68, Val Loss: 5.05157
Epoch 69, Val Loss: 5.25395
Epoch 70, Val Loss: 4.73452
Epoch 71, Val Loss: 5.20135
Epoch 72, Val Loss: 4.98811
Epoch 73, Val Loss: 5.31963
Epoch 74, Val Loss: 5.13059
Epoch 75, Val Loss: 4.92711
Epoch 76, Val Loss: 4.76653
Epoch 77, Val Loss: 4.94392
Epoch 78, Val Loss: 4.97483
Epoch 79, Val Loss: 5.22222
Epoch 80, Val Loss: 4.94631
Epoch 81, Val Loss: 4.77196
Epoch 82, Val Loss: 5.10280
Epoch 83, Val Loss: 4.80185
Epoch 84, Val Loss: 4.79302
Epoch 85, Val Loss: 4.70256
Epoch 86, Val Loss: 5.19552
Epoch 87, Val Loss: 5.22773
Epoch 88, Val Loss: 4.71681
Epoch 89, Val Loss: 5.54201
Epoch 90, Val Loss: 5.07479
Epoch 91, Val Loss: 4.76234
Epoch 92, Val Loss: 5.41178
Epoch 93, Val Loss: 4.72223
Epoch 94, Val Loss: 5.20617
Epoch 95, Val Loss: 4.90551
Epoch 96, Val Loss: 4.84558
Epoch 97, Val Loss: 4.91876
Epoch 98, Val Loss: 4.78964
Epoch 99, Val Loss: 4.86852
DID NOT SAVE RESULTS
{'MSE - mean': 4.805032575604346, 'MSE - std': 0.0, 'R2 - mean': 0.5617969065810393, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.64054
Epoch 1, Val Loss: 10.16987
Epoch 2, Val Loss: 6.33941
Epoch 3, Val Loss: 5.44829
Epoch 4, Val Loss: 5.11637
Epoch 5, Val Loss: 5.02000
Epoch 6, Val Loss: 4.88411
Epoch 7, Val Loss: 4.68081
Epoch 8, Val Loss: 4.67337
Epoch 9, Val Loss: 4.52674
Epoch 10, Val Loss: 4.53958
Epoch 11, Val Loss: 4.81877
Epoch 12, Val Loss: 4.31335
Epoch 13, Val Loss: 4.62459
Epoch 14, Val Loss: 4.51652
Epoch 15, Val Loss: 4.48544
Epoch 16, Val Loss: 4.29598
Epoch 17, Val Loss: 4.76174
Epoch 18, Val Loss: 4.30238
Epoch 19, Val Loss: 4.08024
Epoch 20, Val Loss: 4.06570
Epoch 21, Val Loss: 4.08798
Epoch 22, Val Loss: 4.49954
Epoch 23, Val Loss: 4.70008
Epoch 24, Val Loss: 4.10612
Epoch 25, Val Loss: 4.40517
Epoch 26, Val Loss: 4.02473
Epoch 27, Val Loss: 4.16456
Epoch 28, Val Loss: 4.03492
Epoch 29, Val Loss: 4.14456
Epoch 30, Val Loss: 4.18008
Epoch 31, Val Loss: 4.18642
Epoch 32, Val Loss: 4.22536
Epoch 33, Val Loss: 4.04315
Epoch 34, Val Loss: 4.07387
Epoch 35, Val Loss: 4.18617
Epoch 36, Val Loss: 4.18319
Epoch 37, Val Loss: 3.88669
Epoch 38, Val Loss: 3.91984
Epoch 39, Val Loss: 4.11690
Epoch 40, Val Loss: 3.99964
Epoch 41, Val Loss: 4.09060
Epoch 42, Val Loss: 3.88243
Epoch 43, Val Loss: 3.98836
Epoch 44, Val Loss: 4.15376
Epoch 45, Val Loss: 3.91154
Epoch 46, Val Loss: 4.47051
Epoch 47, Val Loss: 4.07268
Epoch 48, Val Loss: 3.90239
Epoch 49, Val Loss: 4.04509
Epoch 50, Val Loss: 4.04561
Epoch 51, Val Loss: 4.37073
Epoch 52, Val Loss: 3.88365
Epoch 53, Val Loss: 4.11240
Epoch 54, Val Loss: 4.32191
Epoch 55, Val Loss: 4.28868
Epoch 56, Val Loss: 4.17048
Epoch 57, Val Loss: 4.02031
Epoch 58, Val Loss: 4.86579
Epoch 59, Val Loss: 4.66135
Epoch 60, Val Loss: 4.22775
Epoch 61, Val Loss: 3.88834
Epoch 62, Val Loss: 3.97855
Epoch 63, Val Loss: 3.97994
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.457203413978435, 'MSE - std': 0.3478291616259104, 'R2 - mean': 0.5618758659859875, 'R2 - std': 7.895940494823117e-05} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.28777
Epoch 1, Val Loss: 9.51989
Epoch 2, Val Loss: 6.49968
Epoch 3, Val Loss: 5.94087
Epoch 4, Val Loss: 5.74409
Epoch 5, Val Loss: 5.45441
Epoch 6, Val Loss: 5.48240
Epoch 7, Val Loss: 5.43549
Epoch 8, Val Loss: 5.55696
Epoch 9, Val Loss: 5.15050
Epoch 10, Val Loss: 5.42589
Epoch 11, Val Loss: 5.13210
Epoch 12, Val Loss: 5.26279
Epoch 13, Val Loss: 4.94921
Epoch 14, Val Loss: 4.88919
Epoch 15, Val Loss: 4.92271
Epoch 16, Val Loss: 4.93084
Epoch 17, Val Loss: 4.94696
Epoch 18, Val Loss: 4.95771
Epoch 19, Val Loss: 4.90251
Epoch 20, Val Loss: 4.67655
Epoch 21, Val Loss: 4.78031
Epoch 22, Val Loss: 4.72614
Epoch 23, Val Loss: 4.72442
Epoch 24, Val Loss: 5.10308
Epoch 25, Val Loss: 5.50405
Epoch 26, Val Loss: 4.82320
Epoch 27, Val Loss: 4.68665
Epoch 28, Val Loss: 4.71153
Epoch 29, Val Loss: 4.65441
Epoch 30, Val Loss: 4.69615
Epoch 31, Val Loss: 4.79510
Epoch 32, Val Loss: 4.74074
Epoch 33, Val Loss: 4.82079
Epoch 34, Val Loss: 4.67782
Epoch 35, Val Loss: 4.66419
Epoch 36, Val Loss: 4.76537
Epoch 37, Val Loss: 4.66904
Epoch 38, Val Loss: 4.72325
Epoch 39, Val Loss: 4.79218
Epoch 40, Val Loss: 4.68842
Epoch 41, Val Loss: 4.70074
Epoch 42, Val Loss: 4.71505
Epoch 43, Val Loss: 4.60850
Epoch 44, Val Loss: 5.34313
Epoch 45, Val Loss: 4.72492
Epoch 46, Val Loss: 4.67333
Epoch 47, Val Loss: 4.81569
Epoch 48, Val Loss: 4.65936
Epoch 49, Val Loss: 4.66005
Epoch 50, Val Loss: 4.65229
Epoch 51, Val Loss: 4.64841
Epoch 52, Val Loss: 4.78725
Epoch 53, Val Loss: 4.66693
Epoch 54, Val Loss: 4.63933
Epoch 55, Val Loss: 4.66284
Epoch 56, Val Loss: 4.63951
Epoch 57, Val Loss: 4.95622
Epoch 58, Val Loss: 4.78726
Epoch 59, Val Loss: 4.61722
Epoch 60, Val Loss: 4.61159
Epoch 61, Val Loss: 4.62350
Epoch 62, Val Loss: 4.66054
Epoch 63, Val Loss: 4.61141
Epoch 64, Val Loss: 4.63477
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.55053781528496, 'MSE - std': 0.31317626248820934, 'R2 - mean': 0.5525389300026378, 'R2 - std': 0.013204578884087735} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.21708
Epoch 1, Val Loss: 9.25591
Epoch 2, Val Loss: 5.35778
Epoch 3, Val Loss: 5.45153
Epoch 4, Val Loss: 4.93514
Epoch 5, Val Loss: 4.82812
Epoch 6, Val Loss: 4.80297
Epoch 7, Val Loss: 4.88421
Epoch 8, Val Loss: 4.82964
Epoch 9, Val Loss: 4.76490
Epoch 10, Val Loss: 4.68861
Epoch 11, Val Loss: 4.77574
Epoch 12, Val Loss: 4.48013
Epoch 13, Val Loss: 4.51366
Epoch 14, Val Loss: 4.71138
Epoch 15, Val Loss: 4.58155
Epoch 16, Val Loss: 4.47256
Epoch 17, Val Loss: 4.38612
Epoch 18, Val Loss: 4.42835
Epoch 19, Val Loss: 4.29732
Epoch 20, Val Loss: 4.34921
Epoch 21, Val Loss: 4.40311
Epoch 22, Val Loss: 4.33648
Epoch 23, Val Loss: 4.40188
Epoch 24, Val Loss: 4.23245
Epoch 25, Val Loss: 4.33038
Epoch 26, Val Loss: 4.51790
Epoch 27, Val Loss: 4.34266
Epoch 28, Val Loss: 4.29160
Epoch 29, Val Loss: 4.40891
Epoch 30, Val Loss: 4.25107
Epoch 31, Val Loss: 4.15546
Epoch 32, Val Loss: 4.28242
Epoch 33, Val Loss: 4.30508
Epoch 34, Val Loss: 4.61901
Epoch 35, Val Loss: 4.17392
Epoch 36, Val Loss: 4.14231
Epoch 37, Val Loss: 4.24285
Epoch 38, Val Loss: 4.30470
Epoch 39, Val Loss: 4.24027
Epoch 40, Val Loss: 4.26259
Epoch 41, Val Loss: 4.30858
Epoch 42, Val Loss: 4.00865
Epoch 43, Val Loss: 4.17039
Epoch 44, Val Loss: 3.94477
Epoch 45, Val Loss: 4.19040
Epoch 46, Val Loss: 4.39648
Epoch 47, Val Loss: 4.03681
Epoch 48, Val Loss: 4.33193
Epoch 49, Val Loss: 4.40621
Epoch 50, Val Loss: 4.29631
Epoch 51, Val Loss: 3.95543
Epoch 52, Val Loss: 4.29368
Epoch 53, Val Loss: 4.76131
Epoch 54, Val Loss: 4.64838
Epoch 55, Val Loss: 3.97911
Epoch 56, Val Loss: 3.92290
Epoch 57, Val Loss: 3.82947
Epoch 58, Val Loss: 4.07754
Epoch 59, Val Loss: 4.12324
Epoch 60, Val Loss: 4.07336
Epoch 61, Val Loss: 4.08813
Epoch 62, Val Loss: 4.06635
Epoch 63, Val Loss: 3.86044
Epoch 64, Val Loss: 3.99985
Epoch 65, Val Loss: 3.90418
Epoch 66, Val Loss: 4.21069
Epoch 67, Val Loss: 4.38385
Epoch 68, Val Loss: 3.89180
Epoch 69, Val Loss: 4.16280
Epoch 70, Val Loss: 3.89425
Epoch 71, Val Loss: 3.94950
Epoch 72, Val Loss: 4.15778
Epoch 73, Val Loss: 3.93735
Epoch 74, Val Loss: 4.55877
Epoch 75, Val Loss: 3.96455
Epoch 76, Val Loss: 3.86140
Epoch 77, Val Loss: 4.10158
Epoch 78, Val Loss: 3.84243
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.4439056797136915, 'MSE - std': 0.32813223789964757, 'R2 - mean': 0.5541689054698107, 'R2 - std': 0.011778842799712027} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.66066
Epoch 1, Val Loss: 18.60268
Epoch 2, Val Loss: 8.89535
Epoch 3, Val Loss: 8.59761
Epoch 4, Val Loss: 7.84132
Epoch 5, Val Loss: 7.41236
Epoch 6, Val Loss: 7.41854
Epoch 7, Val Loss: 7.52518
Epoch 8, Val Loss: 7.42595
Epoch 9, Val Loss: 7.10924
Epoch 10, Val Loss: 7.05024
Epoch 11, Val Loss: 7.53596
Epoch 12, Val Loss: 7.21947
Epoch 13, Val Loss: 7.26913
Epoch 14, Val Loss: 7.00185
Epoch 15, Val Loss: 7.02825
Epoch 16, Val Loss: 7.16383
Epoch 17, Val Loss: 6.78888
Epoch 18, Val Loss: 6.88026
Epoch 19, Val Loss: 6.73245
Epoch 20, Val Loss: 6.70272
Epoch 21, Val Loss: 6.71345
Epoch 22, Val Loss: 6.92058
Epoch 23, Val Loss: 6.72294
Epoch 24, Val Loss: 6.70558
Epoch 25, Val Loss: 6.81602
Epoch 26, Val Loss: 6.62477
Epoch 27, Val Loss: 6.61368
Epoch 28, Val Loss: 6.42842
Epoch 29, Val Loss: 7.10711
Epoch 30, Val Loss: 6.31301
Epoch 31, Val Loss: 6.65853
Epoch 32, Val Loss: 6.38590
Epoch 33, Val Loss: 6.35113
Epoch 34, Val Loss: 6.27660
Epoch 35, Val Loss: 6.24890
Epoch 36, Val Loss: 6.90638
Epoch 37, Val Loss: 6.33289
Epoch 38, Val Loss: 6.57400
Epoch 39, Val Loss: 6.16783
Epoch 40, Val Loss: 6.07519
Epoch 41, Val Loss: 6.00212
Epoch 42, Val Loss: 6.12609
Epoch 43, Val Loss: 5.95203
Epoch 44, Val Loss: 6.15400
Epoch 45, Val Loss: 6.24784
Epoch 46, Val Loss: 6.07098
Epoch 47, Val Loss: 6.05206
Epoch 48, Val Loss: 5.82179
Epoch 49, Val Loss: 5.91469
Epoch 50, Val Loss: 5.95809
Epoch 51, Val Loss: 5.89420
Epoch 52, Val Loss: 6.07773
Epoch 53, Val Loss: 5.82589
Epoch 54, Val Loss: 5.98263
Epoch 55, Val Loss: 5.96943
Epoch 56, Val Loss: 6.24378
Epoch 57, Val Loss: 5.75230
Epoch 58, Val Loss: 5.76215
Epoch 59, Val Loss: 5.71314
Epoch 60, Val Loss: 5.72008
Epoch 61, Val Loss: 5.91021
Epoch 62, Val Loss: 5.79949
Epoch 63, Val Loss: 5.86781
Epoch 64, Val Loss: 6.07879
Epoch 65, Val Loss: 5.76796
Epoch 66, Val Loss: 6.28674
Epoch 67, Val Loss: 5.79500
Epoch 68, Val Loss: 6.11812
Epoch 69, Val Loss: 5.72710
Epoch 70, Val Loss: 6.00436
Epoch 71, Val Loss: 6.27306
Epoch 72, Val Loss: 6.06058
Epoch 73, Val Loss: 6.17444
Epoch 74, Val Loss: 5.67119
Epoch 75, Val Loss: 6.35101
Epoch 76, Val Loss: 5.97156
Epoch 77, Val Loss: 5.74789
Epoch 78, Val Loss: 6.03021
Epoch 79, Val Loss: 5.99900
Epoch 80, Val Loss: 5.74635
Epoch 81, Val Loss: 5.65711
Epoch 82, Val Loss: 5.96649
Epoch 83, Val Loss: 5.90798
Epoch 84, Val Loss: 5.81234
Epoch 85, Val Loss: 5.73765
Epoch 86, Val Loss: 5.55800
Epoch 87, Val Loss: 5.89060
Epoch 88, Val Loss: 5.64472
Epoch 89, Val Loss: 5.89577
Epoch 90, Val Loss: 6.36031
Epoch 91, Val Loss: 5.73054
Epoch 92, Val Loss: 6.29228
Epoch 93, Val Loss: 6.10459
Epoch 94, Val Loss: 5.92171
Epoch 95, Val Loss: 6.27677
Epoch 96, Val Loss: 6.43922
Epoch 97, Val Loss: 5.68763
Epoch 98, Val Loss: 5.77586
Epoch 99, Val Loss: 5.88935
DID NOT SAVE RESULTS
{'MSE - mean': 4.657824177866479, 'MSE - std': 0.5188266645489608, 'R2 - mean': 0.5521422120514217, 'R2 - std': 0.011288173236127639} 
 

Results After CV: {'MSE - mean': 4.657824177866479, 'MSE - std': 0.5188266645489608, 'R2 - mean': 0.5521422120514217, 'R2 - std': 0.011288173236127639}
Train time: 90.92759426699976
Inference time: 0.04862851580001006
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 30 finished with value: 4.657824177866479 and parameters: {'p_m': 0.6209023617608542, 'alpha': 1.993299849472653, 'K': 20, 'beta': 0.14704330641075236}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.95868
Epoch 1, Val Loss: 13.41970
Epoch 2, Val Loss: 6.92565
Epoch 3, Val Loss: 6.86987
Epoch 4, Val Loss: 7.35256
Epoch 5, Val Loss: 6.82243
Epoch 6, Val Loss: 7.24060
Epoch 7, Val Loss: 6.64827
Epoch 8, Val Loss: 6.56986
Epoch 9, Val Loss: 6.50412
Epoch 10, Val Loss: 6.44966
Epoch 11, Val Loss: 6.60101
Epoch 12, Val Loss: 6.55398
Epoch 13, Val Loss: 6.39720
Epoch 14, Val Loss: 6.30843
Epoch 15, Val Loss: 6.22252
Epoch 16, Val Loss: 6.19393
Epoch 17, Val Loss: 6.12017
Epoch 18, Val Loss: 6.20715
Epoch 19, Val Loss: 6.11473
Epoch 20, Val Loss: 6.28965
Epoch 21, Val Loss: 6.17985
Epoch 22, Val Loss: 6.04984
Epoch 23, Val Loss: 5.97339
Epoch 24, Val Loss: 6.16735
Epoch 25, Val Loss: 5.96392
Epoch 26, Val Loss: 5.93888
Epoch 27, Val Loss: 5.77664
Epoch 28, Val Loss: 5.84739
Epoch 29, Val Loss: 6.07815
Epoch 30, Val Loss: 5.83596
Epoch 31, Val Loss: 6.80649
Epoch 32, Val Loss: 5.72732
Epoch 33, Val Loss: 5.64816
Epoch 34, Val Loss: 5.57103
Epoch 35, Val Loss: 5.83879
Epoch 36, Val Loss: 5.56995
Epoch 37, Val Loss: 5.79467
Epoch 38, Val Loss: 5.66114
Epoch 39, Val Loss: 5.58959
Epoch 40, Val Loss: 5.54849
Epoch 41, Val Loss: 5.59092
Epoch 42, Val Loss: 5.86999
Epoch 43, Val Loss: 5.62491
Epoch 44, Val Loss: 5.96552
Epoch 45, Val Loss: 6.03599
Epoch 46, Val Loss: 5.58089
Epoch 47, Val Loss: 5.41636
Epoch 48, Val Loss: 5.21288
Epoch 49, Val Loss: 5.12579
Epoch 50, Val Loss: 5.47968
Epoch 51, Val Loss: 5.17937
Epoch 52, Val Loss: 5.38560
Epoch 53, Val Loss: 5.28516
Epoch 54, Val Loss: 5.32352
Epoch 55, Val Loss: 5.26653
Epoch 56, Val Loss: 5.30643
Epoch 57, Val Loss: 5.09131
Epoch 58, Val Loss: 5.42870
Epoch 59, Val Loss: 5.18867
Epoch 60, Val Loss: 5.05171
Epoch 61, Val Loss: 5.15044
Epoch 62, Val Loss: 5.10981
Epoch 63, Val Loss: 5.31833
Epoch 64, Val Loss: 5.05616
Epoch 65, Val Loss: 5.18946
Epoch 66, Val Loss: 5.25687
Epoch 67, Val Loss: 5.15574
Epoch 68, Val Loss: 5.20039
Epoch 69, Val Loss: 5.47538
Epoch 70, Val Loss: 5.08066
Epoch 71, Val Loss: 5.05328
Epoch 72, Val Loss: 4.99228
Epoch 73, Val Loss: 5.08686
Epoch 74, Val Loss: 4.96163
Epoch 75, Val Loss: 5.31634
Epoch 76, Val Loss: 5.13171
Epoch 77, Val Loss: 5.20360
Epoch 78, Val Loss: 4.91818
Epoch 79, Val Loss: 4.93432
Epoch 80, Val Loss: 5.17064
Epoch 81, Val Loss: 5.24100
Epoch 82, Val Loss: 5.17919
Epoch 83, Val Loss: 5.13904
Epoch 84, Val Loss: 5.42261
Epoch 85, Val Loss: 4.96159
Epoch 86, Val Loss: 4.94212
Epoch 87, Val Loss: 5.13467
Epoch 88, Val Loss: 4.95553
Epoch 89, Val Loss: 5.07542
Epoch 90, Val Loss: 5.21485
Epoch 91, Val Loss: 5.67993
Epoch 92, Val Loss: 4.98240
Epoch 93, Val Loss: 5.17152
Epoch 94, Val Loss: 5.00649
Epoch 95, Val Loss: 4.86147
Epoch 96, Val Loss: 4.87618
Epoch 97, Val Loss: 5.00971
Epoch 98, Val Loss: 4.91239
Epoch 99, Val Loss: 4.94812
DID NOT SAVE RESULTS
{'MSE - mean': 4.986608763949854, 'MSE - std': 0.0, 'R2 - mean': 0.5452377581939509, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.03162
Epoch 1, Val Loss: 16.91632
Epoch 2, Val Loss: 6.49572
Epoch 3, Val Loss: 5.81778
Epoch 4, Val Loss: 5.53114
Epoch 5, Val Loss: 5.50383
Epoch 6, Val Loss: 5.45531
Epoch 7, Val Loss: 5.33358
Epoch 8, Val Loss: 5.00050
Epoch 9, Val Loss: 4.99265
Epoch 10, Val Loss: 4.99565
Epoch 11, Val Loss: 4.95276
Epoch 12, Val Loss: 5.76051
Epoch 13, Val Loss: 4.96246
Epoch 14, Val Loss: 5.04346
Epoch 15, Val Loss: 5.06499
Epoch 16, Val Loss: 5.63181
Epoch 17, Val Loss: 5.11876
Epoch 18, Val Loss: 4.81531
Epoch 19, Val Loss: 5.23258
Epoch 20, Val Loss: 4.75005
Epoch 21, Val Loss: 4.84712
Epoch 22, Val Loss: 4.81754
Epoch 23, Val Loss: 4.75282
Epoch 24, Val Loss: 4.72570
Epoch 25, Val Loss: 4.81758
Epoch 26, Val Loss: 5.03742
Epoch 27, Val Loss: 5.05877
Epoch 28, Val Loss: 4.78558
Epoch 29, Val Loss: 4.68979
Epoch 30, Val Loss: 4.83759
Epoch 31, Val Loss: 4.76853
Epoch 32, Val Loss: 4.55787
Epoch 33, Val Loss: 4.56761
Epoch 34, Val Loss: 4.74260
Epoch 35, Val Loss: 4.70958
Epoch 36, Val Loss: 4.53908
Epoch 37, Val Loss: 4.49793
Epoch 38, Val Loss: 4.44878
Epoch 39, Val Loss: 4.76072
Epoch 40, Val Loss: 4.30285
Epoch 41, Val Loss: 4.51515
Epoch 42, Val Loss: 4.36218
Epoch 43, Val Loss: 4.53439
Epoch 44, Val Loss: 4.38241
Epoch 45, Val Loss: 4.33009
Epoch 46, Val Loss: 4.21990
Epoch 47, Val Loss: 4.25298
Epoch 48, Val Loss: 4.34146
Epoch 49, Val Loss: 4.21264
Epoch 50, Val Loss: 4.30749
Epoch 51, Val Loss: 4.27162
Epoch 52, Val Loss: 4.29116
Epoch 53, Val Loss: 4.33058
Epoch 54, Val Loss: 4.66426
Epoch 55, Val Loss: 4.26900
Epoch 56, Val Loss: 4.37644
Epoch 57, Val Loss: 4.62856
Epoch 58, Val Loss: 4.31849
Epoch 59, Val Loss: 4.44603
Epoch 60, Val Loss: 4.14470
Epoch 61, Val Loss: 4.27120
Epoch 62, Val Loss: 4.25896
Epoch 63, Val Loss: 4.07938
Epoch 64, Val Loss: 4.42060
Epoch 65, Val Loss: 4.16655
Epoch 66, Val Loss: 4.11379
Epoch 67, Val Loss: 4.08024
Epoch 68, Val Loss: 4.04158
Epoch 69, Val Loss: 4.40000
Epoch 70, Val Loss: 4.09429
Epoch 71, Val Loss: 4.34727
Epoch 72, Val Loss: 4.13775
Epoch 73, Val Loss: 4.37906
Epoch 74, Val Loss: 4.21506
Epoch 75, Val Loss: 4.12112
Epoch 76, Val Loss: 4.17744
Epoch 77, Val Loss: 4.18586
Epoch 78, Val Loss: 4.17652
Epoch 79, Val Loss: 4.41979
Epoch 80, Val Loss: 4.11413
Epoch 81, Val Loss: 4.18832
Epoch 82, Val Loss: 4.26129
Epoch 83, Val Loss: 4.13986
Epoch 84, Val Loss: 4.03297
Epoch 85, Val Loss: 4.13050
Epoch 86, Val Loss: 4.46164
Epoch 87, Val Loss: 4.47856
Epoch 88, Val Loss: 4.19622
Epoch 89, Val Loss: 4.41605
Epoch 90, Val Loss: 4.21856
Epoch 91, Val Loss: 4.47806
Epoch 92, Val Loss: 4.20721
Epoch 93, Val Loss: 4.35884
Epoch 94, Val Loss: 4.31088
Epoch 95, Val Loss: 3.99694
Epoch 96, Val Loss: 4.34389
Epoch 97, Val Loss: 4.07894
Epoch 98, Val Loss: 4.06738
Epoch 99, Val Loss: 4.11864
DID NOT SAVE RESULTS
{'MSE - mean': 4.5761614508042525, 'MSE - std': 0.41044731314560146, 'R2 - mean': 0.5505934727035945, 'R2 - std': 0.005355714509643561} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.83167
Epoch 1, Val Loss: 10.48877
Epoch 2, Val Loss: 7.10095
Epoch 3, Val Loss: 6.67402
Epoch 4, Val Loss: 6.61264
Epoch 5, Val Loss: 6.40931
Epoch 6, Val Loss: 6.64476
Epoch 7, Val Loss: 6.62308
Epoch 8, Val Loss: 6.28648
Epoch 9, Val Loss: 6.43393
Epoch 10, Val Loss: 6.13524
Epoch 11, Val Loss: 6.23982
Epoch 12, Val Loss: 6.17218
Epoch 13, Val Loss: 6.05445
Epoch 14, Val Loss: 6.32573
Epoch 15, Val Loss: 6.13082
Epoch 16, Val Loss: 5.91357
Epoch 17, Val Loss: 6.10525
Epoch 18, Val Loss: 5.96258
Epoch 19, Val Loss: 6.06154
Epoch 20, Val Loss: 5.83375
Epoch 21, Val Loss: 5.98882
Epoch 22, Val Loss: 5.79438
Epoch 23, Val Loss: 5.99414
Epoch 24, Val Loss: 5.90979
Epoch 25, Val Loss: 5.74745
Epoch 26, Val Loss: 5.87512
Epoch 27, Val Loss: 5.61245
Epoch 28, Val Loss: 5.59586
Epoch 29, Val Loss: 5.72392
Epoch 30, Val Loss: 5.73391
Epoch 31, Val Loss: 5.77723
Epoch 32, Val Loss: 5.82820
Epoch 33, Val Loss: 5.51830
Epoch 34, Val Loss: 5.51305
Epoch 35, Val Loss: 5.46722
Epoch 36, Val Loss: 5.73977
Epoch 37, Val Loss: 5.54341
Epoch 38, Val Loss: 5.38213
Epoch 39, Val Loss: 5.42067
Epoch 40, Val Loss: 5.52488
Epoch 41, Val Loss: 5.28938
Epoch 42, Val Loss: 5.30990
Epoch 43, Val Loss: 5.27936
Epoch 44, Val Loss: 5.29350
Epoch 45, Val Loss: 5.50875
Epoch 46, Val Loss: 5.31150
Epoch 47, Val Loss: 5.10698
Epoch 48, Val Loss: 5.21074
Epoch 49, Val Loss: 5.10204
Epoch 50, Val Loss: 5.25268
Epoch 51, Val Loss: 5.09960
Epoch 52, Val Loss: 5.21074
Epoch 53, Val Loss: 5.10730
Epoch 54, Val Loss: 5.14365
Epoch 55, Val Loss: 5.49202
Epoch 56, Val Loss: 5.07547
Epoch 57, Val Loss: 5.01960
Epoch 58, Val Loss: 5.29460
Epoch 59, Val Loss: 5.50419
Epoch 60, Val Loss: 5.10775
Epoch 61, Val Loss: 5.03823
Epoch 62, Val Loss: 4.82944
Epoch 63, Val Loss: 4.85785
Epoch 64, Val Loss: 5.04893
Epoch 65, Val Loss: 4.88679
Epoch 66, Val Loss: 4.99346
Epoch 67, Val Loss: 4.87600
Epoch 68, Val Loss: 5.10344
Epoch 69, Val Loss: 4.94680
Epoch 70, Val Loss: 4.81119
Epoch 71, Val Loss: 5.14383
Epoch 72, Val Loss: 4.92223
Epoch 73, Val Loss: 4.91558
Epoch 74, Val Loss: 4.98893
Epoch 75, Val Loss: 5.18908
Epoch 76, Val Loss: 4.76168
Epoch 77, Val Loss: 5.09927
Epoch 78, Val Loss: 5.45301
Epoch 79, Val Loss: 4.85749
Epoch 80, Val Loss: 5.26647
Epoch 81, Val Loss: 4.69657
Epoch 82, Val Loss: 4.73203
Epoch 83, Val Loss: 4.97302
Epoch 84, Val Loss: 4.91224
Epoch 85, Val Loss: 5.02702
Epoch 86, Val Loss: 4.82580
Epoch 87, Val Loss: 4.92226
Epoch 88, Val Loss: 4.86551
Epoch 89, Val Loss: 4.99040
Epoch 90, Val Loss: 4.92607
Epoch 91, Val Loss: 5.08064
Epoch 92, Val Loss: 5.08291
Epoch 93, Val Loss: 4.94895
Epoch 94, Val Loss: 4.73765
Epoch 95, Val Loss: 4.88266
Epoch 96, Val Loss: 5.02834
Epoch 97, Val Loss: 4.86013
Epoch 98, Val Loss: 4.76537
Epoch 99, Val Loss: 5.13197
DID NOT SAVE RESULTS
{'MSE - mean': 4.660976667819953, 'MSE - std': 0.35594743055747674, 'R2 - mean': 0.5419538392837873, 'R2 - std': 0.012977248675913709} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.49596
Epoch 1, Val Loss: 10.50591
Epoch 2, Val Loss: 6.20859
Epoch 3, Val Loss: 5.70325
Epoch 4, Val Loss: 5.41504
Epoch 5, Val Loss: 5.48811
Epoch 6, Val Loss: 5.29591
Epoch 7, Val Loss: 5.39229
Epoch 8, Val Loss: 5.02229
Epoch 9, Val Loss: 4.98697
Epoch 10, Val Loss: 4.88009
Epoch 11, Val Loss: 4.85770
Epoch 12, Val Loss: 4.86878
Epoch 13, Val Loss: 4.80441
Epoch 14, Val Loss: 4.96264
Epoch 15, Val Loss: 4.78264
Epoch 16, Val Loss: 4.65255
Epoch 17, Val Loss: 5.01112
Epoch 18, Val Loss: 4.72314
Epoch 19, Val Loss: 4.71577
Epoch 20, Val Loss: 4.59711
Epoch 21, Val Loss: 4.71159
Epoch 22, Val Loss: 4.52828
Epoch 23, Val Loss: 4.60386
Epoch 24, Val Loss: 4.64342
Epoch 25, Val Loss: 4.41051
Epoch 26, Val Loss: 4.45193
Epoch 27, Val Loss: 4.54458
Epoch 28, Val Loss: 4.50773
Epoch 29, Val Loss: 4.56652
Epoch 30, Val Loss: 5.03613
Epoch 31, Val Loss: 4.34005
Epoch 32, Val Loss: 4.52362
Epoch 33, Val Loss: 4.28627
Epoch 34, Val Loss: 4.29741
Epoch 35, Val Loss: 4.36428
Epoch 36, Val Loss: 4.30778
Epoch 37, Val Loss: 4.24541
Epoch 38, Val Loss: 4.29545
Epoch 39, Val Loss: 4.37728
Epoch 40, Val Loss: 4.24834
Epoch 41, Val Loss: 4.67141
Epoch 42, Val Loss: 4.20015
Epoch 43, Val Loss: 4.23581
Epoch 44, Val Loss: 4.30596
Epoch 45, Val Loss: 4.31150
Epoch 46, Val Loss: 4.40679
Epoch 47, Val Loss: 4.50320
Epoch 48, Val Loss: 4.20068
Epoch 49, Val Loss: 4.13753
Epoch 50, Val Loss: 4.29453
Epoch 51, Val Loss: 4.38705
Epoch 52, Val Loss: 4.17098
Epoch 53, Val Loss: 4.15188
Epoch 54, Val Loss: 4.33477
Epoch 55, Val Loss: 4.13093
Epoch 56, Val Loss: 4.72325
Epoch 57, Val Loss: 4.08436
Epoch 58, Val Loss: 4.17695
Epoch 59, Val Loss: 4.18636
Epoch 60, Val Loss: 4.22034
Epoch 61, Val Loss: 4.78096
Epoch 62, Val Loss: 4.59333
Epoch 63, Val Loss: 4.60770
Epoch 64, Val Loss: 4.39123
Epoch 65, Val Loss: 4.17924
Epoch 66, Val Loss: 4.20868
Epoch 67, Val Loss: 4.51565
Epoch 68, Val Loss: 4.26894
Epoch 69, Val Loss: 4.19889
Epoch 70, Val Loss: 4.53703
Epoch 71, Val Loss: 4.16054
Epoch 72, Val Loss: 4.05570
Epoch 73, Val Loss: 4.14223
Epoch 74, Val Loss: 4.19419
Epoch 75, Val Loss: 4.48006
Epoch 76, Val Loss: 4.07988
Epoch 77, Val Loss: 4.22407
Epoch 78, Val Loss: 4.58155
Epoch 79, Val Loss: 4.09882
Epoch 80, Val Loss: 4.13690
Epoch 81, Val Loss: 4.13151
Epoch 82, Val Loss: 4.20956
Epoch 83, Val Loss: 4.91718
Epoch 84, Val Loss: 4.15018
Epoch 85, Val Loss: 4.19868
Epoch 86, Val Loss: 4.23267
Epoch 87, Val Loss: 4.15673
Epoch 88, Val Loss: 4.27876
Epoch 89, Val Loss: 4.33657
Epoch 90, Val Loss: 4.08131
Epoch 91, Val Loss: 4.11095
Epoch 92, Val Loss: 4.34359
Epoch 93, Val Loss: 4.19111
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.589479148244177, 'MSE - std': 0.3322041780393766, 'R2 - mean': 0.5395214318607564, 'R2 - std': 0.012002356227517335} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.06599
Epoch 1, Val Loss: 15.76761
Epoch 2, Val Loss: 7.91149
Epoch 3, Val Loss: 7.30303
Epoch 4, Val Loss: 7.20397
Epoch 5, Val Loss: 7.29348
Epoch 6, Val Loss: 7.15317
Epoch 7, Val Loss: 7.27360
Epoch 8, Val Loss: 6.87903
Epoch 9, Val Loss: 6.90008
Epoch 10, Val Loss: 6.98052
Epoch 11, Val Loss: 7.05831
Epoch 12, Val Loss: 6.89819
Epoch 13, Val Loss: 6.89322
Epoch 14, Val Loss: 6.84756
Epoch 15, Val Loss: 6.67087
Epoch 16, Val Loss: 6.83069
Epoch 17, Val Loss: 6.68293
Epoch 18, Val Loss: 6.73861
Epoch 19, Val Loss: 6.72212
Epoch 20, Val Loss: 7.05883
Epoch 21, Val Loss: 6.74571
Epoch 22, Val Loss: 6.68204
Epoch 23, Val Loss: 6.70178
Epoch 24, Val Loss: 6.86263
Epoch 25, Val Loss: 6.57834
Epoch 26, Val Loss: 6.48928
Epoch 27, Val Loss: 6.55399
Epoch 28, Val Loss: 6.70145
Epoch 29, Val Loss: 6.80983
Epoch 30, Val Loss: 6.47987
Epoch 31, Val Loss: 6.45599
Epoch 32, Val Loss: 6.71507
Epoch 33, Val Loss: 6.51146
Epoch 34, Val Loss: 6.69537
Epoch 35, Val Loss: 6.43143
Epoch 36, Val Loss: 6.69822
Epoch 37, Val Loss: 6.48768
Epoch 38, Val Loss: 6.51857
Epoch 39, Val Loss: 6.55781
Epoch 40, Val Loss: 6.56886
Epoch 41, Val Loss: 6.57592
Epoch 42, Val Loss: 6.18290
Epoch 43, Val Loss: 6.56449
Epoch 44, Val Loss: 6.69766
Epoch 45, Val Loss: 6.55898
Epoch 46, Val Loss: 6.31968
Epoch 47, Val Loss: 6.43615
Epoch 48, Val Loss: 6.25248
Epoch 49, Val Loss: 6.24491
Epoch 50, Val Loss: 6.53760
Epoch 51, Val Loss: 6.18736
Epoch 52, Val Loss: 6.53781
Epoch 53, Val Loss: 6.38587
Epoch 54, Val Loss: 6.17074
Epoch 55, Val Loss: 6.11495
Epoch 56, Val Loss: 6.21866
Epoch 57, Val Loss: 6.23210
Epoch 58, Val Loss: 6.63977
Epoch 59, Val Loss: 6.42260
Epoch 60, Val Loss: 6.24700
Epoch 61, Val Loss: 6.21499
Epoch 62, Val Loss: 6.27564
Epoch 63, Val Loss: 6.13585
Epoch 64, Val Loss: 6.32134
Epoch 65, Val Loss: 6.09355
Epoch 66, Val Loss: 6.12531
Epoch 67, Val Loss: 6.05482
Epoch 68, Val Loss: 6.14332
Epoch 69, Val Loss: 6.02139
Epoch 70, Val Loss: 6.26630
Epoch 71, Val Loss: 6.15831
Epoch 72, Val Loss: 6.47826
Epoch 73, Val Loss: 6.05071
Epoch 74, Val Loss: 6.21074
Epoch 75, Val Loss: 6.52797
Epoch 76, Val Loss: 6.31667
Epoch 77, Val Loss: 6.04716
Epoch 78, Val Loss: 6.12905
Epoch 79, Val Loss: 6.38014
Epoch 80, Val Loss: 6.30610
Epoch 81, Val Loss: 6.37506
Epoch 82, Val Loss: 6.13863
Epoch 83, Val Loss: 5.97235
Epoch 84, Val Loss: 6.13915
Epoch 85, Val Loss: 6.21396
Epoch 86, Val Loss: 5.97641
Epoch 87, Val Loss: 6.17217
Epoch 88, Val Loss: 6.11042
Epoch 89, Val Loss: 6.47421
Epoch 90, Val Loss: 6.05738
Epoch 91, Val Loss: 5.95425
Epoch 92, Val Loss: 5.95539
Epoch 93, Val Loss: 6.19102
Epoch 94, Val Loss: 6.08272
Epoch 95, Val Loss: 5.93930
Epoch 96, Val Loss: 6.51671
Epoch 97, Val Loss: 6.19434
Epoch 98, Val Loss: 6.22778
Epoch 99, Val Loss: 6.05306
DID NOT SAVE RESULTS
{'MSE - mean': 4.8551747521201145, 'MSE - std': 0.6088220662898567, 'R2 - mean': 0.5337345068370564, 'R2 - std': 0.015786046019490938} 
 

Results After CV: {'MSE - mean': 4.8551747521201145, 'MSE - std': 0.6088220662898567, 'R2 - mean': 0.5337345068370564, 'R2 - std': 0.015786046019490938}
Train time: 110.88886019619986
Inference time: 0.05109521939975821
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 31 finished with value: 4.8551747521201145 and parameters: {'p_m': 0.49321175783473786, 'alpha': 2.886761291738063, 'K': 20, 'beta': 0.7625017368291537}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.94225
Epoch 1, Val Loss: 10.41655
Epoch 2, Val Loss: 7.70039
Epoch 3, Val Loss: 7.38242
Epoch 4, Val Loss: 6.92352
Epoch 5, Val Loss: 6.78608
Epoch 6, Val Loss: 6.61859
Epoch 7, Val Loss: 6.60816
Epoch 8, Val Loss: 6.38181
Epoch 9, Val Loss: 6.23614
Epoch 10, Val Loss: 6.40727
Epoch 11, Val Loss: 6.11865
Epoch 12, Val Loss: 6.10082
Epoch 13, Val Loss: 5.88334
Epoch 14, Val Loss: 5.91495
Epoch 15, Val Loss: 5.78561
Epoch 16, Val Loss: 5.78049
Epoch 17, Val Loss: 5.46370
Epoch 18, Val Loss: 5.39067
Epoch 19, Val Loss: 5.38490
Epoch 20, Val Loss: 5.42922
Epoch 21, Val Loss: 5.37851
Epoch 22, Val Loss: 5.22331
Epoch 23, Val Loss: 5.15683
Epoch 24, Val Loss: 5.34619
Epoch 25, Val Loss: 5.16459
Epoch 26, Val Loss: 5.07631
Epoch 27, Val Loss: 5.01201
Epoch 28, Val Loss: 5.11068
Epoch 29, Val Loss: 5.60049
Epoch 30, Val Loss: 5.02063
Epoch 31, Val Loss: 4.91130
Epoch 32, Val Loss: 4.95810
Epoch 33, Val Loss: 4.87856
Epoch 34, Val Loss: 5.20391
Epoch 35, Val Loss: 4.81586
Epoch 36, Val Loss: 4.94078
Epoch 37, Val Loss: 5.00794
Epoch 38, Val Loss: 5.06683
Epoch 39, Val Loss: 4.96019
Epoch 40, Val Loss: 4.96214
Epoch 41, Val Loss: 4.67218
Epoch 42, Val Loss: 4.86184
Epoch 43, Val Loss: 5.21453
Epoch 44, Val Loss: 4.69395
Epoch 45, Val Loss: 4.90670
Epoch 46, Val Loss: 4.88648
Epoch 47, Val Loss: 5.71548
Epoch 48, Val Loss: 4.70865
Epoch 49, Val Loss: 4.90255
Epoch 50, Val Loss: 4.67737
Epoch 51, Val Loss: 5.43121
Epoch 52, Val Loss: 4.90423
Epoch 53, Val Loss: 4.78190
Epoch 54, Val Loss: 4.71771
Epoch 55, Val Loss: 4.67566
Epoch 56, Val Loss: 4.78277
Epoch 57, Val Loss: 4.81395
Epoch 58, Val Loss: 4.87265
Epoch 59, Val Loss: 4.62142
Epoch 60, Val Loss: 4.57727
Epoch 61, Val Loss: 4.88499
Epoch 62, Val Loss: 4.67777
Epoch 63, Val Loss: 4.56590
Epoch 64, Val Loss: 4.73273
Epoch 65, Val Loss: 4.93262
Epoch 66, Val Loss: 4.59005
Epoch 67, Val Loss: 4.72832
Epoch 68, Val Loss: 5.03171
Epoch 69, Val Loss: 4.95412
Epoch 70, Val Loss: 4.70466
Epoch 71, Val Loss: 4.64172
Epoch 72, Val Loss: 4.70270
Epoch 73, Val Loss: 4.75723
Epoch 74, Val Loss: 4.85573
Epoch 75, Val Loss: 5.04482
Epoch 76, Val Loss: 4.97116
Epoch 77, Val Loss: 4.62880
Epoch 78, Val Loss: 4.76341
Epoch 79, Val Loss: 4.74358
Epoch 80, Val Loss: 4.56658
Epoch 81, Val Loss: 5.27359
Epoch 82, Val Loss: 4.80957
Epoch 83, Val Loss: 4.82780
Epoch 84, Val Loss: 4.62559
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.707047077827807, 'MSE - std': 0.0, 'R2 - mean': 0.5707328602005579, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.61232
Epoch 1, Val Loss: 11.00723
Epoch 2, Val Loss: 5.69364
Epoch 3, Val Loss: 5.49908
Epoch 4, Val Loss: 5.42790
Epoch 5, Val Loss: 5.54433
Epoch 6, Val Loss: 5.55694
Epoch 7, Val Loss: 5.33430
Epoch 8, Val Loss: 5.41093
Epoch 9, Val Loss: 5.18808
Epoch 10, Val Loss: 5.37220
Epoch 11, Val Loss: 5.27441
Epoch 12, Val Loss: 5.16514
Epoch 13, Val Loss: 5.05260
Epoch 14, Val Loss: 5.88009
Epoch 15, Val Loss: 5.05391
Epoch 16, Val Loss: 5.19744
Epoch 17, Val Loss: 5.18955
Epoch 18, Val Loss: 5.08037
Epoch 19, Val Loss: 5.07890
Epoch 20, Val Loss: 5.10220
Epoch 21, Val Loss: 5.12254
Epoch 22, Val Loss: 4.94713
Epoch 23, Val Loss: 4.81949
Epoch 24, Val Loss: 4.81860
Epoch 25, Val Loss: 4.82348
Epoch 26, Val Loss: 4.75613
Epoch 27, Val Loss: 4.68019
Epoch 28, Val Loss: 4.85106
Epoch 29, Val Loss: 4.66944
Epoch 30, Val Loss: 4.65414
Epoch 31, Val Loss: 5.04856
Epoch 32, Val Loss: 4.76406
Epoch 33, Val Loss: 5.93634
Epoch 34, Val Loss: 4.59323
Epoch 35, Val Loss: 4.55573
Epoch 36, Val Loss: 4.65647
Epoch 37, Val Loss: 4.51835
Epoch 38, Val Loss: 4.58667
Epoch 39, Val Loss: 4.42933
Epoch 40, Val Loss: 4.45092
Epoch 41, Val Loss: 4.55375
Epoch 42, Val Loss: 4.42136
Epoch 43, Val Loss: 4.40679
Epoch 44, Val Loss: 4.40640
Epoch 45, Val Loss: 4.30455
Epoch 46, Val Loss: 4.35974
Epoch 47, Val Loss: 4.27284
Epoch 48, Val Loss: 5.23871
Epoch 49, Val Loss: 5.00836
Epoch 50, Val Loss: 4.21869
Epoch 51, Val Loss: 4.26499
Epoch 52, Val Loss: 4.41662
Epoch 53, Val Loss: 4.33185
Epoch 54, Val Loss: 4.37403
Epoch 55, Val Loss: 4.17734
Epoch 56, Val Loss: 4.25145
Epoch 57, Val Loss: 4.35441
Epoch 58, Val Loss: 4.36974
Epoch 59, Val Loss: 4.22641
Epoch 60, Val Loss: 4.47993
Epoch 61, Val Loss: 4.26402
Epoch 62, Val Loss: 4.14155
Epoch 63, Val Loss: 4.82905
Epoch 64, Val Loss: 4.23244
Epoch 65, Val Loss: 4.12115
Epoch 66, Val Loss: 4.21670
Epoch 67, Val Loss: 4.11842
Epoch 68, Val Loss: 4.16122
Epoch 69, Val Loss: 4.48788
Epoch 70, Val Loss: 4.31367
Epoch 71, Val Loss: 5.33252
Epoch 72, Val Loss: 4.37784
Epoch 73, Val Loss: 4.04821
Epoch 74, Val Loss: 4.55947
Epoch 75, Val Loss: 4.69318
Epoch 76, Val Loss: 4.34623
Epoch 77, Val Loss: 4.18827
Epoch 78, Val Loss: 4.21707
Epoch 79, Val Loss: 4.04037
Epoch 80, Val Loss: 4.40539
Epoch 81, Val Loss: 4.86445
Epoch 82, Val Loss: 4.58437
Epoch 83, Val Loss: 4.21141
Epoch 84, Val Loss: 4.06735
Epoch 85, Val Loss: 4.17067
Epoch 86, Val Loss: 4.01470
Epoch 87, Val Loss: 4.20879
Epoch 88, Val Loss: 4.05674
Epoch 89, Val Loss: 4.33941
Epoch 90, Val Loss: 4.13938
Epoch 91, Val Loss: 4.20858
Epoch 92, Val Loss: 4.01480
Epoch 93, Val Loss: 4.33293
Epoch 94, Val Loss: 4.21079
Epoch 95, Val Loss: 3.97495
Epoch 96, Val Loss: 4.14689
Epoch 97, Val Loss: 4.01673
Epoch 98, Val Loss: 4.45934
Epoch 99, Val Loss: 4.50970
DID NOT SAVE RESULTS
{'MSE - mean': 4.4119573249517785, 'MSE - std': 0.2950897528760281, 'R2 - mean': 0.5659444617288262, 'R2 - std': 0.004788398471731736} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.53194
Epoch 1, Val Loss: 10.61139
Epoch 2, Val Loss: 7.04685
Epoch 3, Val Loss: 6.31598
Epoch 4, Val Loss: 6.07608
Epoch 5, Val Loss: 5.89203
Epoch 6, Val Loss: 5.84668
Epoch 7, Val Loss: 5.79895
Epoch 8, Val Loss: 5.81934
Epoch 9, Val Loss: 5.61375
Epoch 10, Val Loss: 5.59247
Epoch 11, Val Loss: 5.49478
Epoch 12, Val Loss: 5.46956
Epoch 13, Val Loss: 5.44455
Epoch 14, Val Loss: 5.56513
Epoch 15, Val Loss: 5.47505
Epoch 16, Val Loss: 5.33536
Epoch 17, Val Loss: 5.36718
Epoch 18, Val Loss: 5.50327
Epoch 19, Val Loss: 5.45871
Epoch 20, Val Loss: 5.37204
Epoch 21, Val Loss: 5.68812
Epoch 22, Val Loss: 5.38829
Epoch 23, Val Loss: 5.67163
Epoch 24, Val Loss: 5.34941
Epoch 25, Val Loss: 5.20722
Epoch 26, Val Loss: 5.22326
Epoch 27, Val Loss: 5.10447
Epoch 28, Val Loss: 5.31954
Epoch 29, Val Loss: 5.07614
Epoch 30, Val Loss: 5.71576
Epoch 31, Val Loss: 4.99207
Epoch 32, Val Loss: 5.17987
Epoch 33, Val Loss: 4.94623
Epoch 34, Val Loss: 4.85685
Epoch 35, Val Loss: 4.82139
Epoch 36, Val Loss: 4.95899
Epoch 37, Val Loss: 4.75603
Epoch 38, Val Loss: 4.86776
Epoch 39, Val Loss: 4.71556
Epoch 40, Val Loss: 4.72740
Epoch 41, Val Loss: 4.84402
Epoch 42, Val Loss: 5.05465
Epoch 43, Val Loss: 4.69851
Epoch 44, Val Loss: 4.84365
Epoch 45, Val Loss: 4.63110
Epoch 46, Val Loss: 5.00916
Epoch 47, Val Loss: 4.63681
Epoch 48, Val Loss: 4.71679
Epoch 49, Val Loss: 4.71944
Epoch 50, Val Loss: 4.65208
Epoch 51, Val Loss: 4.58577
Epoch 52, Val Loss: 5.05205
Epoch 53, Val Loss: 5.08608
Epoch 54, Val Loss: 4.76829
Epoch 55, Val Loss: 4.62489
Epoch 56, Val Loss: 4.85729
Epoch 57, Val Loss: 4.61197
Epoch 58, Val Loss: 4.78246
Epoch 59, Val Loss: 4.57215
Epoch 60, Val Loss: 4.58721
Epoch 61, Val Loss: 4.64479
Epoch 62, Val Loss: 4.56878
Epoch 63, Val Loss: 4.59875
Epoch 64, Val Loss: 4.62772
Epoch 65, Val Loss: 4.67491
Epoch 66, Val Loss: 4.58170
Epoch 67, Val Loss: 5.33080
Epoch 68, Val Loss: 4.68912
Epoch 69, Val Loss: 4.63439
Epoch 70, Val Loss: 4.83528
Epoch 71, Val Loss: 4.56085
Epoch 72, Val Loss: 4.59622
Epoch 73, Val Loss: 4.70403
Epoch 74, Val Loss: 4.80268
Epoch 75, Val Loss: 4.71387
Epoch 76, Val Loss: 4.54304
Epoch 77, Val Loss: 4.55978
Epoch 78, Val Loss: 4.68131
Epoch 79, Val Loss: 4.87938
Epoch 80, Val Loss: 4.77764
Epoch 81, Val Loss: 4.82018
Epoch 82, Val Loss: 4.75882
Epoch 83, Val Loss: 4.66935
Epoch 84, Val Loss: 4.62084
Epoch 85, Val Loss: 4.60982
Epoch 86, Val Loss: 4.77786
Epoch 87, Val Loss: 4.61941
Epoch 88, Val Loss: 4.53651
Epoch 89, Val Loss: 4.75604
Epoch 90, Val Loss: 4.75116
Epoch 91, Val Loss: 4.82528
Epoch 92, Val Loss: 4.61700
Epoch 93, Val Loss: 4.72372
Epoch 94, Val Loss: 4.54578
Epoch 95, Val Loss: 4.70291
Epoch 96, Val Loss: 4.65018
Epoch 97, Val Loss: 4.51205
Epoch 98, Val Loss: 4.68417
Epoch 99, Val Loss: 4.53115
DID NOT SAVE RESULTS
{'MSE - mean': 4.445297605022755, 'MSE - std': 0.24550992522783913, 'R2 - mean': 0.5626387223259764, 'R2 - std': 0.00609439627432403} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.99120
Epoch 1, Val Loss: 7.91623
Epoch 2, Val Loss: 5.43523
Epoch 3, Val Loss: 5.00433
Epoch 4, Val Loss: 4.98910
Epoch 5, Val Loss: 5.15851
Epoch 6, Val Loss: 4.89837
Epoch 7, Val Loss: 4.83494
Epoch 8, Val Loss: 4.83073
Epoch 9, Val Loss: 4.74534
Epoch 10, Val Loss: 4.75866
Epoch 11, Val Loss: 4.68905
Epoch 12, Val Loss: 4.67533
Epoch 13, Val Loss: 5.14677
Epoch 14, Val Loss: 4.72512
Epoch 15, Val Loss: 4.57317
Epoch 16, Val Loss: 4.93940
Epoch 17, Val Loss: 4.46144
Epoch 18, Val Loss: 4.64198
Epoch 19, Val Loss: 4.43183
Epoch 20, Val Loss: 4.44040
Epoch 21, Val Loss: 4.48229
Epoch 22, Val Loss: 4.51045
Epoch 23, Val Loss: 4.33179
Epoch 24, Val Loss: 4.29755
Epoch 25, Val Loss: 4.28227
Epoch 26, Val Loss: 4.25217
Epoch 27, Val Loss: 4.35952
Epoch 28, Val Loss: 4.31469
Epoch 29, Val Loss: 4.38370
Epoch 30, Val Loss: 4.25142
Epoch 31, Val Loss: 4.20998
Epoch 32, Val Loss: 4.25636
Epoch 33, Val Loss: 4.39841
Epoch 34, Val Loss: 4.24464
Epoch 35, Val Loss: 4.33631
Epoch 36, Val Loss: 4.67143
Epoch 37, Val Loss: 4.13532
Epoch 38, Val Loss: 4.14380
Epoch 39, Val Loss: 4.34511
Epoch 40, Val Loss: 4.28915
Epoch 41, Val Loss: 4.23051
Epoch 42, Val Loss: 4.12278
Epoch 43, Val Loss: 4.11423
Epoch 44, Val Loss: 4.17627
Epoch 45, Val Loss: 4.04042
Epoch 46, Val Loss: 4.06669
Epoch 47, Val Loss: 4.18051
Epoch 48, Val Loss: 4.22520
Epoch 49, Val Loss: 4.09483
Epoch 50, Val Loss: 4.37708
Epoch 51, Val Loss: 4.11825
Epoch 52, Val Loss: 4.13488
Epoch 53, Val Loss: 4.26313
Epoch 54, Val Loss: 4.27110
Epoch 55, Val Loss: 4.12047
Epoch 56, Val Loss: 4.21350
Epoch 57, Val Loss: 4.18821
Epoch 58, Val Loss: 4.12083
Epoch 59, Val Loss: 4.21886
Epoch 60, Val Loss: 4.04996
Epoch 61, Val Loss: 4.07374
Epoch 62, Val Loss: 4.29551
Epoch 63, Val Loss: 4.12436
Epoch 64, Val Loss: 3.99548
Epoch 65, Val Loss: 4.01005
Epoch 66, Val Loss: 4.00770
Epoch 67, Val Loss: 4.00776
Epoch 68, Val Loss: 4.09377
Epoch 69, Val Loss: 3.99702
Epoch 70, Val Loss: 3.98016
Epoch 71, Val Loss: 4.69831
Epoch 72, Val Loss: 4.23787
Epoch 73, Val Loss: 3.96585
Epoch 74, Val Loss: 4.19466
Epoch 75, Val Loss: 4.06669
Epoch 76, Val Loss: 3.98319
Epoch 77, Val Loss: 4.11681
Epoch 78, Val Loss: 4.11056
Epoch 79, Val Loss: 4.25690
Epoch 80, Val Loss: 4.04682
Epoch 81, Val Loss: 4.09684
Epoch 82, Val Loss: 3.97492
Epoch 83, Val Loss: 4.08943
Epoch 84, Val Loss: 4.30622
Epoch 85, Val Loss: 3.93814
Epoch 86, Val Loss: 4.01462
Epoch 87, Val Loss: 4.17501
Epoch 88, Val Loss: 3.99363
Epoch 89, Val Loss: 3.98969
Epoch 90, Val Loss: 4.05729
Epoch 91, Val Loss: 4.23058
Epoch 92, Val Loss: 3.99138
Epoch 93, Val Loss: 4.22616
Epoch 94, Val Loss: 4.06641
Epoch 95, Val Loss: 4.03880
Epoch 96, Val Loss: 4.04688
Epoch 97, Val Loss: 4.07762
Epoch 98, Val Loss: 4.07194
Epoch 99, Val Loss: 4.05676
DID NOT SAVE RESULTS
{'MSE - mean': 4.4087125283086035, 'MSE - std': 0.22185974410328552, 'R2 - mean': 0.5570673667635864, 'R2 - std': 0.010998920759288013} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 44.42133
Epoch 1, Val Loss: 19.94773
Epoch 2, Val Loss: 9.93867
Epoch 3, Val Loss: 8.96398
Epoch 4, Val Loss: 8.45913
Epoch 5, Val Loss: 7.65028
Epoch 6, Val Loss: 7.36297
Epoch 7, Val Loss: 7.34650
Epoch 8, Val Loss: 7.02264
Epoch 9, Val Loss: 6.89769
Epoch 10, Val Loss: 6.86808
Epoch 11, Val Loss: 7.04104
Epoch 12, Val Loss: 7.41058
Epoch 13, Val Loss: 6.93784
Epoch 14, Val Loss: 6.63424
Epoch 15, Val Loss: 6.82223
Epoch 16, Val Loss: 6.57354
Epoch 17, Val Loss: 6.50987
Epoch 18, Val Loss: 6.54318
Epoch 19, Val Loss: 6.47035
Epoch 20, Val Loss: 6.25602
Epoch 21, Val Loss: 6.52043
Epoch 22, Val Loss: 6.25634
Epoch 23, Val Loss: 6.42094
Epoch 24, Val Loss: 6.73910
Epoch 25, Val Loss: 6.27111
Epoch 26, Val Loss: 6.10108
Epoch 27, Val Loss: 6.50905
Epoch 28, Val Loss: 6.24455
Epoch 29, Val Loss: 6.39441
Epoch 30, Val Loss: 6.12367
Epoch 31, Val Loss: 6.30789
Epoch 32, Val Loss: 6.44450
Epoch 33, Val Loss: 6.17389
Epoch 34, Val Loss: 5.96946
Epoch 35, Val Loss: 6.01748
Epoch 36, Val Loss: 5.97168
Epoch 37, Val Loss: 6.24348
Epoch 38, Val Loss: 6.10310
Epoch 39, Val Loss: 6.39654
Epoch 40, Val Loss: 6.72831
Epoch 41, Val Loss: 6.05239
Epoch 42, Val Loss: 5.92601
Epoch 43, Val Loss: 6.16616
Epoch 44, Val Loss: 6.15533
Epoch 45, Val Loss: 6.07023
Epoch 46, Val Loss: 6.08053
Epoch 47, Val Loss: 6.18767
Epoch 48, Val Loss: 6.06417
Epoch 49, Val Loss: 6.06065
Epoch 50, Val Loss: 5.91398
Epoch 51, Val Loss: 5.78885
Epoch 52, Val Loss: 5.89414
Epoch 53, Val Loss: 5.80187
Epoch 54, Val Loss: 6.41798
Epoch 55, Val Loss: 5.85135
Epoch 56, Val Loss: 5.81719
Epoch 57, Val Loss: 5.90218
Epoch 58, Val Loss: 5.66746
Epoch 59, Val Loss: 6.04237
Epoch 60, Val Loss: 5.90920
Epoch 61, Val Loss: 6.04896
Epoch 62, Val Loss: 6.25190
Epoch 63, Val Loss: 5.63144
Epoch 64, Val Loss: 6.49132
Epoch 65, Val Loss: 5.71607
Epoch 66, Val Loss: 6.26737
Epoch 67, Val Loss: 5.68862
Epoch 68, Val Loss: 5.63600
Epoch 69, Val Loss: 5.86066
Epoch 70, Val Loss: 6.40599
Epoch 71, Val Loss: 5.95968
Epoch 72, Val Loss: 5.82611
Epoch 73, Val Loss: 5.68336
Epoch 74, Val Loss: 5.72083
Epoch 75, Val Loss: 5.69437
Epoch 76, Val Loss: 5.93174
Epoch 77, Val Loss: 5.92265
Epoch 78, Val Loss: 5.78206
Epoch 79, Val Loss: 5.92131
Epoch 80, Val Loss: 5.97785
Epoch 81, Val Loss: 5.99795
Epoch 82, Val Loss: 5.86823
Epoch 83, Val Loss: 5.80352
Epoch 84, Val Loss: 6.02173
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.646847999603783, 'MSE - std': 0.5159567884995494, 'R2 - mean': 0.5530403375439954, 'R2 - std': 0.012714120639550215} 
 

Results After CV: {'MSE - mean': 4.646847999603783, 'MSE - std': 0.5159567884995494, 'R2 - mean': 0.5530403375439954, 'R2 - std': 0.012714120639550215}
Train time: 106.57704151939978
Inference time: 0.05378839999993943
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 32 finished with value: 4.646847999603783 and parameters: {'p_m': 0.7147377085528585, 'alpha': 3.5340329031586233, 'K': 20, 'beta': 0.5312081891010202}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.35338
Epoch 1, Val Loss: 13.37121
Epoch 2, Val Loss: 7.48292
Epoch 3, Val Loss: 7.04334
Epoch 4, Val Loss: 6.53978
Epoch 5, Val Loss: 6.51684
Epoch 6, Val Loss: 6.39586
Epoch 7, Val Loss: 6.60976
Epoch 8, Val Loss: 6.74526
Epoch 9, Val Loss: 6.26128
Epoch 10, Val Loss: 6.29686
Epoch 11, Val Loss: 6.26442
Epoch 12, Val Loss: 6.02221
Epoch 13, Val Loss: 6.05434
Epoch 14, Val Loss: 6.03129
Epoch 15, Val Loss: 6.08170
Epoch 16, Val Loss: 5.88190
Epoch 17, Val Loss: 6.01708
Epoch 18, Val Loss: 5.98256
Epoch 19, Val Loss: 5.76304
Epoch 20, Val Loss: 5.64255
Epoch 21, Val Loss: 6.21282
Epoch 22, Val Loss: 5.58251
Epoch 23, Val Loss: 5.56653
Epoch 24, Val Loss: 5.54680
Epoch 25, Val Loss: 5.70850
Epoch 26, Val Loss: 5.61977
Epoch 27, Val Loss: 5.53061
Epoch 28, Val Loss: 5.41579
Epoch 29, Val Loss: 5.59291
Epoch 30, Val Loss: 5.26174
Epoch 31, Val Loss: 5.67965
Epoch 32, Val Loss: 5.34123
Epoch 33, Val Loss: 5.45655
Epoch 34, Val Loss: 5.54842
Epoch 35, Val Loss: 5.50934
Epoch 36, Val Loss: 5.32617
Epoch 37, Val Loss: 5.08194
Epoch 38, Val Loss: 5.22650
Epoch 39, Val Loss: 5.33863
Epoch 40, Val Loss: 5.34205
Epoch 41, Val Loss: 5.29174
Epoch 42, Val Loss: 5.05635
Epoch 43, Val Loss: 5.00973
Epoch 44, Val Loss: 5.23811
Epoch 45, Val Loss: 4.91341
Epoch 46, Val Loss: 5.15374
Epoch 47, Val Loss: 5.21943
Epoch 48, Val Loss: 5.08516
Epoch 49, Val Loss: 5.02839
Epoch 50, Val Loss: 5.02266
Epoch 51, Val Loss: 5.21188
Epoch 52, Val Loss: 5.27390
Epoch 53, Val Loss: 5.06031
Epoch 54, Val Loss: 5.17955
Epoch 55, Val Loss: 4.89903
Epoch 56, Val Loss: 5.08410
Epoch 57, Val Loss: 5.18972
Epoch 58, Val Loss: 4.92375
Epoch 59, Val Loss: 4.96023
Epoch 60, Val Loss: 4.80911
Epoch 61, Val Loss: 4.89703
Epoch 62, Val Loss: 4.93270
Epoch 63, Val Loss: 4.93228
Epoch 64, Val Loss: 5.15139
Epoch 65, Val Loss: 4.97966
Epoch 66, Val Loss: 5.28367
Epoch 67, Val Loss: 5.00655
Epoch 68, Val Loss: 4.88968
Epoch 69, Val Loss: 4.95143
Epoch 70, Val Loss: 4.78882
Epoch 71, Val Loss: 4.74143
Epoch 72, Val Loss: 4.86034
Epoch 73, Val Loss: 4.90743
Epoch 74, Val Loss: 5.00849
Epoch 75, Val Loss: 4.79966
Epoch 76, Val Loss: 5.27102
Epoch 77, Val Loss: 5.18189
Epoch 78, Val Loss: 4.79567
Epoch 79, Val Loss: 4.85852
Epoch 80, Val Loss: 5.03705
Epoch 81, Val Loss: 4.84047
Epoch 82, Val Loss: 4.85329
Epoch 83, Val Loss: 4.79877
Epoch 84, Val Loss: 4.97328
Epoch 85, Val Loss: 4.90568
Epoch 86, Val Loss: 5.35204
Epoch 87, Val Loss: 5.06335
Epoch 88, Val Loss: 5.02255
Epoch 89, Val Loss: 4.83636
Epoch 90, Val Loss: 5.11659
Epoch 91, Val Loss: 4.86870
Epoch 92, Val Loss: 4.70967
Epoch 93, Val Loss: 4.78046
Epoch 94, Val Loss: 5.03118
Epoch 95, Val Loss: 4.92226
Epoch 96, Val Loss: 5.67279
Epoch 97, Val Loss: 4.89861
Epoch 98, Val Loss: 4.83045
Epoch 99, Val Loss: 5.05054
DID NOT SAVE RESULTS
{'MSE - mean': 4.856984313406359, 'MSE - std': 0.0, 'R2 - mean': 0.5570590797598611, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.31750
Epoch 1, Val Loss: 10.48743
Epoch 2, Val Loss: 6.04294
Epoch 3, Val Loss: 5.50058
Epoch 4, Val Loss: 5.45356
Epoch 5, Val Loss: 5.25981
Epoch 6, Val Loss: 5.34803
Epoch 7, Val Loss: 5.47425
Epoch 8, Val Loss: 5.16251
Epoch 9, Val Loss: 5.37241
Epoch 10, Val Loss: 5.15738
Epoch 11, Val Loss: 4.87579
Epoch 12, Val Loss: 4.93116
Epoch 13, Val Loss: 5.10405
Epoch 14, Val Loss: 5.12135
Epoch 15, Val Loss: 4.69723
Epoch 16, Val Loss: 4.62847
Epoch 17, Val Loss: 4.84248
Epoch 18, Val Loss: 4.61565
Epoch 19, Val Loss: 5.37000
Epoch 20, Val Loss: 4.59462
Epoch 21, Val Loss: 4.42997
Epoch 22, Val Loss: 4.48759
Epoch 23, Val Loss: 4.52640
Epoch 24, Val Loss: 4.64694
Epoch 25, Val Loss: 4.65178
Epoch 26, Val Loss: 4.65639
Epoch 27, Val Loss: 4.32388
Epoch 28, Val Loss: 4.43274
Epoch 29, Val Loss: 4.88024
Epoch 30, Val Loss: 4.32765
Epoch 31, Val Loss: 4.70741
Epoch 32, Val Loss: 4.57923
Epoch 33, Val Loss: 4.38735
Epoch 34, Val Loss: 4.23882
Epoch 35, Val Loss: 4.22984
Epoch 36, Val Loss: 4.26013
Epoch 37, Val Loss: 4.14385
Epoch 38, Val Loss: 4.47469
Epoch 39, Val Loss: 4.14376
Epoch 40, Val Loss: 4.22979
Epoch 41, Val Loss: 4.15301
Epoch 42, Val Loss: 4.10478
Epoch 43, Val Loss: 4.23568
Epoch 44, Val Loss: 4.44054
Epoch 45, Val Loss: 4.32634
Epoch 46, Val Loss: 4.07285
Epoch 47, Val Loss: 4.21326
Epoch 48, Val Loss: 4.56084
Epoch 49, Val Loss: 4.36288
Epoch 50, Val Loss: 4.32649
Epoch 51, Val Loss: 4.22368
Epoch 52, Val Loss: 4.05370
Epoch 53, Val Loss: 4.13325
Epoch 54, Val Loss: 4.47530
Epoch 55, Val Loss: 4.23079
Epoch 56, Val Loss: 4.13753
Epoch 57, Val Loss: 4.33133
Epoch 58, Val Loss: 4.45816
Epoch 59, Val Loss: 4.18376
Epoch 60, Val Loss: 4.15452
Epoch 61, Val Loss: 4.25668
Epoch 62, Val Loss: 4.07384
Epoch 63, Val Loss: 4.05735
Epoch 64, Val Loss: 4.09916
Epoch 65, Val Loss: 4.10055
Epoch 66, Val Loss: 4.15751
Epoch 67, Val Loss: 4.00142
Epoch 68, Val Loss: 4.82845
Epoch 69, Val Loss: 4.15013
Epoch 70, Val Loss: 4.15592
Epoch 71, Val Loss: 4.05210
Epoch 72, Val Loss: 4.12185
Epoch 73, Val Loss: 4.01338
Epoch 74, Val Loss: 4.02302
Epoch 75, Val Loss: 4.46137
Epoch 76, Val Loss: 4.12892
Epoch 77, Val Loss: 4.02460
Epoch 78, Val Loss: 4.07521
Epoch 79, Val Loss: 4.05610
Epoch 80, Val Loss: 3.95517
Epoch 81, Val Loss: 4.06495
Epoch 82, Val Loss: 4.08000
Epoch 83, Val Loss: 4.07192
Epoch 84, Val Loss: 4.37600
Epoch 85, Val Loss: 4.04795
Epoch 86, Val Loss: 4.20058
Epoch 87, Val Loss: 4.11295
Epoch 88, Val Loss: 4.28238
Epoch 89, Val Loss: 4.91876
Epoch 90, Val Loss: 4.46923
Epoch 91, Val Loss: 4.05550
Epoch 92, Val Loss: 4.15720
Epoch 93, Val Loss: 4.14702
Epoch 94, Val Loss: 4.20750
Epoch 95, Val Loss: 4.06174
Epoch 96, Val Loss: 4.03471
Epoch 97, Val Loss: 4.35237
Epoch 98, Val Loss: 4.19426
Epoch 99, Val Loss: 4.39868
DID NOT SAVE RESULTS
{'MSE - mean': 4.459768679209644, 'MSE - std': 0.39721563419671524, 'R2 - mean': 0.5620024424827413, 'R2 - std': 0.004943362722880207} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.12061
Epoch 1, Val Loss: 13.20853
Epoch 2, Val Loss: 6.97840
Epoch 3, Val Loss: 6.54248
Epoch 4, Val Loss: 6.27961
Epoch 5, Val Loss: 6.28633
Epoch 6, Val Loss: 6.50835
Epoch 7, Val Loss: 6.10875
Epoch 8, Val Loss: 6.17202
Epoch 9, Val Loss: 6.10488
Epoch 10, Val Loss: 6.40155
Epoch 11, Val Loss: 6.06462
Epoch 12, Val Loss: 6.30969
Epoch 13, Val Loss: 6.44138
Epoch 14, Val Loss: 6.09207
Epoch 15, Val Loss: 6.51313
Epoch 16, Val Loss: 5.96494
Epoch 17, Val Loss: 6.26477
Epoch 18, Val Loss: 5.97246
Epoch 19, Val Loss: 6.03794
Epoch 20, Val Loss: 6.02741
Epoch 21, Val Loss: 5.91418
Epoch 22, Val Loss: 6.22129
Epoch 23, Val Loss: 6.38170
Epoch 24, Val Loss: 6.25722
Epoch 25, Val Loss: 5.95403
Epoch 26, Val Loss: 5.97300
Epoch 27, Val Loss: 5.79349
Epoch 28, Val Loss: 5.81629
Epoch 29, Val Loss: 5.97362
Epoch 30, Val Loss: 6.02284
Epoch 31, Val Loss: 5.78976
Epoch 32, Val Loss: 5.91843
Epoch 33, Val Loss: 5.79162
Epoch 34, Val Loss: 5.75302
Epoch 35, Val Loss: 5.79514
Epoch 36, Val Loss: 5.79199
Epoch 37, Val Loss: 6.22252
Epoch 38, Val Loss: 6.21496
Epoch 39, Val Loss: 5.55513
Epoch 40, Val Loss: 5.59802
Epoch 41, Val Loss: 5.65431
Epoch 42, Val Loss: 5.64402
Epoch 43, Val Loss: 5.89199
Epoch 44, Val Loss: 5.42593
Epoch 45, Val Loss: 5.54127
Epoch 46, Val Loss: 5.89779
Epoch 47, Val Loss: 5.52206
Epoch 48, Val Loss: 5.58946
Epoch 49, Val Loss: 5.39300
Epoch 50, Val Loss: 5.54578
Epoch 51, Val Loss: 5.43240
Epoch 52, Val Loss: 5.32225
Epoch 53, Val Loss: 5.39161
Epoch 54, Val Loss: 5.47025
Epoch 55, Val Loss: 5.44273
Epoch 56, Val Loss: 5.20688
Epoch 57, Val Loss: 5.35735
Epoch 58, Val Loss: 5.37786
Epoch 59, Val Loss: 5.18826
Epoch 60, Val Loss: 5.16504
Epoch 61, Val Loss: 5.35837
Epoch 62, Val Loss: 5.33228
Epoch 63, Val Loss: 5.49786
Epoch 64, Val Loss: 5.43354
Epoch 65, Val Loss: 5.17684
Epoch 66, Val Loss: 5.13856
Epoch 67, Val Loss: 5.24027
Epoch 68, Val Loss: 5.64987
Epoch 69, Val Loss: 5.14354
Epoch 70, Val Loss: 5.09600
Epoch 71, Val Loss: 5.16686
Epoch 72, Val Loss: 5.25037
Epoch 73, Val Loss: 5.17505
Epoch 74, Val Loss: 5.17763
Epoch 75, Val Loss: 5.11322
Epoch 76, Val Loss: 5.21790
Epoch 77, Val Loss: 5.62256
Epoch 78, Val Loss: 5.08269
Epoch 79, Val Loss: 5.11217
Epoch 80, Val Loss: 5.10306
Epoch 81, Val Loss: 5.05059
Epoch 82, Val Loss: 5.24954
Epoch 83, Val Loss: 5.11412
Epoch 84, Val Loss: 5.07613
Epoch 85, Val Loss: 5.15121
Epoch 86, Val Loss: 5.06578
Epoch 87, Val Loss: 5.23574
Epoch 88, Val Loss: 5.16261
Epoch 89, Val Loss: 5.20277
Epoch 90, Val Loss: 5.72531
Epoch 91, Val Loss: 5.01290
Epoch 92, Val Loss: 5.17945
Epoch 93, Val Loss: 4.98252
Epoch 94, Val Loss: 5.09498
Epoch 95, Val Loss: 5.23264
Epoch 96, Val Loss: 5.23413
Epoch 97, Val Loss: 4.99794
Epoch 98, Val Loss: 5.20308
Epoch 99, Val Loss: 5.47806
DID NOT SAVE RESULTS
{'MSE - mean': 4.665234463430041, 'MSE - std': 0.4354528872382615, 'R2 - mean': 0.5415055931741514, 'R2 - std': 0.029266583102543108} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.81594
Epoch 1, Val Loss: 8.86906
Epoch 2, Val Loss: 5.50158
Epoch 3, Val Loss: 5.33400
Epoch 4, Val Loss: 5.18949
Epoch 5, Val Loss: 5.14795
Epoch 6, Val Loss: 5.45520
Epoch 7, Val Loss: 5.56018
Epoch 8, Val Loss: 5.50029
Epoch 9, Val Loss: 5.09335
Epoch 10, Val Loss: 4.92649
Epoch 11, Val Loss: 4.93120
Epoch 12, Val Loss: 5.16014
Epoch 13, Val Loss: 4.92145
Epoch 14, Val Loss: 4.61590
Epoch 15, Val Loss: 4.89524
Epoch 16, Val Loss: 4.63285
Epoch 17, Val Loss: 4.49149
Epoch 18, Val Loss: 4.62205
Epoch 19, Val Loss: 4.43092
Epoch 20, Val Loss: 5.29652
Epoch 21, Val Loss: 4.58529
Epoch 22, Val Loss: 4.66064
Epoch 23, Val Loss: 4.49829
Epoch 24, Val Loss: 4.43355
Epoch 25, Val Loss: 4.35158
Epoch 26, Val Loss: 4.31638
Epoch 27, Val Loss: 4.52408
Epoch 28, Val Loss: 4.45136
Epoch 29, Val Loss: 5.36598
Epoch 30, Val Loss: 4.39587
Epoch 31, Val Loss: 4.60584
Epoch 32, Val Loss: 4.49493
Epoch 33, Val Loss: 4.45874
Epoch 34, Val Loss: 4.36446
Epoch 35, Val Loss: 4.20416
Epoch 36, Val Loss: 4.41759
Epoch 37, Val Loss: 4.45710
Epoch 38, Val Loss: 4.40910
Epoch 39, Val Loss: 4.22574
Epoch 40, Val Loss: 4.42004
Epoch 41, Val Loss: 4.18026
Epoch 42, Val Loss: 4.21163
Epoch 43, Val Loss: 4.37177
Epoch 44, Val Loss: 4.21588
Epoch 45, Val Loss: 4.23441
Epoch 46, Val Loss: 4.08772
Epoch 47, Val Loss: 4.15323
Epoch 48, Val Loss: 4.23832
Epoch 49, Val Loss: 4.20996
Epoch 50, Val Loss: 4.16427
Epoch 51, Val Loss: 4.10789
Epoch 52, Val Loss: 4.31503
Epoch 53, Val Loss: 4.37643
Epoch 54, Val Loss: 4.26171
Epoch 55, Val Loss: 4.13605
Epoch 56, Val Loss: 4.47041
Epoch 57, Val Loss: 4.13135
Epoch 58, Val Loss: 4.27196
Epoch 59, Val Loss: 4.16079
Epoch 60, Val Loss: 4.17956
Epoch 61, Val Loss: 4.16847
Epoch 62, Val Loss: 4.20654
Epoch 63, Val Loss: 3.99799
Epoch 64, Val Loss: 4.17271
Epoch 65, Val Loss: 4.05897
Epoch 66, Val Loss: 4.04816
Epoch 67, Val Loss: 4.01833
Epoch 68, Val Loss: 4.26799
Epoch 69, Val Loss: 4.36851
Epoch 70, Val Loss: 4.24724
Epoch 71, Val Loss: 4.08507
Epoch 72, Val Loss: 4.03351
Epoch 73, Val Loss: 4.25159
Epoch 74, Val Loss: 4.16852
Epoch 75, Val Loss: 4.08514
Epoch 76, Val Loss: 4.07347
Epoch 77, Val Loss: 4.16626
Epoch 78, Val Loss: 4.11488
Epoch 79, Val Loss: 4.04134
Epoch 80, Val Loss: 4.25393
Epoch 81, Val Loss: 4.03471
Epoch 82, Val Loss: 4.06822
Epoch 83, Val Loss: 4.18215
Epoch 84, Val Loss: 4.35554
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.578325472003608, 'MSE - std': 0.4060467105215641, 'R2 - mean': 0.5407192382662165, 'R2 - std': 0.025382173409644142} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.86734
Epoch 1, Val Loss: 16.22765
Epoch 2, Val Loss: 8.45442
Epoch 3, Val Loss: 7.39580
Epoch 4, Val Loss: 7.34526
Epoch 5, Val Loss: 7.29268
Epoch 6, Val Loss: 7.31987
Epoch 7, Val Loss: 7.43221
Epoch 8, Val Loss: 7.28756
Epoch 9, Val Loss: 7.64693
Epoch 10, Val Loss: 7.01596
Epoch 11, Val Loss: 7.40501
Epoch 12, Val Loss: 7.06993
Epoch 13, Val Loss: 7.00700
Epoch 14, Val Loss: 6.69567
Epoch 15, Val Loss: 6.77515
Epoch 16, Val Loss: 6.99235
Epoch 17, Val Loss: 6.63395
Epoch 18, Val Loss: 6.69898
Epoch 19, Val Loss: 7.20785
Epoch 20, Val Loss: 6.66870
Epoch 21, Val Loss: 6.71659
Epoch 22, Val Loss: 6.74366
Epoch 23, Val Loss: 6.62402
Epoch 24, Val Loss: 6.60594
Epoch 25, Val Loss: 6.98992
Epoch 26, Val Loss: 6.78763
Epoch 27, Val Loss: 6.31982
Epoch 28, Val Loss: 6.37330
Epoch 29, Val Loss: 6.63363
Epoch 30, Val Loss: 6.68068
Epoch 31, Val Loss: 6.73633
Epoch 32, Val Loss: 6.30466
Epoch 33, Val Loss: 6.65969
Epoch 34, Val Loss: 6.40620
Epoch 35, Val Loss: 6.32510
Epoch 36, Val Loss: 6.43304
Epoch 37, Val Loss: 6.27152
Epoch 38, Val Loss: 6.79763
Epoch 39, Val Loss: 6.30997
Epoch 40, Val Loss: 6.17836
Epoch 41, Val Loss: 6.15799
Epoch 42, Val Loss: 6.29193
Epoch 43, Val Loss: 6.07127
Epoch 44, Val Loss: 6.29953
Epoch 45, Val Loss: 6.46731
Epoch 46, Val Loss: 6.25645
Epoch 47, Val Loss: 6.15295
Epoch 48, Val Loss: 6.44953
Epoch 49, Val Loss: 6.24450
Epoch 50, Val Loss: 6.03672
Epoch 51, Val Loss: 6.23747
Epoch 52, Val Loss: 6.20852
Epoch 53, Val Loss: 6.31442
Epoch 54, Val Loss: 6.08070
Epoch 55, Val Loss: 6.07941
Epoch 56, Val Loss: 6.29808
Epoch 57, Val Loss: 6.27303
Epoch 58, Val Loss: 6.17766
Epoch 59, Val Loss: 6.05132
Epoch 60, Val Loss: 6.10772
Epoch 61, Val Loss: 6.08960
Epoch 62, Val Loss: 5.99296
Epoch 63, Val Loss: 6.31091
Epoch 64, Val Loss: 6.57358
Epoch 65, Val Loss: 6.05196
Epoch 66, Val Loss: 5.99927
Epoch 67, Val Loss: 6.04768
Epoch 68, Val Loss: 6.07964
Epoch 69, Val Loss: 6.93500
Epoch 70, Val Loss: 5.94437
Epoch 71, Val Loss: 5.87574
Epoch 72, Val Loss: 6.29824
Epoch 73, Val Loss: 6.21308
Epoch 74, Val Loss: 6.14951
Epoch 75, Val Loss: 6.35969
Epoch 76, Val Loss: 6.10860
Epoch 77, Val Loss: 6.25693
Epoch 78, Val Loss: 6.30514
Epoch 79, Val Loss: 5.98756
Epoch 80, Val Loss: 6.28994
Epoch 81, Val Loss: 6.07662
Epoch 82, Val Loss: 6.04109
Epoch 83, Val Loss: 6.24773
Epoch 84, Val Loss: 5.93191
Epoch 85, Val Loss: 6.06567
Epoch 86, Val Loss: 6.00018
Epoch 87, Val Loss: 5.90335
Epoch 88, Val Loss: 5.93751
Epoch 89, Val Loss: 6.72409
Epoch 90, Val Loss: 5.86494
Epoch 91, Val Loss: 6.25075
Epoch 92, Val Loss: 6.09513
Epoch 93, Val Loss: 5.84877
Epoch 94, Val Loss: 6.18386
Epoch 95, Val Loss: 5.90318
Epoch 96, Val Loss: 5.96257
Epoch 97, Val Loss: 6.24747
Epoch 98, Val Loss: 6.06957
Epoch 99, Val Loss: 6.05069
DID NOT SAVE RESULTS
{'MSE - mean': 4.833736251450947, 'MSE - std': 0.6267677479991252, 'R2 - mean': 0.5357277848035507, 'R2 - std': 0.024800447824134753} 
 

Results After CV: {'MSE - mean': 4.833736251450947, 'MSE - std': 0.6267677479991252, 'R2 - mean': 0.5357277848035507, 'R2 - std': 0.024800447824134753}
Train time: 110.23793632200014
Inference time: 0.05227985660021659
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 33 finished with value: 4.833736251450947 and parameters: {'p_m': 0.6997245046865035, 'alpha': 3.6642476012133938, 'K': 20, 'beta': 1.5230775846905198}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.00259
Epoch 1, Val Loss: 10.81156
Epoch 2, Val Loss: 6.51631
Epoch 3, Val Loss: 6.53370
Epoch 4, Val Loss: 6.34577
Epoch 5, Val Loss: 6.47151
Epoch 6, Val Loss: 6.00805
Epoch 7, Val Loss: 6.06584
Epoch 8, Val Loss: 6.00960
Epoch 9, Val Loss: 5.90487
Epoch 10, Val Loss: 5.74025
Epoch 11, Val Loss: 5.69564
Epoch 12, Val Loss: 5.68606
Epoch 13, Val Loss: 5.58068
Epoch 14, Val Loss: 5.60863
Epoch 15, Val Loss: 5.62144
Epoch 16, Val Loss: 5.34473
Epoch 17, Val Loss: 5.42589
Epoch 18, Val Loss: 5.58358
Epoch 19, Val Loss: 5.31454
Epoch 20, Val Loss: 5.25300
Epoch 21, Val Loss: 5.39926
Epoch 22, Val Loss: 5.38220
Epoch 23, Val Loss: 5.79488
Epoch 24, Val Loss: 5.14522
Epoch 25, Val Loss: 5.07656
Epoch 26, Val Loss: 5.03107
Epoch 27, Val Loss: 5.02961
Epoch 28, Val Loss: 5.18157
Epoch 29, Val Loss: 5.08743
Epoch 30, Val Loss: 4.92389
Epoch 31, Val Loss: 4.91300
Epoch 32, Val Loss: 4.96737
Epoch 33, Val Loss: 5.13980
Epoch 34, Val Loss: 5.15094
Epoch 35, Val Loss: 4.88519
Epoch 36, Val Loss: 4.84192
Epoch 37, Val Loss: 4.86880
Epoch 38, Val Loss: 4.95360
Epoch 39, Val Loss: 5.07325
Epoch 40, Val Loss: 4.78003
Epoch 41, Val Loss: 5.10089
Epoch 42, Val Loss: 4.89665
Epoch 43, Val Loss: 4.98236
Epoch 44, Val Loss: 5.22824
Epoch 45, Val Loss: 5.54469
Epoch 46, Val Loss: 4.93730
Epoch 47, Val Loss: 5.17587
Epoch 48, Val Loss: 5.00604
Epoch 49, Val Loss: 5.00368
Epoch 50, Val Loss: 4.93679
Epoch 51, Val Loss: 4.74596
Epoch 52, Val Loss: 4.86663
Epoch 53, Val Loss: 4.94471
Epoch 54, Val Loss: 4.91102
Epoch 55, Val Loss: 4.86654
Epoch 56, Val Loss: 4.86963
Epoch 57, Val Loss: 4.77092
Epoch 58, Val Loss: 4.81611
Epoch 59, Val Loss: 5.13834
Epoch 60, Val Loss: 5.04547
Epoch 61, Val Loss: 4.66745
Epoch 62, Val Loss: 5.06004
Epoch 63, Val Loss: 4.88294
Epoch 64, Val Loss: 4.68777
Epoch 65, Val Loss: 4.93711
Epoch 66, Val Loss: 4.76039
Epoch 67, Val Loss: 4.74216
Epoch 68, Val Loss: 4.79806
Epoch 69, Val Loss: 4.83442
Epoch 70, Val Loss: 4.77254
Epoch 71, Val Loss: 4.79366
Epoch 72, Val Loss: 4.94050
Epoch 73, Val Loss: 4.82271
Epoch 74, Val Loss: 4.87762
Epoch 75, Val Loss: 5.11798
Epoch 76, Val Loss: 4.88355
Epoch 77, Val Loss: 4.83810
Epoch 78, Val Loss: 4.72473
Epoch 79, Val Loss: 4.78219
Epoch 80, Val Loss: 4.96782
Epoch 81, Val Loss: 4.75136
Epoch 82, Val Loss: 4.78690
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.811296365923194, 'MSE - std': 0.0, 'R2 - mean': 0.5612256696016724, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.56479
Epoch 1, Val Loss: 10.58393
Epoch 2, Val Loss: 5.57426
Epoch 3, Val Loss: 5.23054
Epoch 4, Val Loss: 5.04232
Epoch 5, Val Loss: 5.00269
Epoch 6, Val Loss: 5.05659
Epoch 7, Val Loss: 4.76071
Epoch 8, Val Loss: 4.72156
Epoch 9, Val Loss: 4.66228
Epoch 10, Val Loss: 4.51591
Epoch 11, Val Loss: 4.69463
Epoch 12, Val Loss: 4.37681
Epoch 13, Val Loss: 4.44186
Epoch 14, Val Loss: 4.39315
Epoch 15, Val Loss: 4.35436
Epoch 16, Val Loss: 4.66193
Epoch 17, Val Loss: 4.40318
Epoch 18, Val Loss: 4.21537
Epoch 19, Val Loss: 4.12205
Epoch 20, Val Loss: 4.13323
Epoch 21, Val Loss: 4.15794
Epoch 22, Val Loss: 4.34228
Epoch 23, Val Loss: 4.05687
Epoch 24, Val Loss: 4.13262
Epoch 25, Val Loss: 4.13534
Epoch 26, Val Loss: 4.04580
Epoch 27, Val Loss: 4.27284
Epoch 28, Val Loss: 4.03062
Epoch 29, Val Loss: 4.19067
Epoch 30, Val Loss: 4.17361
Epoch 31, Val Loss: 4.03733
Epoch 32, Val Loss: 4.16280
Epoch 33, Val Loss: 4.22090
Epoch 34, Val Loss: 4.06483
Epoch 35, Val Loss: 3.88996
Epoch 36, Val Loss: 3.91203
Epoch 37, Val Loss: 3.93549
Epoch 38, Val Loss: 3.98790
Epoch 39, Val Loss: 4.08070
Epoch 40, Val Loss: 3.97227
Epoch 41, Val Loss: 4.19248
Epoch 42, Val Loss: 4.06240
Epoch 43, Val Loss: 4.04250
Epoch 44, Val Loss: 4.27059
Epoch 45, Val Loss: 3.89605
Epoch 46, Val Loss: 4.04725
Epoch 47, Val Loss: 4.01593
Epoch 48, Val Loss: 3.97680
Epoch 49, Val Loss: 3.88262
Epoch 50, Val Loss: 3.98566
Epoch 51, Val Loss: 3.90626
Epoch 52, Val Loss: 3.99446
Epoch 53, Val Loss: 3.86021
Epoch 54, Val Loss: 3.84928
Epoch 55, Val Loss: 3.95072
Epoch 56, Val Loss: 4.33189
Epoch 57, Val Loss: 4.01479
Epoch 58, Val Loss: 3.89113
Epoch 59, Val Loss: 3.81486
Epoch 60, Val Loss: 4.06522
Epoch 61, Val Loss: 3.82360
Epoch 62, Val Loss: 4.23372
Epoch 63, Val Loss: 4.78342
Epoch 64, Val Loss: 4.05077
Epoch 65, Val Loss: 3.93690
Epoch 66, Val Loss: 3.92341
Epoch 67, Val Loss: 4.27020
Epoch 68, Val Loss: 4.02823
Epoch 69, Val Loss: 3.95969
Epoch 70, Val Loss: 3.99642
Epoch 71, Val Loss: 4.59333
Epoch 72, Val Loss: 4.46592
Epoch 73, Val Loss: 3.89901
Epoch 74, Val Loss: 3.87850
Epoch 75, Val Loss: 3.90685
Epoch 76, Val Loss: 4.03122
Epoch 77, Val Loss: 3.87210
Epoch 78, Val Loss: 4.17304
Epoch 79, Val Loss: 4.04951
Epoch 80, Val Loss: 3.95286
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.405698956303571, 'MSE - std': 0.4055974096196242, 'R2 - mean': 0.5674142949662072, 'R2 - std': 0.006188625364534794} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.98841
Epoch 1, Val Loss: 9.11896
Epoch 2, Val Loss: 6.83099
Epoch 3, Val Loss: 6.28079
Epoch 4, Val Loss: 6.03109
Epoch 5, Val Loss: 5.91800
Epoch 6, Val Loss: 6.29656
Epoch 7, Val Loss: 5.94814
Epoch 8, Val Loss: 5.72681
Epoch 9, Val Loss: 5.93438
Epoch 10, Val Loss: 5.62355
Epoch 11, Val Loss: 5.47467
Epoch 12, Val Loss: 5.38613
Epoch 13, Val Loss: 5.41795
Epoch 14, Val Loss: 5.56256
Epoch 15, Val Loss: 5.29749
Epoch 16, Val Loss: 5.14979
Epoch 17, Val Loss: 5.88135
Epoch 18, Val Loss: 5.18259
Epoch 19, Val Loss: 5.11628
Epoch 20, Val Loss: 5.03135
Epoch 21, Val Loss: 5.28260
Epoch 22, Val Loss: 4.98403
Epoch 23, Val Loss: 4.99552
Epoch 24, Val Loss: 5.00477
Epoch 25, Val Loss: 6.04242
Epoch 26, Val Loss: 5.01741
Epoch 27, Val Loss: 5.21338
Epoch 28, Val Loss: 4.85721
Epoch 29, Val Loss: 4.77900
Epoch 30, Val Loss: 4.89507
Epoch 31, Val Loss: 4.87174
Epoch 32, Val Loss: 4.76827
Epoch 33, Val Loss: 4.72593
Epoch 34, Val Loss: 4.81628
Epoch 35, Val Loss: 4.67903
Epoch 36, Val Loss: 4.75848
Epoch 37, Val Loss: 4.63471
Epoch 38, Val Loss: 4.63786
Epoch 39, Val Loss: 5.42931
Epoch 40, Val Loss: 4.57598
Epoch 41, Val Loss: 4.63809
Epoch 42, Val Loss: 4.55442
Epoch 43, Val Loss: 4.65405
Epoch 44, Val Loss: 4.62449
Epoch 45, Val Loss: 4.66551
Epoch 46, Val Loss: 4.59728
Epoch 47, Val Loss: 4.71696
Epoch 48, Val Loss: 4.42729
Epoch 49, Val Loss: 4.49698
Epoch 50, Val Loss: 4.61626
Epoch 51, Val Loss: 4.58142
Epoch 52, Val Loss: 4.41733
Epoch 53, Val Loss: 4.49682
Epoch 54, Val Loss: 4.59243
Epoch 55, Val Loss: 4.57712
Epoch 56, Val Loss: 4.41107
Epoch 57, Val Loss: 4.68300
Epoch 58, Val Loss: 4.65852
Epoch 59, Val Loss: 4.39458
Epoch 60, Val Loss: 4.45482
Epoch 61, Val Loss: 4.91938
Epoch 62, Val Loss: 4.38260
Epoch 63, Val Loss: 4.35697
Epoch 64, Val Loss: 4.38665
Epoch 65, Val Loss: 4.40122
Epoch 66, Val Loss: 4.36911
Epoch 67, Val Loss: 4.40955
Epoch 68, Val Loss: 4.36697
Epoch 69, Val Loss: 4.41224
Epoch 70, Val Loss: 4.79606
Epoch 71, Val Loss: 4.49160
Epoch 72, Val Loss: 4.40783
Epoch 73, Val Loss: 4.34784
Epoch 74, Val Loss: 4.73846
Epoch 75, Val Loss: 4.69496
Epoch 76, Val Loss: 4.39467
Epoch 77, Val Loss: 4.76866
Epoch 78, Val Loss: 4.44027
Epoch 79, Val Loss: 4.53415
Epoch 80, Val Loss: 4.41336
Epoch 81, Val Loss: 4.50969
Epoch 82, Val Loss: 4.34826
Epoch 83, Val Loss: 4.37621
Epoch 84, Val Loss: 4.49900
Epoch 85, Val Loss: 4.44119
Epoch 86, Val Loss: 4.46563
Epoch 87, Val Loss: 4.78984
Epoch 88, Val Loss: 4.42413
Epoch 89, Val Loss: 4.43489
Epoch 90, Val Loss: 4.41426
Epoch 91, Val Loss: 4.39385
Epoch 92, Val Loss: 4.75922
Epoch 93, Val Loss: 4.48754
Epoch 94, Val Loss: 4.83724
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.4301968212906635, 'MSE - std': 0.3329761701753113, 'R2 - mean': 0.5646939650085009, 'R2 - std': 0.00635083559536053} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.02487
Epoch 1, Val Loss: 7.85999
Epoch 2, Val Loss: 5.73955
Epoch 3, Val Loss: 5.23768
Epoch 4, Val Loss: 5.29695
Epoch 5, Val Loss: 5.24456
Epoch 6, Val Loss: 5.12958
Epoch 7, Val Loss: 4.92395
Epoch 8, Val Loss: 4.88697
Epoch 9, Val Loss: 4.93964
Epoch 10, Val Loss: 4.85924
Epoch 11, Val Loss: 4.96156
Epoch 12, Val Loss: 4.76429
Epoch 13, Val Loss: 4.86283
Epoch 14, Val Loss: 4.70449
Epoch 15, Val Loss: 4.70068
Epoch 16, Val Loss: 4.79769
Epoch 17, Val Loss: 4.65173
Epoch 18, Val Loss: 4.60148
Epoch 19, Val Loss: 4.60971
Epoch 20, Val Loss: 4.54825
Epoch 21, Val Loss: 4.50625
Epoch 22, Val Loss: 4.53655
Epoch 23, Val Loss: 4.46108
Epoch 24, Val Loss: 4.42333
Epoch 25, Val Loss: 4.45579
Epoch 26, Val Loss: 4.58642
Epoch 27, Val Loss: 4.47886
Epoch 28, Val Loss: 4.34521
Epoch 29, Val Loss: 4.45359
Epoch 30, Val Loss: 4.61099
Epoch 31, Val Loss: 4.80998
Epoch 32, Val Loss: 4.27936
Epoch 33, Val Loss: 4.47789
Epoch 34, Val Loss: 4.28841
Epoch 35, Val Loss: 4.27377
Epoch 36, Val Loss: 4.21473
Epoch 37, Val Loss: 4.48006
Epoch 38, Val Loss: 4.18159
Epoch 39, Val Loss: 4.35216
Epoch 40, Val Loss: 4.20081
Epoch 41, Val Loss: 4.13920
Epoch 42, Val Loss: 4.10926
Epoch 43, Val Loss: 4.41077
Epoch 44, Val Loss: 4.34092
Epoch 45, Val Loss: 4.23727
Epoch 46, Val Loss: 4.23394
Epoch 47, Val Loss: 4.31618
Epoch 48, Val Loss: 4.04684
Epoch 49, Val Loss: 4.65791
Epoch 50, Val Loss: 4.06017
Epoch 51, Val Loss: 4.06152
Epoch 52, Val Loss: 4.18420
Epoch 53, Val Loss: 4.16248
Epoch 54, Val Loss: 4.25872
Epoch 55, Val Loss: 4.09331
Epoch 56, Val Loss: 4.21425
Epoch 57, Val Loss: 4.24589
Epoch 58, Val Loss: 4.19095
Epoch 59, Val Loss: 4.11889
Epoch 60, Val Loss: 4.32140
Epoch 61, Val Loss: 4.73995
Epoch 62, Val Loss: 4.38899
Epoch 63, Val Loss: 4.34977
Epoch 64, Val Loss: 4.02373
Epoch 65, Val Loss: 4.04145
Epoch 66, Val Loss: 4.60075
Epoch 67, Val Loss: 4.11720
Epoch 68, Val Loss: 4.13381
Epoch 69, Val Loss: 4.05895
Epoch 70, Val Loss: 4.14781
Epoch 71, Val Loss: 4.06719
Epoch 72, Val Loss: 4.08029
Epoch 73, Val Loss: 5.02751
Epoch 74, Val Loss: 4.31005
Epoch 75, Val Loss: 4.06178
Epoch 76, Val Loss: 4.14127
Epoch 77, Val Loss: 4.25764
Epoch 78, Val Loss: 3.98902
Epoch 79, Val Loss: 4.11903
Epoch 80, Val Loss: 4.03647
Epoch 81, Val Loss: 4.26787
Epoch 82, Val Loss: 4.04056
Epoch 83, Val Loss: 4.16757
Epoch 84, Val Loss: 4.18076
Epoch 85, Val Loss: 4.32541
Epoch 86, Val Loss: 4.23422
Epoch 87, Val Loss: 4.35644
Epoch 88, Val Loss: 4.04923
Epoch 89, Val Loss: 4.09329
Epoch 90, Val Loss: 4.05373
Epoch 91, Val Loss: 4.26787
Epoch 92, Val Loss: 4.09451
Epoch 93, Val Loss: 4.18038
Epoch 94, Val Loss: 4.26354
Epoch 95, Val Loss: 4.08157
Epoch 96, Val Loss: 4.27741
Epoch 97, Val Loss: 4.15466
Epoch 98, Val Loss: 4.40864
Epoch 99, Val Loss: 4.17164
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.386895738199851, 'MSE - std': 0.29795939122466975, 'R2 - mean': 0.5597305234601919, 'R2 - std': 0.010205738120288514} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.93518
Epoch 1, Val Loss: 14.39245
Epoch 2, Val Loss: 8.08673
Epoch 3, Val Loss: 7.33967
Epoch 4, Val Loss: 7.26861
Epoch 5, Val Loss: 7.22148
Epoch 6, Val Loss: 7.25184
Epoch 7, Val Loss: 7.06567
Epoch 8, Val Loss: 7.08030
Epoch 9, Val Loss: 6.81272
Epoch 10, Val Loss: 6.63004
Epoch 11, Val Loss: 6.62361
Epoch 12, Val Loss: 6.27861
Epoch 13, Val Loss: 6.22137
Epoch 14, Val Loss: 6.08963
Epoch 15, Val Loss: 5.90933
Epoch 16, Val Loss: 6.16018
Epoch 17, Val Loss: 6.06950
Epoch 18, Val Loss: 5.94299
Epoch 19, Val Loss: 6.52214
Epoch 20, Val Loss: 6.05993
Epoch 21, Val Loss: 5.77275
Epoch 22, Val Loss: 5.92738
Epoch 23, Val Loss: 5.86660
Epoch 24, Val Loss: 5.79666
Epoch 25, Val Loss: 5.92598
Epoch 26, Val Loss: 5.89482
Epoch 27, Val Loss: 5.72594
Epoch 28, Val Loss: 5.93082
Epoch 29, Val Loss: 5.98140
Epoch 30, Val Loss: 5.78411
Epoch 31, Val Loss: 6.05587
Epoch 32, Val Loss: 5.83397
Epoch 33, Val Loss: 5.82894
Epoch 34, Val Loss: 5.83192
Epoch 35, Val Loss: 5.74554
Epoch 36, Val Loss: 5.81321
Epoch 37, Val Loss: 5.69604
Epoch 38, Val Loss: 5.71850
Epoch 39, Val Loss: 5.61260
Epoch 40, Val Loss: 5.55393
Epoch 41, Val Loss: 5.68031
Epoch 42, Val Loss: 5.80191
Epoch 43, Val Loss: 5.70726
Epoch 44, Val Loss: 5.91944
Epoch 45, Val Loss: 5.80649
Epoch 46, Val Loss: 5.58588
Epoch 47, Val Loss: 5.80912
Epoch 48, Val Loss: 5.75288
Epoch 49, Val Loss: 5.67749
Epoch 50, Val Loss: 5.68070
Epoch 51, Val Loss: 5.73808
Epoch 52, Val Loss: 5.56224
Epoch 53, Val Loss: 5.54862
Epoch 54, Val Loss: 5.79199
Epoch 55, Val Loss: 5.53061
Epoch 56, Val Loss: 5.55924
Epoch 57, Val Loss: 5.56249
Epoch 58, Val Loss: 5.50254
Epoch 59, Val Loss: 5.73584
Epoch 60, Val Loss: 5.67114
Epoch 61, Val Loss: 5.74912
Epoch 62, Val Loss: 5.93815
Epoch 63, Val Loss: 5.59617
Epoch 64, Val Loss: 5.44922
Epoch 65, Val Loss: 5.48094
Epoch 66, Val Loss: 5.63553
Epoch 67, Val Loss: 5.53971
Epoch 68, Val Loss: 5.61405
Epoch 69, Val Loss: 5.50678
Epoch 70, Val Loss: 5.73990
Epoch 71, Val Loss: 5.58089
Epoch 72, Val Loss: 5.55633
Epoch 73, Val Loss: 5.73536
Epoch 74, Val Loss: 5.54935
Epoch 75, Val Loss: 5.51220
Epoch 76, Val Loss: 5.59968
Epoch 77, Val Loss: 5.61577
Epoch 78, Val Loss: 5.57642
Epoch 79, Val Loss: 5.66808
Epoch 80, Val Loss: 5.80761
Epoch 81, Val Loss: 5.79773
Epoch 82, Val Loss: 6.55724
Epoch 83, Val Loss: 5.50826
Epoch 84, Val Loss: 5.42914
Epoch 85, Val Loss: 5.50980
Epoch 86, Val Loss: 5.46883
Epoch 87, Val Loss: 5.37329
Epoch 88, Val Loss: 5.49275
Epoch 89, Val Loss: 5.71498
Epoch 90, Val Loss: 5.43230
Epoch 91, Val Loss: 6.66481
Epoch 92, Val Loss: 6.07659
Epoch 93, Val Loss: 5.49773
Epoch 94, Val Loss: 5.55001
Epoch 95, Val Loss: 5.50220
Epoch 96, Val Loss: 5.55526
Epoch 97, Val Loss: 5.41886
Epoch 98, Val Loss: 5.47183
Epoch 99, Val Loss: 5.53683
DID NOT SAVE RESULTS
{'MSE - mean': 4.593198495583627, 'MSE - std': 0.4911895254092632, 'R2 - mean': 0.5581642666462591, 'R2 - std': 0.009650819348257091} 
 

Results After CV: {'MSE - mean': 4.593198495583627, 'MSE - std': 0.4911895254092632, 'R2 - mean': 0.5581642666462591, 'R2 - std': 0.009650819348257091}
Train time: 105.09673071800007
Inference time: 0.050087450399951196
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 34 finished with value: 4.593198495583627 and parameters: {'p_m': 0.8382711128958475, 'alpha': 2.5120183012361794, 'K': 20, 'beta': 0.9636551627084091}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.98630
Epoch 1, Val Loss: 8.60182
Epoch 2, Val Loss: 8.95732
Epoch 3, Val Loss: 6.98740
Epoch 4, Val Loss: 6.65026
Epoch 5, Val Loss: 6.49589
Epoch 6, Val Loss: 6.68743
Epoch 7, Val Loss: 6.36209
Epoch 8, Val Loss: 6.38727
Epoch 9, Val Loss: 6.38199
Epoch 10, Val Loss: 6.13611
Epoch 11, Val Loss: 6.38051
Epoch 12, Val Loss: 6.20893
Epoch 13, Val Loss: 6.37674
Epoch 14, Val Loss: 6.08831
Epoch 15, Val Loss: 6.18379
Epoch 16, Val Loss: 6.07352
Epoch 17, Val Loss: 5.90640
Epoch 18, Val Loss: 5.80573
Epoch 19, Val Loss: 5.84076
Epoch 20, Val Loss: 5.80582
Epoch 21, Val Loss: 6.01140
Epoch 22, Val Loss: 5.85183
Epoch 23, Val Loss: 5.99281
Epoch 24, Val Loss: 5.72385
Epoch 25, Val Loss: 5.86156
Epoch 26, Val Loss: 5.62577
Epoch 27, Val Loss: 5.61790
Epoch 28, Val Loss: 5.94817
Epoch 29, Val Loss: 5.65207
Epoch 30, Val Loss: 5.89169
Epoch 31, Val Loss: 5.90152
Epoch 32, Val Loss: 5.74337
Epoch 33, Val Loss: 5.49755
Epoch 34, Val Loss: 5.47792
Epoch 35, Val Loss: 5.58633
Epoch 36, Val Loss: 5.66722
Epoch 37, Val Loss: 5.48795
Epoch 38, Val Loss: 5.82438
Epoch 39, Val Loss: 5.60851
Epoch 40, Val Loss: 5.47324
Epoch 41, Val Loss: 5.42750
Epoch 42, Val Loss: 5.68830
Epoch 43, Val Loss: 5.68380
Epoch 44, Val Loss: 5.60755
Epoch 45, Val Loss: 5.88440
Epoch 46, Val Loss: 5.48861
Epoch 47, Val Loss: 5.44520
Epoch 48, Val Loss: 5.46420
Epoch 49, Val Loss: 5.50003
Epoch 50, Val Loss: 5.46109
Epoch 51, Val Loss: 5.25747
Epoch 52, Val Loss: 5.22777
Epoch 53, Val Loss: 5.41140
Epoch 54, Val Loss: 5.36123
Epoch 55, Val Loss: 5.24264
Epoch 56, Val Loss: 5.29954
Epoch 57, Val Loss: 5.25026
Epoch 58, Val Loss: 5.34602
Epoch 59, Val Loss: 5.39865
Epoch 60, Val Loss: 5.33703
Epoch 61, Val Loss: 5.31426
Epoch 62, Val Loss: 5.43522
Epoch 63, Val Loss: 5.16295
Epoch 64, Val Loss: 5.43341
Epoch 65, Val Loss: 5.18380
Epoch 66, Val Loss: 5.36888
Epoch 67, Val Loss: 5.29950
Epoch 68, Val Loss: 5.19277
Epoch 69, Val Loss: 5.31167
Epoch 70, Val Loss: 5.15698
Epoch 71, Val Loss: 5.22302
Epoch 72, Val Loss: 5.04486
Epoch 73, Val Loss: 5.07108
Epoch 74, Val Loss: 5.12420
Epoch 75, Val Loss: 5.16556
Epoch 76, Val Loss: 5.04959
Epoch 77, Val Loss: 5.06867
Epoch 78, Val Loss: 4.98735
Epoch 79, Val Loss: 5.25381
Epoch 80, Val Loss: 5.31587
Epoch 81, Val Loss: 5.10551
Epoch 82, Val Loss: 5.05953
Epoch 83, Val Loss: 4.96725
Epoch 84, Val Loss: 5.37641
Epoch 85, Val Loss: 5.14369
Epoch 86, Val Loss: 5.15469
Epoch 87, Val Loss: 4.99147
Epoch 88, Val Loss: 5.18165
Epoch 89, Val Loss: 5.08213
Epoch 90, Val Loss: 5.23066
Epoch 91, Val Loss: 4.91620
Epoch 92, Val Loss: 4.97774
Epoch 93, Val Loss: 5.01343
Epoch 94, Val Loss: 5.09601
Epoch 95, Val Loss: 5.70835
Epoch 96, Val Loss: 4.89734
Epoch 97, Val Loss: 4.87100
Epoch 98, Val Loss: 5.16594
Epoch 99, Val Loss: 5.02421
DID NOT SAVE RESULTS
{'MSE - mean': 5.096598484508841, 'MSE - std': 0.0, 'R2 - mean': 0.5352070591227437, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.57423
Epoch 1, Val Loss: 12.47484
Epoch 2, Val Loss: 5.36875
Epoch 3, Val Loss: 5.41706
Epoch 4, Val Loss: 5.22996
Epoch 5, Val Loss: 5.30840
Epoch 6, Val Loss: 5.09331
Epoch 7, Val Loss: 5.16425
Epoch 8, Val Loss: 5.28426
Epoch 9, Val Loss: 4.92887
Epoch 10, Val Loss: 5.43220
Epoch 11, Val Loss: 5.10727
Epoch 12, Val Loss: 5.10238
Epoch 13, Val Loss: 4.97116
Epoch 14, Val Loss: 4.68369
Epoch 15, Val Loss: 4.70943
Epoch 16, Val Loss: 4.68859
Epoch 17, Val Loss: 4.90309
Epoch 18, Val Loss: 4.77444
Epoch 19, Val Loss: 4.84337
Epoch 20, Val Loss: 5.15815
Epoch 21, Val Loss: 4.62499
Epoch 22, Val Loss: 5.38456
Epoch 23, Val Loss: 4.63417
Epoch 24, Val Loss: 4.71968
Epoch 25, Val Loss: 4.52636
Epoch 26, Val Loss: 4.60484
Epoch 27, Val Loss: 4.63551
Epoch 28, Val Loss: 4.45619
Epoch 29, Val Loss: 4.98575
Epoch 30, Val Loss: 4.44514
Epoch 31, Val Loss: 4.48517
Epoch 32, Val Loss: 4.44980
Epoch 33, Val Loss: 4.43815
Epoch 34, Val Loss: 4.41018
Epoch 35, Val Loss: 4.46874
Epoch 36, Val Loss: 4.70533
Epoch 37, Val Loss: 4.48102
Epoch 38, Val Loss: 5.00362
Epoch 39, Val Loss: 5.02523
Epoch 40, Val Loss: 4.34872
Epoch 41, Val Loss: 4.63845
Epoch 42, Val Loss: 4.57410
Epoch 43, Val Loss: 4.38636
Epoch 44, Val Loss: 4.92693
Epoch 45, Val Loss: 4.48788
Epoch 46, Val Loss: 4.43996
Epoch 47, Val Loss: 4.37657
Epoch 48, Val Loss: 4.49058
Epoch 49, Val Loss: 4.53097
Epoch 50, Val Loss: 4.32422
Epoch 51, Val Loss: 4.36001
Epoch 52, Val Loss: 4.55229
Epoch 53, Val Loss: 4.57468
Epoch 54, Val Loss: 4.43831
Epoch 55, Val Loss: 4.41549
Epoch 56, Val Loss: 4.24548
Epoch 57, Val Loss: 4.44983
Epoch 58, Val Loss: 4.31320
Epoch 59, Val Loss: 4.48202
Epoch 60, Val Loss: 4.31229
Epoch 61, Val Loss: 4.29664
Epoch 62, Val Loss: 4.62857
Epoch 63, Val Loss: 4.36705
Epoch 64, Val Loss: 4.32759
Epoch 65, Val Loss: 4.29182
Epoch 66, Val Loss: 4.68196
Epoch 67, Val Loss: 4.23786
Epoch 68, Val Loss: 4.24833
Epoch 69, Val Loss: 4.24284
Epoch 70, Val Loss: 4.39813
Epoch 71, Val Loss: 4.28789
Epoch 72, Val Loss: 4.25391
Epoch 73, Val Loss: 4.46188
Epoch 74, Val Loss: 4.29901
Epoch 75, Val Loss: 4.54176
Epoch 76, Val Loss: 4.33739
Epoch 77, Val Loss: 4.21460
Epoch 78, Val Loss: 4.48287
Epoch 79, Val Loss: 4.21860
Epoch 80, Val Loss: 4.51680
Epoch 81, Val Loss: 4.30655
Epoch 82, Val Loss: 4.50065
Epoch 83, Val Loss: 4.15882
Epoch 84, Val Loss: 4.27353
Epoch 85, Val Loss: 4.33027
Epoch 86, Val Loss: 4.28153
Epoch 87, Val Loss: 4.20635
Epoch 88, Val Loss: 4.31188
Epoch 89, Val Loss: 4.09337
Epoch 90, Val Loss: 4.31020
Epoch 91, Val Loss: 4.52926
Epoch 92, Val Loss: 4.57980
Epoch 93, Val Loss: 4.37857
Epoch 94, Val Loss: 4.28292
Epoch 95, Val Loss: 4.26817
Epoch 96, Val Loss: 4.60860
Epoch 97, Val Loss: 4.23888
Epoch 98, Val Loss: 4.18880
Epoch 99, Val Loss: 4.93989
DID NOT SAVE RESULTS
{'MSE - mean': 4.665697702693446, 'MSE - std': 0.43090078181539493, 'R2 - mean': 0.5418961295140303, 'R2 - std': 0.006689070391286578} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.50872
Epoch 1, Val Loss: 9.58452
Epoch 2, Val Loss: 6.81194
Epoch 3, Val Loss: 6.55275
Epoch 4, Val Loss: 6.31512
Epoch 5, Val Loss: 6.27179
Epoch 6, Val Loss: 6.44019
Epoch 7, Val Loss: 6.20170
Epoch 8, Val Loss: 6.23487
Epoch 9, Val Loss: 6.12261
Epoch 10, Val Loss: 6.10336
Epoch 11, Val Loss: 6.05288
Epoch 12, Val Loss: 6.05304
Epoch 13, Val Loss: 6.04522
Epoch 14, Val Loss: 6.11779
Epoch 15, Val Loss: 6.01987
Epoch 16, Val Loss: 5.94484
Epoch 17, Val Loss: 6.17188
Epoch 18, Val Loss: 5.86272
Epoch 19, Val Loss: 6.10923
Epoch 20, Val Loss: 5.89515
Epoch 21, Val Loss: 5.82710
Epoch 22, Val Loss: 5.75511
Epoch 23, Val Loss: 5.92914
Epoch 24, Val Loss: 5.81477
Epoch 25, Val Loss: 5.70143
Epoch 26, Val Loss: 5.68753
Epoch 27, Val Loss: 5.85184
Epoch 28, Val Loss: 5.74625
Epoch 29, Val Loss: 5.84995
Epoch 30, Val Loss: 5.50183
Epoch 31, Val Loss: 5.76392
Epoch 32, Val Loss: 5.50516
Epoch 33, Val Loss: 5.93310
Epoch 34, Val Loss: 5.72800
Epoch 35, Val Loss: 5.45610
Epoch 36, Val Loss: 5.54520
Epoch 37, Val Loss: 5.62147
Epoch 38, Val Loss: 5.47346
Epoch 39, Val Loss: 5.38757
Epoch 40, Val Loss: 5.46628
Epoch 41, Val Loss: 5.52338
Epoch 42, Val Loss: 5.53345
Epoch 43, Val Loss: 5.52126
Epoch 44, Val Loss: 5.35681
Epoch 45, Val Loss: 5.27251
Epoch 46, Val Loss: 5.41330
Epoch 47, Val Loss: 5.24956
Epoch 48, Val Loss: 5.25970
Epoch 49, Val Loss: 5.34236
Epoch 50, Val Loss: 5.22242
Epoch 51, Val Loss: 5.44205
Epoch 52, Val Loss: 5.20756
Epoch 53, Val Loss: 5.17521
Epoch 54, Val Loss: 5.31764
Epoch 55, Val Loss: 5.39345
Epoch 56, Val Loss: 5.12189
Epoch 57, Val Loss: 5.24675
Epoch 58, Val Loss: 5.60329
Epoch 59, Val Loss: 5.24510
Epoch 60, Val Loss: 5.07033
Epoch 61, Val Loss: 5.14469
Epoch 62, Val Loss: 5.05361
Epoch 63, Val Loss: 5.28957
Epoch 64, Val Loss: 5.04541
Epoch 65, Val Loss: 5.11947
Epoch 66, Val Loss: 5.09589
Epoch 67, Val Loss: 4.90339
Epoch 68, Val Loss: 4.95877
Epoch 69, Val Loss: 4.97424
Epoch 70, Val Loss: 5.14819
Epoch 71, Val Loss: 5.15813
Epoch 72, Val Loss: 4.94378
Epoch 73, Val Loss: 5.09148
Epoch 74, Val Loss: 4.91188
Epoch 75, Val Loss: 5.06640
Epoch 76, Val Loss: 4.95013
Epoch 77, Val Loss: 5.20627
Epoch 78, Val Loss: 5.15550
Epoch 79, Val Loss: 4.84892
Epoch 80, Val Loss: 5.06789
Epoch 81, Val Loss: 4.84116
Epoch 82, Val Loss: 4.96065
Epoch 83, Val Loss: 4.80113
Epoch 84, Val Loss: 4.94010
Epoch 85, Val Loss: 4.90632
Epoch 86, Val Loss: 4.90959
Epoch 87, Val Loss: 4.91476
Epoch 88, Val Loss: 5.08190
Epoch 89, Val Loss: 5.12024
Epoch 90, Val Loss: 4.87351
Epoch 91, Val Loss: 4.81042
Epoch 92, Val Loss: 4.73099
Epoch 93, Val Loss: 4.96645
Epoch 94, Val Loss: 4.90597
Epoch 95, Val Loss: 5.20543
Epoch 96, Val Loss: 4.82610
Epoch 97, Val Loss: 4.81510
Epoch 98, Val Loss: 5.06176
Epoch 99, Val Loss: 4.76815
DID NOT SAVE RESULTS
{'MSE - mean': 4.73887002242487, 'MSE - std': 0.36673155385899725, 'R2 - mean': 0.5343645063034387, 'R2 - std': 0.011969954253840578} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.07460
Epoch 1, Val Loss: 10.94760
Epoch 2, Val Loss: 6.61410
Epoch 3, Val Loss: 5.72701
Epoch 4, Val Loss: 5.51416
Epoch 5, Val Loss: 5.42275
Epoch 6, Val Loss: 5.31460
Epoch 7, Val Loss: 5.24728
Epoch 8, Val Loss: 5.25145
Epoch 9, Val Loss: 5.42681
Epoch 10, Val Loss: 5.28286
Epoch 11, Val Loss: 5.43785
Epoch 12, Val Loss: 5.27697
Epoch 13, Val Loss: 5.47861
Epoch 14, Val Loss: 5.20415
Epoch 15, Val Loss: 5.26189
Epoch 16, Val Loss: 5.20692
Epoch 17, Val Loss: 5.10087
Epoch 18, Val Loss: 5.39901
Epoch 19, Val Loss: 5.08534
Epoch 20, Val Loss: 5.12387
Epoch 21, Val Loss: 5.35766
Epoch 22, Val Loss: 4.97741
Epoch 23, Val Loss: 4.96408
Epoch 24, Val Loss: 4.92607
Epoch 25, Val Loss: 5.04436
Epoch 26, Val Loss: 5.07945
Epoch 27, Val Loss: 4.90875
Epoch 28, Val Loss: 4.97725
Epoch 29, Val Loss: 4.79159
Epoch 30, Val Loss: 4.82697
Epoch 31, Val Loss: 5.01529
Epoch 32, Val Loss: 4.89758
Epoch 33, Val Loss: 4.75081
Epoch 34, Val Loss: 4.72124
Epoch 35, Val Loss: 4.75812
Epoch 36, Val Loss: 4.78726
Epoch 37, Val Loss: 4.87669
Epoch 38, Val Loss: 4.94947
Epoch 39, Val Loss: 4.94183
Epoch 40, Val Loss: 4.65469
Epoch 41, Val Loss: 4.78184
Epoch 42, Val Loss: 4.84435
Epoch 43, Val Loss: 4.65064
Epoch 44, Val Loss: 4.60067
Epoch 45, Val Loss: 4.65276
Epoch 46, Val Loss: 4.64718
Epoch 47, Val Loss: 4.66614
Epoch 48, Val Loss: 4.59513
Epoch 49, Val Loss: 4.66949
Epoch 50, Val Loss: 4.56211
Epoch 51, Val Loss: 4.67269
Epoch 52, Val Loss: 4.56587
Epoch 53, Val Loss: 4.82600
Epoch 54, Val Loss: 4.80838
Epoch 55, Val Loss: 4.47153
Epoch 56, Val Loss: 4.50145
Epoch 57, Val Loss: 4.65539
Epoch 58, Val Loss: 4.54683
Epoch 59, Val Loss: 4.54557
Epoch 60, Val Loss: 4.45942
Epoch 61, Val Loss: 4.69718
Epoch 62, Val Loss: 4.43391
Epoch 63, Val Loss: 4.56473
Epoch 64, Val Loss: 4.49775
Epoch 65, Val Loss: 4.37624
Epoch 66, Val Loss: 4.56955
Epoch 67, Val Loss: 5.31858
Epoch 68, Val Loss: 4.84552
Epoch 69, Val Loss: 4.45858
Epoch 70, Val Loss: 4.55204
Epoch 71, Val Loss: 4.51591
Epoch 72, Val Loss: 4.45534
Epoch 73, Val Loss: 4.51545
Epoch 74, Val Loss: 4.48732
Epoch 75, Val Loss: 4.36171
Epoch 76, Val Loss: 4.33731
Epoch 77, Val Loss: 4.38666
Epoch 78, Val Loss: 4.38377
Epoch 79, Val Loss: 4.63502
Epoch 80, Val Loss: 4.39241
Epoch 81, Val Loss: 4.49969
Epoch 82, Val Loss: 4.33478
Epoch 83, Val Loss: 4.34838
Epoch 84, Val Loss: 4.47277
Epoch 85, Val Loss: 4.39507
Epoch 86, Val Loss: 4.26727
Epoch 87, Val Loss: 4.61577
Epoch 88, Val Loss: 4.43136
Epoch 89, Val Loss: 4.37311
Epoch 90, Val Loss: 4.40793
Epoch 91, Val Loss: 4.20967
Epoch 92, Val Loss: 4.31491
Epoch 93, Val Loss: 4.85415
Epoch 94, Val Loss: 4.34001
Epoch 95, Val Loss: 4.24679
Epoch 96, Val Loss: 4.16569
Epoch 97, Val Loss: 4.35767
Epoch 98, Val Loss: 4.22008
Epoch 99, Val Loss: 4.54090
DID NOT SAVE RESULTS
{'MSE - mean': 4.673181888849267, 'MSE - std': 0.3373630346152569, 'R2 - mean': 0.531126190351949, 'R2 - std': 0.011786429664418953} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.19609
Epoch 1, Val Loss: 12.69591
Epoch 2, Val Loss: 8.40253
Epoch 3, Val Loss: 8.89070
Epoch 4, Val Loss: 8.20939
Epoch 5, Val Loss: 8.30769
Epoch 6, Val Loss: 7.52481
Epoch 7, Val Loss: 7.71747
Epoch 8, Val Loss: 7.45661
Epoch 9, Val Loss: 7.36963
Epoch 10, Val Loss: 7.29010
Epoch 11, Val Loss: 7.33491
Epoch 12, Val Loss: 7.39040
Epoch 13, Val Loss: 7.24352
Epoch 14, Val Loss: 7.17755
Epoch 15, Val Loss: 6.88679
Epoch 16, Val Loss: 7.23922
Epoch 17, Val Loss: 6.85683
Epoch 18, Val Loss: 6.84675
Epoch 19, Val Loss: 6.91878
Epoch 20, Val Loss: 6.84175
Epoch 21, Val Loss: 6.91851
Epoch 22, Val Loss: 6.75012
Epoch 23, Val Loss: 6.59388
Epoch 24, Val Loss: 6.74583
Epoch 25, Val Loss: 6.73337
Epoch 26, Val Loss: 6.75264
Epoch 27, Val Loss: 6.54335
Epoch 28, Val Loss: 6.46357
Epoch 29, Val Loss: 6.40989
Epoch 30, Val Loss: 6.40407
Epoch 31, Val Loss: 6.62974
Epoch 32, Val Loss: 6.65902
Epoch 33, Val Loss: 6.78052
Epoch 34, Val Loss: 6.35511
Epoch 35, Val Loss: 6.26599
Epoch 36, Val Loss: 6.61024
Epoch 37, Val Loss: 6.50077
Epoch 38, Val Loss: 6.79058
Epoch 39, Val Loss: 6.40825
Epoch 40, Val Loss: 6.32057
Epoch 41, Val Loss: 6.16649
Epoch 42, Val Loss: 6.08075
Epoch 43, Val Loss: 6.25544
Epoch 44, Val Loss: 6.60292
Epoch 45, Val Loss: 6.82052
Epoch 46, Val Loss: 6.21059
Epoch 47, Val Loss: 6.72052
Epoch 48, Val Loss: 5.96979
Epoch 49, Val Loss: 6.20690
Epoch 50, Val Loss: 6.09326
Epoch 51, Val Loss: 6.60918
Epoch 52, Val Loss: 6.11489
Epoch 53, Val Loss: 6.30544
Epoch 54, Val Loss: 6.93381
Epoch 55, Val Loss: 6.12401
Epoch 56, Val Loss: 6.13817
Epoch 57, Val Loss: 6.09376
Epoch 58, Val Loss: 6.09206
Epoch 59, Val Loss: 6.62218
Epoch 60, Val Loss: 6.19404
Epoch 61, Val Loss: 6.02086
Epoch 62, Val Loss: 5.92756
Epoch 63, Val Loss: 5.90834
Epoch 64, Val Loss: 6.63020
Epoch 65, Val Loss: 5.91079
Epoch 66, Val Loss: 5.98277
Epoch 67, Val Loss: 5.86650
Epoch 68, Val Loss: 5.96216
Epoch 69, Val Loss: 5.96456
Epoch 70, Val Loss: 6.19755
Epoch 71, Val Loss: 5.77086
Epoch 72, Val Loss: 5.93854
Epoch 73, Val Loss: 5.88181
Epoch 74, Val Loss: 5.64500
Epoch 75, Val Loss: 6.03155
Epoch 76, Val Loss: 6.04096
Epoch 77, Val Loss: 6.15811
Epoch 78, Val Loss: 5.88337
Epoch 79, Val Loss: 5.80853
Epoch 80, Val Loss: 5.92843
Epoch 81, Val Loss: 5.71013
Epoch 82, Val Loss: 6.06646
Epoch 83, Val Loss: 5.93778
Epoch 84, Val Loss: 5.64303
Epoch 85, Val Loss: 5.91961
Epoch 86, Val Loss: 6.35120
Epoch 87, Val Loss: 5.87294
Epoch 88, Val Loss: 5.67634
Epoch 89, Val Loss: 6.53353
Epoch 90, Val Loss: 5.96108
Epoch 91, Val Loss: 5.80171
Epoch 92, Val Loss: 5.70987
Epoch 93, Val Loss: 5.82785
Epoch 94, Val Loss: 5.78914
Epoch 95, Val Loss: 5.86283
Epoch 96, Val Loss: 5.72793
Epoch 97, Val Loss: 5.78103
Epoch 98, Val Loss: 5.74661
Epoch 99, Val Loss: 6.28811
DID NOT SAVE RESULTS
{'MSE - mean': 4.880717677420577, 'MSE - std': 0.5131622237183043, 'R2 - mean': 0.5304436739765883, 'R2 - std': 0.010630110714285986} 
 

Results After CV: {'MSE - mean': 4.880717677420577, 'MSE - std': 0.5131622237183043, 'R2 - mean': 0.5304436739765883, 'R2 - std': 0.010630110714285986}
Train time: 48.761713635400156
Inference time: 0.050804419799897006
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 35 finished with value: 4.880717677420577 and parameters: {'p_m': 0.7940292788212966, 'alpha': 2.4515952483536294, 'K': 5, 'beta': 2.4936669874096613}. Best is trial 29 with value: 4.543469724668304.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.31642
Epoch 1, Val Loss: 10.02587
Epoch 2, Val Loss: 7.29598
Epoch 3, Val Loss: 6.73448
Epoch 4, Val Loss: 6.73852
Epoch 5, Val Loss: 6.50321
Epoch 6, Val Loss: 6.22911
Epoch 7, Val Loss: 6.05170
Epoch 8, Val Loss: 5.95107
Epoch 9, Val Loss: 5.84286
Epoch 10, Val Loss: 5.54809
Epoch 11, Val Loss: 5.62969
Epoch 12, Val Loss: 5.58201
Epoch 13, Val Loss: 5.37818
Epoch 14, Val Loss: 5.41517
Epoch 15, Val Loss: 5.44372
Epoch 16, Val Loss: 5.22074
Epoch 17, Val Loss: 5.34331
Epoch 18, Val Loss: 5.35437
Epoch 19, Val Loss: 5.17407
Epoch 20, Val Loss: 5.05712
Epoch 21, Val Loss: 5.52430
Epoch 22, Val Loss: 5.07025
Epoch 23, Val Loss: 5.57142
Epoch 24, Val Loss: 5.16449
Epoch 25, Val Loss: 5.11187
Epoch 26, Val Loss: 4.97692
Epoch 27, Val Loss: 4.96910
Epoch 28, Val Loss: 5.05042
Epoch 29, Val Loss: 4.98070
Epoch 30, Val Loss: 4.92637
Epoch 31, Val Loss: 4.95182
Epoch 32, Val Loss: 4.96799
Epoch 33, Val Loss: 4.83285
Epoch 34, Val Loss: 4.85563
Epoch 35, Val Loss: 5.12102
Epoch 36, Val Loss: 4.89665
Epoch 37, Val Loss: 5.00717
Epoch 38, Val Loss: 4.81292
Epoch 39, Val Loss: 4.88589
Epoch 40, Val Loss: 4.75312
Epoch 41, Val Loss: 4.68502
Epoch 42, Val Loss: 4.79475
Epoch 43, Val Loss: 4.78646
Epoch 44, Val Loss: 4.62547
Epoch 45, Val Loss: 4.95670
Epoch 46, Val Loss: 4.72507
Epoch 47, Val Loss: 4.85489
Epoch 48, Val Loss: 4.60332
Epoch 49, Val Loss: 4.82990
Epoch 50, Val Loss: 5.25841
Epoch 51, Val Loss: 5.41699
Epoch 52, Val Loss: 4.64437
Epoch 53, Val Loss: 4.82216
Epoch 54, Val Loss: 4.77185
Epoch 55, Val Loss: 4.80313
Epoch 56, Val Loss: 4.72680
Epoch 57, Val Loss: 4.70023
Epoch 58, Val Loss: 4.65844
Epoch 59, Val Loss: 4.80237
Epoch 60, Val Loss: 5.10303
Epoch 61, Val Loss: 4.66464
Epoch 62, Val Loss: 4.62478
Epoch 63, Val Loss: 4.69049
Epoch 64, Val Loss: 4.64074
Epoch 65, Val Loss: 4.92421
Epoch 66, Val Loss: 4.80196
Epoch 67, Val Loss: 4.80611
Epoch 68, Val Loss: 4.52210
Epoch 69, Val Loss: 5.24202
Epoch 70, Val Loss: 4.76192
Epoch 71, Val Loss: 4.48650
Epoch 72, Val Loss: 4.82528
Epoch 73, Val Loss: 4.59930
Epoch 74, Val Loss: 4.57530
Epoch 75, Val Loss: 4.56455
Epoch 76, Val Loss: 4.47188
Epoch 77, Val Loss: 5.01967
Epoch 78, Val Loss: 5.07261
Epoch 79, Val Loss: 4.55463
Epoch 80, Val Loss: 4.66512
Epoch 81, Val Loss: 4.65962
Epoch 82, Val Loss: 4.59625
Epoch 83, Val Loss: 4.48985
Epoch 84, Val Loss: 4.88381
Epoch 85, Val Loss: 4.57755
Epoch 86, Val Loss: 4.70080
Epoch 87, Val Loss: 4.61988
Epoch 88, Val Loss: 4.72123
Epoch 89, Val Loss: 4.74429
Epoch 90, Val Loss: 4.54921
Epoch 91, Val Loss: 4.78714
Epoch 92, Val Loss: 4.72276
Epoch 93, Val Loss: 4.68739
Epoch 94, Val Loss: 4.80657
Epoch 95, Val Loss: 4.63463
Epoch 96, Val Loss: 4.59787
Epoch 97, Val Loss: 4.52593
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.621835597240814, 'MSE - std': 0.0, 'R2 - mean': 0.5785038656621251, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.52973
Epoch 1, Val Loss: 9.44108
Epoch 2, Val Loss: 5.53172
Epoch 3, Val Loss: 5.12994
Epoch 4, Val Loss: 5.08945
Epoch 5, Val Loss: 5.01342
Epoch 6, Val Loss: 4.91791
Epoch 7, Val Loss: 4.66004
Epoch 8, Val Loss: 4.74439
Epoch 9, Val Loss: 4.62674
Epoch 10, Val Loss: 4.86130
Epoch 11, Val Loss: 4.43155
Epoch 12, Val Loss: 4.56639
Epoch 13, Val Loss: 4.46128
Epoch 14, Val Loss: 4.47709
Epoch 15, Val Loss: 4.43138
Epoch 16, Val Loss: 4.75080
Epoch 17, Val Loss: 4.33464
Epoch 18, Val Loss: 4.30725
Epoch 19, Val Loss: 4.62078
Epoch 20, Val Loss: 4.56405
Epoch 21, Val Loss: 4.22737
Epoch 22, Val Loss: 4.18398
Epoch 23, Val Loss: 4.49764
Epoch 24, Val Loss: 4.15448
Epoch 25, Val Loss: 4.62255
Epoch 26, Val Loss: 4.42357
Epoch 27, Val Loss: 4.18715
Epoch 28, Val Loss: 4.56868
Epoch 29, Val Loss: 4.15209
Epoch 30, Val Loss: 4.22894
Epoch 31, Val Loss: 4.12603
Epoch 32, Val Loss: 4.09469
Epoch 33, Val Loss: 4.27720
Epoch 34, Val Loss: 4.07259
Epoch 35, Val Loss: 4.06399
Epoch 36, Val Loss: 4.02702
Epoch 37, Val Loss: 3.99316
Epoch 38, Val Loss: 3.95266
Epoch 39, Val Loss: 4.15950
Epoch 40, Val Loss: 4.01105
Epoch 41, Val Loss: 4.04232
Epoch 42, Val Loss: 3.92834
Epoch 43, Val Loss: 3.90675
Epoch 44, Val Loss: 3.88155
Epoch 45, Val Loss: 4.25326
Epoch 46, Val Loss: 4.03857
Epoch 47, Val Loss: 3.91087
Epoch 48, Val Loss: 4.00952
Epoch 49, Val Loss: 3.91939
Epoch 50, Val Loss: 3.90528
Epoch 51, Val Loss: 3.96901
Epoch 52, Val Loss: 5.32971
Epoch 53, Val Loss: 3.90492
Epoch 54, Val Loss: 3.99283
Epoch 55, Val Loss: 3.98139
Epoch 56, Val Loss: 4.24886
Epoch 57, Val Loss: 4.77459
Epoch 58, Val Loss: 4.02237
Epoch 59, Val Loss: 3.96369
Epoch 60, Val Loss: 3.85597
Epoch 61, Val Loss: 3.88296
Epoch 62, Val Loss: 3.91399
Epoch 63, Val Loss: 3.88273
Epoch 64, Val Loss: 3.89417
Epoch 65, Val Loss: 3.88804
Epoch 66, Val Loss: 4.00683
Epoch 67, Val Loss: 3.92586
Epoch 68, Val Loss: 3.92630
Epoch 69, Val Loss: 3.88247
Epoch 70, Val Loss: 4.41057
Epoch 71, Val Loss: 3.87153
Epoch 72, Val Loss: 3.82764
Epoch 73, Val Loss: 3.93367
Epoch 74, Val Loss: 4.24671
Epoch 75, Val Loss: 3.89813
Epoch 76, Val Loss: 4.19185
Epoch 77, Val Loss: 4.32187
Epoch 78, Val Loss: 3.84658
Epoch 79, Val Loss: 3.91605
Epoch 80, Val Loss: 4.59735
Epoch 81, Val Loss: 4.20274
Epoch 82, Val Loss: 4.36485
Epoch 83, Val Loss: 3.88960
Epoch 84, Val Loss: 4.76644
Epoch 85, Val Loss: 3.85462
Epoch 86, Val Loss: 3.98635
Epoch 87, Val Loss: 3.82302
Epoch 88, Val Loss: 4.21182
Epoch 89, Val Loss: 4.66634
Epoch 90, Val Loss: 3.90068
Epoch 91, Val Loss: 4.25664
Epoch 92, Val Loss: 4.14336
Epoch 93, Val Loss: 3.86384
Epoch 94, Val Loss: 3.96218
Epoch 95, Val Loss: 3.93049
Epoch 96, Val Loss: 4.09530
Epoch 97, Val Loss: 4.39854
Epoch 98, Val Loss: 4.23166
Epoch 99, Val Loss: 4.04612
DID NOT SAVE RESULTS
{'MSE - mean': 4.309234485902294, 'MSE - std': 0.3126011113385201, 'R2 - mean': 0.576238240611747, 'R2 - std': 0.0022656250503781394} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.52819
Epoch 1, Val Loss: 12.24937
Epoch 2, Val Loss: 6.58988
Epoch 3, Val Loss: 6.20541
Epoch 4, Val Loss: 6.21609
Epoch 5, Val Loss: 5.99506
Epoch 6, Val Loss: 5.73983
Epoch 7, Val Loss: 5.70317
Epoch 8, Val Loss: 5.63828
Epoch 9, Val Loss: 5.59508
Epoch 10, Val Loss: 5.89531
Epoch 11, Val Loss: 5.45466
Epoch 12, Val Loss: 5.38964
Epoch 13, Val Loss: 5.30880
Epoch 14, Val Loss: 5.24658
Epoch 15, Val Loss: 5.23089
Epoch 16, Val Loss: 5.16533
Epoch 17, Val Loss: 5.07987
Epoch 18, Val Loss: 5.12248
Epoch 19, Val Loss: 5.09605
Epoch 20, Val Loss: 5.19544
Epoch 21, Val Loss: 4.97251
Epoch 22, Val Loss: 4.95282
Epoch 23, Val Loss: 5.22230
Epoch 24, Val Loss: 5.12339
Epoch 25, Val Loss: 4.81724
Epoch 26, Val Loss: 4.81212
Epoch 27, Val Loss: 4.76970
Epoch 28, Val Loss: 4.55723
Epoch 29, Val Loss: 4.71522
Epoch 30, Val Loss: 4.75070
Epoch 31, Val Loss: 4.66402
Epoch 32, Val Loss: 4.53212
Epoch 33, Val Loss: 4.49632
Epoch 34, Val Loss: 4.71910
Epoch 35, Val Loss: 4.50302
Epoch 36, Val Loss: 4.99309
Epoch 37, Val Loss: 4.76292
Epoch 38, Val Loss: 4.45601
Epoch 39, Val Loss: 4.63180
Epoch 40, Val Loss: 4.43033
Epoch 41, Val Loss: 4.56282
Epoch 42, Val Loss: 4.69051
Epoch 43, Val Loss: 4.37576
Epoch 44, Val Loss: 4.48219
Epoch 45, Val Loss: 4.48522
Epoch 46, Val Loss: 4.44777
Epoch 47, Val Loss: 4.85668
Epoch 48, Val Loss: 4.69119
Epoch 49, Val Loss: 4.59604
Epoch 50, Val Loss: 4.33852
Epoch 51, Val Loss: 4.49209
Epoch 52, Val Loss: 4.49912
Epoch 53, Val Loss: 4.49933
Epoch 54, Val Loss: 4.44543
Epoch 55, Val Loss: 4.63014
Epoch 56, Val Loss: 4.31557
Epoch 57, Val Loss: 4.32016
Epoch 58, Val Loss: 4.37210
Epoch 59, Val Loss: 4.31951
Epoch 60, Val Loss: 4.34837
Epoch 61, Val Loss: 4.31696
Epoch 62, Val Loss: 4.51831
Epoch 63, Val Loss: 4.66072
Epoch 64, Val Loss: 4.32796
Epoch 65, Val Loss: 4.57242
Epoch 66, Val Loss: 4.59548
Epoch 67, Val Loss: 4.29833
Epoch 68, Val Loss: 4.27501
Epoch 69, Val Loss: 4.42422
Epoch 70, Val Loss: 4.32248
Epoch 71, Val Loss: 4.32989
Epoch 72, Val Loss: 4.47485
Epoch 73, Val Loss: 4.29983
Epoch 74, Val Loss: 4.56670
Epoch 75, Val Loss: 4.57767
Epoch 76, Val Loss: 4.31236
Epoch 77, Val Loss: 4.32215
Epoch 78, Val Loss: 4.38711
Epoch 79, Val Loss: 4.54878
Epoch 80, Val Loss: 4.29027
Epoch 81, Val Loss: 4.37989
Epoch 82, Val Loss: 4.37792
Epoch 83, Val Loss: 4.65627
Epoch 84, Val Loss: 4.44193
Epoch 85, Val Loss: 4.31247
Epoch 86, Val Loss: 4.37348
Epoch 87, Val Loss: 4.52120
Epoch 88, Val Loss: 4.44988
Epoch 89, Val Loss: 4.34493
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.333892822143395, 'MSE - std': 0.25760894840644977, 'R2 - mean': 0.5737247978954894, 'R2 - std': 0.0040070970150992875} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.03076
Epoch 1, Val Loss: 11.53745
Epoch 2, Val Loss: 5.39710
Epoch 3, Val Loss: 5.28203
Epoch 4, Val Loss: 4.87158
Epoch 5, Val Loss: 5.00258
Epoch 6, Val Loss: 4.79241
Epoch 7, Val Loss: 4.64102
Epoch 8, Val Loss: 4.56363
Epoch 9, Val Loss: 4.49611
Epoch 10, Val Loss: 4.48169
Epoch 11, Val Loss: 4.62392
Epoch 12, Val Loss: 4.51321
Epoch 13, Val Loss: 4.41182
Epoch 14, Val Loss: 4.47808
Epoch 15, Val Loss: 4.41173
Epoch 16, Val Loss: 4.25124
Epoch 17, Val Loss: 4.50412
Epoch 18, Val Loss: 4.29464
Epoch 19, Val Loss: 4.71440
Epoch 20, Val Loss: 4.58567
Epoch 21, Val Loss: 4.42324
Epoch 22, Val Loss: 4.28162
Epoch 23, Val Loss: 4.19930
Epoch 24, Val Loss: 4.39460
Epoch 25, Val Loss: 4.27281
Epoch 26, Val Loss: 4.15337
Epoch 27, Val Loss: 4.36288
Epoch 28, Val Loss: 4.18123
Epoch 29, Val Loss: 4.20821
Epoch 30, Val Loss: 4.15249
Epoch 31, Val Loss: 4.24398
Epoch 32, Val Loss: 4.00819
Epoch 33, Val Loss: 4.21311
Epoch 34, Val Loss: 4.04387
Epoch 35, Val Loss: 4.07587
Epoch 36, Val Loss: 4.13452
Epoch 37, Val Loss: 4.40167
Epoch 38, Val Loss: 5.03028
Epoch 39, Val Loss: 4.21597
Epoch 40, Val Loss: 4.20984
Epoch 41, Val Loss: 4.03408
Epoch 42, Val Loss: 4.27550
Epoch 43, Val Loss: 4.18614
Epoch 44, Val Loss: 4.01447
Epoch 45, Val Loss: 4.04400
Epoch 46, Val Loss: 4.07469
Epoch 47, Val Loss: 4.15246
Epoch 48, Val Loss: 4.03718
Epoch 49, Val Loss: 4.05497
Epoch 50, Val Loss: 3.98701
Epoch 51, Val Loss: 4.03602
Epoch 52, Val Loss: 4.24773
Epoch 53, Val Loss: 4.10030
Epoch 54, Val Loss: 4.45559
Epoch 55, Val Loss: 3.99114
Epoch 56, Val Loss: 4.28392
Epoch 57, Val Loss: 4.15150
Epoch 58, Val Loss: 4.03437
Epoch 59, Val Loss: 3.90603
Epoch 60, Val Loss: 3.95819
Epoch 61, Val Loss: 3.98938
Epoch 62, Val Loss: 3.99642
Epoch 63, Val Loss: 3.98752
Epoch 64, Val Loss: 4.48629
Epoch 65, Val Loss: 3.99636
Epoch 66, Val Loss: 3.87096
Epoch 67, Val Loss: 3.99997
Epoch 68, Val Loss: 3.89604
Epoch 69, Val Loss: 4.11958
Epoch 70, Val Loss: 3.93351
Epoch 71, Val Loss: 3.86605
Epoch 72, Val Loss: 3.95448
Epoch 73, Val Loss: 4.13756
Epoch 74, Val Loss: 4.08262
Epoch 75, Val Loss: 3.96218
Epoch 76, Val Loss: 3.99130
Epoch 77, Val Loss: 4.04356
Epoch 78, Val Loss: 4.06668
Epoch 79, Val Loss: 4.59667
Epoch 80, Val Loss: 3.96145
Epoch 81, Val Loss: 4.24604
Epoch 82, Val Loss: 4.06608
Epoch 83, Val Loss: 3.97386
Epoch 84, Val Loss: 3.91701
Epoch 85, Val Loss: 3.90940
Epoch 86, Val Loss: 3.81671
Epoch 87, Val Loss: 3.96696
Epoch 88, Val Loss: 3.97768
Epoch 89, Val Loss: 3.93951
Epoch 90, Val Loss: 3.92468
Epoch 91, Val Loss: 4.06908
Epoch 92, Val Loss: 4.08096
Epoch 93, Val Loss: 3.87379
Epoch 94, Val Loss: 4.04859
Epoch 95, Val Loss: 3.97745
Epoch 96, Val Loss: 3.86474
Epoch 97, Val Loss: 3.90382
Epoch 98, Val Loss: 3.89343
Epoch 99, Val Loss: 3.93234
DID NOT SAVE RESULTS
{'MSE - mean': 4.27903808612533, 'MSE - std': 0.2424848529602261, 'R2 - mean': 0.5703131887078512, 'R2 - std': 0.006852725852815393} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 40.00325
Epoch 1, Val Loss: 11.72466
Epoch 2, Val Loss: 8.18715
Epoch 3, Val Loss: 7.32126
Epoch 4, Val Loss: 7.34976
Epoch 5, Val Loss: 7.03034
Epoch 6, Val Loss: 6.96482
Epoch 7, Val Loss: 6.92967
Epoch 8, Val Loss: 6.87993
Epoch 9, Val Loss: 6.85428
Epoch 10, Val Loss: 6.78904
Epoch 11, Val Loss: 6.61943
Epoch 12, Val Loss: 6.51756
Epoch 13, Val Loss: 6.41996
Epoch 14, Val Loss: 6.76931
Epoch 15, Val Loss: 6.39438
Epoch 16, Val Loss: 6.29328
Epoch 17, Val Loss: 6.33573
Epoch 18, Val Loss: 6.31632
Epoch 19, Val Loss: 6.35848
Epoch 20, Val Loss: 6.18183
Epoch 21, Val Loss: 6.36559
Epoch 22, Val Loss: 6.17448
Epoch 23, Val Loss: 6.23444
Epoch 24, Val Loss: 6.36314
Epoch 25, Val Loss: 6.20761
Epoch 26, Val Loss: 6.25626
Epoch 27, Val Loss: 6.10851
Epoch 28, Val Loss: 6.10514
Epoch 29, Val Loss: 6.07616
Epoch 30, Val Loss: 6.14407
Epoch 31, Val Loss: 6.01029
Epoch 32, Val Loss: 6.23631
Epoch 33, Val Loss: 5.95888
Epoch 34, Val Loss: 5.94274
Epoch 35, Val Loss: 6.00605
Epoch 36, Val Loss: 6.28070
Epoch 37, Val Loss: 6.36132
Epoch 38, Val Loss: 5.85038
Epoch 39, Val Loss: 5.90692
Epoch 40, Val Loss: 5.92109
Epoch 41, Val Loss: 6.14333
Epoch 42, Val Loss: 6.19897
Epoch 43, Val Loss: 6.09150
Epoch 44, Val Loss: 6.51406
Epoch 45, Val Loss: 5.84376
Epoch 46, Val Loss: 5.72272
Epoch 47, Val Loss: 5.84587
Epoch 48, Val Loss: 6.09177
Epoch 49, Val Loss: 5.69561
Epoch 50, Val Loss: 5.81629
Epoch 51, Val Loss: 5.69942
Epoch 52, Val Loss: 5.77664
Epoch 53, Val Loss: 5.67988
Epoch 54, Val Loss: 5.93105
Epoch 55, Val Loss: 5.72228
Epoch 56, Val Loss: 5.95275
Epoch 57, Val Loss: 5.77367
Epoch 58, Val Loss: 6.08813
Epoch 59, Val Loss: 5.75959
Epoch 60, Val Loss: 5.90870
Epoch 61, Val Loss: 5.58762
Epoch 62, Val Loss: 5.56347
Epoch 63, Val Loss: 5.60114
Epoch 64, Val Loss: 5.79789
Epoch 65, Val Loss: 5.56108
Epoch 66, Val Loss: 5.58579
Epoch 67, Val Loss: 5.38825
Epoch 68, Val Loss: 5.75958
Epoch 69, Val Loss: 5.38091
Epoch 70, Val Loss: 5.58438
Epoch 71, Val Loss: 5.92759
Epoch 72, Val Loss: 5.80007
Epoch 73, Val Loss: 5.63557
Epoch 74, Val Loss: 5.33496
Epoch 75, Val Loss: 5.67187
Epoch 76, Val Loss: 5.60970
Epoch 77, Val Loss: 5.50947
Epoch 78, Val Loss: 5.52732
Epoch 79, Val Loss: 5.81614
Epoch 80, Val Loss: 5.36643
Epoch 81, Val Loss: 5.43615
Epoch 82, Val Loss: 5.60680
Epoch 83, Val Loss: 5.43798
Epoch 84, Val Loss: 5.61626
Epoch 85, Val Loss: 5.60755
Epoch 86, Val Loss: 5.48943
Epoch 87, Val Loss: 5.57295
Epoch 88, Val Loss: 5.68179
Epoch 89, Val Loss: 5.52666
Epoch 90, Val Loss: 5.55849
Epoch 91, Val Loss: 5.60944
Epoch 92, Val Loss: 5.48449
Epoch 93, Val Loss: 5.78310
Epoch 94, Val Loss: 5.44773
Epoch 95, Val Loss: 5.84522
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.48540081526779, 'MSE - std': 0.4662418117764775, 'R2 - mean': 0.568409397967849, 'R2 - std': 0.00721564674980344} 
 

Results After CV: {'MSE - mean': 4.48540081526779, 'MSE - std': 0.4662418117764775, 'R2 - mean': 0.568409397967849, 'R2 - std': 0.00721564674980344}
Train time: 79.10281972400007
Inference time: 0.05285724739969737
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 36 finished with value: 4.48540081526779 and parameters: {'p_m': 0.8721504351545861, 'alpha': 3.038715869332491, 'K': 10, 'beta': 1.2414847045108695}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.78769
Epoch 1, Val Loss: 9.79381
Epoch 2, Val Loss: 7.07466
Epoch 3, Val Loss: 6.71927
Epoch 4, Val Loss: 6.31286
Epoch 5, Val Loss: 6.19043
Epoch 6, Val Loss: 5.96307
Epoch 7, Val Loss: 5.72112
Epoch 8, Val Loss: 5.65146
Epoch 9, Val Loss: 5.51911
Epoch 10, Val Loss: 5.53340
Epoch 11, Val Loss: 5.52252
Epoch 12, Val Loss: 5.33682
Epoch 13, Val Loss: 5.22649
Epoch 14, Val Loss: 5.13786
Epoch 15, Val Loss: 5.07722
Epoch 16, Val Loss: 5.23333
Epoch 17, Val Loss: 4.93024
Epoch 18, Val Loss: 5.12728
Epoch 19, Val Loss: 4.85371
Epoch 20, Val Loss: 4.81849
Epoch 21, Val Loss: 4.99907
Epoch 22, Val Loss: 4.77816
Epoch 23, Val Loss: 4.95322
Epoch 24, Val Loss: 4.73064
Epoch 25, Val Loss: 4.66583
Epoch 26, Val Loss: 4.77194
Epoch 27, Val Loss: 4.68926
Epoch 28, Val Loss: 4.63133
Epoch 29, Val Loss: 4.63609
Epoch 30, Val Loss: 4.69118
Epoch 31, Val Loss: 4.67039
Epoch 32, Val Loss: 4.84661
Epoch 33, Val Loss: 4.69318
Epoch 34, Val Loss: 4.73060
Epoch 35, Val Loss: 4.83635
Epoch 36, Val Loss: 4.67396
Epoch 37, Val Loss: 4.76404
Epoch 38, Val Loss: 4.47372
Epoch 39, Val Loss: 4.48988
Epoch 40, Val Loss: 4.47627
Epoch 41, Val Loss: 4.53034
Epoch 42, Val Loss: 4.48011
Epoch 43, Val Loss: 4.48153
Epoch 44, Val Loss: 4.46969
Epoch 45, Val Loss: 4.40997
Epoch 46, Val Loss: 4.48173
Epoch 47, Val Loss: 4.61505
Epoch 48, Val Loss: 4.47561
Epoch 49, Val Loss: 4.61019
Epoch 50, Val Loss: 4.51788
Epoch 51, Val Loss: 4.42540
Epoch 52, Val Loss: 4.52583
Epoch 53, Val Loss: 4.41242
Epoch 54, Val Loss: 4.41331
Epoch 55, Val Loss: 4.73845
Epoch 56, Val Loss: 4.49617
Epoch 57, Val Loss: 4.27056
Epoch 58, Val Loss: 4.52041
Epoch 59, Val Loss: 4.71302
Epoch 60, Val Loss: 4.71213
Epoch 61, Val Loss: 4.72375
Epoch 62, Val Loss: 4.32867
Epoch 63, Val Loss: 4.32874
Epoch 64, Val Loss: 4.43436
Epoch 65, Val Loss: 4.59528
Epoch 66, Val Loss: 5.34452
Epoch 67, Val Loss: 4.69689
Epoch 68, Val Loss: 4.37023
Epoch 69, Val Loss: 4.51145
Epoch 70, Val Loss: 4.48563
Epoch 71, Val Loss: 4.41064
Epoch 72, Val Loss: 4.36627
Epoch 73, Val Loss: 4.84813
Epoch 74, Val Loss: 4.44174
Epoch 75, Val Loss: 4.30226
Epoch 76, Val Loss: 4.43865
Epoch 77, Val Loss: 4.42775
Epoch 78, Val Loss: 4.46230
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.452384592384832, 'MSE - std': 0.0, 'R2 - mean': 0.5939572373807348, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.36810
Epoch 1, Val Loss: 8.75964
Epoch 2, Val Loss: 6.08871
Epoch 3, Val Loss: 5.74044
Epoch 4, Val Loss: 5.61340
Epoch 5, Val Loss: 5.38940
Epoch 6, Val Loss: 5.22413
Epoch 7, Val Loss: 5.41528
Epoch 8, Val Loss: 5.43399
Epoch 9, Val Loss: 5.08266
Epoch 10, Val Loss: 5.17985
Epoch 11, Val Loss: 5.10909
Epoch 12, Val Loss: 5.08260
Epoch 13, Val Loss: 5.03440
Epoch 14, Val Loss: 5.12501
Epoch 15, Val Loss: 5.25510
Epoch 16, Val Loss: 5.08922
Epoch 17, Val Loss: 4.94318
Epoch 18, Val Loss: 5.16079
Epoch 19, Val Loss: 4.83798
Epoch 20, Val Loss: 4.82135
Epoch 21, Val Loss: 4.72298
Epoch 22, Val Loss: 4.76888
Epoch 23, Val Loss: 4.81248
Epoch 24, Val Loss: 4.65165
Epoch 25, Val Loss: 4.61163
Epoch 26, Val Loss: 4.66361
Epoch 27, Val Loss: 4.70732
Epoch 28, Val Loss: 5.16535
Epoch 29, Val Loss: 4.70015
Epoch 30, Val Loss: 4.55455
Epoch 31, Val Loss: 4.59902
Epoch 32, Val Loss: 4.76606
Epoch 33, Val Loss: 4.89004
Epoch 34, Val Loss: 4.44347
Epoch 35, Val Loss: 4.40049
Epoch 36, Val Loss: 4.33639
Epoch 37, Val Loss: 4.60655
Epoch 38, Val Loss: 4.58132
Epoch 39, Val Loss: 4.41292
Epoch 40, Val Loss: 4.44817
Epoch 41, Val Loss: 4.53438
Epoch 42, Val Loss: 4.25343
Epoch 43, Val Loss: 4.23104
Epoch 44, Val Loss: 4.26327
Epoch 45, Val Loss: 4.28257
Epoch 46, Val Loss: 4.19794
Epoch 47, Val Loss: 4.30736
Epoch 48, Val Loss: 4.14393
Epoch 49, Val Loss: 4.36920
Epoch 50, Val Loss: 4.37117
Epoch 51, Val Loss: 4.18927
Epoch 52, Val Loss: 4.60920
Epoch 53, Val Loss: 4.06333
Epoch 54, Val Loss: 4.49833
Epoch 55, Val Loss: 4.14273
Epoch 56, Val Loss: 4.08795
Epoch 57, Val Loss: 4.15751
Epoch 58, Val Loss: 4.21757
Epoch 59, Val Loss: 4.08881
Epoch 60, Val Loss: 4.54522
Epoch 61, Val Loss: 4.14961
Epoch 62, Val Loss: 4.19524
Epoch 63, Val Loss: 4.28763
Epoch 64, Val Loss: 4.05909
Epoch 65, Val Loss: 4.03484
Epoch 66, Val Loss: 4.07382
Epoch 67, Val Loss: 4.10542
Epoch 68, Val Loss: 4.04548
Epoch 69, Val Loss: 4.04866
Epoch 70, Val Loss: 4.09286
Epoch 71, Val Loss: 4.30777
Epoch 72, Val Loss: 4.95402
Epoch 73, Val Loss: 4.33314
Epoch 74, Val Loss: 4.16488
Epoch 75, Val Loss: 4.46839
Epoch 76, Val Loss: 4.03294
Epoch 77, Val Loss: 4.18976
Epoch 78, Val Loss: 4.19807
Epoch 79, Val Loss: 4.05613
Epoch 80, Val Loss: 4.05837
Epoch 81, Val Loss: 4.38197
Epoch 82, Val Loss: 4.12940
Epoch 83, Val Loss: 4.42619
Epoch 84, Val Loss: 3.98325
Epoch 85, Val Loss: 4.16715
Epoch 86, Val Loss: 4.23938
Epoch 87, Val Loss: 4.10118
Epoch 88, Val Loss: 4.28696
Epoch 89, Val Loss: 4.05972
Epoch 90, Val Loss: 4.10039
Epoch 91, Val Loss: 4.04983
Epoch 92, Val Loss: 4.21505
Epoch 93, Val Loss: 4.12517
Epoch 94, Val Loss: 4.11158
Epoch 95, Val Loss: 4.31554
Epoch 96, Val Loss: 4.45162
Epoch 97, Val Loss: 4.86254
Epoch 98, Val Loss: 4.12925
Epoch 99, Val Loss: 4.10169
DID NOT SAVE RESULTS
{'MSE - mean': 4.287076330772786, 'MSE - std': 0.1653082616120467, 'R2 - mean': 0.5772954622438644, 'R2 - std': 0.016661775136870338} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.16474
Epoch 1, Val Loss: 10.15096
Epoch 2, Val Loss: 8.23723
Epoch 3, Val Loss: 7.26625
Epoch 4, Val Loss: 6.52960
Epoch 5, Val Loss: 6.17850
Epoch 6, Val Loss: 6.12541
Epoch 7, Val Loss: 5.88810
Epoch 8, Val Loss: 6.43395
Epoch 9, Val Loss: 5.70755
Epoch 10, Val Loss: 5.71392
Epoch 11, Val Loss: 5.54930
Epoch 12, Val Loss: 5.44443
Epoch 13, Val Loss: 5.50898
Epoch 14, Val Loss: 5.33283
Epoch 15, Val Loss: 5.52741
Epoch 16, Val Loss: 5.30799
Epoch 17, Val Loss: 5.23622
Epoch 18, Val Loss: 5.19289
Epoch 19, Val Loss: 5.36596
Epoch 20, Val Loss: 5.06961
Epoch 21, Val Loss: 5.18759
Epoch 22, Val Loss: 5.07118
Epoch 23, Val Loss: 5.29716
Epoch 24, Val Loss: 4.95547
Epoch 25, Val Loss: 4.94687
Epoch 26, Val Loss: 4.90353
Epoch 27, Val Loss: 5.09261
Epoch 28, Val Loss: 5.01248
Epoch 29, Val Loss: 5.00043
Epoch 30, Val Loss: 4.80695
Epoch 31, Val Loss: 4.74416
Epoch 32, Val Loss: 5.07267
Epoch 33, Val Loss: 4.78791
Epoch 34, Val Loss: 4.96752
Epoch 35, Val Loss: 5.15571
Epoch 36, Val Loss: 4.63592
Epoch 37, Val Loss: 4.63958
Epoch 38, Val Loss: 4.76119
Epoch 39, Val Loss: 4.64346
Epoch 40, Val Loss: 5.10174
Epoch 41, Val Loss: 4.59844
Epoch 42, Val Loss: 4.53364
Epoch 43, Val Loss: 4.70815
Epoch 44, Val Loss: 4.50669
Epoch 45, Val Loss: 4.57536
Epoch 46, Val Loss: 4.51423
Epoch 47, Val Loss: 4.50488
Epoch 48, Val Loss: 4.46409
Epoch 49, Val Loss: 4.72178
Epoch 50, Val Loss: 4.50944
Epoch 51, Val Loss: 4.55496
Epoch 52, Val Loss: 4.45676
Epoch 53, Val Loss: 4.64182
Epoch 54, Val Loss: 4.46500
Epoch 55, Val Loss: 4.51290
Epoch 56, Val Loss: 4.47883
Epoch 57, Val Loss: 4.65484
Epoch 58, Val Loss: 4.58950
Epoch 59, Val Loss: 4.43595
Epoch 60, Val Loss: 4.41597
Epoch 61, Val Loss: 4.45762
Epoch 62, Val Loss: 4.85100
Epoch 63, Val Loss: 4.51080
Epoch 64, Val Loss: 4.66058
Epoch 65, Val Loss: 4.44778
Epoch 66, Val Loss: 4.43742
Epoch 67, Val Loss: 4.47328
Epoch 68, Val Loss: 4.42451
Epoch 69, Val Loss: 4.47089
Epoch 70, Val Loss: 4.43907
Epoch 71, Val Loss: 4.62051
Epoch 72, Val Loss: 4.67030
Epoch 73, Val Loss: 4.41281
Epoch 74, Val Loss: 4.52631
Epoch 75, Val Loss: 4.40670
Epoch 76, Val Loss: 4.43197
Epoch 77, Val Loss: 4.56434
Epoch 78, Val Loss: 5.42513
Epoch 79, Val Loss: 4.50050
Epoch 80, Val Loss: 4.46084
Epoch 81, Val Loss: 4.59414
Epoch 82, Val Loss: 4.52342
Epoch 83, Val Loss: 4.68594
Epoch 84, Val Loss: 4.35943
Epoch 85, Val Loss: 4.47584
Epoch 86, Val Loss: 4.40081
Epoch 87, Val Loss: 4.40954
Epoch 88, Val Loss: 4.46786
Epoch 89, Val Loss: 4.43432
Epoch 90, Val Loss: 4.63508
Epoch 91, Val Loss: 4.40267
Epoch 92, Val Loss: 5.18458
Epoch 93, Val Loss: 4.56845
Epoch 94, Val Loss: 4.75399
Epoch 95, Val Loss: 4.41593
Epoch 96, Val Loss: 4.75548
Epoch 97, Val Loss: 4.43620
Epoch 98, Val Loss: 4.51370
Epoch 99, Val Loss: 4.42508
DID NOT SAVE RESULTS
{'MSE - mean': 4.336325980985893, 'MSE - std': 0.15188461738117123, 'R2 - mean': 0.5727366369892569, 'R2 - std': 0.015054643000699667} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 16.66319
Epoch 1, Val Loss: 7.15755
Epoch 2, Val Loss: 6.37014
Epoch 3, Val Loss: 5.52275
Epoch 4, Val Loss: 5.39069
Epoch 5, Val Loss: 5.12989
Epoch 6, Val Loss: 5.06108
Epoch 7, Val Loss: 4.93015
Epoch 8, Val Loss: 4.91754
Epoch 9, Val Loss: 4.96515
Epoch 10, Val Loss: 5.00540
Epoch 11, Val Loss: 4.93506
Epoch 12, Val Loss: 4.91255
Epoch 13, Val Loss: 4.69265
Epoch 14, Val Loss: 4.89690
Epoch 15, Val Loss: 4.68163
Epoch 16, Val Loss: 4.64178
Epoch 17, Val Loss: 4.66011
Epoch 18, Val Loss: 4.59325
Epoch 19, Val Loss: 4.59427
Epoch 20, Val Loss: 4.52432
Epoch 21, Val Loss: 4.73163
Epoch 22, Val Loss: 4.96517
Epoch 23, Val Loss: 4.50010
Epoch 24, Val Loss: 4.47290
Epoch 25, Val Loss: 4.56489
Epoch 26, Val Loss: 4.44739
Epoch 27, Val Loss: 4.43935
Epoch 28, Val Loss: 4.56194
Epoch 29, Val Loss: 4.46421
Epoch 30, Val Loss: 4.40188
Epoch 31, Val Loss: 5.67755
Epoch 32, Val Loss: 4.44289
Epoch 33, Val Loss: 4.47386
Epoch 34, Val Loss: 4.45894
Epoch 35, Val Loss: 4.36959
Epoch 36, Val Loss: 4.33807
Epoch 37, Val Loss: 4.26695
Epoch 38, Val Loss: 4.30253
Epoch 39, Val Loss: 4.27165
Epoch 40, Val Loss: 4.26351
Epoch 41, Val Loss: 4.40950
Epoch 42, Val Loss: 4.48474
Epoch 43, Val Loss: 4.54372
Epoch 44, Val Loss: 4.33003
Epoch 45, Val Loss: 4.33501
Epoch 46, Val Loss: 4.38055
Epoch 47, Val Loss: 4.13640
Epoch 48, Val Loss: 4.29677
Epoch 49, Val Loss: 4.18606
Epoch 50, Val Loss: 4.38489
Epoch 51, Val Loss: 4.10976
Epoch 52, Val Loss: 4.39969
Epoch 53, Val Loss: 4.15718
Epoch 54, Val Loss: 4.13911
Epoch 55, Val Loss: 4.14469
Epoch 56, Val Loss: 4.29613
Epoch 57, Val Loss: 4.16749
Epoch 58, Val Loss: 4.06965
Epoch 59, Val Loss: 4.72899
Epoch 60, Val Loss: 4.15903
Epoch 61, Val Loss: 4.06951
Epoch 62, Val Loss: 4.07248
Epoch 63, Val Loss: 5.23238
Epoch 64, Val Loss: 4.20719
Epoch 65, Val Loss: 4.12034
Epoch 66, Val Loss: 4.28520
Epoch 67, Val Loss: 4.24061
Epoch 68, Val Loss: 4.05000
Epoch 69, Val Loss: 4.05712
Epoch 70, Val Loss: 4.20985
Epoch 71, Val Loss: 4.13633
Epoch 72, Val Loss: 4.24120
Epoch 73, Val Loss: 4.11158
Epoch 74, Val Loss: 4.13966
Epoch 75, Val Loss: 4.10806
Epoch 76, Val Loss: 4.18376
Epoch 77, Val Loss: 4.20008
Epoch 78, Val Loss: 4.14928
Epoch 79, Val Loss: 5.00795
Epoch 80, Val Loss: 4.05550
Epoch 81, Val Loss: 4.13057
Epoch 82, Val Loss: 4.62893
Epoch 83, Val Loss: 4.41800
Epoch 84, Val Loss: 4.06414
Epoch 85, Val Loss: 4.34391
Epoch 86, Val Loss: 4.25474
Epoch 87, Val Loss: 4.12188
Epoch 88, Val Loss: 4.18207
Epoch 89, Val Loss: 4.13951
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.337055540076215, 'MSE - std': 0.1315420066639072, 'R2 - mean': 0.563563928290838, 'R2 - std': 0.020552310369081048} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 18.39925
Epoch 1, Val Loss: 10.92764
Epoch 2, Val Loss: 10.35838
Epoch 3, Val Loss: 8.43481
Epoch 4, Val Loss: 7.54812
Epoch 5, Val Loss: 7.52017
Epoch 6, Val Loss: 7.39606
Epoch 7, Val Loss: 7.29974
Epoch 8, Val Loss: 7.42674
Epoch 9, Val Loss: 7.06069
Epoch 10, Val Loss: 7.00809
Epoch 11, Val Loss: 6.83510
Epoch 12, Val Loss: 6.95947
Epoch 13, Val Loss: 6.82453
Epoch 14, Val Loss: 6.85086
Epoch 15, Val Loss: 6.63040
Epoch 16, Val Loss: 6.82188
Epoch 17, Val Loss: 6.56751
Epoch 18, Val Loss: 6.50702
Epoch 19, Val Loss: 6.66081
Epoch 20, Val Loss: 6.31666
Epoch 21, Val Loss: 6.56320
Epoch 22, Val Loss: 6.17975
Epoch 23, Val Loss: 6.14531
Epoch 24, Val Loss: 6.29650
Epoch 25, Val Loss: 6.44138
Epoch 26, Val Loss: 6.74282
Epoch 27, Val Loss: 6.34064
Epoch 28, Val Loss: 6.18658
Epoch 29, Val Loss: 7.07965
Epoch 30, Val Loss: 5.92475
Epoch 31, Val Loss: 6.02295
Epoch 32, Val Loss: 6.03375
Epoch 33, Val Loss: 6.17049
Epoch 34, Val Loss: 5.86095
Epoch 35, Val Loss: 6.05543
Epoch 36, Val Loss: 5.95805
Epoch 37, Val Loss: 6.01780
Epoch 38, Val Loss: 5.92097
Epoch 39, Val Loss: 6.01095
Epoch 40, Val Loss: 5.90329
Epoch 41, Val Loss: 5.77962
Epoch 42, Val Loss: 5.88295
Epoch 43, Val Loss: 6.19351
Epoch 44, Val Loss: 5.80726
Epoch 45, Val Loss: 5.83111
Epoch 46, Val Loss: 5.69370
Epoch 47, Val Loss: 5.66277
Epoch 48, Val Loss: 5.66510
Epoch 49, Val Loss: 5.54583
Epoch 50, Val Loss: 5.54691
Epoch 51, Val Loss: 5.80347
Epoch 52, Val Loss: 5.55451
Epoch 53, Val Loss: 5.62998
Epoch 54, Val Loss: 5.68180
Epoch 55, Val Loss: 5.66123
Epoch 56, Val Loss: 5.80091
Epoch 57, Val Loss: 5.81785
Epoch 58, Val Loss: 5.48050
Epoch 59, Val Loss: 5.68081
Epoch 60, Val Loss: 5.43714
Epoch 61, Val Loss: 5.44136
Epoch 62, Val Loss: 5.63815
Epoch 63, Val Loss: 5.90222
Epoch 64, Val Loss: 5.52267
Epoch 65, Val Loss: 5.49142
Epoch 66, Val Loss: 5.69422
Epoch 67, Val Loss: 5.50279
Epoch 68, Val Loss: 5.59394
Epoch 69, Val Loss: 5.57447
Epoch 70, Val Loss: 5.59726
Epoch 71, Val Loss: 5.79208
Epoch 72, Val Loss: 5.42329
Epoch 73, Val Loss: 5.67634
Epoch 74, Val Loss: 6.18592
Epoch 75, Val Loss: 5.58114
Epoch 76, Val Loss: 5.50897
Epoch 77, Val Loss: 5.64518
Epoch 78, Val Loss: 5.65156
Epoch 79, Val Loss: 5.53932
Epoch 80, Val Loss: 5.62144
Epoch 81, Val Loss: 5.58189
Epoch 82, Val Loss: 5.63637
Epoch 83, Val Loss: 5.68041
Epoch 84, Val Loss: 5.80915
Epoch 85, Val Loss: 5.74005
Epoch 86, Val Loss: 5.60199
Epoch 87, Val Loss: 5.78779
Epoch 88, Val Loss: 5.64307
Epoch 89, Val Loss: 5.54550
Epoch 90, Val Loss: 5.72835
Epoch 91, Val Loss: 5.66335
Epoch 92, Val Loss: 5.59975
Epoch 93, Val Loss: 5.61030
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.5735424319777565, 'MSE - std': 0.4873877714702531, 'R2 - mean': 0.5595591258323811, 'R2 - std': 0.02005172661220674} 
 

Results After CV: {'MSE - mean': 4.5735424319777565, 'MSE - std': 0.4873877714702531, 'R2 - mean': 0.5595591258323811, 'R2 - std': 0.02005172661220674}
Train time: 105.82542047400003
Inference time: 0.048574933400050216
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 37 finished with value: 4.5735424319777565 and parameters: {'p_m': 0.892282082250448, 'alpha': 0.18570239651856735, 'K': 20, 'beta': 3.4406605043468717}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.21974
Epoch 1, Val Loss: 9.09358
Epoch 2, Val Loss: 8.49175
Epoch 3, Val Loss: 6.88941
Epoch 4, Val Loss: 6.56627
Epoch 5, Val Loss: 6.13895
Epoch 6, Val Loss: 6.19837
Epoch 7, Val Loss: 5.75323
Epoch 8, Val Loss: 5.75976
Epoch 9, Val Loss: 5.49814
Epoch 10, Val Loss: 5.72900
Epoch 11, Val Loss: 5.33547
Epoch 12, Val Loss: 5.47273
Epoch 13, Val Loss: 5.62279
Epoch 14, Val Loss: 5.13243
Epoch 15, Val Loss: 5.10674
Epoch 16, Val Loss: 5.05159
Epoch 17, Val Loss: 5.17722
Epoch 18, Val Loss: 5.34197
Epoch 19, Val Loss: 4.95193
Epoch 20, Val Loss: 4.90993
Epoch 21, Val Loss: 5.10748
Epoch 22, Val Loss: 5.10814
Epoch 23, Val Loss: 4.96675
Epoch 24, Val Loss: 4.82454
Epoch 25, Val Loss: 4.92416
Epoch 26, Val Loss: 4.83747
Epoch 27, Val Loss: 4.73219
Epoch 28, Val Loss: 5.52397
Epoch 29, Val Loss: 4.71881
Epoch 30, Val Loss: 5.29398
Epoch 31, Val Loss: 4.74775
Epoch 32, Val Loss: 4.79989
Epoch 33, Val Loss: 5.06117
Epoch 34, Val Loss: 5.13095
Epoch 35, Val Loss: 4.92565
Epoch 36, Val Loss: 4.58587
Epoch 37, Val Loss: 4.85845
Epoch 38, Val Loss: 4.63715
Epoch 39, Val Loss: 4.65289
Epoch 40, Val Loss: 4.70842
Epoch 41, Val Loss: 4.60002
Epoch 42, Val Loss: 4.66726
Epoch 43, Val Loss: 4.64743
Epoch 44, Val Loss: 4.65474
Epoch 45, Val Loss: 4.67995
Epoch 46, Val Loss: 4.66714
Epoch 47, Val Loss: 4.73457
Epoch 48, Val Loss: 4.83060
Epoch 49, Val Loss: 5.22707
Epoch 50, Val Loss: 4.55179
Epoch 51, Val Loss: 4.55998
Epoch 52, Val Loss: 4.49009
Epoch 53, Val Loss: 4.54047
Epoch 54, Val Loss: 4.64428
Epoch 55, Val Loss: 4.68171
Epoch 56, Val Loss: 4.82040
Epoch 57, Val Loss: 4.67764
Epoch 58, Val Loss: 4.63247
Epoch 59, Val Loss: 4.67087
Epoch 60, Val Loss: 4.48479
Epoch 61, Val Loss: 4.56649
Epoch 62, Val Loss: 4.59782
Epoch 63, Val Loss: 4.67457
Epoch 64, Val Loss: 4.58690
Epoch 65, Val Loss: 4.66923
Epoch 66, Val Loss: 4.49570
Epoch 67, Val Loss: 4.49077
Epoch 68, Val Loss: 4.56130
Epoch 69, Val Loss: 4.54010
Epoch 70, Val Loss: 4.59246
Epoch 71, Val Loss: 4.42358
Epoch 72, Val Loss: 4.47491
Epoch 73, Val Loss: 4.42939
Epoch 74, Val Loss: 4.55328
Epoch 75, Val Loss: 4.48420
Epoch 76, Val Loss: 4.67772
Epoch 77, Val Loss: 4.59351
Epoch 78, Val Loss: 4.63775
Epoch 79, Val Loss: 4.49701
Epoch 80, Val Loss: 4.51870
Epoch 81, Val Loss: 4.39028
Epoch 82, Val Loss: 4.46637
Epoch 83, Val Loss: 4.42814
Epoch 84, Val Loss: 4.47391
Epoch 85, Val Loss: 5.01144
Epoch 86, Val Loss: 4.48800
Epoch 87, Val Loss: 4.56751
Epoch 88, Val Loss: 4.65870
Epoch 89, Val Loss: 4.46365
Epoch 90, Val Loss: 4.42776
Epoch 91, Val Loss: 4.45627
Epoch 92, Val Loss: 4.47171
Epoch 93, Val Loss: 4.41150
Epoch 94, Val Loss: 4.46569
Epoch 95, Val Loss: 4.50379
Epoch 96, Val Loss: 4.62546
Epoch 97, Val Loss: 4.48722
Epoch 98, Val Loss: 4.41850
Epoch 99, Val Loss: 4.58481
DID NOT SAVE RESULTS
{'MSE - mean': 4.558871506238269, 'MSE - std': 0.0, 'R2 - mean': 0.5842459827065986, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 12.46146
Epoch 1, Val Loss: 8.65602
Epoch 2, Val Loss: 6.68679
Epoch 3, Val Loss: 5.76170
Epoch 4, Val Loss: 5.72550
Epoch 5, Val Loss: 6.39764
Epoch 6, Val Loss: 5.67113
Epoch 7, Val Loss: 5.48013
Epoch 8, Val Loss: 5.47267
Epoch 9, Val Loss: 5.38347
Epoch 10, Val Loss: 5.31556
Epoch 11, Val Loss: 5.69313
Epoch 12, Val Loss: 5.21443
Epoch 13, Val Loss: 5.24808
Epoch 14, Val Loss: 5.15246
Epoch 15, Val Loss: 5.04653
Epoch 16, Val Loss: 5.10399
Epoch 17, Val Loss: 5.79910
Epoch 18, Val Loss: 4.97478
Epoch 19, Val Loss: 5.19748
Epoch 20, Val Loss: 4.97201
Epoch 21, Val Loss: 5.58283
Epoch 22, Val Loss: 5.04635
Epoch 23, Val Loss: 5.49860
Epoch 24, Val Loss: 5.42851
Epoch 25, Val Loss: 4.89393
Epoch 26, Val Loss: 4.68072
Epoch 27, Val Loss: 4.69882
Epoch 28, Val Loss: 4.66671
Epoch 29, Val Loss: 4.59427
Epoch 30, Val Loss: 4.65810
Epoch 31, Val Loss: 4.62306
Epoch 32, Val Loss: 4.58518
Epoch 33, Val Loss: 4.48833
Epoch 34, Val Loss: 4.53852
Epoch 35, Val Loss: 4.58673
Epoch 36, Val Loss: 4.50298
Epoch 37, Val Loss: 4.41696
Epoch 38, Val Loss: 4.70451
Epoch 39, Val Loss: 4.57891
Epoch 40, Val Loss: 5.24652
Epoch 41, Val Loss: 4.39383
Epoch 42, Val Loss: 4.35615
Epoch 43, Val Loss: 4.39402
Epoch 44, Val Loss: 4.48513
Epoch 45, Val Loss: 4.75834
Epoch 46, Val Loss: 4.31172
Epoch 47, Val Loss: 4.81158
Epoch 48, Val Loss: 4.30957
Epoch 49, Val Loss: 4.49506
Epoch 50, Val Loss: 4.43134
Epoch 51, Val Loss: 4.22542
Epoch 52, Val Loss: 4.53063
Epoch 53, Val Loss: 4.26280
Epoch 54, Val Loss: 4.30929
Epoch 55, Val Loss: 4.48136
Epoch 56, Val Loss: 4.54469
Epoch 57, Val Loss: 4.25161
Epoch 58, Val Loss: 4.34100
Epoch 59, Val Loss: 4.18651
Epoch 60, Val Loss: 4.45574
Epoch 61, Val Loss: 4.28279
Epoch 62, Val Loss: 4.15408
Epoch 63, Val Loss: 4.23416
Epoch 64, Val Loss: 5.03757
Epoch 65, Val Loss: 4.34860
Epoch 66, Val Loss: 4.23490
Epoch 67, Val Loss: 4.11712
Epoch 68, Val Loss: 4.16627
Epoch 69, Val Loss: 4.12095
Epoch 70, Val Loss: 4.11521
Epoch 71, Val Loss: 4.20545
Epoch 72, Val Loss: 5.03102
Epoch 73, Val Loss: 4.34169
Epoch 74, Val Loss: 6.62563
Epoch 75, Val Loss: 4.60174
Epoch 76, Val Loss: 4.21425
Epoch 77, Val Loss: 4.13170
Epoch 78, Val Loss: 4.09116
Epoch 79, Val Loss: 4.31583
Epoch 80, Val Loss: 4.02770
Epoch 81, Val Loss: 4.69025
Epoch 82, Val Loss: 4.16662
Epoch 83, Val Loss: 4.17102
Epoch 84, Val Loss: 4.95270
Epoch 85, Val Loss: 4.37108
Epoch 86, Val Loss: 4.24536
Epoch 87, Val Loss: 4.09872
Epoch 88, Val Loss: 4.23452
Epoch 89, Val Loss: 4.09191
Epoch 90, Val Loss: 4.02594
Epoch 91, Val Loss: 4.20316
Epoch 92, Val Loss: 4.11816
Epoch 93, Val Loss: 4.10986
Epoch 94, Val Loss: 4.19683
Epoch 95, Val Loss: 4.20872
Epoch 96, Val Loss: 4.54608
Epoch 97, Val Loss: 4.09954
Epoch 98, Val Loss: 4.12073
Epoch 99, Val Loss: 4.51268
DID NOT SAVE RESULTS
{'MSE - mean': 4.381805453802109, 'MSE - std': 0.1770660524361598, 'R2 - mean': 0.5680176054539092, 'R2 - std': 0.016228377252689274} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 17.29728
Epoch 1, Val Loss: 9.95724
Epoch 2, Val Loss: 8.13176
Epoch 3, Val Loss: 7.08036
Epoch 4, Val Loss: 6.72457
Epoch 5, Val Loss: 6.88214
Epoch 6, Val Loss: 6.14915
Epoch 7, Val Loss: 6.04028
Epoch 8, Val Loss: 5.85390
Epoch 9, Val Loss: 5.74974
Epoch 10, Val Loss: 5.86568
Epoch 11, Val Loss: 5.63741
Epoch 12, Val Loss: 5.54395
Epoch 13, Val Loss: 5.65073
Epoch 14, Val Loss: 5.45976
Epoch 15, Val Loss: 5.36125
Epoch 16, Val Loss: 5.32295
Epoch 17, Val Loss: 5.53508
Epoch 18, Val Loss: 5.29518
Epoch 19, Val Loss: 5.25744
Epoch 20, Val Loss: 5.10601
Epoch 21, Val Loss: 5.30358
Epoch 22, Val Loss: 5.16309
Epoch 23, Val Loss: 5.53432
Epoch 24, Val Loss: 5.11282
Epoch 25, Val Loss: 5.09521
Epoch 26, Val Loss: 5.00943
Epoch 27, Val Loss: 5.10524
Epoch 28, Val Loss: 5.05090
Epoch 29, Val Loss: 5.24303
Epoch 30, Val Loss: 4.96636
Epoch 31, Val Loss: 4.97518
Epoch 32, Val Loss: 4.91912
Epoch 33, Val Loss: 4.92821
Epoch 34, Val Loss: 4.95797
Epoch 35, Val Loss: 5.37205
Epoch 36, Val Loss: 4.87239
Epoch 37, Val Loss: 4.92601
Epoch 38, Val Loss: 4.78065
Epoch 39, Val Loss: 5.30184
Epoch 40, Val Loss: 4.92551
Epoch 41, Val Loss: 4.74542
Epoch 42, Val Loss: 4.77412
Epoch 43, Val Loss: 4.78405
Epoch 44, Val Loss: 4.97663
Epoch 45, Val Loss: 4.64861
Epoch 46, Val Loss: 4.74874
Epoch 47, Val Loss: 4.81601
Epoch 48, Val Loss: 4.79860
Epoch 49, Val Loss: 4.73199
Epoch 50, Val Loss: 4.68352
Epoch 51, Val Loss: 4.90445
Epoch 52, Val Loss: 4.66499
Epoch 53, Val Loss: 4.61489
Epoch 54, Val Loss: 4.62558
Epoch 55, Val Loss: 4.64467
Epoch 56, Val Loss: 4.92600
Epoch 57, Val Loss: 4.71250
Epoch 58, Val Loss: 4.70112
Epoch 59, Val Loss: 4.71036
Epoch 60, Val Loss: 4.61959
Epoch 61, Val Loss: 4.50436
Epoch 62, Val Loss: 5.02485
Epoch 63, Val Loss: 4.66907
Epoch 64, Val Loss: 4.53373
Epoch 65, Val Loss: 4.76369
Epoch 66, Val Loss: 4.49775
Epoch 67, Val Loss: 4.45455
Epoch 68, Val Loss: 4.41516
Epoch 69, Val Loss: 4.75257
Epoch 70, Val Loss: 4.55464
Epoch 71, Val Loss: 4.39790
Epoch 72, Val Loss: 4.46391
Epoch 73, Val Loss: 4.50697
Epoch 74, Val Loss: 4.76739
Epoch 75, Val Loss: 4.32113
Epoch 76, Val Loss: 4.38348
Epoch 77, Val Loss: 4.49899
Epoch 78, Val Loss: 4.35240
Epoch 79, Val Loss: 4.59411
Epoch 80, Val Loss: 4.37914
Epoch 81, Val Loss: 4.46645
Epoch 82, Val Loss: 4.44881
Epoch 83, Val Loss: 4.39934
Epoch 84, Val Loss: 4.43311
Epoch 85, Val Loss: 4.37019
Epoch 86, Val Loss: 4.49905
Epoch 87, Val Loss: 4.55822
Epoch 88, Val Loss: 4.41727
Epoch 89, Val Loss: 4.66591
Epoch 90, Val Loss: 4.64514
Epoch 91, Val Loss: 4.45735
Epoch 92, Val Loss: 4.32949
Epoch 93, Val Loss: 4.38064
Epoch 94, Val Loss: 4.60349
Epoch 95, Val Loss: 4.43959
Epoch 96, Val Loss: 4.45175
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.388022273209144, 'MSE - std': 0.14484090917496098, 'R2 - mean': 0.5676786994771967, 'R2 - std': 0.013259079908720592} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 21.40059
Epoch 1, Val Loss: 9.46642
Epoch 2, Val Loss: 7.03459
Epoch 3, Val Loss: 6.04861
Epoch 4, Val Loss: 5.48955
Epoch 5, Val Loss: 5.21439
Epoch 6, Val Loss: 5.09060
Epoch 7, Val Loss: 5.07877
Epoch 8, Val Loss: 4.97156
Epoch 9, Val Loss: 4.95234
Epoch 10, Val Loss: 4.84156
Epoch 11, Val Loss: 4.72120
Epoch 12, Val Loss: 4.88673
Epoch 13, Val Loss: 4.89252
Epoch 14, Val Loss: 4.68454
Epoch 15, Val Loss: 5.07420
Epoch 16, Val Loss: 4.59957
Epoch 17, Val Loss: 4.58194
Epoch 18, Val Loss: 4.62775
Epoch 19, Val Loss: 4.43271
Epoch 20, Val Loss: 4.44366
Epoch 21, Val Loss: 4.41126
Epoch 22, Val Loss: 4.36371
Epoch 23, Val Loss: 4.36098
Epoch 24, Val Loss: 4.29152
Epoch 25, Val Loss: 4.54536
Epoch 26, Val Loss: 4.35829
Epoch 27, Val Loss: 4.24880
Epoch 28, Val Loss: 4.29155
Epoch 29, Val Loss: 4.21555
Epoch 30, Val Loss: 4.19313
Epoch 31, Val Loss: 4.26136
Epoch 32, Val Loss: 4.64758
Epoch 33, Val Loss: 4.11437
Epoch 34, Val Loss: 4.26199
Epoch 35, Val Loss: 4.09559
Epoch 36, Val Loss: 4.30749
Epoch 37, Val Loss: 4.16272
Epoch 38, Val Loss: 4.08787
Epoch 39, Val Loss: 4.33276
Epoch 40, Val Loss: 4.14365
Epoch 41, Val Loss: 4.29020
Epoch 42, Val Loss: 4.05066
Epoch 43, Val Loss: 4.24075
Epoch 44, Val Loss: 4.13158
Epoch 45, Val Loss: 4.03506
Epoch 46, Val Loss: 3.97671
Epoch 47, Val Loss: 3.99200
Epoch 48, Val Loss: 4.01362
Epoch 49, Val Loss: 4.01076
Epoch 50, Val Loss: 4.01089
Epoch 51, Val Loss: 4.63277
Epoch 52, Val Loss: 4.10939
Epoch 53, Val Loss: 3.97813
Epoch 54, Val Loss: 4.01422
Epoch 55, Val Loss: 4.13384
Epoch 56, Val Loss: 4.07663
Epoch 57, Val Loss: 3.94094
Epoch 58, Val Loss: 4.24821
Epoch 59, Val Loss: 4.02995
Epoch 60, Val Loss: 3.94265
Epoch 61, Val Loss: 3.92873
Epoch 62, Val Loss: 4.19699
Epoch 63, Val Loss: 3.97993
Epoch 64, Val Loss: 3.95319
Epoch 65, Val Loss: 4.23879
Epoch 66, Val Loss: 3.95190
Epoch 67, Val Loss: 3.99082
Epoch 68, Val Loss: 3.93354
Epoch 69, Val Loss: 3.93292
Epoch 70, Val Loss: 4.02717
Epoch 71, Val Loss: 3.89610
Epoch 72, Val Loss: 3.88162
Epoch 73, Val Loss: 3.95480
Epoch 74, Val Loss: 4.08060
Epoch 75, Val Loss: 3.89195
Epoch 76, Val Loss: 3.97089
Epoch 77, Val Loss: 5.05535
Epoch 78, Val Loss: 3.91131
Epoch 79, Val Loss: 3.90005
Epoch 80, Val Loss: 3.99706
Epoch 81, Val Loss: 3.97778
Epoch 82, Val Loss: 4.01395
Epoch 83, Val Loss: 3.88782
Epoch 84, Val Loss: 3.91297
Epoch 85, Val Loss: 3.88028
Epoch 86, Val Loss: 3.99846
Epoch 87, Val Loss: 3.95889
Epoch 88, Val Loss: 3.87649
Epoch 89, Val Loss: 4.08926
Epoch 90, Val Loss: 4.06544
Epoch 91, Val Loss: 3.89277
Epoch 92, Val Loss: 3.85917
Epoch 93, Val Loss: 3.90889
Epoch 94, Val Loss: 4.05427
Epoch 95, Val Loss: 4.00733
Epoch 96, Val Loss: 3.90547
Epoch 97, Val Loss: 3.99142
Epoch 98, Val Loss: 3.90419
Epoch 99, Val Loss: 3.95804
DID NOT SAVE RESULTS
{'MSE - mean': 4.338043197335988, 'MSE - std': 0.15240699066439103, 'R2 - mean': 0.5638104197257527, 'R2 - std': 0.013294478730874514} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.81314
Epoch 1, Val Loss: 13.90390
Epoch 2, Val Loss: 10.13570
Epoch 3, Val Loss: 8.01141
Epoch 4, Val Loss: 7.56860
Epoch 5, Val Loss: 7.60883
Epoch 6, Val Loss: 7.41306
Epoch 7, Val Loss: 7.22857
Epoch 8, Val Loss: 7.04899
Epoch 9, Val Loss: 6.96716
Epoch 10, Val Loss: 7.03011
Epoch 11, Val Loss: 6.88027
Epoch 12, Val Loss: 6.63255
Epoch 13, Val Loss: 6.63233
Epoch 14, Val Loss: 6.59935
Epoch 15, Val Loss: 6.49701
Epoch 16, Val Loss: 7.19021
Epoch 17, Val Loss: 6.32825
Epoch 18, Val Loss: 6.29065
Epoch 19, Val Loss: 6.16692
Epoch 20, Val Loss: 6.11241
Epoch 21, Val Loss: 6.18494
Epoch 22, Val Loss: 6.20528
Epoch 23, Val Loss: 5.99497
Epoch 24, Val Loss: 5.94497
Epoch 25, Val Loss: 5.90391
Epoch 26, Val Loss: 6.01133
Epoch 27, Val Loss: 6.25695
Epoch 28, Val Loss: 5.77202
Epoch 29, Val Loss: 5.84972
Epoch 30, Val Loss: 5.76998
Epoch 31, Val Loss: 5.81635
Epoch 32, Val Loss: 5.74688
Epoch 33, Val Loss: 5.81798
Epoch 34, Val Loss: 5.76650
Epoch 35, Val Loss: 5.58709
Epoch 36, Val Loss: 5.71274
Epoch 37, Val Loss: 5.68712
Epoch 38, Val Loss: 5.58362
Epoch 39, Val Loss: 5.60098
Epoch 40, Val Loss: 5.66766
Epoch 41, Val Loss: 5.72825
Epoch 42, Val Loss: 5.73301
Epoch 43, Val Loss: 5.54244
Epoch 44, Val Loss: 5.68742
Epoch 45, Val Loss: 5.87652
Epoch 46, Val Loss: 5.58681
Epoch 47, Val Loss: 5.52980
Epoch 48, Val Loss: 5.49425
Epoch 49, Val Loss: 5.70116
Epoch 50, Val Loss: 5.55091
Epoch 51, Val Loss: 5.67806
Epoch 52, Val Loss: 5.58447
Epoch 53, Val Loss: 5.74273
Epoch 54, Val Loss: 5.69210
Epoch 55, Val Loss: 5.65600
Epoch 56, Val Loss: 5.50189
Epoch 57, Val Loss: 5.65762
Epoch 58, Val Loss: 5.51533
Epoch 59, Val Loss: 5.69587
Epoch 60, Val Loss: 5.64183
Epoch 61, Val Loss: 5.66079
Epoch 62, Val Loss: 5.90126
Epoch 63, Val Loss: 5.55149
Epoch 64, Val Loss: 5.50905
Epoch 65, Val Loss: 5.57097
Epoch 66, Val Loss: 5.65305
Epoch 67, Val Loss: 5.61368
Epoch 68, Val Loss: 5.65973
Epoch 69, Val Loss: 5.59348
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.57683800491572, 'MSE - std': 0.4966630176999952, 'R2 - mean': 0.5595491192920131, 'R2 - std': 0.01462973879899764} 
 

Results After CV: {'MSE - mean': 4.57683800491572, 'MSE - std': 0.4966630176999952, 'R2 - mean': 0.5595491192920131, 'R2 - std': 0.01462973879899764}
Train time: 30.744025743400197
Inference time: 0.0476461329999438
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 38 finished with value: 4.57683800491572 and parameters: {'p_m': 0.8998989156257514, 'alpha': 0.13005682766779272, 'K': 3, 'beta': 3.7342044183070806}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.38073
Epoch 1, Val Loss: 11.07479
Epoch 2, Val Loss: 7.99992
Epoch 3, Val Loss: 6.46716
Epoch 4, Val Loss: 6.69172
Epoch 5, Val Loss: 6.28995
Epoch 6, Val Loss: 6.18832
Epoch 7, Val Loss: 5.94895
Epoch 8, Val Loss: 5.93356
Epoch 9, Val Loss: 5.73814
Epoch 10, Val Loss: 5.91594
Epoch 11, Val Loss: 5.56357
Epoch 12, Val Loss: 5.54355
Epoch 13, Val Loss: 5.42331
Epoch 14, Val Loss: 5.40374
Epoch 15, Val Loss: 5.40056
Epoch 16, Val Loss: 5.41689
Epoch 17, Val Loss: 5.28565
Epoch 18, Val Loss: 5.27791
Epoch 19, Val Loss: 5.24369
Epoch 20, Val Loss: 5.22814
Epoch 21, Val Loss: 5.11456
Epoch 22, Val Loss: 5.43366
Epoch 23, Val Loss: 5.23400
Epoch 24, Val Loss: 5.16293
Epoch 25, Val Loss: 5.02280
Epoch 26, Val Loss: 5.05517
Epoch 27, Val Loss: 4.98818
Epoch 28, Val Loss: 4.92028
Epoch 29, Val Loss: 5.14214
Epoch 30, Val Loss: 5.11935
Epoch 31, Val Loss: 4.94982
Epoch 32, Val Loss: 5.32617
Epoch 33, Val Loss: 4.93351
Epoch 34, Val Loss: 4.89846
Epoch 35, Val Loss: 4.82334
Epoch 36, Val Loss: 4.89429
Epoch 37, Val Loss: 4.72664
Epoch 38, Val Loss: 4.87365
Epoch 39, Val Loss: 4.73251
Epoch 40, Val Loss: 4.90923
Epoch 41, Val Loss: 4.75304
Epoch 42, Val Loss: 4.79849
Epoch 43, Val Loss: 4.84683
Epoch 44, Val Loss: 4.76919
Epoch 45, Val Loss: 4.77752
Epoch 46, Val Loss: 5.26918
Epoch 47, Val Loss: 4.71844
Epoch 48, Val Loss: 4.74510
Epoch 49, Val Loss: 4.61913
Epoch 50, Val Loss: 4.67016
Epoch 51, Val Loss: 4.97903
Epoch 52, Val Loss: 5.02338
Epoch 53, Val Loss: 5.64706
Epoch 54, Val Loss: 4.81732
Epoch 55, Val Loss: 4.49737
Epoch 56, Val Loss: 4.66289
Epoch 57, Val Loss: 4.64184
Epoch 58, Val Loss: 4.84915
Epoch 59, Val Loss: 4.68414
Epoch 60, Val Loss: 5.03506
Epoch 61, Val Loss: 4.65120
Epoch 62, Val Loss: 4.72368
Epoch 63, Val Loss: 5.13461
Epoch 64, Val Loss: 4.54926
Epoch 65, Val Loss: 4.63186
Epoch 66, Val Loss: 4.85430
Epoch 67, Val Loss: 4.51765
Epoch 68, Val Loss: 4.44153
Epoch 69, Val Loss: 4.85161
Epoch 70, Val Loss: 4.52045
Epoch 71, Val Loss: 4.69769
Epoch 72, Val Loss: 4.90213
Epoch 73, Val Loss: 4.74733
Epoch 74, Val Loss: 4.60981
Epoch 75, Val Loss: 4.52745
Epoch 76, Val Loss: 4.50063
Epoch 77, Val Loss: 4.83469
Epoch 78, Val Loss: 4.86762
Epoch 79, Val Loss: 4.66674
Epoch 80, Val Loss: 4.92318
Epoch 81, Val Loss: 4.59577
Epoch 82, Val Loss: 4.74637
Epoch 83, Val Loss: 4.49827
Epoch 84, Val Loss: 4.68370
Epoch 85, Val Loss: 4.44712
Epoch 86, Val Loss: 4.56738
Epoch 87, Val Loss: 4.52433
Epoch 88, Val Loss: 5.00561
Epoch 89, Val Loss: 4.75554
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.571401575640706, 'MSE - std': 0.0, 'R2 - mean': 0.5831032817807446, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 15.69128
Epoch 1, Val Loss: 7.61550
Epoch 2, Val Loss: 5.87225
Epoch 3, Val Loss: 5.50159
Epoch 4, Val Loss: 5.37309
Epoch 5, Val Loss: 5.19969
Epoch 6, Val Loss: 5.02068
Epoch 7, Val Loss: 4.81927
Epoch 8, Val Loss: 5.00008
Epoch 9, Val Loss: 4.86196
Epoch 10, Val Loss: 5.14155
Epoch 11, Val Loss: 5.35587
Epoch 12, Val Loss: 4.68921
Epoch 13, Val Loss: 4.80544
Epoch 14, Val Loss: 4.56197
Epoch 15, Val Loss: 4.87530
Epoch 16, Val Loss: 4.97249
Epoch 17, Val Loss: 4.43530
Epoch 18, Val Loss: 4.58157
Epoch 19, Val Loss: 4.51448
Epoch 20, Val Loss: 4.44170
Epoch 21, Val Loss: 4.38332
Epoch 22, Val Loss: 4.36312
Epoch 23, Val Loss: 4.60813
Epoch 24, Val Loss: 4.49209
Epoch 25, Val Loss: 4.69475
Epoch 26, Val Loss: 4.37635
Epoch 27, Val Loss: 4.78045
Epoch 28, Val Loss: 4.33541
Epoch 29, Val Loss: 4.22018
Epoch 30, Val Loss: 4.28452
Epoch 31, Val Loss: 4.25402
Epoch 32, Val Loss: 4.17173
Epoch 33, Val Loss: 4.16957
Epoch 34, Val Loss: 4.10481
Epoch 35, Val Loss: 4.18724
Epoch 36, Val Loss: 4.14166
Epoch 37, Val Loss: 4.06831
Epoch 38, Val Loss: 4.09085
Epoch 39, Val Loss: 4.06396
Epoch 40, Val Loss: 4.03036
Epoch 41, Val Loss: 4.06521
Epoch 42, Val Loss: 4.12447
Epoch 43, Val Loss: 4.03328
Epoch 44, Val Loss: 4.23712
Epoch 45, Val Loss: 4.28806
Epoch 46, Val Loss: 4.00805
Epoch 47, Val Loss: 4.02345
Epoch 48, Val Loss: 4.07118
Epoch 49, Val Loss: 4.14549
Epoch 50, Val Loss: 4.08194
Epoch 51, Val Loss: 4.00066
Epoch 52, Val Loss: 4.04450
Epoch 53, Val Loss: 3.99724
Epoch 54, Val Loss: 3.95100
Epoch 55, Val Loss: 3.93883
Epoch 56, Val Loss: 4.14081
Epoch 57, Val Loss: 4.13490
Epoch 58, Val Loss: 4.38999
Epoch 59, Val Loss: 4.17483
Epoch 60, Val Loss: 4.03993
Epoch 61, Val Loss: 3.97196
Epoch 62, Val Loss: 3.97763
Epoch 63, Val Loss: 4.08153
Epoch 64, Val Loss: 4.03995
Epoch 65, Val Loss: 4.08528
Epoch 66, Val Loss: 4.06123
Epoch 67, Val Loss: 4.22608
Epoch 68, Val Loss: 4.11157
Epoch 69, Val Loss: 3.97435
Epoch 70, Val Loss: 4.29923
Epoch 71, Val Loss: 4.01699
Epoch 72, Val Loss: 4.03074
Epoch 73, Val Loss: 4.01276
Epoch 74, Val Loss: 4.07477
Epoch 75, Val Loss: 3.97087
Epoch 76, Val Loss: 3.96451
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.336786169851955, 'MSE - std': 0.2346154057887504, 'R2 - mean': 0.5729129871352951, 'R2 - std': 0.01019029464544935} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 19.52895
Epoch 1, Val Loss: 8.66423
Epoch 2, Val Loss: 6.94351
Epoch 3, Val Loss: 6.35328
Epoch 4, Val Loss: 6.12114
Epoch 5, Val Loss: 5.89676
Epoch 6, Val Loss: 5.91572
Epoch 7, Val Loss: 5.77088
Epoch 8, Val Loss: 5.66995
Epoch 9, Val Loss: 5.55582
Epoch 10, Val Loss: 5.51891
Epoch 11, Val Loss: 5.52999
Epoch 12, Val Loss: 5.39240
Epoch 13, Val Loss: 5.27236
Epoch 14, Val Loss: 5.23841
Epoch 15, Val Loss: 5.30929
Epoch 16, Val Loss: 5.16321
Epoch 17, Val Loss: 5.16054
Epoch 18, Val Loss: 5.31012
Epoch 19, Val Loss: 5.14502
Epoch 20, Val Loss: 4.95382
Epoch 21, Val Loss: 4.97164
Epoch 22, Val Loss: 4.96515
Epoch 23, Val Loss: 4.87570
Epoch 24, Val Loss: 4.92642
Epoch 25, Val Loss: 4.87797
Epoch 26, Val Loss: 4.81728
Epoch 27, Val Loss: 4.89277
Epoch 28, Val Loss: 4.67033
Epoch 29, Val Loss: 5.03736
Epoch 30, Val Loss: 4.77814
Epoch 31, Val Loss: 4.57676
Epoch 32, Val Loss: 4.63498
Epoch 33, Val Loss: 4.68353
Epoch 34, Val Loss: 4.94943
Epoch 35, Val Loss: 4.65454
Epoch 36, Val Loss: 4.58700
Epoch 37, Val Loss: 4.89999
Epoch 38, Val Loss: 4.66945
Epoch 39, Val Loss: 4.58377
Epoch 40, Val Loss: 4.58719
Epoch 41, Val Loss: 4.52427
Epoch 42, Val Loss: 4.64112
Epoch 43, Val Loss: 4.53399
Epoch 44, Val Loss: 4.53117
Epoch 45, Val Loss: 4.62310
Epoch 46, Val Loss: 4.54925
Epoch 47, Val Loss: 4.49577
Epoch 48, Val Loss: 4.52712
Epoch 49, Val Loss: 4.81939
Epoch 50, Val Loss: 4.67235
Epoch 51, Val Loss: 4.55733
Epoch 52, Val Loss: 4.50612
Epoch 53, Val Loss: 4.65125
Epoch 54, Val Loss: 4.88435
Epoch 55, Val Loss: 4.49575
Epoch 56, Val Loss: 4.58681
Epoch 57, Val Loss: 4.70636
Epoch 58, Val Loss: 4.51849
Epoch 59, Val Loss: 4.88943
Epoch 60, Val Loss: 4.52684
Epoch 61, Val Loss: 4.56105
Epoch 62, Val Loss: 4.55365
Epoch 63, Val Loss: 4.67219
Epoch 64, Val Loss: 4.50155
Epoch 65, Val Loss: 4.76394
Epoch 66, Val Loss: 4.57980
Epoch 67, Val Loss: 4.50605
Epoch 68, Val Loss: 4.50833
Epoch 69, Val Loss: 4.78360
Epoch 70, Val Loss: 4.61603
Epoch 71, Val Loss: 4.49356
Epoch 72, Val Loss: 4.49823
Epoch 73, Val Loss: 4.56628
Epoch 74, Val Loss: 4.54121
Epoch 75, Val Loss: 4.55646
Epoch 76, Val Loss: 4.88017
Epoch 77, Val Loss: 4.52781
Epoch 78, Val Loss: 4.85976
Epoch 79, Val Loss: 4.55930
Epoch 80, Val Loss: 4.51018
Epoch 81, Val Loss: 4.61130
Epoch 82, Val Loss: 4.48412
Epoch 83, Val Loss: 4.66780
Epoch 84, Val Loss: 4.55633
Epoch 85, Val Loss: 4.49744
Epoch 86, Val Loss: 4.60043
Epoch 87, Val Loss: 5.08941
Epoch 88, Val Loss: 4.51923
Epoch 89, Val Loss: 4.58110
Epoch 90, Val Loss: 4.76075
Epoch 91, Val Loss: 4.43586
Epoch 92, Val Loss: 4.59937
Epoch 93, Val Loss: 4.63164
Epoch 94, Val Loss: 4.53374
Epoch 95, Val Loss: 4.63630
Epoch 96, Val Loss: 4.59642
Epoch 97, Val Loss: 4.56800
Epoch 98, Val Loss: 4.61405
Epoch 99, Val Loss: 4.52630
DID NOT SAVE RESULTS
{'MSE - mean': 4.378422053104235, 'MSE - std': 0.20040796550372372, 'R2 - mean': 0.5689337105654193, 'R2 - std': 0.010044767494231768} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 16.32740
Epoch 1, Val Loss: 7.36085
Epoch 2, Val Loss: 6.24016
Epoch 3, Val Loss: 5.67563
Epoch 4, Val Loss: 5.41654
Epoch 5, Val Loss: 5.41408
Epoch 6, Val Loss: 5.34160
Epoch 7, Val Loss: 5.24876
Epoch 8, Val Loss: 5.05196
Epoch 9, Val Loss: 5.07962
Epoch 10, Val Loss: 5.32436
Epoch 11, Val Loss: 4.94987
Epoch 12, Val Loss: 4.86007
Epoch 13, Val Loss: 4.83230
Epoch 14, Val Loss: 4.84584
Epoch 15, Val Loss: 4.84318
Epoch 16, Val Loss: 4.78309
Epoch 17, Val Loss: 4.81182
Epoch 18, Val Loss: 4.69428
Epoch 19, Val Loss: 4.67995
Epoch 20, Val Loss: 4.59610
Epoch 21, Val Loss: 4.75355
Epoch 22, Val Loss: 4.61648
Epoch 23, Val Loss: 4.58796
Epoch 24, Val Loss: 4.57902
Epoch 25, Val Loss: 5.21597
Epoch 26, Val Loss: 4.52103
Epoch 27, Val Loss: 4.57004
Epoch 28, Val Loss: 4.53815
Epoch 29, Val Loss: 4.55671
Epoch 30, Val Loss: 4.49351
Epoch 31, Val Loss: 4.58601
Epoch 32, Val Loss: 4.45225
Epoch 33, Val Loss: 4.48161
Epoch 34, Val Loss: 4.45669
Epoch 35, Val Loss: 4.39621
Epoch 36, Val Loss: 4.49305
Epoch 37, Val Loss: 4.43194
Epoch 38, Val Loss: 5.10251
Epoch 39, Val Loss: 4.66342
Epoch 40, Val Loss: 4.45619
Epoch 41, Val Loss: 4.64261
Epoch 42, Val Loss: 4.40533
Epoch 43, Val Loss: 4.40361
Epoch 44, Val Loss: 4.33344
Epoch 45, Val Loss: 4.33908
Epoch 46, Val Loss: 4.41526
Epoch 47, Val Loss: 4.31432
Epoch 48, Val Loss: 4.39029
Epoch 49, Val Loss: 4.35118
Epoch 50, Val Loss: 4.58589
Epoch 51, Val Loss: 4.71260
Epoch 52, Val Loss: 4.38746
Epoch 53, Val Loss: 4.34885
Epoch 54, Val Loss: 4.31065
Epoch 55, Val Loss: 4.30731
Epoch 56, Val Loss: 4.28611
Epoch 57, Val Loss: 4.54897
Epoch 58, Val Loss: 4.43743
Epoch 59, Val Loss: 4.28457
Epoch 60, Val Loss: 4.31741
Epoch 61, Val Loss: 4.30170
Epoch 62, Val Loss: 4.33474
Epoch 63, Val Loss: 4.37584
Epoch 64, Val Loss: 4.33180
Epoch 65, Val Loss: 4.28769
Epoch 66, Val Loss: 4.29855
Epoch 67, Val Loss: 4.27205
Epoch 68, Val Loss: 4.29497
Epoch 69, Val Loss: 4.28544
Epoch 70, Val Loss: 4.50886
Epoch 71, Val Loss: 4.33377
Epoch 72, Val Loss: 4.34023
Epoch 73, Val Loss: 5.23380
Epoch 74, Val Loss: 4.37799
Epoch 75, Val Loss: 4.23315
Epoch 76, Val Loss: 4.34624
Epoch 77, Val Loss: 4.25596
Epoch 78, Val Loss: 4.23524
Epoch 79, Val Loss: 4.21734
Epoch 80, Val Loss: 4.25444
Epoch 81, Val Loss: 4.31709
Epoch 82, Val Loss: 4.52283
Epoch 83, Val Loss: 4.51569
Epoch 84, Val Loss: 4.26316
Epoch 85, Val Loss: 4.48390
Epoch 86, Val Loss: 4.38090
Epoch 87, Val Loss: 4.18416
Epoch 88, Val Loss: 4.43675
Epoch 89, Val Loss: 4.26684
Epoch 90, Val Loss: 4.28837
Epoch 91, Val Loss: 4.49847
Epoch 92, Val Loss: 4.19792
Epoch 93, Val Loss: 4.20954
Epoch 94, Val Loss: 4.43299
Epoch 95, Val Loss: 4.35584
Epoch 96, Val Loss: 4.18973
Epoch 97, Val Loss: 4.24463
Epoch 98, Val Loss: 4.34249
Epoch 99, Val Loss: 4.52783
DID NOT SAVE RESULTS
{'MSE - mean': 4.415760474842292, 'MSE - std': 0.18521605678685946, 'R2 - mean': 0.5556722619084333, 'R2 - std': 0.024561577248937202} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.48550
Epoch 1, Val Loss: 13.69477
Epoch 2, Val Loss: 9.41377
Epoch 3, Val Loss: 7.94300
Epoch 4, Val Loss: 7.91555
Epoch 5, Val Loss: 7.69128
Epoch 6, Val Loss: 7.72544
Epoch 7, Val Loss: 7.57024
Epoch 8, Val Loss: 7.58717
Epoch 9, Val Loss: 7.28282
Epoch 10, Val Loss: 7.12527
Epoch 11, Val Loss: 7.11393
Epoch 12, Val Loss: 7.02511
Epoch 13, Val Loss: 7.00770
Epoch 14, Val Loss: 6.94981
Epoch 15, Val Loss: 6.93034
Epoch 16, Val Loss: 6.77362
Epoch 17, Val Loss: 6.63588
Epoch 18, Val Loss: 6.79195
Epoch 19, Val Loss: 6.63981
Epoch 20, Val Loss: 6.47896
Epoch 21, Val Loss: 6.40514
Epoch 22, Val Loss: 6.38383
Epoch 23, Val Loss: 6.33823
Epoch 24, Val Loss: 6.23895
Epoch 25, Val Loss: 6.18150
Epoch 26, Val Loss: 6.47425
Epoch 27, Val Loss: 6.27585
Epoch 28, Val Loss: 6.19670
Epoch 29, Val Loss: 6.01109
Epoch 30, Val Loss: 6.02273
Epoch 31, Val Loss: 6.15358
Epoch 32, Val Loss: 5.97034
Epoch 33, Val Loss: 6.01784
Epoch 34, Val Loss: 6.34529
Epoch 35, Val Loss: 6.00740
Epoch 36, Val Loss: 5.79145
Epoch 37, Val Loss: 5.86551
Epoch 38, Val Loss: 5.68583
Epoch 39, Val Loss: 5.70848
Epoch 40, Val Loss: 5.76755
Epoch 41, Val Loss: 5.81079
Epoch 42, Val Loss: 5.62498
Epoch 43, Val Loss: 5.50459
Epoch 44, Val Loss: 5.76732
Epoch 45, Val Loss: 5.65875
Epoch 46, Val Loss: 5.59102
Epoch 47, Val Loss: 6.20904
Epoch 48, Val Loss: 5.67145
Epoch 49, Val Loss: 5.54886
Epoch 50, Val Loss: 5.61068
Epoch 51, Val Loss: 5.56082
Epoch 52, Val Loss: 5.46198
Epoch 53, Val Loss: 5.56169
Epoch 54, Val Loss: 5.49898
Epoch 55, Val Loss: 5.47960
Epoch 56, Val Loss: 5.45595
Epoch 57, Val Loss: 5.43304
Epoch 58, Val Loss: 5.29583
Epoch 59, Val Loss: 5.59683
Epoch 60, Val Loss: 5.45773
Epoch 61, Val Loss: 5.67760
Epoch 62, Val Loss: 5.65423
Epoch 63, Val Loss: 5.51811
Epoch 64, Val Loss: 5.50185
Epoch 65, Val Loss: 5.38874
Epoch 66, Val Loss: 5.47195
Epoch 67, Val Loss: 5.55939
Epoch 68, Val Loss: 5.83671
Epoch 69, Val Loss: 5.50351
Epoch 70, Val Loss: 5.46794
Epoch 71, Val Loss: 5.35233
Epoch 72, Val Loss: 5.75084
Epoch 73, Val Loss: 5.66608
Epoch 74, Val Loss: 5.74790
Epoch 75, Val Loss: 5.50577
Epoch 76, Val Loss: 5.40887
Epoch 77, Val Loss: 5.48900
Epoch 78, Val Loss: 5.53430
Epoch 79, Val Loss: 5.72835
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.603469635609875, 'MSE - std': 0.41034486264314396, 'R2 - mean': 0.5559779210616863, 'R2 - std': 0.021977046472087123} 
 

Results After CV: {'MSE - mean': 4.603469635609875, 'MSE - std': 0.41034486264314396, 'R2 - mean': 0.5559779210616863, 'R2 - std': 0.021977046472087123}
Train time: 29.65592320939995
Inference time: 0.04903555660002894
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 39 finished with value: 4.603469635609875 and parameters: {'p_m': 0.8951702647994555, 'alpha': 0.26169799358626095, 'K': 3, 'beta': 3.50616842502322}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.03173
Epoch 1, Val Loss: 11.60883
Epoch 2, Val Loss: 6.74397
Epoch 3, Val Loss: 6.37187
Epoch 4, Val Loss: 6.21720
Epoch 5, Val Loss: 6.10027
Epoch 6, Val Loss: 5.97151
Epoch 7, Val Loss: 5.94315
Epoch 8, Val Loss: 5.90044
Epoch 9, Val Loss: 6.06927
Epoch 10, Val Loss: 6.12495
Epoch 11, Val Loss: 5.70131
Epoch 12, Val Loss: 5.75403
Epoch 13, Val Loss: 6.04530
Epoch 14, Val Loss: 5.89437
Epoch 15, Val Loss: 5.67572
Epoch 16, Val Loss: 5.56856
Epoch 17, Val Loss: 5.87242
Epoch 18, Val Loss: 5.93590
Epoch 19, Val Loss: 5.61577
Epoch 20, Val Loss: 5.49735
Epoch 21, Val Loss: 5.44584
Epoch 22, Val Loss: 5.54265
Epoch 23, Val Loss: 5.55082
Epoch 24, Val Loss: 5.66955
Epoch 25, Val Loss: 5.35647
Epoch 26, Val Loss: 5.65651
Epoch 27, Val Loss: 5.32881
Epoch 28, Val Loss: 5.76581
Epoch 29, Val Loss: 5.51722
Epoch 30, Val Loss: 5.29106
Epoch 31, Val Loss: 5.32251
Epoch 32, Val Loss: 5.26085
Epoch 33, Val Loss: 5.25526
Epoch 34, Val Loss: 5.32411
Epoch 35, Val Loss: 5.27674
Epoch 36, Val Loss: 5.50173
Epoch 37, Val Loss: 5.20008
Epoch 38, Val Loss: 5.34512
Epoch 39, Val Loss: 5.18447
Epoch 40, Val Loss: 5.23270
Epoch 41, Val Loss: 5.58318
Epoch 42, Val Loss: 5.14786
Epoch 43, Val Loss: 5.03229
Epoch 44, Val Loss: 5.39911
Epoch 45, Val Loss: 5.05153
Epoch 46, Val Loss: 5.24256
Epoch 47, Val Loss: 5.19361
Epoch 48, Val Loss: 5.26330
Epoch 49, Val Loss: 5.06848
Epoch 50, Val Loss: 5.10587
Epoch 51, Val Loss: 4.92328
Epoch 52, Val Loss: 5.32840
Epoch 53, Val Loss: 4.84142
Epoch 54, Val Loss: 5.08197
Epoch 55, Val Loss: 5.00926
Epoch 56, Val Loss: 4.85071
Epoch 57, Val Loss: 4.80982
Epoch 58, Val Loss: 5.01811
Epoch 59, Val Loss: 4.84869
Epoch 60, Val Loss: 5.11688
Epoch 61, Val Loss: 5.03522
Epoch 62, Val Loss: 5.13341
Epoch 63, Val Loss: 4.87408
Epoch 64, Val Loss: 4.81248
Epoch 65, Val Loss: 5.48093
Epoch 66, Val Loss: 5.42226
Epoch 67, Val Loss: 4.89585
Epoch 68, Val Loss: 4.86606
Epoch 69, Val Loss: 4.92494
Epoch 70, Val Loss: 4.91935
Epoch 71, Val Loss: 4.81892
Epoch 72, Val Loss: 4.78410
Epoch 73, Val Loss: 5.21973
Epoch 74, Val Loss: 4.95740
Epoch 75, Val Loss: 4.90396
Epoch 76, Val Loss: 4.85834
Epoch 77, Val Loss: 5.03186
Epoch 78, Val Loss: 4.85328
Epoch 79, Val Loss: 4.85267
Epoch 80, Val Loss: 4.69299
Epoch 81, Val Loss: 4.73821
Epoch 82, Val Loss: 4.64283
Epoch 83, Val Loss: 4.82304
Epoch 84, Val Loss: 4.78128
Epoch 85, Val Loss: 4.73632
Epoch 86, Val Loss: 4.94757
Epoch 87, Val Loss: 4.88717
Epoch 88, Val Loss: 4.78122
Epoch 89, Val Loss: 4.72966
Epoch 90, Val Loss: 4.60148
Epoch 91, Val Loss: 4.88217
Epoch 92, Val Loss: 4.69923
Epoch 93, Val Loss: 4.76242
Epoch 94, Val Loss: 5.05922
Epoch 95, Val Loss: 4.97029
Epoch 96, Val Loss: 4.97093
Epoch 97, Val Loss: 4.68388
Epoch 98, Val Loss: 4.69038
Epoch 99, Val Loss: 4.73889
DID NOT SAVE RESULTS
{'MSE - mean': 4.80154111417708, 'MSE - std': 0.0, 'R2 - mean': 0.5621153163262196, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.04210
Epoch 1, Val Loss: 10.14132
Epoch 2, Val Loss: 5.67184
Epoch 3, Val Loss: 5.47784
Epoch 4, Val Loss: 5.55353
Epoch 5, Val Loss: 5.42329
Epoch 6, Val Loss: 5.16990
Epoch 7, Val Loss: 5.20311
Epoch 8, Val Loss: 5.11695
Epoch 9, Val Loss: 5.04734
Epoch 10, Val Loss: 5.05459
Epoch 11, Val Loss: 5.08282
Epoch 12, Val Loss: 4.94902
Epoch 13, Val Loss: 5.06538
Epoch 14, Val Loss: 5.23259
Epoch 15, Val Loss: 4.93610
Epoch 16, Val Loss: 4.76505
Epoch 17, Val Loss: 4.75981
Epoch 18, Val Loss: 4.73029
Epoch 19, Val Loss: 4.86441
Epoch 20, Val Loss: 4.93006
Epoch 21, Val Loss: 4.69063
Epoch 22, Val Loss: 4.55660
Epoch 23, Val Loss: 5.31078
Epoch 24, Val Loss: 5.08837
Epoch 25, Val Loss: 4.57976
Epoch 26, Val Loss: 4.55417
Epoch 27, Val Loss: 4.86571
Epoch 28, Val Loss: 4.68234
Epoch 29, Val Loss: 4.50618
Epoch 30, Val Loss: 4.37004
Epoch 31, Val Loss: 4.51984
Epoch 32, Val Loss: 4.61600
Epoch 33, Val Loss: 4.61086
Epoch 34, Val Loss: 4.43006
Epoch 35, Val Loss: 4.41329
Epoch 36, Val Loss: 4.39359
Epoch 37, Val Loss: 4.39102
Epoch 38, Val Loss: 4.29362
Epoch 39, Val Loss: 4.53365
Epoch 40, Val Loss: 4.76506
Epoch 41, Val Loss: 4.67846
Epoch 42, Val Loss: 4.33772
Epoch 43, Val Loss: 4.21318
Epoch 44, Val Loss: 4.25837
Epoch 45, Val Loss: 4.23906
Epoch 46, Val Loss: 4.17235
Epoch 47, Val Loss: 4.12143
Epoch 48, Val Loss: 4.30186
Epoch 49, Val Loss: 4.48271
Epoch 50, Val Loss: 4.19755
Epoch 51, Val Loss: 4.47586
Epoch 52, Val Loss: 4.14647
Epoch 53, Val Loss: 4.24413
Epoch 54, Val Loss: 4.21522
Epoch 55, Val Loss: 4.21414
Epoch 56, Val Loss: 4.06537
Epoch 57, Val Loss: 4.05739
Epoch 58, Val Loss: 4.29475
Epoch 59, Val Loss: 4.22934
Epoch 60, Val Loss: 4.51216
Epoch 61, Val Loss: 4.49457
Epoch 62, Val Loss: 4.69429
Epoch 63, Val Loss: 4.59512
Epoch 64, Val Loss: 4.92570
Epoch 65, Val Loss: 4.16967
Epoch 66, Val Loss: 4.06254
Epoch 67, Val Loss: 4.19563
Epoch 68, Val Loss: 4.12693
Epoch 69, Val Loss: 4.39533
Epoch 70, Val Loss: 4.22798
Epoch 71, Val Loss: 4.53782
Epoch 72, Val Loss: 4.31201
Epoch 73, Val Loss: 4.15661
Epoch 74, Val Loss: 4.16742
Epoch 75, Val Loss: 4.25706
Epoch 76, Val Loss: 4.62086
Epoch 77, Val Loss: 4.41807
Epoch 78, Val Loss: 4.25907
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.526781155349333, 'MSE - std': 0.2747599588277465, 'R2 - mean': 0.5544322338171213, 'R2 - std': 0.007683082509098327} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.96247
Epoch 1, Val Loss: 12.26633
Epoch 2, Val Loss: 6.66165
Epoch 3, Val Loss: 6.43307
Epoch 4, Val Loss: 6.30631
Epoch 5, Val Loss: 6.36843
Epoch 6, Val Loss: 6.20614
Epoch 7, Val Loss: 6.24348
Epoch 8, Val Loss: 6.21844
Epoch 9, Val Loss: 6.08858
Epoch 10, Val Loss: 6.14726
Epoch 11, Val Loss: 6.00027
Epoch 12, Val Loss: 5.90692
Epoch 13, Val Loss: 5.88722
Epoch 14, Val Loss: 5.92610
Epoch 15, Val Loss: 5.83226
Epoch 16, Val Loss: 5.76969
Epoch 17, Val Loss: 5.89096
Epoch 18, Val Loss: 5.65840
Epoch 19, Val Loss: 5.59367
Epoch 20, Val Loss: 5.50795
Epoch 21, Val Loss: 6.01564
Epoch 22, Val Loss: 5.46239
Epoch 23, Val Loss: 5.48524
Epoch 24, Val Loss: 5.39972
Epoch 25, Val Loss: 5.40423
Epoch 26, Val Loss: 5.55970
Epoch 27, Val Loss: 5.28889
Epoch 28, Val Loss: 5.29400
Epoch 29, Val Loss: 5.13886
Epoch 30, Val Loss: 5.18733
Epoch 31, Val Loss: 5.17039
Epoch 32, Val Loss: 5.04023
Epoch 33, Val Loss: 5.02843
Epoch 34, Val Loss: 5.32750
Epoch 35, Val Loss: 5.05249
Epoch 36, Val Loss: 5.01440
Epoch 37, Val Loss: 5.00611
Epoch 38, Val Loss: 5.41472
Epoch 39, Val Loss: 4.76751
Epoch 40, Val Loss: 4.88901
Epoch 41, Val Loss: 4.97851
Epoch 42, Val Loss: 5.35670
Epoch 43, Val Loss: 4.75992
Epoch 44, Val Loss: 4.77022
Epoch 45, Val Loss: 4.82497
Epoch 46, Val Loss: 4.66575
Epoch 47, Val Loss: 5.10194
Epoch 48, Val Loss: 4.96011
Epoch 49, Val Loss: 4.54480
Epoch 50, Val Loss: 4.69061
Epoch 51, Val Loss: 4.54290
Epoch 52, Val Loss: 4.44805
Epoch 53, Val Loss: 5.00470
Epoch 54, Val Loss: 4.54723
Epoch 55, Val Loss: 4.52580
Epoch 56, Val Loss: 4.93165
Epoch 57, Val Loss: 4.52194
Epoch 58, Val Loss: 4.82314
Epoch 59, Val Loss: 4.57469
Epoch 60, Val Loss: 4.81946
Epoch 61, Val Loss: 4.58774
Epoch 62, Val Loss: 4.57629
Epoch 63, Val Loss: 4.60003
Epoch 64, Val Loss: 4.84073
Epoch 65, Val Loss: 4.53907
Epoch 66, Val Loss: 4.59265
Epoch 67, Val Loss: 4.57666
Epoch 68, Val Loss: 4.47061
Epoch 69, Val Loss: 4.50952
Epoch 70, Val Loss: 4.65312
Epoch 71, Val Loss: 4.53598
Epoch 72, Val Loss: 4.58789
Epoch 73, Val Loss: 4.58128
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.530145485104804, 'MSE - std': 0.22439101455440918, 'R2 - mean': 0.5541473264345124, 'R2 - std': 0.006286136783515912} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.06742
Epoch 1, Val Loss: 16.62070
Epoch 2, Val Loss: 7.58888
Epoch 3, Val Loss: 5.63997
Epoch 4, Val Loss: 5.50469
Epoch 5, Val Loss: 5.36292
Epoch 6, Val Loss: 5.18504
Epoch 7, Val Loss: 5.28157
Epoch 8, Val Loss: 5.27376
Epoch 9, Val Loss: 5.06494
Epoch 10, Val Loss: 4.88165
Epoch 11, Val Loss: 4.89809
Epoch 12, Val Loss: 5.45726
Epoch 13, Val Loss: 4.83395
Epoch 14, Val Loss: 4.80777
Epoch 15, Val Loss: 4.92710
Epoch 16, Val Loss: 4.73810
Epoch 17, Val Loss: 4.78094
Epoch 18, Val Loss: 4.81827
Epoch 19, Val Loss: 4.89152
Epoch 20, Val Loss: 4.63451
Epoch 21, Val Loss: 4.59136
Epoch 22, Val Loss: 4.62798
Epoch 23, Val Loss: 4.52496
Epoch 24, Val Loss: 4.65087
Epoch 25, Val Loss: 4.89244
Epoch 26, Val Loss: 4.53326
Epoch 27, Val Loss: 4.83639
Epoch 28, Val Loss: 4.48073
Epoch 29, Val Loss: 4.54680
Epoch 30, Val Loss: 4.52934
Epoch 31, Val Loss: 4.50301
Epoch 32, Val Loss: 4.45324
Epoch 33, Val Loss: 4.55216
Epoch 34, Val Loss: 4.42212
Epoch 35, Val Loss: 4.57915
Epoch 36, Val Loss: 4.45803
Epoch 37, Val Loss: 4.54719
Epoch 38, Val Loss: 4.51103
Epoch 39, Val Loss: 4.40421
Epoch 40, Val Loss: 4.35390
Epoch 41, Val Loss: 4.47903
Epoch 42, Val Loss: 4.48922
Epoch 43, Val Loss: 4.57795
Epoch 44, Val Loss: 4.36176
Epoch 45, Val Loss: 4.42842
Epoch 46, Val Loss: 4.50933
Epoch 47, Val Loss: 4.35132
Epoch 48, Val Loss: 4.32232
Epoch 49, Val Loss: 4.35734
Epoch 50, Val Loss: 4.38765
Epoch 51, Val Loss: 4.39524
Epoch 52, Val Loss: 4.50448
Epoch 53, Val Loss: 4.41370
Epoch 54, Val Loss: 4.28638
Epoch 55, Val Loss: 4.25243
Epoch 56, Val Loss: 4.29716
Epoch 57, Val Loss: 4.18110
Epoch 58, Val Loss: 4.37199
Epoch 59, Val Loss: 4.19983
Epoch 60, Val Loss: 4.19650
Epoch 61, Val Loss: 4.21931
Epoch 62, Val Loss: 4.18977
Epoch 63, Val Loss: 4.21129
Epoch 64, Val Loss: 4.23956
Epoch 65, Val Loss: 4.17265
Epoch 66, Val Loss: 4.29546
Epoch 67, Val Loss: 4.16279
Epoch 68, Val Loss: 4.27257
Epoch 69, Val Loss: 4.52328
Epoch 70, Val Loss: 4.09736
Epoch 71, Val Loss: 4.22219
Epoch 72, Val Loss: 4.06189
Epoch 73, Val Loss: 4.14634
Epoch 74, Val Loss: 4.37423
Epoch 75, Val Loss: 4.13051
Epoch 76, Val Loss: 4.19086
Epoch 77, Val Loss: 4.15033
Epoch 78, Val Loss: 4.25758
Epoch 79, Val Loss: 4.02670
Epoch 80, Val Loss: 4.19004
Epoch 81, Val Loss: 4.21937
Epoch 82, Val Loss: 4.12379
Epoch 83, Val Loss: 4.13432
Epoch 84, Val Loss: 4.24189
Epoch 85, Val Loss: 4.27493
Epoch 86, Val Loss: 4.40863
Epoch 87, Val Loss: 4.05981
Epoch 88, Val Loss: 4.18207
Epoch 89, Val Loss: 4.20538
Epoch 90, Val Loss: 4.45335
Epoch 91, Val Loss: 4.05640
Epoch 92, Val Loss: 4.26063
Epoch 93, Val Loss: 4.00134
Epoch 94, Val Loss: 4.07613
Epoch 95, Val Loss: 4.51092
Epoch 96, Val Loss: 4.03498
Epoch 97, Val Loss: 4.18013
Epoch 98, Val Loss: 4.24063
Epoch 99, Val Loss: 4.05085
DID NOT SAVE RESULTS
{'MSE - mean': 4.4730130098319245, 'MSE - std': 0.21807304911883696, 'R2 - mean': 0.5506277635264242, 'R2 - std': 0.00817304141294876} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.06503
Epoch 1, Val Loss: 15.87073
Epoch 2, Val Loss: 8.96286
Epoch 3, Val Loss: 8.72223
Epoch 4, Val Loss: 7.76629
Epoch 5, Val Loss: 7.96604
Epoch 6, Val Loss: 8.20219
Epoch 7, Val Loss: 7.65627
Epoch 8, Val Loss: 7.40604
Epoch 9, Val Loss: 7.82767
Epoch 10, Val Loss: 7.48567
Epoch 11, Val Loss: 7.27665
Epoch 12, Val Loss: 7.17131
Epoch 13, Val Loss: 7.09369
Epoch 14, Val Loss: 7.06759
Epoch 15, Val Loss: 7.09847
Epoch 16, Val Loss: 7.08094
Epoch 17, Val Loss: 6.84679
Epoch 18, Val Loss: 6.91947
Epoch 19, Val Loss: 6.80556
Epoch 20, Val Loss: 6.88260
Epoch 21, Val Loss: 7.02823
Epoch 22, Val Loss: 6.82719
Epoch 23, Val Loss: 6.66552
Epoch 24, Val Loss: 6.73495
Epoch 25, Val Loss: 6.62565
Epoch 26, Val Loss: 6.78587
Epoch 27, Val Loss: 6.73298
Epoch 28, Val Loss: 6.68628
Epoch 29, Val Loss: 6.55018
Epoch 30, Val Loss: 6.44079
Epoch 31, Val Loss: 6.69089
Epoch 32, Val Loss: 6.70213
Epoch 33, Val Loss: 6.44423
Epoch 34, Val Loss: 6.35869
Epoch 35, Val Loss: 6.48682
Epoch 36, Val Loss: 6.58281
Epoch 37, Val Loss: 6.70754
Epoch 38, Val Loss: 6.28151
Epoch 39, Val Loss: 6.20171
Epoch 40, Val Loss: 6.23117
Epoch 41, Val Loss: 6.28044
Epoch 42, Val Loss: 6.27464
Epoch 43, Val Loss: 6.20473
Epoch 44, Val Loss: 6.31036
Epoch 45, Val Loss: 6.26006
Epoch 46, Val Loss: 6.11377
Epoch 47, Val Loss: 6.25332
Epoch 48, Val Loss: 6.29213
Epoch 49, Val Loss: 6.45562
Epoch 50, Val Loss: 6.09975
Epoch 51, Val Loss: 6.27294
Epoch 52, Val Loss: 6.20777
Epoch 53, Val Loss: 6.09352
Epoch 54, Val Loss: 6.05670
Epoch 55, Val Loss: 6.61882
Epoch 56, Val Loss: 6.17203
Epoch 57, Val Loss: 6.13627
Epoch 58, Val Loss: 6.15182
Epoch 59, Val Loss: 6.24318
Epoch 60, Val Loss: 6.11561
Epoch 61, Val Loss: 6.20457
Epoch 62, Val Loss: 7.25587
Epoch 63, Val Loss: 5.95449
Epoch 64, Val Loss: 5.92290
Epoch 65, Val Loss: 6.09170
Epoch 66, Val Loss: 6.03122
Epoch 67, Val Loss: 6.10798
Epoch 68, Val Loss: 5.97155
Epoch 69, Val Loss: 6.33178
Epoch 70, Val Loss: 5.93213
Epoch 71, Val Loss: 6.11426
Epoch 72, Val Loss: 5.97451
Epoch 73, Val Loss: 6.13416
Epoch 74, Val Loss: 6.04943
Epoch 75, Val Loss: 6.01952
Epoch 76, Val Loss: 5.98976
Epoch 77, Val Loss: 6.12611
Epoch 78, Val Loss: 6.05261
Epoch 79, Val Loss: 5.91758
Epoch 80, Val Loss: 6.16887
Epoch 81, Val Loss: 6.17813
Epoch 82, Val Loss: 6.01375
Epoch 83, Val Loss: 5.77149
Epoch 84, Val Loss: 6.04063
Epoch 85, Val Loss: 5.86052
Epoch 86, Val Loss: 5.91748
Epoch 87, Val Loss: 5.91164
Epoch 88, Val Loss: 6.27721
Epoch 89, Val Loss: 6.12253
Epoch 90, Val Loss: 6.66568
Epoch 91, Val Loss: 5.80092
Epoch 92, Val Loss: 6.07645
Epoch 93, Val Loss: 5.99137
Epoch 94, Val Loss: 6.17376
Epoch 95, Val Loss: 6.13859
Epoch 96, Val Loss: 6.02274
Epoch 97, Val Loss: 6.07897
Epoch 98, Val Loss: 6.06754
Epoch 99, Val Loss: 5.80608
DID NOT SAVE RESULTS
{'MSE - mean': 4.751723901517289, 'MSE - std': 0.5905622138079905, 'R2 - mean': 0.5434695545589336, 'R2 - std': 0.016074784827152994} 
 

Results After CV: {'MSE - mean': 4.751723901517289, 'MSE - std': 0.5905622138079905, 'R2 - mean': 0.5434695545589336, 'R2 - std': 0.016074784827152994}
Train time: 29.85831367840019
Inference time: 0.04813589019977371
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 40 finished with value: 4.751723901517289 and parameters: {'p_m': 0.8380775255756033, 'alpha': 0.8710247008708542, 'K': 3, 'beta': 4.374264504404425}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 21.14916
Epoch 1, Val Loss: 8.90324
Epoch 2, Val Loss: 7.00891
Epoch 3, Val Loss: 6.70907
Epoch 4, Val Loss: 6.25420
Epoch 5, Val Loss: 6.00039
Epoch 6, Val Loss: 6.09402
Epoch 7, Val Loss: 5.79022
Epoch 8, Val Loss: 5.89434
Epoch 9, Val Loss: 5.78216
Epoch 10, Val Loss: 5.60226
Epoch 11, Val Loss: 5.62618
Epoch 12, Val Loss: 5.92499
Epoch 13, Val Loss: 5.46502
Epoch 14, Val Loss: 5.47915
Epoch 15, Val Loss: 5.29021
Epoch 16, Val Loss: 5.33148
Epoch 17, Val Loss: 5.43708
Epoch 18, Val Loss: 5.23657
Epoch 19, Val Loss: 5.27302
Epoch 20, Val Loss: 5.20762
Epoch 21, Val Loss: 5.16991
Epoch 22, Val Loss: 5.09416
Epoch 23, Val Loss: 5.11002
Epoch 24, Val Loss: 5.08717
Epoch 25, Val Loss: 5.44457
Epoch 26, Val Loss: 5.27311
Epoch 27, Val Loss: 5.16273
Epoch 28, Val Loss: 4.99670
Epoch 29, Val Loss: 5.23710
Epoch 30, Val Loss: 4.98000
Epoch 31, Val Loss: 5.24392
Epoch 32, Val Loss: 5.11863
Epoch 33, Val Loss: 4.91729
Epoch 34, Val Loss: 4.90302
Epoch 35, Val Loss: 4.83232
Epoch 36, Val Loss: 5.03788
Epoch 37, Val Loss: 5.03822
Epoch 38, Val Loss: 4.94992
Epoch 39, Val Loss: 5.01701
Epoch 40, Val Loss: 4.93585
Epoch 41, Val Loss: 4.85801
Epoch 42, Val Loss: 4.84937
Epoch 43, Val Loss: 4.86934
Epoch 44, Val Loss: 4.75493
Epoch 45, Val Loss: 4.89868
Epoch 46, Val Loss: 5.01070
Epoch 47, Val Loss: 4.93277
Epoch 48, Val Loss: 4.92035
Epoch 49, Val Loss: 4.85323
Epoch 50, Val Loss: 4.71075
Epoch 51, Val Loss: 4.71963
Epoch 52, Val Loss: 4.79902
Epoch 53, Val Loss: 5.30281
Epoch 54, Val Loss: 4.79173
Epoch 55, Val Loss: 4.67950
Epoch 56, Val Loss: 4.81353
Epoch 57, Val Loss: 4.66497
Epoch 58, Val Loss: 4.93703
Epoch 59, Val Loss: 4.82474
Epoch 60, Val Loss: 4.67021
Epoch 61, Val Loss: 4.66440
Epoch 62, Val Loss: 4.63470
Epoch 63, Val Loss: 4.78165
Epoch 64, Val Loss: 4.85533
Epoch 65, Val Loss: 4.62519
Epoch 66, Val Loss: 4.68943
Epoch 67, Val Loss: 4.71195
Epoch 68, Val Loss: 4.56381
Epoch 69, Val Loss: 4.65866
Epoch 70, Val Loss: 4.69961
Epoch 71, Val Loss: 4.56259
Epoch 72, Val Loss: 4.59832
Epoch 73, Val Loss: 4.57224
Epoch 74, Val Loss: 4.64780
Epoch 75, Val Loss: 4.61152
Epoch 76, Val Loss: 4.57838
Epoch 77, Val Loss: 4.65149
Epoch 78, Val Loss: 4.64954
Epoch 79, Val Loss: 5.13301
Epoch 80, Val Loss: 4.73392
Epoch 81, Val Loss: 4.66988
Epoch 82, Val Loss: 4.62374
Epoch 83, Val Loss: 4.61690
Epoch 84, Val Loss: 4.65256
Epoch 85, Val Loss: 4.65037
Epoch 86, Val Loss: 4.56352
Epoch 87, Val Loss: 4.58465
Epoch 88, Val Loss: 4.56489
Epoch 89, Val Loss: 4.62818
Epoch 90, Val Loss: 4.61860
Epoch 91, Val Loss: 4.62766
Epoch 92, Val Loss: 5.76987
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.686987506001226, 'MSE - std': 0.0, 'R2 - mean': 0.5725622268674346, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 16.06455
Epoch 1, Val Loss: 7.86048
Epoch 2, Val Loss: 6.62264
Epoch 3, Val Loss: 6.13179
Epoch 4, Val Loss: 5.93488
Epoch 5, Val Loss: 5.12323
Epoch 6, Val Loss: 5.11641
Epoch 7, Val Loss: 5.08453
Epoch 8, Val Loss: 4.85878
Epoch 9, Val Loss: 4.91443
Epoch 10, Val Loss: 5.38061
Epoch 11, Val Loss: 4.87419
Epoch 12, Val Loss: 5.25661
Epoch 13, Val Loss: 4.59665
Epoch 14, Val Loss: 4.55710
Epoch 15, Val Loss: 4.66536
Epoch 16, Val Loss: 4.52621
Epoch 17, Val Loss: 4.57567
Epoch 18, Val Loss: 4.52949
Epoch 19, Val Loss: 4.43053
Epoch 20, Val Loss: 4.55044
Epoch 21, Val Loss: 4.34374
Epoch 22, Val Loss: 4.31681
Epoch 23, Val Loss: 4.29734
Epoch 24, Val Loss: 4.27250
Epoch 25, Val Loss: 4.49965
Epoch 26, Val Loss: 4.53414
Epoch 27, Val Loss: 4.26815
Epoch 28, Val Loss: 4.41820
Epoch 29, Val Loss: 4.47678
Epoch 30, Val Loss: 4.62227
Epoch 31, Val Loss: 4.29023
Epoch 32, Val Loss: 4.15801
Epoch 33, Val Loss: 4.23545
Epoch 34, Val Loss: 4.19170
Epoch 35, Val Loss: 4.41589
Epoch 36, Val Loss: 4.12252
Epoch 37, Val Loss: 4.08203
Epoch 38, Val Loss: 4.28812
Epoch 39, Val Loss: 4.20213
Epoch 40, Val Loss: 4.19300
Epoch 41, Val Loss: 4.32360
Epoch 42, Val Loss: 4.32199
Epoch 43, Val Loss: 4.05636
Epoch 44, Val Loss: 4.07326
Epoch 45, Val Loss: 4.13049
Epoch 46, Val Loss: 4.05003
Epoch 47, Val Loss: 4.04109
Epoch 48, Val Loss: 4.11158
Epoch 49, Val Loss: 4.10562
Epoch 50, Val Loss: 4.07785
Epoch 51, Val Loss: 4.13496
Epoch 52, Val Loss: 4.07666
Epoch 53, Val Loss: 4.07686
Epoch 54, Val Loss: 4.35860
Epoch 55, Val Loss: 4.20236
Epoch 56, Val Loss: 4.01503
Epoch 57, Val Loss: 3.99551
Epoch 58, Val Loss: 4.10117
Epoch 59, Val Loss: 4.03911
Epoch 60, Val Loss: 4.05601
Epoch 61, Val Loss: 4.57121
Epoch 62, Val Loss: 4.17032
Epoch 63, Val Loss: 4.10884
Epoch 64, Val Loss: 4.03073
Epoch 65, Val Loss: 4.15317
Epoch 66, Val Loss: 4.19938
Epoch 67, Val Loss: 4.29363
Epoch 68, Val Loss: 3.96128
Epoch 69, Val Loss: 4.01637
Epoch 70, Val Loss: 4.17664
Epoch 71, Val Loss: 3.99585
Epoch 72, Val Loss: 4.07863
Epoch 73, Val Loss: 4.01588
Epoch 74, Val Loss: 4.06370
Epoch 75, Val Loss: 4.60840
Epoch 76, Val Loss: 4.02943
Epoch 77, Val Loss: 4.01377
Epoch 78, Val Loss: 4.02236
Epoch 79, Val Loss: 4.05368
Epoch 80, Val Loss: 4.06593
Epoch 81, Val Loss: 4.97054
Epoch 82, Val Loss: 4.01962
Epoch 83, Val Loss: 3.98877
Epoch 84, Val Loss: 4.09440
Epoch 85, Val Loss: 4.08915
Epoch 86, Val Loss: 4.04714
Epoch 87, Val Loss: 4.00643
Epoch 88, Val Loss: 4.84439
Epoch 89, Val Loss: 4.01503
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.387449855875502, 'MSE - std': 0.2995376501257243, 'R2 - mean': 0.5684024163390129, 'R2 - std': 0.004159810528421681} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 14.62522
Epoch 1, Val Loss: 8.27091
Epoch 2, Val Loss: 6.81144
Epoch 3, Val Loss: 6.44537
Epoch 4, Val Loss: 6.17031
Epoch 5, Val Loss: 6.08321
Epoch 6, Val Loss: 6.20290
Epoch 7, Val Loss: 6.00618
Epoch 8, Val Loss: 5.97069
Epoch 9, Val Loss: 5.87292
Epoch 10, Val Loss: 5.84778
Epoch 11, Val Loss: 5.77487
Epoch 12, Val Loss: 5.77991
Epoch 13, Val Loss: 5.80382
Epoch 14, Val Loss: 5.54558
Epoch 15, Val Loss: 5.63228
Epoch 16, Val Loss: 5.61561
Epoch 17, Val Loss: 5.55650
Epoch 18, Val Loss: 5.53986
Epoch 19, Val Loss: 5.57377
Epoch 20, Val Loss: 5.85523
Epoch 21, Val Loss: 5.66387
Epoch 22, Val Loss: 5.32506
Epoch 23, Val Loss: 5.24533
Epoch 24, Val Loss: 5.24948
Epoch 25, Val Loss: 5.20169
Epoch 26, Val Loss: 5.18797
Epoch 27, Val Loss: 5.23550
Epoch 28, Val Loss: 5.10697
Epoch 29, Val Loss: 5.09665
Epoch 30, Val Loss: 5.11294
Epoch 31, Val Loss: 5.08779
Epoch 32, Val Loss: 5.24098
Epoch 33, Val Loss: 5.12856
Epoch 34, Val Loss: 5.08502
Epoch 35, Val Loss: 5.06248
Epoch 36, Val Loss: 5.25163
Epoch 37, Val Loss: 4.97925
Epoch 38, Val Loss: 4.98219
Epoch 39, Val Loss: 5.01151
Epoch 40, Val Loss: 4.94455
Epoch 41, Val Loss: 5.12103
Epoch 42, Val Loss: 4.96342
Epoch 43, Val Loss: 5.49424
Epoch 44, Val Loss: 4.98685
Epoch 45, Val Loss: 5.16683
Epoch 46, Val Loss: 5.05019
Epoch 47, Val Loss: 5.12024
Epoch 48, Val Loss: 4.96044
Epoch 49, Val Loss: 4.94268
Epoch 50, Val Loss: 5.04045
Epoch 51, Val Loss: 4.87958
Epoch 52, Val Loss: 5.37844
Epoch 53, Val Loss: 5.07968
Epoch 54, Val Loss: 4.93510
Epoch 55, Val Loss: 4.89096
Epoch 56, Val Loss: 4.88012
Epoch 57, Val Loss: 4.86298
Epoch 58, Val Loss: 5.19632
Epoch 59, Val Loss: 4.82842
Epoch 60, Val Loss: 4.85704
Epoch 61, Val Loss: 4.85009
Epoch 62, Val Loss: 4.82564
Epoch 63, Val Loss: 4.92049
Epoch 64, Val Loss: 4.81312
Epoch 65, Val Loss: 4.89944
Epoch 66, Val Loss: 4.77335
Epoch 67, Val Loss: 5.23105
Epoch 68, Val Loss: 4.83032
Epoch 69, Val Loss: 5.00473
Epoch 70, Val Loss: 5.13561
Epoch 71, Val Loss: 4.95494
Epoch 72, Val Loss: 5.10474
Epoch 73, Val Loss: 4.77717
Epoch 74, Val Loss: 4.95459
Epoch 75, Val Loss: 4.80244
Epoch 76, Val Loss: 4.73336
Epoch 77, Val Loss: 4.82401
Epoch 78, Val Loss: 4.87443
Epoch 79, Val Loss: 4.76612
Epoch 80, Val Loss: 4.73179
Epoch 81, Val Loss: 4.77659
Epoch 82, Val Loss: 4.80462
Epoch 83, Val Loss: 4.86290
Epoch 84, Val Loss: 4.80163
Epoch 85, Val Loss: 4.81231
Epoch 86, Val Loss: 5.07352
Epoch 87, Val Loss: 4.97375
Epoch 88, Val Loss: 4.80740
Epoch 89, Val Loss: 4.84792
Epoch 90, Val Loss: 4.78760
Epoch 91, Val Loss: 5.10795
Epoch 92, Val Loss: 4.74087
Epoch 93, Val Loss: 4.73786
Epoch 94, Val Loss: 4.90225
Epoch 95, Val Loss: 5.20802
Epoch 96, Val Loss: 4.75634
Epoch 97, Val Loss: 4.89830
Epoch 98, Val Loss: 4.86647
Epoch 99, Val Loss: 4.94405
DID NOT SAVE RESULTS
{'MSE - mean': 4.4989190979804885, 'MSE - std': 0.2909742023493046, 'R2 - mean': 0.5573934052579411, 'R2 - std': 0.01593526484628469} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 21.70962
Epoch 1, Val Loss: 7.96243
Epoch 2, Val Loss: 5.88505
Epoch 3, Val Loss: 5.41675
Epoch 4, Val Loss: 5.26966
Epoch 5, Val Loss: 5.13001
Epoch 6, Val Loss: 5.21267
Epoch 7, Val Loss: 4.93918
Epoch 8, Val Loss: 5.01822
Epoch 9, Val Loss: 4.82780
Epoch 10, Val Loss: 4.91389
Epoch 11, Val Loss: 4.70506
Epoch 12, Val Loss: 4.67364
Epoch 13, Val Loss: 4.53795
Epoch 14, Val Loss: 4.55442
Epoch 15, Val Loss: 4.60004
Epoch 16, Val Loss: 4.50731
Epoch 17, Val Loss: 4.40157
Epoch 18, Val Loss: 4.36203
Epoch 19, Val Loss: 4.57346
Epoch 20, Val Loss: 4.26895
Epoch 21, Val Loss: 4.29523
Epoch 22, Val Loss: 4.32733
Epoch 23, Val Loss: 4.21512
Epoch 24, Val Loss: 4.50385
Epoch 25, Val Loss: 4.85674
Epoch 26, Val Loss: 4.33330
Epoch 27, Val Loss: 4.88759
Epoch 28, Val Loss: 4.12312
Epoch 29, Val Loss: 4.13991
Epoch 30, Val Loss: 4.11496
Epoch 31, Val Loss: 4.31373
Epoch 32, Val Loss: 4.23545
Epoch 33, Val Loss: 4.12850
Epoch 34, Val Loss: 4.20499
Epoch 35, Val Loss: 4.17676
Epoch 36, Val Loss: 4.08741
Epoch 37, Val Loss: 4.42470
Epoch 38, Val Loss: 4.13798
Epoch 39, Val Loss: 4.33214
Epoch 40, Val Loss: 4.49116
Epoch 41, Val Loss: 4.00337
Epoch 42, Val Loss: 4.04032
Epoch 43, Val Loss: 4.06369
Epoch 44, Val Loss: 4.02248
Epoch 45, Val Loss: 4.11363
Epoch 46, Val Loss: 4.01469
Epoch 47, Val Loss: 4.14620
Epoch 48, Val Loss: 4.06502
Epoch 49, Val Loss: 4.11496
Epoch 50, Val Loss: 3.95904
Epoch 51, Val Loss: 4.02630
Epoch 52, Val Loss: 4.00169
Epoch 53, Val Loss: 4.06090
Epoch 54, Val Loss: 4.48773
Epoch 55, Val Loss: 3.91659
Epoch 56, Val Loss: 4.01993
Epoch 57, Val Loss: 4.23786
Epoch 58, Val Loss: 4.03973
Epoch 59, Val Loss: 3.95613
Epoch 60, Val Loss: 4.31895
Epoch 61, Val Loss: 4.52482
Epoch 62, Val Loss: 3.92270
Epoch 63, Val Loss: 4.22449
Epoch 64, Val Loss: 3.93311
Epoch 65, Val Loss: 4.12577
Epoch 66, Val Loss: 4.06377
Epoch 67, Val Loss: 4.13407
Epoch 68, Val Loss: 4.15533
Epoch 69, Val Loss: 3.96950
Epoch 70, Val Loss: 3.93747
Epoch 71, Val Loss: 4.11458
Epoch 72, Val Loss: 4.62079
Epoch 73, Val Loss: 4.02015
Epoch 74, Val Loss: 4.20134
Epoch 75, Val Loss: 4.03807
Epoch 76, Val Loss: 3.97988
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.429555528525614, 'MSE - std': 0.27916554967827634, 'R2 - mean': 0.5552047627489938, 'R2 - std': 0.014311532670781344} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.29663
Epoch 1, Val Loss: 10.77650
Epoch 2, Val Loss: 8.62524
Epoch 3, Val Loss: 7.87397
Epoch 4, Val Loss: 7.53171
Epoch 5, Val Loss: 7.62034
Epoch 6, Val Loss: 7.35661
Epoch 7, Val Loss: 7.39497
Epoch 8, Val Loss: 7.31917
Epoch 9, Val Loss: 7.27692
Epoch 10, Val Loss: 7.42642
Epoch 11, Val Loss: 7.30053
Epoch 12, Val Loss: 7.20064
Epoch 13, Val Loss: 7.05774
Epoch 14, Val Loss: 6.93910
Epoch 15, Val Loss: 6.91237
Epoch 16, Val Loss: 7.32710
Epoch 17, Val Loss: 6.90493
Epoch 18, Val Loss: 6.81483
Epoch 19, Val Loss: 6.86141
Epoch 20, Val Loss: 6.67616
Epoch 21, Val Loss: 6.63246
Epoch 22, Val Loss: 6.53460
Epoch 23, Val Loss: 6.41288
Epoch 24, Val Loss: 6.44007
Epoch 25, Val Loss: 6.51175
Epoch 26, Val Loss: 6.38229
Epoch 27, Val Loss: 6.38094
Epoch 28, Val Loss: 6.46147
Epoch 29, Val Loss: 6.41730
Epoch 30, Val Loss: 6.70731
Epoch 31, Val Loss: 6.35345
Epoch 32, Val Loss: 6.45511
Epoch 33, Val Loss: 6.38082
Epoch 34, Val Loss: 6.15875
Epoch 35, Val Loss: 6.28396
Epoch 36, Val Loss: 6.24810
Epoch 37, Val Loss: 6.53846
Epoch 38, Val Loss: 6.32802
Epoch 39, Val Loss: 6.28614
Epoch 40, Val Loss: 6.63823
Epoch 41, Val Loss: 6.30512
Epoch 42, Val Loss: 6.23372
Epoch 43, Val Loss: 6.17596
Epoch 44, Val Loss: 6.20277
Epoch 45, Val Loss: 6.16061
Epoch 46, Val Loss: 6.07406
Epoch 47, Val Loss: 6.18356
Epoch 48, Val Loss: 6.30525
Epoch 49, Val Loss: 6.61748
Epoch 50, Val Loss: 6.12686
Epoch 51, Val Loss: 5.97171
Epoch 52, Val Loss: 6.12877
Epoch 53, Val Loss: 6.42662
Epoch 54, Val Loss: 6.36171
Epoch 55, Val Loss: 6.37831
Epoch 56, Val Loss: 6.25974
Epoch 57, Val Loss: 6.03582
Epoch 58, Val Loss: 6.12724
Epoch 59, Val Loss: 6.01520
Epoch 60, Val Loss: 6.19017
Epoch 61, Val Loss: 6.26407
Epoch 62, Val Loss: 6.34209
Epoch 63, Val Loss: 6.28528
Epoch 64, Val Loss: 6.39482
Epoch 65, Val Loss: 6.14009
Epoch 66, Val Loss: 6.03047
Epoch 67, Val Loss: 6.31692
Epoch 68, Val Loss: 6.18334
Epoch 69, Val Loss: 5.96193
Epoch 70, Val Loss: 5.90397
Epoch 71, Val Loss: 5.96488
Epoch 72, Val Loss: 6.20849
Epoch 73, Val Loss: 5.97699
Epoch 74, Val Loss: 5.94160
Epoch 75, Val Loss: 5.99410
Epoch 76, Val Loss: 5.89559
Epoch 77, Val Loss: 6.02897
Epoch 78, Val Loss: 5.87568
Epoch 79, Val Loss: 6.08019
Epoch 80, Val Loss: 6.26113
Epoch 81, Val Loss: 6.27238
Epoch 82, Val Loss: 6.44357
Epoch 83, Val Loss: 5.84478
Epoch 84, Val Loss: 5.93674
Epoch 85, Val Loss: 5.86057
Epoch 86, Val Loss: 6.16084
Epoch 87, Val Loss: 5.92148
Epoch 88, Val Loss: 5.75581
Epoch 89, Val Loss: 6.00480
Epoch 90, Val Loss: 5.90790
Epoch 91, Val Loss: 5.90264
Epoch 92, Val Loss: 5.99751
Epoch 93, Val Loss: 5.79614
Epoch 94, Val Loss: 6.01093
Epoch 95, Val Loss: 5.90745
Epoch 96, Val Loss: 5.87640
Epoch 97, Val Loss: 6.17920
Epoch 98, Val Loss: 6.05183
Epoch 99, Val Loss: 5.73966
DID NOT SAVE RESULTS
{'MSE - mean': 4.693514700540084, 'MSE - std': 0.5839901551087984, 'R2 - mean': 0.5490699005085862, 'R2 - std': 0.017731387783943734} 
 

Results After CV: {'MSE - mean': 4.693514700540084, 'MSE - std': 0.5839901551087984, 'R2 - mean': 0.5490699005085862, 'R2 - std': 0.017731387783943734}
Train time: 30.55164641079973
Inference time: 0.048582926000381124
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 41 finished with value: 4.693514700540084 and parameters: {'p_m': 0.8479425048692986, 'alpha': 0.14668482518342477, 'K': 3, 'beta': 2.7485980418520652}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.46772
Epoch 1, Val Loss: 11.39652
Epoch 2, Val Loss: 8.15745
Epoch 3, Val Loss: 7.63631
Epoch 4, Val Loss: 7.17469
Epoch 5, Val Loss: 7.77757
Epoch 6, Val Loss: 7.28026
Epoch 7, Val Loss: 6.69343
Epoch 8, Val Loss: 6.66571
Epoch 9, Val Loss: 6.50922
Epoch 10, Val Loss: 6.36750
Epoch 11, Val Loss: 6.54494
Epoch 12, Val Loss: 6.33477
Epoch 13, Val Loss: 6.36279
Epoch 14, Val Loss: 6.32781
Epoch 15, Val Loss: 6.18510
Epoch 16, Val Loss: 6.16327
Epoch 17, Val Loss: 6.11942
Epoch 18, Val Loss: 5.97593
Epoch 19, Val Loss: 6.25484
Epoch 20, Val Loss: 6.26192
Epoch 21, Val Loss: 5.94103
Epoch 22, Val Loss: 5.96582
Epoch 23, Val Loss: 5.86523
Epoch 24, Val Loss: 5.81078
Epoch 25, Val Loss: 5.78573
Epoch 26, Val Loss: 5.55746
Epoch 27, Val Loss: 5.56845
Epoch 28, Val Loss: 5.45599
Epoch 29, Val Loss: 5.70727
Epoch 30, Val Loss: 5.47185
Epoch 31, Val Loss: 5.52861
Epoch 32, Val Loss: 5.40170
Epoch 33, Val Loss: 5.29516
Epoch 34, Val Loss: 5.18309
Epoch 35, Val Loss: 5.20078
Epoch 36, Val Loss: 5.15252
Epoch 37, Val Loss: 5.26886
Epoch 38, Val Loss: 5.37903
Epoch 39, Val Loss: 5.08660
Epoch 40, Val Loss: 5.31850
Epoch 41, Val Loss: 5.10500
Epoch 42, Val Loss: 5.15318
Epoch 43, Val Loss: 5.20391
Epoch 44, Val Loss: 5.06860
Epoch 45, Val Loss: 5.02148
Epoch 46, Val Loss: 4.99254
Epoch 47, Val Loss: 5.51780
Epoch 48, Val Loss: 4.86631
Epoch 49, Val Loss: 4.91080
Epoch 50, Val Loss: 5.52941
Epoch 51, Val Loss: 4.90686
Epoch 52, Val Loss: 5.36865
Epoch 53, Val Loss: 4.80265
Epoch 54, Val Loss: 4.74645
Epoch 55, Val Loss: 5.56297
Epoch 56, Val Loss: 4.77891
Epoch 57, Val Loss: 4.79524
Epoch 58, Val Loss: 4.71466
Epoch 59, Val Loss: 4.84459
Epoch 60, Val Loss: 4.66743
Epoch 61, Val Loss: 4.65847
Epoch 62, Val Loss: 4.58303
Epoch 63, Val Loss: 4.71402
Epoch 64, Val Loss: 4.60994
Epoch 65, Val Loss: 4.70007
Epoch 66, Val Loss: 4.70257
Epoch 67, Val Loss: 4.67640
Epoch 68, Val Loss: 4.69853
Epoch 69, Val Loss: 5.77946
Epoch 70, Val Loss: 5.21760
Epoch 71, Val Loss: 4.96224
Epoch 72, Val Loss: 4.54926
Epoch 73, Val Loss: 4.53559
Epoch 74, Val Loss: 4.58630
Epoch 75, Val Loss: 4.54669
Epoch 76, Val Loss: 4.87997
Epoch 77, Val Loss: 4.53101
Epoch 78, Val Loss: 4.74252
Epoch 79, Val Loss: 4.48363
Epoch 80, Val Loss: 4.80586
Epoch 81, Val Loss: 4.75573
Epoch 82, Val Loss: 4.55095
Epoch 83, Val Loss: 4.72893
Epoch 84, Val Loss: 4.57277
Epoch 85, Val Loss: 5.12898
Epoch 86, Val Loss: 4.52520
Epoch 87, Val Loss: 4.74627
Epoch 88, Val Loss: 4.49741
Epoch 89, Val Loss: 4.85567
Epoch 90, Val Loss: 4.48500
Epoch 91, Val Loss: 4.45458
Epoch 92, Val Loss: 4.46660
Epoch 93, Val Loss: 4.76628
Epoch 94, Val Loss: 5.27525
Epoch 95, Val Loss: 5.02450
Epoch 96, Val Loss: 4.81752
Epoch 97, Val Loss: 4.93150
Epoch 98, Val Loss: 4.74322
Epoch 99, Val Loss: 4.55673
DID NOT SAVE RESULTS
{'MSE - mean': 4.590244748415599, 'MSE - std': 0.0, 'R2 - mean': 0.5813848466879818, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.08255
Epoch 1, Val Loss: 7.68883
Epoch 2, Val Loss: 6.62297
Epoch 3, Val Loss: 6.54292
Epoch 4, Val Loss: 6.40172
Epoch 5, Val Loss: 5.96926
Epoch 6, Val Loss: 5.63027
Epoch 7, Val Loss: 5.62484
Epoch 8, Val Loss: 5.38745
Epoch 9, Val Loss: 5.33661
Epoch 10, Val Loss: 5.38746
Epoch 11, Val Loss: 5.39654
Epoch 12, Val Loss: 5.64415
Epoch 13, Val Loss: 5.19707
Epoch 14, Val Loss: 5.39669
Epoch 15, Val Loss: 5.41365
Epoch 16, Val Loss: 5.15553
Epoch 17, Val Loss: 5.18664
Epoch 18, Val Loss: 5.32758
Epoch 19, Val Loss: 5.44716
Epoch 20, Val Loss: 5.18527
Epoch 21, Val Loss: 5.34276
Epoch 22, Val Loss: 5.23290
Epoch 23, Val Loss: 5.02482
Epoch 24, Val Loss: 5.16412
Epoch 25, Val Loss: 5.27935
Epoch 26, Val Loss: 5.61277
Epoch 27, Val Loss: 4.98457
Epoch 28, Val Loss: 5.28835
Epoch 29, Val Loss: 5.21644
Epoch 30, Val Loss: 4.94858
Epoch 31, Val Loss: 4.92655
Epoch 32, Val Loss: 5.36636
Epoch 33, Val Loss: 4.98556
Epoch 34, Val Loss: 4.96204
Epoch 35, Val Loss: 5.10892
Epoch 36, Val Loss: 5.39710
Epoch 37, Val Loss: 4.93923
Epoch 38, Val Loss: 4.88780
Epoch 39, Val Loss: 5.01704
Epoch 40, Val Loss: 4.96121
Epoch 41, Val Loss: 4.81444
Epoch 42, Val Loss: 4.97881
Epoch 43, Val Loss: 5.28601
Epoch 44, Val Loss: 5.55067
Epoch 45, Val Loss: 4.77329
Epoch 46, Val Loss: 4.74009
Epoch 47, Val Loss: 4.66536
Epoch 48, Val Loss: 4.74363
Epoch 49, Val Loss: 4.70224
Epoch 50, Val Loss: 4.71558
Epoch 51, Val Loss: 4.71091
Epoch 52, Val Loss: 4.61900
Epoch 53, Val Loss: 4.62896
Epoch 54, Val Loss: 4.70305
Epoch 55, Val Loss: 4.77879
Epoch 56, Val Loss: 4.57499
Epoch 57, Val Loss: 4.63959
Epoch 58, Val Loss: 4.53459
Epoch 59, Val Loss: 4.68559
Epoch 60, Val Loss: 4.86136
Epoch 61, Val Loss: 5.44989
Epoch 62, Val Loss: 4.86019
Epoch 63, Val Loss: 4.51677
Epoch 64, Val Loss: 4.45436
Epoch 65, Val Loss: 4.45618
Epoch 66, Val Loss: 4.66446
Epoch 67, Val Loss: 4.52307
Epoch 68, Val Loss: 4.72180
Epoch 69, Val Loss: 4.96032
Epoch 70, Val Loss: 4.61672
Epoch 71, Val Loss: 4.47549
Epoch 72, Val Loss: 4.36427
Epoch 73, Val Loss: 4.44729
Epoch 74, Val Loss: 4.43629
Epoch 75, Val Loss: 4.45071
Epoch 76, Val Loss: 4.49783
Epoch 77, Val Loss: 4.66444
Epoch 78, Val Loss: 4.73247
Epoch 79, Val Loss: 4.32362
Epoch 80, Val Loss: 4.35063
Epoch 81, Val Loss: 4.39526
Epoch 82, Val Loss: 4.39821
Epoch 83, Val Loss: 4.36704
Epoch 84, Val Loss: 4.63474
Epoch 85, Val Loss: 4.64848
Epoch 86, Val Loss: 4.44954
Epoch 87, Val Loss: 4.35876
Epoch 88, Val Loss: 4.82643
Epoch 89, Val Loss: 4.29900
Epoch 90, Val Loss: 4.37384
Epoch 91, Val Loss: 4.28364
Epoch 92, Val Loss: 4.55949
Epoch 93, Val Loss: 4.25968
Epoch 94, Val Loss: 4.32288
Epoch 95, Val Loss: 4.68428
Epoch 96, Val Loss: 4.28379
Epoch 97, Val Loss: 4.56882
Epoch 98, Val Loss: 4.49109
Epoch 99, Val Loss: 4.29145
DID NOT SAVE RESULTS
{'MSE - mean': 4.545730647252125, 'MSE - std': 0.044514101163473985, 'R2 - mean': 0.5507853150104245, 'R2 - std': 0.030599531677557412} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.50193
Epoch 1, Val Loss: 10.01120
Epoch 2, Val Loss: 6.49413
Epoch 3, Val Loss: 6.27296
Epoch 4, Val Loss: 6.19849
Epoch 5, Val Loss: 6.13620
Epoch 6, Val Loss: 5.92844
Epoch 7, Val Loss: 5.86333
Epoch 8, Val Loss: 5.87811
Epoch 9, Val Loss: 5.85465
Epoch 10, Val Loss: 5.78510
Epoch 11, Val Loss: 6.07971
Epoch 12, Val Loss: 5.64020
Epoch 13, Val Loss: 5.68836
Epoch 14, Val Loss: 5.49433
Epoch 15, Val Loss: 5.65996
Epoch 16, Val Loss: 5.60530
Epoch 17, Val Loss: 5.42325
Epoch 18, Val Loss: 5.40474
Epoch 19, Val Loss: 5.27556
Epoch 20, Val Loss: 5.30566
Epoch 21, Val Loss: 5.19994
Epoch 22, Val Loss: 5.21061
Epoch 23, Val Loss: 5.09461
Epoch 24, Val Loss: 5.27724
Epoch 25, Val Loss: 5.03191
Epoch 26, Val Loss: 5.29701
Epoch 27, Val Loss: 4.99248
Epoch 28, Val Loss: 5.03162
Epoch 29, Val Loss: 5.12801
Epoch 30, Val Loss: 4.99238
Epoch 31, Val Loss: 4.91806
Epoch 32, Val Loss: 4.88854
Epoch 33, Val Loss: 5.02182
Epoch 34, Val Loss: 4.89999
Epoch 35, Val Loss: 4.98554
Epoch 36, Val Loss: 4.79865
Epoch 37, Val Loss: 4.80740
Epoch 38, Val Loss: 4.75830
Epoch 39, Val Loss: 4.85229
Epoch 40, Val Loss: 4.70482
Epoch 41, Val Loss: 4.72624
Epoch 42, Val Loss: 4.56192
Epoch 43, Val Loss: 4.58536
Epoch 44, Val Loss: 4.68653
Epoch 45, Val Loss: 4.63920
Epoch 46, Val Loss: 5.48487
Epoch 47, Val Loss: 4.56300
Epoch 48, Val Loss: 4.53761
Epoch 49, Val Loss: 5.30818
Epoch 50, Val Loss: 4.46182
Epoch 51, Val Loss: 4.48392
Epoch 52, Val Loss: 4.72980
Epoch 53, Val Loss: 4.60831
Epoch 54, Val Loss: 4.70660
Epoch 55, Val Loss: 5.07939
Epoch 56, Val Loss: 4.60219
Epoch 57, Val Loss: 4.49542
Epoch 58, Val Loss: 4.52898
Epoch 59, Val Loss: 4.56427
Epoch 60, Val Loss: 4.87709
Epoch 61, Val Loss: 4.38549
Epoch 62, Val Loss: 4.45211
Epoch 63, Val Loss: 4.61531
Epoch 64, Val Loss: 4.44869
Epoch 65, Val Loss: 4.37918
Epoch 66, Val Loss: 4.56370
Epoch 67, Val Loss: 4.43105
Epoch 68, Val Loss: 4.44746
Epoch 69, Val Loss: 4.43701
Epoch 70, Val Loss: 5.00483
Epoch 71, Val Loss: 4.53087
Epoch 72, Val Loss: 4.39595
Epoch 73, Val Loss: 4.52004
Epoch 74, Val Loss: 4.58394
Epoch 75, Val Loss: 4.57864
Epoch 76, Val Loss: 4.58549
Epoch 77, Val Loss: 4.39520
Epoch 78, Val Loss: 4.63363
Epoch 79, Val Loss: 4.37990
Epoch 80, Val Loss: 4.59157
Epoch 81, Val Loss: 4.39147
Epoch 82, Val Loss: 4.37890
Epoch 83, Val Loss: 4.40990
Epoch 84, Val Loss: 4.73118
Epoch 85, Val Loss: 4.59019
Epoch 86, Val Loss: 4.70197
Epoch 87, Val Loss: 4.41523
Epoch 88, Val Loss: 4.42153
Epoch 89, Val Loss: 4.52566
Epoch 90, Val Loss: 4.89200
Epoch 91, Val Loss: 4.36485
Epoch 92, Val Loss: 4.81288
Epoch 93, Val Loss: 4.44302
Epoch 94, Val Loss: 4.38878
Epoch 95, Val Loss: 4.55792
Epoch 96, Val Loss: 4.48681
Epoch 97, Val Loss: 4.74366
Epoch 98, Val Loss: 4.53907
Epoch 99, Val Loss: 4.80726
DID NOT SAVE RESULTS
{'MSE - mean': 4.499169999974608, 'MSE - std': 0.07521164283582663, 'R2 - mean': 0.556007064660498, 'R2 - std': 0.02605291214829247} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.99377
Epoch 1, Val Loss: 15.56585
Epoch 2, Val Loss: 6.50898
Epoch 3, Val Loss: 6.00400
Epoch 4, Val Loss: 5.40058
Epoch 5, Val Loss: 5.23162
Epoch 6, Val Loss: 5.14157
Epoch 7, Val Loss: 4.99137
Epoch 8, Val Loss: 4.92443
Epoch 9, Val Loss: 5.11676
Epoch 10, Val Loss: 4.83525
Epoch 11, Val Loss: 4.79693
Epoch 12, Val Loss: 4.79240
Epoch 13, Val Loss: 4.82731
Epoch 14, Val Loss: 4.82866
Epoch 15, Val Loss: 4.69354
Epoch 16, Val Loss: 4.83176
Epoch 17, Val Loss: 4.75488
Epoch 18, Val Loss: 4.60896
Epoch 19, Val Loss: 4.59930
Epoch 20, Val Loss: 4.53205
Epoch 21, Val Loss: 4.66113
Epoch 22, Val Loss: 4.54149
Epoch 23, Val Loss: 4.40501
Epoch 24, Val Loss: 4.43120
Epoch 25, Val Loss: 4.38566
Epoch 26, Val Loss: 4.38359
Epoch 27, Val Loss: 4.41611
Epoch 28, Val Loss: 4.41269
Epoch 29, Val Loss: 4.70512
Epoch 30, Val Loss: 4.39467
Epoch 31, Val Loss: 4.35072
Epoch 32, Val Loss: 4.48203
Epoch 33, Val Loss: 4.29562
Epoch 34, Val Loss: 4.40078
Epoch 35, Val Loss: 4.56227
Epoch 36, Val Loss: 4.25238
Epoch 37, Val Loss: 4.35816
Epoch 38, Val Loss: 4.90245
Epoch 39, Val Loss: 4.28170
Epoch 40, Val Loss: 4.25362
Epoch 41, Val Loss: 4.49486
Epoch 42, Val Loss: 4.43607
Epoch 43, Val Loss: 4.87221
Epoch 44, Val Loss: 4.23243
Epoch 45, Val Loss: 4.34714
Epoch 46, Val Loss: 4.24896
Epoch 47, Val Loss: 4.15186
Epoch 48, Val Loss: 4.15035
Epoch 49, Val Loss: 4.21042
Epoch 50, Val Loss: 4.14358
Epoch 51, Val Loss: 4.28743
Epoch 52, Val Loss: 4.22926
Epoch 53, Val Loss: 4.18829
Epoch 54, Val Loss: 4.10216
Epoch 55, Val Loss: 4.26654
Epoch 56, Val Loss: 4.27821
Epoch 57, Val Loss: 4.12144
Epoch 58, Val Loss: 4.03089
Epoch 59, Val Loss: 4.12557
Epoch 60, Val Loss: 4.10509
Epoch 61, Val Loss: 4.07596
Epoch 62, Val Loss: 4.18663
Epoch 63, Val Loss: 4.04089
Epoch 64, Val Loss: 4.04427
Epoch 65, Val Loss: 4.01797
Epoch 66, Val Loss: 4.00858
Epoch 67, Val Loss: 4.07146
Epoch 68, Val Loss: 4.03462
Epoch 69, Val Loss: 3.95209
Epoch 70, Val Loss: 4.01095
Epoch 71, Val Loss: 4.28126
Epoch 72, Val Loss: 4.29436
Epoch 73, Val Loss: 4.18441
Epoch 74, Val Loss: 4.01264
Epoch 75, Val Loss: 3.97130
Epoch 76, Val Loss: 3.92638
Epoch 77, Val Loss: 3.99072
Epoch 78, Val Loss: 3.96861
Epoch 79, Val Loss: 4.00828
Epoch 80, Val Loss: 4.01515
Epoch 81, Val Loss: 3.93169
Epoch 82, Val Loss: 4.02462
Epoch 83, Val Loss: 4.07987
Epoch 84, Val Loss: 4.08340
Epoch 85, Val Loss: 4.00943
Epoch 86, Val Loss: 3.92656
Epoch 87, Val Loss: 4.14187
Epoch 88, Val Loss: 3.97683
Epoch 89, Val Loss: 3.93580
Epoch 90, Val Loss: 4.17562
Epoch 91, Val Loss: 4.11373
Epoch 92, Val Loss: 3.98987
Epoch 93, Val Loss: 4.04130
Epoch 94, Val Loss: 3.97111
Epoch 95, Val Loss: 4.11274
Epoch 96, Val Loss: 4.20153
Epoch 97, Val Loss: 4.09079
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.432125894479309, 'MSE - std': 0.1331440184857817, 'R2 - mean': 0.5539103023929379, 'R2 - std': 0.022852897181210394} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.58856
Epoch 1, Val Loss: 14.56118
Epoch 2, Val Loss: 9.50565
Epoch 3, Val Loss: 8.63394
Epoch 4, Val Loss: 8.04652
Epoch 5, Val Loss: 7.71570
Epoch 6, Val Loss: 7.54702
Epoch 7, Val Loss: 7.41449
Epoch 8, Val Loss: 7.31995
Epoch 9, Val Loss: 7.31974
Epoch 10, Val Loss: 7.53951
Epoch 11, Val Loss: 7.11449
Epoch 12, Val Loss: 7.33844
Epoch 13, Val Loss: 7.05318
Epoch 14, Val Loss: 7.06574
Epoch 15, Val Loss: 7.13761
Epoch 16, Val Loss: 7.07671
Epoch 17, Val Loss: 6.84752
Epoch 18, Val Loss: 6.79583
Epoch 19, Val Loss: 6.91948
Epoch 20, Val Loss: 6.77938
Epoch 21, Val Loss: 6.94502
Epoch 22, Val Loss: 6.77720
Epoch 23, Val Loss: 7.28510
Epoch 24, Val Loss: 6.73164
Epoch 25, Val Loss: 6.71402
Epoch 26, Val Loss: 6.56905
Epoch 27, Val Loss: 6.60672
Epoch 28, Val Loss: 6.62201
Epoch 29, Val Loss: 6.55902
Epoch 30, Val Loss: 6.53060
Epoch 31, Val Loss: 6.57632
Epoch 32, Val Loss: 6.57920
Epoch 33, Val Loss: 6.53337
Epoch 34, Val Loss: 6.39115
Epoch 35, Val Loss: 7.27164
Epoch 36, Val Loss: 6.37743
Epoch 37, Val Loss: 6.43183
Epoch 38, Val Loss: 6.29398
Epoch 39, Val Loss: 6.45057
Epoch 40, Val Loss: 6.32390
Epoch 41, Val Loss: 6.60125
Epoch 42, Val Loss: 6.47399
Epoch 43, Val Loss: 6.29487
Epoch 44, Val Loss: 6.29107
Epoch 45, Val Loss: 6.56855
Epoch 46, Val Loss: 6.20970
Epoch 47, Val Loss: 6.52575
Epoch 48, Val Loss: 6.34346
Epoch 49, Val Loss: 6.64627
Epoch 50, Val Loss: 6.67006
Epoch 51, Val Loss: 6.14210
Epoch 52, Val Loss: 6.46005
Epoch 53, Val Loss: 6.10176
Epoch 54, Val Loss: 6.10182
Epoch 55, Val Loss: 6.27282
Epoch 56, Val Loss: 6.15752
Epoch 57, Val Loss: 6.16595
Epoch 58, Val Loss: 6.41695
Epoch 59, Val Loss: 5.98868
Epoch 60, Val Loss: 6.12767
Epoch 61, Val Loss: 6.11475
Epoch 62, Val Loss: 6.01223
Epoch 63, Val Loss: 6.24628
Epoch 64, Val Loss: 5.97438
Epoch 65, Val Loss: 6.03856
Epoch 66, Val Loss: 6.08325
Epoch 67, Val Loss: 5.96121
Epoch 68, Val Loss: 6.15301
Epoch 69, Val Loss: 5.86303
Epoch 70, Val Loss: 5.88956
Epoch 71, Val Loss: 6.31004
Epoch 72, Val Loss: 5.91508
Epoch 73, Val Loss: 5.83030
Epoch 74, Val Loss: 5.99303
Epoch 75, Val Loss: 6.09453
Epoch 76, Val Loss: 6.03439
Epoch 77, Val Loss: 7.11067
Epoch 78, Val Loss: 5.91082
Epoch 79, Val Loss: 6.19144
Epoch 80, Val Loss: 6.15745
Epoch 81, Val Loss: 6.10557
Epoch 82, Val Loss: 6.13272
Epoch 83, Val Loss: 5.95287
Epoch 84, Val Loss: 5.94501
Epoch 85, Val Loss: 6.10127
Epoch 86, Val Loss: 6.01815
Epoch 87, Val Loss: 5.82283
Epoch 88, Val Loss: 6.40952
Epoch 89, Val Loss: 6.26993
Epoch 90, Val Loss: 6.20812
Epoch 91, Val Loss: 5.83556
Epoch 92, Val Loss: 5.83955
Epoch 93, Val Loss: 5.83736
Epoch 94, Val Loss: 5.84527
Epoch 95, Val Loss: 5.82755
Epoch 96, Val Loss: 5.77927
Epoch 97, Val Loss: 6.19809
Epoch 98, Val Loss: 5.78396
Epoch 99, Val Loss: 5.97018
DID NOT SAVE RESULTS
{'MSE - mean': 4.690708383904524, 'MSE - std': 0.5306990475553915, 'R2 - mean': 0.5484364684889906, 'R2 - std': 0.02318739653544547} 
 

Results After CV: {'MSE - mean': 4.690708383904524, 'MSE - std': 0.5306990475553915, 'R2 - mean': 0.5484364684889906, 'R2 - std': 0.02318739653544547}
Train time: 32.97253205039924
Inference time: 0.04643820880046405
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 42 finished with value: 4.690708383904524 and parameters: {'p_m': 0.8472823709120125, 'alpha': 1.2241841113697625, 'K': 3, 'beta': 3.090741761856316}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.85839
Epoch 1, Val Loss: 12.79444
Epoch 2, Val Loss: 7.42482
Epoch 3, Val Loss: 7.02620
Epoch 4, Val Loss: 7.01016
Epoch 5, Val Loss: 6.63837
Epoch 6, Val Loss: 6.54483
Epoch 7, Val Loss: 6.37871
Epoch 8, Val Loss: 6.35786
Epoch 9, Val Loss: 6.61943
Epoch 10, Val Loss: 6.28129
Epoch 11, Val Loss: 6.19269
Epoch 12, Val Loss: 5.96751
Epoch 13, Val Loss: 6.49660
Epoch 14, Val Loss: 6.03485
Epoch 15, Val Loss: 5.90200
Epoch 16, Val Loss: 6.06495
Epoch 17, Val Loss: 5.88671
Epoch 18, Val Loss: 5.97417
Epoch 19, Val Loss: 5.83801
Epoch 20, Val Loss: 6.14425
Epoch 21, Val Loss: 5.77445
Epoch 22, Val Loss: 5.69883
Epoch 23, Val Loss: 5.66844
Epoch 24, Val Loss: 5.78693
Epoch 25, Val Loss: 5.78156
Epoch 26, Val Loss: 5.61906
Epoch 27, Val Loss: 5.59110
Epoch 28, Val Loss: 5.68138
Epoch 29, Val Loss: 5.59467
Epoch 30, Val Loss: 5.55730
Epoch 31, Val Loss: 5.47551
Epoch 32, Val Loss: 5.42166
Epoch 33, Val Loss: 5.59221
Epoch 34, Val Loss: 5.50708
Epoch 35, Val Loss: 5.44339
Epoch 36, Val Loss: 5.44284
Epoch 37, Val Loss: 5.40794
Epoch 38, Val Loss: 5.44052
Epoch 39, Val Loss: 5.29537
Epoch 40, Val Loss: 5.36356
Epoch 41, Val Loss: 6.07698
Epoch 42, Val Loss: 5.25186
Epoch 43, Val Loss: 5.41969
Epoch 44, Val Loss: 5.18192
Epoch 45, Val Loss: 5.63087
Epoch 46, Val Loss: 5.44883
Epoch 47, Val Loss: 5.30655
Epoch 48, Val Loss: 5.47668
Epoch 49, Val Loss: 5.24662
Epoch 50, Val Loss: 5.22242
Epoch 51, Val Loss: 5.37381
Epoch 52, Val Loss: 5.20540
Epoch 53, Val Loss: 5.51386
Epoch 54, Val Loss: 5.14321
Epoch 55, Val Loss: 5.34429
Epoch 56, Val Loss: 5.13882
Epoch 57, Val Loss: 5.49978
Epoch 58, Val Loss: 5.08504
Epoch 59, Val Loss: 5.14239
Epoch 60, Val Loss: 5.21647
Epoch 61, Val Loss: 5.13762
Epoch 62, Val Loss: 5.52448
Epoch 63, Val Loss: 5.17536
Epoch 64, Val Loss: 5.06462
Epoch 65, Val Loss: 5.04932
Epoch 66, Val Loss: 5.36386
Epoch 67, Val Loss: 5.12463
Epoch 68, Val Loss: 5.12435
Epoch 69, Val Loss: 4.92960
Epoch 70, Val Loss: 5.28690
Epoch 71, Val Loss: 5.05672
Epoch 72, Val Loss: 5.29705
Epoch 73, Val Loss: 5.24622
Epoch 74, Val Loss: 5.15221
Epoch 75, Val Loss: 4.96216
Epoch 76, Val Loss: 5.16556
Epoch 77, Val Loss: 5.33249
Epoch 78, Val Loss: 5.01789
Epoch 79, Val Loss: 4.93641
Epoch 80, Val Loss: 4.89913
Epoch 81, Val Loss: 4.84727
Epoch 82, Val Loss: 4.93120
Epoch 83, Val Loss: 5.05661
Epoch 84, Val Loss: 4.84413
Epoch 85, Val Loss: 5.10187
Epoch 86, Val Loss: 5.12530
Epoch 87, Val Loss: 5.41506
Epoch 88, Val Loss: 4.96834
Epoch 89, Val Loss: 5.03513
Epoch 90, Val Loss: 5.03934
Epoch 91, Val Loss: 4.98779
Epoch 92, Val Loss: 5.05966
Epoch 93, Val Loss: 4.95989
Epoch 94, Val Loss: 4.94554
Epoch 95, Val Loss: 4.93320
Epoch 96, Val Loss: 4.86930
Epoch 97, Val Loss: 4.80841
Epoch 98, Val Loss: 4.94768
Epoch 99, Val Loss: 4.89377
DID NOT SAVE RESULTS
{'MSE - mean': 4.993564957771604, 'MSE - std': 0.0, 'R2 - mean': 0.5446033763030582, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.85861
Epoch 1, Val Loss: 14.16014
Epoch 2, Val Loss: 6.06107
Epoch 3, Val Loss: 5.47658
Epoch 4, Val Loss: 5.85034
Epoch 5, Val Loss: 5.46934
Epoch 6, Val Loss: 5.40717
Epoch 7, Val Loss: 5.28847
Epoch 8, Val Loss: 5.25875
Epoch 9, Val Loss: 5.30476
Epoch 10, Val Loss: 5.50130
Epoch 11, Val Loss: 5.66108
Epoch 12, Val Loss: 5.66876
Epoch 13, Val Loss: 5.19687
Epoch 14, Val Loss: 5.15620
Epoch 15, Val Loss: 5.68390
Epoch 16, Val Loss: 5.26868
Epoch 17, Val Loss: 5.08261
Epoch 18, Val Loss: 5.57413
Epoch 19, Val Loss: 5.25711
Epoch 20, Val Loss: 5.29015
Epoch 21, Val Loss: 5.18101
Epoch 22, Val Loss: 5.25411
Epoch 23, Val Loss: 5.25610
Epoch 24, Val Loss: 5.06837
Epoch 25, Val Loss: 4.88596
Epoch 26, Val Loss: 5.04926
Epoch 27, Val Loss: 4.98128
Epoch 28, Val Loss: 5.02155
Epoch 29, Val Loss: 5.77035
Epoch 30, Val Loss: 4.87572
Epoch 31, Val Loss: 5.10590
Epoch 32, Val Loss: 4.81252
Epoch 33, Val Loss: 4.87673
Epoch 34, Val Loss: 5.43772
Epoch 35, Val Loss: 4.92083
Epoch 36, Val Loss: 4.84410
Epoch 37, Val Loss: 5.78975
Epoch 38, Val Loss: 5.48798
Epoch 39, Val Loss: 4.82956
Epoch 40, Val Loss: 5.03442
Epoch 41, Val Loss: 4.82453
Epoch 42, Val Loss: 5.55565
Epoch 43, Val Loss: 5.39541
Epoch 44, Val Loss: 4.66524
Epoch 45, Val Loss: 4.68723
Epoch 46, Val Loss: 4.68146
Epoch 47, Val Loss: 4.66086
Epoch 48, Val Loss: 4.89247
Epoch 49, Val Loss: 4.82219
Epoch 50, Val Loss: 5.19048
Epoch 51, Val Loss: 4.66244
Epoch 52, Val Loss: 4.59612
Epoch 53, Val Loss: 4.77691
Epoch 54, Val Loss: 4.95265
Epoch 55, Val Loss: 4.58235
Epoch 56, Val Loss: 4.58274
Epoch 57, Val Loss: 4.43825
Epoch 58, Val Loss: 4.52329
Epoch 59, Val Loss: 4.70149
Epoch 60, Val Loss: 4.48969
Epoch 61, Val Loss: 4.64199
Epoch 62, Val Loss: 4.56066
Epoch 63, Val Loss: 4.46590
Epoch 64, Val Loss: 4.46761
Epoch 65, Val Loss: 4.38307
Epoch 66, Val Loss: 4.47089
Epoch 67, Val Loss: 4.43772
Epoch 68, Val Loss: 4.38379
Epoch 69, Val Loss: 4.54186
Epoch 70, Val Loss: 4.51284
Epoch 71, Val Loss: 4.42746
Epoch 72, Val Loss: 4.46498
Epoch 73, Val Loss: 4.36773
Epoch 74, Val Loss: 4.73551
Epoch 75, Val Loss: 4.25870
Epoch 76, Val Loss: 4.30929
Epoch 77, Val Loss: 4.45331
Epoch 78, Val Loss: 4.26361
Epoch 79, Val Loss: 4.33305
Epoch 80, Val Loss: 4.59216
Epoch 81, Val Loss: 4.35609
Epoch 82, Val Loss: 4.31305
Epoch 83, Val Loss: 4.96199
Epoch 84, Val Loss: 4.68730
Epoch 85, Val Loss: 4.34793
Epoch 86, Val Loss: 4.30160
Epoch 87, Val Loss: 4.26148
Epoch 88, Val Loss: 4.35645
Epoch 89, Val Loss: 4.30255
Epoch 90, Val Loss: 4.25210
Epoch 91, Val Loss: 4.31941
Epoch 92, Val Loss: 4.77897
Epoch 93, Val Loss: 4.26486
Epoch 94, Val Loss: 4.38837
Epoch 95, Val Loss: 4.18811
Epoch 96, Val Loss: 4.25183
Epoch 97, Val Loss: 4.43010
Epoch 98, Val Loss: 4.44118
Epoch 99, Val Loss: 4.29531
DID NOT SAVE RESULTS
{'MSE - mean': 4.66941299369081, 'MSE - std': 0.3241519640807944, 'R2 - mean': 0.5407067408979642, 'R2 - std': 0.0038966354050939955} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.04749
Epoch 1, Val Loss: 9.60060
Epoch 2, Val Loss: 7.18844
Epoch 3, Val Loss: 6.52685
Epoch 4, Val Loss: 6.58354
Epoch 5, Val Loss: 6.53707
Epoch 6, Val Loss: 6.52263
Epoch 7, Val Loss: 6.61973
Epoch 8, Val Loss: 6.40206
Epoch 9, Val Loss: 6.28847
Epoch 10, Val Loss: 6.24865
Epoch 11, Val Loss: 6.37067
Epoch 12, Val Loss: 6.37059
Epoch 13, Val Loss: 6.22982
Epoch 14, Val Loss: 6.13104
Epoch 15, Val Loss: 6.27258
Epoch 16, Val Loss: 6.26327
Epoch 17, Val Loss: 6.20077
Epoch 18, Val Loss: 6.16072
Epoch 19, Val Loss: 6.16835
Epoch 20, Val Loss: 6.37424
Epoch 21, Val Loss: 6.17197
Epoch 22, Val Loss: 6.23165
Epoch 23, Val Loss: 6.08695
Epoch 24, Val Loss: 6.12201
Epoch 25, Val Loss: 6.01478
Epoch 26, Val Loss: 6.07028
Epoch 27, Val Loss: 6.10756
Epoch 28, Val Loss: 6.34812
Epoch 29, Val Loss: 6.14508
Epoch 30, Val Loss: 6.12954
Epoch 31, Val Loss: 6.07265
Epoch 32, Val Loss: 5.97743
Epoch 33, Val Loss: 5.96649
Epoch 34, Val Loss: 6.32659
Epoch 35, Val Loss: 5.93478
Epoch 36, Val Loss: 5.91509
Epoch 37, Val Loss: 6.11160
Epoch 38, Val Loss: 6.04146
Epoch 39, Val Loss: 5.88905
Epoch 40, Val Loss: 6.05127
Epoch 41, Val Loss: 5.98421
Epoch 42, Val Loss: 5.91172
Epoch 43, Val Loss: 5.87645
Epoch 44, Val Loss: 6.00339
Epoch 45, Val Loss: 5.70532
Epoch 46, Val Loss: 5.72417
Epoch 47, Val Loss: 5.86182
Epoch 48, Val Loss: 5.61058
Epoch 49, Val Loss: 5.58599
Epoch 50, Val Loss: 5.74760
Epoch 51, Val Loss: 5.68098
Epoch 52, Val Loss: 5.53447
Epoch 53, Val Loss: 5.60340
Epoch 54, Val Loss: 5.50548
Epoch 55, Val Loss: 5.44826
Epoch 56, Val Loss: 5.49280
Epoch 57, Val Loss: 5.35752
Epoch 58, Val Loss: 5.57882
Epoch 59, Val Loss: 5.82930
Epoch 60, Val Loss: 5.47259
Epoch 61, Val Loss: 5.28491
Epoch 62, Val Loss: 5.38171
Epoch 63, Val Loss: 5.31844
Epoch 64, Val Loss: 5.43033
Epoch 65, Val Loss: 5.19067
Epoch 66, Val Loss: 5.39999
Epoch 67, Val Loss: 5.08653
Epoch 68, Val Loss: 5.32145
Epoch 69, Val Loss: 5.20068
Epoch 70, Val Loss: 5.34122
Epoch 71, Val Loss: 4.98336
Epoch 72, Val Loss: 5.14196
Epoch 73, Val Loss: 5.08839
Epoch 74, Val Loss: 5.07629
Epoch 75, Val Loss: 5.03560
Epoch 76, Val Loss: 5.05972
Epoch 77, Val Loss: 5.49531
Epoch 78, Val Loss: 5.01164
Epoch 79, Val Loss: 4.98816
Epoch 80, Val Loss: 5.15891
Epoch 81, Val Loss: 4.96352
Epoch 82, Val Loss: 5.02779
Epoch 83, Val Loss: 5.47293
Epoch 84, Val Loss: 4.74840
Epoch 85, Val Loss: 5.19452
Epoch 86, Val Loss: 4.82058
Epoch 87, Val Loss: 4.84697
Epoch 88, Val Loss: 4.73910
Epoch 89, Val Loss: 4.90192
Epoch 90, Val Loss: 5.16494
Epoch 91, Val Loss: 4.80180
Epoch 92, Val Loss: 4.83649
Epoch 93, Val Loss: 4.72284
Epoch 94, Val Loss: 4.54673
Epoch 95, Val Loss: 4.66287
Epoch 96, Val Loss: 4.79607
Epoch 97, Val Loss: 4.73197
Epoch 98, Val Loss: 4.70142
Epoch 99, Val Loss: 4.58488
DID NOT SAVE RESULTS
{'MSE - mean': 4.6699615716014025, 'MSE - std': 0.2646701074049335, 'R2 - mean': 0.5405958019437863, 'R2 - std': 0.0031854554708230015} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.14599
Epoch 1, Val Loss: 14.22230
Epoch 2, Val Loss: 6.15852
Epoch 3, Val Loss: 6.55458
Epoch 4, Val Loss: 5.72976
Epoch 5, Val Loss: 5.48819
Epoch 6, Val Loss: 5.61024
Epoch 7, Val Loss: 5.42483
Epoch 8, Val Loss: 5.60431
Epoch 9, Val Loss: 5.21401
Epoch 10, Val Loss: 5.15661
Epoch 11, Val Loss: 5.02876
Epoch 12, Val Loss: 5.02281
Epoch 13, Val Loss: 4.98038
Epoch 14, Val Loss: 4.98455
Epoch 15, Val Loss: 5.09040
Epoch 16, Val Loss: 4.93997
Epoch 17, Val Loss: 4.89528
Epoch 18, Val Loss: 4.83878
Epoch 19, Val Loss: 5.11808
Epoch 20, Val Loss: 4.91856
Epoch 21, Val Loss: 4.97145
Epoch 22, Val Loss: 4.76328
Epoch 23, Val Loss: 4.80887
Epoch 24, Val Loss: 4.77214
Epoch 25, Val Loss: 4.72197
Epoch 26, Val Loss: 4.61283
Epoch 27, Val Loss: 4.58827
Epoch 28, Val Loss: 5.06724
Epoch 29, Val Loss: 4.72432
Epoch 30, Val Loss: 4.67860
Epoch 31, Val Loss: 4.65748
Epoch 32, Val Loss: 4.52846
Epoch 33, Val Loss: 4.54744
Epoch 34, Val Loss: 4.52401
Epoch 35, Val Loss: 4.72235
Epoch 36, Val Loss: 4.50854
Epoch 37, Val Loss: 4.48112
Epoch 38, Val Loss: 4.82877
Epoch 39, Val Loss: 4.51529
Epoch 40, Val Loss: 4.45546
Epoch 41, Val Loss: 4.63547
Epoch 42, Val Loss: 4.45661
Epoch 43, Val Loss: 4.38399
Epoch 44, Val Loss: 4.38754
Epoch 45, Val Loss: 4.45749
Epoch 46, Val Loss: 4.32108
Epoch 47, Val Loss: 4.33635
Epoch 48, Val Loss: 4.44109
Epoch 49, Val Loss: 4.29728
Epoch 50, Val Loss: 4.26881
Epoch 51, Val Loss: 4.30575
Epoch 52, Val Loss: 4.24444
Epoch 53, Val Loss: 4.34870
Epoch 54, Val Loss: 4.47114
Epoch 55, Val Loss: 4.34071
Epoch 56, Val Loss: 4.28305
Epoch 57, Val Loss: 4.15098
Epoch 58, Val Loss: 4.36885
Epoch 59, Val Loss: 4.21535
Epoch 60, Val Loss: 4.26498
Epoch 61, Val Loss: 4.44118
Epoch 62, Val Loss: 4.28971
Epoch 63, Val Loss: 4.37203
Epoch 64, Val Loss: 4.13605
Epoch 65, Val Loss: 4.10143
Epoch 66, Val Loss: 4.28842
Epoch 67, Val Loss: 4.17844
Epoch 68, Val Loss: 4.38278
Epoch 69, Val Loss: 4.05599
Epoch 70, Val Loss: 4.12112
Epoch 71, Val Loss: 4.36272
Epoch 72, Val Loss: 4.25074
Epoch 73, Val Loss: 4.11326
Epoch 74, Val Loss: 4.33364
Epoch 75, Val Loss: 4.22494
Epoch 76, Val Loss: 4.08009
Epoch 77, Val Loss: 4.02583
Epoch 78, Val Loss: 4.01393
Epoch 79, Val Loss: 4.07863
Epoch 80, Val Loss: 4.10007
Epoch 81, Val Loss: 4.07787
Epoch 82, Val Loss: 4.03539
Epoch 83, Val Loss: 4.06067
Epoch 84, Val Loss: 4.00626
Epoch 85, Val Loss: 4.08866
Epoch 86, Val Loss: 4.24795
Epoch 87, Val Loss: 4.00110
Epoch 88, Val Loss: 4.06473
Epoch 89, Val Loss: 4.04041
Epoch 90, Val Loss: 3.99593
Epoch 91, Val Loss: 3.91924
Epoch 92, Val Loss: 4.15274
Epoch 93, Val Loss: 4.46059
Epoch 94, Val Loss: 3.97955
Epoch 95, Val Loss: 3.99159
Epoch 96, Val Loss: 3.97135
Epoch 97, Val Loss: 4.14336
Epoch 98, Val Loss: 4.05628
Epoch 99, Val Loss: 4.05201
DID NOT SAVE RESULTS
{'MSE - mean': 4.549654207571061, 'MSE - std': 0.3097729569137554, 'R2 - mean': 0.5434815096198525, 'R2 - std': 0.005708964117295622} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.94538
Epoch 1, Val Loss: 14.62039
Epoch 2, Val Loss: 9.31023
Epoch 3, Val Loss: 8.14009
Epoch 4, Val Loss: 8.03753
Epoch 5, Val Loss: 7.67741
Epoch 6, Val Loss: 7.69362
Epoch 7, Val Loss: 7.70546
Epoch 8, Val Loss: 7.85305
Epoch 9, Val Loss: 7.71607
Epoch 10, Val Loss: 7.73660
Epoch 11, Val Loss: 7.61600
Epoch 12, Val Loss: 7.62621
Epoch 13, Val Loss: 7.58958
Epoch 14, Val Loss: 7.93439
Epoch 15, Val Loss: 7.76953
Epoch 16, Val Loss: 7.60778
Epoch 17, Val Loss: 7.73543
Epoch 18, Val Loss: 7.61457
Epoch 19, Val Loss: 7.89975
Epoch 20, Val Loss: 7.44628
Epoch 21, Val Loss: 7.76055
Epoch 22, Val Loss: 7.43751
Epoch 23, Val Loss: 7.81913
Epoch 24, Val Loss: 7.48256
Epoch 25, Val Loss: 7.43563
Epoch 26, Val Loss: 7.41973
Epoch 27, Val Loss: 7.40995
Epoch 28, Val Loss: 7.45620
Epoch 29, Val Loss: 7.48240
Epoch 30, Val Loss: 7.23767
Epoch 31, Val Loss: 7.22520
Epoch 32, Val Loss: 7.28942
Epoch 33, Val Loss: 7.11418
Epoch 34, Val Loss: 7.19147
Epoch 35, Val Loss: 7.55080
Epoch 36, Val Loss: 7.07500
Epoch 37, Val Loss: 7.33791
Epoch 38, Val Loss: 7.20031
Epoch 39, Val Loss: 7.25555
Epoch 40, Val Loss: 7.14214
Epoch 41, Val Loss: 7.07515
Epoch 42, Val Loss: 7.16584
Epoch 43, Val Loss: 6.93729
Epoch 44, Val Loss: 7.13703
Epoch 45, Val Loss: 7.48282
Epoch 46, Val Loss: 6.78828
Epoch 47, Val Loss: 6.88688
Epoch 48, Val Loss: 6.98475
Epoch 49, Val Loss: 7.01845
Epoch 50, Val Loss: 6.78639
Epoch 51, Val Loss: 6.98184
Epoch 52, Val Loss: 7.43359
Epoch 53, Val Loss: 6.67745
Epoch 54, Val Loss: 6.76791
Epoch 55, Val Loss: 6.65391
Epoch 56, Val Loss: 6.87343
Epoch 57, Val Loss: 6.78528
Epoch 58, Val Loss: 6.86688
Epoch 59, Val Loss: 6.47376
Epoch 60, Val Loss: 6.49396
Epoch 61, Val Loss: 6.56962
Epoch 62, Val Loss: 6.94940
Epoch 63, Val Loss: 6.80709
Epoch 64, Val Loss: 6.43393
Epoch 65, Val Loss: 6.60269
Epoch 66, Val Loss: 6.46999
Epoch 67, Val Loss: 6.48475
Epoch 68, Val Loss: 6.47214
Epoch 69, Val Loss: 6.29781
Epoch 70, Val Loss: 6.72000
Epoch 71, Val Loss: 6.30014
Epoch 72, Val Loss: 6.53655
Epoch 73, Val Loss: 6.58602
Epoch 74, Val Loss: 6.47751
Epoch 75, Val Loss: 6.27471
Epoch 76, Val Loss: 6.27240
Epoch 77, Val Loss: 6.16150
Epoch 78, Val Loss: 6.37669
Epoch 79, Val Loss: 6.36760
Epoch 80, Val Loss: 6.19964
Epoch 81, Val Loss: 6.10512
Epoch 82, Val Loss: 6.36326
Epoch 83, Val Loss: 6.36449
Epoch 84, Val Loss: 6.24944
Epoch 85, Val Loss: 6.36017
Epoch 86, Val Loss: 6.47070
Epoch 87, Val Loss: 6.21820
Epoch 88, Val Loss: 6.15050
Epoch 89, Val Loss: 6.12400
Epoch 90, Val Loss: 6.24229
Epoch 91, Val Loss: 6.05458
Epoch 92, Val Loss: 6.17831
Epoch 93, Val Loss: 6.29175
Epoch 94, Val Loss: 6.02179
Epoch 95, Val Loss: 6.02644
Epoch 96, Val Loss: 6.29187
Epoch 97, Val Loss: 6.13629
Epoch 98, Val Loss: 6.01737
Epoch 99, Val Loss: 5.91243
DID NOT SAVE RESULTS
{'MSE - mean': 4.824205832363343, 'MSE - std': 0.6150461824712032, 'R2 - mean': 0.5368288809140126, 'R2 - std': 0.014251445253907275} 
 

Results After CV: {'MSE - mean': 4.824205832363343, 'MSE - std': 0.6150461824712032, 'R2 - mean': 0.5368288809140126, 'R2 - std': 0.014251445253907275}
Train time: 81.47801829679956
Inference time: 0.05664416859981429
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 43 finished with value: 4.824205832363343 and parameters: {'p_m': 0.7995536004428264, 'alpha': 0.6465355804911765, 'K': 10, 'beta': 5.836479115385093}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.29977
Epoch 1, Val Loss: 10.39149
Epoch 2, Val Loss: 8.04208
Epoch 3, Val Loss: 6.91240
Epoch 4, Val Loss: 6.61228
Epoch 5, Val Loss: 6.31074
Epoch 6, Val Loss: 6.10662
Epoch 7, Val Loss: 6.07490
Epoch 8, Val Loss: 5.81064
Epoch 9, Val Loss: 5.84155
Epoch 10, Val Loss: 5.84110
Epoch 11, Val Loss: 5.55375
Epoch 12, Val Loss: 5.91536
Epoch 13, Val Loss: 5.60546
Epoch 14, Val Loss: 5.50394
Epoch 15, Val Loss: 5.60695
Epoch 16, Val Loss: 5.66465
Epoch 17, Val Loss: 5.52316
Epoch 18, Val Loss: 5.37866
Epoch 19, Val Loss: 5.40514
Epoch 20, Val Loss: 5.68897
Epoch 21, Val Loss: 5.37453
Epoch 22, Val Loss: 5.33147
Epoch 23, Val Loss: 5.35181
Epoch 24, Val Loss: 5.62425
Epoch 25, Val Loss: 5.28234
Epoch 26, Val Loss: 5.34382
Epoch 27, Val Loss: 5.32965
Epoch 28, Val Loss: 5.50740
Epoch 29, Val Loss: 5.23980
Epoch 30, Val Loss: 5.04478
Epoch 31, Val Loss: 5.22414
Epoch 32, Val Loss: 5.12109
Epoch 33, Val Loss: 5.02189
Epoch 34, Val Loss: 5.06584
Epoch 35, Val Loss: 5.20245
Epoch 36, Val Loss: 5.03548
Epoch 37, Val Loss: 4.86959
Epoch 38, Val Loss: 5.04576
Epoch 39, Val Loss: 4.94980
Epoch 40, Val Loss: 4.84846
Epoch 41, Val Loss: 5.20654
Epoch 42, Val Loss: 4.93186
Epoch 43, Val Loss: 4.91215
Epoch 44, Val Loss: 5.02249
Epoch 45, Val Loss: 4.78309
Epoch 46, Val Loss: 5.07127
Epoch 47, Val Loss: 4.72892
Epoch 48, Val Loss: 4.80172
Epoch 49, Val Loss: 4.86263
Epoch 50, Val Loss: 4.76245
Epoch 51, Val Loss: 4.98937
Epoch 52, Val Loss: 5.03110
Epoch 53, Val Loss: 4.96953
Epoch 54, Val Loss: 5.19728
Epoch 55, Val Loss: 4.90720
Epoch 56, Val Loss: 4.94561
Epoch 57, Val Loss: 4.81896
Epoch 58, Val Loss: 4.69968
Epoch 59, Val Loss: 4.88788
Epoch 60, Val Loss: 4.89125
Epoch 61, Val Loss: 4.68529
Epoch 62, Val Loss: 4.85755
Epoch 63, Val Loss: 4.70835
Epoch 64, Val Loss: 4.68876
Epoch 65, Val Loss: 4.62732
Epoch 66, Val Loss: 4.70020
Epoch 67, Val Loss: 4.64398
Epoch 68, Val Loss: 4.81494
Epoch 69, Val Loss: 4.88025
Epoch 70, Val Loss: 4.60963
Epoch 71, Val Loss: 4.77851
Epoch 72, Val Loss: 4.62674
Epoch 73, Val Loss: 4.73637
Epoch 74, Val Loss: 4.73643
Epoch 75, Val Loss: 5.52101
Epoch 76, Val Loss: 4.76873
Epoch 77, Val Loss: 4.63765
Epoch 78, Val Loss: 4.64788
Epoch 79, Val Loss: 4.65785
Epoch 80, Val Loss: 4.55545
Epoch 81, Val Loss: 5.06028
Epoch 82, Val Loss: 4.62579
Epoch 83, Val Loss: 5.16703
Epoch 84, Val Loss: 4.69150
Epoch 85, Val Loss: 4.67216
Epoch 86, Val Loss: 4.49735
Epoch 87, Val Loss: 5.54572
Epoch 88, Val Loss: 4.71684
Epoch 89, Val Loss: 4.85893
Epoch 90, Val Loss: 4.51168
Epoch 91, Val Loss: 4.67458
Epoch 92, Val Loss: 4.68333
Epoch 93, Val Loss: 4.90948
Epoch 94, Val Loss: 4.69100
Epoch 95, Val Loss: 4.62625
Epoch 96, Val Loss: 4.77997
Epoch 97, Val Loss: 4.91943
Epoch 98, Val Loss: 4.57473
Epoch 99, Val Loss: 4.61245
DID NOT SAVE RESULTS
{'MSE - mean': 4.6464768734955895, 'MSE - std': 0.0, 'R2 - mean': 0.5762566626909202, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 21.58883
Epoch 1, Val Loss: 7.77083
Epoch 2, Val Loss: 5.73730
Epoch 3, Val Loss: 5.69125
Epoch 4, Val Loss: 5.49415
Epoch 5, Val Loss: 5.57499
Epoch 6, Val Loss: 5.30051
Epoch 7, Val Loss: 5.49315
Epoch 8, Val Loss: 5.34071
Epoch 9, Val Loss: 5.58668
Epoch 10, Val Loss: 5.40064
Epoch 11, Val Loss: 5.19839
Epoch 12, Val Loss: 5.11696
Epoch 13, Val Loss: 5.06965
Epoch 14, Val Loss: 5.06192
Epoch 15, Val Loss: 5.28092
Epoch 16, Val Loss: 5.01774
Epoch 17, Val Loss: 5.07738
Epoch 18, Val Loss: 4.91668
Epoch 19, Val Loss: 5.14222
Epoch 20, Val Loss: 4.89155
Epoch 21, Val Loss: 5.10364
Epoch 22, Val Loss: 5.04095
Epoch 23, Val Loss: 4.85461
Epoch 24, Val Loss: 4.80598
Epoch 25, Val Loss: 4.77589
Epoch 26, Val Loss: 4.85009
Epoch 27, Val Loss: 4.74117
Epoch 28, Val Loss: 4.69022
Epoch 29, Val Loss: 4.57487
Epoch 30, Val Loss: 4.78036
Epoch 31, Val Loss: 4.66934
Epoch 32, Val Loss: 5.01268
Epoch 33, Val Loss: 5.12738
Epoch 34, Val Loss: 4.90865
Epoch 35, Val Loss: 4.85350
Epoch 36, Val Loss: 4.48958
Epoch 37, Val Loss: 4.74234
Epoch 38, Val Loss: 4.60478
Epoch 39, Val Loss: 4.63285
Epoch 40, Val Loss: 4.43875
Epoch 41, Val Loss: 4.56145
Epoch 42, Val Loss: 4.54154
Epoch 43, Val Loss: 4.38947
Epoch 44, Val Loss: 4.47977
Epoch 45, Val Loss: 4.36249
Epoch 46, Val Loss: 4.43858
Epoch 47, Val Loss: 4.47906
Epoch 48, Val Loss: 4.40144
Epoch 49, Val Loss: 4.32357
Epoch 50, Val Loss: 4.59719
Epoch 51, Val Loss: 4.41119
Epoch 52, Val Loss: 4.28924
Epoch 53, Val Loss: 4.33119
Epoch 54, Val Loss: 4.49842
Epoch 55, Val Loss: 4.40472
Epoch 56, Val Loss: 4.33791
Epoch 57, Val Loss: 4.36195
Epoch 58, Val Loss: 4.51533
Epoch 59, Val Loss: 4.23038
Epoch 60, Val Loss: 4.30657
Epoch 61, Val Loss: 4.31787
Epoch 62, Val Loss: 4.32108
Epoch 63, Val Loss: 4.28021
Epoch 64, Val Loss: 4.19439
Epoch 65, Val Loss: 4.15312
Epoch 66, Val Loss: 4.27390
Epoch 67, Val Loss: 4.21421
Epoch 68, Val Loss: 4.13694
Epoch 69, Val Loss: 4.44442
Epoch 70, Val Loss: 4.41200
Epoch 71, Val Loss: 4.41226
Epoch 72, Val Loss: 4.46619
Epoch 73, Val Loss: 4.30918
Epoch 74, Val Loss: 4.11571
Epoch 75, Val Loss: 4.47587
Epoch 76, Val Loss: 4.21030
Epoch 77, Val Loss: 4.21518
Epoch 78, Val Loss: 4.22169
Epoch 79, Val Loss: 4.38053
Epoch 80, Val Loss: 4.21414
Epoch 81, Val Loss: 4.14705
Epoch 82, Val Loss: 4.16166
Epoch 83, Val Loss: 4.52696
Epoch 84, Val Loss: 4.08909
Epoch 85, Val Loss: 4.09535
Epoch 86, Val Loss: 4.50224
Epoch 87, Val Loss: 4.26984
Epoch 88, Val Loss: 4.08222
Epoch 89, Val Loss: 4.13796
Epoch 90, Val Loss: 4.32226
Epoch 91, Val Loss: 4.04199
Epoch 92, Val Loss: 4.09350
Epoch 93, Val Loss: 4.24305
Epoch 94, Val Loss: 4.15809
Epoch 95, Val Loss: 4.31827
Epoch 96, Val Loss: 4.18545
Epoch 97, Val Loss: 4.06951
Epoch 98, Val Loss: 4.02803
Epoch 99, Val Loss: 4.12464
DID NOT SAVE RESULTS
{'MSE - mean': 4.387131124626237, 'MSE - std': 0.259345748869352, 'R2 - mean': 0.5681244627957609, 'R2 - std': 0.008132199895159342} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.49855
Epoch 1, Val Loss: 10.75358
Epoch 2, Val Loss: 7.07676
Epoch 3, Val Loss: 6.71294
Epoch 4, Val Loss: 6.62919
Epoch 5, Val Loss: 6.41692
Epoch 6, Val Loss: 6.15988
Epoch 7, Val Loss: 6.15411
Epoch 8, Val Loss: 6.05042
Epoch 9, Val Loss: 6.05971
Epoch 10, Val Loss: 6.07252
Epoch 11, Val Loss: 5.99270
Epoch 12, Val Loss: 5.90644
Epoch 13, Val Loss: 5.96056
Epoch 14, Val Loss: 6.14142
Epoch 15, Val Loss: 5.83745
Epoch 16, Val Loss: 5.82691
Epoch 17, Val Loss: 5.79899
Epoch 18, Val Loss: 5.60348
Epoch 19, Val Loss: 5.72792
Epoch 20, Val Loss: 5.62566
Epoch 21, Val Loss: 5.73603
Epoch 22, Val Loss: 5.65756
Epoch 23, Val Loss: 5.57303
Epoch 24, Val Loss: 5.58837
Epoch 25, Val Loss: 5.71436
Epoch 26, Val Loss: 5.70259
Epoch 27, Val Loss: 5.82388
Epoch 28, Val Loss: 5.52090
Epoch 29, Val Loss: 5.46047
Epoch 30, Val Loss: 5.72534
Epoch 31, Val Loss: 5.61865
Epoch 32, Val Loss: 5.73963
Epoch 33, Val Loss: 5.41033
Epoch 34, Val Loss: 5.39066
Epoch 35, Val Loss: 5.42496
Epoch 36, Val Loss: 5.31860
Epoch 37, Val Loss: 5.34592
Epoch 38, Val Loss: 5.31003
Epoch 39, Val Loss: 5.34569
Epoch 40, Val Loss: 5.36071
Epoch 41, Val Loss: 5.34286
Epoch 42, Val Loss: 5.25017
Epoch 43, Val Loss: 5.53278
Epoch 44, Val Loss: 6.08499
Epoch 45, Val Loss: 5.33986
Epoch 46, Val Loss: 5.21433
Epoch 47, Val Loss: 5.24863
Epoch 48, Val Loss: 5.19902
Epoch 49, Val Loss: 5.24658
Epoch 50, Val Loss: 5.37041
Epoch 51, Val Loss: 5.44640
Epoch 52, Val Loss: 5.41172
Epoch 53, Val Loss: 5.13294
Epoch 54, Val Loss: 5.27829
Epoch 55, Val Loss: 5.18871
Epoch 56, Val Loss: 5.06241
Epoch 57, Val Loss: 5.08856
Epoch 58, Val Loss: 5.12076
Epoch 59, Val Loss: 5.13494
Epoch 60, Val Loss: 5.21191
Epoch 61, Val Loss: 5.08533
Epoch 62, Val Loss: 5.25246
Epoch 63, Val Loss: 5.11012
Epoch 64, Val Loss: 5.15977
Epoch 65, Val Loss: 5.10656
Epoch 66, Val Loss: 5.04405
Epoch 67, Val Loss: 5.00503
Epoch 68, Val Loss: 5.27545
Epoch 69, Val Loss: 4.97264
Epoch 70, Val Loss: 5.20438
Epoch 71, Val Loss: 5.14338
Epoch 72, Val Loss: 5.16839
Epoch 73, Val Loss: 4.96042
Epoch 74, Val Loss: 4.95463
Epoch 75, Val Loss: 5.35834
Epoch 76, Val Loss: 4.98920
Epoch 77, Val Loss: 4.99204
Epoch 78, Val Loss: 4.98454
Epoch 79, Val Loss: 5.07054
Epoch 80, Val Loss: 4.92589
Epoch 81, Val Loss: 5.21314
Epoch 82, Val Loss: 5.37713
Epoch 83, Val Loss: 4.95651
Epoch 84, Val Loss: 4.95809
Epoch 85, Val Loss: 5.38434
Epoch 86, Val Loss: 4.98746
Epoch 87, Val Loss: 4.78253
Epoch 88, Val Loss: 4.84261
Epoch 89, Val Loss: 4.86871
Epoch 90, Val Loss: 4.82153
Epoch 91, Val Loss: 4.98128
Epoch 92, Val Loss: 5.37081
Epoch 93, Val Loss: 4.88635
Epoch 94, Val Loss: 4.85229
Epoch 95, Val Loss: 5.11886
Epoch 96, Val Loss: 4.90045
Epoch 97, Val Loss: 4.78240
Epoch 98, Val Loss: 4.79718
Epoch 99, Val Loss: 4.81445
DID NOT SAVE RESULTS
{'MSE - mean': 4.547298970371636, 'MSE - std': 0.3100768011195184, 'R2 - mean': 0.552426678169237, 'R2 - std': 0.023171735680594774} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.71323
Epoch 1, Val Loss: 8.26238
Epoch 2, Val Loss: 6.07579
Epoch 3, Val Loss: 5.64631
Epoch 4, Val Loss: 5.60988
Epoch 5, Val Loss: 5.42952
Epoch 6, Val Loss: 5.44587
Epoch 7, Val Loss: 5.21902
Epoch 8, Val Loss: 5.30317
Epoch 9, Val Loss: 5.19980
Epoch 10, Val Loss: 5.20264
Epoch 11, Val Loss: 5.18247
Epoch 12, Val Loss: 5.05783
Epoch 13, Val Loss: 5.03154
Epoch 14, Val Loss: 5.01134
Epoch 15, Val Loss: 5.12433
Epoch 16, Val Loss: 4.93854
Epoch 17, Val Loss: 5.02368
Epoch 18, Val Loss: 4.95666
Epoch 19, Val Loss: 5.03665
Epoch 20, Val Loss: 4.90744
Epoch 21, Val Loss: 5.25495
Epoch 22, Val Loss: 4.88311
Epoch 23, Val Loss: 4.79583
Epoch 24, Val Loss: 4.90082
Epoch 25, Val Loss: 4.71322
Epoch 26, Val Loss: 4.69673
Epoch 27, Val Loss: 4.69940
Epoch 28, Val Loss: 4.66997
Epoch 29, Val Loss: 4.64804
Epoch 30, Val Loss: 4.60050
Epoch 31, Val Loss: 4.58571
Epoch 32, Val Loss: 4.79664
Epoch 33, Val Loss: 4.64056
Epoch 34, Val Loss: 4.65364
Epoch 35, Val Loss: 4.66051
Epoch 36, Val Loss: 4.72846
Epoch 37, Val Loss: 4.56428
Epoch 38, Val Loss: 4.60818
Epoch 39, Val Loss: 4.49203
Epoch 40, Val Loss: 4.70031
Epoch 41, Val Loss: 4.59819
Epoch 42, Val Loss: 4.44205
Epoch 43, Val Loss: 4.39850
Epoch 44, Val Loss: 4.63278
Epoch 45, Val Loss: 4.44307
Epoch 46, Val Loss: 4.55352
Epoch 47, Val Loss: 4.66803
Epoch 48, Val Loss: 4.55597
Epoch 49, Val Loss: 4.60882
Epoch 50, Val Loss: 4.35037
Epoch 51, Val Loss: 4.37230
Epoch 52, Val Loss: 4.32113
Epoch 53, Val Loss: 4.41626
Epoch 54, Val Loss: 4.38770
Epoch 55, Val Loss: 4.42167
Epoch 56, Val Loss: 4.47918
Epoch 57, Val Loss: 4.38443
Epoch 58, Val Loss: 4.49843
Epoch 59, Val Loss: 4.29882
Epoch 60, Val Loss: 4.55557
Epoch 61, Val Loss: 4.46290
Epoch 62, Val Loss: 4.33071
Epoch 63, Val Loss: 4.39600
Epoch 64, Val Loss: 4.35158
Epoch 65, Val Loss: 4.25099
Epoch 66, Val Loss: 4.63175
Epoch 67, Val Loss: 4.31669
Epoch 68, Val Loss: 4.24447
Epoch 69, Val Loss: 4.39655
Epoch 70, Val Loss: 4.36483
Epoch 71, Val Loss: 4.28467
Epoch 72, Val Loss: 4.24488
Epoch 73, Val Loss: 4.21857
Epoch 74, Val Loss: 4.32724
Epoch 75, Val Loss: 4.73438
Epoch 76, Val Loss: 4.53563
Epoch 77, Val Loss: 4.31239
Epoch 78, Val Loss: 4.24470
Epoch 79, Val Loss: 4.40271
Epoch 80, Val Loss: 4.41392
Epoch 81, Val Loss: 4.19996
Epoch 82, Val Loss: 4.24379
Epoch 83, Val Loss: 4.29011
Epoch 84, Val Loss: 4.25362
Epoch 85, Val Loss: 4.17916
Epoch 86, Val Loss: 4.65150
Epoch 87, Val Loss: 4.40352
Epoch 88, Val Loss: 4.28472
Epoch 89, Val Loss: 4.21210
Epoch 90, Val Loss: 4.24023
Epoch 91, Val Loss: 4.35193
Epoch 92, Val Loss: 4.48311
Epoch 93, Val Loss: 5.14078
Epoch 94, Val Loss: 4.31565
Epoch 95, Val Loss: 4.62318
Epoch 96, Val Loss: 4.19856
Epoch 97, Val Loss: 4.20075
Epoch 98, Val Loss: 4.24077
Epoch 99, Val Loss: 4.24659
DID NOT SAVE RESULTS
{'MSE - mean': 4.541602003444179, 'MSE - std': 0.26871561778375036, 'R2 - mean': 0.5433792517837935, 'R2 - std': 0.025461044233074315} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.00256
Epoch 1, Val Loss: 18.95465
Epoch 2, Val Loss: 9.85476
Epoch 3, Val Loss: 7.89565
Epoch 4, Val Loss: 7.79121
Epoch 5, Val Loss: 7.42461
Epoch 6, Val Loss: 7.49240
Epoch 7, Val Loss: 7.49442
Epoch 8, Val Loss: 7.43708
Epoch 9, Val Loss: 7.32932
Epoch 10, Val Loss: 7.12114
Epoch 11, Val Loss: 7.21149
Epoch 12, Val Loss: 7.11341
Epoch 13, Val Loss: 7.21259
Epoch 14, Val Loss: 7.33693
Epoch 15, Val Loss: 7.02218
Epoch 16, Val Loss: 7.01739
Epoch 17, Val Loss: 6.78463
Epoch 18, Val Loss: 6.88947
Epoch 19, Val Loss: 6.77434
Epoch 20, Val Loss: 6.86702
Epoch 21, Val Loss: 6.83180
Epoch 22, Val Loss: 6.82967
Epoch 23, Val Loss: 6.69077
Epoch 24, Val Loss: 6.72544
Epoch 25, Val Loss: 6.58387
Epoch 26, Val Loss: 6.76368
Epoch 27, Val Loss: 6.49050
Epoch 28, Val Loss: 6.40468
Epoch 29, Val Loss: 6.40179
Epoch 30, Val Loss: 6.41092
Epoch 31, Val Loss: 6.66545
Epoch 32, Val Loss: 6.35839
Epoch 33, Val Loss: 6.38638
Epoch 34, Val Loss: 6.54011
Epoch 35, Val Loss: 6.56254
Epoch 36, Val Loss: 6.41565
Epoch 37, Val Loss: 6.45790
Epoch 38, Val Loss: 6.23079
Epoch 39, Val Loss: 6.27262
Epoch 40, Val Loss: 6.25947
Epoch 41, Val Loss: 6.24007
Epoch 42, Val Loss: 6.43336
Epoch 43, Val Loss: 6.31957
Epoch 44, Val Loss: 6.18178
Epoch 45, Val Loss: 6.13365
Epoch 46, Val Loss: 6.21066
Epoch 47, Val Loss: 6.18648
Epoch 48, Val Loss: 6.32649
Epoch 49, Val Loss: 6.04730
Epoch 50, Val Loss: 6.05959
Epoch 51, Val Loss: 6.12020
Epoch 52, Val Loss: 5.98720
Epoch 53, Val Loss: 6.31614
Epoch 54, Val Loss: 6.10312
Epoch 55, Val Loss: 5.96612
Epoch 56, Val Loss: 5.98208
Epoch 57, Val Loss: 6.33745
Epoch 58, Val Loss: 6.19997
Epoch 59, Val Loss: 6.25145
Epoch 60, Val Loss: 5.95865
Epoch 61, Val Loss: 6.15601
Epoch 62, Val Loss: 6.05180
Epoch 63, Val Loss: 6.08527
Epoch 64, Val Loss: 6.01928
Epoch 65, Val Loss: 6.33293
Epoch 66, Val Loss: 5.93098
Epoch 67, Val Loss: 5.89358
Epoch 68, Val Loss: 6.17190
Epoch 69, Val Loss: 5.82911
Epoch 70, Val Loss: 6.32632
Epoch 71, Val Loss: 5.98560
Epoch 72, Val Loss: 6.39825
Epoch 73, Val Loss: 6.12252
Epoch 74, Val Loss: 5.96051
Epoch 75, Val Loss: 5.84886
Epoch 76, Val Loss: 5.88792
Epoch 77, Val Loss: 5.83954
Epoch 78, Val Loss: 5.81480
Epoch 79, Val Loss: 5.73210
Epoch 80, Val Loss: 5.87550
Epoch 81, Val Loss: 6.11355
Epoch 82, Val Loss: 6.10582
Epoch 83, Val Loss: 5.93552
Epoch 84, Val Loss: 5.87744
Epoch 85, Val Loss: 5.82049
Epoch 86, Val Loss: 5.85311
Epoch 87, Val Loss: 5.88887
Epoch 88, Val Loss: 5.90868
Epoch 89, Val Loss: 5.91810
Epoch 90, Val Loss: 6.06236
Epoch 91, Val Loss: 5.89420
Epoch 92, Val Loss: 5.82703
Epoch 93, Val Loss: 5.96355
Epoch 94, Val Loss: 6.10117
Epoch 95, Val Loss: 6.22210
Epoch 96, Val Loss: 6.28453
Epoch 97, Val Loss: 5.82598
Epoch 98, Val Loss: 5.95517
Epoch 99, Val Loss: 6.03912
DID NOT SAVE RESULTS
{'MSE - mean': 4.781514628655417, 'MSE - std': 0.5366551383670097, 'R2 - mean': 0.5397448919460694, 'R2 - std': 0.023904938913770477} 
 

Results After CV: {'MSE - mean': 4.781514628655417, 'MSE - std': 0.5366551383670097, 'R2 - mean': 0.5397448919460694, 'R2 - std': 0.023904938913770477}
Train time: 113.72587823419926
Inference time: 0.04959895179999876
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 44 finished with value: 4.781514628655417 and parameters: {'p_m': 0.8668485495253443, 'alpha': 1.2956069516192252, 'K': 20, 'beta': 4.548591312531553}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.91309
Epoch 1, Val Loss: 15.75709
Epoch 2, Val Loss: 8.17679
Epoch 3, Val Loss: 7.05966
Epoch 4, Val Loss: 7.05038
Epoch 5, Val Loss: 6.69844
Epoch 6, Val Loss: 6.76772
Epoch 7, Val Loss: 6.60389
Epoch 8, Val Loss: 6.30526
Epoch 9, Val Loss: 6.29408
Epoch 10, Val Loss: 6.35761
Epoch 11, Val Loss: 6.14397
Epoch 12, Val Loss: 6.10699
Epoch 13, Val Loss: 6.37724
Epoch 14, Val Loss: 6.08903
Epoch 15, Val Loss: 6.44305
Epoch 16, Val Loss: 5.95919
Epoch 17, Val Loss: 5.88919
Epoch 18, Val Loss: 6.33445
Epoch 19, Val Loss: 5.97479
Epoch 20, Val Loss: 5.94814
Epoch 21, Val Loss: 5.79800
Epoch 22, Val Loss: 5.70119
Epoch 23, Val Loss: 5.84392
Epoch 24, Val Loss: 5.94503
Epoch 25, Val Loss: 5.87594
Epoch 26, Val Loss: 6.15868
Epoch 27, Val Loss: 6.21252
Epoch 28, Val Loss: 5.62739
Epoch 29, Val Loss: 5.46160
Epoch 30, Val Loss: 5.65994
Epoch 31, Val Loss: 6.08223
Epoch 32, Val Loss: 5.52605
Epoch 33, Val Loss: 5.39833
Epoch 34, Val Loss: 5.53842
Epoch 35, Val Loss: 5.46623
Epoch 36, Val Loss: 5.25265
Epoch 37, Val Loss: 5.15140
Epoch 38, Val Loss: 5.27438
Epoch 39, Val Loss: 5.25302
Epoch 40, Val Loss: 5.12978
Epoch 41, Val Loss: 5.68022
Epoch 42, Val Loss: 5.21999
Epoch 43, Val Loss: 5.41856
Epoch 44, Val Loss: 4.96800
Epoch 45, Val Loss: 5.08012
Epoch 46, Val Loss: 5.54855
Epoch 47, Val Loss: 4.95429
Epoch 48, Val Loss: 4.90838
Epoch 49, Val Loss: 5.42327
Epoch 50, Val Loss: 4.96477
Epoch 51, Val Loss: 4.92151
Epoch 52, Val Loss: 4.91260
Epoch 53, Val Loss: 5.21930
Epoch 54, Val Loss: 5.13842
Epoch 55, Val Loss: 4.87922
Epoch 56, Val Loss: 4.74034
Epoch 57, Val Loss: 4.87616
Epoch 58, Val Loss: 4.81772
Epoch 59, Val Loss: 4.86940
Epoch 60, Val Loss: 4.91038
Epoch 61, Val Loss: 5.00165
Epoch 62, Val Loss: 4.71373
Epoch 63, Val Loss: 4.77591
Epoch 64, Val Loss: 4.78830
Epoch 65, Val Loss: 5.38606
Epoch 66, Val Loss: 5.13583
Epoch 67, Val Loss: 4.81726
Epoch 68, Val Loss: 4.73115
Epoch 69, Val Loss: 5.43426
Epoch 70, Val Loss: 4.92134
Epoch 71, Val Loss: 4.97859
Epoch 72, Val Loss: 4.68007
Epoch 73, Val Loss: 4.93959
Epoch 74, Val Loss: 4.76096
Epoch 75, Val Loss: 4.84163
Epoch 76, Val Loss: 5.44044
Epoch 77, Val Loss: 5.68535
Epoch 78, Val Loss: 4.82497
Epoch 79, Val Loss: 4.82589
Epoch 80, Val Loss: 4.72379
Epoch 81, Val Loss: 4.73194
Epoch 82, Val Loss: 4.68060
Epoch 83, Val Loss: 4.72122
Epoch 84, Val Loss: 4.63797
Epoch 85, Val Loss: 4.76655
Epoch 86, Val Loss: 4.89524
Epoch 87, Val Loss: 4.63993
Epoch 88, Val Loss: 4.82561
Epoch 89, Val Loss: 4.72543
Epoch 90, Val Loss: 4.92700
Epoch 91, Val Loss: 4.63027
Epoch 92, Val Loss: 5.08192
Epoch 93, Val Loss: 4.88773
Epoch 94, Val Loss: 4.64975
Epoch 95, Val Loss: 4.73070
Epoch 96, Val Loss: 4.63938
Epoch 97, Val Loss: 5.14803
Epoch 98, Val Loss: 4.52826
Epoch 99, Val Loss: 4.74486
DID NOT SAVE RESULTS
{'MSE - mean': 4.660661911847989, 'MSE - std': 0.0, 'R2 - mean': 0.5749630340654148, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.84437
Epoch 1, Val Loss: 11.96222
Epoch 2, Val Loss: 5.91128
Epoch 3, Val Loss: 5.78858
Epoch 4, Val Loss: 5.61075
Epoch 5, Val Loss: 5.48460
Epoch 6, Val Loss: 5.33012
Epoch 7, Val Loss: 5.31749
Epoch 8, Val Loss: 5.23979
Epoch 9, Val Loss: 5.37219
Epoch 10, Val Loss: 5.34471
Epoch 11, Val Loss: 5.21823
Epoch 12, Val Loss: 5.09311
Epoch 13, Val Loss: 5.24538
Epoch 14, Val Loss: 5.55313
Epoch 15, Val Loss: 5.37333
Epoch 16, Val Loss: 5.07715
Epoch 17, Val Loss: 5.41889
Epoch 18, Val Loss: 4.95312
Epoch 19, Val Loss: 4.95087
Epoch 20, Val Loss: 4.86683
Epoch 21, Val Loss: 4.89540
Epoch 22, Val Loss: 4.87328
Epoch 23, Val Loss: 4.93315
Epoch 24, Val Loss: 4.80654
Epoch 25, Val Loss: 4.82373
Epoch 26, Val Loss: 5.25498
Epoch 27, Val Loss: 5.04621
Epoch 28, Val Loss: 4.82419
Epoch 29, Val Loss: 4.63525
Epoch 30, Val Loss: 4.64144
Epoch 31, Val Loss: 4.55004
Epoch 32, Val Loss: 4.53524
Epoch 33, Val Loss: 4.51920
Epoch 34, Val Loss: 4.53441
Epoch 35, Val Loss: 4.56343
Epoch 36, Val Loss: 4.93849
Epoch 37, Val Loss: 4.96124
Epoch 38, Val Loss: 4.59941
Epoch 39, Val Loss: 4.37423
Epoch 40, Val Loss: 4.63640
Epoch 41, Val Loss: 4.33074
Epoch 42, Val Loss: 4.47962
Epoch 43, Val Loss: 4.54072
Epoch 44, Val Loss: 4.36723
Epoch 45, Val Loss: 4.48380
Epoch 46, Val Loss: 4.42380
Epoch 47, Val Loss: 4.18735
Epoch 48, Val Loss: 4.37925
Epoch 49, Val Loss: 4.40168
Epoch 50, Val Loss: 4.13770
Epoch 51, Val Loss: 4.34486
Epoch 52, Val Loss: 4.46992
Epoch 53, Val Loss: 4.22753
Epoch 54, Val Loss: 4.34777
Epoch 55, Val Loss: 4.24055
Epoch 56, Val Loss: 4.19616
Epoch 57, Val Loss: 4.06917
Epoch 58, Val Loss: 4.12749
Epoch 59, Val Loss: 4.05518
Epoch 60, Val Loss: 3.96862
Epoch 61, Val Loss: 4.41389
Epoch 62, Val Loss: 4.07766
Epoch 63, Val Loss: 4.29605
Epoch 64, Val Loss: 4.15258
Epoch 65, Val Loss: 4.16511
Epoch 66, Val Loss: 4.44790
Epoch 67, Val Loss: 4.04523
Epoch 68, Val Loss: 4.17543
Epoch 69, Val Loss: 4.05493
Epoch 70, Val Loss: 4.15921
Epoch 71, Val Loss: 4.05733
Epoch 72, Val Loss: 3.93914
Epoch 73, Val Loss: 3.97539
Epoch 74, Val Loss: 4.01744
Epoch 75, Val Loss: 4.15368
Epoch 76, Val Loss: 4.04611
Epoch 77, Val Loss: 4.04790
Epoch 78, Val Loss: 4.03214
Epoch 79, Val Loss: 4.38579
Epoch 80, Val Loss: 3.94670
Epoch 81, Val Loss: 4.06516
Epoch 82, Val Loss: 3.99574
Epoch 83, Val Loss: 4.42492
Epoch 84, Val Loss: 4.03252
Epoch 85, Val Loss: 4.10292
Epoch 86, Val Loss: 4.48311
Epoch 87, Val Loss: 4.41603
Epoch 88, Val Loss: 4.13633
Epoch 89, Val Loss: 3.97986
Epoch 90, Val Loss: 4.13408
Epoch 91, Val Loss: 3.98924
Epoch 92, Val Loss: 3.97742
Epoch 93, Val Loss: 3.98982
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.411161179732992, 'MSE - std': 0.24950073211499735, 'R2 - mean': 0.565672165353819, 'R2 - std': 0.00929086871159579} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.74413
Epoch 1, Val Loss: 12.08806
Epoch 2, Val Loss: 7.62085
Epoch 3, Val Loss: 6.67408
Epoch 4, Val Loss: 6.66933
Epoch 5, Val Loss: 6.34851
Epoch 6, Val Loss: 6.34672
Epoch 7, Val Loss: 6.21129
Epoch 8, Val Loss: 6.32286
Epoch 9, Val Loss: 6.31277
Epoch 10, Val Loss: 6.22762
Epoch 11, Val Loss: 6.20460
Epoch 12, Val Loss: 6.03966
Epoch 13, Val Loss: 6.08703
Epoch 14, Val Loss: 6.03973
Epoch 15, Val Loss: 6.10759
Epoch 16, Val Loss: 6.00698
Epoch 17, Val Loss: 5.95920
Epoch 18, Val Loss: 5.97956
Epoch 19, Val Loss: 6.02094
Epoch 20, Val Loss: 6.04130
Epoch 21, Val Loss: 6.24397
Epoch 22, Val Loss: 5.93621
Epoch 23, Val Loss: 5.78224
Epoch 24, Val Loss: 5.71346
Epoch 25, Val Loss: 5.74067
Epoch 26, Val Loss: 5.85702
Epoch 27, Val Loss: 6.05958
Epoch 28, Val Loss: 5.81465
Epoch 29, Val Loss: 5.85329
Epoch 30, Val Loss: 6.22765
Epoch 31, Val Loss: 5.59042
Epoch 32, Val Loss: 5.77302
Epoch 33, Val Loss: 5.73359
Epoch 34, Val Loss: 6.09582
Epoch 35, Val Loss: 5.81449
Epoch 36, Val Loss: 5.69374
Epoch 37, Val Loss: 5.72431
Epoch 38, Val Loss: 5.96266
Epoch 39, Val Loss: 5.50462
Epoch 40, Val Loss: 5.63427
Epoch 41, Val Loss: 5.66476
Epoch 42, Val Loss: 5.63603
Epoch 43, Val Loss: 5.80189
Epoch 44, Val Loss: 5.55455
Epoch 45, Val Loss: 5.44501
Epoch 46, Val Loss: 5.60757
Epoch 47, Val Loss: 5.68506
Epoch 48, Val Loss: 5.71302
Epoch 49, Val Loss: 5.52394
Epoch 50, Val Loss: 5.75210
Epoch 51, Val Loss: 5.40832
Epoch 52, Val Loss: 5.39639
Epoch 53, Val Loss: 5.53002
Epoch 54, Val Loss: 5.41421
Epoch 55, Val Loss: 5.61726
Epoch 56, Val Loss: 5.45406
Epoch 57, Val Loss: 5.75902
Epoch 58, Val Loss: 5.37275
Epoch 59, Val Loss: 5.47465
Epoch 60, Val Loss: 5.47318
Epoch 61, Val Loss: 6.15708
Epoch 62, Val Loss: 5.30620
Epoch 63, Val Loss: 5.36108
Epoch 64, Val Loss: 5.31352
Epoch 65, Val Loss: 5.28637
Epoch 66, Val Loss: 5.37392
Epoch 67, Val Loss: 5.29822
Epoch 68, Val Loss: 5.47828
Epoch 69, Val Loss: 5.68759
Epoch 70, Val Loss: 5.16577
Epoch 71, Val Loss: 5.44764
Epoch 72, Val Loss: 5.23246
Epoch 73, Val Loss: 5.29837
Epoch 74, Val Loss: 5.54916
Epoch 75, Val Loss: 5.28149
Epoch 76, Val Loss: 5.17814
Epoch 77, Val Loss: 5.30152
Epoch 78, Val Loss: 5.34153
Epoch 79, Val Loss: 5.20564
Epoch 80, Val Loss: 5.19754
Epoch 81, Val Loss: 5.28119
Epoch 82, Val Loss: 5.24200
Epoch 83, Val Loss: 5.31883
Epoch 84, Val Loss: 5.16935
Epoch 85, Val Loss: 5.08529
Epoch 86, Val Loss: 5.12542
Epoch 87, Val Loss: 5.19669
Epoch 88, Val Loss: 5.14678
Epoch 89, Val Loss: 5.08558
Epoch 90, Val Loss: 5.22632
Epoch 91, Val Loss: 5.06587
Epoch 92, Val Loss: 5.13403
Epoch 93, Val Loss: 5.01863
Epoch 94, Val Loss: 5.17065
Epoch 95, Val Loss: 5.13277
Epoch 96, Val Loss: 5.17904
Epoch 97, Val Loss: 5.08175
Epoch 98, Val Loss: 5.64710
Epoch 99, Val Loss: 5.28757
DID NOT SAVE RESULTS
{'MSE - mean': 4.675832678900339, 'MSE - std': 0.426148348771014, 'R2 - mean': 0.539720614904654, 'R2 - std': 0.03747682976242602} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.99651
Epoch 1, Val Loss: 14.93742
Epoch 2, Val Loss: 5.83454
Epoch 3, Val Loss: 5.61159
Epoch 4, Val Loss: 5.40576
Epoch 5, Val Loss: 5.37783
Epoch 6, Val Loss: 5.27923
Epoch 7, Val Loss: 5.34265
Epoch 8, Val Loss: 5.15735
Epoch 9, Val Loss: 5.23345
Epoch 10, Val Loss: 5.17187
Epoch 11, Val Loss: 5.07055
Epoch 12, Val Loss: 5.03197
Epoch 13, Val Loss: 5.06435
Epoch 14, Val Loss: 5.12444
Epoch 15, Val Loss: 4.98718
Epoch 16, Val Loss: 4.97837
Epoch 17, Val Loss: 5.09151
Epoch 18, Val Loss: 5.34642
Epoch 19, Val Loss: 5.16499
Epoch 20, Val Loss: 5.01727
Epoch 21, Val Loss: 4.97237
Epoch 22, Val Loss: 4.98757
Epoch 23, Val Loss: 4.83967
Epoch 24, Val Loss: 4.77213
Epoch 25, Val Loss: 4.78131
Epoch 26, Val Loss: 4.82345
Epoch 27, Val Loss: 4.79064
Epoch 28, Val Loss: 4.73470
Epoch 29, Val Loss: 4.80223
Epoch 30, Val Loss: 4.81225
Epoch 31, Val Loss: 4.93584
Epoch 32, Val Loss: 4.66499
Epoch 33, Val Loss: 4.95582
Epoch 34, Val Loss: 4.65694
Epoch 35, Val Loss: 4.87823
Epoch 36, Val Loss: 4.54297
Epoch 37, Val Loss: 4.53137
Epoch 38, Val Loss: 4.71204
Epoch 39, Val Loss: 4.50575
Epoch 40, Val Loss: 4.48841
Epoch 41, Val Loss: 4.60492
Epoch 42, Val Loss: 4.65865
Epoch 43, Val Loss: 4.71881
Epoch 44, Val Loss: 4.64780
Epoch 45, Val Loss: 4.71969
Epoch 46, Val Loss: 4.46141
Epoch 47, Val Loss: 4.48283
Epoch 48, Val Loss: 4.50009
Epoch 49, Val Loss: 4.80856
Epoch 50, Val Loss: 4.40948
Epoch 51, Val Loss: 4.72954
Epoch 52, Val Loss: 4.93385
Epoch 53, Val Loss: 4.85578
Epoch 54, Val Loss: 4.45992
Epoch 55, Val Loss: 4.36540
Epoch 56, Val Loss: 4.39519
Epoch 57, Val Loss: 4.48131
Epoch 58, Val Loss: 4.33368
Epoch 59, Val Loss: 4.37701
Epoch 60, Val Loss: 4.53440
Epoch 61, Val Loss: 4.30047
Epoch 62, Val Loss: 4.44490
Epoch 63, Val Loss: 4.45688
Epoch 64, Val Loss: 4.84873
Epoch 65, Val Loss: 4.26921
Epoch 66, Val Loss: 4.31631
Epoch 67, Val Loss: 4.35463
Epoch 68, Val Loss: 4.48055
Epoch 69, Val Loss: 4.89817
Epoch 70, Val Loss: 4.28528
Epoch 71, Val Loss: 4.36420
Epoch 72, Val Loss: 4.70108
Epoch 73, Val Loss: 4.31345
Epoch 74, Val Loss: 4.30233
Epoch 75, Val Loss: 4.42826
Epoch 76, Val Loss: 4.29371
Epoch 77, Val Loss: 4.27326
Epoch 78, Val Loss: 4.20584
Epoch 79, Val Loss: 4.21429
Epoch 80, Val Loss: 4.23936
Epoch 81, Val Loss: 4.27242
Epoch 82, Val Loss: 4.20475
Epoch 83, Val Loss: 4.29434
Epoch 84, Val Loss: 4.16546
Epoch 85, Val Loss: 4.33222
Epoch 86, Val Loss: 4.28905
Epoch 87, Val Loss: 4.40551
Epoch 88, Val Loss: 4.18362
Epoch 89, Val Loss: 4.28446
Epoch 90, Val Loss: 4.29017
Epoch 91, Val Loss: 4.26450
Epoch 92, Val Loss: 4.28502
Epoch 93, Val Loss: 4.16584
Epoch 94, Val Loss: 4.28830
Epoch 95, Val Loss: 4.34064
Epoch 96, Val Loss: 4.27195
Epoch 97, Val Loss: 4.54829
Epoch 98, Val Loss: 4.37930
Epoch 99, Val Loss: 4.26196
DID NOT SAVE RESULTS
{'MSE - mean': 4.6156181781348815, 'MSE - std': 0.38350902163768724, 'R2 - mean': 0.5362430244044947, 'R2 - std': 0.03301008154854801} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.33850
Epoch 1, Val Loss: 17.76604
Epoch 2, Val Loss: 9.85279
Epoch 3, Val Loss: 7.97751
Epoch 4, Val Loss: 7.79193
Epoch 5, Val Loss: 8.19644
Epoch 6, Val Loss: 7.70529
Epoch 7, Val Loss: 7.38542
Epoch 8, Val Loss: 7.49304
Epoch 9, Val Loss: 7.36887
Epoch 10, Val Loss: 7.09123
Epoch 11, Val Loss: 7.35615
Epoch 12, Val Loss: 7.01061
Epoch 13, Val Loss: 6.91323
Epoch 14, Val Loss: 6.83646
Epoch 15, Val Loss: 6.73007
Epoch 16, Val Loss: 6.77633
Epoch 17, Val Loss: 6.72342
Epoch 18, Val Loss: 6.70462
Epoch 19, Val Loss: 6.66466
Epoch 20, Val Loss: 6.65185
Epoch 21, Val Loss: 6.78868
Epoch 22, Val Loss: 6.61538
Epoch 23, Val Loss: 6.52952
Epoch 24, Val Loss: 6.47936
Epoch 25, Val Loss: 6.39602
Epoch 26, Val Loss: 6.53291
Epoch 27, Val Loss: 6.66899
Epoch 28, Val Loss: 6.53474
Epoch 29, Val Loss: 6.59009
Epoch 30, Val Loss: 6.33483
Epoch 31, Val Loss: 6.32667
Epoch 32, Val Loss: 6.63199
Epoch 33, Val Loss: 6.36030
Epoch 34, Val Loss: 6.33837
Epoch 35, Val Loss: 6.25080
Epoch 36, Val Loss: 6.23677
Epoch 37, Val Loss: 6.25754
Epoch 38, Val Loss: 6.25344
Epoch 39, Val Loss: 6.38299
Epoch 40, Val Loss: 6.29300
Epoch 41, Val Loss: 6.15283
Epoch 42, Val Loss: 6.23115
Epoch 43, Val Loss: 6.21349
Epoch 44, Val Loss: 6.23060
Epoch 45, Val Loss: 6.25895
Epoch 46, Val Loss: 6.24293
Epoch 47, Val Loss: 6.31023
Epoch 48, Val Loss: 6.33417
Epoch 49, Val Loss: 6.14400
Epoch 50, Val Loss: 6.13802
Epoch 51, Val Loss: 6.23680
Epoch 52, Val Loss: 6.20540
Epoch 53, Val Loss: 6.19837
Epoch 54, Val Loss: 6.35166
Epoch 55, Val Loss: 6.10670
Epoch 56, Val Loss: 6.01484
Epoch 57, Val Loss: 6.03468
Epoch 58, Val Loss: 5.98858
Epoch 59, Val Loss: 6.04703
Epoch 60, Val Loss: 6.11086
Epoch 61, Val Loss: 6.04169
Epoch 62, Val Loss: 6.10137
Epoch 63, Val Loss: 5.97551
Epoch 64, Val Loss: 6.03466
Epoch 65, Val Loss: 6.03254
Epoch 66, Val Loss: 5.88561
Epoch 67, Val Loss: 5.90443
Epoch 68, Val Loss: 6.06290
Epoch 69, Val Loss: 5.81667
Epoch 70, Val Loss: 5.94119
Epoch 71, Val Loss: 6.55984
Epoch 72, Val Loss: 5.83259
Epoch 73, Val Loss: 6.06828
Epoch 74, Val Loss: 5.91198
Epoch 75, Val Loss: 6.15947
Epoch 76, Val Loss: 5.94392
Epoch 77, Val Loss: 6.14137
Epoch 78, Val Loss: 5.91907
Epoch 79, Val Loss: 5.88687
Epoch 80, Val Loss: 6.05135
Epoch 81, Val Loss: 5.79697
Epoch 82, Val Loss: 5.77581
Epoch 83, Val Loss: 5.82495
Epoch 84, Val Loss: 6.18872
Epoch 85, Val Loss: 5.82200
Epoch 86, Val Loss: 5.78976
Epoch 87, Val Loss: 5.78409
Epoch 88, Val Loss: 6.36170
Epoch 89, Val Loss: 6.14055
Epoch 90, Val Loss: 5.92293
Epoch 91, Val Loss: 5.85264
Epoch 92, Val Loss: 5.75411
Epoch 93, Val Loss: 5.67540
Epoch 94, Val Loss: 5.71842
Epoch 95, Val Loss: 5.79772
Epoch 96, Val Loss: 6.14087
Epoch 97, Val Loss: 5.78194
Epoch 98, Val Loss: 5.77646
Epoch 99, Val Loss: 5.95190
DID NOT SAVE RESULTS
{'MSE - mean': 4.833603809524905, 'MSE - std': 0.5547380261997783, 'R2 - mean': 0.5346250426578575, 'R2 - std': 0.02970191655101127} 
 

Results After CV: {'MSE - mean': 4.833603809524905, 'MSE - std': 0.5547380261997783, 'R2 - mean': 0.5346250426578575, 'R2 - std': 0.02970191655101127}
Train time: 32.880072011800074
Inference time: 0.048368898200351396
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 45 finished with value: 4.833603809524905 and parameters: {'p_m': 0.8186880610166125, 'alpha': 1.8116237518289349, 'K': 3, 'beta': 3.8237751333040304}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.66618
Epoch 1, Val Loss: 8.75743
Epoch 2, Val Loss: 6.72394
Epoch 3, Val Loss: 6.72675
Epoch 4, Val Loss: 6.45285
Epoch 5, Val Loss: 6.40260
Epoch 6, Val Loss: 6.29743
Epoch 7, Val Loss: 6.25047
Epoch 8, Val Loss: 6.54079
Epoch 9, Val Loss: 6.14115
Epoch 10, Val Loss: 6.27677
Epoch 11, Val Loss: 6.02703
Epoch 12, Val Loss: 6.05288
Epoch 13, Val Loss: 6.41072
Epoch 14, Val Loss: 6.10356
Epoch 15, Val Loss: 6.09716
Epoch 16, Val Loss: 6.16934
Epoch 17, Val Loss: 5.95017
Epoch 18, Val Loss: 6.49680
Epoch 19, Val Loss: 6.27281
Epoch 20, Val Loss: 6.22037
Epoch 21, Val Loss: 5.90266
Epoch 22, Val Loss: 5.98969
Epoch 23, Val Loss: 6.16789
Epoch 24, Val Loss: 5.90420
Epoch 25, Val Loss: 6.15912
Epoch 26, Val Loss: 5.84538
Epoch 27, Val Loss: 5.72787
Epoch 28, Val Loss: 5.66475
Epoch 29, Val Loss: 5.95389
Epoch 30, Val Loss: 5.83693
Epoch 31, Val Loss: 5.83730
Epoch 32, Val Loss: 6.05257
Epoch 33, Val Loss: 5.83238
Epoch 34, Val Loss: 5.64915
Epoch 35, Val Loss: 5.54113
Epoch 36, Val Loss: 5.59146
Epoch 37, Val Loss: 5.64134
Epoch 38, Val Loss: 5.89358
Epoch 39, Val Loss: 5.53979
Epoch 40, Val Loss: 5.66204
Epoch 41, Val Loss: 5.84553
Epoch 42, Val Loss: 5.62176
Epoch 43, Val Loss: 5.55254
Epoch 44, Val Loss: 5.45212
Epoch 45, Val Loss: 5.38115
Epoch 46, Val Loss: 5.47931
Epoch 47, Val Loss: 5.43742
Epoch 48, Val Loss: 5.46969
Epoch 49, Val Loss: 5.30682
Epoch 50, Val Loss: 5.37068
Epoch 51, Val Loss: 5.70062
Epoch 52, Val Loss: 5.49187
Epoch 53, Val Loss: 5.38843
Epoch 54, Val Loss: 5.32254
Epoch 55, Val Loss: 5.32745
Epoch 56, Val Loss: 5.20360
Epoch 57, Val Loss: 5.32147
Epoch 58, Val Loss: 5.36558
Epoch 59, Val Loss: 5.28933
Epoch 60, Val Loss: 5.30522
Epoch 61, Val Loss: 5.21405
Epoch 62, Val Loss: 5.37448
Epoch 63, Val Loss: 5.23114
Epoch 64, Val Loss: 5.22026
Epoch 65, Val Loss: 5.09111
Epoch 66, Val Loss: 5.52635
Epoch 67, Val Loss: 5.38704
Epoch 68, Val Loss: 5.36063
Epoch 69, Val Loss: 5.49369
Epoch 70, Val Loss: 5.45030
Epoch 71, Val Loss: 5.39226
Epoch 72, Val Loss: 5.33318
Epoch 73, Val Loss: 5.12813
Epoch 74, Val Loss: 5.03409
Epoch 75, Val Loss: 5.09923
Epoch 76, Val Loss: 5.09730
Epoch 77, Val Loss: 5.19545
Epoch 78, Val Loss: 5.29495
Epoch 79, Val Loss: 5.30990
Epoch 80, Val Loss: 5.26544
Epoch 81, Val Loss: 5.08037
Epoch 82, Val Loss: 5.19020
Epoch 83, Val Loss: 5.15970
Epoch 84, Val Loss: 5.11383
Epoch 85, Val Loss: 5.01199
Epoch 86, Val Loss: 5.10437
Epoch 87, Val Loss: 5.35071
Epoch 88, Val Loss: 5.21854
Epoch 89, Val Loss: 5.64351
Epoch 90, Val Loss: 5.30172
Epoch 91, Val Loss: 4.92814
Epoch 92, Val Loss: 5.08420
Epoch 93, Val Loss: 5.02447
Epoch 94, Val Loss: 4.89520
Epoch 95, Val Loss: 6.24635
Epoch 96, Val Loss: 5.17933
Epoch 97, Val Loss: 4.95507
Epoch 98, Val Loss: 4.94478
Epoch 99, Val Loss: 5.16294
DID NOT SAVE RESULTS
{'MSE - mean': 5.0120917546107, 'MSE - std': 0.0, 'R2 - mean': 0.5429137936502257, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.34592
Epoch 1, Val Loss: 10.18039
Epoch 2, Val Loss: 5.21727
Epoch 3, Val Loss: 5.33324
Epoch 4, Val Loss: 5.25538
Epoch 5, Val Loss: 5.15120
Epoch 6, Val Loss: 5.03479
Epoch 7, Val Loss: 5.13294
Epoch 8, Val Loss: 4.74671
Epoch 9, Val Loss: 4.76058
Epoch 10, Val Loss: 4.79953
Epoch 11, Val Loss: 4.97571
Epoch 12, Val Loss: 4.63289
Epoch 13, Val Loss: 4.61890
Epoch 14, Val Loss: 4.49101
Epoch 15, Val Loss: 4.53941
Epoch 16, Val Loss: 4.46097
Epoch 17, Val Loss: 4.41653
Epoch 18, Val Loss: 4.50530
Epoch 19, Val Loss: 4.49680
Epoch 20, Val Loss: 4.51295
Epoch 21, Val Loss: 4.43676
Epoch 22, Val Loss: 4.71693
Epoch 23, Val Loss: 4.32163
Epoch 24, Val Loss: 4.21538
Epoch 25, Val Loss: 4.92868
Epoch 26, Val Loss: 4.79966
Epoch 27, Val Loss: 4.21774
Epoch 28, Val Loss: 4.36014
Epoch 29, Val Loss: 4.32821
Epoch 30, Val Loss: 4.17380
Epoch 31, Val Loss: 4.37395
Epoch 32, Val Loss: 4.35313
Epoch 33, Val Loss: 4.07286
Epoch 34, Val Loss: 4.27931
Epoch 35, Val Loss: 4.08751
Epoch 36, Val Loss: 4.03464
Epoch 37, Val Loss: 4.12160
Epoch 38, Val Loss: 4.01439
Epoch 39, Val Loss: 4.06213
Epoch 40, Val Loss: 4.13835
Epoch 41, Val Loss: 4.20006
Epoch 42, Val Loss: 4.25757
Epoch 43, Val Loss: 4.14301
Epoch 44, Val Loss: 4.13154
Epoch 45, Val Loss: 4.50856
Epoch 46, Val Loss: 3.99503
Epoch 47, Val Loss: 4.13408
Epoch 48, Val Loss: 4.15764
Epoch 49, Val Loss: 4.05742
Epoch 50, Val Loss: 3.96046
Epoch 51, Val Loss: 4.24343
Epoch 52, Val Loss: 4.16000
Epoch 53, Val Loss: 3.92588
Epoch 54, Val Loss: 4.19368
Epoch 55, Val Loss: 3.92652
Epoch 56, Val Loss: 4.08143
Epoch 57, Val Loss: 3.92723
Epoch 58, Val Loss: 4.02605
Epoch 59, Val Loss: 4.00563
Epoch 60, Val Loss: 4.15698
Epoch 61, Val Loss: 4.02756
Epoch 62, Val Loss: 4.02271
Epoch 63, Val Loss: 3.99737
Epoch 64, Val Loss: 4.04143
Epoch 65, Val Loss: 4.13358
Epoch 66, Val Loss: 4.11100
Epoch 67, Val Loss: 3.99023
Epoch 68, Val Loss: 4.17221
Epoch 69, Val Loss: 4.31341
Epoch 70, Val Loss: 4.00013
Epoch 71, Val Loss: 4.12448
Epoch 72, Val Loss: 4.22196
Epoch 73, Val Loss: 3.94485
Epoch 74, Val Loss: 4.01926
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.554427980231504, 'MSE - std': 0.4576637743791956, 'R2 - mean': 0.5531064033336295, 'R2 - std': 0.010192609683403742} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.01534
Epoch 1, Val Loss: 15.10210
Epoch 2, Val Loss: 7.05509
Epoch 3, Val Loss: 6.33231
Epoch 4, Val Loss: 6.28306
Epoch 5, Val Loss: 6.27900
Epoch 6, Val Loss: 6.51807
Epoch 7, Val Loss: 6.18711
Epoch 8, Val Loss: 5.99804
Epoch 9, Val Loss: 6.43346
Epoch 10, Val Loss: 5.90503
Epoch 11, Val Loss: 5.92113
Epoch 12, Val Loss: 5.86431
Epoch 13, Val Loss: 5.90448
Epoch 14, Val Loss: 6.15861
Epoch 15, Val Loss: 5.70763
Epoch 16, Val Loss: 5.75352
Epoch 17, Val Loss: 5.80645
Epoch 18, Val Loss: 5.66547
Epoch 19, Val Loss: 5.53840
Epoch 20, Val Loss: 5.70933
Epoch 21, Val Loss: 5.64826
Epoch 22, Val Loss: 5.55115
Epoch 23, Val Loss: 5.52949
Epoch 24, Val Loss: 5.42726
Epoch 25, Val Loss: 5.45002
Epoch 26, Val Loss: 5.61344
Epoch 27, Val Loss: 5.67890
Epoch 28, Val Loss: 5.33676
Epoch 29, Val Loss: 5.28639
Epoch 30, Val Loss: 6.19223
Epoch 31, Val Loss: 5.24450
Epoch 32, Val Loss: 5.39900
Epoch 33, Val Loss: 5.75109
Epoch 34, Val Loss: 5.21416
Epoch 35, Val Loss: 5.22081
Epoch 36, Val Loss: 5.21484
Epoch 37, Val Loss: 5.49668
Epoch 38, Val Loss: 5.23981
Epoch 39, Val Loss: 5.14116
Epoch 40, Val Loss: 5.04541
Epoch 41, Val Loss: 4.89453
Epoch 42, Val Loss: 4.89460
Epoch 43, Val Loss: 4.85367
Epoch 44, Val Loss: 5.05758
Epoch 45, Val Loss: 4.79649
Epoch 46, Val Loss: 4.77781
Epoch 47, Val Loss: 5.15083
Epoch 48, Val Loss: 4.66830
Epoch 49, Val Loss: 4.86522
Epoch 50, Val Loss: 4.74816
Epoch 51, Val Loss: 4.94538
Epoch 52, Val Loss: 4.78162
Epoch 53, Val Loss: 4.75124
Epoch 54, Val Loss: 4.87189
Epoch 55, Val Loss: 4.65630
Epoch 56, Val Loss: 4.98107
Epoch 57, Val Loss: 4.63204
Epoch 58, Val Loss: 5.40643
Epoch 59, Val Loss: 5.27976
Epoch 60, Val Loss: 4.79161
Epoch 61, Val Loss: 4.59249
Epoch 62, Val Loss: 4.68556
Epoch 63, Val Loss: 4.69095
Epoch 64, Val Loss: 5.46162
Epoch 65, Val Loss: 4.68746
Epoch 66, Val Loss: 5.17469
Epoch 67, Val Loss: 4.62413
Epoch 68, Val Loss: 5.07772
Epoch 69, Val Loss: 4.77547
Epoch 70, Val Loss: 4.47590
Epoch 71, Val Loss: 4.95978
Epoch 72, Val Loss: 4.71774
Epoch 73, Val Loss: 4.69764
Epoch 74, Val Loss: 4.66440
Epoch 75, Val Loss: 4.76564
Epoch 76, Val Loss: 4.61863
Epoch 77, Val Loss: 4.49851
Epoch 78, Val Loss: 4.49240
Epoch 79, Val Loss: 4.51720
Epoch 80, Val Loss: 4.52291
Epoch 81, Val Loss: 4.56516
Epoch 82, Val Loss: 4.47634
Epoch 83, Val Loss: 4.46812
Epoch 84, Val Loss: 4.65129
Epoch 85, Val Loss: 4.56976
Epoch 86, Val Loss: 4.51147
Epoch 87, Val Loss: 4.49395
Epoch 88, Val Loss: 4.55613
Epoch 89, Val Loss: 5.49746
Epoch 90, Val Loss: 4.59250
Epoch 91, Val Loss: 4.54144
Epoch 92, Val Loss: 4.49936
Epoch 93, Val Loss: 4.77970
Epoch 94, Val Loss: 4.47654
Epoch 95, Val Loss: 4.55622
Epoch 96, Val Loss: 4.46463
Epoch 97, Val Loss: 5.21720
Epoch 98, Val Loss: 5.10430
Epoch 99, Val Loss: 4.59858
DID NOT SAVE RESULTS
{'MSE - mean': 4.538971996446106, 'MSE - std': 0.3743196429820684, 'R2 - mean': 0.5542085298931014, 'R2 - std': 0.008466929432306865} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.34506
Epoch 1, Val Loss: 9.98677
Epoch 2, Val Loss: 6.36925
Epoch 3, Val Loss: 5.61709
Epoch 4, Val Loss: 5.54942
Epoch 5, Val Loss: 5.37139
Epoch 6, Val Loss: 5.41414
Epoch 7, Val Loss: 5.14953
Epoch 8, Val Loss: 5.19581
Epoch 9, Val Loss: 4.96684
Epoch 10, Val Loss: 4.96008
Epoch 11, Val Loss: 5.07538
Epoch 12, Val Loss: 4.87378
Epoch 13, Val Loss: 4.80966
Epoch 14, Val Loss: 5.19215
Epoch 15, Val Loss: 4.92565
Epoch 16, Val Loss: 4.72931
Epoch 17, Val Loss: 4.79616
Epoch 18, Val Loss: 4.92953
Epoch 19, Val Loss: 4.70897
Epoch 20, Val Loss: 4.79519
Epoch 21, Val Loss: 4.66556
Epoch 22, Val Loss: 4.63992
Epoch 23, Val Loss: 4.62827
Epoch 24, Val Loss: 4.73705
Epoch 25, Val Loss: 4.63256
Epoch 26, Val Loss: 4.57378
Epoch 27, Val Loss: 4.70332
Epoch 28, Val Loss: 4.57103
Epoch 29, Val Loss: 4.64492
Epoch 30, Val Loss: 4.62387
Epoch 31, Val Loss: 4.62415
Epoch 32, Val Loss: 5.47315
Epoch 33, Val Loss: 4.56965
Epoch 34, Val Loss: 4.53138
Epoch 35, Val Loss: 4.70024
Epoch 36, Val Loss: 4.70535
Epoch 37, Val Loss: 4.56564
Epoch 38, Val Loss: 4.45440
Epoch 39, Val Loss: 4.65561
Epoch 40, Val Loss: 4.47946
Epoch 41, Val Loss: 4.79137
Epoch 42, Val Loss: 4.45012
Epoch 43, Val Loss: 4.64246
Epoch 44, Val Loss: 4.69603
Epoch 45, Val Loss: 4.45603
Epoch 46, Val Loss: 4.48794
Epoch 47, Val Loss: 4.62100
Epoch 48, Val Loss: 4.41406
Epoch 49, Val Loss: 4.48444
Epoch 50, Val Loss: 4.46460
Epoch 51, Val Loss: 4.69599
Epoch 52, Val Loss: 4.42251
Epoch 53, Val Loss: 4.49326
Epoch 54, Val Loss: 4.31264
Epoch 55, Val Loss: 4.33350
Epoch 56, Val Loss: 4.35267
Epoch 57, Val Loss: 4.52134
Epoch 58, Val Loss: 4.30428
Epoch 59, Val Loss: 4.21850
Epoch 60, Val Loss: 4.44916
Epoch 61, Val Loss: 4.36311
Epoch 62, Val Loss: 4.49591
Epoch 63, Val Loss: 4.25696
Epoch 64, Val Loss: 4.55949
Epoch 65, Val Loss: 4.31689
Epoch 66, Val Loss: 4.35757
Epoch 67, Val Loss: 4.44207
Epoch 68, Val Loss: 4.49623
Epoch 69, Val Loss: 4.36462
Epoch 70, Val Loss: 4.39336
Epoch 71, Val Loss: 4.24487
Epoch 72, Val Loss: 4.21326
Epoch 73, Val Loss: 4.20201
Epoch 74, Val Loss: 4.70139
Epoch 75, Val Loss: 4.13027
Epoch 76, Val Loss: 4.57777
Epoch 77, Val Loss: 4.19909
Epoch 78, Val Loss: 4.47632
Epoch 79, Val Loss: 4.18939
Epoch 80, Val Loss: 4.18935
Epoch 81, Val Loss: 4.34803
Epoch 82, Val Loss: 4.20237
Epoch 83, Val Loss: 4.20910
Epoch 84, Val Loss: 4.18089
Epoch 85, Val Loss: 4.18867
Epoch 86, Val Loss: 4.43034
Epoch 87, Val Loss: 4.20836
Epoch 88, Val Loss: 4.10198
Epoch 89, Val Loss: 4.56575
Epoch 90, Val Loss: 4.23614
Epoch 91, Val Loss: 4.17919
Epoch 92, Val Loss: 4.19506
Epoch 93, Val Loss: 4.61807
Epoch 94, Val Loss: 4.17696
Epoch 95, Val Loss: 4.11282
Epoch 96, Val Loss: 4.28334
Epoch 97, Val Loss: 4.18270
Epoch 98, Val Loss: 4.11243
Epoch 99, Val Loss: 4.18761
DID NOT SAVE RESULTS
{'MSE - mean': 4.516872520955601, 'MSE - std': 0.32642235951682863, 'R2 - mean': 0.5466919862027355, 'R2 - std': 0.014941952939836552} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 45.03834
Epoch 1, Val Loss: 14.77366
Epoch 2, Val Loss: 8.36522
Epoch 3, Val Loss: 7.53257
Epoch 4, Val Loss: 7.36269
Epoch 5, Val Loss: 8.30377
Epoch 6, Val Loss: 7.60704
Epoch 7, Val Loss: 7.23981
Epoch 8, Val Loss: 7.10700
Epoch 9, Val Loss: 7.28050
Epoch 10, Val Loss: 7.05256
Epoch 11, Val Loss: 6.96879
Epoch 12, Val Loss: 6.91994
Epoch 13, Val Loss: 6.69066
Epoch 14, Val Loss: 6.87315
Epoch 15, Val Loss: 6.66450
Epoch 16, Val Loss: 6.65570
Epoch 17, Val Loss: 6.67571
Epoch 18, Val Loss: 6.50982
Epoch 19, Val Loss: 6.56729
Epoch 20, Val Loss: 6.37953
Epoch 21, Val Loss: 6.42921
Epoch 22, Val Loss: 6.53806
Epoch 23, Val Loss: 6.70407
Epoch 24, Val Loss: 6.34671
Epoch 25, Val Loss: 6.22573
Epoch 26, Val Loss: 6.28787
Epoch 27, Val Loss: 6.37334
Epoch 28, Val Loss: 6.65651
Epoch 29, Val Loss: 6.21667
Epoch 30, Val Loss: 6.23254
Epoch 31, Val Loss: 6.20378
Epoch 32, Val Loss: 6.28430
Epoch 33, Val Loss: 6.04932
Epoch 34, Val Loss: 6.00211
Epoch 35, Val Loss: 5.97215
Epoch 36, Val Loss: 6.10987
Epoch 37, Val Loss: 6.06017
Epoch 38, Val Loss: 5.96206
Epoch 39, Val Loss: 6.16621
Epoch 40, Val Loss: 6.11208
Epoch 41, Val Loss: 6.60399
Epoch 42, Val Loss: 6.36566
Epoch 43, Val Loss: 5.98770
Epoch 44, Val Loss: 5.90419
Epoch 45, Val Loss: 5.78587
Epoch 46, Val Loss: 5.92144
Epoch 47, Val Loss: 5.95741
Epoch 48, Val Loss: 6.07103
Epoch 49, Val Loss: 5.85073
Epoch 50, Val Loss: 6.02158
Epoch 51, Val Loss: 6.05390
Epoch 52, Val Loss: 5.92745
Epoch 53, Val Loss: 5.74868
Epoch 54, Val Loss: 5.96449
Epoch 55, Val Loss: 5.90734
Epoch 56, Val Loss: 5.87719
Epoch 57, Val Loss: 5.87364
Epoch 58, Val Loss: 5.81401
Epoch 59, Val Loss: 6.06800
Epoch 60, Val Loss: 5.82790
Epoch 61, Val Loss: 5.79000
Epoch 62, Val Loss: 6.00814
Epoch 63, Val Loss: 5.86431
Epoch 64, Val Loss: 6.04614
Epoch 65, Val Loss: 5.99992
Epoch 66, Val Loss: 5.84959
Epoch 67, Val Loss: 5.94747
Epoch 68, Val Loss: 5.80809
Epoch 69, Val Loss: 6.04479
Epoch 70, Val Loss: 5.79148
Epoch 71, Val Loss: 5.81143
Epoch 72, Val Loss: 5.85350
Epoch 73, Val Loss: 5.87209
Epoch 74, Val Loss: 5.90146
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.755716402196082, 'MSE - std': 0.5598453749546353, 'R2 - mean': 0.5428924883530002, 'R2 - std': 0.015373818711224875} 
 

Results After CV: {'MSE - mean': 4.755716402196082, 'MSE - std': 0.5598453749546353, 'R2 - mean': 0.5428924883530002, 'R2 - std': 0.015373818711224875}
Train time: 89.78273847199962
Inference time: 0.051690064599824836
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 46 finished with value: 4.755716402196082 and parameters: {'p_m': 0.7659381161445131, 'alpha': 1.6100576838218073, 'K': 15, 'beta': 1.8235700242145958}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.72429
Epoch 1, Val Loss: 11.39074
Epoch 2, Val Loss: 8.04519
Epoch 3, Val Loss: 6.93787
Epoch 4, Val Loss: 6.95600
Epoch 5, Val Loss: 7.05838
Epoch 6, Val Loss: 7.01818
Epoch 7, Val Loss: 6.45409
Epoch 8, Val Loss: 6.34505
Epoch 9, Val Loss: 6.17926
Epoch 10, Val Loss: 6.28928
Epoch 11, Val Loss: 6.20967
Epoch 12, Val Loss: 6.20340
Epoch 13, Val Loss: 6.25078
Epoch 14, Val Loss: 5.97648
Epoch 15, Val Loss: 5.98530
Epoch 16, Val Loss: 5.96623
Epoch 17, Val Loss: 5.91149
Epoch 18, Val Loss: 5.81506
Epoch 19, Val Loss: 5.99043
Epoch 20, Val Loss: 5.81109
Epoch 21, Val Loss: 6.23425
Epoch 22, Val Loss: 5.84436
Epoch 23, Val Loss: 5.78005
Epoch 24, Val Loss: 5.85039
Epoch 25, Val Loss: 5.90671
Epoch 26, Val Loss: 5.61802
Epoch 27, Val Loss: 5.95213
Epoch 28, Val Loss: 5.66871
Epoch 29, Val Loss: 5.59097
Epoch 30, Val Loss: 5.49733
Epoch 31, Val Loss: 5.54465
Epoch 32, Val Loss: 5.45376
Epoch 33, Val Loss: 5.61419
Epoch 34, Val Loss: 5.43812
Epoch 35, Val Loss: 5.49573
Epoch 36, Val Loss: 5.51909
Epoch 37, Val Loss: 5.32743
Epoch 38, Val Loss: 5.36678
Epoch 39, Val Loss: 5.50439
Epoch 40, Val Loss: 5.46329
Epoch 41, Val Loss: 5.52656
Epoch 42, Val Loss: 5.51312
Epoch 43, Val Loss: 5.53852
Epoch 44, Val Loss: 5.36163
Epoch 45, Val Loss: 5.19740
Epoch 46, Val Loss: 5.08505
Epoch 47, Val Loss: 5.83951
Epoch 48, Val Loss: 5.22676
Epoch 49, Val Loss: 5.18565
Epoch 50, Val Loss: 5.03993
Epoch 51, Val Loss: 5.06476
Epoch 52, Val Loss: 5.24991
Epoch 53, Val Loss: 4.94801
Epoch 54, Val Loss: 4.99989
Epoch 55, Val Loss: 5.34202
Epoch 56, Val Loss: 4.85267
Epoch 57, Val Loss: 5.04870
Epoch 58, Val Loss: 4.89587
Epoch 59, Val Loss: 4.95676
Epoch 60, Val Loss: 5.11017
Epoch 61, Val Loss: 4.87579
Epoch 62, Val Loss: 4.96208
Epoch 63, Val Loss: 4.77427
Epoch 64, Val Loss: 4.97570
Epoch 65, Val Loss: 4.82304
Epoch 66, Val Loss: 5.24117
Epoch 67, Val Loss: 4.91832
Epoch 68, Val Loss: 4.82267
Epoch 69, Val Loss: 5.26659
Epoch 70, Val Loss: 4.83619
Epoch 71, Val Loss: 4.81758
Epoch 72, Val Loss: 4.73319
Epoch 73, Val Loss: 4.97355
Epoch 74, Val Loss: 4.86298
Epoch 75, Val Loss: 4.89244
Epoch 76, Val Loss: 4.68825
Epoch 77, Val Loss: 4.97356
Epoch 78, Val Loss: 4.75955
Epoch 79, Val Loss: 4.92259
Epoch 80, Val Loss: 4.80322
Epoch 81, Val Loss: 4.67294
Epoch 82, Val Loss: 4.78200
Epoch 83, Val Loss: 4.67724
Epoch 84, Val Loss: 5.02045
Epoch 85, Val Loss: 4.90219
Epoch 86, Val Loss: 4.75654
Epoch 87, Val Loss: 4.90511
Epoch 88, Val Loss: 4.76790
Epoch 89, Val Loss: 4.65787
Epoch 90, Val Loss: 4.65226
Epoch 91, Val Loss: 4.75043
Epoch 92, Val Loss: 4.68351
Epoch 93, Val Loss: 4.75865
Epoch 94, Val Loss: 4.80698
Epoch 95, Val Loss: 4.76358
Epoch 96, Val Loss: 4.96104
Epoch 97, Val Loss: 5.37102
Epoch 98, Val Loss: 4.67223
Epoch 99, Val Loss: 4.73924
DID NOT SAVE RESULTS
{'MSE - mean': 4.799073713496246, 'MSE - std': 0.0, 'R2 - mean': 0.5623403351151732, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.89682
Epoch 1, Val Loss: 9.84861
Epoch 2, Val Loss: 6.08855
Epoch 3, Val Loss: 6.34841
Epoch 4, Val Loss: 5.74777
Epoch 5, Val Loss: 5.60037
Epoch 6, Val Loss: 5.41222
Epoch 7, Val Loss: 5.28275
Epoch 8, Val Loss: 5.25694
Epoch 9, Val Loss: 5.37309
Epoch 10, Val Loss: 5.44941
Epoch 11, Val Loss: 5.32995
Epoch 12, Val Loss: 5.24977
Epoch 13, Val Loss: 5.09492
Epoch 14, Val Loss: 5.41436
Epoch 15, Val Loss: 4.94493
Epoch 16, Val Loss: 5.09026
Epoch 17, Val Loss: 5.40674
Epoch 18, Val Loss: 5.05564
Epoch 19, Val Loss: 4.88022
Epoch 20, Val Loss: 4.92967
Epoch 21, Val Loss: 4.80772
Epoch 22, Val Loss: 5.03507
Epoch 23, Val Loss: 4.93364
Epoch 24, Val Loss: 4.87216
Epoch 25, Val Loss: 4.78570
Epoch 26, Val Loss: 4.65000
Epoch 27, Val Loss: 4.76588
Epoch 28, Val Loss: 4.79202
Epoch 29, Val Loss: 4.66465
Epoch 30, Val Loss: 4.58621
Epoch 31, Val Loss: 4.97827
Epoch 32, Val Loss: 5.34219
Epoch 33, Val Loss: 4.56324
Epoch 34, Val Loss: 4.51578
Epoch 35, Val Loss: 4.92274
Epoch 36, Val Loss: 4.42108
Epoch 37, Val Loss: 4.39117
Epoch 38, Val Loss: 4.50786
Epoch 39, Val Loss: 4.47560
Epoch 40, Val Loss: 4.67246
Epoch 41, Val Loss: 4.37590
Epoch 42, Val Loss: 4.64012
Epoch 43, Val Loss: 4.42372
Epoch 44, Val Loss: 5.03708
Epoch 45, Val Loss: 4.63487
Epoch 46, Val Loss: 4.35084
Epoch 47, Val Loss: 4.81814
Epoch 48, Val Loss: 4.88548
Epoch 49, Val Loss: 4.19320
Epoch 50, Val Loss: 4.19632
Epoch 51, Val Loss: 4.38335
Epoch 52, Val Loss: 4.23087
Epoch 53, Val Loss: 4.15361
Epoch 54, Val Loss: 4.19454
Epoch 55, Val Loss: 4.20050
Epoch 56, Val Loss: 4.09577
Epoch 57, Val Loss: 4.17154
Epoch 58, Val Loss: 4.09977
Epoch 59, Val Loss: 4.00367
Epoch 60, Val Loss: 4.10605
Epoch 61, Val Loss: 4.05506
Epoch 62, Val Loss: 4.09536
Epoch 63, Val Loss: 3.97359
Epoch 64, Val Loss: 3.95788
Epoch 65, Val Loss: 4.13799
Epoch 66, Val Loss: 3.95720
Epoch 67, Val Loss: 4.08834
Epoch 68, Val Loss: 4.15094
Epoch 69, Val Loss: 4.47728
Epoch 70, Val Loss: 4.41086
Epoch 71, Val Loss: 4.18632
Epoch 72, Val Loss: 4.68047
Epoch 73, Val Loss: 3.97536
Epoch 74, Val Loss: 4.02211
Epoch 75, Val Loss: 4.20970
Epoch 76, Val Loss: 4.04585
Epoch 77, Val Loss: 4.00991
Epoch 78, Val Loss: 4.04315
Epoch 79, Val Loss: 4.09516
Epoch 80, Val Loss: 3.92138
Epoch 81, Val Loss: 4.10077
Epoch 82, Val Loss: 3.98109
Epoch 83, Val Loss: 4.06887
Epoch 84, Val Loss: 4.11761
Epoch 85, Val Loss: 4.18237
Epoch 86, Val Loss: 3.95941
Epoch 87, Val Loss: 4.01592
Epoch 88, Val Loss: 4.37005
Epoch 89, Val Loss: 4.32891
Epoch 90, Val Loss: 4.40955
Epoch 91, Val Loss: 4.64329
Epoch 92, Val Loss: 4.91197
Epoch 93, Val Loss: 4.19896
Epoch 94, Val Loss: 4.11327
Epoch 95, Val Loss: 4.23825
Epoch 96, Val Loss: 4.12411
Epoch 97, Val Loss: 4.02217
Epoch 98, Val Loss: 4.14553
Epoch 99, Val Loss: 4.53948
DID NOT SAVE RESULTS
{'MSE - mean': 4.464714097631072, 'MSE - std': 0.33435961586517404, 'R2 - mean': 0.5610293700716068, 'R2 - std': 0.0013109650435664255} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.41940
Epoch 1, Val Loss: 10.94661
Epoch 2, Val Loss: 7.43528
Epoch 3, Val Loss: 6.83991
Epoch 4, Val Loss: 6.51162
Epoch 5, Val Loss: 6.38890
Epoch 6, Val Loss: 6.35721
Epoch 7, Val Loss: 6.38418
Epoch 8, Val Loss: 6.57506
Epoch 9, Val Loss: 6.30463
Epoch 10, Val Loss: 6.20218
Epoch 11, Val Loss: 6.24420
Epoch 12, Val Loss: 6.04472
Epoch 13, Val Loss: 5.95027
Epoch 14, Val Loss: 5.96405
Epoch 15, Val Loss: 6.04134
Epoch 16, Val Loss: 5.98530
Epoch 17, Val Loss: 6.61046
Epoch 18, Val Loss: 6.12693
Epoch 19, Val Loss: 5.92722
Epoch 20, Val Loss: 5.73587
Epoch 21, Val Loss: 6.00554
Epoch 22, Val Loss: 6.16564
Epoch 23, Val Loss: 5.76124
Epoch 24, Val Loss: 5.90063
Epoch 25, Val Loss: 5.69239
Epoch 26, Val Loss: 5.60079
Epoch 27, Val Loss: 5.63168
Epoch 28, Val Loss: 5.65647
Epoch 29, Val Loss: 5.79807
Epoch 30, Val Loss: 5.44821
Epoch 31, Val Loss: 5.68441
Epoch 32, Val Loss: 5.45867
Epoch 33, Val Loss: 5.42672
Epoch 34, Val Loss: 5.43655
Epoch 35, Val Loss: 5.37247
Epoch 36, Val Loss: 5.54319
Epoch 37, Val Loss: 5.47034
Epoch 38, Val Loss: 5.59992
Epoch 39, Val Loss: 5.45531
Epoch 40, Val Loss: 5.21614
Epoch 41, Val Loss: 5.33556
Epoch 42, Val Loss: 5.50154
Epoch 43, Val Loss: 5.24528
Epoch 44, Val Loss: 5.22367
Epoch 45, Val Loss: 5.19971
Epoch 46, Val Loss: 5.03858
Epoch 47, Val Loss: 5.22276
Epoch 48, Val Loss: 5.08180
Epoch 49, Val Loss: 5.28284
Epoch 50, Val Loss: 5.05095
Epoch 51, Val Loss: 4.95272
Epoch 52, Val Loss: 5.20729
Epoch 53, Val Loss: 5.30902
Epoch 54, Val Loss: 5.07131
Epoch 55, Val Loss: 4.94394
Epoch 56, Val Loss: 4.89246
Epoch 57, Val Loss: 5.03960
Epoch 58, Val Loss: 5.07385
Epoch 59, Val Loss: 5.52938
Epoch 60, Val Loss: 4.90126
Epoch 61, Val Loss: 4.91526
Epoch 62, Val Loss: 4.95738
Epoch 63, Val Loss: 4.94499
Epoch 64, Val Loss: 4.91390
Epoch 65, Val Loss: 4.95294
Epoch 66, Val Loss: 4.94350
Epoch 67, Val Loss: 4.90879
Epoch 68, Val Loss: 4.89329
Epoch 69, Val Loss: 5.65024
Epoch 70, Val Loss: 4.89454
Epoch 71, Val Loss: 4.84109
Epoch 72, Val Loss: 5.48573
Epoch 73, Val Loss: 5.01039
Epoch 74, Val Loss: 5.19769
Epoch 75, Val Loss: 4.76957
Epoch 76, Val Loss: 4.82273
Epoch 77, Val Loss: 4.81075
Epoch 78, Val Loss: 4.64543
Epoch 79, Val Loss: 4.94691
Epoch 80, Val Loss: 4.76507
Epoch 81, Val Loss: 4.78005
Epoch 82, Val Loss: 4.75831
Epoch 83, Val Loss: 4.66322
Epoch 84, Val Loss: 4.85511
Epoch 85, Val Loss: 5.14709
Epoch 86, Val Loss: 4.89054
Epoch 87, Val Loss: 4.69968
Epoch 88, Val Loss: 4.87197
Epoch 89, Val Loss: 4.81250
Epoch 90, Val Loss: 4.76869
Epoch 91, Val Loss: 4.78078
Epoch 92, Val Loss: 4.77036
Epoch 93, Val Loss: 4.91520
Epoch 94, Val Loss: 4.85144
Epoch 95, Val Loss: 5.12165
Epoch 96, Val Loss: 4.86342
Epoch 97, Val Loss: 4.64214
Epoch 98, Val Loss: 4.66232
Epoch 99, Val Loss: 4.64463
DID NOT SAVE RESULTS
{'MSE - mean': 4.546310536774747, 'MSE - std': 0.2963897089579746, 'R2 - mean': 0.5528832523811743, 'R2 - std': 0.011569970602802952} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.20720
Epoch 1, Val Loss: 11.17570
Epoch 2, Val Loss: 6.93483
Epoch 3, Val Loss: 6.50047
Epoch 4, Val Loss: 5.48185
Epoch 5, Val Loss: 5.24998
Epoch 6, Val Loss: 5.11125
Epoch 7, Val Loss: 5.10461
Epoch 8, Val Loss: 5.00139
Epoch 9, Val Loss: 4.97373
Epoch 10, Val Loss: 4.97821
Epoch 11, Val Loss: 4.99874
Epoch 12, Val Loss: 4.93716
Epoch 13, Val Loss: 4.90117
Epoch 14, Val Loss: 4.77264
Epoch 15, Val Loss: 4.79449
Epoch 16, Val Loss: 4.77324
Epoch 17, Val Loss: 4.84229
Epoch 18, Val Loss: 4.67769
Epoch 19, Val Loss: 4.87944
Epoch 20, Val Loss: 4.67143
Epoch 21, Val Loss: 4.68232
Epoch 22, Val Loss: 4.72144
Epoch 23, Val Loss: 4.74352
Epoch 24, Val Loss: 4.54424
Epoch 25, Val Loss: 4.57545
Epoch 26, Val Loss: 4.53147
Epoch 27, Val Loss: 4.97888
Epoch 28, Val Loss: 4.48783
Epoch 29, Val Loss: 4.97790
Epoch 30, Val Loss: 4.45931
Epoch 31, Val Loss: 4.52681
Epoch 32, Val Loss: 4.39648
Epoch 33, Val Loss: 4.39291
Epoch 34, Val Loss: 4.43615
Epoch 35, Val Loss: 4.41063
Epoch 36, Val Loss: 4.43739
Epoch 37, Val Loss: 4.35715
Epoch 38, Val Loss: 4.48526
Epoch 39, Val Loss: 4.36177
Epoch 40, Val Loss: 4.34107
Epoch 41, Val Loss: 4.38626
Epoch 42, Val Loss: 4.27138
Epoch 43, Val Loss: 4.59046
Epoch 44, Val Loss: 4.33399
Epoch 45, Val Loss: 4.28382
Epoch 46, Val Loss: 4.32025
Epoch 47, Val Loss: 4.54311
Epoch 48, Val Loss: 4.30126
Epoch 49, Val Loss: 4.42777
Epoch 50, Val Loss: 4.20634
Epoch 51, Val Loss: 4.30119
Epoch 52, Val Loss: 4.41145
Epoch 53, Val Loss: 4.59715
Epoch 54, Val Loss: 4.29101
Epoch 55, Val Loss: 4.22581
Epoch 56, Val Loss: 4.19119
Epoch 57, Val Loss: 4.15386
Epoch 58, Val Loss: 4.14753
Epoch 59, Val Loss: 4.24308
Epoch 60, Val Loss: 4.43031
Epoch 61, Val Loss: 4.11512
Epoch 62, Val Loss: 4.05748
Epoch 63, Val Loss: 4.12434
Epoch 64, Val Loss: 4.28973
Epoch 65, Val Loss: 4.08500
Epoch 66, Val Loss: 4.13489
Epoch 67, Val Loss: 4.09064
Epoch 68, Val Loss: 4.06416
Epoch 69, Val Loss: 4.03082
Epoch 70, Val Loss: 4.20921
Epoch 71, Val Loss: 4.28897
Epoch 72, Val Loss: 3.98101
Epoch 73, Val Loss: 4.02422
Epoch 74, Val Loss: 4.01678
Epoch 75, Val Loss: 4.20882
Epoch 76, Val Loss: 3.98322
Epoch 77, Val Loss: 4.05700
Epoch 78, Val Loss: 4.03716
Epoch 79, Val Loss: 4.06105
Epoch 80, Val Loss: 3.93068
Epoch 81, Val Loss: 4.02486
Epoch 82, Val Loss: 4.14170
Epoch 83, Val Loss: 4.12025
Epoch 84, Val Loss: 3.99941
Epoch 85, Val Loss: 5.12589
Epoch 86, Val Loss: 4.02502
Epoch 87, Val Loss: 3.88084
Epoch 88, Val Loss: 3.89767
Epoch 89, Val Loss: 3.94993
Epoch 90, Val Loss: 3.87961
Epoch 91, Val Loss: 4.34378
Epoch 92, Val Loss: 4.02966
Epoch 93, Val Loss: 4.03164
Epoch 94, Val Loss: 4.01169
Epoch 95, Val Loss: 4.29129
Epoch 96, Val Loss: 4.00355
Epoch 97, Val Loss: 3.94090
Epoch 98, Val Loss: 3.91784
Epoch 99, Val Loss: 4.04288
DID NOT SAVE RESULTS
{'MSE - mean': 4.457159106840837, 'MSE - std': 0.29954812144282805, 'R2 - mean': 0.5526710970115885, 'R2 - std': 0.010026624283118709} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.09822
Epoch 1, Val Loss: 20.00845
Epoch 2, Val Loss: 9.70422
Epoch 3, Val Loss: 8.22025
Epoch 4, Val Loss: 7.87747
Epoch 5, Val Loss: 7.62292
Epoch 6, Val Loss: 7.57087
Epoch 7, Val Loss: 7.46561
Epoch 8, Val Loss: 7.36637
Epoch 9, Val Loss: 7.15126
Epoch 10, Val Loss: 7.05976
Epoch 11, Val Loss: 7.11122
Epoch 12, Val Loss: 7.11242
Epoch 13, Val Loss: 6.98103
Epoch 14, Val Loss: 6.80169
Epoch 15, Val Loss: 7.10537
Epoch 16, Val Loss: 6.82186
Epoch 17, Val Loss: 7.01916
Epoch 18, Val Loss: 6.73364
Epoch 19, Val Loss: 6.72839
Epoch 20, Val Loss: 6.81383
Epoch 21, Val Loss: 6.73368
Epoch 22, Val Loss: 6.64596
Epoch 23, Val Loss: 6.85798
Epoch 24, Val Loss: 6.85200
Epoch 25, Val Loss: 6.79633
Epoch 26, Val Loss: 6.66298
Epoch 27, Val Loss: 6.77708
Epoch 28, Val Loss: 6.47224
Epoch 29, Val Loss: 6.53917
Epoch 30, Val Loss: 6.82835
Epoch 31, Val Loss: 6.55385
Epoch 32, Val Loss: 6.53344
Epoch 33, Val Loss: 6.39310
Epoch 34, Val Loss: 6.55862
Epoch 35, Val Loss: 6.68177
Epoch 36, Val Loss: 6.45360
Epoch 37, Val Loss: 6.78773
Epoch 38, Val Loss: 6.65165
Epoch 39, Val Loss: 6.35975
Epoch 40, Val Loss: 6.49663
Epoch 41, Val Loss: 6.36669
Epoch 42, Val Loss: 6.35327
Epoch 43, Val Loss: 6.44981
Epoch 44, Val Loss: 6.29977
Epoch 45, Val Loss: 6.26782
Epoch 46, Val Loss: 6.26954
Epoch 47, Val Loss: 6.49588
Epoch 48, Val Loss: 6.26150
Epoch 49, Val Loss: 6.70029
Epoch 50, Val Loss: 6.30628
Epoch 51, Val Loss: 6.37691
Epoch 52, Val Loss: 6.53179
Epoch 53, Val Loss: 6.24614
Epoch 54, Val Loss: 6.35400
Epoch 55, Val Loss: 6.16971
Epoch 56, Val Loss: 6.19320
Epoch 57, Val Loss: 6.22318
Epoch 58, Val Loss: 6.07494
Epoch 59, Val Loss: 6.11121
Epoch 60, Val Loss: 5.96149
Epoch 61, Val Loss: 6.61659
Epoch 62, Val Loss: 6.07939
Epoch 63, Val Loss: 6.14699
Epoch 64, Val Loss: 6.02780
Epoch 65, Val Loss: 6.03376
Epoch 66, Val Loss: 6.31487
Epoch 67, Val Loss: 6.15001
Epoch 68, Val Loss: 6.26569
Epoch 69, Val Loss: 6.33869
Epoch 70, Val Loss: 6.80082
Epoch 71, Val Loss: 5.94136
Epoch 72, Val Loss: 6.05981
Epoch 73, Val Loss: 6.18945
Epoch 74, Val Loss: 5.94382
Epoch 75, Val Loss: 5.91188
Epoch 76, Val Loss: 6.20036
Epoch 77, Val Loss: 6.27329
Epoch 78, Val Loss: 5.89102
Epoch 79, Val Loss: 6.19172
Epoch 80, Val Loss: 5.96295
Epoch 81, Val Loss: 5.99271
Epoch 82, Val Loss: 6.00946
Epoch 83, Val Loss: 5.91092
Epoch 84, Val Loss: 6.12397
Epoch 85, Val Loss: 6.12032
Epoch 86, Val Loss: 6.03161
Epoch 87, Val Loss: 6.52461
Epoch 88, Val Loss: 6.15318
Epoch 89, Val Loss: 5.85936
Epoch 90, Val Loss: 5.85755
Epoch 91, Val Loss: 5.80752
Epoch 92, Val Loss: 6.32721
Epoch 93, Val Loss: 5.82292
Epoch 94, Val Loss: 6.12611
Epoch 95, Val Loss: 5.82077
Epoch 96, Val Loss: 6.04557
Epoch 97, Val Loss: 6.09868
Epoch 98, Val Loss: 6.51483
Epoch 99, Val Loss: 6.40011
DID NOT SAVE RESULTS
{'MSE - mean': 4.746702762294512, 'MSE - std': 0.6380637705604714, 'R2 - mean': 0.5444705777528741, 'R2 - std': 0.018692795940202303} 
 

Results After CV: {'MSE - mean': 4.746702762294512, 'MSE - std': 0.6380637705604714, 'R2 - mean': 0.5444705777528741, 'R2 - std': 0.018692795940202303}
Train time: 81.29162448080024
Inference time: 0.05289612999986275
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 47 finished with value: 4.746702762294512 and parameters: {'p_m': 0.899353753399585, 'alpha': 2.8299654831025887, 'K': 10, 'beta': 5.666082600802973}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.28185
Epoch 1, Val Loss: 9.32568
Epoch 2, Val Loss: 7.47828
Epoch 3, Val Loss: 7.47863
Epoch 4, Val Loss: 6.83339
Epoch 5, Val Loss: 6.67047
Epoch 6, Val Loss: 6.63777
Epoch 7, Val Loss: 6.74230
Epoch 8, Val Loss: 6.73883
Epoch 9, Val Loss: 6.61930
Epoch 10, Val Loss: 6.46671
Epoch 11, Val Loss: 6.56880
Epoch 12, Val Loss: 6.54701
Epoch 13, Val Loss: 6.33513
Epoch 14, Val Loss: 6.30857
Epoch 15, Val Loss: 6.51804
Epoch 16, Val Loss: 6.14450
Epoch 17, Val Loss: 6.12618
Epoch 18, Val Loss: 6.35539
Epoch 19, Val Loss: 6.06560
Epoch 20, Val Loss: 6.28380
Epoch 21, Val Loss: 5.99789
Epoch 22, Val Loss: 6.18081
Epoch 23, Val Loss: 6.25206
Epoch 24, Val Loss: 6.03973
Epoch 25, Val Loss: 5.93464
Epoch 26, Val Loss: 6.17398
Epoch 27, Val Loss: 6.36264
Epoch 28, Val Loss: 5.79654
Epoch 29, Val Loss: 6.48309
Epoch 30, Val Loss: 5.79315
Epoch 31, Val Loss: 5.94364
Epoch 32, Val Loss: 5.72685
Epoch 33, Val Loss: 5.85345
Epoch 34, Val Loss: 5.61038
Epoch 35, Val Loss: 5.75639
Epoch 36, Val Loss: 5.67125
Epoch 37, Val Loss: 5.82785
Epoch 38, Val Loss: 5.52182
Epoch 39, Val Loss: 6.14234
Epoch 40, Val Loss: 5.47589
Epoch 41, Val Loss: 5.85975
Epoch 42, Val Loss: 5.56186
Epoch 43, Val Loss: 5.62766
Epoch 44, Val Loss: 6.03082
Epoch 45, Val Loss: 5.51021
Epoch 46, Val Loss: 5.86104
Epoch 47, Val Loss: 5.72850
Epoch 48, Val Loss: 5.59221
Epoch 49, Val Loss: 5.40960
Epoch 50, Val Loss: 5.36605
Epoch 51, Val Loss: 5.51315
Epoch 52, Val Loss: 5.50112
Epoch 53, Val Loss: 5.31086
Epoch 54, Val Loss: 5.66398
Epoch 55, Val Loss: 5.50744
Epoch 56, Val Loss: 5.50854
Epoch 57, Val Loss: 6.11972
Epoch 58, Val Loss: 5.31168
Epoch 59, Val Loss: 5.31614
Epoch 60, Val Loss: 5.42430
Epoch 61, Val Loss: 5.79055
Epoch 62, Val Loss: 5.45718
Epoch 63, Val Loss: 5.28023
Epoch 64, Val Loss: 5.55459
Epoch 65, Val Loss: 5.17561
Epoch 66, Val Loss: 5.46997
Epoch 67, Val Loss: 5.29532
Epoch 68, Val Loss: 5.11849
Epoch 69, Val Loss: 5.12071
Epoch 70, Val Loss: 5.40370
Epoch 71, Val Loss: 5.05169
Epoch 72, Val Loss: 4.96553
Epoch 73, Val Loss: 5.32611
Epoch 74, Val Loss: 5.04784
Epoch 75, Val Loss: 5.20157
Epoch 76, Val Loss: 5.02114
Epoch 77, Val Loss: 5.18874
Epoch 78, Val Loss: 5.39431
Epoch 79, Val Loss: 5.03859
Epoch 80, Val Loss: 5.16645
Epoch 81, Val Loss: 5.25061
Epoch 82, Val Loss: 5.23600
Epoch 83, Val Loss: 5.04715
Epoch 84, Val Loss: 5.17437
Epoch 85, Val Loss: 5.20243
Epoch 86, Val Loss: 5.18326
Epoch 87, Val Loss: 5.47016
Epoch 88, Val Loss: 5.18210
Epoch 89, Val Loss: 4.86296
Epoch 90, Val Loss: 4.91794
Epoch 91, Val Loss: 5.36429
Epoch 92, Val Loss: 5.39996
Epoch 93, Val Loss: 4.89379
Epoch 94, Val Loss: 4.99617
Epoch 95, Val Loss: 4.89910
Epoch 96, Val Loss: 5.07590
Epoch 97, Val Loss: 4.96459
Epoch 98, Val Loss: 4.88037
Epoch 99, Val Loss: 5.00017
DID NOT SAVE RESULTS
{'MSE - mean': 5.063385814875983, 'MSE - std': 0.0, 'R2 - mean': 0.5382359448472053, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.95013
Epoch 1, Val Loss: 15.13644
Epoch 2, Val Loss: 6.23233
Epoch 3, Val Loss: 5.88050
Epoch 4, Val Loss: 5.82420
Epoch 5, Val Loss: 5.16399
Epoch 6, Val Loss: 5.22933
Epoch 7, Val Loss: 5.14050
Epoch 8, Val Loss: 5.08743
Epoch 9, Val Loss: 5.05204
Epoch 10, Val Loss: 5.36635
Epoch 11, Val Loss: 5.00782
Epoch 12, Val Loss: 5.30631
Epoch 13, Val Loss: 5.02365
Epoch 14, Val Loss: 5.19121
Epoch 15, Val Loss: 5.12607
Epoch 16, Val Loss: 5.02775
Epoch 17, Val Loss: 4.92960
Epoch 18, Val Loss: 5.15305
Epoch 19, Val Loss: 4.92607
Epoch 20, Val Loss: 4.83816
Epoch 21, Val Loss: 4.94117
Epoch 22, Val Loss: 4.76164
Epoch 23, Val Loss: 5.09028
Epoch 24, Val Loss: 4.80190
Epoch 25, Val Loss: 5.18838
Epoch 26, Val Loss: 4.80378
Epoch 27, Val Loss: 4.83559
Epoch 28, Val Loss: 4.72586
Epoch 29, Val Loss: 4.69421
Epoch 30, Val Loss: 4.93179
Epoch 31, Val Loss: 4.68700
Epoch 32, Val Loss: 4.81686
Epoch 33, Val Loss: 4.58795
Epoch 34, Val Loss: 4.60767
Epoch 35, Val Loss: 4.56921
Epoch 36, Val Loss: 4.57528
Epoch 37, Val Loss: 4.97300
Epoch 38, Val Loss: 4.56674
Epoch 39, Val Loss: 4.47221
Epoch 40, Val Loss: 5.25236
Epoch 41, Val Loss: 4.48851
Epoch 42, Val Loss: 4.51779
Epoch 43, Val Loss: 4.51557
Epoch 44, Val Loss: 4.56408
Epoch 45, Val Loss: 4.54549
Epoch 46, Val Loss: 4.36655
Epoch 47, Val Loss: 4.63174
Epoch 48, Val Loss: 4.79615
Epoch 49, Val Loss: 4.58778
Epoch 50, Val Loss: 4.81534
Epoch 51, Val Loss: 4.45437
Epoch 52, Val Loss: 4.35625
Epoch 53, Val Loss: 4.73737
Epoch 54, Val Loss: 4.67115
Epoch 55, Val Loss: 4.53754
Epoch 56, Val Loss: 4.50936
Epoch 57, Val Loss: 4.33013
Epoch 58, Val Loss: 4.50191
Epoch 59, Val Loss: 4.57399
Epoch 60, Val Loss: 4.27931
Epoch 61, Val Loss: 4.41384
Epoch 62, Val Loss: 4.27145
Epoch 63, Val Loss: 4.67393
Epoch 64, Val Loss: 4.74412
Epoch 65, Val Loss: 4.40195
Epoch 66, Val Loss: 4.29448
Epoch 67, Val Loss: 4.17868
Epoch 68, Val Loss: 4.86971
Epoch 69, Val Loss: 4.37938
Epoch 70, Val Loss: 4.34624
Epoch 71, Val Loss: 4.61408
Epoch 72, Val Loss: 4.24290
Epoch 73, Val Loss: 4.40480
Epoch 74, Val Loss: 4.35418
Epoch 75, Val Loss: 5.04510
Epoch 76, Val Loss: 4.25561
Epoch 77, Val Loss: 4.17736
Epoch 78, Val Loss: 4.15145
Epoch 79, Val Loss: 4.50862
Epoch 80, Val Loss: 4.56975
Epoch 81, Val Loss: 4.25916
Epoch 82, Val Loss: 4.36533
Epoch 83, Val Loss: 4.22287
Epoch 84, Val Loss: 4.13879
Epoch 85, Val Loss: 4.49312
Epoch 86, Val Loss: 4.28762
Epoch 87, Val Loss: 4.23542
Epoch 88, Val Loss: 4.17311
Epoch 89, Val Loss: 4.45939
Epoch 90, Val Loss: 4.34224
Epoch 91, Val Loss: 4.16199
Epoch 92, Val Loss: 4.53355
Epoch 93, Val Loss: 4.88965
Epoch 94, Val Loss: 4.24156
Epoch 95, Val Loss: 4.25997
Epoch 96, Val Loss: 5.20548
Epoch 97, Val Loss: 4.32822
Epoch 98, Val Loss: 4.25804
Epoch 99, Val Loss: 4.14977
DID NOT SAVE RESULTS
{'MSE - mean': 4.673717734215172, 'MSE - std': 0.3896680806608108, 'R2 - mean': 0.5407854863460928, 'R2 - std': 0.0025495414988874754} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.98377
Epoch 1, Val Loss: 8.16298
Epoch 2, Val Loss: 7.27869
Epoch 3, Val Loss: 7.38083
Epoch 4, Val Loss: 6.80826
Epoch 5, Val Loss: 6.15953
Epoch 6, Val Loss: 6.27092
Epoch 7, Val Loss: 6.16186
Epoch 8, Val Loss: 6.16911
Epoch 9, Val Loss: 6.31977
Epoch 10, Val Loss: 6.66584
Epoch 11, Val Loss: 6.60049
Epoch 12, Val Loss: 6.02146
Epoch 13, Val Loss: 6.06083
Epoch 14, Val Loss: 5.95611
Epoch 15, Val Loss: 5.88906
Epoch 16, Val Loss: 5.82862
Epoch 17, Val Loss: 5.84312
Epoch 18, Val Loss: 6.03626
Epoch 19, Val Loss: 5.69941
Epoch 20, Val Loss: 5.96163
Epoch 21, Val Loss: 5.74594
Epoch 22, Val Loss: 5.57006
Epoch 23, Val Loss: 5.61957
Epoch 24, Val Loss: 5.58033
Epoch 25, Val Loss: 5.68045
Epoch 26, Val Loss: 5.78120
Epoch 27, Val Loss: 5.47943
Epoch 28, Val Loss: 5.61403
Epoch 29, Val Loss: 5.42539
Epoch 30, Val Loss: 5.45507
Epoch 31, Val Loss: 5.63162
Epoch 32, Val Loss: 5.43389
Epoch 33, Val Loss: 5.52092
Epoch 34, Val Loss: 5.51113
Epoch 35, Val Loss: 5.24875
Epoch 36, Val Loss: 5.48561
Epoch 37, Val Loss: 5.22341
Epoch 38, Val Loss: 5.26734
Epoch 39, Val Loss: 5.47611
Epoch 40, Val Loss: 5.32628
Epoch 41, Val Loss: 5.18253
Epoch 42, Val Loss: 5.34503
Epoch 43, Val Loss: 5.40186
Epoch 44, Val Loss: 5.37738
Epoch 45, Val Loss: 5.26074
Epoch 46, Val Loss: 5.12326
Epoch 47, Val Loss: 5.80327
Epoch 48, Val Loss: 5.40108
Epoch 49, Val Loss: 5.04202
Epoch 50, Val Loss: 5.60964
Epoch 51, Val Loss: 5.06617
Epoch 52, Val Loss: 5.03774
Epoch 53, Val Loss: 5.19765
Epoch 54, Val Loss: 4.95231
Epoch 55, Val Loss: 5.13593
Epoch 56, Val Loss: 5.02443
Epoch 57, Val Loss: 5.42240
Epoch 58, Val Loss: 5.20544
Epoch 59, Val Loss: 5.29863
Epoch 60, Val Loss: 5.01663
Epoch 61, Val Loss: 4.84648
Epoch 62, Val Loss: 4.91135
Epoch 63, Val Loss: 5.15192
Epoch 64, Val Loss: 5.00069
Epoch 65, Val Loss: 4.89449
Epoch 66, Val Loss: 5.05727
Epoch 67, Val Loss: 5.07395
Epoch 68, Val Loss: 4.87792
Epoch 69, Val Loss: 4.99360
Epoch 70, Val Loss: 5.07530
Epoch 71, Val Loss: 4.94566
Epoch 72, Val Loss: 4.87342
Epoch 73, Val Loss: 4.85893
Epoch 74, Val Loss: 5.18796
Epoch 75, Val Loss: 4.89545
Epoch 76, Val Loss: 4.93092
Epoch 77, Val Loss: 4.97275
Epoch 78, Val Loss: 4.92508
Epoch 79, Val Loss: 4.84983
Epoch 80, Val Loss: 4.67143
Epoch 81, Val Loss: 4.87459
Epoch 82, Val Loss: 4.75867
Epoch 83, Val Loss: 4.83325
Epoch 84, Val Loss: 5.08852
Epoch 85, Val Loss: 5.02897
Epoch 86, Val Loss: 4.95824
Epoch 87, Val Loss: 5.08522
Epoch 88, Val Loss: 5.29235
Epoch 89, Val Loss: 5.04190
Epoch 90, Val Loss: 4.92068
Epoch 91, Val Loss: 4.70337
Epoch 92, Val Loss: 4.90265
Epoch 93, Val Loss: 5.09093
Epoch 94, Val Loss: 4.77613
Epoch 95, Val Loss: 5.14608
Epoch 96, Val Loss: 5.55180
Epoch 97, Val Loss: 4.89807
Epoch 98, Val Loss: 4.71837
Epoch 99, Val Loss: 4.91363
DID NOT SAVE RESULTS
{'MSE - mean': 4.724796683148219, 'MSE - std': 0.3262600089480728, 'R2 - mean': 0.5355349828048818, 'R2 - std': 0.007711615661384041} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.94050
Epoch 1, Val Loss: 9.42802
Epoch 2, Val Loss: 6.10734
Epoch 3, Val Loss: 5.49621
Epoch 4, Val Loss: 5.60415
Epoch 5, Val Loss: 5.75282
Epoch 6, Val Loss: 5.48304
Epoch 7, Val Loss: 5.26698
Epoch 8, Val Loss: 5.64624
Epoch 9, Val Loss: 5.39967
Epoch 10, Val Loss: 5.45754
Epoch 11, Val Loss: 5.21117
Epoch 12, Val Loss: 5.42439
Epoch 13, Val Loss: 5.32422
Epoch 14, Val Loss: 5.15072
Epoch 15, Val Loss: 5.46299
Epoch 16, Val Loss: 5.28972
Epoch 17, Val Loss: 5.25860
Epoch 18, Val Loss: 5.21978
Epoch 19, Val Loss: 5.16591
Epoch 20, Val Loss: 5.14898
Epoch 21, Val Loss: 5.50188
Epoch 22, Val Loss: 5.09035
Epoch 23, Val Loss: 5.17085
Epoch 24, Val Loss: 5.00355
Epoch 25, Val Loss: 5.34555
Epoch 26, Val Loss: 5.05155
Epoch 27, Val Loss: 4.94659
Epoch 28, Val Loss: 5.13687
Epoch 29, Val Loss: 4.98411
Epoch 30, Val Loss: 5.47174
Epoch 31, Val Loss: 4.93840
Epoch 32, Val Loss: 4.86141
Epoch 33, Val Loss: 5.37030
Epoch 34, Val Loss: 5.26411
Epoch 35, Val Loss: 5.00718
Epoch 36, Val Loss: 4.95219
Epoch 37, Val Loss: 5.00869
Epoch 38, Val Loss: 4.86515
Epoch 39, Val Loss: 4.78965
Epoch 40, Val Loss: 5.09431
Epoch 41, Val Loss: 4.86793
Epoch 42, Val Loss: 4.74175
Epoch 43, Val Loss: 4.84718
Epoch 44, Val Loss: 4.70670
Epoch 45, Val Loss: 5.06733
Epoch 46, Val Loss: 4.97383
Epoch 47, Val Loss: 4.68595
Epoch 48, Val Loss: 4.81963
Epoch 49, Val Loss: 4.86830
Epoch 50, Val Loss: 4.61357
Epoch 51, Val Loss: 4.74894
Epoch 52, Val Loss: 4.85378
Epoch 53, Val Loss: 4.65810
Epoch 54, Val Loss: 4.56399
Epoch 55, Val Loss: 4.84508
Epoch 56, Val Loss: 4.69770
Epoch 57, Val Loss: 4.76165
Epoch 58, Val Loss: 4.93250
Epoch 59, Val Loss: 4.64930
Epoch 60, Val Loss: 4.56837
Epoch 61, Val Loss: 4.50986
Epoch 62, Val Loss: 4.78672
Epoch 63, Val Loss: 4.61713
Epoch 64, Val Loss: 4.53692
Epoch 65, Val Loss: 4.61799
Epoch 66, Val Loss: 4.49760
Epoch 67, Val Loss: 4.95947
Epoch 68, Val Loss: 4.64874
Epoch 69, Val Loss: 4.38341
Epoch 70, Val Loss: 4.54959
Epoch 71, Val Loss: 4.88393
Epoch 72, Val Loss: 4.38487
Epoch 73, Val Loss: 4.38578
Epoch 74, Val Loss: 4.46200
Epoch 75, Val Loss: 4.62867
Epoch 76, Val Loss: 4.35935
Epoch 77, Val Loss: 4.33409
Epoch 78, Val Loss: 4.42755
Epoch 79, Val Loss: 4.51643
Epoch 80, Val Loss: 4.33670
Epoch 81, Val Loss: 4.48944
Epoch 82, Val Loss: 4.25140
Epoch 83, Val Loss: 4.45304
Epoch 84, Val Loss: 4.22005
Epoch 85, Val Loss: 4.31595
Epoch 86, Val Loss: 4.17974
Epoch 87, Val Loss: 4.22753
Epoch 88, Val Loss: 4.45332
Epoch 89, Val Loss: 4.38761
Epoch 90, Val Loss: 4.24818
Epoch 91, Val Loss: 4.31054
Epoch 92, Val Loss: 4.14873
Epoch 93, Val Loss: 4.17421
Epoch 94, Val Loss: 4.24658
Epoch 95, Val Loss: 4.24957
Epoch 96, Val Loss: 4.15792
Epoch 97, Val Loss: 4.16099
Epoch 98, Val Loss: 4.15887
Epoch 99, Val Loss: 4.34443
DID NOT SAVE RESULTS
{'MSE - mean': 4.680109635447734, 'MSE - std': 0.29295902746912206, 'R2 - mean': 0.5301347830968419, 'R2 - std': 0.011492964488843588} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.71507
Epoch 1, Val Loss: 17.43477
Epoch 2, Val Loss: 9.20958
Epoch 3, Val Loss: 7.64624
Epoch 4, Val Loss: 7.61461
Epoch 5, Val Loss: 7.37844
Epoch 6, Val Loss: 7.45940
Epoch 7, Val Loss: 7.34339
Epoch 8, Val Loss: 7.56583
Epoch 9, Val Loss: 7.14398
Epoch 10, Val Loss: 7.16189
Epoch 11, Val Loss: 7.30945
Epoch 12, Val Loss: 7.13263
Epoch 13, Val Loss: 7.41027
Epoch 14, Val Loss: 6.85323
Epoch 15, Val Loss: 7.03992
Epoch 16, Val Loss: 6.94737
Epoch 17, Val Loss: 6.91895
Epoch 18, Val Loss: 7.37083
Epoch 19, Val Loss: 6.75263
Epoch 20, Val Loss: 6.68703
Epoch 21, Val Loss: 6.77090
Epoch 22, Val Loss: 6.71954
Epoch 23, Val Loss: 6.70253
Epoch 24, Val Loss: 6.72590
Epoch 25, Val Loss: 6.72359
Epoch 26, Val Loss: 6.89210
Epoch 27, Val Loss: 6.60881
Epoch 28, Val Loss: 6.58578
Epoch 29, Val Loss: 6.62354
Epoch 30, Val Loss: 6.88686
Epoch 31, Val Loss: 6.58809
Epoch 32, Val Loss: 7.12486
Epoch 33, Val Loss: 7.03124
Epoch 34, Val Loss: 6.50472
Epoch 35, Val Loss: 6.62632
Epoch 36, Val Loss: 6.47379
Epoch 37, Val Loss: 6.53414
Epoch 38, Val Loss: 6.53204
Epoch 39, Val Loss: 6.73101
Epoch 40, Val Loss: 6.21248
Epoch 41, Val Loss: 6.55769
Epoch 42, Val Loss: 6.59670
Epoch 43, Val Loss: 6.59201
Epoch 44, Val Loss: 6.39524
Epoch 45, Val Loss: 6.47910
Epoch 46, Val Loss: 6.35655
Epoch 47, Val Loss: 6.40363
Epoch 48, Val Loss: 6.28783
Epoch 49, Val Loss: 6.92413
Epoch 50, Val Loss: 6.90500
Epoch 51, Val Loss: 6.65282
Epoch 52, Val Loss: 6.30125
Epoch 53, Val Loss: 6.45965
Epoch 54, Val Loss: 6.49791
Epoch 55, Val Loss: 6.24280
Epoch 56, Val Loss: 6.61579
Epoch 57, Val Loss: 6.20549
Epoch 58, Val Loss: 6.23363
Epoch 59, Val Loss: 6.13573
Epoch 60, Val Loss: 6.63950
Epoch 61, Val Loss: 6.49456
Epoch 62, Val Loss: 6.51037
Epoch 63, Val Loss: 6.23759
Epoch 64, Val Loss: 6.62466
Epoch 65, Val Loss: 6.16881
Epoch 66, Val Loss: 6.09101
Epoch 67, Val Loss: 6.19926
Epoch 68, Val Loss: 6.15830
Epoch 69, Val Loss: 6.40114
Epoch 70, Val Loss: 6.26447
Epoch 71, Val Loss: 6.60643
Epoch 72, Val Loss: 6.09749
Epoch 73, Val Loss: 6.16881
Epoch 74, Val Loss: 6.00335
Epoch 75, Val Loss: 6.43094
Epoch 76, Val Loss: 6.31823
Epoch 77, Val Loss: 6.61661
Epoch 78, Val Loss: 6.07241
Epoch 79, Val Loss: 6.14183
Epoch 80, Val Loss: 5.93491
Epoch 81, Val Loss: 6.36379
Epoch 82, Val Loss: 5.97694
Epoch 83, Val Loss: 6.12774
Epoch 84, Val Loss: 6.01825
Epoch 85, Val Loss: 6.12226
Epoch 86, Val Loss: 6.19374
Epoch 87, Val Loss: 6.43316
Epoch 88, Val Loss: 7.03420
Epoch 89, Val Loss: 6.33020
Epoch 90, Val Loss: 6.17278
Epoch 91, Val Loss: 6.21030
Epoch 92, Val Loss: 5.83193
Epoch 93, Val Loss: 5.99889
Epoch 94, Val Loss: 6.24524
Epoch 95, Val Loss: 6.07611
Epoch 96, Val Loss: 6.02776
Epoch 97, Val Loss: 6.12821
Epoch 98, Val Loss: 6.06748
Epoch 99, Val Loss: 6.38898
DID NOT SAVE RESULTS
{'MSE - mean': 4.922190757825748, 'MSE - std': 0.5505207286449078, 'R2 - mean': 0.5266790754582922, 'R2 - std': 0.012387019307564672} 
 

Results After CV: {'MSE - mean': 4.922190757825748, 'MSE - std': 0.5505207286449078, 'R2 - mean': 0.5266790754582922, 'R2 - std': 0.012387019307564672}
Train time: 27.709133992199714
Inference time: 0.04852346000043326
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 48 finished with value: 4.922190757825748 and parameters: {'p_m': 0.5157956528274678, 'alpha': 0.5343827926843775, 'K': 2, 'beta': 2.5314632897098432}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.80969
Epoch 1, Val Loss: 12.85505
Epoch 2, Val Loss: 8.05478
Epoch 3, Val Loss: 6.50469
Epoch 4, Val Loss: 6.16362
Epoch 5, Val Loss: 6.17929
Epoch 6, Val Loss: 5.96001
Epoch 7, Val Loss: 5.67366
Epoch 8, Val Loss: 5.41828
Epoch 9, Val Loss: 5.51484
Epoch 10, Val Loss: 5.36441
Epoch 11, Val Loss: 5.44810
Epoch 12, Val Loss: 5.20960
Epoch 13, Val Loss: 5.49438
Epoch 14, Val Loss: 5.74618
Epoch 15, Val Loss: 5.12013
Epoch 16, Val Loss: 5.33468
Epoch 17, Val Loss: 4.94815
Epoch 18, Val Loss: 4.93373
Epoch 19, Val Loss: 5.30558
Epoch 20, Val Loss: 5.56984
Epoch 21, Val Loss: 5.04656
Epoch 22, Val Loss: 4.84961
Epoch 23, Val Loss: 4.97705
Epoch 24, Val Loss: 4.93261
Epoch 25, Val Loss: 4.90618
Epoch 26, Val Loss: 4.73719
Epoch 27, Val Loss: 4.79008
Epoch 28, Val Loss: 4.78661
Epoch 29, Val Loss: 4.96758
Epoch 30, Val Loss: 5.08604
Epoch 31, Val Loss: 4.75191
Epoch 32, Val Loss: 4.70744
Epoch 33, Val Loss: 5.01876
Epoch 34, Val Loss: 4.61713
Epoch 35, Val Loss: 4.62052
Epoch 36, Val Loss: 4.87833
Epoch 37, Val Loss: 4.94661
Epoch 38, Val Loss: 4.59804
Epoch 39, Val Loss: 4.69687
Epoch 40, Val Loss: 4.56775
Epoch 41, Val Loss: 4.59466
Epoch 42, Val Loss: 4.55760
Epoch 43, Val Loss: 4.73536
Epoch 44, Val Loss: 4.61879
Epoch 45, Val Loss: 5.03553
Epoch 46, Val Loss: 4.66661
Epoch 47, Val Loss: 4.72731
Epoch 48, Val Loss: 4.63307
Epoch 49, Val Loss: 4.71162
Epoch 50, Val Loss: 4.50954
Epoch 51, Val Loss: 4.56873
Epoch 52, Val Loss: 4.98535
Epoch 53, Val Loss: 4.74599
Epoch 54, Val Loss: 4.54841
Epoch 55, Val Loss: 5.33272
Epoch 56, Val Loss: 4.53791
Epoch 57, Val Loss: 4.52824
Epoch 58, Val Loss: 4.54162
Epoch 59, Val Loss: 4.81369
Epoch 60, Val Loss: 4.56108
Epoch 61, Val Loss: 4.58310
Epoch 62, Val Loss: 4.61575
Epoch 63, Val Loss: 4.64018
Epoch 64, Val Loss: 4.90415
Epoch 65, Val Loss: 4.52434
Epoch 66, Val Loss: 5.31526
Epoch 67, Val Loss: 4.80434
Epoch 68, Val Loss: 4.52175
Epoch 69, Val Loss: 4.59161
Epoch 70, Val Loss: 4.53207
Epoch 71, Val Loss: 4.58512
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.681336818111095, 'MSE - std': 0.0, 'R2 - mean': 0.573077550931203, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.45372
Epoch 1, Val Loss: 9.36818
Epoch 2, Val Loss: 5.87959
Epoch 3, Val Loss: 5.74079
Epoch 4, Val Loss: 5.52805
Epoch 5, Val Loss: 5.42543
Epoch 6, Val Loss: 5.66543
Epoch 7, Val Loss: 5.21242
Epoch 8, Val Loss: 5.21751
Epoch 9, Val Loss: 5.22072
Epoch 10, Val Loss: 5.05717
Epoch 11, Val Loss: 5.35611
Epoch 12, Val Loss: 5.17143
Epoch 13, Val Loss: 5.06452
Epoch 14, Val Loss: 4.86028
Epoch 15, Val Loss: 5.06294
Epoch 16, Val Loss: 4.91432
Epoch 17, Val Loss: 4.90950
Epoch 18, Val Loss: 5.28283
Epoch 19, Val Loss: 5.72988
Epoch 20, Val Loss: 5.03008
Epoch 21, Val Loss: 4.70239
Epoch 22, Val Loss: 4.76016
Epoch 23, Val Loss: 4.68692
Epoch 24, Val Loss: 4.70269
Epoch 25, Val Loss: 4.68387
Epoch 26, Val Loss: 4.57668
Epoch 27, Val Loss: 4.67551
Epoch 28, Val Loss: 5.08368
Epoch 29, Val Loss: 4.55411
Epoch 30, Val Loss: 4.52871
Epoch 31, Val Loss: 4.60453
Epoch 32, Val Loss: 4.63241
Epoch 33, Val Loss: 4.47628
Epoch 34, Val Loss: 4.52491
Epoch 35, Val Loss: 4.47182
Epoch 36, Val Loss: 4.43522
Epoch 37, Val Loss: 4.60460
Epoch 38, Val Loss: 4.66302
Epoch 39, Val Loss: 4.75190
Epoch 40, Val Loss: 4.42730
Epoch 41, Val Loss: 4.90492
Epoch 42, Val Loss: 4.58774
Epoch 43, Val Loss: 4.36388
Epoch 44, Val Loss: 4.46994
Epoch 45, Val Loss: 4.39375
Epoch 46, Val Loss: 4.40526
Epoch 47, Val Loss: 4.77640
Epoch 48, Val Loss: 4.32255
Epoch 49, Val Loss: 4.87153
Epoch 50, Val Loss: 4.74870
Epoch 51, Val Loss: 4.30784
Epoch 52, Val Loss: 4.23555
Epoch 53, Val Loss: 4.44203
Epoch 54, Val Loss: 4.24588
Epoch 55, Val Loss: 4.39999
Epoch 56, Val Loss: 4.42920
Epoch 57, Val Loss: 4.57919
Epoch 58, Val Loss: 4.21344
Epoch 59, Val Loss: 4.55045
Epoch 60, Val Loss: 4.35170
Epoch 61, Val Loss: 4.46689
Epoch 62, Val Loss: 4.24030
Epoch 63, Val Loss: 4.79418
Epoch 64, Val Loss: 4.22492
Epoch 65, Val Loss: 4.28414
Epoch 66, Val Loss: 4.74695
Epoch 67, Val Loss: 4.63110
Epoch 68, Val Loss: 4.23079
Epoch 69, Val Loss: 4.19243
Epoch 70, Val Loss: 4.19107
Epoch 71, Val Loss: 4.07805
Epoch 72, Val Loss: 4.14816
Epoch 73, Val Loss: 4.05590
Epoch 74, Val Loss: 4.15827
Epoch 75, Val Loss: 4.36580
Epoch 76, Val Loss: 4.21477
Epoch 77, Val Loss: 4.13938
Epoch 78, Val Loss: 4.11202
Epoch 79, Val Loss: 4.51050
Epoch 80, Val Loss: 4.55977
Epoch 81, Val Loss: 4.36485
Epoch 82, Val Loss: 4.71391
Epoch 83, Val Loss: 4.47683
Epoch 84, Val Loss: 4.13784
Epoch 85, Val Loss: 4.74432
Epoch 86, Val Loss: 4.65671
Epoch 87, Val Loss: 4.05306
Epoch 88, Val Loss: 4.12316
Epoch 89, Val Loss: 4.40736
Epoch 90, Val Loss: 4.01559
Epoch 91, Val Loss: 4.03612
Epoch 92, Val Loss: 4.82337
Epoch 93, Val Loss: 4.12755
Epoch 94, Val Loss: 4.08462
Epoch 95, Val Loss: 4.20346
Epoch 96, Val Loss: 4.33761
Epoch 97, Val Loss: 4.10303
Epoch 98, Val Loss: 4.09180
Epoch 99, Val Loss: 4.28845
DID NOT SAVE RESULTS
{'MSE - mean': 4.386401955521993, 'MSE - std': 0.2949348625891024, 'R2 - mean': 0.5684706089917149, 'R2 - std': 0.0046069419394882405} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.40565
Epoch 1, Val Loss: 10.03626
Epoch 2, Val Loss: 6.25318
Epoch 3, Val Loss: 6.02267
Epoch 4, Val Loss: 5.81091
Epoch 5, Val Loss: 5.51418
Epoch 6, Val Loss: 5.47169
Epoch 7, Val Loss: 5.52617
Epoch 8, Val Loss: 5.20729
Epoch 9, Val Loss: 5.18379
Epoch 10, Val Loss: 5.18534
Epoch 11, Val Loss: 5.13105
Epoch 12, Val Loss: 5.16873
Epoch 13, Val Loss: 5.38563
Epoch 14, Val Loss: 4.94756
Epoch 15, Val Loss: 5.01657
Epoch 16, Val Loss: 5.33532
Epoch 17, Val Loss: 4.84472
Epoch 18, Val Loss: 4.86323
Epoch 19, Val Loss: 4.92217
Epoch 20, Val Loss: 4.85578
Epoch 21, Val Loss: 4.86682
Epoch 22, Val Loss: 4.87577
Epoch 23, Val Loss: 4.73094
Epoch 24, Val Loss: 5.10966
Epoch 25, Val Loss: 4.80343
Epoch 26, Val Loss: 4.90584
Epoch 27, Val Loss: 4.77263
Epoch 28, Val Loss: 4.67308
Epoch 29, Val Loss: 4.74847
Epoch 30, Val Loss: 4.68918
Epoch 31, Val Loss: 5.00367
Epoch 32, Val Loss: 5.00257
Epoch 33, Val Loss: 5.11761
Epoch 34, Val Loss: 4.83273
Epoch 35, Val Loss: 4.74206
Epoch 36, Val Loss: 4.77781
Epoch 37, Val Loss: 4.99325
Epoch 38, Val Loss: 4.60342
Epoch 39, Val Loss: 4.77673
Epoch 40, Val Loss: 4.55755
Epoch 41, Val Loss: 4.58858
Epoch 42, Val Loss: 4.70433
Epoch 43, Val Loss: 4.68488
Epoch 44, Val Loss: 4.59235
Epoch 45, Val Loss: 4.79421
Epoch 46, Val Loss: 4.57427
Epoch 47, Val Loss: 4.76717
Epoch 48, Val Loss: 4.82576
Epoch 49, Val Loss: 4.55342
Epoch 50, Val Loss: 4.96442
Epoch 51, Val Loss: 4.65640
Epoch 52, Val Loss: 4.63909
Epoch 53, Val Loss: 4.55037
Epoch 54, Val Loss: 4.68550
Epoch 55, Val Loss: 5.07720
Epoch 56, Val Loss: 4.88454
Epoch 57, Val Loss: 4.57802
Epoch 58, Val Loss: 4.83490
Epoch 59, Val Loss: 4.43666
Epoch 60, Val Loss: 4.42347
Epoch 61, Val Loss: 4.67299
Epoch 62, Val Loss: 4.61759
Epoch 63, Val Loss: 4.48317
Epoch 64, Val Loss: 4.43224
Epoch 65, Val Loss: 4.74308
Epoch 66, Val Loss: 4.47698
Epoch 67, Val Loss: 4.46764
Epoch 68, Val Loss: 4.62252
Epoch 69, Val Loss: 4.64067
Epoch 70, Val Loss: 4.40431
Epoch 71, Val Loss: 4.48733
Epoch 72, Val Loss: 4.51951
Epoch 73, Val Loss: 4.48297
Epoch 74, Val Loss: 4.54337
Epoch 75, Val Loss: 4.34537
Epoch 76, Val Loss: 5.07294
Epoch 77, Val Loss: 4.47602
Epoch 78, Val Loss: 4.92184
Epoch 79, Val Loss: 4.41899
Epoch 80, Val Loss: 4.48159
Epoch 81, Val Loss: 4.32595
Epoch 82, Val Loss: 4.76975
Epoch 83, Val Loss: 4.83815
Epoch 84, Val Loss: 4.54136
Epoch 85, Val Loss: 4.73181
Epoch 86, Val Loss: 4.40544
Epoch 87, Val Loss: 4.45426
Epoch 88, Val Loss: 4.94468
Epoch 89, Val Loss: 4.47194
Epoch 90, Val Loss: 4.36430
Epoch 91, Val Loss: 4.47379
Epoch 92, Val Loss: 4.59011
Epoch 93, Val Loss: 4.36984
Epoch 94, Val Loss: 4.34833
Epoch 95, Val Loss: 4.43393
Epoch 96, Val Loss: 4.44235
Epoch 97, Val Loss: 4.44337
Epoch 98, Val Loss: 4.50143
Epoch 99, Val Loss: 4.68640
DID NOT SAVE RESULTS
{'MSE - mean': 4.407650476075216, 'MSE - std': 0.24268095935137407, 'R2 - mean': 0.5663508388274988, 'R2 - std': 0.0048100028192033725} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.50075
Epoch 1, Val Loss: 7.56018
Epoch 2, Val Loss: 5.67657
Epoch 3, Val Loss: 5.45775
Epoch 4, Val Loss: 5.54393
Epoch 5, Val Loss: 5.53277
Epoch 6, Val Loss: 5.22214
Epoch 7, Val Loss: 5.17795
Epoch 8, Val Loss: 4.97740
Epoch 9, Val Loss: 4.96258
Epoch 10, Val Loss: 4.86635
Epoch 11, Val Loss: 4.83145
Epoch 12, Val Loss: 4.85827
Epoch 13, Val Loss: 5.25759
Epoch 14, Val Loss: 4.78389
Epoch 15, Val Loss: 4.65425
Epoch 16, Val Loss: 4.72057
Epoch 17, Val Loss: 4.62462
Epoch 18, Val Loss: 4.60412
Epoch 19, Val Loss: 4.60249
Epoch 20, Val Loss: 5.10977
Epoch 21, Val Loss: 4.69216
Epoch 22, Val Loss: 4.57388
Epoch 23, Val Loss: 4.91431
Epoch 24, Val Loss: 4.58512
Epoch 25, Val Loss: 4.52298
Epoch 26, Val Loss: 4.46106
Epoch 27, Val Loss: 4.38797
Epoch 28, Val Loss: 4.39346
Epoch 29, Val Loss: 4.41631
Epoch 30, Val Loss: 4.53486
Epoch 31, Val Loss: 4.33732
Epoch 32, Val Loss: 4.35269
Epoch 33, Val Loss: 4.24934
Epoch 34, Val Loss: 4.91514
Epoch 35, Val Loss: 4.24597
Epoch 36, Val Loss: 4.24453
Epoch 37, Val Loss: 4.19302
Epoch 38, Val Loss: 4.19645
Epoch 39, Val Loss: 4.17422
Epoch 40, Val Loss: 4.28900
Epoch 41, Val Loss: 4.29716
Epoch 42, Val Loss: 4.37346
Epoch 43, Val Loss: 4.24736
Epoch 44, Val Loss: 4.20807
Epoch 45, Val Loss: 4.66297
Epoch 46, Val Loss: 4.37163
Epoch 47, Val Loss: 4.13322
Epoch 48, Val Loss: 4.23494
Epoch 49, Val Loss: 4.16023
Epoch 50, Val Loss: 4.34018
Epoch 51, Val Loss: 4.14398
Epoch 52, Val Loss: 4.31264
Epoch 53, Val Loss: 4.08274
Epoch 54, Val Loss: 4.00835
Epoch 55, Val Loss: 4.18290
Epoch 56, Val Loss: 4.21730
Epoch 57, Val Loss: 4.28215
Epoch 58, Val Loss: 4.10742
Epoch 59, Val Loss: 4.05501
Epoch 60, Val Loss: 4.26458
Epoch 61, Val Loss: 3.98706
Epoch 62, Val Loss: 4.27037
Epoch 63, Val Loss: 4.12953
Epoch 64, Val Loss: 4.03716
Epoch 65, Val Loss: 4.04861
Epoch 66, Val Loss: 4.23883
Epoch 67, Val Loss: 4.25351
Epoch 68, Val Loss: 3.96532
Epoch 69, Val Loss: 3.98609
Epoch 70, Val Loss: 4.06001
Epoch 71, Val Loss: 4.01304
Epoch 72, Val Loss: 4.22917
Epoch 73, Val Loss: 3.96703
Epoch 74, Val Loss: 4.33218
Epoch 75, Val Loss: 4.18990
Epoch 76, Val Loss: 4.86156
Epoch 77, Val Loss: 3.94629
Epoch 78, Val Loss: 4.08435
Epoch 79, Val Loss: 3.97550
Epoch 80, Val Loss: 3.97152
Epoch 81, Val Loss: 3.99857
Epoch 82, Val Loss: 4.02697
Epoch 83, Val Loss: 3.99641
Epoch 84, Val Loss: 4.11702
Epoch 85, Val Loss: 4.94370
Epoch 86, Val Loss: 4.21229
Epoch 87, Val Loss: 4.43089
Epoch 88, Val Loss: 4.45906
Epoch 89, Val Loss: 4.07987
Epoch 90, Val Loss: 4.01623
Epoch 91, Val Loss: 4.38444
Epoch 92, Val Loss: 4.05277
Epoch 93, Val Loss: 4.08448
Epoch 94, Val Loss: 4.10966
Epoch 95, Val Loss: 4.04227
Epoch 96, Val Loss: 4.13843
Epoch 97, Val Loss: 3.99805
Epoch 98, Val Loss: 4.20191
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.3588821885697095, 'MSE - std': 0.2265073367960443, 'R2 - mean': 0.5621604017732712, 'R2 - std': 0.008368475575449277} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.34117
Epoch 1, Val Loss: 10.81891
Epoch 2, Val Loss: 7.41936
Epoch 3, Val Loss: 7.86116
Epoch 4, Val Loss: 7.88623
Epoch 5, Val Loss: 7.29421
Epoch 6, Val Loss: 7.06566
Epoch 7, Val Loss: 7.16007
Epoch 8, Val Loss: 6.99954
Epoch 9, Val Loss: 7.59672
Epoch 10, Val Loss: 6.68686
Epoch 11, Val Loss: 6.69114
Epoch 12, Val Loss: 6.70685
Epoch 13, Val Loss: 6.83496
Epoch 14, Val Loss: 6.62389
Epoch 15, Val Loss: 6.68448
Epoch 16, Val Loss: 6.61190
Epoch 17, Val Loss: 6.52507
Epoch 18, Val Loss: 6.59233
Epoch 19, Val Loss: 6.67112
Epoch 20, Val Loss: 6.65400
Epoch 21, Val Loss: 6.52216
Epoch 22, Val Loss: 6.62480
Epoch 23, Val Loss: 6.43932
Epoch 24, Val Loss: 6.49015
Epoch 25, Val Loss: 6.60278
Epoch 26, Val Loss: 6.41677
Epoch 27, Val Loss: 6.68053
Epoch 28, Val Loss: 6.86819
Epoch 29, Val Loss: 6.37545
Epoch 30, Val Loss: 6.70474
Epoch 31, Val Loss: 6.51385
Epoch 32, Val Loss: 6.77743
Epoch 33, Val Loss: 6.36470
Epoch 34, Val Loss: 6.43417
Epoch 35, Val Loss: 6.42245
Epoch 36, Val Loss: 6.29467
Epoch 37, Val Loss: 6.39436
Epoch 38, Val Loss: 6.55739
Epoch 39, Val Loss: 6.36856
Epoch 40, Val Loss: 6.31283
Epoch 41, Val Loss: 6.33351
Epoch 42, Val Loss: 6.23882
Epoch 43, Val Loss: 7.40761
Epoch 44, Val Loss: 6.41237
Epoch 45, Val Loss: 6.50155
Epoch 46, Val Loss: 6.37903
Epoch 47, Val Loss: 6.36041
Epoch 48, Val Loss: 6.66113
Epoch 49, Val Loss: 6.46809
Epoch 50, Val Loss: 6.27905
Epoch 51, Val Loss: 6.33929
Epoch 52, Val Loss: 6.54097
Epoch 53, Val Loss: 6.27552
Epoch 54, Val Loss: 6.21180
Epoch 55, Val Loss: 6.18555
Epoch 56, Val Loss: 6.16323
Epoch 57, Val Loss: 6.24846
Epoch 58, Val Loss: 6.42883
Epoch 59, Val Loss: 6.28975
Epoch 60, Val Loss: 6.20237
Epoch 61, Val Loss: 6.17086
Epoch 62, Val Loss: 6.32294
Epoch 63, Val Loss: 6.42019
Epoch 64, Val Loss: 6.19103
Epoch 65, Val Loss: 6.39984
Epoch 66, Val Loss: 6.19929
Epoch 67, Val Loss: 6.30242
Epoch 68, Val Loss: 6.34165
Epoch 69, Val Loss: 6.61273
Epoch 70, Val Loss: 6.35270
Epoch 71, Val Loss: 6.63441
Epoch 72, Val Loss: 6.29780
Epoch 73, Val Loss: 6.25464
Epoch 74, Val Loss: 6.22039
Epoch 75, Val Loss: 6.46135
Epoch 76, Val Loss: 6.92983
Epoch 77, Val Loss: 6.23401
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.706751468837662, 'MSE - std': 0.7246354970014395, 'R2 - mean': 0.5488640048016854, 'R2 - std': 0.027626107153732243} 
 

Results After CV: {'MSE - mean': 4.706751468837662, 'MSE - std': 0.7246354970014395, 'R2 - mean': 0.5488640048016854, 'R2 - std': 0.027626107153732243}
Train time: 44.43707545420002
Inference time: 0.05208766299983836
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 49 finished with value: 4.706751468837662 and parameters: {'p_m': 0.8650251055686033, 'alpha': 2.4048784892836497, 'K': 5, 'beta': 1.2581195327311436}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.91171
Epoch 1, Val Loss: 12.91152
Epoch 2, Val Loss: 7.54095
Epoch 3, Val Loss: 6.90956
Epoch 4, Val Loss: 6.62370
Epoch 5, Val Loss: 6.54921
Epoch 6, Val Loss: 6.43219
Epoch 7, Val Loss: 6.36499
Epoch 8, Val Loss: 6.38882
Epoch 9, Val Loss: 6.45666
Epoch 10, Val Loss: 6.61340
Epoch 11, Val Loss: 6.31573
Epoch 12, Val Loss: 6.07976
Epoch 13, Val Loss: 6.05397
Epoch 14, Val Loss: 6.32642
Epoch 15, Val Loss: 6.47386
Epoch 16, Val Loss: 6.05358
Epoch 17, Val Loss: 5.91423
Epoch 18, Val Loss: 6.20250
Epoch 19, Val Loss: 5.76085
Epoch 20, Val Loss: 5.71510
Epoch 21, Val Loss: 5.70352
Epoch 22, Val Loss: 5.87492
Epoch 23, Val Loss: 5.76019
Epoch 24, Val Loss: 5.70881
Epoch 25, Val Loss: 5.64609
Epoch 26, Val Loss: 5.80607
Epoch 27, Val Loss: 5.69095
Epoch 28, Val Loss: 5.97836
Epoch 29, Val Loss: 5.57326
Epoch 30, Val Loss: 5.47741
Epoch 31, Val Loss: 5.50823
Epoch 32, Val Loss: 5.60970
Epoch 33, Val Loss: 5.67378
Epoch 34, Val Loss: 5.30542
Epoch 35, Val Loss: 5.38653
Epoch 36, Val Loss: 5.68733
Epoch 37, Val Loss: 5.30146
Epoch 38, Val Loss: 5.23545
Epoch 39, Val Loss: 5.43852
Epoch 40, Val Loss: 5.29507
Epoch 41, Val Loss: 5.24567
Epoch 42, Val Loss: 5.09224
Epoch 43, Val Loss: 5.78146
Epoch 44, Val Loss: 5.15463
Epoch 45, Val Loss: 5.30646
Epoch 46, Val Loss: 5.34145
Epoch 47, Val Loss: 5.24622
Epoch 48, Val Loss: 5.07300
Epoch 49, Val Loss: 5.16592
Epoch 50, Val Loss: 5.04364
Epoch 51, Val Loss: 5.18210
Epoch 52, Val Loss: 5.00859
Epoch 53, Val Loss: 4.96913
Epoch 54, Val Loss: 5.15324
Epoch 55, Val Loss: 5.14799
Epoch 56, Val Loss: 4.96240
Epoch 57, Val Loss: 5.00830
Epoch 58, Val Loss: 4.94135
Epoch 59, Val Loss: 5.18095
Epoch 60, Val Loss: 4.95544
Epoch 61, Val Loss: 5.64493
Epoch 62, Val Loss: 4.99611
Epoch 63, Val Loss: 5.03486
Epoch 64, Val Loss: 4.83295
Epoch 65, Val Loss: 5.13382
Epoch 66, Val Loss: 4.70689
Epoch 67, Val Loss: 4.81646
Epoch 68, Val Loss: 4.96153
Epoch 69, Val Loss: 4.97200
Epoch 70, Val Loss: 4.79851
Epoch 71, Val Loss: 4.61450
Epoch 72, Val Loss: 4.68847
Epoch 73, Val Loss: 4.93270
Epoch 74, Val Loss: 4.82960
Epoch 75, Val Loss: 4.73150
Epoch 76, Val Loss: 4.70394
Epoch 77, Val Loss: 4.80501
Epoch 78, Val Loss: 6.02647
Epoch 79, Val Loss: 4.83082
Epoch 80, Val Loss: 4.80124
Epoch 81, Val Loss: 4.73117
Epoch 82, Val Loss: 4.82040
Epoch 83, Val Loss: 4.89558
Epoch 84, Val Loss: 4.50766
Epoch 85, Val Loss: 4.59284
Epoch 86, Val Loss: 4.66153
Epoch 87, Val Loss: 4.83143
Epoch 88, Val Loss: 5.02050
Epoch 89, Val Loss: 4.83919
Epoch 90, Val Loss: 4.77604
Epoch 91, Val Loss: 5.41440
Epoch 92, Val Loss: 4.60964
Epoch 93, Val Loss: 4.89617
Epoch 94, Val Loss: 4.72745
Epoch 95, Val Loss: 4.85275
Epoch 96, Val Loss: 4.62793
Epoch 97, Val Loss: 4.71235
Epoch 98, Val Loss: 5.21494
Epoch 99, Val Loss: 4.90391
DID NOT SAVE RESULTS
{'MSE - mean': 4.681119977916324, 'MSE - std': 0.0, 'R2 - mean': 0.5730973260404519, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.15772
Epoch 1, Val Loss: 6.56700
Epoch 2, Val Loss: 5.60801
Epoch 3, Val Loss: 5.53469
Epoch 4, Val Loss: 5.40264
Epoch 5, Val Loss: 5.40375
Epoch 6, Val Loss: 5.13066
Epoch 7, Val Loss: 5.16494
Epoch 8, Val Loss: 5.20019
Epoch 9, Val Loss: 5.23679
Epoch 10, Val Loss: 4.99766
Epoch 11, Val Loss: 5.10850
Epoch 12, Val Loss: 5.02435
Epoch 13, Val Loss: 5.03432
Epoch 14, Val Loss: 5.03620
Epoch 15, Val Loss: 5.11694
Epoch 16, Val Loss: 5.13276
Epoch 17, Val Loss: 4.85118
Epoch 18, Val Loss: 5.08820
Epoch 19, Val Loss: 4.79120
Epoch 20, Val Loss: 5.22910
Epoch 21, Val Loss: 4.89032
Epoch 22, Val Loss: 4.93317
Epoch 23, Val Loss: 5.00278
Epoch 24, Val Loss: 5.09797
Epoch 25, Val Loss: 4.90243
Epoch 26, Val Loss: 4.89243
Epoch 27, Val Loss: 4.99152
Epoch 28, Val Loss: 4.71645
Epoch 29, Val Loss: 4.79716
Epoch 30, Val Loss: 4.94778
Epoch 31, Val Loss: 4.73482
Epoch 32, Val Loss: 4.63377
Epoch 33, Val Loss: 4.63826
Epoch 34, Val Loss: 4.54141
Epoch 35, Val Loss: 4.48929
Epoch 36, Val Loss: 4.55844
Epoch 37, Val Loss: 4.58269
Epoch 38, Val Loss: 4.64927
Epoch 39, Val Loss: 4.58009
Epoch 40, Val Loss: 4.44317
Epoch 41, Val Loss: 4.56525
Epoch 42, Val Loss: 4.60619
Epoch 43, Val Loss: 4.74336
Epoch 44, Val Loss: 4.39597
Epoch 45, Val Loss: 4.48255
Epoch 46, Val Loss: 4.44012
Epoch 47, Val Loss: 4.42110
Epoch 48, Val Loss: 5.15940
Epoch 49, Val Loss: 4.46662
Epoch 50, Val Loss: 4.52169
Epoch 51, Val Loss: 4.41441
Epoch 52, Val Loss: 4.29391
Epoch 53, Val Loss: 4.53942
Epoch 54, Val Loss: 4.24209
Epoch 55, Val Loss: 4.25602
Epoch 56, Val Loss: 4.26814
Epoch 57, Val Loss: 4.31564
Epoch 58, Val Loss: 4.65262
Epoch 59, Val Loss: 4.25941
Epoch 60, Val Loss: 4.20420
Epoch 61, Val Loss: 4.29024
Epoch 62, Val Loss: 4.41248
Epoch 63, Val Loss: 4.23369
Epoch 64, Val Loss: 4.31158
Epoch 65, Val Loss: 4.31882
Epoch 66, Val Loss: 4.15624
Epoch 67, Val Loss: 4.29321
Epoch 68, Val Loss: 4.27644
Epoch 69, Val Loss: 4.23927
Epoch 70, Val Loss: 4.22106
Epoch 71, Val Loss: 4.28319
Epoch 72, Val Loss: 4.37883
Epoch 73, Val Loss: 4.32795
Epoch 74, Val Loss: 4.23987
Epoch 75, Val Loss: 4.25812
Epoch 76, Val Loss: 4.18713
Epoch 77, Val Loss: 4.05931
Epoch 78, Val Loss: 4.15268
Epoch 79, Val Loss: 4.65702
Epoch 80, Val Loss: 4.38945
Epoch 81, Val Loss: 4.28251
Epoch 82, Val Loss: 4.14299
Epoch 83, Val Loss: 4.08322
Epoch 84, Val Loss: 4.39292
Epoch 85, Val Loss: 4.20460
Epoch 86, Val Loss: 4.17509
Epoch 87, Val Loss: 4.36040
Epoch 88, Val Loss: 4.02387
Epoch 89, Val Loss: 4.05896
Epoch 90, Val Loss: 4.24400
Epoch 91, Val Loss: 4.08970
Epoch 92, Val Loss: 4.29992
Epoch 93, Val Loss: 4.19395
Epoch 94, Val Loss: 4.11567
Epoch 95, Val Loss: 4.11111
Epoch 96, Val Loss: 4.05186
Epoch 97, Val Loss: 4.65639
Epoch 98, Val Loss: 4.02710
Epoch 99, Val Loss: 4.37091
DID NOT SAVE RESULTS
{'MSE - mean': 4.450486978894051, 'MSE - std': 0.23063299902227286, 'R2 - mean': 0.5616376960549428, 'R2 - std': 0.01145962998550909} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.56093
Epoch 1, Val Loss: 8.65703
Epoch 2, Val Loss: 6.98280
Epoch 3, Val Loss: 6.44872
Epoch 4, Val Loss: 6.60522
Epoch 5, Val Loss: 6.33418
Epoch 6, Val Loss: 6.18824
Epoch 7, Val Loss: 6.40167
Epoch 8, Val Loss: 6.29050
Epoch 9, Val Loss: 6.18450
Epoch 10, Val Loss: 6.31950
Epoch 11, Val Loss: 6.19306
Epoch 12, Val Loss: 6.19827
Epoch 13, Val Loss: 6.05156
Epoch 14, Val Loss: 6.00471
Epoch 15, Val Loss: 6.09416
Epoch 16, Val Loss: 6.21685
Epoch 17, Val Loss: 6.09752
Epoch 18, Val Loss: 5.91678
Epoch 19, Val Loss: 5.91559
Epoch 20, Val Loss: 6.15810
Epoch 21, Val Loss: 6.11983
Epoch 22, Val Loss: 5.80268
Epoch 23, Val Loss: 5.79970
Epoch 24, Val Loss: 5.93565
Epoch 25, Val Loss: 6.03472
Epoch 26, Val Loss: 5.91017
Epoch 27, Val Loss: 5.83878
Epoch 28, Val Loss: 5.86586
Epoch 29, Val Loss: 5.63392
Epoch 30, Val Loss: 5.83110
Epoch 31, Val Loss: 5.76452
Epoch 32, Val Loss: 5.77288
Epoch 33, Val Loss: 5.71024
Epoch 34, Val Loss: 5.63828
Epoch 35, Val Loss: 5.97851
Epoch 36, Val Loss: 5.89496
Epoch 37, Val Loss: 5.62513
Epoch 38, Val Loss: 5.83684
Epoch 39, Val Loss: 5.52977
Epoch 40, Val Loss: 6.08996
Epoch 41, Val Loss: 5.49533
Epoch 42, Val Loss: 5.45217
Epoch 43, Val Loss: 5.46181
Epoch 44, Val Loss: 5.47408
Epoch 45, Val Loss: 5.29841
Epoch 46, Val Loss: 5.38464
Epoch 47, Val Loss: 5.31172
Epoch 48, Val Loss: 5.68690
Epoch 49, Val Loss: 5.31002
Epoch 50, Val Loss: 5.25329
Epoch 51, Val Loss: 5.52464
Epoch 52, Val Loss: 5.47524
Epoch 53, Val Loss: 5.20785
Epoch 54, Val Loss: 5.45442
Epoch 55, Val Loss: 5.26585
Epoch 56, Val Loss: 5.22092
Epoch 57, Val Loss: 5.06477
Epoch 58, Val Loss: 5.17371
Epoch 59, Val Loss: 4.97054
Epoch 60, Val Loss: 5.03089
Epoch 61, Val Loss: 4.94849
Epoch 62, Val Loss: 5.02973
Epoch 63, Val Loss: 4.98469
Epoch 64, Val Loss: 5.08450
Epoch 65, Val Loss: 4.81796
Epoch 66, Val Loss: 5.05291
Epoch 67, Val Loss: 5.14696
Epoch 68, Val Loss: 4.83907
Epoch 69, Val Loss: 5.05890
Epoch 70, Val Loss: 4.81059
Epoch 71, Val Loss: 4.84320
Epoch 72, Val Loss: 4.72682
Epoch 73, Val Loss: 4.79279
Epoch 74, Val Loss: 4.58700
Epoch 75, Val Loss: 4.87822
Epoch 76, Val Loss: 5.12777
Epoch 77, Val Loss: 4.63777
Epoch 78, Val Loss: 4.66448
Epoch 79, Val Loss: 4.70178
Epoch 80, Val Loss: 4.56187
Epoch 81, Val Loss: 4.82697
Epoch 82, Val Loss: 4.77547
Epoch 83, Val Loss: 4.63645
Epoch 84, Val Loss: 4.69796
Epoch 85, Val Loss: 4.64536
Epoch 86, Val Loss: 5.02697
Epoch 87, Val Loss: 4.67623
Epoch 88, Val Loss: 4.60880
Epoch 89, Val Loss: 5.02813
Epoch 90, Val Loss: 4.52282
Epoch 91, Val Loss: 4.52478
Epoch 92, Val Loss: 4.71726
Epoch 93, Val Loss: 4.70957
Epoch 94, Val Loss: 4.66283
Epoch 95, Val Loss: 4.69901
Epoch 96, Val Loss: 4.56218
Epoch 97, Val Loss: 4.62489
Epoch 98, Val Loss: 5.07889
Epoch 99, Val Loss: 4.48492
DID NOT SAVE RESULTS
{'MSE - mean': 4.504405713289418, 'MSE - std': 0.20316375988251784, 'R2 - mean': 0.5564788963211834, 'R2 - std': 0.011864871497657508} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.23956
Epoch 1, Val Loss: 6.78091
Epoch 2, Val Loss: 5.86253
Epoch 3, Val Loss: 5.70676
Epoch 4, Val Loss: 5.96382
Epoch 5, Val Loss: 5.53909
Epoch 6, Val Loss: 5.93879
Epoch 7, Val Loss: 5.66161
Epoch 8, Val Loss: 5.52680
Epoch 9, Val Loss: 5.40091
Epoch 10, Val Loss: 5.21351
Epoch 11, Val Loss: 5.57331
Epoch 12, Val Loss: 5.17525
Epoch 13, Val Loss: 5.35090
Epoch 14, Val Loss: 5.09837
Epoch 15, Val Loss: 4.99505
Epoch 16, Val Loss: 4.98904
Epoch 17, Val Loss: 4.98266
Epoch 18, Val Loss: 4.88936
Epoch 19, Val Loss: 4.96708
Epoch 20, Val Loss: 4.89049
Epoch 21, Val Loss: 4.91058
Epoch 22, Val Loss: 5.03478
Epoch 23, Val Loss: 4.81243
Epoch 24, Val Loss: 4.76348
Epoch 25, Val Loss: 4.77971
Epoch 26, Val Loss: 4.72751
Epoch 27, Val Loss: 4.89573
Epoch 28, Val Loss: 4.70699
Epoch 29, Val Loss: 4.80958
Epoch 30, Val Loss: 4.69541
Epoch 31, Val Loss: 4.79604
Epoch 32, Val Loss: 4.69503
Epoch 33, Val Loss: 4.71222
Epoch 34, Val Loss: 4.94390
Epoch 35, Val Loss: 4.77323
Epoch 36, Val Loss: 4.80589
Epoch 37, Val Loss: 4.89682
Epoch 38, Val Loss: 4.73153
Epoch 39, Val Loss: 4.57920
Epoch 40, Val Loss: 4.50645
Epoch 41, Val Loss: 4.75933
Epoch 42, Val Loss: 4.51027
Epoch 43, Val Loss: 4.62944
Epoch 44, Val Loss: 4.76058
Epoch 45, Val Loss: 4.59717
Epoch 46, Val Loss: 4.76714
Epoch 47, Val Loss: 4.66879
Epoch 48, Val Loss: 4.63254
Epoch 49, Val Loss: 4.50145
Epoch 50, Val Loss: 4.66910
Epoch 51, Val Loss: 4.79293
Epoch 52, Val Loss: 4.63193
Epoch 53, Val Loss: 4.45278
Epoch 54, Val Loss: 4.52420
Epoch 55, Val Loss: 4.48801
Epoch 56, Val Loss: 4.58158
Epoch 57, Val Loss: 4.54523
Epoch 58, Val Loss: 4.47858
Epoch 59, Val Loss: 4.50996
Epoch 60, Val Loss: 4.82066
Epoch 61, Val Loss: 4.36142
Epoch 62, Val Loss: 4.36356
Epoch 63, Val Loss: 4.51483
Epoch 64, Val Loss: 4.32309
Epoch 65, Val Loss: 4.47988
Epoch 66, Val Loss: 4.53777
Epoch 67, Val Loss: 4.56389
Epoch 68, Val Loss: 4.54807
Epoch 69, Val Loss: 4.39856
Epoch 70, Val Loss: 4.84411
Epoch 71, Val Loss: 4.70505
Epoch 72, Val Loss: 4.72086
Epoch 73, Val Loss: 4.48164
Epoch 74, Val Loss: 4.42418
Epoch 75, Val Loss: 4.53012
Epoch 76, Val Loss: 4.37616
Epoch 77, Val Loss: 4.45686
Epoch 78, Val Loss: 4.56919
Epoch 79, Val Loss: 4.44094
Epoch 80, Val Loss: 4.40820
Epoch 81, Val Loss: 4.51251
Epoch 82, Val Loss: 4.58021
Epoch 83, Val Loss: 4.39955
Epoch 84, Val Loss: 4.30995
Epoch 85, Val Loss: 4.58200
Epoch 86, Val Loss: 5.01881
Epoch 87, Val Loss: 4.40014
Epoch 88, Val Loss: 4.41268
Epoch 89, Val Loss: 4.38304
Epoch 90, Val Loss: 4.32679
Epoch 91, Val Loss: 4.34457
Epoch 92, Val Loss: 4.48620
Epoch 93, Val Loss: 4.31944
Epoch 94, Val Loss: 4.89489
Epoch 95, Val Loss: 4.33001
Epoch 96, Val Loss: 4.49613
Epoch 97, Val Loss: 4.33953
Epoch 98, Val Loss: 4.39216
Epoch 99, Val Loss: 4.51273
DID NOT SAVE RESULTS
{'MSE - mean': 4.544471492971731, 'MSE - std': 0.18913602275044253, 'R2 - mean': 0.542671981477885, 'R2 - std': 0.026028332144265993} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.23586
Epoch 1, Val Loss: 14.67501
Epoch 2, Val Loss: 8.06161
Epoch 3, Val Loss: 8.09882
Epoch 4, Val Loss: 7.75706
Epoch 5, Val Loss: 7.81604
Epoch 6, Val Loss: 8.31674
Epoch 7, Val Loss: 8.56087
Epoch 8, Val Loss: 7.86879
Epoch 9, Val Loss: 7.71475
Epoch 10, Val Loss: 7.71966
Epoch 11, Val Loss: 7.50267
Epoch 12, Val Loss: 7.71807
Epoch 13, Val Loss: 7.40518
Epoch 14, Val Loss: 7.32725
Epoch 15, Val Loss: 7.44538
Epoch 16, Val Loss: 7.22266
Epoch 17, Val Loss: 7.59424
Epoch 18, Val Loss: 7.09153
Epoch 19, Val Loss: 7.14819
Epoch 20, Val Loss: 7.05027
Epoch 21, Val Loss: 6.93117
Epoch 22, Val Loss: 6.97985
Epoch 23, Val Loss: 7.05961
Epoch 24, Val Loss: 6.90082
Epoch 25, Val Loss: 6.75799
Epoch 26, Val Loss: 6.89149
Epoch 27, Val Loss: 6.97146
Epoch 28, Val Loss: 6.78286
Epoch 29, Val Loss: 6.72571
Epoch 30, Val Loss: 6.61245
Epoch 31, Val Loss: 6.73992
Epoch 32, Val Loss: 6.90190
Epoch 33, Val Loss: 6.60944
Epoch 34, Val Loss: 7.23564
Epoch 35, Val Loss: 6.56795
Epoch 36, Val Loss: 6.52919
Epoch 37, Val Loss: 6.43973
Epoch 38, Val Loss: 7.32861
Epoch 39, Val Loss: 6.75819
Epoch 40, Val Loss: 6.45724
Epoch 41, Val Loss: 6.41033
Epoch 42, Val Loss: 6.52935
Epoch 43, Val Loss: 6.47503
Epoch 44, Val Loss: 6.32863
Epoch 45, Val Loss: 6.30356
Epoch 46, Val Loss: 6.27800
Epoch 47, Val Loss: 6.30999
Epoch 48, Val Loss: 6.37802
Epoch 49, Val Loss: 6.41581
Epoch 50, Val Loss: 6.14572
Epoch 51, Val Loss: 6.44143
Epoch 52, Val Loss: 6.33798
Epoch 53, Val Loss: 6.44093
Epoch 54, Val Loss: 6.20547
Epoch 55, Val Loss: 6.34070
Epoch 56, Val Loss: 6.17815
Epoch 57, Val Loss: 6.30468
Epoch 58, Val Loss: 6.55375
Epoch 59, Val Loss: 6.18984
Epoch 60, Val Loss: 6.14427
Epoch 61, Val Loss: 6.08480
Epoch 62, Val Loss: 6.19345
Epoch 63, Val Loss: 6.24178
Epoch 64, Val Loss: 6.09396
Epoch 65, Val Loss: 6.41016
Epoch 66, Val Loss: 6.43316
Epoch 67, Val Loss: 6.12189
Epoch 68, Val Loss: 6.09522
Epoch 69, Val Loss: 6.13771
Epoch 70, Val Loss: 6.00012
Epoch 71, Val Loss: 6.38626
Epoch 72, Val Loss: 6.17777
Epoch 73, Val Loss: 6.25719
Epoch 74, Val Loss: 6.11833
Epoch 75, Val Loss: 6.13664
Epoch 76, Val Loss: 6.34336
Epoch 77, Val Loss: 5.99667
Epoch 78, Val Loss: 5.85209
Epoch 79, Val Loss: 6.19528
Epoch 80, Val Loss: 6.08983
Epoch 81, Val Loss: 6.41459
Epoch 82, Val Loss: 6.00102
Epoch 83, Val Loss: 6.02243
Epoch 84, Val Loss: 6.20977
Epoch 85, Val Loss: 6.07291
Epoch 86, Val Loss: 6.06118
Epoch 87, Val Loss: 6.07239
Epoch 88, Val Loss: 5.92865
Epoch 89, Val Loss: 6.01397
Epoch 90, Val Loss: 5.99566
Epoch 91, Val Loss: 6.46133
Epoch 92, Val Loss: 6.12126
Epoch 93, Val Loss: 6.09002
Epoch 94, Val Loss: 6.38475
Epoch 95, Val Loss: 6.36913
Epoch 96, Val Loss: 6.09420
Epoch 97, Val Loss: 5.95159
Epoch 98, Val Loss: 6.17449
Epoch 99, Val Loss: 6.01343
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.81016905929532, 'MSE - std': 0.5576726056411564, 'R2 - mean': 0.5369992080191509, 'R2 - std': 0.025897889763960555} 
 

Results After CV: {'MSE - mean': 4.81016905929532, 'MSE - std': 0.5576726056411564, 'R2 - mean': 0.5369992080191509, 'R2 - std': 0.025897889763960555}
Train time: 114.92770461500004
Inference time: 0.05273857700012741
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 50 finished with value: 4.81016905929532 and parameters: {'p_m': 0.7424106808961499, 'alpha': 1.0970372669874926, 'K': 20, 'beta': 3.656353806581328}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.62218
Epoch 1, Val Loss: 10.83188
Epoch 2, Val Loss: 8.14673
Epoch 3, Val Loss: 7.23203
Epoch 4, Val Loss: 6.83812
Epoch 5, Val Loss: 6.94463
Epoch 6, Val Loss: 6.62791
Epoch 7, Val Loss: 6.98749
Epoch 8, Val Loss: 6.46572
Epoch 9, Val Loss: 6.45606
Epoch 10, Val Loss: 6.45811
Epoch 11, Val Loss: 6.39803
Epoch 12, Val Loss: 6.54829
Epoch 13, Val Loss: 6.28493
Epoch 14, Val Loss: 6.14297
Epoch 15, Val Loss: 6.19258
Epoch 16, Val Loss: 6.23546
Epoch 17, Val Loss: 6.09030
Epoch 18, Val Loss: 6.08010
Epoch 19, Val Loss: 6.03028
Epoch 20, Val Loss: 5.89414
Epoch 21, Val Loss: 5.92750
Epoch 22, Val Loss: 5.87983
Epoch 23, Val Loss: 5.91786
Epoch 24, Val Loss: 5.88880
Epoch 25, Val Loss: 5.77014
Epoch 26, Val Loss: 5.71629
Epoch 27, Val Loss: 5.82253
Epoch 28, Val Loss: 5.82817
Epoch 29, Val Loss: 5.68246
Epoch 30, Val Loss: 5.67280
Epoch 31, Val Loss: 5.85788
Epoch 32, Val Loss: 5.72378
Epoch 33, Val Loss: 5.67232
Epoch 34, Val Loss: 5.46960
Epoch 35, Val Loss: 5.75699
Epoch 36, Val Loss: 5.52264
Epoch 37, Val Loss: 5.55074
Epoch 38, Val Loss: 5.72721
Epoch 39, Val Loss: 5.45942
Epoch 40, Val Loss: 5.38775
Epoch 41, Val Loss: 5.35010
Epoch 42, Val Loss: 5.37231
Epoch 43, Val Loss: 5.42125
Epoch 44, Val Loss: 5.63844
Epoch 45, Val Loss: 5.29295
Epoch 46, Val Loss: 5.52939
Epoch 47, Val Loss: 5.38595
Epoch 48, Val Loss: 5.36703
Epoch 49, Val Loss: 5.45854
Epoch 50, Val Loss: 5.53717
Epoch 51, Val Loss: 5.27033
Epoch 52, Val Loss: 5.17015
Epoch 53, Val Loss: 5.16877
Epoch 54, Val Loss: 5.26142
Epoch 55, Val Loss: 5.16391
Epoch 56, Val Loss: 5.22406
Epoch 57, Val Loss: 5.36334
Epoch 58, Val Loss: 5.17583
Epoch 59, Val Loss: 5.34495
Epoch 60, Val Loss: 5.21915
Epoch 61, Val Loss: 5.34518
Epoch 62, Val Loss: 5.24321
Epoch 63, Val Loss: 5.14802
Epoch 64, Val Loss: 5.22143
Epoch 65, Val Loss: 5.27972
Epoch 66, Val Loss: 5.12003
Epoch 67, Val Loss: 5.06510
Epoch 68, Val Loss: 5.04137
Epoch 69, Val Loss: 5.01655
Epoch 70, Val Loss: 4.98696
Epoch 71, Val Loss: 5.40153
Epoch 72, Val Loss: 5.13285
Epoch 73, Val Loss: 5.17916
Epoch 74, Val Loss: 5.04864
Epoch 75, Val Loss: 5.21744
Epoch 76, Val Loss: 5.65820
Epoch 77, Val Loss: 5.04163
Epoch 78, Val Loss: 4.97840
Epoch 79, Val Loss: 5.04525
Epoch 80, Val Loss: 5.15604
Epoch 81, Val Loss: 5.27646
Epoch 82, Val Loss: 5.09049
Epoch 83, Val Loss: 5.09752
Epoch 84, Val Loss: 5.72625
Epoch 85, Val Loss: 5.22212
Epoch 86, Val Loss: 5.09741
Epoch 87, Val Loss: 4.93618
Epoch 88, Val Loss: 5.00531
Epoch 89, Val Loss: 5.07786
Epoch 90, Val Loss: 4.97933
Epoch 91, Val Loss: 4.87671
Epoch 92, Val Loss: 5.08113
Epoch 93, Val Loss: 5.03950
Epoch 94, Val Loss: 5.36133
Epoch 95, Val Loss: 4.89899
Epoch 96, Val Loss: 4.95687
Epoch 97, Val Loss: 4.96852
Epoch 98, Val Loss: 5.08046
Epoch 99, Val Loss: 4.86913
DID NOT SAVE RESULTS
{'MSE - mean': 5.0169131829089135, 'MSE - std': 0.0, 'R2 - mean': 0.5424740953210819, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.12253
Epoch 1, Val Loss: 9.67578
Epoch 2, Val Loss: 6.08795
Epoch 3, Val Loss: 6.09835
Epoch 4, Val Loss: 5.76327
Epoch 5, Val Loss: 5.82862
Epoch 6, Val Loss: 5.70646
Epoch 7, Val Loss: 5.46566
Epoch 8, Val Loss: 5.43224
Epoch 9, Val Loss: 5.61532
Epoch 10, Val Loss: 5.55884
Epoch 11, Val Loss: 5.34609
Epoch 12, Val Loss: 5.32986
Epoch 13, Val Loss: 5.39492
Epoch 14, Val Loss: 5.71459
Epoch 15, Val Loss: 5.40603
Epoch 16, Val Loss: 5.16873
Epoch 17, Val Loss: 5.29612
Epoch 18, Val Loss: 5.21860
Epoch 19, Val Loss: 5.18650
Epoch 20, Val Loss: 5.13417
Epoch 21, Val Loss: 5.48813
Epoch 22, Val Loss: 5.29727
Epoch 23, Val Loss: 5.63306
Epoch 24, Val Loss: 5.34420
Epoch 25, Val Loss: 5.22073
Epoch 26, Val Loss: 5.08638
Epoch 27, Val Loss: 5.06265
Epoch 28, Val Loss: 4.97121
Epoch 29, Val Loss: 4.99653
Epoch 30, Val Loss: 5.31245
Epoch 31, Val Loss: 4.93075
Epoch 32, Val Loss: 4.87550
Epoch 33, Val Loss: 5.00125
Epoch 34, Val Loss: 4.99580
Epoch 35, Val Loss: 4.95869
Epoch 36, Val Loss: 4.83598
Epoch 37, Val Loss: 4.99564
Epoch 38, Val Loss: 5.08830
Epoch 39, Val Loss: 4.71001
Epoch 40, Val Loss: 4.78676
Epoch 41, Val Loss: 4.74283
Epoch 42, Val Loss: 5.28661
Epoch 43, Val Loss: 4.68936
Epoch 44, Val Loss: 4.88076
Epoch 45, Val Loss: 4.57610
Epoch 46, Val Loss: 4.84189
Epoch 47, Val Loss: 4.90403
Epoch 48, Val Loss: 4.92785
Epoch 49, Val Loss: 5.00850
Epoch 50, Val Loss: 4.74049
Epoch 51, Val Loss: 4.58147
Epoch 52, Val Loss: 4.58152
Epoch 53, Val Loss: 4.65324
Epoch 54, Val Loss: 4.39647
Epoch 55, Val Loss: 4.41325
Epoch 56, Val Loss: 4.65706
Epoch 57, Val Loss: 4.50098
Epoch 58, Val Loss: 4.89604
Epoch 59, Val Loss: 4.51242
Epoch 60, Val Loss: 4.51602
Epoch 61, Val Loss: 4.28761
Epoch 62, Val Loss: 4.22506
Epoch 63, Val Loss: 4.25022
Epoch 64, Val Loss: 4.38390
Epoch 65, Val Loss: 4.39327
Epoch 66, Val Loss: 4.41728
Epoch 67, Val Loss: 4.33853
Epoch 68, Val Loss: 4.45086
Epoch 69, Val Loss: 5.24612
Epoch 70, Val Loss: 4.22671
Epoch 71, Val Loss: 4.24979
Epoch 72, Val Loss: 4.31214
Epoch 73, Val Loss: 4.40354
Epoch 74, Val Loss: 4.31920
Epoch 75, Val Loss: 4.19299
Epoch 76, Val Loss: 4.27620
Epoch 77, Val Loss: 4.18371
Epoch 78, Val Loss: 4.95199
Epoch 79, Val Loss: 4.13403
Epoch 80, Val Loss: 4.19850
Epoch 81, Val Loss: 4.14574
Epoch 82, Val Loss: 4.22305
Epoch 83, Val Loss: 4.13424
Epoch 84, Val Loss: 4.12934
Epoch 85, Val Loss: 4.33280
Epoch 86, Val Loss: 4.24078
Epoch 87, Val Loss: 4.27034
Epoch 88, Val Loss: 4.07149
Epoch 89, Val Loss: 4.13443
Epoch 90, Val Loss: 4.16827
Epoch 91, Val Loss: 4.23973
Epoch 92, Val Loss: 4.21439
Epoch 93, Val Loss: 4.56760
Epoch 94, Val Loss: 4.31762
Epoch 95, Val Loss: 4.20386
Epoch 96, Val Loss: 4.07053
Epoch 97, Val Loss: 4.18188
Epoch 98, Val Loss: 4.02051
Epoch 99, Val Loss: 4.09310
DID NOT SAVE RESULTS
{'MSE - mean': 4.629875441996804, 'MSE - std': 0.3870377409121093, 'R2 - mean': 0.5451010878431084, 'R2 - std': 0.0026269925220264168} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.08179
Epoch 1, Val Loss: 11.29549
Epoch 2, Val Loss: 7.01847
Epoch 3, Val Loss: 6.46075
Epoch 4, Val Loss: 6.61229
Epoch 5, Val Loss: 6.36622
Epoch 6, Val Loss: 6.65370
Epoch 7, Val Loss: 6.28340
Epoch 8, Val Loss: 6.24514
Epoch 9, Val Loss: 6.35060
Epoch 10, Val Loss: 6.19003
Epoch 11, Val Loss: 6.21885
Epoch 12, Val Loss: 6.14653
Epoch 13, Val Loss: 6.30872
Epoch 14, Val Loss: 6.07353
Epoch 15, Val Loss: 6.01674
Epoch 16, Val Loss: 5.90391
Epoch 17, Val Loss: 5.88032
Epoch 18, Val Loss: 5.93462
Epoch 19, Val Loss: 5.90727
Epoch 20, Val Loss: 5.83809
Epoch 21, Val Loss: 5.82229
Epoch 22, Val Loss: 5.86273
Epoch 23, Val Loss: 5.84509
Epoch 24, Val Loss: 5.93008
Epoch 25, Val Loss: 5.98103
Epoch 26, Val Loss: 5.76599
Epoch 27, Val Loss: 5.61992
Epoch 28, Val Loss: 5.62729
Epoch 29, Val Loss: 5.57963
Epoch 30, Val Loss: 5.60059
Epoch 31, Val Loss: 5.49334
Epoch 32, Val Loss: 5.60246
Epoch 33, Val Loss: 5.45153
Epoch 34, Val Loss: 5.43214
Epoch 35, Val Loss: 5.37654
Epoch 36, Val Loss: 5.38517
Epoch 37, Val Loss: 5.38396
Epoch 38, Val Loss: 5.54612
Epoch 39, Val Loss: 5.68105
Epoch 40, Val Loss: 5.31695
Epoch 41, Val Loss: 5.26278
Epoch 42, Val Loss: 5.39083
Epoch 43, Val Loss: 5.30497
Epoch 44, Val Loss: 5.27261
Epoch 45, Val Loss: 5.44220
Epoch 46, Val Loss: 5.34719
Epoch 47, Val Loss: 5.19151
Epoch 48, Val Loss: 5.25503
Epoch 49, Val Loss: 5.13399
Epoch 50, Val Loss: 5.28107
Epoch 51, Val Loss: 5.19839
Epoch 52, Val Loss: 5.15335
Epoch 53, Val Loss: 5.13605
Epoch 54, Val Loss: 5.76342
Epoch 55, Val Loss: 5.07919
Epoch 56, Val Loss: 5.03949
Epoch 57, Val Loss: 5.23275
Epoch 58, Val Loss: 5.02845
Epoch 59, Val Loss: 5.08541
Epoch 60, Val Loss: 4.96623
Epoch 61, Val Loss: 5.15873
Epoch 62, Val Loss: 4.98786
Epoch 63, Val Loss: 5.17475
Epoch 64, Val Loss: 5.08796
Epoch 65, Val Loss: 4.88221
Epoch 66, Val Loss: 4.96943
Epoch 67, Val Loss: 4.84630
Epoch 68, Val Loss: 4.95640
Epoch 69, Val Loss: 5.15072
Epoch 70, Val Loss: 4.91314
Epoch 71, Val Loss: 5.09614
Epoch 72, Val Loss: 5.04817
Epoch 73, Val Loss: 4.91949
Epoch 74, Val Loss: 4.81902
Epoch 75, Val Loss: 4.92437
Epoch 76, Val Loss: 4.77923
Epoch 77, Val Loss: 5.17761
Epoch 78, Val Loss: 4.88474
Epoch 79, Val Loss: 4.94913
Epoch 80, Val Loss: 4.85840
Epoch 81, Val Loss: 4.94667
Epoch 82, Val Loss: 4.71833
Epoch 83, Val Loss: 4.88987
Epoch 84, Val Loss: 4.72791
Epoch 85, Val Loss: 5.20839
Epoch 86, Val Loss: 4.75916
Epoch 87, Val Loss: 4.95773
Epoch 88, Val Loss: 4.96650
Epoch 89, Val Loss: 4.81012
Epoch 90, Val Loss: 4.86313
Epoch 91, Val Loss: 4.83057
Epoch 92, Val Loss: 5.04729
Epoch 93, Val Loss: 4.70789
Epoch 94, Val Loss: 5.06830
Epoch 95, Val Loss: 4.76278
Epoch 96, Val Loss: 4.77922
Epoch 97, Val Loss: 4.95747
Epoch 98, Val Loss: 4.80209
Epoch 99, Val Loss: 4.80894
DID NOT SAVE RESULTS
{'MSE - mean': 4.676566844654157, 'MSE - std': 0.32283997494804556, 'R2 - mean': 0.5402817873818949, 'R2 - std': 0.007145071052464102} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.13645
Epoch 1, Val Loss: 10.94657
Epoch 2, Val Loss: 6.15679
Epoch 3, Val Loss: 5.92138
Epoch 4, Val Loss: 5.96750
Epoch 5, Val Loss: 5.87147
Epoch 6, Val Loss: 5.44266
Epoch 7, Val Loss: 5.36699
Epoch 8, Val Loss: 5.37195
Epoch 9, Val Loss: 5.63247
Epoch 10, Val Loss: 5.32643
Epoch 11, Val Loss: 5.19692
Epoch 12, Val Loss: 5.52848
Epoch 13, Val Loss: 5.30900
Epoch 14, Val Loss: 5.19036
Epoch 15, Val Loss: 5.21411
Epoch 16, Val Loss: 5.08271
Epoch 17, Val Loss: 5.11583
Epoch 18, Val Loss: 5.03714
Epoch 19, Val Loss: 4.98419
Epoch 20, Val Loss: 5.08233
Epoch 21, Val Loss: 5.09607
Epoch 22, Val Loss: 5.01816
Epoch 23, Val Loss: 5.04054
Epoch 24, Val Loss: 5.03730
Epoch 25, Val Loss: 4.94403
Epoch 26, Val Loss: 4.91443
Epoch 27, Val Loss: 4.81637
Epoch 28, Val Loss: 4.82554
Epoch 29, Val Loss: 4.89459
Epoch 30, Val Loss: 4.75902
Epoch 31, Val Loss: 4.82442
Epoch 32, Val Loss: 4.86324
Epoch 33, Val Loss: 4.78332
Epoch 34, Val Loss: 4.71778
Epoch 35, Val Loss: 4.69521
Epoch 36, Val Loss: 4.62004
Epoch 37, Val Loss: 4.68040
Epoch 38, Val Loss: 4.80519
Epoch 39, Val Loss: 4.56661
Epoch 40, Val Loss: 4.89846
Epoch 41, Val Loss: 4.50215
Epoch 42, Val Loss: 4.57230
Epoch 43, Val Loss: 4.50004
Epoch 44, Val Loss: 4.53827
Epoch 45, Val Loss: 4.88637
Epoch 46, Val Loss: 4.41545
Epoch 47, Val Loss: 4.43104
Epoch 48, Val Loss: 4.41980
Epoch 49, Val Loss: 4.47912
Epoch 50, Val Loss: 4.53550
Epoch 51, Val Loss: 4.47632
Epoch 52, Val Loss: 4.30143
Epoch 53, Val Loss: 4.28387
Epoch 54, Val Loss: 4.49274
Epoch 55, Val Loss: 4.34616
Epoch 56, Val Loss: 4.21386
Epoch 57, Val Loss: 4.37529
Epoch 58, Val Loss: 4.52987
Epoch 59, Val Loss: 4.18821
Epoch 60, Val Loss: 4.39326
Epoch 61, Val Loss: 4.16005
Epoch 62, Val Loss: 4.16900
Epoch 63, Val Loss: 4.75546
Epoch 64, Val Loss: 4.38102
Epoch 65, Val Loss: 4.61206
Epoch 66, Val Loss: 4.15529
Epoch 67, Val Loss: 4.13166
Epoch 68, Val Loss: 4.19279
Epoch 69, Val Loss: 4.15340
Epoch 70, Val Loss: 4.10987
Epoch 71, Val Loss: 4.32639
Epoch 72, Val Loss: 4.11889
Epoch 73, Val Loss: 4.48703
Epoch 74, Val Loss: 4.05493
Epoch 75, Val Loss: 4.14488
Epoch 76, Val Loss: 3.99867
Epoch 77, Val Loss: 4.16419
Epoch 78, Val Loss: 4.46893
Epoch 79, Val Loss: 4.27372
Epoch 80, Val Loss: 4.07615
Epoch 81, Val Loss: 4.12385
Epoch 82, Val Loss: 4.28651
Epoch 83, Val Loss: 4.13620
Epoch 84, Val Loss: 4.25200
Epoch 85, Val Loss: 4.29396
Epoch 86, Val Loss: 4.28107
Epoch 87, Val Loss: 4.34088
Epoch 88, Val Loss: 4.05085
Epoch 89, Val Loss: 4.03158
Epoch 90, Val Loss: 4.16916
Epoch 91, Val Loss: 3.99686
Epoch 92, Val Loss: 4.12795
Epoch 93, Val Loss: 4.16831
Epoch 94, Val Loss: 3.99318
Epoch 95, Val Loss: 4.04869
Epoch 96, Val Loss: 3.97505
Epoch 97, Val Loss: 4.08968
Epoch 98, Val Loss: 4.16584
Epoch 99, Val Loss: 4.50439
DID NOT SAVE RESULTS
{'MSE - mean': 4.559511303789067, 'MSE - std': 0.34536247047123797, 'R2 - mean': 0.5427217523241323, 'R2 - std': 0.007493284794842188} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.03609
Epoch 1, Val Loss: 13.09752
Epoch 2, Val Loss: 11.70523
Epoch 3, Val Loss: 8.39455
Epoch 4, Val Loss: 8.01269
Epoch 5, Val Loss: 8.00504
Epoch 6, Val Loss: 8.17911
Epoch 7, Val Loss: 7.88791
Epoch 8, Val Loss: 7.65266
Epoch 9, Val Loss: 7.86936
Epoch 10, Val Loss: 7.70856
Epoch 11, Val Loss: 8.03764
Epoch 12, Val Loss: 7.64857
Epoch 13, Val Loss: 7.76149
Epoch 14, Val Loss: 7.44642
Epoch 15, Val Loss: 7.66805
Epoch 16, Val Loss: 7.84134
Epoch 17, Val Loss: 7.69141
Epoch 18, Val Loss: 7.41294
Epoch 19, Val Loss: 7.55726
Epoch 20, Val Loss: 7.72707
Epoch 21, Val Loss: 7.30916
Epoch 22, Val Loss: 7.37461
Epoch 23, Val Loss: 7.59474
Epoch 24, Val Loss: 7.58777
Epoch 25, Val Loss: 7.35708
Epoch 26, Val Loss: 7.28082
Epoch 27, Val Loss: 7.37435
Epoch 28, Val Loss: 7.19954
Epoch 29, Val Loss: 7.17805
Epoch 30, Val Loss: 7.40471
Epoch 31, Val Loss: 7.32089
Epoch 32, Val Loss: 7.21453
Epoch 33, Val Loss: 7.38696
Epoch 34, Val Loss: 7.15394
Epoch 35, Val Loss: 7.23343
Epoch 36, Val Loss: 7.20363
Epoch 37, Val Loss: 7.50936
Epoch 38, Val Loss: 7.18254
Epoch 39, Val Loss: 7.08119
Epoch 40, Val Loss: 7.14376
Epoch 41, Val Loss: 7.09024
Epoch 42, Val Loss: 7.32186
Epoch 43, Val Loss: 7.27597
Epoch 44, Val Loss: 7.34850
Epoch 45, Val Loss: 7.06193
Epoch 46, Val Loss: 6.90543
Epoch 47, Val Loss: 7.30206
Epoch 48, Val Loss: 7.19288
Epoch 49, Val Loss: 6.89568
Epoch 50, Val Loss: 7.00342
Epoch 51, Val Loss: 7.75134
Epoch 52, Val Loss: 7.39109
Epoch 53, Val Loss: 6.93855
Epoch 54, Val Loss: 6.90093
Epoch 55, Val Loss: 7.56242
Epoch 56, Val Loss: 6.93729
Epoch 57, Val Loss: 7.14975
Epoch 58, Val Loss: 6.92517
Epoch 59, Val Loss: 7.52867
Epoch 60, Val Loss: 6.89327
Epoch 61, Val Loss: 6.84185
Epoch 62, Val Loss: 7.13245
Epoch 63, Val Loss: 6.90379
Epoch 64, Val Loss: 6.93053
Epoch 65, Val Loss: 6.76002
Epoch 66, Val Loss: 7.15060
Epoch 67, Val Loss: 6.84864
Epoch 68, Val Loss: 6.97515
Epoch 69, Val Loss: 6.58126
Epoch 70, Val Loss: 6.69539
Epoch 71, Val Loss: 6.69896
Epoch 72, Val Loss: 6.60189
Epoch 73, Val Loss: 6.64031
Epoch 74, Val Loss: 6.86310
Epoch 75, Val Loss: 6.76451
Epoch 76, Val Loss: 6.74321
Epoch 77, Val Loss: 6.85737
Epoch 78, Val Loss: 6.54461
Epoch 79, Val Loss: 6.72586
Epoch 80, Val Loss: 6.45293
Epoch 81, Val Loss: 6.42822
Epoch 82, Val Loss: 6.35807
Epoch 83, Val Loss: 6.46377
Epoch 84, Val Loss: 6.45502
Epoch 85, Val Loss: 6.45000
Epoch 86, Val Loss: 6.69695
Epoch 87, Val Loss: 6.39878
Epoch 88, Val Loss: 6.47363
Epoch 89, Val Loss: 6.26564
Epoch 90, Val Loss: 6.53417
Epoch 91, Val Loss: 6.29091
Epoch 92, Val Loss: 6.68836
Epoch 93, Val Loss: 6.57385
Epoch 94, Val Loss: 6.30182
Epoch 95, Val Loss: 6.45749
Epoch 96, Val Loss: 6.52876
Epoch 97, Val Loss: 6.36364
Epoch 98, Val Loss: 6.78460
Epoch 99, Val Loss: 6.46246
DID NOT SAVE RESULTS
{'MSE - mean': 4.910100615651393, 'MSE - std': 0.7662060109242111, 'R2 - mean': 0.529769746562757, 'R2 - std': 0.026757004065928024} 
 

Results After CV: {'MSE - mean': 4.910100615651393, 'MSE - std': 0.7662060109242111, 'R2 - mean': 0.529769746562757, 'R2 - std': 0.026757004065928024}
Train time: 113.76157271099946
Inference time: 0.05509981739996874
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 51 finished with value: 4.910100615651393 and parameters: {'p_m': 0.8231815718445588, 'alpha': 2.997189098093011, 'K': 20, 'beta': 6.585140927135938}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.18018
Epoch 1, Val Loss: 14.64667
Epoch 2, Val Loss: 6.96126
Epoch 3, Val Loss: 6.75613
Epoch 4, Val Loss: 6.78113
Epoch 5, Val Loss: 6.93309
Epoch 6, Val Loss: 6.65777
Epoch 7, Val Loss: 6.40298
Epoch 8, Val Loss: 6.50758
Epoch 9, Val Loss: 6.34535
Epoch 10, Val Loss: 6.20259
Epoch 11, Val Loss: 6.22123
Epoch 12, Val Loss: 6.11262
Epoch 13, Val Loss: 6.27029
Epoch 14, Val Loss: 6.06784
Epoch 15, Val Loss: 5.94383
Epoch 16, Val Loss: 5.98928
Epoch 17, Val Loss: 5.93234
Epoch 18, Val Loss: 6.24893
Epoch 19, Val Loss: 5.82602
Epoch 20, Val Loss: 6.40415
Epoch 21, Val Loss: 5.81236
Epoch 22, Val Loss: 5.89279
Epoch 23, Val Loss: 5.76005
Epoch 24, Val Loss: 5.82838
Epoch 25, Val Loss: 5.84308
Epoch 26, Val Loss: 5.66079
Epoch 27, Val Loss: 5.63410
Epoch 28, Val Loss: 5.53405
Epoch 29, Val Loss: 5.56699
Epoch 30, Val Loss: 5.61482
Epoch 31, Val Loss: 5.52464
Epoch 32, Val Loss: 5.45399
Epoch 33, Val Loss: 5.56925
Epoch 34, Val Loss: 5.49955
Epoch 35, Val Loss: 5.38684
Epoch 36, Val Loss: 6.03509
Epoch 37, Val Loss: 5.32533
Epoch 38, Val Loss: 5.27585
Epoch 39, Val Loss: 5.59712
Epoch 40, Val Loss: 5.42201
Epoch 41, Val Loss: 5.27952
Epoch 42, Val Loss: 5.21846
Epoch 43, Val Loss: 5.65303
Epoch 44, Val Loss: 5.52717
Epoch 45, Val Loss: 5.76381
Epoch 46, Val Loss: 5.44353
Epoch 47, Val Loss: 5.39120
Epoch 48, Val Loss: 5.17147
Epoch 49, Val Loss: 5.04900
Epoch 50, Val Loss: 5.64745
Epoch 51, Val Loss: 5.12291
Epoch 52, Val Loss: 5.13535
Epoch 53, Val Loss: 5.15740
Epoch 54, Val Loss: 5.01040
Epoch 55, Val Loss: 5.10056
Epoch 56, Val Loss: 5.56192
Epoch 57, Val Loss: 5.23519
Epoch 58, Val Loss: 4.86031
Epoch 59, Val Loss: 4.93698
Epoch 60, Val Loss: 4.91742
Epoch 61, Val Loss: 5.27909
Epoch 62, Val Loss: 4.89834
Epoch 63, Val Loss: 5.09609
Epoch 64, Val Loss: 4.95270
Epoch 65, Val Loss: 5.02615
Epoch 66, Val Loss: 5.46171
Epoch 67, Val Loss: 5.05722
Epoch 68, Val Loss: 4.75701
Epoch 69, Val Loss: 4.82790
Epoch 70, Val Loss: 4.81683
Epoch 71, Val Loss: 4.76150
Epoch 72, Val Loss: 4.89540
Epoch 73, Val Loss: 4.91445
Epoch 74, Val Loss: 5.00919
Epoch 75, Val Loss: 4.97449
Epoch 76, Val Loss: 5.16167
Epoch 77, Val Loss: 5.12157
Epoch 78, Val Loss: 5.08011
Epoch 79, Val Loss: 4.90387
Epoch 80, Val Loss: 4.68841
Epoch 81, Val Loss: 4.63424
Epoch 82, Val Loss: 4.93517
Epoch 83, Val Loss: 4.75021
Epoch 84, Val Loss: 5.27958
Epoch 85, Val Loss: 4.85551
Epoch 86, Val Loss: 4.76488
Epoch 87, Val Loss: 4.58536
Epoch 88, Val Loss: 5.05362
Epoch 89, Val Loss: 4.63334
Epoch 90, Val Loss: 4.61478
Epoch 91, Val Loss: 4.78659
Epoch 92, Val Loss: 4.61297
Epoch 93, Val Loss: 4.77460
Epoch 94, Val Loss: 4.68704
Epoch 95, Val Loss: 4.47543
Epoch 96, Val Loss: 4.81649
Epoch 97, Val Loss: 4.61291
Epoch 98, Val Loss: 4.75409
Epoch 99, Val Loss: 4.49808
DID NOT SAVE RESULTS
{'MSE - mean': 4.579527472300086, 'MSE - std': 0.0, 'R2 - mean': 0.5823622268561595, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.71220
Epoch 1, Val Loss: 10.62909
Epoch 2, Val Loss: 6.84312
Epoch 3, Val Loss: 6.42140
Epoch 4, Val Loss: 5.98183
Epoch 5, Val Loss: 5.73997
Epoch 6, Val Loss: 5.98587
Epoch 7, Val Loss: 5.82113
Epoch 8, Val Loss: 5.25994
Epoch 9, Val Loss: 5.96485
Epoch 10, Val Loss: 5.10938
Epoch 11, Val Loss: 4.93062
Epoch 12, Val Loss: 4.84484
Epoch 13, Val Loss: 4.92088
Epoch 14, Val Loss: 5.62350
Epoch 15, Val Loss: 5.01387
Epoch 16, Val Loss: 4.84496
Epoch 17, Val Loss: 4.68140
Epoch 18, Val Loss: 4.69331
Epoch 19, Val Loss: 4.57276
Epoch 20, Val Loss: 4.60897
Epoch 21, Val Loss: 4.69630
Epoch 22, Val Loss: 4.46395
Epoch 23, Val Loss: 4.96144
Epoch 24, Val Loss: 4.51976
Epoch 25, Val Loss: 4.36026
Epoch 26, Val Loss: 4.42051
Epoch 27, Val Loss: 4.38258
Epoch 28, Val Loss: 4.24770
Epoch 29, Val Loss: 4.20357
Epoch 30, Val Loss: 4.58284
Epoch 31, Val Loss: 4.48914
Epoch 32, Val Loss: 4.30622
Epoch 33, Val Loss: 4.80879
Epoch 34, Val Loss: 4.19889
Epoch 35, Val Loss: 4.35296
Epoch 36, Val Loss: 4.23359
Epoch 37, Val Loss: 4.45229
Epoch 38, Val Loss: 4.54627
Epoch 39, Val Loss: 4.12471
Epoch 40, Val Loss: 4.04251
Epoch 41, Val Loss: 4.36672
Epoch 42, Val Loss: 4.16836
Epoch 43, Val Loss: 4.29051
Epoch 44, Val Loss: 4.34745
Epoch 45, Val Loss: 4.10062
Epoch 46, Val Loss: 4.15414
Epoch 47, Val Loss: 3.94727
Epoch 48, Val Loss: 4.10342
Epoch 49, Val Loss: 4.05200
Epoch 50, Val Loss: 4.07427
Epoch 51, Val Loss: 3.98111
Epoch 52, Val Loss: 3.91968
Epoch 53, Val Loss: 4.09396
Epoch 54, Val Loss: 3.97655
Epoch 55, Val Loss: 4.14500
Epoch 56, Val Loss: 4.15514
Epoch 57, Val Loss: 4.47933
Epoch 58, Val Loss: 3.92520
Epoch 59, Val Loss: 3.88518
Epoch 60, Val Loss: 3.82503
Epoch 61, Val Loss: 3.77268
Epoch 62, Val Loss: 3.84949
Epoch 63, Val Loss: 4.05838
Epoch 64, Val Loss: 3.90153
Epoch 65, Val Loss: 4.00859
Epoch 66, Val Loss: 3.99899
Epoch 67, Val Loss: 3.97094
Epoch 68, Val Loss: 3.95314
Epoch 69, Val Loss: 3.91612
Epoch 70, Val Loss: 3.81059
Epoch 71, Val Loss: 3.86827
Epoch 72, Val Loss: 4.21774
Epoch 73, Val Loss: 3.89494
Epoch 74, Val Loss: 4.02454
Epoch 75, Val Loss: 4.01279
Epoch 76, Val Loss: 3.81596
Epoch 77, Val Loss: 3.87370
Epoch 78, Val Loss: 4.42792
Epoch 79, Val Loss: 3.80660
Epoch 80, Val Loss: 3.88592
Epoch 81, Val Loss: 3.87538
Epoch 82, Val Loss: 3.88043
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.284683589208212, 'MSE - std': 0.2948438830918738, 'R2 - mean': 0.5785295120647611, 'R2 - std': 0.003832714791398295} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.60368
Epoch 1, Val Loss: 10.89016
Epoch 2, Val Loss: 6.33592
Epoch 3, Val Loss: 6.20996
Epoch 4, Val Loss: 5.99180
Epoch 5, Val Loss: 5.87486
Epoch 6, Val Loss: 6.06924
Epoch 7, Val Loss: 5.76764
Epoch 8, Val Loss: 5.73143
Epoch 9, Val Loss: 5.64334
Epoch 10, Val Loss: 5.82474
Epoch 11, Val Loss: 5.84522
Epoch 12, Val Loss: 5.55867
Epoch 13, Val Loss: 5.50317
Epoch 14, Val Loss: 5.52666
Epoch 15, Val Loss: 5.62029
Epoch 16, Val Loss: 5.44896
Epoch 17, Val Loss: 5.46855
Epoch 18, Val Loss: 5.35304
Epoch 19, Val Loss: 5.39065
Epoch 20, Val Loss: 5.53961
Epoch 21, Val Loss: 5.44490
Epoch 22, Val Loss: 5.35850
Epoch 23, Val Loss: 5.43728
Epoch 24, Val Loss: 5.30352
Epoch 25, Val Loss: 5.37273
Epoch 26, Val Loss: 5.20565
Epoch 27, Val Loss: 5.49648
Epoch 28, Val Loss: 5.28788
Epoch 29, Val Loss: 5.26280
Epoch 30, Val Loss: 5.43853
Epoch 31, Val Loss: 5.25222
Epoch 32, Val Loss: 5.38918
Epoch 33, Val Loss: 5.12132
Epoch 34, Val Loss: 5.55641
Epoch 35, Val Loss: 5.33452
Epoch 36, Val Loss: 5.21448
Epoch 37, Val Loss: 5.04168
Epoch 38, Val Loss: 5.08201
Epoch 39, Val Loss: 4.97803
Epoch 40, Val Loss: 5.26353
Epoch 41, Val Loss: 5.13477
Epoch 42, Val Loss: 5.08094
Epoch 43, Val Loss: 4.95859
Epoch 44, Val Loss: 4.99922
Epoch 45, Val Loss: 5.40819
Epoch 46, Val Loss: 5.02453
Epoch 47, Val Loss: 5.12115
Epoch 48, Val Loss: 4.80672
Epoch 49, Val Loss: 5.07904
Epoch 50, Val Loss: 5.01673
Epoch 51, Val Loss: 4.74604
Epoch 52, Val Loss: 4.94431
Epoch 53, Val Loss: 4.73138
Epoch 54, Val Loss: 5.15155
Epoch 55, Val Loss: 4.92196
Epoch 56, Val Loss: 4.89577
Epoch 57, Val Loss: 4.88002
Epoch 58, Val Loss: 4.82934
Epoch 59, Val Loss: 4.87121
Epoch 60, Val Loss: 4.87959
Epoch 61, Val Loss: 4.77350
Epoch 62, Val Loss: 5.36849
Epoch 63, Val Loss: 4.86776
Epoch 64, Val Loss: 5.11412
Epoch 65, Val Loss: 4.74816
Epoch 66, Val Loss: 5.18198
Epoch 67, Val Loss: 4.74392
Epoch 68, Val Loss: 4.75528
Epoch 69, Val Loss: 4.76490
Epoch 70, Val Loss: 4.79770
Epoch 71, Val Loss: 4.77293
Epoch 72, Val Loss: 4.84163
Epoch 73, Val Loss: 4.89595
Epoch 74, Val Loss: 4.90038
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.480002166994324, 'MSE - std': 0.36640683752887077, 'R2 - mean': 0.5592648261193548, 'R2 - std': 0.027423518816247442} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 43.42091
Epoch 1, Val Loss: 17.49691
Epoch 2, Val Loss: 6.47280
Epoch 3, Val Loss: 6.27210
Epoch 4, Val Loss: 5.54061
Epoch 5, Val Loss: 5.21917
Epoch 6, Val Loss: 5.08995
Epoch 7, Val Loss: 4.83009
Epoch 8, Val Loss: 4.88072
Epoch 9, Val Loss: 4.81828
Epoch 10, Val Loss: 4.83809
Epoch 11, Val Loss: 4.81082
Epoch 12, Val Loss: 4.64051
Epoch 13, Val Loss: 4.68947
Epoch 14, Val Loss: 4.64893
Epoch 15, Val Loss: 4.55854
Epoch 16, Val Loss: 4.50786
Epoch 17, Val Loss: 4.66760
Epoch 18, Val Loss: 4.41988
Epoch 19, Val Loss: 4.97105
Epoch 20, Val Loss: 4.56423
Epoch 21, Val Loss: 4.48705
Epoch 22, Val Loss: 4.35661
Epoch 23, Val Loss: 4.42176
Epoch 24, Val Loss: 4.61174
Epoch 25, Val Loss: 4.50058
Epoch 26, Val Loss: 4.77051
Epoch 27, Val Loss: 4.58024
Epoch 28, Val Loss: 4.55450
Epoch 29, Val Loss: 4.33892
Epoch 30, Val Loss: 4.32910
Epoch 31, Val Loss: 4.30397
Epoch 32, Val Loss: 4.31037
Epoch 33, Val Loss: 4.44660
Epoch 34, Val Loss: 4.30561
Epoch 35, Val Loss: 4.19827
Epoch 36, Val Loss: 4.29224
Epoch 37, Val Loss: 4.08080
Epoch 38, Val Loss: 4.23358
Epoch 39, Val Loss: 4.27298
Epoch 40, Val Loss: 4.43506
Epoch 41, Val Loss: 4.08580
Epoch 42, Val Loss: 4.16821
Epoch 43, Val Loss: 4.32814
Epoch 44, Val Loss: 4.26502
Epoch 45, Val Loss: 4.22247
Epoch 46, Val Loss: 4.45771
Epoch 47, Val Loss: 3.99980
Epoch 48, Val Loss: 4.23336
Epoch 49, Val Loss: 3.98587
Epoch 50, Val Loss: 4.22902
Epoch 51, Val Loss: 4.01594
Epoch 52, Val Loss: 4.09249
Epoch 53, Val Loss: 3.99978
Epoch 54, Val Loss: 4.04958
Epoch 55, Val Loss: 4.20031
Epoch 56, Val Loss: 4.02559
Epoch 57, Val Loss: 3.98259
Epoch 58, Val Loss: 4.31543
Epoch 59, Val Loss: 4.59407
Epoch 60, Val Loss: 3.98959
Epoch 61, Val Loss: 4.16920
Epoch 62, Val Loss: 4.19376
Epoch 63, Val Loss: 4.09789
Epoch 64, Val Loss: 3.94771
Epoch 65, Val Loss: 4.21769
Epoch 66, Val Loss: 3.94289
Epoch 67, Val Loss: 3.99549
Epoch 68, Val Loss: 4.03286
Epoch 69, Val Loss: 4.03508
Epoch 70, Val Loss: 4.00609
Epoch 71, Val Loss: 3.96488
Epoch 72, Val Loss: 4.02633
Epoch 73, Val Loss: 4.03443
Epoch 74, Val Loss: 4.17451
Epoch 75, Val Loss: 4.01275
Epoch 76, Val Loss: 4.11026
Epoch 77, Val Loss: 4.12532
Epoch 78, Val Loss: 3.93062
Epoch 79, Val Loss: 4.03569
Epoch 80, Val Loss: 4.13165
Epoch 81, Val Loss: 4.04569
Epoch 82, Val Loss: 3.89969
Epoch 83, Val Loss: 4.11703
Epoch 84, Val Loss: 4.04140
Epoch 85, Val Loss: 4.54114
Epoch 86, Val Loss: 4.17623
Epoch 87, Val Loss: 4.18472
Epoch 88, Val Loss: 4.12834
Epoch 89, Val Loss: 4.12468
Epoch 90, Val Loss: 4.28256
Epoch 91, Val Loss: 4.55253
Epoch 92, Val Loss: 3.96969
Epoch 93, Val Loss: 4.23105
Epoch 94, Val Loss: 3.98482
Epoch 95, Val Loss: 4.00444
Epoch 96, Val Loss: 3.92214
Epoch 97, Val Loss: 3.94087
Epoch 98, Val Loss: 4.02450
Epoch 99, Val Loss: 4.27517
DID NOT SAVE RESULTS
{'MSE - mean': 4.408209735243997, 'MSE - std': 0.3408121736540634, 'R2 - mean': 0.5573736755561425, 'R2 - std': 0.023974286007241653} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.45451
Epoch 1, Val Loss: 12.24061
Epoch 2, Val Loss: 8.19983
Epoch 3, Val Loss: 7.90966
Epoch 4, Val Loss: 7.86170
Epoch 5, Val Loss: 7.70228
Epoch 6, Val Loss: 7.49220
Epoch 7, Val Loss: 7.97666
Epoch 8, Val Loss: 7.85753
Epoch 9, Val Loss: 7.76871
Epoch 10, Val Loss: 7.62230
Epoch 11, Val Loss: 7.60879
Epoch 12, Val Loss: 7.19359
Epoch 13, Val Loss: 7.94161
Epoch 14, Val Loss: 7.52881
Epoch 15, Val Loss: 7.04793
Epoch 16, Val Loss: 7.69157
Epoch 17, Val Loss: 6.95423
Epoch 18, Val Loss: 7.09621
Epoch 19, Val Loss: 6.94442
Epoch 20, Val Loss: 6.88706
Epoch 21, Val Loss: 6.90790
Epoch 22, Val Loss: 6.87033
Epoch 23, Val Loss: 6.87492
Epoch 24, Val Loss: 7.13736
Epoch 25, Val Loss: 7.14340
Epoch 26, Val Loss: 7.02647
Epoch 27, Val Loss: 6.88641
Epoch 28, Val Loss: 6.69622
Epoch 29, Val Loss: 6.67825
Epoch 30, Val Loss: 6.61192
Epoch 31, Val Loss: 6.68578
Epoch 32, Val Loss: 7.03453
Epoch 33, Val Loss: 6.85297
Epoch 34, Val Loss: 6.69567
Epoch 35, Val Loss: 6.76216
Epoch 36, Val Loss: 6.65141
Epoch 37, Val Loss: 6.89148
Epoch 38, Val Loss: 7.00566
Epoch 39, Val Loss: 6.81506
Epoch 40, Val Loss: 6.45427
Epoch 41, Val Loss: 6.69536
Epoch 42, Val Loss: 6.75584
Epoch 43, Val Loss: 6.47119
Epoch 44, Val Loss: 6.59714
Epoch 45, Val Loss: 6.34092
Epoch 46, Val Loss: 6.46200
Epoch 47, Val Loss: 6.71490
Epoch 48, Val Loss: 6.46240
Epoch 49, Val Loss: 6.48252
Epoch 50, Val Loss: 6.52308
Epoch 51, Val Loss: 6.62854
Epoch 52, Val Loss: 6.38982
Epoch 53, Val Loss: 6.39749
Epoch 54, Val Loss: 6.63943
Epoch 55, Val Loss: 6.54049
Epoch 56, Val Loss: 6.19230
Epoch 57, Val Loss: 6.37415
Epoch 58, Val Loss: 6.36920
Epoch 59, Val Loss: 6.20863
Epoch 60, Val Loss: 6.31098
Epoch 61, Val Loss: 7.05182
Epoch 62, Val Loss: 6.61610
Epoch 63, Val Loss: 6.40472
Epoch 64, Val Loss: 6.27951
Epoch 65, Val Loss: 6.19431
Epoch 66, Val Loss: 6.25504
Epoch 67, Val Loss: 6.26508
Epoch 68, Val Loss: 6.40752
Epoch 69, Val Loss: 6.25622
Epoch 70, Val Loss: 6.33053
Epoch 71, Val Loss: 6.22026
Epoch 72, Val Loss: 6.10376
Epoch 73, Val Loss: 6.53211
Epoch 74, Val Loss: 6.16196
Epoch 75, Val Loss: 6.37542
Epoch 76, Val Loss: 6.52122
Epoch 77, Val Loss: 6.34060
Epoch 78, Val Loss: 6.46741
Epoch 79, Val Loss: 6.30470
Epoch 80, Val Loss: 6.27374
Epoch 81, Val Loss: 6.81978
Epoch 82, Val Loss: 6.39558
Epoch 83, Val Loss: 6.22137
Epoch 84, Val Loss: 6.25520
Epoch 85, Val Loss: 6.34435
Epoch 86, Val Loss: 6.23068
Epoch 87, Val Loss: 6.20204
Epoch 88, Val Loss: 6.27261
Epoch 89, Val Loss: 6.32496
Epoch 90, Val Loss: 5.97429
Epoch 91, Val Loss: 6.33239
Epoch 92, Val Loss: 6.63032
Epoch 93, Val Loss: 6.18507
Epoch 94, Val Loss: 6.20755
Epoch 95, Val Loss: 6.03812
Epoch 96, Val Loss: 6.11985
Epoch 97, Val Loss: 6.28857
Epoch 98, Val Loss: 5.98448
Epoch 99, Val Loss: 6.32359
DID NOT SAVE RESULTS
{'MSE - mean': 4.712967706140485, 'MSE - std': 0.6814925043376665, 'R2 - mean': 0.5477840410166265, 'R2 - std': 0.028769036724428744} 
 

Results After CV: {'MSE - mean': 4.712967706140485, 'MSE - std': 0.6814925043376665, 'R2 - mean': 0.5477840410166265, 'R2 - std': 0.028769036724428744}
Train time: 105.08995014879947
Inference time: 0.05552173580035742
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 52 finished with value: 4.712967706140485 and parameters: {'p_m': 0.5547562742090971, 'alpha': 4.124931528590844, 'K': 20, 'beta': 0.5442281999316789}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.65471
Epoch 1, Val Loss: 13.94636
Epoch 2, Val Loss: 7.55544
Epoch 3, Val Loss: 7.05631
Epoch 4, Val Loss: 6.72823
Epoch 5, Val Loss: 6.67883
Epoch 6, Val Loss: 6.70919
Epoch 7, Val Loss: 6.42501
Epoch 8, Val Loss: 6.47118
Epoch 9, Val Loss: 6.39176
Epoch 10, Val Loss: 6.32428
Epoch 11, Val Loss: 6.24348
Epoch 12, Val Loss: 6.58649
Epoch 13, Val Loss: 6.17681
Epoch 14, Val Loss: 6.10815
Epoch 15, Val Loss: 6.14449
Epoch 16, Val Loss: 6.42837
Epoch 17, Val Loss: 6.07754
Epoch 18, Val Loss: 6.02870
Epoch 19, Val Loss: 6.23750
Epoch 20, Val Loss: 6.11843
Epoch 21, Val Loss: 6.07593
Epoch 22, Val Loss: 6.01989
Epoch 23, Val Loss: 5.99786
Epoch 24, Val Loss: 5.88449
Epoch 25, Val Loss: 6.03171
Epoch 26, Val Loss: 5.84541
Epoch 27, Val Loss: 5.91937
Epoch 28, Val Loss: 5.73980
Epoch 29, Val Loss: 5.77527
Epoch 30, Val Loss: 6.24380
Epoch 31, Val Loss: 5.71994
Epoch 32, Val Loss: 5.66598
Epoch 33, Val Loss: 5.70989
Epoch 34, Val Loss: 5.91847
Epoch 35, Val Loss: 5.91797
Epoch 36, Val Loss: 5.84492
Epoch 37, Val Loss: 5.74505
Epoch 38, Val Loss: 5.95723
Epoch 39, Val Loss: 6.06469
Epoch 40, Val Loss: 5.78206
Epoch 41, Val Loss: 5.57020
Epoch 42, Val Loss: 5.56370
Epoch 43, Val Loss: 5.57540
Epoch 44, Val Loss: 5.55688
Epoch 45, Val Loss: 5.80528
Epoch 46, Val Loss: 5.43674
Epoch 47, Val Loss: 5.28349
Epoch 48, Val Loss: 5.48322
Epoch 49, Val Loss: 5.30695
Epoch 50, Val Loss: 5.45322
Epoch 51, Val Loss: 5.35965
Epoch 52, Val Loss: 5.46644
Epoch 53, Val Loss: 5.19248
Epoch 54, Val Loss: 5.21486
Epoch 55, Val Loss: 5.09828
Epoch 56, Val Loss: 5.87659
Epoch 57, Val Loss: 5.37235
Epoch 58, Val Loss: 5.21474
Epoch 59, Val Loss: 5.45551
Epoch 60, Val Loss: 5.14637
Epoch 61, Val Loss: 5.05926
Epoch 62, Val Loss: 5.12585
Epoch 63, Val Loss: 5.37291
Epoch 64, Val Loss: 5.17704
Epoch 65, Val Loss: 5.39728
Epoch 66, Val Loss: 4.91532
Epoch 67, Val Loss: 4.93782
Epoch 68, Val Loss: 5.00661
Epoch 69, Val Loss: 4.91235
Epoch 70, Val Loss: 4.91255
Epoch 71, Val Loss: 5.44170
Epoch 72, Val Loss: 5.22109
Epoch 73, Val Loss: 5.05951
Epoch 74, Val Loss: 4.92814
Epoch 75, Val Loss: 5.31186
Epoch 76, Val Loss: 4.99860
Epoch 77, Val Loss: 5.00241
Epoch 78, Val Loss: 4.96647
Epoch 79, Val Loss: 5.00533
Epoch 80, Val Loss: 4.88611
Epoch 81, Val Loss: 4.87031
Epoch 82, Val Loss: 5.18017
Epoch 83, Val Loss: 4.93495
Epoch 84, Val Loss: 5.01506
Epoch 85, Val Loss: 4.96447
Epoch 86, Val Loss: 4.76661
Epoch 87, Val Loss: 4.96750
Epoch 88, Val Loss: 4.75549
Epoch 89, Val Loss: 4.87211
Epoch 90, Val Loss: 5.00140
Epoch 91, Val Loss: 5.03014
Epoch 92, Val Loss: 5.06397
Epoch 93, Val Loss: 4.80908
Epoch 94, Val Loss: 5.09513
Epoch 95, Val Loss: 4.98801
Epoch 96, Val Loss: 5.03914
Epoch 97, Val Loss: 4.89380
Epoch 98, Val Loss: 5.09182
Epoch 99, Val Loss: 4.79457
DID NOT SAVE RESULTS
{'MSE - mean': 4.958921747080216, 'MSE - std': 0.0, 'R2 - mean': 0.5477627226450593, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.51080
Epoch 1, Val Loss: 11.08941
Epoch 2, Val Loss: 6.39486
Epoch 3, Val Loss: 6.24438
Epoch 4, Val Loss: 6.29335
Epoch 5, Val Loss: 5.55819
Epoch 6, Val Loss: 5.76272
Epoch 7, Val Loss: 5.43093
Epoch 8, Val Loss: 5.54009
Epoch 9, Val Loss: 5.51004
Epoch 10, Val Loss: 5.50469
Epoch 11, Val Loss: 5.18068
Epoch 12, Val Loss: 5.15980
Epoch 13, Val Loss: 5.20777
Epoch 14, Val Loss: 5.18603
Epoch 15, Val Loss: 6.18322
Epoch 16, Val Loss: 5.32861
Epoch 17, Val Loss: 5.04224
Epoch 18, Val Loss: 5.15615
Epoch 19, Val Loss: 5.18031
Epoch 20, Val Loss: 5.03665
Epoch 21, Val Loss: 5.08885
Epoch 22, Val Loss: 4.99365
Epoch 23, Val Loss: 5.00038
Epoch 24, Val Loss: 4.97009
Epoch 25, Val Loss: 4.91486
Epoch 26, Val Loss: 4.87652
Epoch 27, Val Loss: 5.47259
Epoch 28, Val Loss: 4.86728
Epoch 29, Val Loss: 4.83792
Epoch 30, Val Loss: 4.90461
Epoch 31, Val Loss: 4.79620
Epoch 32, Val Loss: 4.83260
Epoch 33, Val Loss: 4.69295
Epoch 34, Val Loss: 4.98576
Epoch 35, Val Loss: 4.94380
Epoch 36, Val Loss: 4.69497
Epoch 37, Val Loss: 4.54614
Epoch 38, Val Loss: 5.02677
Epoch 39, Val Loss: 4.43946
Epoch 40, Val Loss: 4.37888
Epoch 41, Val Loss: 4.39466
Epoch 42, Val Loss: 4.88168
Epoch 43, Val Loss: 4.44599
Epoch 44, Val Loss: 4.36671
Epoch 45, Val Loss: 4.24096
Epoch 46, Val Loss: 4.23289
Epoch 47, Val Loss: 4.17530
Epoch 48, Val Loss: 4.37250
Epoch 49, Val Loss: 4.15479
Epoch 50, Val Loss: 4.26682
Epoch 51, Val Loss: 4.39216
Epoch 52, Val Loss: 4.75568
Epoch 53, Val Loss: 4.05439
Epoch 54, Val Loss: 4.06543
Epoch 55, Val Loss: 4.29528
Epoch 56, Val Loss: 4.07418
Epoch 57, Val Loss: 4.25454
Epoch 58, Val Loss: 4.12381
Epoch 59, Val Loss: 4.09649
Epoch 60, Val Loss: 4.04278
Epoch 61, Val Loss: 4.49258
Epoch 62, Val Loss: 4.16422
Epoch 63, Val Loss: 4.17376
Epoch 64, Val Loss: 4.12197
Epoch 65, Val Loss: 4.04061
Epoch 66, Val Loss: 4.09608
Epoch 67, Val Loss: 4.00094
Epoch 68, Val Loss: 3.97922
Epoch 69, Val Loss: 4.51752
Epoch 70, Val Loss: 4.08397
Epoch 71, Val Loss: 4.01669
Epoch 72, Val Loss: 4.06146
Epoch 73, Val Loss: 3.92073
Epoch 74, Val Loss: 4.00067
Epoch 75, Val Loss: 4.28076
Epoch 76, Val Loss: 3.99596
Epoch 77, Val Loss: 4.04868
Epoch 78, Val Loss: 4.43873
Epoch 79, Val Loss: 4.52429
Epoch 80, Val Loss: 4.13416
Epoch 81, Val Loss: 3.93656
Epoch 82, Val Loss: 4.26545
Epoch 83, Val Loss: 4.03787
Epoch 84, Val Loss: 4.06435
Epoch 85, Val Loss: 3.99244
Epoch 86, Val Loss: 4.02610
Epoch 87, Val Loss: 3.97171
Epoch 88, Val Loss: 4.22527
Epoch 89, Val Loss: 4.02426
Epoch 90, Val Loss: 4.00840
Epoch 91, Val Loss: 4.05361
Epoch 92, Val Loss: 3.95894
Epoch 93, Val Loss: 4.06737
Epoch 94, Val Loss: 4.02114
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.506110844052726, 'MSE - std': 0.4528109030274896, 'R2 - mean': 0.557847438470059, 'R2 - std': 0.010084715824999702} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 25.59280
Epoch 1, Val Loss: 13.47758
Epoch 2, Val Loss: 7.46128
Epoch 3, Val Loss: 7.00370
Epoch 4, Val Loss: 6.56776
Epoch 5, Val Loss: 6.66812
Epoch 6, Val Loss: 6.38347
Epoch 7, Val Loss: 6.54101
Epoch 8, Val Loss: 6.31147
Epoch 9, Val Loss: 6.43689
Epoch 10, Val Loss: 6.46092
Epoch 11, Val Loss: 6.32684
Epoch 12, Val Loss: 6.36342
Epoch 13, Val Loss: 6.42798
Epoch 14, Val Loss: 6.22845
Epoch 15, Val Loss: 6.38370
Epoch 16, Val Loss: 6.40363
Epoch 17, Val Loss: 6.22651
Epoch 18, Val Loss: 6.52936
Epoch 19, Val Loss: 6.24129
Epoch 20, Val Loss: 6.05219
Epoch 21, Val Loss: 6.16770
Epoch 22, Val Loss: 6.10153
Epoch 23, Val Loss: 6.22845
Epoch 24, Val Loss: 6.05381
Epoch 25, Val Loss: 6.04028
Epoch 26, Val Loss: 6.00370
Epoch 27, Val Loss: 6.06230
Epoch 28, Val Loss: 5.90921
Epoch 29, Val Loss: 5.95413
Epoch 30, Val Loss: 5.87656
Epoch 31, Val Loss: 6.03301
Epoch 32, Val Loss: 5.85031
Epoch 33, Val Loss: 5.76607
Epoch 34, Val Loss: 6.12166
Epoch 35, Val Loss: 5.80740
Epoch 36, Val Loss: 6.36354
Epoch 37, Val Loss: 5.90411
Epoch 38, Val Loss: 5.76637
Epoch 39, Val Loss: 5.69624
Epoch 40, Val Loss: 5.70330
Epoch 41, Val Loss: 5.48318
Epoch 42, Val Loss: 5.44982
Epoch 43, Val Loss: 5.43067
Epoch 44, Val Loss: 6.16951
Epoch 45, Val Loss: 5.49211
Epoch 46, Val Loss: 5.34295
Epoch 47, Val Loss: 5.27476
Epoch 48, Val Loss: 5.35415
Epoch 49, Val Loss: 5.46481
Epoch 50, Val Loss: 5.24271
Epoch 51, Val Loss: 5.21834
Epoch 52, Val Loss: 5.22973
Epoch 53, Val Loss: 5.39921
Epoch 54, Val Loss: 5.06081
Epoch 55, Val Loss: 5.20544
Epoch 56, Val Loss: 5.23495
Epoch 57, Val Loss: 5.49189
Epoch 58, Val Loss: 5.82931
Epoch 59, Val Loss: 5.18205
Epoch 60, Val Loss: 5.01592
Epoch 61, Val Loss: 4.96074
Epoch 62, Val Loss: 4.95402
Epoch 63, Val Loss: 4.88764
Epoch 64, Val Loss: 4.98182
Epoch 65, Val Loss: 5.09460
Epoch 66, Val Loss: 5.05979
Epoch 67, Val Loss: 5.07200
Epoch 68, Val Loss: 5.19808
Epoch 69, Val Loss: 4.90837
Epoch 70, Val Loss: 4.96530
Epoch 71, Val Loss: 4.89853
Epoch 72, Val Loss: 5.03337
Epoch 73, Val Loss: 5.08281
Epoch 74, Val Loss: 4.85767
Epoch 75, Val Loss: 4.94340
Epoch 76, Val Loss: 5.08502
Epoch 77, Val Loss: 4.88659
Epoch 78, Val Loss: 4.78506
Epoch 79, Val Loss: 4.74149
Epoch 80, Val Loss: 5.20233
Epoch 81, Val Loss: 4.81852
Epoch 82, Val Loss: 4.94731
Epoch 83, Val Loss: 4.76550
Epoch 84, Val Loss: 5.03370
Epoch 85, Val Loss: 4.92240
Epoch 86, Val Loss: 4.81296
Epoch 87, Val Loss: 4.78085
Epoch 88, Val Loss: 4.78973
Epoch 89, Val Loss: 4.82076
Epoch 90, Val Loss: 5.27300
Epoch 91, Val Loss: 4.93805
Epoch 92, Val Loss: 5.02507
Epoch 93, Val Loss: 4.73363
Epoch 94, Val Loss: 4.73535
Epoch 95, Val Loss: 4.92140
Epoch 96, Val Loss: 4.96431
Epoch 97, Val Loss: 4.85639
Epoch 98, Val Loss: 5.04541
Epoch 99, Val Loss: 4.96379
DID NOT SAVE RESULTS
{'MSE - mean': 4.611356919482362, 'MSE - std': 0.39855398888196875, 'R2 - mean': 0.5470770760807792, 'R2 - std': 0.01731480313219962} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.66998
Epoch 1, Val Loss: 12.40940
Epoch 2, Val Loss: 6.51375
Epoch 3, Val Loss: 6.09907
Epoch 4, Val Loss: 5.54187
Epoch 5, Val Loss: 5.46906
Epoch 6, Val Loss: 5.44930
Epoch 7, Val Loss: 5.51175
Epoch 8, Val Loss: 5.24678
Epoch 9, Val Loss: 5.34938
Epoch 10, Val Loss: 5.19987
Epoch 11, Val Loss: 5.26983
Epoch 12, Val Loss: 5.21256
Epoch 13, Val Loss: 5.06965
Epoch 14, Val Loss: 5.22631
Epoch 15, Val Loss: 5.07734
Epoch 16, Val Loss: 4.96892
Epoch 17, Val Loss: 4.98428
Epoch 18, Val Loss: 5.49126
Epoch 19, Val Loss: 4.93626
Epoch 20, Val Loss: 4.85467
Epoch 21, Val Loss: 4.91919
Epoch 22, Val Loss: 4.96738
Epoch 23, Val Loss: 4.79802
Epoch 24, Val Loss: 4.83054
Epoch 25, Val Loss: 4.81829
Epoch 26, Val Loss: 4.91677
Epoch 27, Val Loss: 4.78982
Epoch 28, Val Loss: 4.76225
Epoch 29, Val Loss: 4.69487
Epoch 30, Val Loss: 4.73460
Epoch 31, Val Loss: 4.66602
Epoch 32, Val Loss: 4.69199
Epoch 33, Val Loss: 4.69199
Epoch 34, Val Loss: 4.90018
Epoch 35, Val Loss: 4.65686
Epoch 36, Val Loss: 4.73749
Epoch 37, Val Loss: 4.66916
Epoch 38, Val Loss: 4.65216
Epoch 39, Val Loss: 4.59099
Epoch 40, Val Loss: 4.61717
Epoch 41, Val Loss: 4.52879
Epoch 42, Val Loss: 4.52679
Epoch 43, Val Loss: 4.71986
Epoch 44, Val Loss: 4.52620
Epoch 45, Val Loss: 4.57086
Epoch 46, Val Loss: 4.53628
Epoch 47, Val Loss: 4.51571
Epoch 48, Val Loss: 4.46210
Epoch 49, Val Loss: 4.48444
Epoch 50, Val Loss: 4.65259
Epoch 51, Val Loss: 4.55951
Epoch 52, Val Loss: 4.42137
Epoch 53, Val Loss: 4.35028
Epoch 54, Val Loss: 4.53989
Epoch 55, Val Loss: 4.27006
Epoch 56, Val Loss: 4.30966
Epoch 57, Val Loss: 4.35870
Epoch 58, Val Loss: 4.35052
Epoch 59, Val Loss: 4.63304
Epoch 60, Val Loss: 4.51962
Epoch 61, Val Loss: 4.41312
Epoch 62, Val Loss: 4.54562
Epoch 63, Val Loss: 4.24661
Epoch 64, Val Loss: 4.39261
Epoch 65, Val Loss: 4.14257
Epoch 66, Val Loss: 4.15889
Epoch 67, Val Loss: 4.18982
Epoch 68, Val Loss: 4.16934
Epoch 69, Val Loss: 4.18429
Epoch 70, Val Loss: 4.80819
Epoch 71, Val Loss: 4.17677
Epoch 72, Val Loss: 4.50821
Epoch 73, Val Loss: 4.12132
Epoch 74, Val Loss: 4.10338
Epoch 75, Val Loss: 4.12785
Epoch 76, Val Loss: 4.14322
Epoch 77, Val Loss: 4.79309
Epoch 78, Val Loss: 4.15265
Epoch 79, Val Loss: 4.02523
Epoch 80, Val Loss: 4.18108
Epoch 81, Val Loss: 4.59524
Epoch 82, Val Loss: 4.09900
Epoch 83, Val Loss: 4.12506
Epoch 84, Val Loss: 4.09417
Epoch 85, Val Loss: 4.53157
Epoch 86, Val Loss: 4.17389
Epoch 87, Val Loss: 4.10778
Epoch 88, Val Loss: 4.12355
Epoch 89, Val Loss: 4.43519
Epoch 90, Val Loss: 4.17727
Epoch 91, Val Loss: 4.09565
Epoch 92, Val Loss: 4.23003
Epoch 93, Val Loss: 4.12459
Epoch 94, Val Loss: 4.11668
Epoch 95, Val Loss: 4.22188
Epoch 96, Val Loss: 4.16754
Epoch 97, Val Loss: 4.15547
Epoch 98, Val Loss: 4.21240
Epoch 99, Val Loss: 4.05279
DID NOT SAVE RESULTS
{'MSE - mean': 4.550742006391423, 'MSE - std': 0.36077203966959914, 'R2 - mean': 0.5435266278201631, 'R2 - std': 0.016207061861548338} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.54945
Epoch 1, Val Loss: 17.01451
Epoch 2, Val Loss: 8.71653
Epoch 3, Val Loss: 8.89853
Epoch 4, Val Loss: 8.14512
Epoch 5, Val Loss: 7.73587
Epoch 6, Val Loss: 7.73035
Epoch 7, Val Loss: 7.86260
Epoch 8, Val Loss: 7.55113
Epoch 9, Val Loss: 7.34654
Epoch 10, Val Loss: 7.40667
Epoch 11, Val Loss: 7.28091
Epoch 12, Val Loss: 7.23582
Epoch 13, Val Loss: 7.31485
Epoch 14, Val Loss: 7.22267
Epoch 15, Val Loss: 7.18968
Epoch 16, Val Loss: 7.42683
Epoch 17, Val Loss: 7.14014
Epoch 18, Val Loss: 7.07604
Epoch 19, Val Loss: 7.16802
Epoch 20, Val Loss: 6.93932
Epoch 21, Val Loss: 6.76089
Epoch 22, Val Loss: 6.81884
Epoch 23, Val Loss: 6.72913
Epoch 24, Val Loss: 6.67466
Epoch 25, Val Loss: 6.61246
Epoch 26, Val Loss: 6.64888
Epoch 27, Val Loss: 6.78544
Epoch 28, Val Loss: 6.85398
Epoch 29, Val Loss: 6.65702
Epoch 30, Val Loss: 6.86925
Epoch 31, Val Loss: 6.46424
Epoch 32, Val Loss: 6.43962
Epoch 33, Val Loss: 6.51034
Epoch 34, Val Loss: 6.74920
Epoch 35, Val Loss: 6.42172
Epoch 36, Val Loss: 6.45955
Epoch 37, Val Loss: 6.30393
Epoch 38, Val Loss: 6.51571
Epoch 39, Val Loss: 6.34529
Epoch 40, Val Loss: 6.44938
Epoch 41, Val Loss: 6.23806
Epoch 42, Val Loss: 6.46936
Epoch 43, Val Loss: 6.93640
Epoch 44, Val Loss: 6.19916
Epoch 45, Val Loss: 6.24418
Epoch 46, Val Loss: 6.37366
Epoch 47, Val Loss: 6.14993
Epoch 48, Val Loss: 6.31557
Epoch 49, Val Loss: 6.05678
Epoch 50, Val Loss: 6.09893
Epoch 51, Val Loss: 6.17929
Epoch 52, Val Loss: 5.99916
Epoch 53, Val Loss: 6.46004
Epoch 54, Val Loss: 6.23528
Epoch 55, Val Loss: 6.24904
Epoch 56, Val Loss: 6.03933
Epoch 57, Val Loss: 5.91771
Epoch 58, Val Loss: 6.12422
Epoch 59, Val Loss: 5.88136
Epoch 60, Val Loss: 5.94320
Epoch 61, Val Loss: 6.12335
Epoch 62, Val Loss: 6.01724
Epoch 63, Val Loss: 6.20026
Epoch 64, Val Loss: 6.12629
Epoch 65, Val Loss: 6.09444
Epoch 66, Val Loss: 6.09924
Epoch 67, Val Loss: 6.04187
Epoch 68, Val Loss: 5.84560
Epoch 69, Val Loss: 5.92327
Epoch 70, Val Loss: 6.12682
Epoch 71, Val Loss: 5.84228
Epoch 72, Val Loss: 6.14366
Epoch 73, Val Loss: 5.92764
Epoch 74, Val Loss: 6.10682
Epoch 75, Val Loss: 5.94279
Epoch 76, Val Loss: 5.93017
Epoch 77, Val Loss: 5.89378
Epoch 78, Val Loss: 5.85013
Epoch 79, Val Loss: 5.94520
Epoch 80, Val Loss: 5.82316
Epoch 81, Val Loss: 5.87680
Epoch 82, Val Loss: 5.85178
Epoch 83, Val Loss: 6.10066
Epoch 84, Val Loss: 5.86174
Epoch 85, Val Loss: 6.22517
Epoch 86, Val Loss: 5.86958
Epoch 87, Val Loss: 5.77728
Epoch 88, Val Loss: 5.84909
Epoch 89, Val Loss: 5.78717
Epoch 90, Val Loss: 6.10989
Epoch 91, Val Loss: 5.72314
Epoch 92, Val Loss: 5.88419
Epoch 93, Val Loss: 5.78427
Epoch 94, Val Loss: 5.98938
Epoch 95, Val Loss: 5.90765
Epoch 96, Val Loss: 5.92742
Epoch 97, Val Loss: 5.74470
Epoch 98, Val Loss: 5.91492
Epoch 99, Val Loss: 5.80738
DID NOT SAVE RESULTS
{'MSE - mean': 4.7909881969875, 'MSE - std': 0.5787902038472973, 'R2 - mean': 0.5396840319501122, 'R2 - std': 0.016407231802756248} 
 

Results After CV: {'MSE - mean': 4.7909881969875, 'MSE - std': 0.5787902038472973, 'R2 - mean': 0.5396840319501122, 'R2 - std': 0.016407231802756248}
Train time: 113.21027558159949
Inference time: 0.05374921319962596
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 53 finished with value: 4.7909881969875 and parameters: {'p_m': 0.8681723965465912, 'alpha': 2.3135119856398694, 'K': 20, 'beta': 9.226089876357548}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.18422
Epoch 1, Val Loss: 11.48370
Epoch 2, Val Loss: 8.64189
Epoch 3, Val Loss: 7.59617
Epoch 4, Val Loss: 6.79870
Epoch 5, Val Loss: 6.62755
Epoch 6, Val Loss: 6.64202
Epoch 7, Val Loss: 6.30289
Epoch 8, Val Loss: 6.31711
Epoch 9, Val Loss: 6.69677
Epoch 10, Val Loss: 6.53241
Epoch 11, Val Loss: 6.20064
Epoch 12, Val Loss: 6.18379
Epoch 13, Val Loss: 6.11732
Epoch 14, Val Loss: 6.10224
Epoch 15, Val Loss: 6.04101
Epoch 16, Val Loss: 5.96912
Epoch 17, Val Loss: 6.20933
Epoch 18, Val Loss: 5.80797
Epoch 19, Val Loss: 6.15733
Epoch 20, Val Loss: 5.78029
Epoch 21, Val Loss: 5.63468
Epoch 22, Val Loss: 5.65026
Epoch 23, Val Loss: 5.47173
Epoch 24, Val Loss: 5.64087
Epoch 25, Val Loss: 5.56456
Epoch 26, Val Loss: 5.66950
Epoch 27, Val Loss: 5.96860
Epoch 28, Val Loss: 5.42837
Epoch 29, Val Loss: 5.41212
Epoch 30, Val Loss: 5.95913
Epoch 31, Val Loss: 5.47850
Epoch 32, Val Loss: 5.35303
Epoch 33, Val Loss: 5.51841
Epoch 34, Val Loss: 5.46343
Epoch 35, Val Loss: 5.94301
Epoch 36, Val Loss: 5.17003
Epoch 37, Val Loss: 5.29979
Epoch 38, Val Loss: 5.20492
Epoch 39, Val Loss: 5.38929
Epoch 40, Val Loss: 5.08882
Epoch 41, Val Loss: 5.22110
Epoch 42, Val Loss: 5.08104
Epoch 43, Val Loss: 5.32279
Epoch 44, Val Loss: 5.26864
Epoch 45, Val Loss: 5.03204
Epoch 46, Val Loss: 5.04552
Epoch 47, Val Loss: 5.00932
Epoch 48, Val Loss: 5.18713
Epoch 49, Val Loss: 5.55498
Epoch 50, Val Loss: 4.94647
Epoch 51, Val Loss: 4.89019
Epoch 52, Val Loss: 5.22677
Epoch 53, Val Loss: 5.24035
Epoch 54, Val Loss: 5.36670
Epoch 55, Val Loss: 4.93457
Epoch 56, Val Loss: 5.12922
Epoch 57, Val Loss: 5.02015
Epoch 58, Val Loss: 4.95842
Epoch 59, Val Loss: 5.51759
Epoch 60, Val Loss: 5.02922
Epoch 61, Val Loss: 5.03072
Epoch 62, Val Loss: 5.34242
Epoch 63, Val Loss: 5.06758
Epoch 64, Val Loss: 5.09730
Epoch 65, Val Loss: 4.94278
Epoch 66, Val Loss: 4.92108
Epoch 67, Val Loss: 4.97877
Epoch 68, Val Loss: 4.92689
Epoch 69, Val Loss: 4.89714
Epoch 70, Val Loss: 4.94903
Epoch 71, Val Loss: 4.86380
Epoch 72, Val Loss: 5.13202
Epoch 73, Val Loss: 4.77657
Epoch 74, Val Loss: 4.89086
Epoch 75, Val Loss: 4.76703
Epoch 76, Val Loss: 5.33351
Epoch 77, Val Loss: 4.99026
Epoch 78, Val Loss: 4.96516
Epoch 79, Val Loss: 4.91913
Epoch 80, Val Loss: 4.91826
Epoch 81, Val Loss: 4.99396
Epoch 82, Val Loss: 4.79659
Epoch 83, Val Loss: 5.02798
Epoch 84, Val Loss: 5.07473
Epoch 85, Val Loss: 4.83249
Epoch 86, Val Loss: 4.89847
Epoch 87, Val Loss: 4.76314
Epoch 88, Val Loss: 4.75944
Epoch 89, Val Loss: 4.76455
Epoch 90, Val Loss: 4.70156
Epoch 91, Val Loss: 4.83427
Epoch 92, Val Loss: 4.91968
Epoch 93, Val Loss: 4.73037
Epoch 94, Val Loss: 4.98418
Epoch 95, Val Loss: 5.15682
Epoch 96, Val Loss: 5.14453
Epoch 97, Val Loss: 4.72791
Epoch 98, Val Loss: 4.96158
Epoch 99, Val Loss: 5.27807
DID NOT SAVE RESULTS
{'MSE - mean': 4.862385441694717, 'MSE - std': 0.0, 'R2 - mean': 0.5565665147071439, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.61780
Epoch 1, Val Loss: 8.26156
Epoch 2, Val Loss: 5.57907
Epoch 3, Val Loss: 5.48303
Epoch 4, Val Loss: 5.28654
Epoch 5, Val Loss: 5.20509
Epoch 6, Val Loss: 5.09809
Epoch 7, Val Loss: 5.12020
Epoch 8, Val Loss: 5.00440
Epoch 9, Val Loss: 5.01657
Epoch 10, Val Loss: 5.04033
Epoch 11, Val Loss: 5.58784
Epoch 12, Val Loss: 5.20483
Epoch 13, Val Loss: 4.83767
Epoch 14, Val Loss: 5.05249
Epoch 15, Val Loss: 4.82241
Epoch 16, Val Loss: 4.95020
Epoch 17, Val Loss: 4.71672
Epoch 18, Val Loss: 4.80841
Epoch 19, Val Loss: 4.74669
Epoch 20, Val Loss: 4.83998
Epoch 21, Val Loss: 4.85659
Epoch 22, Val Loss: 5.09848
Epoch 23, Val Loss: 4.84379
Epoch 24, Val Loss: 4.91682
Epoch 25, Val Loss: 5.58416
Epoch 26, Val Loss: 4.95963
Epoch 27, Val Loss: 4.60426
Epoch 28, Val Loss: 4.76181
Epoch 29, Val Loss: 4.42230
Epoch 30, Val Loss: 4.61634
Epoch 31, Val Loss: 4.77945
Epoch 32, Val Loss: 4.71506
Epoch 33, Val Loss: 5.03079
Epoch 34, Val Loss: 4.52093
Epoch 35, Val Loss: 4.31825
Epoch 36, Val Loss: 4.24137
Epoch 37, Val Loss: 4.46625
Epoch 38, Val Loss: 4.52278
Epoch 39, Val Loss: 4.30000
Epoch 40, Val Loss: 4.25771
Epoch 41, Val Loss: 4.52820
Epoch 42, Val Loss: 4.27775
Epoch 43, Val Loss: 4.33376
Epoch 44, Val Loss: 4.71425
Epoch 45, Val Loss: 4.29476
Epoch 46, Val Loss: 4.41741
Epoch 47, Val Loss: 4.08183
Epoch 48, Val Loss: 3.93221
Epoch 49, Val Loss: 4.25720
Epoch 50, Val Loss: 4.06953
Epoch 51, Val Loss: 4.55592
Epoch 52, Val Loss: 4.50695
Epoch 53, Val Loss: 4.28989
Epoch 54, Val Loss: 4.02194
Epoch 55, Val Loss: 3.90668
Epoch 56, Val Loss: 4.02893
Epoch 57, Val Loss: 4.03261
Epoch 58, Val Loss: 4.09258
Epoch 59, Val Loss: 4.17855
Epoch 60, Val Loss: 4.03334
Epoch 61, Val Loss: 3.81897
Epoch 62, Val Loss: 4.20266
Epoch 63, Val Loss: 4.10093
Epoch 64, Val Loss: 3.88742
Epoch 65, Val Loss: 3.92164
Epoch 66, Val Loss: 3.88882
Epoch 67, Val Loss: 4.13218
Epoch 68, Val Loss: 4.25018
Epoch 69, Val Loss: 3.95641
Epoch 70, Val Loss: 3.99530
Epoch 71, Val Loss: 4.06695
Epoch 72, Val Loss: 3.80550
Epoch 73, Val Loss: 4.21130
Epoch 74, Val Loss: 3.88411
Epoch 75, Val Loss: 3.91726
Epoch 76, Val Loss: 3.84284
Epoch 77, Val Loss: 3.86875
Epoch 78, Val Loss: 3.81934
Epoch 79, Val Loss: 4.10000
Epoch 80, Val Loss: 3.90972
Epoch 81, Val Loss: 3.97594
Epoch 82, Val Loss: 3.97519
Epoch 83, Val Loss: 4.00339
Epoch 84, Val Loss: 4.11286
Epoch 85, Val Loss: 3.87658
Epoch 86, Val Loss: 3.98825
Epoch 87, Val Loss: 4.18434
Epoch 88, Val Loss: 3.98924
Epoch 89, Val Loss: 3.93115
Epoch 90, Val Loss: 3.87476
Epoch 91, Val Loss: 4.42565
Epoch 92, Val Loss: 3.89278
Epoch 93, Val Loss: 3.91277
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.4325590122698415, 'MSE - std': 0.42982642942487503, 'R2 - mean': 0.5649444878119629, 'R2 - std': 0.00837797310481908} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.15401
Epoch 1, Val Loss: 15.13800
Epoch 2, Val Loss: 6.07111
Epoch 3, Val Loss: 6.40416
Epoch 4, Val Loss: 6.35052
Epoch 5, Val Loss: 6.19115
Epoch 6, Val Loss: 5.88193
Epoch 7, Val Loss: 5.80142
Epoch 8, Val Loss: 5.72627
Epoch 9, Val Loss: 5.76290
Epoch 10, Val Loss: 5.79132
Epoch 11, Val Loss: 5.70407
Epoch 12, Val Loss: 5.54480
Epoch 13, Val Loss: 5.61726
Epoch 14, Val Loss: 5.51944
Epoch 15, Val Loss: 5.80285
Epoch 16, Val Loss: 5.69511
Epoch 17, Val Loss: 5.63497
Epoch 18, Val Loss: 5.55214
Epoch 19, Val Loss: 5.54713
Epoch 20, Val Loss: 5.59081
Epoch 21, Val Loss: 5.28847
Epoch 22, Val Loss: 5.32590
Epoch 23, Val Loss: 5.25264
Epoch 24, Val Loss: 5.58357
Epoch 25, Val Loss: 6.10626
Epoch 26, Val Loss: 5.33469
Epoch 27, Val Loss: 5.32354
Epoch 28, Val Loss: 5.19603
Epoch 29, Val Loss: 5.17737
Epoch 30, Val Loss: 5.27461
Epoch 31, Val Loss: 5.22343
Epoch 32, Val Loss: 4.99254
Epoch 33, Val Loss: 5.07119
Epoch 34, Val Loss: 5.32760
Epoch 35, Val Loss: 5.21348
Epoch 36, Val Loss: 5.01634
Epoch 37, Val Loss: 4.92961
Epoch 38, Val Loss: 4.97594
Epoch 39, Val Loss: 5.20624
Epoch 40, Val Loss: 5.47631
Epoch 41, Val Loss: 4.95663
Epoch 42, Val Loss: 5.29007
Epoch 43, Val Loss: 4.97699
Epoch 44, Val Loss: 4.85211
Epoch 45, Val Loss: 4.88901
Epoch 46, Val Loss: 4.96159
Epoch 47, Val Loss: 4.96026
Epoch 48, Val Loss: 4.81525
Epoch 49, Val Loss: 5.12794
Epoch 50, Val Loss: 4.86395
Epoch 51, Val Loss: 4.81979
Epoch 52, Val Loss: 4.96599
Epoch 53, Val Loss: 4.98241
Epoch 54, Val Loss: 4.97526
Epoch 55, Val Loss: 4.79116
Epoch 56, Val Loss: 4.92133
Epoch 57, Val Loss: 4.84152
Epoch 58, Val Loss: 4.75228
Epoch 59, Val Loss: 5.05224
Epoch 60, Val Loss: 4.80786
Epoch 61, Val Loss: 4.76296
Epoch 62, Val Loss: 4.77429
Epoch 63, Val Loss: 4.86848
Epoch 64, Val Loss: 5.25140
Epoch 65, Val Loss: 4.72116
Epoch 66, Val Loss: 5.43988
Epoch 67, Val Loss: 4.84458
Epoch 68, Val Loss: 4.72585
Epoch 69, Val Loss: 4.79157
Epoch 70, Val Loss: 4.88757
Epoch 71, Val Loss: 4.77571
Epoch 72, Val Loss: 4.68291
Epoch 73, Val Loss: 4.82572
Epoch 74, Val Loss: 4.82148
Epoch 75, Val Loss: 4.84366
Epoch 76, Val Loss: 4.78675
Epoch 77, Val Loss: 4.80727
Epoch 78, Val Loss: 4.78228
Epoch 79, Val Loss: 4.69987
Epoch 80, Val Loss: 4.76400
Epoch 81, Val Loss: 4.83284
Epoch 82, Val Loss: 4.78039
Epoch 83, Val Loss: 4.75080
Epoch 84, Val Loss: 4.69419
Epoch 85, Val Loss: 4.77490
Epoch 86, Val Loss: 4.69492
Epoch 87, Val Loss: 5.09431
Epoch 88, Val Loss: 4.69546
Epoch 89, Val Loss: 4.83258
Epoch 90, Val Loss: 4.80871
Epoch 91, Val Loss: 4.94511
Epoch 92, Val Loss: 4.76692
Epoch 93, Val Loss: 4.75229
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.547541163558397, 'MSE - std': 0.3867931788238344, 'R2 - mean': 0.5532628932147972, 'R2 - std': 0.01788051808240226} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.92484
Epoch 1, Val Loss: 12.42171
Epoch 2, Val Loss: 5.40517
Epoch 3, Val Loss: 5.26215
Epoch 4, Val Loss: 5.27646
Epoch 5, Val Loss: 5.14042
Epoch 6, Val Loss: 5.08468
Epoch 7, Val Loss: 5.07247
Epoch 8, Val Loss: 5.48685
Epoch 9, Val Loss: 5.02231
Epoch 10, Val Loss: 5.20557
Epoch 11, Val Loss: 5.11809
Epoch 12, Val Loss: 4.87832
Epoch 13, Val Loss: 4.98632
Epoch 14, Val Loss: 4.93638
Epoch 15, Val Loss: 4.84135
Epoch 16, Val Loss: 4.79620
Epoch 17, Val Loss: 4.91763
Epoch 18, Val Loss: 5.02756
Epoch 19, Val Loss: 4.82556
Epoch 20, Val Loss: 4.75663
Epoch 21, Val Loss: 4.80254
Epoch 22, Val Loss: 4.56833
Epoch 23, Val Loss: 4.71658
Epoch 24, Val Loss: 4.54119
Epoch 25, Val Loss: 4.57800
Epoch 26, Val Loss: 4.46958
Epoch 27, Val Loss: 4.53455
Epoch 28, Val Loss: 4.37461
Epoch 29, Val Loss: 4.47961
Epoch 30, Val Loss: 4.36109
Epoch 31, Val Loss: 4.70136
Epoch 32, Val Loss: 4.39254
Epoch 33, Val Loss: 4.68200
Epoch 34, Val Loss: 4.39867
Epoch 35, Val Loss: 4.33160
Epoch 36, Val Loss: 4.27861
Epoch 37, Val Loss: 4.33435
Epoch 38, Val Loss: 4.73567
Epoch 39, Val Loss: 4.33428
Epoch 40, Val Loss: 4.23421
Epoch 41, Val Loss: 4.29718
Epoch 42, Val Loss: 4.29230
Epoch 43, Val Loss: 4.42714
Epoch 44, Val Loss: 4.52815
Epoch 45, Val Loss: 4.28550
Epoch 46, Val Loss: 4.40852
Epoch 47, Val Loss: 4.64755
Epoch 48, Val Loss: 4.48414
Epoch 49, Val Loss: 4.31496
Epoch 50, Val Loss: 4.33616
Epoch 51, Val Loss: 4.23977
Epoch 52, Val Loss: 4.29809
Epoch 53, Val Loss: 4.20223
Epoch 54, Val Loss: 4.25072
Epoch 55, Val Loss: 4.14807
Epoch 56, Val Loss: 4.16228
Epoch 57, Val Loss: 4.41304
Epoch 58, Val Loss: 4.44728
Epoch 59, Val Loss: 4.36678
Epoch 60, Val Loss: 4.21926
Epoch 61, Val Loss: 4.14684
Epoch 62, Val Loss: 4.34134
Epoch 63, Val Loss: 4.20185
Epoch 64, Val Loss: 4.10137
Epoch 65, Val Loss: 4.19693
Epoch 66, Val Loss: 4.50405
Epoch 67, Val Loss: 4.31340
Epoch 68, Val Loss: 4.24822
Epoch 69, Val Loss: 4.23838
Epoch 70, Val Loss: 4.04202
Epoch 71, Val Loss: 4.15064
Epoch 72, Val Loss: 4.19283
Epoch 73, Val Loss: 4.21871
Epoch 74, Val Loss: 4.12840
Epoch 75, Val Loss: 4.15850
Epoch 76, Val Loss: 4.11917
Epoch 77, Val Loss: 4.15505
Epoch 78, Val Loss: 4.09997
Epoch 79, Val Loss: 4.34278
Epoch 80, Val Loss: 4.25442
Epoch 81, Val Loss: 4.12873
Epoch 82, Val Loss: 4.05253
Epoch 83, Val Loss: 4.09171
Epoch 84, Val Loss: 4.14601
Epoch 85, Val Loss: 4.05469
Epoch 86, Val Loss: 4.08862
Epoch 87, Val Loss: 4.25255
Epoch 88, Val Loss: 4.19764
Epoch 89, Val Loss: 4.02668
Epoch 90, Val Loss: 4.05338
Epoch 91, Val Loss: 4.35095
Epoch 92, Val Loss: 4.04387
Epoch 93, Val Loss: 4.01800
Epoch 94, Val Loss: 4.14603
Epoch 95, Val Loss: 4.21378
Epoch 96, Val Loss: 4.19961
Epoch 97, Val Loss: 4.43045
Epoch 98, Val Loss: 4.58768
Epoch 99, Val Loss: 3.94460
DID NOT SAVE RESULTS
{'MSE - mean': 4.476266746286585, 'MSE - std': 0.3569969888679651, 'R2 - mean': 0.5510115135439029, 'R2 - std': 0.015968432184747642} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.47461
Epoch 1, Val Loss: 20.58386
Epoch 2, Val Loss: 8.58914
Epoch 3, Val Loss: 8.37340
Epoch 4, Val Loss: 7.71358
Epoch 5, Val Loss: 7.75573
Epoch 6, Val Loss: 7.75582
Epoch 7, Val Loss: 7.80216
Epoch 8, Val Loss: 7.47159
Epoch 9, Val Loss: 7.32308
Epoch 10, Val Loss: 7.06865
Epoch 11, Val Loss: 7.06720
Epoch 12, Val Loss: 7.28054
Epoch 13, Val Loss: 6.93696
Epoch 14, Val Loss: 6.72822
Epoch 15, Val Loss: 6.77379
Epoch 16, Val Loss: 6.75786
Epoch 17, Val Loss: 6.69330
Epoch 18, Val Loss: 6.72236
Epoch 19, Val Loss: 6.94302
Epoch 20, Val Loss: 6.56095
Epoch 21, Val Loss: 6.89815
Epoch 22, Val Loss: 6.59154
Epoch 23, Val Loss: 6.67357
Epoch 24, Val Loss: 6.76080
Epoch 25, Val Loss: 6.63484
Epoch 26, Val Loss: 6.66514
Epoch 27, Val Loss: 6.52316
Epoch 28, Val Loss: 6.72321
Epoch 29, Val Loss: 6.65461
Epoch 30, Val Loss: 6.74173
Epoch 31, Val Loss: 6.51539
Epoch 32, Val Loss: 6.88175
Epoch 33, Val Loss: 6.88061
Epoch 34, Val Loss: 6.55229
Epoch 35, Val Loss: 6.54981
Epoch 36, Val Loss: 6.94206
Epoch 37, Val Loss: 6.61736
Epoch 38, Val Loss: 6.51787
Epoch 39, Val Loss: 6.58585
Epoch 40, Val Loss: 6.33034
Epoch 41, Val Loss: 6.80102
Epoch 42, Val Loss: 6.47792
Epoch 43, Val Loss: 6.30339
Epoch 44, Val Loss: 6.52016
Epoch 45, Val Loss: 6.56953
Epoch 46, Val Loss: 6.35366
Epoch 47, Val Loss: 6.35199
Epoch 48, Val Loss: 6.74258
Epoch 49, Val Loss: 6.57594
Epoch 50, Val Loss: 6.23353
Epoch 51, Val Loss: 6.29747
Epoch 52, Val Loss: 6.51277
Epoch 53, Val Loss: 6.26986
Epoch 54, Val Loss: 6.34643
Epoch 55, Val Loss: 6.41012
Epoch 56, Val Loss: 6.15063
Epoch 57, Val Loss: 6.20408
Epoch 58, Val Loss: 6.15584
Epoch 59, Val Loss: 6.36125
Epoch 60, Val Loss: 6.38356
Epoch 61, Val Loss: 6.36981
Epoch 62, Val Loss: 6.52831
Epoch 63, Val Loss: 6.17396
Epoch 64, Val Loss: 6.19608
Epoch 65, Val Loss: 6.41102
Epoch 66, Val Loss: 6.45194
Epoch 67, Val Loss: 6.35811
Epoch 68, Val Loss: 6.33283
Epoch 69, Val Loss: 6.32583
Epoch 70, Val Loss: 6.21084
Epoch 71, Val Loss: 6.49273
Epoch 72, Val Loss: 6.32173
Epoch 73, Val Loss: 6.15456
Epoch 74, Val Loss: 6.23911
Epoch 75, Val Loss: 6.07734
Epoch 76, Val Loss: 6.06943
Epoch 77, Val Loss: 6.11025
Epoch 78, Val Loss: 6.12528
Epoch 79, Val Loss: 6.47755
Epoch 80, Val Loss: 6.26514
Epoch 81, Val Loss: 6.19676
Epoch 82, Val Loss: 6.16234
Epoch 83, Val Loss: 6.03450
Epoch 84, Val Loss: 6.35570
Epoch 85, Val Loss: 6.23555
Epoch 86, Val Loss: 6.23999
Epoch 87, Val Loss: 6.09014
Epoch 88, Val Loss: 6.03967
Epoch 89, Val Loss: 6.21411
Epoch 90, Val Loss: 5.90533
Epoch 91, Val Loss: 6.09920
Epoch 92, Val Loss: 6.23270
Epoch 93, Val Loss: 6.31449
Epoch 94, Val Loss: 5.85880
Epoch 95, Val Loss: 6.66696
Epoch 96, Val Loss: 6.05198
Epoch 97, Val Loss: 5.94154
Epoch 98, Val Loss: 6.09467
Epoch 99, Val Loss: 6.04234
DID NOT SAVE RESULTS
{'MSE - mean': 4.745133560527353, 'MSE - std': 0.6253918253771406, 'R2 - mean': 0.5445368400801848, 'R2 - std': 0.019278958659590718} 
 

Results After CV: {'MSE - mean': 4.745133560527353, 'MSE - std': 0.6253918253771406, 'R2 - mean': 0.5445368400801848, 'R2 - std': 0.019278958659590718}
Train time: 112.07150177620024
Inference time: 0.05249838259987882
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 54 finished with value: 4.745133560527353 and parameters: {'p_m': 0.6714578966864783, 'alpha': 3.2912423864907088, 'K': 20, 'beta': 1.054916862346262}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.31084
Epoch 1, Val Loss: 13.88428
Epoch 2, Val Loss: 7.94646
Epoch 3, Val Loss: 7.41018
Epoch 4, Val Loss: 7.37532
Epoch 5, Val Loss: 7.13119
Epoch 6, Val Loss: 7.08490
Epoch 7, Val Loss: 7.00555
Epoch 8, Val Loss: 6.77925
Epoch 9, Val Loss: 6.67954
Epoch 10, Val Loss: 6.54880
Epoch 11, Val Loss: 6.73297
Epoch 12, Val Loss: 6.45156
Epoch 13, Val Loss: 6.36875
Epoch 14, Val Loss: 6.34127
Epoch 15, Val Loss: 6.56430
Epoch 16, Val Loss: 6.77581
Epoch 17, Val Loss: 6.36136
Epoch 18, Val Loss: 6.35465
Epoch 19, Val Loss: 6.33429
Epoch 20, Val Loss: 6.34604
Epoch 21, Val Loss: 6.46703
Epoch 22, Val Loss: 6.08950
Epoch 23, Val Loss: 6.04496
Epoch 24, Val Loss: 5.96152
Epoch 25, Val Loss: 5.97740
Epoch 26, Val Loss: 6.00163
Epoch 27, Val Loss: 6.26385
Epoch 28, Val Loss: 5.85025
Epoch 29, Val Loss: 5.90415
Epoch 30, Val Loss: 5.85828
Epoch 31, Val Loss: 5.73012
Epoch 32, Val Loss: 5.57397
Epoch 33, Val Loss: 5.62209
Epoch 34, Val Loss: 6.21533
Epoch 35, Val Loss: 5.55463
Epoch 36, Val Loss: 5.46230
Epoch 37, Val Loss: 5.47810
Epoch 38, Val Loss: 5.80439
Epoch 39, Val Loss: 5.87253
Epoch 40, Val Loss: 5.30888
Epoch 41, Val Loss: 5.56214
Epoch 42, Val Loss: 5.56637
Epoch 43, Val Loss: 5.46098
Epoch 44, Val Loss: 5.42232
Epoch 45, Val Loss: 5.15336
Epoch 46, Val Loss: 5.70803
Epoch 47, Val Loss: 5.18554
Epoch 48, Val Loss: 5.19096
Epoch 49, Val Loss: 5.17636
Epoch 50, Val Loss: 5.73351
Epoch 51, Val Loss: 4.92156
Epoch 52, Val Loss: 5.09683
Epoch 53, Val Loss: 5.43851
Epoch 54, Val Loss: 5.11573
Epoch 55, Val Loss: 4.97226
Epoch 56, Val Loss: 5.12269
Epoch 57, Val Loss: 5.03104
Epoch 58, Val Loss: 5.32076
Epoch 59, Val Loss: 5.25317
Epoch 60, Val Loss: 5.17135
Epoch 61, Val Loss: 5.03812
Epoch 62, Val Loss: 5.84677
Epoch 63, Val Loss: 5.19106
Epoch 64, Val Loss: 4.74169
Epoch 65, Val Loss: 4.83497
Epoch 66, Val Loss: 4.73761
Epoch 67, Val Loss: 5.04018
Epoch 68, Val Loss: 4.90466
Epoch 69, Val Loss: 5.00061
Epoch 70, Val Loss: 4.91823
Epoch 71, Val Loss: 4.85992
Epoch 72, Val Loss: 5.07163
Epoch 73, Val Loss: 5.05034
Epoch 74, Val Loss: 4.64450
Epoch 75, Val Loss: 4.75562
Epoch 76, Val Loss: 4.65293
Epoch 77, Val Loss: 4.91144
Epoch 78, Val Loss: 4.94111
Epoch 79, Val Loss: 4.68222
Epoch 80, Val Loss: 4.81571
Epoch 81, Val Loss: 4.81571
Epoch 82, Val Loss: 4.66473
Epoch 83, Val Loss: 4.63882
Epoch 84, Val Loss: 4.77720
Epoch 85, Val Loss: 4.75022
Epoch 86, Val Loss: 5.07776
Epoch 87, Val Loss: 4.53488
Epoch 88, Val Loss: 5.13816
Epoch 89, Val Loss: 4.80410
Epoch 90, Val Loss: 4.66569
Epoch 91, Val Loss: 4.80660
Epoch 92, Val Loss: 4.93624
Epoch 93, Val Loss: 4.59550
Epoch 94, Val Loss: 4.54061
Epoch 95, Val Loss: 4.83118
Epoch 96, Val Loss: 4.78208
Epoch 97, Val Loss: 5.04621
Epoch 98, Val Loss: 4.85787
Epoch 99, Val Loss: 4.72017
DID NOT SAVE RESULTS
{'MSE - mean': 4.728755970271805, 'MSE - std': 0.0, 'R2 - mean': 0.5687530809432939, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.69817
Epoch 1, Val Loss: 11.97195
Epoch 2, Val Loss: 6.04494
Epoch 3, Val Loss: 5.38005
Epoch 4, Val Loss: 5.32146
Epoch 5, Val Loss: 5.38194
Epoch 6, Val Loss: 5.32763
Epoch 7, Val Loss: 5.15116
Epoch 8, Val Loss: 5.12783
Epoch 9, Val Loss: 5.16243
Epoch 10, Val Loss: 5.10125
Epoch 11, Val Loss: 5.07096
Epoch 12, Val Loss: 5.04851
Epoch 13, Val Loss: 5.11939
Epoch 14, Val Loss: 5.14157
Epoch 15, Val Loss: 4.98947
Epoch 16, Val Loss: 5.71037
Epoch 17, Val Loss: 5.02058
Epoch 18, Val Loss: 4.89886
Epoch 19, Val Loss: 4.90823
Epoch 20, Val Loss: 4.74129
Epoch 21, Val Loss: 4.92775
Epoch 22, Val Loss: 4.66188
Epoch 23, Val Loss: 5.16111
Epoch 24, Val Loss: 4.73510
Epoch 25, Val Loss: 4.92846
Epoch 26, Val Loss: 4.70974
Epoch 27, Val Loss: 4.93704
Epoch 28, Val Loss: 4.73800
Epoch 29, Val Loss: 4.57449
Epoch 30, Val Loss: 4.68758
Epoch 31, Val Loss: 4.53129
Epoch 32, Val Loss: 4.95678
Epoch 33, Val Loss: 4.54187
Epoch 34, Val Loss: 4.95472
Epoch 35, Val Loss: 4.39572
Epoch 36, Val Loss: 4.52781
Epoch 37, Val Loss: 4.53206
Epoch 38, Val Loss: 4.75392
Epoch 39, Val Loss: 4.56407
Epoch 40, Val Loss: 4.44996
Epoch 41, Val Loss: 4.28250
Epoch 42, Val Loss: 4.18979
Epoch 43, Val Loss: 4.24220
Epoch 44, Val Loss: 4.20373
Epoch 45, Val Loss: 4.15866
Epoch 46, Val Loss: 4.40162
Epoch 47, Val Loss: 4.34659
Epoch 48, Val Loss: 4.83867
Epoch 49, Val Loss: 4.23444
Epoch 50, Val Loss: 4.21559
Epoch 51, Val Loss: 4.58260
Epoch 52, Val Loss: 4.24945
Epoch 53, Val Loss: 4.20236
Epoch 54, Val Loss: 4.29844
Epoch 55, Val Loss: 4.54204
Epoch 56, Val Loss: 4.27650
Epoch 57, Val Loss: 4.62357
Epoch 58, Val Loss: 4.19562
Epoch 59, Val Loss: 4.16780
Epoch 60, Val Loss: 4.23859
Epoch 61, Val Loss: 4.35912
Epoch 62, Val Loss: 4.45937
Epoch 63, Val Loss: 4.45622
Epoch 64, Val Loss: 4.07649
Epoch 65, Val Loss: 4.19492
Epoch 66, Val Loss: 4.14347
Epoch 67, Val Loss: 4.20571
Epoch 68, Val Loss: 4.12108
Epoch 69, Val Loss: 4.14346
Epoch 70, Val Loss: 4.88497
Epoch 71, Val Loss: 4.18563
Epoch 72, Val Loss: 4.48677
Epoch 73, Val Loss: 4.17589
Epoch 74, Val Loss: 4.64316
Epoch 75, Val Loss: 4.14210
Epoch 76, Val Loss: 4.24427
Epoch 77, Val Loss: 4.10029
Epoch 78, Val Loss: 4.07907
Epoch 79, Val Loss: 4.09473
Epoch 80, Val Loss: 4.15667
Epoch 81, Val Loss: 4.20081
Epoch 82, Val Loss: 4.01239
Epoch 83, Val Loss: 4.90038
Epoch 84, Val Loss: 4.32848
Epoch 85, Val Loss: 4.01739
Epoch 86, Val Loss: 4.11119
Epoch 87, Val Loss: 3.91593
Epoch 88, Val Loss: 3.94761
Epoch 89, Val Loss: 4.56283
Epoch 90, Val Loss: 3.99797
Epoch 91, Val Loss: 4.32412
Epoch 92, Val Loss: 4.84419
Epoch 93, Val Loss: 4.32496
Epoch 94, Val Loss: 4.03531
Epoch 95, Val Loss: 4.08016
Epoch 96, Val Loss: 4.05138
Epoch 97, Val Loss: 3.98645
Epoch 98, Val Loss: 3.97816
Epoch 99, Val Loss: 4.29835
DID NOT SAVE RESULTS
{'MSE - mean': 4.4293467044639705, 'MSE - std': 0.29940926580783467, 'R2 - mean': 0.5642579706668926, 'R2 - std': 0.004495110276401204} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.23368
Epoch 1, Val Loss: 12.31423
Epoch 2, Val Loss: 6.52367
Epoch 3, Val Loss: 6.30854
Epoch 4, Val Loss: 6.80917
Epoch 5, Val Loss: 6.22471
Epoch 6, Val Loss: 6.08119
Epoch 7, Val Loss: 6.25918
Epoch 8, Val Loss: 5.93773
Epoch 9, Val Loss: 5.88674
Epoch 10, Val Loss: 6.10888
Epoch 11, Val Loss: 5.79591
Epoch 12, Val Loss: 5.83662
Epoch 13, Val Loss: 5.75909
Epoch 14, Val Loss: 5.99218
Epoch 15, Val Loss: 5.79162
Epoch 16, Val Loss: 5.74294
Epoch 17, Val Loss: 5.71078
Epoch 18, Val Loss: 5.92390
Epoch 19, Val Loss: 5.51156
Epoch 20, Val Loss: 5.51750
Epoch 21, Val Loss: 5.83313
Epoch 22, Val Loss: 5.42135
Epoch 23, Val Loss: 5.59509
Epoch 24, Val Loss: 5.41920
Epoch 25, Val Loss: 5.66046
Epoch 26, Val Loss: 5.39087
Epoch 27, Val Loss: 5.31002
Epoch 28, Val Loss: 5.28455
Epoch 29, Val Loss: 5.61347
Epoch 30, Val Loss: 5.76100
Epoch 31, Val Loss: 5.47469
Epoch 32, Val Loss: 5.26911
Epoch 33, Val Loss: 5.30554
Epoch 34, Val Loss: 5.95899
Epoch 35, Val Loss: 5.18805
Epoch 36, Val Loss: 5.20903
Epoch 37, Val Loss: 5.11615
Epoch 38, Val Loss: 5.09744
Epoch 39, Val Loss: 4.97111
Epoch 40, Val Loss: 5.12135
Epoch 41, Val Loss: 5.20271
Epoch 42, Val Loss: 5.12999
Epoch 43, Val Loss: 5.20796
Epoch 44, Val Loss: 5.11157
Epoch 45, Val Loss: 5.30864
Epoch 46, Val Loss: 5.09643
Epoch 47, Val Loss: 4.98815
Epoch 48, Val Loss: 4.90985
Epoch 49, Val Loss: 4.86280
Epoch 50, Val Loss: 4.81184
Epoch 51, Val Loss: 4.92722
Epoch 52, Val Loss: 4.78753
Epoch 53, Val Loss: 4.86892
Epoch 54, Val Loss: 4.73905
Epoch 55, Val Loss: 4.70623
Epoch 56, Val Loss: 4.82501
Epoch 57, Val Loss: 5.11167
Epoch 58, Val Loss: 4.62588
Epoch 59, Val Loss: 4.75022
Epoch 60, Val Loss: 4.66111
Epoch 61, Val Loss: 4.67596
Epoch 62, Val Loss: 4.84584
Epoch 63, Val Loss: 4.77036
Epoch 64, Val Loss: 4.78456
Epoch 65, Val Loss: 4.75480
Epoch 66, Val Loss: 4.84115
Epoch 67, Val Loss: 4.73020
Epoch 68, Val Loss: 4.62249
Epoch 69, Val Loss: 4.72435
Epoch 70, Val Loss: 4.75906
Epoch 71, Val Loss: 4.65369
Epoch 72, Val Loss: 4.58405
Epoch 73, Val Loss: 4.64801
Epoch 74, Val Loss: 4.83935
Epoch 75, Val Loss: 4.61945
Epoch 76, Val Loss: 4.64523
Epoch 77, Val Loss: 4.65793
Epoch 78, Val Loss: 4.70973
Epoch 79, Val Loss: 4.72656
Epoch 80, Val Loss: 4.66263
Epoch 81, Val Loss: 4.87883
Epoch 82, Val Loss: 5.54269
Epoch 83, Val Loss: 4.86999
Epoch 84, Val Loss: 5.13369
Epoch 85, Val Loss: 4.85662
Epoch 86, Val Loss: 4.81539
Epoch 87, Val Loss: 4.52855
Epoch 88, Val Loss: 4.67870
Epoch 89, Val Loss: 4.68780
Epoch 90, Val Loss: 4.67250
Epoch 91, Val Loss: 4.64974
Epoch 92, Val Loss: 4.59921
Epoch 93, Val Loss: 4.71785
Epoch 94, Val Loss: 4.52754
Epoch 95, Val Loss: 4.69148
Epoch 96, Val Loss: 4.55494
Epoch 97, Val Loss: 4.86405
Epoch 98, Val Loss: 4.63012
Epoch 99, Val Loss: 4.60406
DID NOT SAVE RESULTS
{'MSE - mean': 4.5054087336978, 'MSE - std': 0.26708576066511003, 'R2 - mean': 0.5567402665755546, 'R2 - std': 0.01124732978123462} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.16983
Epoch 1, Val Loss: 10.24127
Epoch 2, Val Loss: 5.90447
Epoch 3, Val Loss: 5.46474
Epoch 4, Val Loss: 5.36235
Epoch 5, Val Loss: 5.39900
Epoch 6, Val Loss: 5.26952
Epoch 7, Val Loss: 5.34328
Epoch 8, Val Loss: 5.20805
Epoch 9, Val Loss: 5.11352
Epoch 10, Val Loss: 5.09348
Epoch 11, Val Loss: 5.12340
Epoch 12, Val Loss: 5.22597
Epoch 13, Val Loss: 5.15700
Epoch 14, Val Loss: 5.23451
Epoch 15, Val Loss: 5.02190
Epoch 16, Val Loss: 5.73452
Epoch 17, Val Loss: 4.90625
Epoch 18, Val Loss: 4.81569
Epoch 19, Val Loss: 4.79653
Epoch 20, Val Loss: 4.75119
Epoch 21, Val Loss: 4.76466
Epoch 22, Val Loss: 4.79388
Epoch 23, Val Loss: 4.65522
Epoch 24, Val Loss: 4.56698
Epoch 25, Val Loss: 4.62013
Epoch 26, Val Loss: 4.45761
Epoch 27, Val Loss: 4.73858
Epoch 28, Val Loss: 4.63075
Epoch 29, Val Loss: 4.49156
Epoch 30, Val Loss: 4.44367
Epoch 31, Val Loss: 4.58592
Epoch 32, Val Loss: 4.44710
Epoch 33, Val Loss: 4.42997
Epoch 34, Val Loss: 4.44002
Epoch 35, Val Loss: 4.29585
Epoch 36, Val Loss: 4.87763
Epoch 37, Val Loss: 4.29408
Epoch 38, Val Loss: 4.52803
Epoch 39, Val Loss: 4.27720
Epoch 40, Val Loss: 4.58252
Epoch 41, Val Loss: 4.35073
Epoch 42, Val Loss: 4.45824
Epoch 43, Val Loss: 4.51039
Epoch 44, Val Loss: 4.45851
Epoch 45, Val Loss: 4.40762
Epoch 46, Val Loss: 4.57187
Epoch 47, Val Loss: 4.32852
Epoch 48, Val Loss: 4.30892
Epoch 49, Val Loss: 4.18561
Epoch 50, Val Loss: 4.09557
Epoch 51, Val Loss: 4.46326
Epoch 52, Val Loss: 4.18888
Epoch 53, Val Loss: 4.12846
Epoch 54, Val Loss: 4.11022
Epoch 55, Val Loss: 4.12477
Epoch 56, Val Loss: 3.99481
Epoch 57, Val Loss: 4.31768
Epoch 58, Val Loss: 4.00679
Epoch 59, Val Loss: 4.25588
Epoch 60, Val Loss: 4.30821
Epoch 61, Val Loss: 4.20099
Epoch 62, Val Loss: 4.11621
Epoch 63, Val Loss: 3.99182
Epoch 64, Val Loss: 4.06182
Epoch 65, Val Loss: 4.31077
Epoch 66, Val Loss: 3.98648
Epoch 67, Val Loss: 3.98207
Epoch 68, Val Loss: 4.10843
Epoch 69, Val Loss: 4.04954
Epoch 70, Val Loss: 4.10915
Epoch 71, Val Loss: 3.96645
Epoch 72, Val Loss: 4.03829
Epoch 73, Val Loss: 3.91989
Epoch 74, Val Loss: 3.89793
Epoch 75, Val Loss: 4.10179
Epoch 76, Val Loss: 3.99178
Epoch 77, Val Loss: 4.21349
Epoch 78, Val Loss: 4.28776
Epoch 79, Val Loss: 4.04297
Epoch 80, Val Loss: 4.01953
Epoch 81, Val Loss: 4.05565
Epoch 82, Val Loss: 4.02198
Epoch 83, Val Loss: 3.98071
Epoch 84, Val Loss: 4.07586
Epoch 85, Val Loss: 4.01282
Epoch 86, Val Loss: 3.84111
Epoch 87, Val Loss: 4.10445
Epoch 88, Val Loss: 4.04242
Epoch 89, Val Loss: 4.21301
Epoch 90, Val Loss: 4.15994
Epoch 91, Val Loss: 4.17602
Epoch 92, Val Loss: 4.17761
Epoch 93, Val Loss: 3.99904
Epoch 94, Val Loss: 4.00458
Epoch 95, Val Loss: 3.97466
Epoch 96, Val Loss: 3.96815
Epoch 97, Val Loss: 3.99805
Epoch 98, Val Loss: 4.21766
Epoch 99, Val Loss: 3.96607
DID NOT SAVE RESULTS
{'MSE - mean': 4.409884523197544, 'MSE - std': 0.2843865802699511, 'R2 - mean': 0.5573385489903682, 'R2 - std': 0.009795440059002496} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.81836
Epoch 1, Val Loss: 22.55581
Epoch 2, Val Loss: 8.36995
Epoch 3, Val Loss: 8.15121
Epoch 4, Val Loss: 7.37490
Epoch 5, Val Loss: 7.51092
Epoch 6, Val Loss: 7.48596
Epoch 7, Val Loss: 7.92265
Epoch 8, Val Loss: 7.70559
Epoch 9, Val Loss: 7.57202
Epoch 10, Val Loss: 7.71004
Epoch 11, Val Loss: 7.26351
Epoch 12, Val Loss: 7.16515
Epoch 13, Val Loss: 7.16478
Epoch 14, Val Loss: 7.18974
Epoch 15, Val Loss: 7.15873
Epoch 16, Val Loss: 7.39667
Epoch 17, Val Loss: 7.43473
Epoch 18, Val Loss: 6.90896
Epoch 19, Val Loss: 7.02619
Epoch 20, Val Loss: 6.80780
Epoch 21, Val Loss: 6.82096
Epoch 22, Val Loss: 7.20082
Epoch 23, Val Loss: 6.72836
Epoch 24, Val Loss: 6.91176
Epoch 25, Val Loss: 7.15813
Epoch 26, Val Loss: 6.93534
Epoch 27, Val Loss: 7.02663
Epoch 28, Val Loss: 6.66431
Epoch 29, Val Loss: 6.64347
Epoch 30, Val Loss: 6.82514
Epoch 31, Val Loss: 6.52079
Epoch 32, Val Loss: 6.59840
Epoch 33, Val Loss: 6.70305
Epoch 34, Val Loss: 6.96306
Epoch 35, Val Loss: 6.58878
Epoch 36, Val Loss: 6.65974
Epoch 37, Val Loss: 6.45659
Epoch 38, Val Loss: 6.44170
Epoch 39, Val Loss: 6.51058
Epoch 40, Val Loss: 7.11267
Epoch 41, Val Loss: 6.53989
Epoch 42, Val Loss: 7.29376
Epoch 43, Val Loss: 6.42129
Epoch 44, Val Loss: 6.44584
Epoch 45, Val Loss: 6.62329
Epoch 46, Val Loss: 6.36371
Epoch 47, Val Loss: 6.48629
Epoch 48, Val Loss: 6.47099
Epoch 49, Val Loss: 6.53919
Epoch 50, Val Loss: 6.35269
Epoch 51, Val Loss: 6.39434
Epoch 52, Val Loss: 6.44594
Epoch 53, Val Loss: 6.66780
Epoch 54, Val Loss: 6.48908
Epoch 55, Val Loss: 6.23873
Epoch 56, Val Loss: 6.30942
Epoch 57, Val Loss: 6.31013
Epoch 58, Val Loss: 6.74440
Epoch 59, Val Loss: 6.45703
Epoch 60, Val Loss: 6.59657
Epoch 61, Val Loss: 6.17719
Epoch 62, Val Loss: 6.38428
Epoch 63, Val Loss: 6.78062
Epoch 64, Val Loss: 6.22338
Epoch 65, Val Loss: 6.17434
Epoch 66, Val Loss: 6.33351
Epoch 67, Val Loss: 7.03695
Epoch 68, Val Loss: 6.26262
Epoch 69, Val Loss: 6.42017
Epoch 70, Val Loss: 6.63916
Epoch 71, Val Loss: 6.41602
Epoch 72, Val Loss: 6.28076
Epoch 73, Val Loss: 6.25336
Epoch 74, Val Loss: 6.34538
Epoch 75, Val Loss: 6.47499
Epoch 76, Val Loss: 6.55988
Epoch 77, Val Loss: 6.22021
Epoch 78, Val Loss: 6.51042
Epoch 79, Val Loss: 6.27563
Epoch 80, Val Loss: 6.27491
Epoch 81, Val Loss: 6.27721
Epoch 82, Val Loss: 6.38208
Epoch 83, Val Loss: 6.28703
Epoch 84, Val Loss: 6.09928
Epoch 85, Val Loss: 6.19291
Epoch 86, Val Loss: 6.15168
Epoch 87, Val Loss: 6.61934
Epoch 88, Val Loss: 6.42425
Epoch 89, Val Loss: 6.18891
Epoch 90, Val Loss: 6.11441
Epoch 91, Val Loss: 6.15318
Epoch 92, Val Loss: 6.26335
Epoch 93, Val Loss: 6.04862
Epoch 94, Val Loss: 6.24518
Epoch 95, Val Loss: 6.11905
Epoch 96, Val Loss: 6.09888
Epoch 97, Val Loss: 6.24239
Epoch 98, Val Loss: 7.04267
Epoch 99, Val Loss: 6.21326
DID NOT SAVE RESULTS
{'MSE - mean': 4.7403168733627545, 'MSE - std': 0.7081262131660766, 'R2 - mean': 0.5456049758002036, 'R2 - std': 0.025049300908316828} 
 

Results After CV: {'MSE - mean': 4.7403168733627545, 'MSE - std': 0.7081262131660766, 'R2 - mean': 0.5456049758002036, 'R2 - std': 0.025049300908316828}
Train time: 81.67766856400013
Inference time: 0.05240431380079826
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 55 finished with value: 4.7403168733627545 and parameters: {'p_m': 0.6029408925919124, 'alpha': 5.779645308571537, 'K': 10, 'beta': 1.5568083000511423}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.92845
Epoch 1, Val Loss: 11.23735
Epoch 2, Val Loss: 7.15755
Epoch 3, Val Loss: 7.01650
Epoch 4, Val Loss: 7.25954
Epoch 5, Val Loss: 6.94870
Epoch 6, Val Loss: 6.99547
Epoch 7, Val Loss: 7.27361
Epoch 8, Val Loss: 7.14318
Epoch 9, Val Loss: 6.78019
Epoch 10, Val Loss: 6.69534
Epoch 11, Val Loss: 6.80031
Epoch 12, Val Loss: 6.63609
Epoch 13, Val Loss: 6.61165
Epoch 14, Val Loss: 6.65375
Epoch 15, Val Loss: 6.57723
Epoch 16, Val Loss: 6.48025
Epoch 17, Val Loss: 6.61169
Epoch 18, Val Loss: 6.34814
Epoch 19, Val Loss: 6.34728
Epoch 20, Val Loss: 6.33093
Epoch 21, Val Loss: 6.19084
Epoch 22, Val Loss: 6.28610
Epoch 23, Val Loss: 6.31036
Epoch 24, Val Loss: 6.32270
Epoch 25, Val Loss: 6.16682
Epoch 26, Val Loss: 7.00236
Epoch 27, Val Loss: 6.03902
Epoch 28, Val Loss: 6.09575
Epoch 29, Val Loss: 6.07003
Epoch 30, Val Loss: 6.09994
Epoch 31, Val Loss: 5.85560
Epoch 32, Val Loss: 5.97377
Epoch 33, Val Loss: 6.12374
Epoch 34, Val Loss: 6.07579
Epoch 35, Val Loss: 5.98486
Epoch 36, Val Loss: 5.92169
Epoch 37, Val Loss: 6.40733
Epoch 38, Val Loss: 5.76635
Epoch 39, Val Loss: 5.66953
Epoch 40, Val Loss: 5.76303
Epoch 41, Val Loss: 5.88778
Epoch 42, Val Loss: 5.67171
Epoch 43, Val Loss: 5.87289
Epoch 44, Val Loss: 5.58504
Epoch 45, Val Loss: 5.53009
Epoch 46, Val Loss: 5.51531
Epoch 47, Val Loss: 5.56418
Epoch 48, Val Loss: 5.46629
Epoch 49, Val Loss: 5.76165
Epoch 50, Val Loss: 5.85865
Epoch 51, Val Loss: 5.57681
Epoch 52, Val Loss: 5.48087
Epoch 53, Val Loss: 5.43928
Epoch 54, Val Loss: 5.32782
Epoch 55, Val Loss: 5.26078
Epoch 56, Val Loss: 5.38315
Epoch 57, Val Loss: 5.50398
Epoch 58, Val Loss: 5.21998
Epoch 59, Val Loss: 5.37025
Epoch 60, Val Loss: 5.40374
Epoch 61, Val Loss: 5.22396
Epoch 62, Val Loss: 5.31393
Epoch 63, Val Loss: 5.30510
Epoch 64, Val Loss: 5.18096
Epoch 65, Val Loss: 5.34444
Epoch 66, Val Loss: 5.27877
Epoch 67, Val Loss: 5.11083
Epoch 68, Val Loss: 5.07845
Epoch 69, Val Loss: 5.32506
Epoch 70, Val Loss: 4.98359
Epoch 71, Val Loss: 5.08558
Epoch 72, Val Loss: 5.34172
Epoch 73, Val Loss: 5.24858
Epoch 74, Val Loss: 4.99446
Epoch 75, Val Loss: 5.89926
Epoch 76, Val Loss: 5.30105
Epoch 77, Val Loss: 5.53356
Epoch 78, Val Loss: 4.95369
Epoch 79, Val Loss: 4.93960
Epoch 80, Val Loss: 5.32399
Epoch 81, Val Loss: 5.28157
Epoch 82, Val Loss: 5.09069
Epoch 83, Val Loss: 5.06177
Epoch 84, Val Loss: 4.99051
Epoch 85, Val Loss: 5.44169
Epoch 86, Val Loss: 4.84854
Epoch 87, Val Loss: 5.08416
Epoch 88, Val Loss: 5.08589
Epoch 89, Val Loss: 4.98998
Epoch 90, Val Loss: 4.96757
Epoch 91, Val Loss: 4.90848
Epoch 92, Val Loss: 5.25165
Epoch 93, Val Loss: 4.90646
Epoch 94, Val Loss: 5.30938
Epoch 95, Val Loss: 4.94005
Epoch 96, Val Loss: 4.89616
Epoch 97, Val Loss: 4.85345
Epoch 98, Val Loss: 4.81001
Epoch 99, Val Loss: 4.85993
DID NOT SAVE RESULTS
{'MSE - mean': 5.016807089582723, 'MSE - std': 0.0, 'R2 - mean': 0.5424837706818618, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.46550
Epoch 1, Val Loss: 9.72582
Epoch 2, Val Loss: 6.02660
Epoch 3, Val Loss: 5.84045
Epoch 4, Val Loss: 5.66824
Epoch 5, Val Loss: 5.44587
Epoch 6, Val Loss: 5.57943
Epoch 7, Val Loss: 5.33596
Epoch 8, Val Loss: 5.68845
Epoch 9, Val Loss: 5.27738
Epoch 10, Val Loss: 5.34126
Epoch 11, Val Loss: 5.28628
Epoch 12, Val Loss: 5.39875
Epoch 13, Val Loss: 5.26705
Epoch 14, Val Loss: 5.15222
Epoch 15, Val Loss: 5.18291
Epoch 16, Val Loss: 5.31312
Epoch 17, Val Loss: 5.27093
Epoch 18, Val Loss: 5.13225
Epoch 19, Val Loss: 5.11144
Epoch 20, Val Loss: 5.22902
Epoch 21, Val Loss: 5.10017
Epoch 22, Val Loss: 5.15143
Epoch 23, Val Loss: 5.04588
Epoch 24, Val Loss: 5.19089
Epoch 25, Val Loss: 5.02015
Epoch 26, Val Loss: 5.00471
Epoch 27, Val Loss: 5.12190
Epoch 28, Val Loss: 5.17165
Epoch 29, Val Loss: 5.01865
Epoch 30, Val Loss: 4.98550
Epoch 31, Val Loss: 5.22810
Epoch 32, Val Loss: 5.12737
Epoch 33, Val Loss: 5.11935
Epoch 34, Val Loss: 4.93991
Epoch 35, Val Loss: 5.32351
Epoch 36, Val Loss: 4.91316
Epoch 37, Val Loss: 4.91265
Epoch 38, Val Loss: 4.90230
Epoch 39, Val Loss: 5.07169
Epoch 40, Val Loss: 5.09722
Epoch 41, Val Loss: 4.91075
Epoch 42, Val Loss: 5.19597
Epoch 43, Val Loss: 5.76370
Epoch 44, Val Loss: 4.96542
Epoch 45, Val Loss: 4.87879
Epoch 46, Val Loss: 5.08680
Epoch 47, Val Loss: 4.80471
Epoch 48, Val Loss: 4.79883
Epoch 49, Val Loss: 4.94343
Epoch 50, Val Loss: 4.86076
Epoch 51, Val Loss: 4.92734
Epoch 52, Val Loss: 4.76280
Epoch 53, Val Loss: 4.82764
Epoch 54, Val Loss: 4.72350
Epoch 55, Val Loss: 4.79096
Epoch 56, Val Loss: 4.97504
Epoch 57, Val Loss: 5.48882
Epoch 58, Val Loss: 4.72343
Epoch 59, Val Loss: 4.75239
Epoch 60, Val Loss: 5.05718
Epoch 61, Val Loss: 4.62757
Epoch 62, Val Loss: 4.90042
Epoch 63, Val Loss: 4.89892
Epoch 64, Val Loss: 4.69580
Epoch 65, Val Loss: 4.76523
Epoch 66, Val Loss: 4.65812
Epoch 67, Val Loss: 4.57614
Epoch 68, Val Loss: 4.69732
Epoch 69, Val Loss: 4.83128
Epoch 70, Val Loss: 4.70294
Epoch 71, Val Loss: 4.59165
Epoch 72, Val Loss: 4.58917
Epoch 73, Val Loss: 4.53674
Epoch 74, Val Loss: 4.68010
Epoch 75, Val Loss: 4.55325
Epoch 76, Val Loss: 4.56195
Epoch 77, Val Loss: 4.52808
Epoch 78, Val Loss: 4.49586
Epoch 79, Val Loss: 4.46121
Epoch 80, Val Loss: 4.87590
Epoch 81, Val Loss: 5.03763
Epoch 82, Val Loss: 4.87687
Epoch 83, Val Loss: 4.49547
Epoch 84, Val Loss: 4.55678
Epoch 85, Val Loss: 4.44468
Epoch 86, Val Loss: 4.39629
Epoch 87, Val Loss: 4.40241
Epoch 88, Val Loss: 4.92964
Epoch 89, Val Loss: 4.51113
Epoch 90, Val Loss: 4.43901
Epoch 91, Val Loss: 5.24270
Epoch 92, Val Loss: 4.62297
Epoch 93, Val Loss: 4.70200
Epoch 94, Val Loss: 4.33961
Epoch 95, Val Loss: 4.34088
Epoch 96, Val Loss: 4.79542
Epoch 97, Val Loss: 5.24203
Epoch 98, Val Loss: 4.47305
Epoch 99, Val Loss: 4.45407
DID NOT SAVE RESULTS
{'MSE - mean': 4.741056693387636, 'MSE - std': 0.27575039619508734, 'R2 - mean': 0.5332487315758663, 'R2 - std': 0.00923503910599549} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.77514
Epoch 1, Val Loss: 11.09714
Epoch 2, Val Loss: 7.55047
Epoch 3, Val Loss: 6.63772
Epoch 4, Val Loss: 6.50707
Epoch 5, Val Loss: 6.47880
Epoch 6, Val Loss: 6.24219
Epoch 7, Val Loss: 6.36184
Epoch 8, Val Loss: 6.11018
Epoch 9, Val Loss: 6.32022
Epoch 10, Val Loss: 5.93627
Epoch 11, Val Loss: 5.84576
Epoch 12, Val Loss: 5.98313
Epoch 13, Val Loss: 5.84336
Epoch 14, Val Loss: 5.74771
Epoch 15, Val Loss: 5.60910
Epoch 16, Val Loss: 5.82659
Epoch 17, Val Loss: 5.68108
Epoch 18, Val Loss: 5.83010
Epoch 19, Val Loss: 5.67052
Epoch 20, Val Loss: 5.65396
Epoch 21, Val Loss: 6.09845
Epoch 22, Val Loss: 5.54656
Epoch 23, Val Loss: 5.70267
Epoch 24, Val Loss: 5.61773
Epoch 25, Val Loss: 5.38718
Epoch 26, Val Loss: 5.39830
Epoch 27, Val Loss: 5.51419
Epoch 28, Val Loss: 5.38916
Epoch 29, Val Loss: 5.51337
Epoch 30, Val Loss: 5.35951
Epoch 31, Val Loss: 5.44613
Epoch 32, Val Loss: 5.59656
Epoch 33, Val Loss: 5.42228
Epoch 34, Val Loss: 5.35602
Epoch 35, Val Loss: 5.45679
Epoch 36, Val Loss: 5.32809
Epoch 37, Val Loss: 5.23527
Epoch 38, Val Loss: 5.40163
Epoch 39, Val Loss: 5.46969
Epoch 40, Val Loss: 5.35641
Epoch 41, Val Loss: 5.28107
Epoch 42, Val Loss: 5.31569
Epoch 43, Val Loss: 5.36043
Epoch 44, Val Loss: 5.26132
Epoch 45, Val Loss: 5.32760
Epoch 46, Val Loss: 5.12772
Epoch 47, Val Loss: 5.25288
Epoch 48, Val Loss: 5.21178
Epoch 49, Val Loss: 5.23978
Epoch 50, Val Loss: 5.39204
Epoch 51, Val Loss: 5.16957
Epoch 52, Val Loss: 5.38935
Epoch 53, Val Loss: 5.72392
Epoch 54, Val Loss: 5.17825
Epoch 55, Val Loss: 5.32169
Epoch 56, Val Loss: 5.33370
Epoch 57, Val Loss: 5.07486
Epoch 58, Val Loss: 5.16133
Epoch 59, Val Loss: 5.08182
Epoch 60, Val Loss: 5.17569
Epoch 61, Val Loss: 5.10479
Epoch 62, Val Loss: 5.07970
Epoch 63, Val Loss: 5.05570
Epoch 64, Val Loss: 5.10114
Epoch 65, Val Loss: 5.07119
Epoch 66, Val Loss: 5.09113
Epoch 67, Val Loss: 5.32108
Epoch 68, Val Loss: 5.00287
Epoch 69, Val Loss: 5.06481
Epoch 70, Val Loss: 5.07476
Epoch 71, Val Loss: 5.33124
Epoch 72, Val Loss: 5.57446
Epoch 73, Val Loss: 5.79056
Epoch 74, Val Loss: 4.98679
Epoch 75, Val Loss: 5.39715
Epoch 76, Val Loss: 5.21418
Epoch 77, Val Loss: 5.18557
Epoch 78, Val Loss: 5.04264
Epoch 79, Val Loss: 5.09054
Epoch 80, Val Loss: 5.01177
Epoch 81, Val Loss: 4.97582
Epoch 82, Val Loss: 5.23203
Epoch 83, Val Loss: 4.91559
Epoch 84, Val Loss: 4.89132
Epoch 85, Val Loss: 5.23219
Epoch 86, Val Loss: 4.97518
Epoch 87, Val Loss: 5.50216
Epoch 88, Val Loss: 5.01372
Epoch 89, Val Loss: 5.01532
Epoch 90, Val Loss: 4.92916
Epoch 91, Val Loss: 5.03586
Epoch 92, Val Loss: 5.16621
Epoch 93, Val Loss: 4.95631
Epoch 94, Val Loss: 4.94709
Epoch 95, Val Loss: 5.04863
Epoch 96, Val Loss: 5.29071
Epoch 97, Val Loss: 5.81910
Epoch 98, Val Loss: 4.87738
Epoch 99, Val Loss: 4.87952
DID NOT SAVE RESULTS
{'MSE - mean': 4.794872577675759, 'MSE - std': 0.2376646505854913, 'R2 - mean': 0.5280324802272649, 'R2 - std': 0.010548737102441016} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.61427
Epoch 1, Val Loss: 7.55210
Epoch 2, Val Loss: 5.82832
Epoch 3, Val Loss: 5.59192
Epoch 4, Val Loss: 5.52134
Epoch 5, Val Loss: 5.60941
Epoch 6, Val Loss: 5.41794
Epoch 7, Val Loss: 5.31070
Epoch 8, Val Loss: 5.58795
Epoch 9, Val Loss: 5.70930
Epoch 10, Val Loss: 5.40502
Epoch 11, Val Loss: 5.38710
Epoch 12, Val Loss: 5.36594
Epoch 13, Val Loss: 5.15063
Epoch 14, Val Loss: 5.51946
Epoch 15, Val Loss: 5.14365
Epoch 16, Val Loss: 5.23063
Epoch 17, Val Loss: 5.10156
Epoch 18, Val Loss: 5.01788
Epoch 19, Val Loss: 5.01166
Epoch 20, Val Loss: 5.11249
Epoch 21, Val Loss: 5.06891
Epoch 22, Val Loss: 5.22149
Epoch 23, Val Loss: 5.03270
Epoch 24, Val Loss: 4.89565
Epoch 25, Val Loss: 4.84138
Epoch 26, Val Loss: 4.99837
Epoch 27, Val Loss: 4.81554
Epoch 28, Val Loss: 4.98104
Epoch 29, Val Loss: 4.88007
Epoch 30, Val Loss: 4.85146
Epoch 31, Val Loss: 4.82185
Epoch 32, Val Loss: 4.80991
Epoch 33, Val Loss: 4.88982
Epoch 34, Val Loss: 4.68482
Epoch 35, Val Loss: 4.95409
Epoch 36, Val Loss: 4.97198
Epoch 37, Val Loss: 4.93531
Epoch 38, Val Loss: 4.84745
Epoch 39, Val Loss: 4.62550
Epoch 40, Val Loss: 4.69537
Epoch 41, Val Loss: 4.55066
Epoch 42, Val Loss: 4.63303
Epoch 43, Val Loss: 5.04491
Epoch 44, Val Loss: 4.65532
Epoch 45, Val Loss: 4.54227
Epoch 46, Val Loss: 4.76339
Epoch 47, Val Loss: 4.48554
Epoch 48, Val Loss: 4.50952
Epoch 49, Val Loss: 4.59938
Epoch 50, Val Loss: 4.72065
Epoch 51, Val Loss: 4.50762
Epoch 52, Val Loss: 4.49389
Epoch 53, Val Loss: 5.09829
Epoch 54, Val Loss: 4.51393
Epoch 55, Val Loss: 4.40526
Epoch 56, Val Loss: 4.42729
Epoch 57, Val Loss: 4.31210
Epoch 58, Val Loss: 4.27620
Epoch 59, Val Loss: 4.43385
Epoch 60, Val Loss: 4.58146
Epoch 61, Val Loss: 4.27320
Epoch 62, Val Loss: 4.33116
Epoch 63, Val Loss: 4.34393
Epoch 64, Val Loss: 4.65634
Epoch 65, Val Loss: 4.13713
Epoch 66, Val Loss: 4.09888
Epoch 67, Val Loss: 4.25108
Epoch 68, Val Loss: 4.33847
Epoch 69, Val Loss: 4.39460
Epoch 70, Val Loss: 4.12202
Epoch 71, Val Loss: 4.11853
Epoch 72, Val Loss: 4.24652
Epoch 73, Val Loss: 4.07133
Epoch 74, Val Loss: 4.34825
Epoch 75, Val Loss: 4.40086
Epoch 76, Val Loss: 4.18897
Epoch 77, Val Loss: 4.62629
Epoch 78, Val Loss: 4.23215
Epoch 79, Val Loss: 4.17466
Epoch 80, Val Loss: 4.16062
Epoch 81, Val Loss: 4.05497
Epoch 82, Val Loss: 4.21353
Epoch 83, Val Loss: 4.01987
Epoch 84, Val Loss: 4.11374
Epoch 85, Val Loss: 4.09315
Epoch 86, Val Loss: 4.19780
Epoch 87, Val Loss: 4.08697
Epoch 88, Val Loss: 4.22180
Epoch 89, Val Loss: 4.29734
Epoch 90, Val Loss: 4.09216
Epoch 91, Val Loss: 4.07206
Epoch 92, Val Loss: 4.11952
Epoch 93, Val Loss: 4.24807
Epoch 94, Val Loss: 4.16895
Epoch 95, Val Loss: 4.16436
Epoch 96, Val Loss: 4.04036
Epoch 97, Val Loss: 4.24018
Epoch 98, Val Loss: 4.04086
Epoch 99, Val Loss: 4.17210
DID NOT SAVE RESULTS
{'MSE - mean': 4.693249339413474, 'MSE - std': 0.27082321220342587, 'R2 - mean': 0.5287224150376151, 'R2 - std': 0.009213301306801504} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.10791
Epoch 1, Val Loss: 15.94130
Epoch 2, Val Loss: 8.73164
Epoch 3, Val Loss: 8.69134
Epoch 4, Val Loss: 8.79667
Epoch 5, Val Loss: 8.46182
Epoch 6, Val Loss: 7.86764
Epoch 7, Val Loss: 7.81982
Epoch 8, Val Loss: 8.15625
Epoch 9, Val Loss: 7.71845
Epoch 10, Val Loss: 7.81997
Epoch 11, Val Loss: 7.90688
Epoch 12, Val Loss: 7.73206
Epoch 13, Val Loss: 7.39753
Epoch 14, Val Loss: 7.32403
Epoch 15, Val Loss: 7.87443
Epoch 16, Val Loss: 7.49833
Epoch 17, Val Loss: 7.64149
Epoch 18, Val Loss: 7.32757
Epoch 19, Val Loss: 7.41020
Epoch 20, Val Loss: 7.15130
Epoch 21, Val Loss: 7.36863
Epoch 22, Val Loss: 7.19675
Epoch 23, Val Loss: 7.69334
Epoch 24, Val Loss: 7.17907
Epoch 25, Val Loss: 7.18167
Epoch 26, Val Loss: 7.35013
Epoch 27, Val Loss: 7.12545
Epoch 28, Val Loss: 7.04276
Epoch 29, Val Loss: 7.16581
Epoch 30, Val Loss: 6.96678
Epoch 31, Val Loss: 7.22998
Epoch 32, Val Loss: 7.31996
Epoch 33, Val Loss: 7.38856
Epoch 34, Val Loss: 7.41043
Epoch 35, Val Loss: 6.87017
Epoch 36, Val Loss: 6.92297
Epoch 37, Val Loss: 7.61721
Epoch 38, Val Loss: 7.00837
Epoch 39, Val Loss: 7.23736
Epoch 40, Val Loss: 7.18921
Epoch 41, Val Loss: 6.76079
Epoch 42, Val Loss: 7.07301
Epoch 43, Val Loss: 6.86508
Epoch 44, Val Loss: 6.73637
Epoch 45, Val Loss: 6.72637
Epoch 46, Val Loss: 6.83592
Epoch 47, Val Loss: 6.64919
Epoch 48, Val Loss: 6.88972
Epoch 49, Val Loss: 6.75118
Epoch 50, Val Loss: 6.64955
Epoch 51, Val Loss: 6.72991
Epoch 52, Val Loss: 6.50083
Epoch 53, Val Loss: 6.63995
Epoch 54, Val Loss: 6.62480
Epoch 55, Val Loss: 6.94335
Epoch 56, Val Loss: 6.63334
Epoch 57, Val Loss: 6.65320
Epoch 58, Val Loss: 6.42656
Epoch 59, Val Loss: 6.55483
Epoch 60, Val Loss: 6.38793
Epoch 61, Val Loss: 6.46569
Epoch 62, Val Loss: 6.60974
Epoch 63, Val Loss: 6.80722
Epoch 64, Val Loss: 6.44751
Epoch 65, Val Loss: 6.94423
Epoch 66, Val Loss: 6.64460
Epoch 67, Val Loss: 6.89091
Epoch 68, Val Loss: 6.38997
Epoch 69, Val Loss: 6.44348
Epoch 70, Val Loss: 6.71329
Epoch 71, Val Loss: 6.37771
Epoch 72, Val Loss: 6.90632
Epoch 73, Val Loss: 6.54815
Epoch 74, Val Loss: 6.48413
Epoch 75, Val Loss: 6.33987
Epoch 76, Val Loss: 6.43967
Epoch 77, Val Loss: 6.44336
Epoch 78, Val Loss: 6.71657
Epoch 79, Val Loss: 6.64422
Epoch 80, Val Loss: 6.30672
Epoch 81, Val Loss: 6.48112
Epoch 82, Val Loss: 6.46879
Epoch 83, Val Loss: 6.84990
Epoch 84, Val Loss: 6.56256
Epoch 85, Val Loss: 6.21336
Epoch 86, Val Loss: 6.48470
Epoch 87, Val Loss: 6.70087
Epoch 88, Val Loss: 7.01611
Epoch 89, Val Loss: 6.45174
Epoch 90, Val Loss: 6.28708
Epoch 91, Val Loss: 6.45400
Epoch 92, Val Loss: 6.23608
Epoch 93, Val Loss: 6.41789
Epoch 94, Val Loss: 6.37339
Epoch 95, Val Loss: 6.37874
Epoch 96, Val Loss: 6.50180
Epoch 97, Val Loss: 6.55232
Epoch 98, Val Loss: 6.42721
Epoch 99, Val Loss: 6.83633
DID NOT SAVE RESULTS
{'MSE - mean': 4.994589923286066, 'MSE - std': 0.6495388824152437, 'R2 - mean': 0.5204311123398894, 'R2 - std': 0.018517309158654422} 
 

Results After CV: {'MSE - mean': 4.994589923286066, 'MSE - std': 0.6495388824152437, 'R2 - mean': 0.5204311123398894, 'R2 - std': 0.018517309158654422}
Train time: 113.4844070836003
Inference time: 0.051230831600332746
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 56 finished with value: 4.994589923286066 and parameters: {'p_m': 0.7892801996866146, 'alpha': 2.061522013546524, 'K': 20, 'beta': 4.991462394409848}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.19746
Epoch 1, Val Loss: 12.26563
Epoch 2, Val Loss: 7.67287
Epoch 3, Val Loss: 7.06493
Epoch 4, Val Loss: 6.66217
Epoch 5, Val Loss: 6.82305
Epoch 6, Val Loss: 6.42707
Epoch 7, Val Loss: 6.33576
Epoch 8, Val Loss: 6.39968
Epoch 9, Val Loss: 6.32670
Epoch 10, Val Loss: 6.20694
Epoch 11, Val Loss: 6.25706
Epoch 12, Val Loss: 6.20251
Epoch 13, Val Loss: 6.29482
Epoch 14, Val Loss: 6.20893
Epoch 15, Val Loss: 6.42350
Epoch 16, Val Loss: 6.09082
Epoch 17, Val Loss: 6.11948
Epoch 18, Val Loss: 6.14861
Epoch 19, Val Loss: 5.91410
Epoch 20, Val Loss: 5.94095
Epoch 21, Val Loss: 6.01907
Epoch 22, Val Loss: 6.12956
Epoch 23, Val Loss: 5.79001
Epoch 24, Val Loss: 5.77843
Epoch 25, Val Loss: 6.04036
Epoch 26, Val Loss: 5.78678
Epoch 27, Val Loss: 5.75820
Epoch 28, Val Loss: 6.14681
Epoch 29, Val Loss: 5.68243
Epoch 30, Val Loss: 5.69402
Epoch 31, Val Loss: 5.64786
Epoch 32, Val Loss: 5.70507
Epoch 33, Val Loss: 5.69490
Epoch 34, Val Loss: 5.71772
Epoch 35, Val Loss: 5.64481
Epoch 36, Val Loss: 5.49135
Epoch 37, Val Loss: 5.53490
Epoch 38, Val Loss: 5.45932
Epoch 39, Val Loss: 5.61635
Epoch 40, Val Loss: 5.52339
Epoch 41, Val Loss: 5.58049
Epoch 42, Val Loss: 5.42515
Epoch 43, Val Loss: 5.88063
Epoch 44, Val Loss: 5.37112
Epoch 45, Val Loss: 5.30562
Epoch 46, Val Loss: 5.25882
Epoch 47, Val Loss: 5.71281
Epoch 48, Val Loss: 5.18575
Epoch 49, Val Loss: 5.22083
Epoch 50, Val Loss: 5.67687
Epoch 51, Val Loss: 5.40459
Epoch 52, Val Loss: 5.21612
Epoch 53, Val Loss: 5.59068
Epoch 54, Val Loss: 5.16339
Epoch 55, Val Loss: 5.32021
Epoch 56, Val Loss: 5.39968
Epoch 57, Val Loss: 5.74434
Epoch 58, Val Loss: 5.53511
Epoch 59, Val Loss: 5.13925
Epoch 60, Val Loss: 5.45728
Epoch 61, Val Loss: 5.11886
Epoch 62, Val Loss: 5.48555
Epoch 63, Val Loss: 5.12554
Epoch 64, Val Loss: 5.42328
Epoch 65, Val Loss: 5.28383
Epoch 66, Val Loss: 5.43580
Epoch 67, Val Loss: 4.95446
Epoch 68, Val Loss: 5.16226
Epoch 69, Val Loss: 5.01538
Epoch 70, Val Loss: 5.43806
Epoch 71, Val Loss: 5.86744
Epoch 72, Val Loss: 5.49049
Epoch 73, Val Loss: 5.52694
Epoch 74, Val Loss: 5.30084
Epoch 75, Val Loss: 5.52286
Epoch 76, Val Loss: 5.02788
Epoch 77, Val Loss: 5.41420
Epoch 78, Val Loss: 5.14570
Epoch 79, Val Loss: 5.22109
Epoch 80, Val Loss: 5.15330
Epoch 81, Val Loss: 5.05868
Epoch 82, Val Loss: 5.13534
Epoch 83, Val Loss: 5.48746
Epoch 84, Val Loss: 5.07776
Epoch 85, Val Loss: 5.12888
Epoch 86, Val Loss: 5.05497
Epoch 87, Val Loss: 5.00794
Epoch 88, Val Loss: 5.03453
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 5.15563388043287, 'MSE - std': 0.0, 'R2 - mean': 0.5298232260876745, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.62865
Epoch 1, Val Loss: 8.40554
Epoch 2, Val Loss: 5.86579
Epoch 3, Val Loss: 6.01582
Epoch 4, Val Loss: 5.59497
Epoch 5, Val Loss: 5.65805
Epoch 6, Val Loss: 5.39925
Epoch 7, Val Loss: 5.40973
Epoch 8, Val Loss: 5.29803
Epoch 9, Val Loss: 5.34658
Epoch 10, Val Loss: 5.35639
Epoch 11, Val Loss: 5.32980
Epoch 12, Val Loss: 5.43130
Epoch 13, Val Loss: 5.17773
Epoch 14, Val Loss: 5.69037
Epoch 15, Val Loss: 5.20891
Epoch 16, Val Loss: 5.07540
Epoch 17, Val Loss: 5.07154
Epoch 18, Val Loss: 5.06415
Epoch 19, Val Loss: 4.92740
Epoch 20, Val Loss: 4.92162
Epoch 21, Val Loss: 4.92594
Epoch 22, Val Loss: 5.31185
Epoch 23, Val Loss: 4.93585
Epoch 24, Val Loss: 4.90437
Epoch 25, Val Loss: 4.92991
Epoch 26, Val Loss: 5.09242
Epoch 27, Val Loss: 5.64155
Epoch 28, Val Loss: 4.79641
Epoch 29, Val Loss: 5.11308
Epoch 30, Val Loss: 5.02862
Epoch 31, Val Loss: 4.87118
Epoch 32, Val Loss: 4.73125
Epoch 33, Val Loss: 4.72606
Epoch 34, Val Loss: 4.87848
Epoch 35, Val Loss: 4.73821
Epoch 36, Val Loss: 4.69440
Epoch 37, Val Loss: 4.94778
Epoch 38, Val Loss: 4.82559
Epoch 39, Val Loss: 4.77453
Epoch 40, Val Loss: 4.73885
Epoch 41, Val Loss: 4.95006
Epoch 42, Val Loss: 5.39482
Epoch 43, Val Loss: 5.61309
Epoch 44, Val Loss: 4.87904
Epoch 45, Val Loss: 4.65252
Epoch 46, Val Loss: 4.76286
Epoch 47, Val Loss: 4.52857
Epoch 48, Val Loss: 5.02623
Epoch 49, Val Loss: 4.53571
Epoch 50, Val Loss: 4.95590
Epoch 51, Val Loss: 4.59255
Epoch 52, Val Loss: 4.58369
Epoch 53, Val Loss: 4.65449
Epoch 54, Val Loss: 4.56084
Epoch 55, Val Loss: 4.47030
Epoch 56, Val Loss: 4.46596
Epoch 57, Val Loss: 4.73063
Epoch 58, Val Loss: 4.63365
Epoch 59, Val Loss: 4.76230
Epoch 60, Val Loss: 4.34053
Epoch 61, Val Loss: 4.44898
Epoch 62, Val Loss: 4.64052
Epoch 63, Val Loss: 4.45787
Epoch 64, Val Loss: 4.47638
Epoch 65, Val Loss: 4.27212
Epoch 66, Val Loss: 4.40358
Epoch 67, Val Loss: 4.37839
Epoch 68, Val Loss: 4.38698
Epoch 69, Val Loss: 4.60614
Epoch 70, Val Loss: 4.45685
Epoch 71, Val Loss: 4.36482
Epoch 72, Val Loss: 4.70696
Epoch 73, Val Loss: 4.55304
Epoch 74, Val Loss: 4.31211
Epoch 75, Val Loss: 4.78513
Epoch 76, Val Loss: 4.34313
Epoch 77, Val Loss: 4.24825
Epoch 78, Val Loss: 4.58719
Epoch 79, Val Loss: 4.17848
Epoch 80, Val Loss: 4.42592
Epoch 81, Val Loss: 4.29491
Epoch 82, Val Loss: 4.25594
Epoch 83, Val Loss: 4.23235
Epoch 84, Val Loss: 4.30224
Epoch 85, Val Loss: 4.65229
Epoch 86, Val Loss: 4.35318
Epoch 87, Val Loss: 4.17741
Epoch 88, Val Loss: 4.27954
Epoch 89, Val Loss: 4.57496
Epoch 90, Val Loss: 4.39259
Epoch 91, Val Loss: 4.39688
Epoch 92, Val Loss: 4.14227
Epoch 93, Val Loss: 5.10757
Epoch 94, Val Loss: 4.30876
Epoch 95, Val Loss: 4.33926
Epoch 96, Val Loss: 4.51473
Epoch 97, Val Loss: 4.52192
Epoch 98, Val Loss: 4.24474
Epoch 99, Val Loss: 4.15258
DID NOT SAVE RESULTS
{'MSE - mean': 4.732103935553235, 'MSE - std': 0.4235299448796339, 'R2 - mean': 0.5352720219333142, 'R2 - std': 0.005448795845639731} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.14380
Epoch 1, Val Loss: 8.15244
Epoch 2, Val Loss: 6.90654
Epoch 3, Val Loss: 6.41871
Epoch 4, Val Loss: 6.93696
Epoch 5, Val Loss: 6.15312
Epoch 6, Val Loss: 6.08481
Epoch 7, Val Loss: 6.17665
Epoch 8, Val Loss: 6.55507
Epoch 9, Val Loss: 5.96917
Epoch 10, Val Loss: 6.32735
Epoch 11, Val Loss: 6.05273
Epoch 12, Val Loss: 6.05888
Epoch 13, Val Loss: 5.92633
Epoch 14, Val Loss: 6.16510
Epoch 15, Val Loss: 5.93182
Epoch 16, Val Loss: 6.10110
Epoch 17, Val Loss: 5.68362
Epoch 18, Val Loss: 5.98764
Epoch 19, Val Loss: 5.76750
Epoch 20, Val Loss: 5.57611
Epoch 21, Val Loss: 5.52684
Epoch 22, Val Loss: 5.79114
Epoch 23, Val Loss: 6.27750
Epoch 24, Val Loss: 5.41897
Epoch 25, Val Loss: 5.97345
Epoch 26, Val Loss: 5.37192
Epoch 27, Val Loss: 5.42526
Epoch 28, Val Loss: 5.60640
Epoch 29, Val Loss: 5.31795
Epoch 30, Val Loss: 5.21104
Epoch 31, Val Loss: 5.34836
Epoch 32, Val Loss: 5.32637
Epoch 33, Val Loss: 5.35867
Epoch 34, Val Loss: 5.43763
Epoch 35, Val Loss: 5.63296
Epoch 36, Val Loss: 5.32447
Epoch 37, Val Loss: 5.21487
Epoch 38, Val Loss: 5.15574
Epoch 39, Val Loss: 5.42096
Epoch 40, Val Loss: 5.23799
Epoch 41, Val Loss: 5.17587
Epoch 42, Val Loss: 5.24184
Epoch 43, Val Loss: 5.36247
Epoch 44, Val Loss: 5.13283
Epoch 45, Val Loss: 5.22858
Epoch 46, Val Loss: 5.15032
Epoch 47, Val Loss: 5.30119
Epoch 48, Val Loss: 4.99919
Epoch 49, Val Loss: 5.28308
Epoch 50, Val Loss: 5.15964
Epoch 51, Val Loss: 5.12421
Epoch 52, Val Loss: 5.32383
Epoch 53, Val Loss: 5.00561
Epoch 54, Val Loss: 5.13843
Epoch 55, Val Loss: 5.38846
Epoch 56, Val Loss: 5.00426
Epoch 57, Val Loss: 4.87355
Epoch 58, Val Loss: 4.81038
Epoch 59, Val Loss: 4.88565
Epoch 60, Val Loss: 5.01382
Epoch 61, Val Loss: 4.89564
Epoch 62, Val Loss: 5.01904
Epoch 63, Val Loss: 4.90250
Epoch 64, Val Loss: 5.36813
Epoch 65, Val Loss: 4.95050
Epoch 66, Val Loss: 4.85821
Epoch 67, Val Loss: 4.94576
Epoch 68, Val Loss: 4.82813
Epoch 69, Val Loss: 5.85966
Epoch 70, Val Loss: 4.91904
Epoch 71, Val Loss: 4.82661
Epoch 72, Val Loss: 4.84237
Epoch 73, Val Loss: 4.79589
Epoch 74, Val Loss: 4.72021
Epoch 75, Val Loss: 4.90932
Epoch 76, Val Loss: 4.75236
Epoch 77, Val Loss: 4.95895
Epoch 78, Val Loss: 4.63167
Epoch 79, Val Loss: 5.01660
Epoch 80, Val Loss: 4.70516
Epoch 81, Val Loss: 4.77497
Epoch 82, Val Loss: 4.62617
Epoch 83, Val Loss: 4.63865
Epoch 84, Val Loss: 4.61014
Epoch 85, Val Loss: 4.99993
Epoch 86, Val Loss: 4.58759
Epoch 87, Val Loss: 5.05819
Epoch 88, Val Loss: 4.57354
Epoch 89, Val Loss: 4.62669
Epoch 90, Val Loss: 4.66974
Epoch 91, Val Loss: 4.63694
Epoch 92, Val Loss: 4.59090
Epoch 93, Val Loss: 5.10484
Epoch 94, Val Loss: 4.47518
Epoch 95, Val Loss: 4.71890
Epoch 96, Val Loss: 4.65845
Epoch 97, Val Loss: 4.61972
Epoch 98, Val Loss: 4.63740
Epoch 99, Val Loss: 4.76946
DID NOT SAVE RESULTS
{'MSE - mean': 4.673439715187266, 'MSE - std': 0.35562347734946376, 'R2 - mean': 0.5407428823644433, 'R2 - std': 0.008924883481522993} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.32920
Epoch 1, Val Loss: 8.72209
Epoch 2, Val Loss: 6.43924
Epoch 3, Val Loss: 5.58139
Epoch 4, Val Loss: 5.49305
Epoch 5, Val Loss: 5.55768
Epoch 6, Val Loss: 5.61905
Epoch 7, Val Loss: 5.39496
Epoch 8, Val Loss: 5.50324
Epoch 9, Val Loss: 5.46571
Epoch 10, Val Loss: 5.26277
Epoch 11, Val Loss: 5.36573
Epoch 12, Val Loss: 5.49468
Epoch 13, Val Loss: 5.49992
Epoch 14, Val Loss: 5.58331
Epoch 15, Val Loss: 5.40035
Epoch 16, Val Loss: 5.49138
Epoch 17, Val Loss: 5.17001
Epoch 18, Val Loss: 5.17866
Epoch 19, Val Loss: 5.24207
Epoch 20, Val Loss: 5.18746
Epoch 21, Val Loss: 5.08685
Epoch 22, Val Loss: 5.43915
Epoch 23, Val Loss: 5.08333
Epoch 24, Val Loss: 5.26385
Epoch 25, Val Loss: 5.19332
Epoch 26, Val Loss: 5.29910
Epoch 27, Val Loss: 5.22302
Epoch 28, Val Loss: 5.05143
Epoch 29, Val Loss: 5.05094
Epoch 30, Val Loss: 4.96204
Epoch 31, Val Loss: 4.93533
Epoch 32, Val Loss: 5.49071
Epoch 33, Val Loss: 5.00414
Epoch 34, Val Loss: 5.32078
Epoch 35, Val Loss: 5.04071
Epoch 36, Val Loss: 4.99234
Epoch 37, Val Loss: 4.91880
Epoch 38, Val Loss: 4.99785
Epoch 39, Val Loss: 5.05004
Epoch 40, Val Loss: 4.90634
Epoch 41, Val Loss: 4.80064
Epoch 42, Val Loss: 4.81561
Epoch 43, Val Loss: 4.81423
Epoch 44, Val Loss: 4.87467
Epoch 45, Val Loss: 4.79175
Epoch 46, Val Loss: 4.92757
Epoch 47, Val Loss: 4.80599
Epoch 48, Val Loss: 4.68047
Epoch 49, Val Loss: 4.79338
Epoch 50, Val Loss: 4.78360
Epoch 51, Val Loss: 4.78487
Epoch 52, Val Loss: 4.71076
Epoch 53, Val Loss: 4.66758
Epoch 54, Val Loss: 4.69838
Epoch 55, Val Loss: 4.64174
Epoch 56, Val Loss: 4.69641
Epoch 57, Val Loss: 4.59125
Epoch 58, Val Loss: 4.73533
Epoch 59, Val Loss: 4.69777
Epoch 60, Val Loss: 4.58056
Epoch 61, Val Loss: 4.60366
Epoch 62, Val Loss: 4.69145
Epoch 63, Val Loss: 4.59110
Epoch 64, Val Loss: 4.62098
Epoch 65, Val Loss: 4.82008
Epoch 66, Val Loss: 4.71659
Epoch 67, Val Loss: 4.56183
Epoch 68, Val Loss: 4.57427
Epoch 69, Val Loss: 5.07651
Epoch 70, Val Loss: 4.67898
Epoch 71, Val Loss: 4.80184
Epoch 72, Val Loss: 4.51722
Epoch 73, Val Loss: 4.60371
Epoch 74, Val Loss: 4.78675
Epoch 75, Val Loss: 4.46643
Epoch 76, Val Loss: 4.56337
Epoch 77, Val Loss: 4.53023
Epoch 78, Val Loss: 4.36079
Epoch 79, Val Loss: 4.67139
Epoch 80, Val Loss: 4.53696
Epoch 81, Val Loss: 4.45676
Epoch 82, Val Loss: 4.43595
Epoch 83, Val Loss: 4.27652
Epoch 84, Val Loss: 4.75965
Epoch 85, Val Loss: 4.29869
Epoch 86, Val Loss: 4.27386
Epoch 87, Val Loss: 4.39350
Epoch 88, Val Loss: 4.31997
Epoch 89, Val Loss: 4.65250
Epoch 90, Val Loss: 4.33206
Epoch 91, Val Loss: 4.47423
Epoch 92, Val Loss: 4.69613
Epoch 93, Val Loss: 4.38328
Epoch 94, Val Loss: 4.43625
Epoch 95, Val Loss: 4.36860
Epoch 96, Val Loss: 4.68621
Epoch 97, Val Loss: 4.22534
Epoch 98, Val Loss: 4.54726
Epoch 99, Val Loss: 4.47660
DID NOT SAVE RESULTS
{'MSE - mean': 4.652771728177262, 'MSE - std': 0.3100524799009523, 'R2 - mean': 0.5328453558672274, 'R2 - std': 0.015711554130376653} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.29593
Epoch 1, Val Loss: 10.99457
Epoch 2, Val Loss: 9.98858
Epoch 3, Val Loss: 8.16869
Epoch 4, Val Loss: 7.85881
Epoch 5, Val Loss: 7.82108
Epoch 6, Val Loss: 7.82587
Epoch 7, Val Loss: 8.41697
Epoch 8, Val Loss: 7.53920
Epoch 9, Val Loss: 7.54049
Epoch 10, Val Loss: 7.57838
Epoch 11, Val Loss: 7.54732
Epoch 12, Val Loss: 7.81575
Epoch 13, Val Loss: 7.32311
Epoch 14, Val Loss: 7.86538
Epoch 15, Val Loss: 7.80888
Epoch 16, Val Loss: 7.93666
Epoch 17, Val Loss: 7.28077
Epoch 18, Val Loss: 7.47189
Epoch 19, Val Loss: 7.85178
Epoch 20, Val Loss: 7.22750
Epoch 21, Val Loss: 7.42566
Epoch 22, Val Loss: 7.46136
Epoch 23, Val Loss: 7.06667
Epoch 24, Val Loss: 7.03515
Epoch 25, Val Loss: 6.98212
Epoch 26, Val Loss: 7.27090
Epoch 27, Val Loss: 6.93187
Epoch 28, Val Loss: 7.25584
Epoch 29, Val Loss: 6.89048
Epoch 30, Val Loss: 6.91554
Epoch 31, Val Loss: 7.08716
Epoch 32, Val Loss: 6.84376
Epoch 33, Val Loss: 7.01006
Epoch 34, Val Loss: 6.85351
Epoch 35, Val Loss: 6.89270
Epoch 36, Val Loss: 7.11510
Epoch 37, Val Loss: 7.01241
Epoch 38, Val Loss: 6.83939
Epoch 39, Val Loss: 6.73597
Epoch 40, Val Loss: 6.78596
Epoch 41, Val Loss: 6.68053
Epoch 42, Val Loss: 6.87764
Epoch 43, Val Loss: 6.62048
Epoch 44, Val Loss: 6.77173
Epoch 45, Val Loss: 6.60114
Epoch 46, Val Loss: 7.12294
Epoch 47, Val Loss: 6.56647
Epoch 48, Val Loss: 6.48521
Epoch 49, Val Loss: 6.70778
Epoch 50, Val Loss: 6.46095
Epoch 51, Val Loss: 6.44141
Epoch 52, Val Loss: 6.99287
Epoch 53, Val Loss: 6.48108
Epoch 54, Val Loss: 6.28486
Epoch 55, Val Loss: 6.25800
Epoch 56, Val Loss: 6.15180
Epoch 57, Val Loss: 6.63372
Epoch 58, Val Loss: 6.48788
Epoch 59, Val Loss: 6.20264
Epoch 60, Val Loss: 6.33346
Epoch 61, Val Loss: 6.08882
Epoch 62, Val Loss: 6.65575
Epoch 63, Val Loss: 6.27213
Epoch 64, Val Loss: 6.19022
Epoch 65, Val Loss: 6.07346
Epoch 66, Val Loss: 6.26489
Epoch 67, Val Loss: 5.99966
Epoch 68, Val Loss: 6.14785
Epoch 69, Val Loss: 6.30776
Epoch 70, Val Loss: 5.95551
Epoch 71, Val Loss: 6.36861
Epoch 72, Val Loss: 6.00093
Epoch 73, Val Loss: 6.36990
Epoch 74, Val Loss: 6.33329
Epoch 75, Val Loss: 6.08375
Epoch 76, Val Loss: 5.83008
Epoch 77, Val Loss: 6.37712
Epoch 78, Val Loss: 5.91184
Epoch 79, Val Loss: 5.79124
Epoch 80, Val Loss: 6.11051
Epoch 81, Val Loss: 6.39213
Epoch 82, Val Loss: 5.69328
Epoch 83, Val Loss: 5.91635
Epoch 84, Val Loss: 5.88946
Epoch 85, Val Loss: 6.10947
Epoch 86, Val Loss: 5.95073
Epoch 87, Val Loss: 5.98780
Epoch 88, Val Loss: 5.81076
Epoch 89, Val Loss: 5.97011
Epoch 90, Val Loss: 6.03751
Epoch 91, Val Loss: 5.71100
Epoch 92, Val Loss: 6.10322
Epoch 93, Val Loss: 6.12817
Epoch 94, Val Loss: 6.00992
Epoch 95, Val Loss: 6.28908
Epoch 96, Val Loss: 6.29605
Epoch 97, Val Loss: 7.11881
Epoch 98, Val Loss: 5.87981
Epoch 99, Val Loss: 5.82384
DID NOT SAVE RESULTS
{'MSE - mean': 4.859450053821069, 'MSE - std': 0.4977647570870148, 'R2 - mean': 0.532227501074199, 'R2 - std': 0.014107066482244895} 
 

Results After CV: {'MSE - mean': 4.859450053821069, 'MSE - std': 0.4977647570870148, 'R2 - mean': 0.532227501074199, 'R2 - std': 0.014107066482244895}
Train time: 112.03589011519944
Inference time: 0.05417474640016735
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 57 finished with value: 4.859450053821069 and parameters: {'p_m': 0.49694232038533, 'alpha': 5.003530964999024, 'K': 20, 'beta': 2.126891790802045}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 41.75891
Epoch 1, Val Loss: 11.10233
Epoch 2, Val Loss: 6.85034
Epoch 3, Val Loss: 6.35465
Epoch 4, Val Loss: 6.41010
Epoch 5, Val Loss: 6.30977
Epoch 6, Val Loss: 6.25272
Epoch 7, Val Loss: 5.98736
Epoch 8, Val Loss: 6.08986
Epoch 9, Val Loss: 5.90577
Epoch 10, Val Loss: 5.85269
Epoch 11, Val Loss: 5.78730
Epoch 12, Val Loss: 6.16081
Epoch 13, Val Loss: 5.80307
Epoch 14, Val Loss: 5.76432
Epoch 15, Val Loss: 5.37680
Epoch 16, Val Loss: 5.26560
Epoch 17, Val Loss: 5.45843
Epoch 18, Val Loss: 5.58309
Epoch 19, Val Loss: 5.11943
Epoch 20, Val Loss: 5.16696
Epoch 21, Val Loss: 5.32807
Epoch 22, Val Loss: 5.47529
Epoch 23, Val Loss: 5.07615
Epoch 24, Val Loss: 5.04192
Epoch 25, Val Loss: 4.99967
Epoch 26, Val Loss: 5.18159
Epoch 27, Val Loss: 5.05762
Epoch 28, Val Loss: 5.58440
Epoch 29, Val Loss: 5.05969
Epoch 30, Val Loss: 4.91606
Epoch 31, Val Loss: 5.00010
Epoch 32, Val Loss: 4.94647
Epoch 33, Val Loss: 4.97069
Epoch 34, Val Loss: 4.99349
Epoch 35, Val Loss: 5.16880
Epoch 36, Val Loss: 5.23963
Epoch 37, Val Loss: 4.92603
Epoch 38, Val Loss: 4.90711
Epoch 39, Val Loss: 4.94330
Epoch 40, Val Loss: 4.87008
Epoch 41, Val Loss: 4.84276
Epoch 42, Val Loss: 4.85531
Epoch 43, Val Loss: 5.12951
Epoch 44, Val Loss: 4.84742
Epoch 45, Val Loss: 4.98876
Epoch 46, Val Loss: 4.95668
Epoch 47, Val Loss: 4.87985
Epoch 48, Val Loss: 4.85474
Epoch 49, Val Loss: 4.82448
Epoch 50, Val Loss: 5.03792
Epoch 51, Val Loss: 4.85079
Epoch 52, Val Loss: 5.22402
Epoch 53, Val Loss: 4.79425
Epoch 54, Val Loss: 4.81373
Epoch 55, Val Loss: 5.49666
Epoch 56, Val Loss: 5.11862
Epoch 57, Val Loss: 4.85059
Epoch 58, Val Loss: 4.87201
Epoch 59, Val Loss: 4.80879
Epoch 60, Val Loss: 4.89161
Epoch 61, Val Loss: 4.89524
Epoch 62, Val Loss: 4.87888
Epoch 63, Val Loss: 5.05872
Epoch 64, Val Loss: 4.98191
Epoch 65, Val Loss: 4.78648
Epoch 66, Val Loss: 4.74669
Epoch 67, Val Loss: 5.01414
Epoch 68, Val Loss: 4.98104
Epoch 69, Val Loss: 4.97923
Epoch 70, Val Loss: 4.95032
Epoch 71, Val Loss: 5.08909
Epoch 72, Val Loss: 4.76847
Epoch 73, Val Loss: 4.90348
Epoch 74, Val Loss: 4.77482
Epoch 75, Val Loss: 4.92588
Epoch 76, Val Loss: 4.72989
Epoch 77, Val Loss: 4.81555
Epoch 78, Val Loss: 5.23445
Epoch 79, Val Loss: 4.82959
Epoch 80, Val Loss: 4.75024
Epoch 81, Val Loss: 4.80144
Epoch 82, Val Loss: 4.94219
Epoch 83, Val Loss: 5.07129
Epoch 84, Val Loss: 4.73168
Epoch 85, Val Loss: 4.87243
Epoch 86, Val Loss: 4.94799
Epoch 87, Val Loss: 4.82075
Epoch 88, Val Loss: 4.89124
Epoch 89, Val Loss: 4.72792
Epoch 90, Val Loss: 4.95256
Epoch 91, Val Loss: 4.73436
Epoch 92, Val Loss: 4.72603
Epoch 93, Val Loss: 4.76375
Epoch 94, Val Loss: 4.91273
Epoch 95, Val Loss: 4.81798
Epoch 96, Val Loss: 4.87928
Epoch 97, Val Loss: 5.18424
Epoch 98, Val Loss: 5.29651
Epoch 99, Val Loss: 4.76550
DID NOT SAVE RESULTS
{'MSE - mean': 4.8178155169576975, 'MSE - std': 0.0, 'R2 - mean': 0.5606311445688374, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.98553
Epoch 1, Val Loss: 13.56577
Epoch 2, Val Loss: 5.65411
Epoch 3, Val Loss: 5.31033
Epoch 4, Val Loss: 5.27045
Epoch 5, Val Loss: 5.21846
Epoch 6, Val Loss: 5.04630
Epoch 7, Val Loss: 4.98323
Epoch 8, Val Loss: 5.03651
Epoch 9, Val Loss: 4.87486
Epoch 10, Val Loss: 4.85029
Epoch 11, Val Loss: 4.89622
Epoch 12, Val Loss: 4.76221
Epoch 13, Val Loss: 4.94301
Epoch 14, Val Loss: 5.09656
Epoch 15, Val Loss: 5.06437
Epoch 16, Val Loss: 4.83365
Epoch 17, Val Loss: 4.54505
Epoch 18, Val Loss: 4.48926
Epoch 19, Val Loss: 4.47741
Epoch 20, Val Loss: 4.52515
Epoch 21, Val Loss: 4.48535
Epoch 22, Val Loss: 4.48750
Epoch 23, Val Loss: 4.41364
Epoch 24, Val Loss: 4.56237
Epoch 25, Val Loss: 4.51420
Epoch 26, Val Loss: 4.54357
Epoch 27, Val Loss: 4.24679
Epoch 28, Val Loss: 4.24118
Epoch 29, Val Loss: 4.22764
Epoch 30, Val Loss: 4.38717
Epoch 31, Val Loss: 4.27785
Epoch 32, Val Loss: 4.24190
Epoch 33, Val Loss: 4.20773
Epoch 34, Val Loss: 4.55476
Epoch 35, Val Loss: 4.86323
Epoch 36, Val Loss: 4.21009
Epoch 37, Val Loss: 4.19272
Epoch 38, Val Loss: 4.22550
Epoch 39, Val Loss: 4.28935
Epoch 40, Val Loss: 4.31316
Epoch 41, Val Loss: 4.30842
Epoch 42, Val Loss: 4.16734
Epoch 43, Val Loss: 4.08611
Epoch 44, Val Loss: 4.30741
Epoch 45, Val Loss: 4.21809
Epoch 46, Val Loss: 4.22870
Epoch 47, Val Loss: 4.10496
Epoch 48, Val Loss: 4.61445
Epoch 49, Val Loss: 4.24774
Epoch 50, Val Loss: 4.13626
Epoch 51, Val Loss: 4.24848
Epoch 52, Val Loss: 4.10401
Epoch 53, Val Loss: 4.23446
Epoch 54, Val Loss: 4.39887
Epoch 55, Val Loss: 4.63174
Epoch 56, Val Loss: 4.37549
Epoch 57, Val Loss: 4.20092
Epoch 58, Val Loss: 4.07558
Epoch 59, Val Loss: 4.24988
Epoch 60, Val Loss: 4.21104
Epoch 61, Val Loss: 5.06956
Epoch 62, Val Loss: 4.08701
Epoch 63, Val Loss: 4.48511
Epoch 64, Val Loss: 4.17043
Epoch 65, Val Loss: 4.18755
Epoch 66, Val Loss: 4.13285
Epoch 67, Val Loss: 4.17909
Epoch 68, Val Loss: 4.04924
Epoch 69, Val Loss: 4.14838
Epoch 70, Val Loss: 4.04862
Epoch 71, Val Loss: 4.57397
Epoch 72, Val Loss: 4.09549
Epoch 73, Val Loss: 4.63966
Epoch 74, Val Loss: 4.40146
Epoch 75, Val Loss: 4.18199
Epoch 76, Val Loss: 4.33630
Epoch 77, Val Loss: 4.53244
Epoch 78, Val Loss: 4.21573
Epoch 79, Val Loss: 4.11086
Epoch 80, Val Loss: 4.30465
Epoch 81, Val Loss: 4.15227
Epoch 82, Val Loss: 4.05793
Epoch 83, Val Loss: 4.24248
Epoch 84, Val Loss: 4.40079
Epoch 85, Val Loss: 4.08083
Epoch 86, Val Loss: 4.37048
Epoch 87, Val Loss: 4.29761
Epoch 88, Val Loss: 4.17112
Epoch 89, Val Loss: 4.25390
Epoch 90, Val Loss: 4.20335
Epoch 91, Val Loss: 4.25559
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.499877916459141, 'MSE - std': 0.3179376004985559, 'R2 - mean': 0.5574253384658598, 'R2 - std': 0.003205806102977604} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.05585
Epoch 1, Val Loss: 9.87428
Epoch 2, Val Loss: 6.25186
Epoch 3, Val Loss: 6.16762
Epoch 4, Val Loss: 6.20168
Epoch 5, Val Loss: 6.15623
Epoch 6, Val Loss: 6.33604
Epoch 7, Val Loss: 6.16319
Epoch 8, Val Loss: 5.92492
Epoch 9, Val Loss: 5.97128
Epoch 10, Val Loss: 5.98930
Epoch 11, Val Loss: 5.80654
Epoch 12, Val Loss: 5.72891
Epoch 13, Val Loss: 5.88174
Epoch 14, Val Loss: 5.86606
Epoch 15, Val Loss: 6.25405
Epoch 16, Val Loss: 5.64864
Epoch 17, Val Loss: 5.61398
Epoch 18, Val Loss: 5.81632
Epoch 19, Val Loss: 5.62147
Epoch 20, Val Loss: 5.47118
Epoch 21, Val Loss: 5.76534
Epoch 22, Val Loss: 5.45995
Epoch 23, Val Loss: 5.80141
Epoch 24, Val Loss: 5.52900
Epoch 25, Val Loss: 5.73214
Epoch 26, Val Loss: 5.52292
Epoch 27, Val Loss: 5.38684
Epoch 28, Val Loss: 5.27250
Epoch 29, Val Loss: 5.50459
Epoch 30, Val Loss: 5.17254
Epoch 31, Val Loss: 5.41646
Epoch 32, Val Loss: 5.44854
Epoch 33, Val Loss: 5.07098
Epoch 34, Val Loss: 5.31648
Epoch 35, Val Loss: 5.00964
Epoch 36, Val Loss: 5.21858
Epoch 37, Val Loss: 5.13110
Epoch 38, Val Loss: 5.05939
Epoch 39, Val Loss: 5.42690
Epoch 40, Val Loss: 4.92791
Epoch 41, Val Loss: 5.22317
Epoch 42, Val Loss: 5.00577
Epoch 43, Val Loss: 4.92379
Epoch 44, Val Loss: 5.01405
Epoch 45, Val Loss: 5.22922
Epoch 46, Val Loss: 4.97512
Epoch 47, Val Loss: 4.77161
Epoch 48, Val Loss: 4.91697
Epoch 49, Val Loss: 4.75943
Epoch 50, Val Loss: 5.05318
Epoch 51, Val Loss: 5.13556
Epoch 52, Val Loss: 5.11911
Epoch 53, Val Loss: 6.00752
Epoch 54, Val Loss: 5.05251
Epoch 55, Val Loss: 5.02588
Epoch 56, Val Loss: 4.67588
Epoch 57, Val Loss: 4.77549
Epoch 58, Val Loss: 4.78992
Epoch 59, Val Loss: 4.81201
Epoch 60, Val Loss: 4.78952
Epoch 61, Val Loss: 4.80680
Epoch 62, Val Loss: 4.70253
Epoch 63, Val Loss: 4.84294
Epoch 64, Val Loss: 4.80538
Epoch 65, Val Loss: 4.93905
Epoch 66, Val Loss: 4.69717
Epoch 67, Val Loss: 4.81952
Epoch 68, Val Loss: 4.86420
Epoch 69, Val Loss: 5.05273
Epoch 70, Val Loss: 4.70970
Epoch 71, Val Loss: 4.75250
Epoch 72, Val Loss: 4.77696
Epoch 73, Val Loss: 4.96294
Epoch 74, Val Loss: 4.55912
Epoch 75, Val Loss: 5.02491
Epoch 76, Val Loss: 4.82118
Epoch 77, Val Loss: 4.71555
Epoch 78, Val Loss: 4.80158
Epoch 79, Val Loss: 4.79655
Epoch 80, Val Loss: 4.91623
Epoch 81, Val Loss: 4.72689
Epoch 82, Val Loss: 4.60491
Epoch 83, Val Loss: 4.74233
Epoch 84, Val Loss: 4.72680
Epoch 85, Val Loss: 4.75446
Epoch 86, Val Loss: 4.88850
Epoch 87, Val Loss: 4.58339
Epoch 88, Val Loss: 4.87755
Epoch 89, Val Loss: 4.70798
Epoch 90, Val Loss: 4.54240
Epoch 91, Val Loss: 4.82025
Epoch 92, Val Loss: 4.68838
Epoch 93, Val Loss: 4.61747
Epoch 94, Val Loss: 4.68208
Epoch 95, Val Loss: 4.65875
Epoch 96, Val Loss: 4.57364
Epoch 97, Val Loss: 4.53823
Epoch 98, Val Loss: 4.77200
Epoch 99, Val Loss: 4.83280
DID NOT SAVE RESULTS
{'MSE - mean': 4.549511831885977, 'MSE - std': 0.2689174526288368, 'R2 - mean': 0.5524722772746643, 'R2 - std': 0.007477773209588957} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.44206
Epoch 1, Val Loss: 9.86795
Epoch 2, Val Loss: 5.33010
Epoch 3, Val Loss: 5.18222
Epoch 4, Val Loss: 5.08593
Epoch 5, Val Loss: 4.96318
Epoch 6, Val Loss: 4.86866
Epoch 7, Val Loss: 4.96304
Epoch 8, Val Loss: 4.87010
Epoch 9, Val Loss: 4.57322
Epoch 10, Val Loss: 4.60236
Epoch 11, Val Loss: 4.71895
Epoch 12, Val Loss: 4.75617
Epoch 13, Val Loss: 4.49577
Epoch 14, Val Loss: 4.33558
Epoch 15, Val Loss: 4.57991
Epoch 16, Val Loss: 4.38398
Epoch 17, Val Loss: 4.46044
Epoch 18, Val Loss: 4.40042
Epoch 19, Val Loss: 4.30296
Epoch 20, Val Loss: 4.31063
Epoch 21, Val Loss: 4.20572
Epoch 22, Val Loss: 5.13487
Epoch 23, Val Loss: 4.27689
Epoch 24, Val Loss: 4.39953
Epoch 25, Val Loss: 4.24310
Epoch 26, Val Loss: 4.11993
Epoch 27, Val Loss: 4.91471
Epoch 28, Val Loss: 4.38329
Epoch 29, Val Loss: 4.17110
Epoch 30, Val Loss: 4.12953
Epoch 31, Val Loss: 4.62104
Epoch 32, Val Loss: 4.08772
Epoch 33, Val Loss: 4.15924
Epoch 34, Val Loss: 4.05461
Epoch 35, Val Loss: 4.10245
Epoch 36, Val Loss: 4.12186
Epoch 37, Val Loss: 4.23817
Epoch 38, Val Loss: 4.07324
Epoch 39, Val Loss: 4.18380
Epoch 40, Val Loss: 4.33852
Epoch 41, Val Loss: 4.05791
Epoch 42, Val Loss: 4.27781
Epoch 43, Val Loss: 4.13057
Epoch 44, Val Loss: 4.09657
Epoch 45, Val Loss: 4.07513
Epoch 46, Val Loss: 3.99780
Epoch 47, Val Loss: 4.07588
Epoch 48, Val Loss: 4.04013
Epoch 49, Val Loss: 4.03193
Epoch 50, Val Loss: 4.05958
Epoch 51, Val Loss: 4.15561
Epoch 52, Val Loss: 4.01027
Epoch 53, Val Loss: 4.06107
Epoch 54, Val Loss: 4.25379
Epoch 55, Val Loss: 4.13226
Epoch 56, Val Loss: 4.09159
Epoch 57, Val Loss: 4.07925
Epoch 58, Val Loss: 4.29450
Epoch 59, Val Loss: 3.97137
Epoch 60, Val Loss: 3.99961
Epoch 61, Val Loss: 4.08919
Epoch 62, Val Loss: 4.06738
Epoch 63, Val Loss: 4.01952
Epoch 64, Val Loss: 3.96546
Epoch 65, Val Loss: 4.08176
Epoch 66, Val Loss: 4.01263
Epoch 67, Val Loss: 4.10474
Epoch 68, Val Loss: 4.36970
Epoch 69, Val Loss: 4.13600
Epoch 70, Val Loss: 3.94359
Epoch 71, Val Loss: 4.17114
Epoch 72, Val Loss: 3.92783
Epoch 73, Val Loss: 5.67254
Epoch 74, Val Loss: 4.01998
Epoch 75, Val Loss: 4.02009
Epoch 76, Val Loss: 4.03338
Epoch 77, Val Loss: 3.92236
Epoch 78, Val Loss: 4.00182
Epoch 79, Val Loss: 3.98009
Epoch 80, Val Loss: 4.07463
Epoch 81, Val Loss: 4.08827
Epoch 82, Val Loss: 4.26859
Epoch 83, Val Loss: 4.03362
Epoch 84, Val Loss: 4.03667
Epoch 85, Val Loss: 4.40058
Epoch 86, Val Loss: 4.15564
Epoch 87, Val Loss: 4.14787
Epoch 88, Val Loss: 4.02143
Epoch 89, Val Loss: 4.27810
Epoch 90, Val Loss: 4.04854
Epoch 91, Val Loss: 4.10485
Epoch 92, Val Loss: 4.66885
Epoch 93, Val Loss: 4.46007
Epoch 94, Val Loss: 4.58266
Epoch 95, Val Loss: 4.14625
Epoch 96, Val Loss: 3.98488
Epoch 97, Val Loss: 4.15169
Epoch 98, Val Loss: 3.98820
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.47265362461895, 'MSE - std': 0.26825174616242603, 'R2 - mean': 0.5509628970390386, 'R2 - std': 0.006983731468035371} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.22467
Epoch 1, Val Loss: 10.98967
Epoch 2, Val Loss: 8.17820
Epoch 3, Val Loss: 8.45697
Epoch 4, Val Loss: 7.74448
Epoch 5, Val Loss: 7.60840
Epoch 6, Val Loss: 7.60331
Epoch 7, Val Loss: 7.47388
Epoch 8, Val Loss: 7.57147
Epoch 9, Val Loss: 7.36193
Epoch 10, Val Loss: 6.97596
Epoch 11, Val Loss: 7.75364
Epoch 12, Val Loss: 7.00537
Epoch 13, Val Loss: 7.21662
Epoch 14, Val Loss: 7.10422
Epoch 15, Val Loss: 6.91289
Epoch 16, Val Loss: 6.90515
Epoch 17, Val Loss: 6.82128
Epoch 18, Val Loss: 7.00801
Epoch 19, Val Loss: 6.74478
Epoch 20, Val Loss: 6.59985
Epoch 21, Val Loss: 6.63253
Epoch 22, Val Loss: 6.61198
Epoch 23, Val Loss: 6.73069
Epoch 24, Val Loss: 6.62119
Epoch 25, Val Loss: 6.61211
Epoch 26, Val Loss: 7.12521
Epoch 27, Val Loss: 6.80193
Epoch 28, Val Loss: 6.59334
Epoch 29, Val Loss: 6.72643
Epoch 30, Val Loss: 6.79837
Epoch 31, Val Loss: 6.50038
Epoch 32, Val Loss: 6.57657
Epoch 33, Val Loss: 6.65514
Epoch 34, Val Loss: 6.50445
Epoch 35, Val Loss: 6.46963
Epoch 36, Val Loss: 6.58136
Epoch 37, Val Loss: 6.54236
Epoch 38, Val Loss: 6.82167
Epoch 39, Val Loss: 6.74472
Epoch 40, Val Loss: 6.44652
Epoch 41, Val Loss: 6.38564
Epoch 42, Val Loss: 6.80181
Epoch 43, Val Loss: 6.37328
Epoch 44, Val Loss: 6.23461
Epoch 45, Val Loss: 6.56692
Epoch 46, Val Loss: 6.18788
Epoch 47, Val Loss: 6.36408
Epoch 48, Val Loss: 6.46248
Epoch 49, Val Loss: 6.38817
Epoch 50, Val Loss: 6.53327
Epoch 51, Val Loss: 6.21145
Epoch 52, Val Loss: 6.73033
Epoch 53, Val Loss: 6.25849
Epoch 54, Val Loss: 6.21351
Epoch 55, Val Loss: 6.86410
Epoch 56, Val Loss: 6.20607
Epoch 57, Val Loss: 6.31829
Epoch 58, Val Loss: 6.72754
Epoch 59, Val Loss: 6.46726
Epoch 60, Val Loss: 6.23205
Epoch 61, Val Loss: 6.20393
Epoch 62, Val Loss: 6.08604
Epoch 63, Val Loss: 6.12667
Epoch 64, Val Loss: 6.59233
Epoch 65, Val Loss: 6.38331
Epoch 66, Val Loss: 6.06928
Epoch 67, Val Loss: 6.09996
Epoch 68, Val Loss: 6.53848
Epoch 69, Val Loss: 6.17688
Epoch 70, Val Loss: 6.32246
Epoch 71, Val Loss: 6.18816
Epoch 72, Val Loss: 6.02967
Epoch 73, Val Loss: 6.32429
Epoch 74, Val Loss: 6.15444
Epoch 75, Val Loss: 6.14261
Epoch 76, Val Loss: 6.22706
Epoch 77, Val Loss: 6.48527
Epoch 78, Val Loss: 6.12229
Epoch 79, Val Loss: 6.06391
Epoch 80, Val Loss: 6.17097
Epoch 81, Val Loss: 6.75833
Epoch 82, Val Loss: 6.10668
Epoch 83, Val Loss: 6.10434
Epoch 84, Val Loss: 6.38353
Epoch 85, Val Loss: 5.94213
Epoch 86, Val Loss: 6.22668
Epoch 87, Val Loss: 6.11791
Epoch 88, Val Loss: 6.02702
Epoch 89, Val Loss: 6.21958
Epoch 90, Val Loss: 6.30221
Epoch 91, Val Loss: 6.20151
Epoch 92, Val Loss: 6.21548
Epoch 93, Val Loss: 5.97294
Epoch 94, Val Loss: 6.04862
Epoch 95, Val Loss: 5.96019
Epoch 96, Val Loss: 6.15177
Epoch 97, Val Loss: 6.02923
Epoch 98, Val Loss: 5.95019
Epoch 99, Val Loss: 6.01646
DID NOT SAVE RESULTS
{'MSE - mean': 4.759203093079881, 'MSE - std': 0.6212967012276184, 'R2 - mean': 0.5430953577480759, 'R2 - std': 0.016929580684513914} 
 

Results After CV: {'MSE - mean': 4.759203093079881, 'MSE - std': 0.6212967012276184, 'R2 - mean': 0.5430953577480759, 'R2 - std': 0.016929580684513914}
Train time: 79.69619878119993
Inference time: 0.05672040579993336
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 58 finished with value: 4.759203093079881 and parameters: {'p_m': 0.7393165085990474, 'alpha': 1.4385559091096891, 'K': 10, 'beta': 0.582693715542332}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.04609
Epoch 1, Val Loss: 10.95907
Epoch 2, Val Loss: 6.79917
Epoch 3, Val Loss: 6.55000
Epoch 4, Val Loss: 6.44353
Epoch 5, Val Loss: 6.41120
Epoch 6, Val Loss: 6.29657
Epoch 7, Val Loss: 6.20994
Epoch 8, Val Loss: 6.08444
Epoch 9, Val Loss: 6.19069
Epoch 10, Val Loss: 6.19042
Epoch 11, Val Loss: 6.01944
Epoch 12, Val Loss: 6.00025
Epoch 13, Val Loss: 5.95157
Epoch 14, Val Loss: 6.12380
Epoch 15, Val Loss: 5.79322
Epoch 16, Val Loss: 5.84974
Epoch 17, Val Loss: 5.68050
Epoch 18, Val Loss: 5.76094
Epoch 19, Val Loss: 5.68480
Epoch 20, Val Loss: 5.75362
Epoch 21, Val Loss: 5.88265
Epoch 22, Val Loss: 5.61207
Epoch 23, Val Loss: 5.58279
Epoch 24, Val Loss: 5.64832
Epoch 25, Val Loss: 5.54287
Epoch 26, Val Loss: 5.39438
Epoch 27, Val Loss: 5.35790
Epoch 28, Val Loss: 6.08089
Epoch 29, Val Loss: 5.72107
Epoch 30, Val Loss: 5.32082
Epoch 31, Val Loss: 5.25806
Epoch 32, Val Loss: 5.33986
Epoch 33, Val Loss: 5.19404
Epoch 34, Val Loss: 5.14773
Epoch 35, Val Loss: 5.25872
Epoch 36, Val Loss: 5.22870
Epoch 37, Val Loss: 5.14766
Epoch 38, Val Loss: 5.79684
Epoch 39, Val Loss: 5.12455
Epoch 40, Val Loss: 4.93314
Epoch 41, Val Loss: 5.11515
Epoch 42, Val Loss: 5.09370
Epoch 43, Val Loss: 5.06370
Epoch 44, Val Loss: 5.14773
Epoch 45, Val Loss: 5.02086
Epoch 46, Val Loss: 5.08101
Epoch 47, Val Loss: 5.29826
Epoch 48, Val Loss: 5.24292
Epoch 49, Val Loss: 4.97384
Epoch 50, Val Loss: 5.20399
Epoch 51, Val Loss: 5.32117
Epoch 52, Val Loss: 5.05564
Epoch 53, Val Loss: 5.76788
Epoch 54, Val Loss: 4.89714
Epoch 55, Val Loss: 5.03911
Epoch 56, Val Loss: 5.04012
Epoch 57, Val Loss: 5.10839
Epoch 58, Val Loss: 5.24669
Epoch 59, Val Loss: 5.22582
Epoch 60, Val Loss: 5.13118
Epoch 61, Val Loss: 4.88248
Epoch 62, Val Loss: 4.91117
Epoch 63, Val Loss: 5.07284
Epoch 64, Val Loss: 5.02976
Epoch 65, Val Loss: 4.96966
Epoch 66, Val Loss: 4.82082
Epoch 67, Val Loss: 5.00152
Epoch 68, Val Loss: 5.12166
Epoch 69, Val Loss: 4.95099
Epoch 70, Val Loss: 5.04915
Epoch 71, Val Loss: 4.96958
Epoch 72, Val Loss: 4.92249
Epoch 73, Val Loss: 4.86742
Epoch 74, Val Loss: 5.11718
Epoch 75, Val Loss: 5.29610
Epoch 76, Val Loss: 5.21818
Epoch 77, Val Loss: 5.24553
Epoch 78, Val Loss: 5.31251
Epoch 79, Val Loss: 4.94501
Epoch 80, Val Loss: 4.97139
Epoch 81, Val Loss: 4.89620
Epoch 82, Val Loss: 4.98153
Epoch 83, Val Loss: 4.99125
Epoch 84, Val Loss: 4.91493
Epoch 85, Val Loss: 5.09814
Epoch 86, Val Loss: 4.90638
Epoch 87, Val Loss: 5.08022
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 5.005417187351722, 'MSE - std': 0.0, 'R2 - mean': 0.5435224921291844, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 22.13697
Epoch 1, Val Loss: 8.13996
Epoch 2, Val Loss: 5.65199
Epoch 3, Val Loss: 5.65280
Epoch 4, Val Loss: 5.27392
Epoch 5, Val Loss: 5.06399
Epoch 6, Val Loss: 5.21582
Epoch 7, Val Loss: 5.00261
Epoch 8, Val Loss: 5.13851
Epoch 9, Val Loss: 4.85452
Epoch 10, Val Loss: 4.77953
Epoch 11, Val Loss: 4.82795
Epoch 12, Val Loss: 4.70686
Epoch 13, Val Loss: 4.67119
Epoch 14, Val Loss: 4.72604
Epoch 15, Val Loss: 4.87535
Epoch 16, Val Loss: 4.52110
Epoch 17, Val Loss: 4.51775
Epoch 18, Val Loss: 4.53670
Epoch 19, Val Loss: 4.53585
Epoch 20, Val Loss: 4.62347
Epoch 21, Val Loss: 4.54476
Epoch 22, Val Loss: 4.81430
Epoch 23, Val Loss: 4.37682
Epoch 24, Val Loss: 4.68439
Epoch 25, Val Loss: 4.32926
Epoch 26, Val Loss: 4.26557
Epoch 27, Val Loss: 4.28350
Epoch 28, Val Loss: 4.34562
Epoch 29, Val Loss: 4.25443
Epoch 30, Val Loss: 4.30336
Epoch 31, Val Loss: 4.32963
Epoch 32, Val Loss: 4.26541
Epoch 33, Val Loss: 4.20212
Epoch 34, Val Loss: 4.27104
Epoch 35, Val Loss: 4.17339
Epoch 36, Val Loss: 4.17804
Epoch 37, Val Loss: 4.17112
Epoch 38, Val Loss: 4.31716
Epoch 39, Val Loss: 4.12335
Epoch 40, Val Loss: 4.17559
Epoch 41, Val Loss: 4.15550
Epoch 42, Val Loss: 4.11630
Epoch 43, Val Loss: 4.23991
Epoch 44, Val Loss: 4.12402
Epoch 45, Val Loss: 4.28062
Epoch 46, Val Loss: 4.14371
Epoch 47, Val Loss: 4.51321
Epoch 48, Val Loss: 4.23646
Epoch 49, Val Loss: 4.01692
Epoch 50, Val Loss: 4.07233
Epoch 51, Val Loss: 4.04043
Epoch 52, Val Loss: 4.16394
Epoch 53, Val Loss: 4.02944
Epoch 54, Val Loss: 4.36939
Epoch 55, Val Loss: 4.25935
Epoch 56, Val Loss: 4.11500
Epoch 57, Val Loss: 3.98905
Epoch 58, Val Loss: 4.14924
Epoch 59, Val Loss: 4.08565
Epoch 60, Val Loss: 4.07792
Epoch 61, Val Loss: 3.93792
Epoch 62, Val Loss: 4.03920
Epoch 63, Val Loss: 4.13169
Epoch 64, Val Loss: 3.95867
Epoch 65, Val Loss: 3.91833
Epoch 66, Val Loss: 4.01144
Epoch 67, Val Loss: 4.07150
Epoch 68, Val Loss: 4.08794
Epoch 69, Val Loss: 4.07401
Epoch 70, Val Loss: 4.03501
Epoch 71, Val Loss: 3.98344
Epoch 72, Val Loss: 4.01940
Epoch 73, Val Loss: 3.99421
Epoch 74, Val Loss: 4.01697
Epoch 75, Val Loss: 4.46442
Epoch 76, Val Loss: 4.19021
Epoch 77, Val Loss: 4.01474
Epoch 78, Val Loss: 4.18882
Epoch 79, Val Loss: 3.94400
Epoch 80, Val Loss: 3.98665
Epoch 81, Val Loss: 4.07801
Epoch 82, Val Loss: 4.06297
Epoch 83, Val Loss: 4.04605
Epoch 84, Val Loss: 3.97701
Epoch 85, Val Loss: 5.36676
Epoch 86, Val Loss: 3.96801
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.550870903965457, 'MSE - std': 0.45454628338626524, 'R2 - mean': 0.5534341817129113, 'R2 - std': 0.009911689583726901} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.70625
Epoch 1, Val Loss: 13.23467
Epoch 2, Val Loss: 7.41156
Epoch 3, Val Loss: 6.80063
Epoch 4, Val Loss: 6.01720
Epoch 5, Val Loss: 5.87239
Epoch 6, Val Loss: 5.70629
Epoch 7, Val Loss: 5.58284
Epoch 8, Val Loss: 5.47061
Epoch 9, Val Loss: 5.52609
Epoch 10, Val Loss: 5.32356
Epoch 11, Val Loss: 5.33647
Epoch 12, Val Loss: 5.18556
Epoch 13, Val Loss: 5.20252
Epoch 14, Val Loss: 5.13694
Epoch 15, Val Loss: 5.19277
Epoch 16, Val Loss: 5.12971
Epoch 17, Val Loss: 5.03034
Epoch 18, Val Loss: 5.06611
Epoch 19, Val Loss: 5.01624
Epoch 20, Val Loss: 4.93465
Epoch 21, Val Loss: 4.92887
Epoch 22, Val Loss: 4.94788
Epoch 23, Val Loss: 5.28778
Epoch 24, Val Loss: 4.88177
Epoch 25, Val Loss: 4.93046
Epoch 26, Val Loss: 4.84344
Epoch 27, Val Loss: 4.90516
Epoch 28, Val Loss: 4.80610
Epoch 29, Val Loss: 4.75506
Epoch 30, Val Loss: 4.82005
Epoch 31, Val Loss: 4.69213
Epoch 32, Val Loss: 4.84173
Epoch 33, Val Loss: 4.76163
Epoch 34, Val Loss: 4.65842
Epoch 35, Val Loss: 4.72066
Epoch 36, Val Loss: 4.71478
Epoch 37, Val Loss: 4.62510
Epoch 38, Val Loss: 4.61661
Epoch 39, Val Loss: 4.69574
Epoch 40, Val Loss: 4.75570
Epoch 41, Val Loss: 4.64965
Epoch 42, Val Loss: 4.59144
Epoch 43, Val Loss: 4.61186
Epoch 44, Val Loss: 4.62686
Epoch 45, Val Loss: 4.63359
Epoch 46, Val Loss: 4.56891
Epoch 47, Val Loss: 4.64388
Epoch 48, Val Loss: 4.67771
Epoch 49, Val Loss: 4.52180
Epoch 50, Val Loss: 4.55959
Epoch 51, Val Loss: 4.52042
Epoch 52, Val Loss: 4.54249
Epoch 53, Val Loss: 4.94080
Epoch 54, Val Loss: 4.53013
Epoch 55, Val Loss: 4.55707
Epoch 56, Val Loss: 4.57408
Epoch 57, Val Loss: 4.68963
Epoch 58, Val Loss: 4.57939
Epoch 59, Val Loss: 4.53766
Epoch 60, Val Loss: 4.55718
Epoch 61, Val Loss: 4.48290
Epoch 62, Val Loss: 4.49102
Epoch 63, Val Loss: 4.50208
Epoch 64, Val Loss: 4.68272
Epoch 65, Val Loss: 4.65704
Epoch 66, Val Loss: 4.50389
Epoch 67, Val Loss: 4.62028
Epoch 68, Val Loss: 4.51137
Epoch 69, Val Loss: 4.93882
Epoch 70, Val Loss: 4.48596
Epoch 71, Val Loss: 4.68324
Epoch 72, Val Loss: 4.82262
Epoch 73, Val Loss: 4.55292
Epoch 74, Val Loss: 4.53179
Epoch 75, Val Loss: 4.48691
Epoch 76, Val Loss: 4.47680
Epoch 77, Val Loss: 4.70948
Epoch 78, Val Loss: 4.55611
Epoch 79, Val Loss: 4.48899
Epoch 80, Val Loss: 4.45801
Epoch 81, Val Loss: 4.50841
Epoch 82, Val Loss: 4.51619
Epoch 83, Val Loss: 4.42232
Epoch 84, Val Loss: 4.49176
Epoch 85, Val Loss: 4.54131
Epoch 86, Val Loss: 4.42407
Epoch 87, Val Loss: 4.39365
Epoch 88, Val Loss: 4.42070
Epoch 89, Val Loss: 4.84446
Epoch 90, Val Loss: 4.45067
Epoch 91, Val Loss: 4.65164
Epoch 92, Val Loss: 4.43591
Epoch 93, Val Loss: 4.75078
Epoch 94, Val Loss: 4.45426
Epoch 95, Val Loss: 4.49004
Epoch 96, Val Loss: 4.58178
Epoch 97, Val Loss: 4.54834
Epoch 98, Val Loss: 4.55712
Epoch 99, Val Loss: 4.48386
DID NOT SAVE RESULTS
{'MSE - mean': 4.5086200946008, 'MSE - std': 0.37591463252195323, 'R2 - mean': 0.5571802951941489, 'R2 - std': 0.009672700038324105} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 18.97587
Epoch 1, Val Loss: 9.22479
Epoch 2, Val Loss: 5.97456
Epoch 3, Val Loss: 5.50518
Epoch 4, Val Loss: 5.37159
Epoch 5, Val Loss: 5.26355
Epoch 6, Val Loss: 5.30149
Epoch 7, Val Loss: 5.00943
Epoch 8, Val Loss: 4.94700
Epoch 9, Val Loss: 4.93505
Epoch 10, Val Loss: 4.87921
Epoch 11, Val Loss: 4.89581
Epoch 12, Val Loss: 4.78032
Epoch 13, Val Loss: 4.73094
Epoch 14, Val Loss: 4.93267
Epoch 15, Val Loss: 4.69198
Epoch 16, Val Loss: 4.86297
Epoch 17, Val Loss: 4.70228
Epoch 18, Val Loss: 4.59485
Epoch 19, Val Loss: 4.64854
Epoch 20, Val Loss: 4.59024
Epoch 21, Val Loss: 4.77144
Epoch 22, Val Loss: 4.59373
Epoch 23, Val Loss: 4.71101
Epoch 24, Val Loss: 4.48070
Epoch 25, Val Loss: 4.58008
Epoch 26, Val Loss: 4.76479
Epoch 27, Val Loss: 4.59544
Epoch 28, Val Loss: 4.42535
Epoch 29, Val Loss: 4.44077
Epoch 30, Val Loss: 4.61622
Epoch 31, Val Loss: 4.54096
Epoch 32, Val Loss: 4.34511
Epoch 33, Val Loss: 4.34116
Epoch 34, Val Loss: 4.80583
Epoch 35, Val Loss: 4.51971
Epoch 36, Val Loss: 4.36712
Epoch 37, Val Loss: 4.30591
Epoch 38, Val Loss: 4.30579
Epoch 39, Val Loss: 4.23652
Epoch 40, Val Loss: 4.21277
Epoch 41, Val Loss: 4.37813
Epoch 42, Val Loss: 4.63551
Epoch 43, Val Loss: 4.28764
Epoch 44, Val Loss: 4.20053
Epoch 45, Val Loss: 4.46095
Epoch 46, Val Loss: 4.22201
Epoch 47, Val Loss: 4.14258
Epoch 48, Val Loss: 4.21106
Epoch 49, Val Loss: 4.20426
Epoch 50, Val Loss: 4.09618
Epoch 51, Val Loss: 4.17658
Epoch 52, Val Loss: 4.07955
Epoch 53, Val Loss: 4.15816
Epoch 54, Val Loss: 4.06881
Epoch 55, Val Loss: 4.19242
Epoch 56, Val Loss: 4.76816
Epoch 57, Val Loss: 4.05835
Epoch 58, Val Loss: 3.99746
Epoch 59, Val Loss: 4.00723
Epoch 60, Val Loss: 4.38714
Epoch 61, Val Loss: 4.51218
Epoch 62, Val Loss: 4.01545
Epoch 63, Val Loss: 4.41049
Epoch 64, Val Loss: 4.01279
Epoch 65, Val Loss: 4.07093
Epoch 66, Val Loss: 4.06572
Epoch 67, Val Loss: 4.03977
Epoch 68, Val Loss: 4.09388
Epoch 69, Val Loss: 4.24800
Epoch 70, Val Loss: 4.17861
Epoch 71, Val Loss: 4.01066
Epoch 72, Val Loss: 4.18715
Epoch 73, Val Loss: 4.17784
Epoch 74, Val Loss: 4.17832
Epoch 75, Val Loss: 4.06851
Epoch 76, Val Loss: 4.13896
Epoch 77, Val Loss: 3.98278
Epoch 78, Val Loss: 4.13514
Epoch 79, Val Loss: 4.10375
Epoch 80, Val Loss: 3.94592
Epoch 81, Val Loss: 4.02645
Epoch 82, Val Loss: 4.08604
Epoch 83, Val Loss: 3.96832
Epoch 84, Val Loss: 4.07189
Epoch 85, Val Loss: 3.98855
Epoch 86, Val Loss: 3.99045
Epoch 87, Val Loss: 4.11474
Epoch 88, Val Loss: 4.12084
Epoch 89, Val Loss: 4.15110
Epoch 90, Val Loss: 3.94251
Epoch 91, Val Loss: 4.07994
Epoch 92, Val Loss: 3.97050
Epoch 93, Val Loss: 4.10748
Epoch 94, Val Loss: 4.05170
Epoch 95, Val Loss: 4.07113
Epoch 96, Val Loss: 4.05162
Epoch 97, Val Loss: 3.92258
Epoch 98, Val Loss: 4.00707
Epoch 99, Val Loss: 4.07384
DID NOT SAVE RESULTS
{'MSE - mean': 4.428147496944436, 'MSE - std': 0.3541346850123205, 'R2 - mean': 0.555973404271653, 'R2 - std': 0.008633689919145548} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.11100
Epoch 1, Val Loss: 13.18587
Epoch 2, Val Loss: 7.85382
Epoch 3, Val Loss: 7.99024
Epoch 4, Val Loss: 7.88076
Epoch 5, Val Loss: 7.64932
Epoch 6, Val Loss: 7.59640
Epoch 7, Val Loss: 7.51084
Epoch 8, Val Loss: 7.57813
Epoch 9, Val Loss: 7.22737
Epoch 10, Val Loss: 7.20525
Epoch 11, Val Loss: 7.25651
Epoch 12, Val Loss: 7.53875
Epoch 13, Val Loss: 7.02031
Epoch 14, Val Loss: 6.99512
Epoch 15, Val Loss: 7.15126
Epoch 16, Val Loss: 7.05775
Epoch 17, Val Loss: 6.86763
Epoch 18, Val Loss: 6.94981
Epoch 19, Val Loss: 6.84119
Epoch 20, Val Loss: 6.87426
Epoch 21, Val Loss: 6.69264
Epoch 22, Val Loss: 6.73101
Epoch 23, Val Loss: 6.81019
Epoch 24, Val Loss: 7.21212
Epoch 25, Val Loss: 6.78659
Epoch 26, Val Loss: 6.57005
Epoch 27, Val Loss: 6.54059
Epoch 28, Val Loss: 6.88504
Epoch 29, Val Loss: 6.42650
Epoch 30, Val Loss: 6.36047
Epoch 31, Val Loss: 6.40908
Epoch 32, Val Loss: 6.35147
Epoch 33, Val Loss: 6.57490
Epoch 34, Val Loss: 6.73513
Epoch 35, Val Loss: 6.66682
Epoch 36, Val Loss: 6.90238
Epoch 37, Val Loss: 6.43434
Epoch 38, Val Loss: 6.22106
Epoch 39, Val Loss: 6.24613
Epoch 40, Val Loss: 6.18601
Epoch 41, Val Loss: 6.19485
Epoch 42, Val Loss: 6.65654
Epoch 43, Val Loss: 6.08416
Epoch 44, Val Loss: 6.50988
Epoch 45, Val Loss: 6.03971
Epoch 46, Val Loss: 6.07865
Epoch 47, Val Loss: 6.18221
Epoch 48, Val Loss: 5.93941
Epoch 49, Val Loss: 5.97255
Epoch 50, Val Loss: 5.97481
Epoch 51, Val Loss: 6.08383
Epoch 52, Val Loss: 6.06827
Epoch 53, Val Loss: 5.93424
Epoch 54, Val Loss: 6.02957
Epoch 55, Val Loss: 5.93361
Epoch 56, Val Loss: 5.96679
Epoch 57, Val Loss: 5.79996
Epoch 58, Val Loss: 5.78146
Epoch 59, Val Loss: 5.93721
Epoch 60, Val Loss: 5.80297
Epoch 61, Val Loss: 6.03347
Epoch 62, Val Loss: 6.34820
Epoch 63, Val Loss: 5.94879
Epoch 64, Val Loss: 6.10199
Epoch 65, Val Loss: 6.16383
Epoch 66, Val Loss: 5.69942
Epoch 67, Val Loss: 6.39665
Epoch 68, Val Loss: 5.92380
Epoch 69, Val Loss: 5.83716
Epoch 70, Val Loss: 5.76641
Epoch 71, Val Loss: 6.02269
Epoch 72, Val Loss: 5.74421
Epoch 73, Val Loss: 5.82060
Epoch 74, Val Loss: 5.61087
Epoch 75, Val Loss: 5.59502
Epoch 76, Val Loss: 5.81228
Epoch 77, Val Loss: 5.54158
Epoch 78, Val Loss: 5.63777
Epoch 79, Val Loss: 5.76317
Epoch 80, Val Loss: 5.58526
Epoch 81, Val Loss: 6.09992
Epoch 82, Val Loss: 5.62154
Epoch 83, Val Loss: 5.73880
Epoch 84, Val Loss: 5.98880
Epoch 85, Val Loss: 5.85464
Epoch 86, Val Loss: 5.75743
Epoch 87, Val Loss: 5.61086
Epoch 88, Val Loss: 5.78320
Epoch 89, Val Loss: 5.54774
Epoch 90, Val Loss: 5.63111
Epoch 91, Val Loss: 5.96654
Epoch 92, Val Loss: 5.67621
Epoch 93, Val Loss: 5.75544
Epoch 94, Val Loss: 5.85376
Epoch 95, Val Loss: 5.57301
Epoch 96, Val Loss: 5.65071
Epoch 97, Val Loss: 6.17870
Epoch 98, Val Loss: 5.59081
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.651004401076586, 'MSE - std': 0.5467996881678749, 'R2 - mean': 0.5531072470845786, 'R2 - std': 0.00961727141033458} 
 

Results After CV: {'MSE - mean': 4.651004401076586, 'MSE - std': 0.5467996881678749, 'R2 - mean': 0.5531072470845786, 'R2 - std': 0.00961727141033458}
Train time: 95.19787773720017
Inference time: 0.05430337879952276
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 59 finished with value: 4.651004401076586 and parameters: {'p_m': 0.8738350442734926, 'alpha': 0.43833319517107694, 'K': 15, 'beta': 4.116907676039605}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.56902
Epoch 1, Val Loss: 10.48587
Epoch 2, Val Loss: 7.44765
Epoch 3, Val Loss: 6.99747
Epoch 4, Val Loss: 6.81232
Epoch 5, Val Loss: 7.46786
Epoch 6, Val Loss: 6.49989
Epoch 7, Val Loss: 6.34912
Epoch 8, Val Loss: 6.32248
Epoch 9, Val Loss: 5.85509
Epoch 10, Val Loss: 5.65378
Epoch 11, Val Loss: 5.93748
Epoch 12, Val Loss: 5.79049
Epoch 13, Val Loss: 5.46268
Epoch 14, Val Loss: 5.66656
Epoch 15, Val Loss: 5.44293
Epoch 16, Val Loss: 5.28622
Epoch 17, Val Loss: 5.46144
Epoch 18, Val Loss: 5.69124
Epoch 19, Val Loss: 5.85874
Epoch 20, Val Loss: 5.31901
Epoch 21, Val Loss: 5.34619
Epoch 22, Val Loss: 5.20408
Epoch 23, Val Loss: 5.61712
Epoch 24, Val Loss: 5.17474
Epoch 25, Val Loss: 4.89196
Epoch 26, Val Loss: 5.20681
Epoch 27, Val Loss: 4.83904
Epoch 28, Val Loss: 5.21076
Epoch 29, Val Loss: 5.05645
Epoch 30, Val Loss: 4.87920
Epoch 31, Val Loss: 4.89233
Epoch 32, Val Loss: 4.75390
Epoch 33, Val Loss: 5.10663
Epoch 34, Val Loss: 4.65718
Epoch 35, Val Loss: 4.87210
Epoch 36, Val Loss: 4.88803
Epoch 37, Val Loss: 4.85624
Epoch 38, Val Loss: 4.98184
Epoch 39, Val Loss: 4.63930
Epoch 40, Val Loss: 5.46844
Epoch 41, Val Loss: 4.92673
Epoch 42, Val Loss: 4.83347
Epoch 43, Val Loss: 5.24151
Epoch 44, Val Loss: 4.85150
Epoch 45, Val Loss: 4.95010
Epoch 46, Val Loss: 4.73448
Epoch 47, Val Loss: 4.70150
Epoch 48, Val Loss: 4.80640
Epoch 49, Val Loss: 4.73441
Epoch 50, Val Loss: 4.83964
Epoch 51, Val Loss: 4.86082
Epoch 52, Val Loss: 5.06806
Epoch 53, Val Loss: 5.03150
Epoch 54, Val Loss: 4.77367
Epoch 55, Val Loss: 4.61524
Epoch 56, Val Loss: 4.83952
Epoch 57, Val Loss: 4.59102
Epoch 58, Val Loss: 4.66060
Epoch 59, Val Loss: 4.80887
Epoch 60, Val Loss: 4.50561
Epoch 61, Val Loss: 4.57998
Epoch 62, Val Loss: 4.85484
Epoch 63, Val Loss: 4.77303
Epoch 64, Val Loss: 4.60308
Epoch 65, Val Loss: 4.62449
Epoch 66, Val Loss: 4.60573
Epoch 67, Val Loss: 4.60615
Epoch 68, Val Loss: 4.77198
Epoch 69, Val Loss: 4.51317
Epoch 70, Val Loss: 4.71300
Epoch 71, Val Loss: 4.57455
Epoch 72, Val Loss: 4.56795
Epoch 73, Val Loss: 4.69475
Epoch 74, Val Loss: 4.58618
Epoch 75, Val Loss: 5.19662
Epoch 76, Val Loss: 4.76734
Epoch 77, Val Loss: 4.61151
Epoch 78, Val Loss: 4.68242
Epoch 79, Val Loss: 4.58023
Epoch 80, Val Loss: 4.48753
Epoch 81, Val Loss: 4.72577
Epoch 82, Val Loss: 4.84407
Epoch 83, Val Loss: 4.97540
Epoch 84, Val Loss: 4.76466
Epoch 85, Val Loss: 4.57747
Epoch 86, Val Loss: 4.83044
Epoch 87, Val Loss: 4.53046
Epoch 88, Val Loss: 4.58790
Epoch 89, Val Loss: 4.56764
Epoch 90, Val Loss: 5.04401
Epoch 91, Val Loss: 4.52433
Epoch 92, Val Loss: 4.53931
Epoch 93, Val Loss: 4.49497
Epoch 94, Val Loss: 4.81154
Epoch 95, Val Loss: 4.53859
Epoch 96, Val Loss: 4.65993
Epoch 97, Val Loss: 4.68663
Epoch 98, Val Loss: 4.77269
Epoch 99, Val Loss: 5.02785
DID NOT SAVE RESULTS
{'MSE - mean': 4.617628680758764, 'MSE - std': 0.0, 'R2 - mean': 0.5788875225441927, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.18580
Epoch 1, Val Loss: 11.88723
Epoch 2, Val Loss: 5.86477
Epoch 3, Val Loss: 5.63476
Epoch 4, Val Loss: 4.76931
Epoch 5, Val Loss: 4.84661
Epoch 6, Val Loss: 4.52050
Epoch 7, Val Loss: 4.46970
Epoch 8, Val Loss: 4.52955
Epoch 9, Val Loss: 4.42273
Epoch 10, Val Loss: 4.41476
Epoch 11, Val Loss: 4.34639
Epoch 12, Val Loss: 4.35405
Epoch 13, Val Loss: 4.40370
Epoch 14, Val Loss: 4.20858
Epoch 15, Val Loss: 4.30112
Epoch 16, Val Loss: 4.34340
Epoch 17, Val Loss: 4.24379
Epoch 18, Val Loss: 4.39695
Epoch 19, Val Loss: 4.13417
Epoch 20, Val Loss: 4.23005
Epoch 21, Val Loss: 4.23627
Epoch 22, Val Loss: 4.36750
Epoch 23, Val Loss: 4.23309
Epoch 24, Val Loss: 4.35370
Epoch 25, Val Loss: 4.12050
Epoch 26, Val Loss: 4.45085
Epoch 27, Val Loss: 4.55846
Epoch 28, Val Loss: 4.28535
Epoch 29, Val Loss: 4.07889
Epoch 30, Val Loss: 4.02706
Epoch 31, Val Loss: 4.22425
Epoch 32, Val Loss: 4.09890
Epoch 33, Val Loss: 4.20435
Epoch 34, Val Loss: 4.10869
Epoch 35, Val Loss: 4.28105
Epoch 36, Val Loss: 4.30524
Epoch 37, Val Loss: 4.00887
Epoch 38, Val Loss: 4.15775
Epoch 39, Val Loss: 3.99932
Epoch 40, Val Loss: 3.97389
Epoch 41, Val Loss: 3.99802
Epoch 42, Val Loss: 4.00881
Epoch 43, Val Loss: 4.39814
Epoch 44, Val Loss: 4.85195
Epoch 45, Val Loss: 4.27614
Epoch 46, Val Loss: 4.22090
Epoch 47, Val Loss: 4.19353
Epoch 48, Val Loss: 4.06356
Epoch 49, Val Loss: 3.93851
Epoch 50, Val Loss: 4.00085
Epoch 51, Val Loss: 4.05904
Epoch 52, Val Loss: 4.09501
Epoch 53, Val Loss: 4.09651
Epoch 54, Val Loss: 3.99420
Epoch 55, Val Loss: 3.96185
Epoch 56, Val Loss: 3.85076
Epoch 57, Val Loss: 4.11258
Epoch 58, Val Loss: 3.88083
Epoch 59, Val Loss: 4.09703
Epoch 60, Val Loss: 4.15842
Epoch 61, Val Loss: 4.24587
Epoch 62, Val Loss: 3.99105
Epoch 63, Val Loss: 3.91520
Epoch 64, Val Loss: 3.81592
Epoch 65, Val Loss: 4.08866
Epoch 66, Val Loss: 4.02651
Epoch 67, Val Loss: 4.16452
Epoch 68, Val Loss: 3.89656
Epoch 69, Val Loss: 3.97864
Epoch 70, Val Loss: 3.91705
Epoch 71, Val Loss: 3.86818
Epoch 72, Val Loss: 3.84981
Epoch 73, Val Loss: 3.80178
Epoch 74, Val Loss: 3.86021
Epoch 75, Val Loss: 3.98148
Epoch 76, Val Loss: 3.92283
Epoch 77, Val Loss: 3.84624
Epoch 78, Val Loss: 3.93120
Epoch 79, Val Loss: 4.04445
Epoch 80, Val Loss: 4.40204
Epoch 81, Val Loss: 4.07941
Epoch 82, Val Loss: 3.95383
Epoch 83, Val Loss: 3.87527
Epoch 84, Val Loss: 4.49254
Epoch 85, Val Loss: 4.29445
Epoch 86, Val Loss: 3.91767
Epoch 87, Val Loss: 4.17664
Epoch 88, Val Loss: 4.17418
Epoch 89, Val Loss: 3.98031
Epoch 90, Val Loss: 3.86918
Epoch 91, Val Loss: 3.94425
Epoch 92, Val Loss: 4.06067
Epoch 93, Val Loss: 3.84571
Epoch 94, Val Loss: 4.01435
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.308184613787386, 'MSE - std': 0.30944406697137805, 'R2 - mean': 0.5763177603920847, 'R2 - std': 0.002569762152108024} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.47940
Epoch 1, Val Loss: 10.31940
Epoch 2, Val Loss: 7.38433
Epoch 3, Val Loss: 6.38979
Epoch 4, Val Loss: 6.41108
Epoch 5, Val Loss: 5.83371
Epoch 6, Val Loss: 5.81902
Epoch 7, Val Loss: 5.92959
Epoch 8, Val Loss: 5.46362
Epoch 9, Val Loss: 5.55203
Epoch 10, Val Loss: 5.70869
Epoch 11, Val Loss: 5.30367
Epoch 12, Val Loss: 5.23509
Epoch 13, Val Loss: 5.19474
Epoch 14, Val Loss: 5.17838
Epoch 15, Val Loss: 5.17358
Epoch 16, Val Loss: 5.25552
Epoch 17, Val Loss: 5.05275
Epoch 18, Val Loss: 5.09109
Epoch 19, Val Loss: 5.13233
Epoch 20, Val Loss: 5.02691
Epoch 21, Val Loss: 5.01767
Epoch 22, Val Loss: 5.18309
Epoch 23, Val Loss: 5.14017
Epoch 24, Val Loss: 5.00857
Epoch 25, Val Loss: 4.99432
Epoch 26, Val Loss: 5.06419
Epoch 27, Val Loss: 5.14367
Epoch 28, Val Loss: 4.95686
Epoch 29, Val Loss: 5.00996
Epoch 30, Val Loss: 4.97794
Epoch 31, Val Loss: 5.06929
Epoch 32, Val Loss: 4.96545
Epoch 33, Val Loss: 4.85066
Epoch 34, Val Loss: 4.90192
Epoch 35, Val Loss: 4.92239
Epoch 36, Val Loss: 5.01403
Epoch 37, Val Loss: 4.96453
Epoch 38, Val Loss: 5.03701
Epoch 39, Val Loss: 4.83230
Epoch 40, Val Loss: 4.85629
Epoch 41, Val Loss: 5.04907
Epoch 42, Val Loss: 4.86338
Epoch 43, Val Loss: 5.16477
Epoch 44, Val Loss: 4.82971
Epoch 45, Val Loss: 5.05223
Epoch 46, Val Loss: 4.79131
Epoch 47, Val Loss: 4.89744
Epoch 48, Val Loss: 4.87039
Epoch 49, Val Loss: 4.79374
Epoch 50, Val Loss: 5.07761
Epoch 51, Val Loss: 5.06195
Epoch 52, Val Loss: 4.89695
Epoch 53, Val Loss: 4.79354
Epoch 54, Val Loss: 4.81241
Epoch 55, Val Loss: 4.99239
Epoch 56, Val Loss: 4.87925
Epoch 57, Val Loss: 4.84020
Epoch 58, Val Loss: 4.76869
Epoch 59, Val Loss: 4.80499
Epoch 60, Val Loss: 5.41585
Epoch 61, Val Loss: 5.10292
Epoch 62, Val Loss: 5.04559
Epoch 63, Val Loss: 4.83535
Epoch 64, Val Loss: 4.92077
Epoch 65, Val Loss: 5.09380
Epoch 66, Val Loss: 4.75274
Epoch 67, Val Loss: 4.81893
Epoch 68, Val Loss: 4.82212
Epoch 69, Val Loss: 4.78553
Epoch 70, Val Loss: 4.99362
Epoch 71, Val Loss: 4.95506
Epoch 72, Val Loss: 4.83559
Epoch 73, Val Loss: 4.71494
Epoch 74, Val Loss: 4.88507
Epoch 75, Val Loss: 4.66241
Epoch 76, Val Loss: 4.93882
Epoch 77, Val Loss: 4.83215
Epoch 78, Val Loss: 4.70759
Epoch 79, Val Loss: 4.70415
Epoch 80, Val Loss: 4.67339
Epoch 81, Val Loss: 4.90800
Epoch 82, Val Loss: 4.77748
Epoch 83, Val Loss: 5.01115
Epoch 84, Val Loss: 4.69710
Epoch 85, Val Loss: 4.73821
Epoch 86, Val Loss: 4.87456
Epoch 87, Val Loss: 4.73711
Epoch 88, Val Loss: 5.07790
Epoch 89, Val Loss: 4.75831
Epoch 90, Val Loss: 4.75883
Epoch 91, Val Loss: 5.21570
Epoch 92, Val Loss: 4.86116
Epoch 93, Val Loss: 5.09950
Epoch 94, Val Loss: 4.67714
Epoch 95, Val Loss: 4.75320
Epoch 96, Val Loss: 4.85454
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.461555537069891, 'MSE - std': 0.33299004080139416, 'R2 - mean': 0.5611470960307287, 'R2 - std': 0.021556914575346194} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.59740
Epoch 1, Val Loss: 9.98786
Epoch 2, Val Loss: 5.81755
Epoch 3, Val Loss: 5.31369
Epoch 4, Val Loss: 5.42878
Epoch 5, Val Loss: 4.92793
Epoch 6, Val Loss: 4.84147
Epoch 7, Val Loss: 4.77244
Epoch 8, Val Loss: 4.63253
Epoch 9, Val Loss: 4.67541
Epoch 10, Val Loss: 4.87348
Epoch 11, Val Loss: 4.48705
Epoch 12, Val Loss: 4.23097
Epoch 13, Val Loss: 4.45906
Epoch 14, Val Loss: 4.11538
Epoch 15, Val Loss: 4.17417
Epoch 16, Val Loss: 4.07635
Epoch 17, Val Loss: 4.32810
Epoch 18, Val Loss: 4.13874
Epoch 19, Val Loss: 4.73960
Epoch 20, Val Loss: 4.48227
Epoch 21, Val Loss: 4.16929
Epoch 22, Val Loss: 4.15918
Epoch 23, Val Loss: 4.12002
Epoch 24, Val Loss: 4.02931
Epoch 25, Val Loss: 3.94723
Epoch 26, Val Loss: 3.96372
Epoch 27, Val Loss: 3.97389
Epoch 28, Val Loss: 4.16822
Epoch 29, Val Loss: 4.38031
Epoch 30, Val Loss: 4.01643
Epoch 31, Val Loss: 4.14094
Epoch 32, Val Loss: 3.95278
Epoch 33, Val Loss: 3.87640
Epoch 34, Val Loss: 3.90137
Epoch 35, Val Loss: 4.16910
Epoch 36, Val Loss: 3.92221
Epoch 37, Val Loss: 3.95660
Epoch 38, Val Loss: 4.04771
Epoch 39, Val Loss: 4.02978
Epoch 40, Val Loss: 3.87764
Epoch 41, Val Loss: 3.99717
Epoch 42, Val Loss: 3.93191
Epoch 43, Val Loss: 4.38924
Epoch 44, Val Loss: 3.98972
Epoch 45, Val Loss: 4.01774
Epoch 46, Val Loss: 3.96342
Epoch 47, Val Loss: 3.90235
Epoch 48, Val Loss: 3.91631
Epoch 49, Val Loss: 3.96113
Epoch 50, Val Loss: 4.23656
Epoch 51, Val Loss: 3.99640
Epoch 52, Val Loss: 3.94715
Epoch 53, Val Loss: 4.01736
Epoch 54, Val Loss: 3.96004
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.397592321969423, 'MSE - std': 0.308926616063835, 'R2 - mean': 0.5584413549275327, 'R2 - std': 0.019248078586164213} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.90673
Epoch 1, Val Loss: 17.13581
Epoch 2, Val Loss: 7.30347
Epoch 3, Val Loss: 7.10476
Epoch 4, Val Loss: 6.77224
Epoch 5, Val Loss: 7.05910
Epoch 6, Val Loss: 6.59675
Epoch 7, Val Loss: 6.63905
Epoch 8, Val Loss: 6.63254
Epoch 9, Val Loss: 6.83493
Epoch 10, Val Loss: 6.42528
Epoch 11, Val Loss: 6.68856
Epoch 12, Val Loss: 6.64633
Epoch 13, Val Loss: 6.43183
Epoch 14, Val Loss: 6.41389
Epoch 15, Val Loss: 6.48136
Epoch 16, Val Loss: 6.52482
Epoch 17, Val Loss: 6.44993
Epoch 18, Val Loss: 6.36026
Epoch 19, Val Loss: 6.36947
Epoch 20, Val Loss: 6.28671
Epoch 21, Val Loss: 6.63429
Epoch 22, Val Loss: 6.24861
Epoch 23, Val Loss: 6.25866
Epoch 24, Val Loss: 6.30751
Epoch 25, Val Loss: 6.34965
Epoch 26, Val Loss: 6.48477
Epoch 27, Val Loss: 6.29257
Epoch 28, Val Loss: 6.20058
Epoch 29, Val Loss: 6.19271
Epoch 30, Val Loss: 6.47427
Epoch 31, Val Loss: 6.06555
Epoch 32, Val Loss: 6.22729
Epoch 33, Val Loss: 6.04112
Epoch 34, Val Loss: 6.11878
Epoch 35, Val Loss: 6.37225
Epoch 36, Val Loss: 6.15353
Epoch 37, Val Loss: 6.13161
Epoch 38, Val Loss: 6.12590
Epoch 39, Val Loss: 5.97499
Epoch 40, Val Loss: 5.99856
Epoch 41, Val Loss: 5.90080
Epoch 42, Val Loss: 5.76298
Epoch 43, Val Loss: 5.99590
Epoch 44, Val Loss: 5.84876
Epoch 45, Val Loss: 5.96660
Epoch 46, Val Loss: 5.98446
Epoch 47, Val Loss: 5.96434
Epoch 48, Val Loss: 5.91714
Epoch 49, Val Loss: 5.85053
Epoch 50, Val Loss: 5.70411
Epoch 51, Val Loss: 6.02456
Epoch 52, Val Loss: 5.79769
Epoch 53, Val Loss: 6.03074
Epoch 54, Val Loss: 5.98783
Epoch 55, Val Loss: 5.67666
Epoch 56, Val Loss: 5.91431
Epoch 57, Val Loss: 5.76850
Epoch 58, Val Loss: 5.92052
Epoch 59, Val Loss: 5.79431
Epoch 60, Val Loss: 5.92658
Epoch 61, Val Loss: 5.65305
Epoch 62, Val Loss: 5.69195
Epoch 63, Val Loss: 5.56667
Epoch 64, Val Loss: 5.94376
Epoch 65, Val Loss: 5.57657
Epoch 66, Val Loss: 5.93513
Epoch 67, Val Loss: 5.56599
Epoch 68, Val Loss: 5.66455
Epoch 69, Val Loss: 5.72804
Epoch 70, Val Loss: 5.45285
Epoch 71, Val Loss: 5.77978
Epoch 72, Val Loss: 5.55881
Epoch 73, Val Loss: 5.60815
Epoch 74, Val Loss: 5.78015
Epoch 75, Val Loss: 5.58565
Epoch 76, Val Loss: 5.62414
Epoch 77, Val Loss: 5.58308
Epoch 78, Val Loss: 5.56922
Epoch 79, Val Loss: 5.66580
Epoch 80, Val Loss: 5.86416
Epoch 81, Val Loss: 5.50220
Epoch 82, Val Loss: 5.52271
Epoch 83, Val Loss: 5.52509
Epoch 84, Val Loss: 5.53379
Epoch 85, Val Loss: 5.45319
Epoch 86, Val Loss: 5.66164
Epoch 87, Val Loss: 5.59980
Epoch 88, Val Loss: 5.71704
Epoch 89, Val Loss: 5.59456
Epoch 90, Val Loss: 5.57269
Epoch 91, Val Loss: 5.73827
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.584821418614173, 'MSE - std': 0.4653680928165994, 'R2 - mean': 0.5585333967323854, 'R2 - std': 0.017216988998738567} 
 

Results After CV: {'MSE - mean': 4.584821418614173, 'MSE - std': 0.4653680928165994, 'R2 - mean': 0.5585333967323854, 'R2 - std': 0.017216988998738567}
Train time: 24.542985767799472
Inference time: 0.04866558620087744
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 60 finished with value: 4.584821418614173 and parameters: {'p_m': 0.44768451254169794, 'alpha': 2.792708834620306, 'K': 2, 'beta': 0.12675207091847634}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.19923
Epoch 1, Val Loss: 11.01957
Epoch 2, Val Loss: 7.51604
Epoch 3, Val Loss: 7.34685
Epoch 4, Val Loss: 7.16159
Epoch 5, Val Loss: 6.85931
Epoch 6, Val Loss: 6.94638
Epoch 7, Val Loss: 6.54905
Epoch 8, Val Loss: 6.42047
Epoch 9, Val Loss: 6.55206
Epoch 10, Val Loss: 6.46064
Epoch 11, Val Loss: 6.51527
Epoch 12, Val Loss: 6.34484
Epoch 13, Val Loss: 6.30695
Epoch 14, Val Loss: 6.34917
Epoch 15, Val Loss: 6.21253
Epoch 16, Val Loss: 6.10203
Epoch 17, Val Loss: 6.15103
Epoch 18, Val Loss: 5.97413
Epoch 19, Val Loss: 6.16923
Epoch 20, Val Loss: 6.01489
Epoch 21, Val Loss: 5.84629
Epoch 22, Val Loss: 5.82482
Epoch 23, Val Loss: 5.69743
Epoch 24, Val Loss: 5.86911
Epoch 25, Val Loss: 5.75074
Epoch 26, Val Loss: 5.95142
Epoch 27, Val Loss: 5.78803
Epoch 28, Val Loss: 5.88469
Epoch 29, Val Loss: 5.77918
Epoch 30, Val Loss: 5.98831
Epoch 31, Val Loss: 6.11611
Epoch 32, Val Loss: 5.85413
Epoch 33, Val Loss: 5.83217
Epoch 34, Val Loss: 6.07373
Epoch 35, Val Loss: 5.66833
Epoch 36, Val Loss: 6.22274
Epoch 37, Val Loss: 5.60163
Epoch 38, Val Loss: 5.66317
Epoch 39, Val Loss: 5.83694
Epoch 40, Val Loss: 5.56614
Epoch 41, Val Loss: 5.61665
Epoch 42, Val Loss: 5.67405
Epoch 43, Val Loss: 5.39342
Epoch 44, Val Loss: 5.51552
Epoch 45, Val Loss: 6.08308
Epoch 46, Val Loss: 5.62877
Epoch 47, Val Loss: 5.32715
Epoch 48, Val Loss: 5.38104
Epoch 49, Val Loss: 5.44193
Epoch 50, Val Loss: 6.40507
Epoch 51, Val Loss: 5.39636
Epoch 52, Val Loss: 5.41156
Epoch 53, Val Loss: 5.34699
Epoch 54, Val Loss: 6.13969
Epoch 55, Val Loss: 5.42454
Epoch 56, Val Loss: 5.56272
Epoch 57, Val Loss: 5.68259
Epoch 58, Val Loss: 5.16667
Epoch 59, Val Loss: 5.39742
Epoch 60, Val Loss: 5.56717
Epoch 61, Val Loss: 5.31846
Epoch 62, Val Loss: 5.47880
Epoch 63, Val Loss: 5.24374
Epoch 64, Val Loss: 5.31271
Epoch 65, Val Loss: 5.10232
Epoch 66, Val Loss: 5.12998
Epoch 67, Val Loss: 5.01075
Epoch 68, Val Loss: 5.12105
Epoch 69, Val Loss: 5.36220
Epoch 70, Val Loss: 5.20025
Epoch 71, Val Loss: 5.17760
Epoch 72, Val Loss: 5.06624
Epoch 73, Val Loss: 5.04245
Epoch 74, Val Loss: 5.09003
Epoch 75, Val Loss: 5.04687
Epoch 76, Val Loss: 5.15084
Epoch 77, Val Loss: 5.21815
Epoch 78, Val Loss: 5.26857
Epoch 79, Val Loss: 4.99930
Epoch 80, Val Loss: 5.29140
Epoch 81, Val Loss: 5.16050
Epoch 82, Val Loss: 4.86636
Epoch 83, Val Loss: 5.16367
Epoch 84, Val Loss: 5.48763
Epoch 85, Val Loss: 4.91490
Epoch 86, Val Loss: 5.08070
Epoch 87, Val Loss: 4.96563
Epoch 88, Val Loss: 5.08216
Epoch 89, Val Loss: 5.63779
Epoch 90, Val Loss: 4.97221
Epoch 91, Val Loss: 4.96391
Epoch 92, Val Loss: 5.18399
Epoch 93, Val Loss: 5.03387
Epoch 94, Val Loss: 4.75598
Epoch 95, Val Loss: 4.75039
Epoch 96, Val Loss: 4.86291
Epoch 97, Val Loss: 5.28274
Epoch 98, Val Loss: 5.15609
Epoch 99, Val Loss: 4.89832
DID NOT SAVE RESULTS
{'MSE - mean': 4.951064745406217, 'MSE - std': 0.0, 'R2 - mean': 0.5484792552354989, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.56176
Epoch 1, Val Loss: 8.47505
Epoch 2, Val Loss: 5.61469
Epoch 3, Val Loss: 5.18721
Epoch 4, Val Loss: 5.05883
Epoch 5, Val Loss: 5.07205
Epoch 6, Val Loss: 4.86240
Epoch 7, Val Loss: 4.71088
Epoch 8, Val Loss: 4.72084
Epoch 9, Val Loss: 4.49671
Epoch 10, Val Loss: 4.72523
Epoch 11, Val Loss: 4.38104
Epoch 12, Val Loss: 4.46189
Epoch 13, Val Loss: 4.72565
Epoch 14, Val Loss: 4.43795
Epoch 15, Val Loss: 4.31121
Epoch 16, Val Loss: 4.64106
Epoch 17, Val Loss: 4.20378
Epoch 18, Val Loss: 4.17373
Epoch 19, Val Loss: 4.24361
Epoch 20, Val Loss: 4.25190
Epoch 21, Val Loss: 4.36963
Epoch 22, Val Loss: 4.48162
Epoch 23, Val Loss: 4.13383
Epoch 24, Val Loss: 4.42946
Epoch 25, Val Loss: 4.83691
Epoch 26, Val Loss: 4.05946
Epoch 27, Val Loss: 4.06250
Epoch 28, Val Loss: 4.01804
Epoch 29, Val Loss: 4.57506
Epoch 30, Val Loss: 4.63688
Epoch 31, Val Loss: 4.05871
Epoch 32, Val Loss: 3.97277
Epoch 33, Val Loss: 4.02611
Epoch 34, Val Loss: 4.03037
Epoch 35, Val Loss: 4.04118
Epoch 36, Val Loss: 4.13158
Epoch 37, Val Loss: 3.95119
Epoch 38, Val Loss: 4.11807
Epoch 39, Val Loss: 4.23746
Epoch 40, Val Loss: 3.91801
Epoch 41, Val Loss: 4.36430
Epoch 42, Val Loss: 4.04780
Epoch 43, Val Loss: 3.91622
Epoch 44, Val Loss: 3.98631
Epoch 45, Val Loss: 3.93911
Epoch 46, Val Loss: 3.89321
Epoch 47, Val Loss: 3.96982
Epoch 48, Val Loss: 3.93596
Epoch 49, Val Loss: 4.69784
Epoch 50, Val Loss: 4.02945
Epoch 51, Val Loss: 4.06500
Epoch 52, Val Loss: 3.93326
Epoch 53, Val Loss: 4.03910
Epoch 54, Val Loss: 4.16847
Epoch 55, Val Loss: 4.10363
Epoch 56, Val Loss: 3.94096
Epoch 57, Val Loss: 4.04047
Epoch 58, Val Loss: 4.05592
Epoch 59, Val Loss: 4.00560
Epoch 60, Val Loss: 3.92483
Epoch 61, Val Loss: 3.98181
Epoch 62, Val Loss: 4.14017
Epoch 63, Val Loss: 3.93046
Epoch 64, Val Loss: 4.04985
Epoch 65, Val Loss: 3.97605
Epoch 66, Val Loss: 4.11671
Epoch 67, Val Loss: 4.13982
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.529528697553339, 'MSE - std': 0.42153604785287824, 'R2 - mean': 0.5552906773608308, 'R2 - std': 0.006811422125331923} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.18833
Epoch 1, Val Loss: 9.65749
Epoch 2, Val Loss: 6.75942
Epoch 3, Val Loss: 6.36840
Epoch 4, Val Loss: 6.20422
Epoch 5, Val Loss: 5.90710
Epoch 6, Val Loss: 5.95865
Epoch 7, Val Loss: 5.44420
Epoch 8, Val Loss: 5.39731
Epoch 9, Val Loss: 5.32542
Epoch 10, Val Loss: 5.26456
Epoch 11, Val Loss: 5.30721
Epoch 12, Val Loss: 5.29340
Epoch 13, Val Loss: 5.17822
Epoch 14, Val Loss: 5.22986
Epoch 15, Val Loss: 5.23632
Epoch 16, Val Loss: 5.16681
Epoch 17, Val Loss: 5.36680
Epoch 18, Val Loss: 5.39507
Epoch 19, Val Loss: 5.26817
Epoch 20, Val Loss: 5.15122
Epoch 21, Val Loss: 5.53853
Epoch 22, Val Loss: 5.00021
Epoch 23, Val Loss: 4.95687
Epoch 24, Val Loss: 5.44778
Epoch 25, Val Loss: 5.29376
Epoch 26, Val Loss: 5.25529
Epoch 27, Val Loss: 5.70852
Epoch 28, Val Loss: 4.89191
Epoch 29, Val Loss: 4.81813
Epoch 30, Val Loss: 5.00514
Epoch 31, Val Loss: 5.07310
Epoch 32, Val Loss: 4.85680
Epoch 33, Val Loss: 5.01838
Epoch 34, Val Loss: 4.85331
Epoch 35, Val Loss: 5.01788
Epoch 36, Val Loss: 4.86866
Epoch 37, Val Loss: 4.81384
Epoch 38, Val Loss: 5.14327
Epoch 39, Val Loss: 4.79167
Epoch 40, Val Loss: 5.04678
Epoch 41, Val Loss: 5.05068
Epoch 42, Val Loss: 4.86530
Epoch 43, Val Loss: 4.76205
Epoch 44, Val Loss: 4.85858
Epoch 45, Val Loss: 4.83609
Epoch 46, Val Loss: 4.74486
Epoch 47, Val Loss: 4.94626
Epoch 48, Val Loss: 4.75633
Epoch 49, Val Loss: 4.67752
Epoch 50, Val Loss: 4.77611
Epoch 51, Val Loss: 4.70050
Epoch 52, Val Loss: 4.74625
Epoch 53, Val Loss: 4.90189
Epoch 54, Val Loss: 4.79734
Epoch 55, Val Loss: 4.66951
Epoch 56, Val Loss: 4.70340
Epoch 57, Val Loss: 4.75862
Epoch 58, Val Loss: 4.65791
Epoch 59, Val Loss: 4.70048
Epoch 60, Val Loss: 5.06639
Epoch 61, Val Loss: 4.67403
Epoch 62, Val Loss: 4.64921
Epoch 63, Val Loss: 4.58606
Epoch 64, Val Loss: 4.67028
Epoch 65, Val Loss: 4.70601
Epoch 66, Val Loss: 4.85042
Epoch 67, Val Loss: 4.55528
Epoch 68, Val Loss: 4.70557
Epoch 69, Val Loss: 4.70957
Epoch 70, Val Loss: 4.76507
Epoch 71, Val Loss: 5.26974
Epoch 72, Val Loss: 4.68346
Epoch 73, Val Loss: 5.13610
Epoch 74, Val Loss: 4.54319
Epoch 75, Val Loss: 4.91107
Epoch 76, Val Loss: 4.67998
Epoch 77, Val Loss: 4.55109
Epoch 78, Val Loss: 4.55274
Epoch 79, Val Loss: 4.58527
Epoch 80, Val Loss: 4.50866
Epoch 81, Val Loss: 4.51794
Epoch 82, Val Loss: 4.67937
Epoch 83, Val Loss: 4.54870
Epoch 84, Val Loss: 4.97040
Epoch 85, Val Loss: 4.46661
Epoch 86, Val Loss: 4.44885
Epoch 87, Val Loss: 4.97777
Epoch 88, Val Loss: 4.83298
Epoch 89, Val Loss: 4.55818
Epoch 90, Val Loss: 4.39253
Epoch 91, Val Loss: 4.41870
Epoch 92, Val Loss: 4.84625
Epoch 93, Val Loss: 4.85702
Epoch 94, Val Loss: 4.44334
Epoch 95, Val Loss: 4.41607
Epoch 96, Val Loss: 4.43240
Epoch 97, Val Loss: 4.40892
Epoch 98, Val Loss: 4.98994
Epoch 99, Val Loss: 4.69079
DID NOT SAVE RESULTS
{'MSE - mean': 4.5338764811052785, 'MSE - std': 0.3442376594785136, 'R2 - mean': 0.5545327333739226, 'R2 - std': 0.00566385667375932} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 45.55673
Epoch 1, Val Loss: 18.10048
Epoch 2, Val Loss: 6.68597
Epoch 3, Val Loss: 5.96368
Epoch 4, Val Loss: 5.62783
Epoch 5, Val Loss: 5.55955
Epoch 6, Val Loss: 5.29966
Epoch 7, Val Loss: 5.33469
Epoch 8, Val Loss: 5.25169
Epoch 9, Val Loss: 5.39808
Epoch 10, Val Loss: 5.74572
Epoch 11, Val Loss: 5.28332
Epoch 12, Val Loss: 4.98695
Epoch 13, Val Loss: 5.11301
Epoch 14, Val Loss: 4.88865
Epoch 15, Val Loss: 4.87835
Epoch 16, Val Loss: 4.98838
Epoch 17, Val Loss: 4.83091
Epoch 18, Val Loss: 4.85923
Epoch 19, Val Loss: 4.79756
Epoch 20, Val Loss: 5.03476
Epoch 21, Val Loss: 4.77091
Epoch 22, Val Loss: 5.10262
Epoch 23, Val Loss: 4.93193
Epoch 24, Val Loss: 4.94264
Epoch 25, Val Loss: 4.98544
Epoch 26, Val Loss: 4.77549
Epoch 27, Val Loss: 4.50930
Epoch 28, Val Loss: 4.65160
Epoch 29, Val Loss: 4.53260
Epoch 30, Val Loss: 4.49524
Epoch 31, Val Loss: 4.55836
Epoch 32, Val Loss: 4.54242
Epoch 33, Val Loss: 4.71229
Epoch 34, Val Loss: 4.52304
Epoch 35, Val Loss: 4.62156
Epoch 36, Val Loss: 4.67245
Epoch 37, Val Loss: 4.55148
Epoch 38, Val Loss: 4.50365
Epoch 39, Val Loss: 4.38820
Epoch 40, Val Loss: 4.43511
Epoch 41, Val Loss: 4.71198
Epoch 42, Val Loss: 4.44278
Epoch 43, Val Loss: 4.33658
Epoch 44, Val Loss: 4.29462
Epoch 45, Val Loss: 4.23392
Epoch 46, Val Loss: 4.34510
Epoch 47, Val Loss: 4.80286
Epoch 48, Val Loss: 4.55195
Epoch 49, Val Loss: 4.32058
Epoch 50, Val Loss: 4.39692
Epoch 51, Val Loss: 4.60078
Epoch 52, Val Loss: 4.25605
Epoch 53, Val Loss: 4.36416
Epoch 54, Val Loss: 4.46313
Epoch 55, Val Loss: 4.37573
Epoch 56, Val Loss: 4.07945
Epoch 57, Val Loss: 4.17625
Epoch 58, Val Loss: 4.06112
Epoch 59, Val Loss: 4.22365
Epoch 60, Val Loss: 4.03949
Epoch 61, Val Loss: 4.20659
Epoch 62, Val Loss: 4.47954
Epoch 63, Val Loss: 4.02961
Epoch 64, Val Loss: 3.98535
Epoch 65, Val Loss: 4.01855
Epoch 66, Val Loss: 4.02345
Epoch 67, Val Loss: 4.38279
Epoch 68, Val Loss: 4.01474
Epoch 69, Val Loss: 4.47280
Epoch 70, Val Loss: 3.99460
Epoch 71, Val Loss: 4.07230
Epoch 72, Val Loss: 3.98352
Epoch 73, Val Loss: 4.05348
Epoch 74, Val Loss: 3.95977
Epoch 75, Val Loss: 3.88690
Epoch 76, Val Loss: 3.94694
Epoch 77, Val Loss: 4.11906
Epoch 78, Val Loss: 4.29122
Epoch 79, Val Loss: 4.09530
Epoch 80, Val Loss: 4.13385
Epoch 81, Val Loss: 4.03033
Epoch 82, Val Loss: 4.04595
Epoch 83, Val Loss: 4.31846
Epoch 84, Val Loss: 4.54919
Epoch 85, Val Loss: 4.11394
Epoch 86, Val Loss: 3.98076
Epoch 87, Val Loss: 4.08717
Epoch 88, Val Loss: 4.12051
Epoch 89, Val Loss: 4.07527
Epoch 90, Val Loss: 4.07996
Epoch 91, Val Loss: 4.07442
Epoch 92, Val Loss: 4.10982
Epoch 93, Val Loss: 4.57985
Epoch 94, Val Loss: 4.04419
Epoch 95, Val Loss: 4.03254
Epoch 96, Val Loss: 4.01230
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.441563927887753, 'MSE - std': 0.33828907327469127, 'R2 - mean': 0.5545785605531823, 'R2 - std': 0.004905685956799794} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 45.71492
Epoch 1, Val Loss: 23.63688
Epoch 2, Val Loss: 7.90275
Epoch 3, Val Loss: 7.36608
Epoch 4, Val Loss: 7.42905
Epoch 5, Val Loss: 7.29446
Epoch 6, Val Loss: 7.22489
Epoch 7, Val Loss: 7.34425
Epoch 8, Val Loss: 7.09270
Epoch 9, Val Loss: 7.40225
Epoch 10, Val Loss: 7.13426
Epoch 11, Val Loss: 6.96169
Epoch 12, Val Loss: 7.10853
Epoch 13, Val Loss: 6.91340
Epoch 14, Val Loss: 6.90729
Epoch 15, Val Loss: 6.80536
Epoch 16, Val Loss: 7.14448
Epoch 17, Val Loss: 6.98922
Epoch 18, Val Loss: 6.71986
Epoch 19, Val Loss: 7.13218
Epoch 20, Val Loss: 6.79521
Epoch 21, Val Loss: 6.98233
Epoch 22, Val Loss: 6.78554
Epoch 23, Val Loss: 6.56217
Epoch 24, Val Loss: 6.61992
Epoch 25, Val Loss: 6.81861
Epoch 26, Val Loss: 7.20557
Epoch 27, Val Loss: 6.50858
Epoch 28, Val Loss: 7.16536
Epoch 29, Val Loss: 6.55460
Epoch 30, Val Loss: 6.86552
Epoch 31, Val Loss: 6.69687
Epoch 32, Val Loss: 6.94213
Epoch 33, Val Loss: 6.52984
Epoch 34, Val Loss: 6.66970
Epoch 35, Val Loss: 6.49508
Epoch 36, Val Loss: 6.71200
Epoch 37, Val Loss: 6.45414
Epoch 38, Val Loss: 6.25649
Epoch 39, Val Loss: 6.32800
Epoch 40, Val Loss: 6.30230
Epoch 41, Val Loss: 6.56650
Epoch 42, Val Loss: 6.13451
Epoch 43, Val Loss: 6.18071
Epoch 44, Val Loss: 6.45408
Epoch 45, Val Loss: 6.14821
Epoch 46, Val Loss: 6.28135
Epoch 47, Val Loss: 6.82655
Epoch 48, Val Loss: 6.30554
Epoch 49, Val Loss: 6.21933
Epoch 50, Val Loss: 6.21678
Epoch 51, Val Loss: 5.97217
Epoch 52, Val Loss: 6.23054
Epoch 53, Val Loss: 6.07131
Epoch 54, Val Loss: 6.03690
Epoch 55, Val Loss: 6.08863
Epoch 56, Val Loss: 6.49568
Epoch 57, Val Loss: 5.96412
Epoch 58, Val Loss: 6.13516
Epoch 59, Val Loss: 5.99917
Epoch 60, Val Loss: 6.25026
Epoch 61, Val Loss: 6.65628
Epoch 62, Val Loss: 6.14811
Epoch 63, Val Loss: 5.98785
Epoch 64, Val Loss: 6.15472
Epoch 65, Val Loss: 6.25406
Epoch 66, Val Loss: 6.01346
Epoch 67, Val Loss: 6.39470
Epoch 68, Val Loss: 5.95541
Epoch 69, Val Loss: 6.09740
Epoch 70, Val Loss: 5.74078
Epoch 71, Val Loss: 5.79237
Epoch 72, Val Loss: 5.86917
Epoch 73, Val Loss: 5.98589
Epoch 74, Val Loss: 6.15577
Epoch 75, Val Loss: 5.80370
Epoch 76, Val Loss: 5.87530
Epoch 77, Val Loss: 5.72594
Epoch 78, Val Loss: 5.73664
Epoch 79, Val Loss: 5.86911
Epoch 80, Val Loss: 5.64113
Epoch 81, Val Loss: 6.21393
Epoch 82, Val Loss: 5.80108
Epoch 83, Val Loss: 6.40774
Epoch 84, Val Loss: 5.78435
Epoch 85, Val Loss: 5.92289
Epoch 86, Val Loss: 6.03364
Epoch 87, Val Loss: 5.72382
Epoch 88, Val Loss: 5.91294
Epoch 89, Val Loss: 5.78732
Epoch 90, Val Loss: 5.59149
Epoch 91, Val Loss: 5.66324
Epoch 92, Val Loss: 5.62655
Epoch 93, Val Loss: 5.64817
Epoch 94, Val Loss: 5.68405
Epoch 95, Val Loss: 5.78965
Epoch 96, Val Loss: 5.44266
Epoch 97, Val Loss: 5.90292
Epoch 98, Val Loss: 5.47168
Epoch 99, Val Loss: 6.52074
DID NOT SAVE RESULTS
{'MSE - mean': 4.628125626798344, 'MSE - std': 0.48038803865132135, 'R2 - mean': 0.5547710672240901, 'R2 - std': 0.004404638355049148} 
 

Results After CV: {'MSE - mean': 4.628125626798344, 'MSE - std': 0.48038803865132135, 'R2 - mean': 0.5547710672240901, 'R2 - std': 0.004404638355049148}
Train time: 25.914105050200305
Inference time: 0.04852821819986275
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 61 finished with value: 4.628125626798344 and parameters: {'p_m': 0.4361794591892464, 'alpha': 3.053002285100433, 'K': 2, 'beta': 0.280999246604218}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.94519
Epoch 1, Val Loss: 15.02571
Epoch 2, Val Loss: 8.38144
Epoch 3, Val Loss: 7.55467
Epoch 4, Val Loss: 7.02838
Epoch 5, Val Loss: 6.83950
Epoch 6, Val Loss: 6.66931
Epoch 7, Val Loss: 6.85997
Epoch 8, Val Loss: 6.70003
Epoch 9, Val Loss: 6.40920
Epoch 10, Val Loss: 6.22026
Epoch 11, Val Loss: 6.73648
Epoch 12, Val Loss: 6.32747
Epoch 13, Val Loss: 6.53610
Epoch 14, Val Loss: 6.20873
Epoch 15, Val Loss: 6.30159
Epoch 16, Val Loss: 5.90260
Epoch 17, Val Loss: 5.88714
Epoch 18, Val Loss: 5.95159
Epoch 19, Val Loss: 5.74843
Epoch 20, Val Loss: 5.62943
Epoch 21, Val Loss: 5.49801
Epoch 22, Val Loss: 5.44723
Epoch 23, Val Loss: 5.49837
Epoch 24, Val Loss: 5.23334
Epoch 25, Val Loss: 5.25659
Epoch 26, Val Loss: 5.22622
Epoch 27, Val Loss: 5.25337
Epoch 28, Val Loss: 5.15840
Epoch 29, Val Loss: 5.09864
Epoch 30, Val Loss: 5.16059
Epoch 31, Val Loss: 5.31805
Epoch 32, Val Loss: 5.54387
Epoch 33, Val Loss: 5.22832
Epoch 34, Val Loss: 5.20769
Epoch 35, Val Loss: 5.42558
Epoch 36, Val Loss: 5.03512
Epoch 37, Val Loss: 5.19314
Epoch 38, Val Loss: 5.19320
Epoch 39, Val Loss: 5.08002
Epoch 40, Val Loss: 4.93276
Epoch 41, Val Loss: 5.23535
Epoch 42, Val Loss: 5.01062
Epoch 43, Val Loss: 4.93779
Epoch 44, Val Loss: 5.29361
Epoch 45, Val Loss: 5.12753
Epoch 46, Val Loss: 4.84914
Epoch 47, Val Loss: 5.78544
Epoch 48, Val Loss: 5.21699
Epoch 49, Val Loss: 5.37015
Epoch 50, Val Loss: 4.96159
Epoch 51, Val Loss: 4.76753
Epoch 52, Val Loss: 4.97598
Epoch 53, Val Loss: 4.92273
Epoch 54, Val Loss: 5.01775
Epoch 55, Val Loss: 4.79062
Epoch 56, Val Loss: 4.80108
Epoch 57, Val Loss: 4.82100
Epoch 58, Val Loss: 4.76213
Epoch 59, Val Loss: 5.08353
Epoch 60, Val Loss: 4.93867
Epoch 61, Val Loss: 5.09786
Epoch 62, Val Loss: 5.11259
Epoch 63, Val Loss: 4.72840
Epoch 64, Val Loss: 4.55930
Epoch 65, Val Loss: 4.64707
Epoch 66, Val Loss: 4.93206
Epoch 67, Val Loss: 4.95093
Epoch 68, Val Loss: 5.01042
Epoch 69, Val Loss: 4.68793
Epoch 70, Val Loss: 4.68554
Epoch 71, Val Loss: 4.59703
Epoch 72, Val Loss: 5.08246
Epoch 73, Val Loss: 4.88022
Epoch 74, Val Loss: 4.70587
Epoch 75, Val Loss: 4.66546
Epoch 76, Val Loss: 4.68001
Epoch 77, Val Loss: 4.97021
Epoch 78, Val Loss: 4.93190
Epoch 79, Val Loss: 4.72081
Epoch 80, Val Loss: 4.54618
Epoch 81, Val Loss: 4.95587
Epoch 82, Val Loss: 4.73586
Epoch 83, Val Loss: 4.64216
Epoch 84, Val Loss: 4.65411
Epoch 85, Val Loss: 4.53030
Epoch 86, Val Loss: 4.65598
Epoch 87, Val Loss: 4.86006
Epoch 88, Val Loss: 4.71712
Epoch 89, Val Loss: 4.58050
Epoch 90, Val Loss: 5.21535
Epoch 91, Val Loss: 4.55606
Epoch 92, Val Loss: 4.61148
Epoch 93, Val Loss: 4.69650
Epoch 94, Val Loss: 4.51105
Epoch 95, Val Loss: 5.17633
Epoch 96, Val Loss: 4.60928
Epoch 97, Val Loss: 4.60076
Epoch 98, Val Loss: 4.82009
Epoch 99, Val Loss: 4.67069
DID NOT SAVE RESULTS
{'MSE - mean': 4.670786771635926, 'MSE - std': 0.0, 'R2 - mean': 0.5740396803087653, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.13606
Epoch 1, Val Loss: 8.05572
Epoch 2, Val Loss: 5.55091
Epoch 3, Val Loss: 5.27324
Epoch 4, Val Loss: 5.87758
Epoch 5, Val Loss: 5.10480
Epoch 6, Val Loss: 5.15563
Epoch 7, Val Loss: 4.98041
Epoch 8, Val Loss: 5.07155
Epoch 9, Val Loss: 4.93798
Epoch 10, Val Loss: 5.01093
Epoch 11, Val Loss: 4.88986
Epoch 12, Val Loss: 4.92540
Epoch 13, Val Loss: 4.95855
Epoch 14, Val Loss: 5.28678
Epoch 15, Val Loss: 4.93602
Epoch 16, Val Loss: 4.99101
Epoch 17, Val Loss: 4.76854
Epoch 18, Val Loss: 4.80958
Epoch 19, Val Loss: 4.79105
Epoch 20, Val Loss: 4.80186
Epoch 21, Val Loss: 4.83259
Epoch 22, Val Loss: 4.72393
Epoch 23, Val Loss: 5.92559
Epoch 24, Val Loss: 5.23570
Epoch 25, Val Loss: 4.73409
Epoch 26, Val Loss: 4.78565
Epoch 27, Val Loss: 4.98935
Epoch 28, Val Loss: 4.74827
Epoch 29, Val Loss: 4.64436
Epoch 30, Val Loss: 5.15686
Epoch 31, Val Loss: 4.98976
Epoch 32, Val Loss: 5.07236
Epoch 33, Val Loss: 5.33307
Epoch 34, Val Loss: 4.66977
Epoch 35, Val Loss: 4.93531
Epoch 36, Val Loss: 4.65946
Epoch 37, Val Loss: 4.68342
Epoch 38, Val Loss: 4.71872
Epoch 39, Val Loss: 4.78672
Epoch 40, Val Loss: 4.99816
Epoch 41, Val Loss: 4.66610
Epoch 42, Val Loss: 4.72076
Epoch 43, Val Loss: 5.03801
Epoch 44, Val Loss: 4.76461
Epoch 45, Val Loss: 4.76342
Epoch 46, Val Loss: 4.71752
Epoch 47, Val Loss: 4.77139
Epoch 48, Val Loss: 4.68410
Epoch 49, Val Loss: 4.59114
Epoch 50, Val Loss: 5.02531
Epoch 51, Val Loss: 4.58968
Epoch 52, Val Loss: 4.70126
Epoch 53, Val Loss: 4.58867
Epoch 54, Val Loss: 4.70429
Epoch 55, Val Loss: 4.54240
Epoch 56, Val Loss: 4.65065
Epoch 57, Val Loss: 4.75269
Epoch 58, Val Loss: 4.57376
Epoch 59, Val Loss: 4.87328
Epoch 60, Val Loss: 4.47804
Epoch 61, Val Loss: 4.57298
Epoch 62, Val Loss: 4.45844
Epoch 63, Val Loss: 4.59050
Epoch 64, Val Loss: 4.48843
Epoch 65, Val Loss: 4.58353
Epoch 66, Val Loss: 4.44534
Epoch 67, Val Loss: 4.40497
Epoch 68, Val Loss: 4.48789
Epoch 69, Val Loss: 4.44092
Epoch 70, Val Loss: 4.82313
Epoch 71, Val Loss: 4.49510
Epoch 72, Val Loss: 5.14332
Epoch 73, Val Loss: 4.34440
Epoch 74, Val Loss: 4.50822
Epoch 75, Val Loss: 4.54906
Epoch 76, Val Loss: 4.73066
Epoch 77, Val Loss: 4.28479
Epoch 78, Val Loss: 4.50659
Epoch 79, Val Loss: 4.26991
Epoch 80, Val Loss: 4.36204
Epoch 81, Val Loss: 4.30749
Epoch 82, Val Loss: 4.32294
Epoch 83, Val Loss: 4.73032
Epoch 84, Val Loss: 4.46070
Epoch 85, Val Loss: 4.39889
Epoch 86, Val Loss: 4.37726
Epoch 87, Val Loss: 4.35248
Epoch 88, Val Loss: 4.41929
Epoch 89, Val Loss: 4.51388
Epoch 90, Val Loss: 4.38028
Epoch 91, Val Loss: 4.39579
Epoch 92, Val Loss: 4.30671
Epoch 93, Val Loss: 4.52151
Epoch 94, Val Loss: 4.42508
Epoch 95, Val Loss: 4.41150
Epoch 96, Val Loss: 4.61180
Epoch 97, Val Loss: 4.58432
Epoch 98, Val Loss: 4.34008
Epoch 99, Val Loss: 4.26789
DID NOT SAVE RESULTS
{'MSE - mean': 4.495894936583484, 'MSE - std': 0.17489183505244155, 'R2 - mean': 0.556717798789704, 'R2 - std': 0.017321881519061333} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.05817
Epoch 1, Val Loss: 15.07505
Epoch 2, Val Loss: 7.35021
Epoch 3, Val Loss: 6.65203
Epoch 4, Val Loss: 6.25539
Epoch 5, Val Loss: 6.18089
Epoch 6, Val Loss: 5.93680
Epoch 7, Val Loss: 6.00206
Epoch 8, Val Loss: 5.87719
Epoch 9, Val Loss: 6.10214
Epoch 10, Val Loss: 5.74165
Epoch 11, Val Loss: 5.84800
Epoch 12, Val Loss: 5.68088
Epoch 13, Val Loss: 5.89778
Epoch 14, Val Loss: 6.32325
Epoch 15, Val Loss: 5.90984
Epoch 16, Val Loss: 5.94619
Epoch 17, Val Loss: 6.18494
Epoch 18, Val Loss: 5.61521
Epoch 19, Val Loss: 5.66775
Epoch 20, Val Loss: 5.80141
Epoch 21, Val Loss: 5.61213
Epoch 22, Val Loss: 5.57187
Epoch 23, Val Loss: 5.61714
Epoch 24, Val Loss: 5.55201
Epoch 25, Val Loss: 5.78883
Epoch 26, Val Loss: 5.80696
Epoch 27, Val Loss: 5.61614
Epoch 28, Val Loss: 5.43473
Epoch 29, Val Loss: 5.62466
Epoch 30, Val Loss: 5.60574
Epoch 31, Val Loss: 5.46696
Epoch 32, Val Loss: 5.62663
Epoch 33, Val Loss: 6.16025
Epoch 34, Val Loss: 5.44359
Epoch 35, Val Loss: 5.70581
Epoch 36, Val Loss: 5.48692
Epoch 37, Val Loss: 5.45199
Epoch 38, Val Loss: 5.58308
Epoch 39, Val Loss: 5.30094
Epoch 40, Val Loss: 5.28833
Epoch 41, Val Loss: 5.27656
Epoch 42, Val Loss: 5.35028
Epoch 43, Val Loss: 5.53765
Epoch 44, Val Loss: 5.25815
Epoch 45, Val Loss: 5.41313
Epoch 46, Val Loss: 5.20231
Epoch 47, Val Loss: 5.17331
Epoch 48, Val Loss: 5.22440
Epoch 49, Val Loss: 5.46726
Epoch 50, Val Loss: 5.11724
Epoch 51, Val Loss: 5.17365
Epoch 52, Val Loss: 5.16461
Epoch 53, Val Loss: 5.06132
Epoch 54, Val Loss: 5.11881
Epoch 55, Val Loss: 5.08810
Epoch 56, Val Loss: 5.10262
Epoch 57, Val Loss: 5.13271
Epoch 58, Val Loss: 5.24214
Epoch 59, Val Loss: 5.05731
Epoch 60, Val Loss: 4.91755
Epoch 61, Val Loss: 5.53415
Epoch 62, Val Loss: 4.99207
Epoch 63, Val Loss: 4.98231
Epoch 64, Val Loss: 4.93964
Epoch 65, Val Loss: 5.12179
Epoch 66, Val Loss: 4.83849
Epoch 67, Val Loss: 4.93868
Epoch 68, Val Loss: 4.83684
Epoch 69, Val Loss: 4.77527
Epoch 70, Val Loss: 4.76285
Epoch 71, Val Loss: 4.79967
Epoch 72, Val Loss: 4.90084
Epoch 73, Val Loss: 4.78340
Epoch 74, Val Loss: 4.89048
Epoch 75, Val Loss: 4.76771
Epoch 76, Val Loss: 5.05478
Epoch 77, Val Loss: 4.69635
Epoch 78, Val Loss: 4.80278
Epoch 79, Val Loss: 4.74430
Epoch 80, Val Loss: 4.76682
Epoch 81, Val Loss: 4.74425
Epoch 82, Val Loss: 4.78756
Epoch 83, Val Loss: 5.29352
Epoch 84, Val Loss: 4.77428
Epoch 85, Val Loss: 4.69320
Epoch 86, Val Loss: 4.70554
Epoch 87, Val Loss: 4.70306
Epoch 88, Val Loss: 5.20604
Epoch 89, Val Loss: 5.06875
Epoch 90, Val Loss: 5.23317
Epoch 91, Val Loss: 4.57934
Epoch 92, Val Loss: 4.71121
Epoch 93, Val Loss: 5.01762
Epoch 94, Val Loss: 4.84274
Epoch 95, Val Loss: 4.58352
Epoch 96, Val Loss: 4.59341
Epoch 97, Val Loss: 4.77890
Epoch 98, Val Loss: 4.87252
Epoch 99, Val Loss: 4.70024
DID NOT SAVE RESULTS
{'MSE - mean': 4.559993651972758, 'MSE - std': 0.16914114404184385, 'R2 - mean': 0.5507079067447307, 'R2 - std': 0.01650058557621713} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.26081
Epoch 1, Val Loss: 9.38738
Epoch 2, Val Loss: 5.71661
Epoch 3, Val Loss: 5.60806
Epoch 4, Val Loss: 5.92472
Epoch 5, Val Loss: 5.55626
Epoch 6, Val Loss: 5.26522
Epoch 7, Val Loss: 5.18813
Epoch 8, Val Loss: 5.30336
Epoch 9, Val Loss: 5.19316
Epoch 10, Val Loss: 5.16968
Epoch 11, Val Loss: 5.03933
Epoch 12, Val Loss: 5.29103
Epoch 13, Val Loss: 5.04720
Epoch 14, Val Loss: 5.07141
Epoch 15, Val Loss: 4.99339
Epoch 16, Val Loss: 5.30524
Epoch 17, Val Loss: 4.94094
Epoch 18, Val Loss: 4.92761
Epoch 19, Val Loss: 4.95836
Epoch 20, Val Loss: 5.51525
Epoch 21, Val Loss: 5.04905
Epoch 22, Val Loss: 5.03749
Epoch 23, Val Loss: 4.83392
Epoch 24, Val Loss: 4.93047
Epoch 25, Val Loss: 4.82092
Epoch 26, Val Loss: 5.23525
Epoch 27, Val Loss: 4.80304
Epoch 28, Val Loss: 5.13591
Epoch 29, Val Loss: 4.86454
Epoch 30, Val Loss: 4.89495
Epoch 31, Val Loss: 4.96219
Epoch 32, Val Loss: 4.79959
Epoch 33, Val Loss: 4.98956
Epoch 34, Val Loss: 4.69625
Epoch 35, Val Loss: 5.07615
Epoch 36, Val Loss: 4.74775
Epoch 37, Val Loss: 4.70271
Epoch 38, Val Loss: 4.77077
Epoch 39, Val Loss: 4.66501
Epoch 40, Val Loss: 4.75700
Epoch 41, Val Loss: 4.85728
Epoch 42, Val Loss: 4.58813
Epoch 43, Val Loss: 4.74489
Epoch 44, Val Loss: 4.81336
Epoch 45, Val Loss: 4.70603
Epoch 46, Val Loss: 4.68706
Epoch 47, Val Loss: 4.57213
Epoch 48, Val Loss: 4.65678
Epoch 49, Val Loss: 4.85201
Epoch 50, Val Loss: 4.60437
Epoch 51, Val Loss: 4.49358
Epoch 52, Val Loss: 4.64632
Epoch 53, Val Loss: 4.47368
Epoch 54, Val Loss: 4.47823
Epoch 55, Val Loss: 4.58781
Epoch 56, Val Loss: 4.67995
Epoch 57, Val Loss: 4.43734
Epoch 58, Val Loss: 4.53505
Epoch 59, Val Loss: 4.42894
Epoch 60, Val Loss: 4.49791
Epoch 61, Val Loss: 4.44599
Epoch 62, Val Loss: 4.42850
Epoch 63, Val Loss: 4.33799
Epoch 64, Val Loss: 4.58516
Epoch 65, Val Loss: 4.54449
Epoch 66, Val Loss: 4.36664
Epoch 67, Val Loss: 4.37881
Epoch 68, Val Loss: 4.37827
Epoch 69, Val Loss: 4.39694
Epoch 70, Val Loss: 4.18751
Epoch 71, Val Loss: 4.32746
Epoch 72, Val Loss: 4.25706
Epoch 73, Val Loss: 4.21295
Epoch 74, Val Loss: 4.41315
Epoch 75, Val Loss: 4.13143
Epoch 76, Val Loss: 4.56064
Epoch 77, Val Loss: 4.57444
Epoch 78, Val Loss: 4.29054
Epoch 79, Val Loss: 4.40765
Epoch 80, Val Loss: 4.18022
Epoch 81, Val Loss: 4.06581
Epoch 82, Val Loss: 4.13337
Epoch 83, Val Loss: 4.23349
Epoch 84, Val Loss: 4.07002
Epoch 85, Val Loss: 4.12615
Epoch 86, Val Loss: 4.14379
Epoch 87, Val Loss: 4.33044
Epoch 88, Val Loss: 4.12769
Epoch 89, Val Loss: 4.50188
Epoch 90, Val Loss: 4.16335
Epoch 91, Val Loss: 4.36607
Epoch 92, Val Loss: 4.14992
Epoch 93, Val Loss: 4.03625
Epoch 94, Val Loss: 4.04891
Epoch 95, Val Loss: 4.33669
Epoch 96, Val Loss: 4.00399
Epoch 97, Val Loss: 4.00018
Epoch 98, Val Loss: 4.07369
Epoch 99, Val Loss: 4.18285
DID NOT SAVE RESULTS
{'MSE - mean': 4.504444614342776, 'MSE - std': 0.1752530504747048, 'R2 - mean': 0.5470810515071782, 'R2 - std': 0.015609747916319309} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.99213
Epoch 1, Val Loss: 18.24451
Epoch 2, Val Loss: 9.08755
Epoch 3, Val Loss: 7.65667
Epoch 4, Val Loss: 8.41321
Epoch 5, Val Loss: 7.49535
Epoch 6, Val Loss: 7.42299
Epoch 7, Val Loss: 7.28673
Epoch 8, Val Loss: 7.25182
Epoch 9, Val Loss: 7.34413
Epoch 10, Val Loss: 7.39638
Epoch 11, Val Loss: 7.41369
Epoch 12, Val Loss: 7.19620
Epoch 13, Val Loss: 7.15010
Epoch 14, Val Loss: 6.81643
Epoch 15, Val Loss: 6.89271
Epoch 16, Val Loss: 6.89063
Epoch 17, Val Loss: 6.89788
Epoch 18, Val Loss: 7.49960
Epoch 19, Val Loss: 6.83864
Epoch 20, Val Loss: 6.93365
Epoch 21, Val Loss: 6.69596
Epoch 22, Val Loss: 6.62043
Epoch 23, Val Loss: 6.68378
Epoch 24, Val Loss: 7.04782
Epoch 25, Val Loss: 6.85475
Epoch 26, Val Loss: 6.94590
Epoch 27, Val Loss: 7.00411
Epoch 28, Val Loss: 7.17452
Epoch 29, Val Loss: 6.66730
Epoch 30, Val Loss: 6.63524
Epoch 31, Val Loss: 6.63633
Epoch 32, Val Loss: 6.35396
Epoch 33, Val Loss: 6.41337
Epoch 34, Val Loss: 6.53735
Epoch 35, Val Loss: 6.51396
Epoch 36, Val Loss: 6.48769
Epoch 37, Val Loss: 6.58117
Epoch 38, Val Loss: 6.30813
Epoch 39, Val Loss: 6.56664
Epoch 40, Val Loss: 6.52108
Epoch 41, Val Loss: 6.71839
Epoch 42, Val Loss: 6.24133
Epoch 43, Val Loss: 6.30501
Epoch 44, Val Loss: 6.25477
Epoch 45, Val Loss: 6.65504
Epoch 46, Val Loss: 6.26028
Epoch 47, Val Loss: 6.29885
Epoch 48, Val Loss: 6.39972
Epoch 49, Val Loss: 6.29978
Epoch 50, Val Loss: 6.23369
Epoch 51, Val Loss: 6.78277
Epoch 52, Val Loss: 6.60165
Epoch 53, Val Loss: 6.77749
Epoch 54, Val Loss: 6.15482
Epoch 55, Val Loss: 6.36799
Epoch 56, Val Loss: 6.33778
Epoch 57, Val Loss: 6.34013
Epoch 58, Val Loss: 6.93151
Epoch 59, Val Loss: 6.16528
Epoch 60, Val Loss: 6.22252
Epoch 61, Val Loss: 6.17421
Epoch 62, Val Loss: 6.31686
Epoch 63, Val Loss: 6.09195
Epoch 64, Val Loss: 6.00091
Epoch 65, Val Loss: 6.04300
Epoch 66, Val Loss: 6.18732
Epoch 67, Val Loss: 6.04479
Epoch 68, Val Loss: 5.92152
Epoch 69, Val Loss: 6.48417
Epoch 70, Val Loss: 6.69885
Epoch 71, Val Loss: 6.18835
Epoch 72, Val Loss: 6.13783
Epoch 73, Val Loss: 6.32625
Epoch 74, Val Loss: 6.19695
Epoch 75, Val Loss: 7.19305
Epoch 76, Val Loss: 6.19847
Epoch 77, Val Loss: 6.07099
Epoch 78, Val Loss: 6.31474
Epoch 79, Val Loss: 6.13469
Epoch 80, Val Loss: 6.48843
Epoch 81, Val Loss: 6.03682
Epoch 82, Val Loss: 5.94503
Epoch 83, Val Loss: 5.95157
Epoch 84, Val Loss: 5.95240
Epoch 85, Val Loss: 6.16359
Epoch 86, Val Loss: 5.99908
Epoch 87, Val Loss: 6.49547
Epoch 88, Val Loss: 5.96877
Epoch 89, Val Loss: 5.85817
Epoch 90, Val Loss: 5.97512
Epoch 91, Val Loss: 5.96023
Epoch 92, Val Loss: 5.88409
Epoch 93, Val Loss: 6.04085
Epoch 94, Val Loss: 5.83000
Epoch 95, Val Loss: 6.06937
Epoch 96, Val Loss: 6.04423
Epoch 97, Val Loss: 6.07429
Epoch 98, Val Loss: 5.93583
Epoch 99, Val Loss: 6.08325
DID NOT SAVE RESULTS
{'MSE - mean': 4.7623111659576285, 'MSE - std': 0.5390283286873647, 'R2 - mean': 0.541836128542126, 'R2 - std': 0.017463340220191356} 
 

Results After CV: {'MSE - mean': 4.7623111659576285, 'MSE - std': 0.5390283286873647, 'R2 - mean': 0.541836128542126, 'R2 - std': 0.017463340220191356}
Train time: 27.719283059400187
Inference time: 0.047958091001055435
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 62 finished with value: 4.7623111659576285 and parameters: {'p_m': 0.37859019709910124, 'alpha': 2.666746909816665, 'K': 2, 'beta': 0.9779356704211903}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 46.34687
Epoch 1, Val Loss: 17.14986
Epoch 2, Val Loss: 7.33588
Epoch 3, Val Loss: 8.36008
Epoch 4, Val Loss: 7.50975
Epoch 5, Val Loss: 7.14198
Epoch 6, Val Loss: 7.32101
Epoch 7, Val Loss: 7.72634
Epoch 8, Val Loss: 7.49668
Epoch 9, Val Loss: 7.25328
Epoch 10, Val Loss: 7.54439
Epoch 11, Val Loss: 7.19333
Epoch 12, Val Loss: 6.97649
Epoch 13, Val Loss: 7.33406
Epoch 14, Val Loss: 6.87830
Epoch 15, Val Loss: 6.89893
Epoch 16, Val Loss: 6.91985
Epoch 17, Val Loss: 6.45415
Epoch 18, Val Loss: 6.43194
Epoch 19, Val Loss: 6.90515
Epoch 20, Val Loss: 6.34606
Epoch 21, Val Loss: 6.21984
Epoch 22, Val Loss: 6.17360
Epoch 23, Val Loss: 6.09420
Epoch 24, Val Loss: 5.86841
Epoch 25, Val Loss: 5.86057
Epoch 26, Val Loss: 5.85670
Epoch 27, Val Loss: 5.76845
Epoch 28, Val Loss: 5.67745
Epoch 29, Val Loss: 5.72586
Epoch 30, Val Loss: 5.38883
Epoch 31, Val Loss: 5.40809
Epoch 32, Val Loss: 5.22759
Epoch 33, Val Loss: 5.49281
Epoch 34, Val Loss: 5.16232
Epoch 35, Val Loss: 5.16889
Epoch 36, Val Loss: 5.22789
Epoch 37, Val Loss: 5.00315
Epoch 38, Val Loss: 5.16421
Epoch 39, Val Loss: 5.10765
Epoch 40, Val Loss: 5.00015
Epoch 41, Val Loss: 4.99974
Epoch 42, Val Loss: 4.95493
Epoch 43, Val Loss: 5.03601
Epoch 44, Val Loss: 4.93172
Epoch 45, Val Loss: 4.94337
Epoch 46, Val Loss: 4.80458
Epoch 47, Val Loss: 5.01582
Epoch 48, Val Loss: 5.23684
Epoch 49, Val Loss: 4.96326
Epoch 50, Val Loss: 4.87561
Epoch 51, Val Loss: 4.87487
Epoch 52, Val Loss: 5.31044
Epoch 53, Val Loss: 4.89789
Epoch 54, Val Loss: 4.75407
Epoch 55, Val Loss: 4.85782
Epoch 56, Val Loss: 4.81270
Epoch 57, Val Loss: 4.81068
Epoch 58, Val Loss: 5.18636
Epoch 59, Val Loss: 5.22093
Epoch 60, Val Loss: 4.73518
Epoch 61, Val Loss: 4.80285
Epoch 62, Val Loss: 4.66289
Epoch 63, Val Loss: 5.12020
Epoch 64, Val Loss: 4.69698
Epoch 65, Val Loss: 4.82894
Epoch 66, Val Loss: 4.77382
Epoch 67, Val Loss: 4.76603
Epoch 68, Val Loss: 4.77129
Epoch 69, Val Loss: 4.87202
Epoch 70, Val Loss: 4.76427
Epoch 71, Val Loss: 4.81780
Epoch 72, Val Loss: 4.74317
Epoch 73, Val Loss: 4.67320
Epoch 74, Val Loss: 4.72844
Epoch 75, Val Loss: 4.62117
Epoch 76, Val Loss: 4.70057
Epoch 77, Val Loss: 4.73009
Epoch 78, Val Loss: 5.08946
Epoch 79, Val Loss: 4.80930
Epoch 80, Val Loss: 4.85504
Epoch 81, Val Loss: 4.66593
Epoch 82, Val Loss: 5.17183
Epoch 83, Val Loss: 4.87196
Epoch 84, Val Loss: 4.76830
Epoch 85, Val Loss: 4.67733
Epoch 86, Val Loss: 4.62858
Epoch 87, Val Loss: 4.81571
Epoch 88, Val Loss: 4.72123
Epoch 89, Val Loss: 5.01501
Epoch 90, Val Loss: 4.63190
Epoch 91, Val Loss: 4.74087
Epoch 92, Val Loss: 4.64299
Epoch 93, Val Loss: 4.64936
Epoch 94, Val Loss: 4.69041
Epoch 95, Val Loss: 4.65551
Epoch 96, Val Loss: 4.67343
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.7878087248198575, 'MSE - std': 0.0, 'R2 - mean': 0.5633676648590724, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 38.53151
Epoch 1, Val Loss: 17.03119
Epoch 2, Val Loss: 7.46284
Epoch 3, Val Loss: 5.96047
Epoch 4, Val Loss: 5.79459
Epoch 5, Val Loss: 5.77021
Epoch 6, Val Loss: 5.67042
Epoch 7, Val Loss: 5.28368
Epoch 8, Val Loss: 5.43388
Epoch 9, Val Loss: 5.01760
Epoch 10, Val Loss: 4.94719
Epoch 11, Val Loss: 5.08257
Epoch 12, Val Loss: 4.68952
Epoch 13, Val Loss: 4.80235
Epoch 14, Val Loss: 5.45749
Epoch 15, Val Loss: 4.86788
Epoch 16, Val Loss: 4.96388
Epoch 17, Val Loss: 4.59882
Epoch 18, Val Loss: 5.05902
Epoch 19, Val Loss: 4.54068
Epoch 20, Val Loss: 4.44667
Epoch 21, Val Loss: 4.75360
Epoch 22, Val Loss: 4.39841
Epoch 23, Val Loss: 4.42025
Epoch 24, Val Loss: 4.52131
Epoch 25, Val Loss: 4.69462
Epoch 26, Val Loss: 4.53043
Epoch 27, Val Loss: 4.46327
Epoch 28, Val Loss: 4.36567
Epoch 29, Val Loss: 4.69335
Epoch 30, Val Loss: 4.44957
Epoch 31, Val Loss: 4.58002
Epoch 32, Val Loss: 4.44422
Epoch 33, Val Loss: 4.25408
Epoch 34, Val Loss: 4.29698
Epoch 35, Val Loss: 4.43920
Epoch 36, Val Loss: 4.54929
Epoch 37, Val Loss: 4.23161
Epoch 38, Val Loss: 4.50866
Epoch 39, Val Loss: 4.63347
Epoch 40, Val Loss: 4.23130
Epoch 41, Val Loss: 4.21011
Epoch 42, Val Loss: 4.33194
Epoch 43, Val Loss: 4.53726
Epoch 44, Val Loss: 4.28939
Epoch 45, Val Loss: 4.27856
Epoch 46, Val Loss: 4.18030
Epoch 47, Val Loss: 4.18729
Epoch 48, Val Loss: 4.13651
Epoch 49, Val Loss: 4.28370
Epoch 50, Val Loss: 4.09754
Epoch 51, Val Loss: 4.15177
Epoch 52, Val Loss: 4.47207
Epoch 53, Val Loss: 4.10789
Epoch 54, Val Loss: 4.14924
Epoch 55, Val Loss: 4.26700
Epoch 56, Val Loss: 4.45796
Epoch 57, Val Loss: 4.30479
Epoch 58, Val Loss: 4.14559
Epoch 59, Val Loss: 4.16352
Epoch 60, Val Loss: 4.16636
Epoch 61, Val Loss: 4.14264
Epoch 62, Val Loss: 4.05339
Epoch 63, Val Loss: 4.21796
Epoch 64, Val Loss: 4.93040
Epoch 65, Val Loss: 4.30777
Epoch 66, Val Loss: 4.24415
Epoch 67, Val Loss: 4.41742
Epoch 68, Val Loss: 4.05957
Epoch 69, Val Loss: 4.25096
Epoch 70, Val Loss: 4.22094
Epoch 71, Val Loss: 4.25469
Epoch 72, Val Loss: 4.06469
Epoch 73, Val Loss: 4.02805
Epoch 74, Val Loss: 4.02722
Epoch 75, Val Loss: 4.22421
Epoch 76, Val Loss: 4.01686
Epoch 77, Val Loss: 4.34476
Epoch 78, Val Loss: 4.09406
Epoch 79, Val Loss: 4.15315
Epoch 80, Val Loss: 4.11833
Epoch 81, Val Loss: 4.28523
Epoch 82, Val Loss: 4.25593
Epoch 83, Val Loss: 4.24811
Epoch 84, Val Loss: 4.04672
Epoch 85, Val Loss: 4.01265
Epoch 86, Val Loss: 4.38251
Epoch 87, Val Loss: 5.04093
Epoch 88, Val Loss: 4.64782
Epoch 89, Val Loss: 4.21926
Epoch 90, Val Loss: 3.99929
Epoch 91, Val Loss: 4.09690
Epoch 92, Val Loss: 4.06847
Epoch 93, Val Loss: 3.97347
Epoch 94, Val Loss: 4.41478
Epoch 95, Val Loss: 4.15736
Epoch 96, Val Loss: 4.32640
Epoch 97, Val Loss: 4.34644
Epoch 98, Val Loss: 4.39251
Epoch 99, Val Loss: 4.16642
DID NOT SAVE RESULTS
{'MSE - mean': 4.497625788493776, 'MSE - std': 0.29018293632608083, 'R2 - mean': 0.5574343572472317, 'R2 - std': 0.0059333076118407435} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.56424
Epoch 1, Val Loss: 9.86261
Epoch 2, Val Loss: 6.36015
Epoch 3, Val Loss: 6.21817
Epoch 4, Val Loss: 6.03753
Epoch 5, Val Loss: 5.79190
Epoch 6, Val Loss: 5.72868
Epoch 7, Val Loss: 5.64368
Epoch 8, Val Loss: 5.69837
Epoch 9, Val Loss: 5.89791
Epoch 10, Val Loss: 5.56655
Epoch 11, Val Loss: 5.49926
Epoch 12, Val Loss: 5.48022
Epoch 13, Val Loss: 5.58967
Epoch 14, Val Loss: 5.50869
Epoch 15, Val Loss: 5.54176
Epoch 16, Val Loss: 5.27200
Epoch 17, Val Loss: 5.69195
Epoch 18, Val Loss: 5.92450
Epoch 19, Val Loss: 5.58860
Epoch 20, Val Loss: 5.18547
Epoch 21, Val Loss: 5.20815
Epoch 22, Val Loss: 5.32959
Epoch 23, Val Loss: 5.63286
Epoch 24, Val Loss: 5.12680
Epoch 25, Val Loss: 5.14242
Epoch 26, Val Loss: 5.13899
Epoch 27, Val Loss: 5.69627
Epoch 28, Val Loss: 5.23828
Epoch 29, Val Loss: 5.13690
Epoch 30, Val Loss: 5.16255
Epoch 31, Val Loss: 5.12844
Epoch 32, Val Loss: 5.21313
Epoch 33, Val Loss: 5.31795
Epoch 34, Val Loss: 5.08694
Epoch 35, Val Loss: 5.20231
Epoch 36, Val Loss: 5.02003
Epoch 37, Val Loss: 5.09402
Epoch 38, Val Loss: 4.99841
Epoch 39, Val Loss: 5.55464
Epoch 40, Val Loss: 5.30589
Epoch 41, Val Loss: 5.07742
Epoch 42, Val Loss: 4.96664
Epoch 43, Val Loss: 5.63196
Epoch 44, Val Loss: 5.76020
Epoch 45, Val Loss: 5.00799
Epoch 46, Val Loss: 4.91098
Epoch 47, Val Loss: 5.04425
Epoch 48, Val Loss: 4.83910
Epoch 49, Val Loss: 5.11950
Epoch 50, Val Loss: 4.90780
Epoch 51, Val Loss: 5.11776
Epoch 52, Val Loss: 4.89205
Epoch 53, Val Loss: 4.82185
Epoch 54, Val Loss: 4.87115
Epoch 55, Val Loss: 4.87367
Epoch 56, Val Loss: 4.86142
Epoch 57, Val Loss: 5.11363
Epoch 58, Val Loss: 4.87879
Epoch 59, Val Loss: 4.81826
Epoch 60, Val Loss: 4.98928
Epoch 61, Val Loss: 4.85277
Epoch 62, Val Loss: 4.77395
Epoch 63, Val Loss: 4.90575
Epoch 64, Val Loss: 4.79075
Epoch 65, Val Loss: 4.79240
Epoch 66, Val Loss: 4.75825
Epoch 67, Val Loss: 4.71053
Epoch 68, Val Loss: 4.89472
Epoch 69, Val Loss: 4.82729
Epoch 70, Val Loss: 4.69825
Epoch 71, Val Loss: 4.81945
Epoch 72, Val Loss: 4.98513
Epoch 73, Val Loss: 4.83484
Epoch 74, Val Loss: 4.95396
Epoch 75, Val Loss: 4.93859
Epoch 76, Val Loss: 4.84432
Epoch 77, Val Loss: 4.98309
Epoch 78, Val Loss: 4.81552
Epoch 79, Val Loss: 4.71531
Epoch 80, Val Loss: 4.98868
Epoch 81, Val Loss: 4.82535
Epoch 82, Val Loss: 5.00784
Epoch 83, Val Loss: 4.94934
Epoch 84, Val Loss: 4.76039
Epoch 85, Val Loss: 4.83501
Epoch 86, Val Loss: 4.79662
Epoch 87, Val Loss: 5.02420
Epoch 88, Val Loss: 5.02724
Epoch 89, Val Loss: 4.87897
Epoch 90, Val Loss: 5.07698
Epoch 91, Val Loss: 4.79833
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.620827015900005, 'MSE - std': 0.29409948865197516, 'R2 - mean': 0.5453132312301402, 'R2 - std': 0.01781327645294113} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.33098
Epoch 1, Val Loss: 13.13073
Epoch 2, Val Loss: 6.54007
Epoch 3, Val Loss: 7.03267
Epoch 4, Val Loss: 6.12721
Epoch 5, Val Loss: 5.89479
Epoch 6, Val Loss: 6.10813
Epoch 7, Val Loss: 5.86807
Epoch 8, Val Loss: 5.60127
Epoch 9, Val Loss: 5.27159
Epoch 10, Val Loss: 5.13447
Epoch 11, Val Loss: 4.99199
Epoch 12, Val Loss: 5.02242
Epoch 13, Val Loss: 5.09779
Epoch 14, Val Loss: 4.96824
Epoch 15, Val Loss: 4.63497
Epoch 16, Val Loss: 4.70162
Epoch 17, Val Loss: 5.27278
Epoch 18, Val Loss: 5.17170
Epoch 19, Val Loss: 4.49510
Epoch 20, Val Loss: 4.48289
Epoch 21, Val Loss: 4.54412
Epoch 22, Val Loss: 4.92024
Epoch 23, Val Loss: 4.98291
Epoch 24, Val Loss: 4.63435
Epoch 25, Val Loss: 4.71201
Epoch 26, Val Loss: 4.49817
Epoch 27, Val Loss: 4.44560
Epoch 28, Val Loss: 4.42132
Epoch 29, Val Loss: 4.37158
Epoch 30, Val Loss: 4.91272
Epoch 31, Val Loss: 4.48193
Epoch 32, Val Loss: 4.33758
Epoch 33, Val Loss: 4.33442
Epoch 34, Val Loss: 4.96848
Epoch 35, Val Loss: 4.71183
Epoch 36, Val Loss: 4.85160
Epoch 37, Val Loss: 4.71857
Epoch 38, Val Loss: 4.36899
Epoch 39, Val Loss: 4.29856
Epoch 40, Val Loss: 4.28865
Epoch 41, Val Loss: 4.38747
Epoch 42, Val Loss: 4.89980
Epoch 43, Val Loss: 4.41784
Epoch 44, Val Loss: 4.19799
Epoch 45, Val Loss: 4.19991
Epoch 46, Val Loss: 4.44971
Epoch 47, Val Loss: 4.34234
Epoch 48, Val Loss: 4.33261
Epoch 49, Val Loss: 4.25344
Epoch 50, Val Loss: 4.25775
Epoch 51, Val Loss: 4.19985
Epoch 52, Val Loss: 4.76247
Epoch 53, Val Loss: 4.41559
Epoch 54, Val Loss: 4.14731
Epoch 55, Val Loss: 4.25837
Epoch 56, Val Loss: 4.08583
Epoch 57, Val Loss: 4.03534
Epoch 58, Val Loss: 4.34846
Epoch 59, Val Loss: 4.20391
Epoch 60, Val Loss: 4.09513
Epoch 61, Val Loss: 4.22570
Epoch 62, Val Loss: 4.23401
Epoch 63, Val Loss: 4.06087
Epoch 64, Val Loss: 4.16188
Epoch 65, Val Loss: 4.09600
Epoch 66, Val Loss: 4.31598
Epoch 67, Val Loss: 4.08153
Epoch 68, Val Loss: 4.04521
Epoch 69, Val Loss: 4.31574
Epoch 70, Val Loss: 4.12152
Epoch 71, Val Loss: 4.24341
Epoch 72, Val Loss: 4.08587
Epoch 73, Val Loss: 4.10197
Epoch 74, Val Loss: 4.64006
Epoch 75, Val Loss: 4.18124
Epoch 76, Val Loss: 4.20198
Epoch 77, Val Loss: 4.23223
Epoch 78, Val Loss: 4.07907
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.55399775804044, 'MSE - std': 0.2797665652596744, 'R2 - mean': 0.5426150482033378, 'R2 - std': 0.016119093908469353} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 40.96212
Epoch 1, Val Loss: 17.38220
Epoch 2, Val Loss: 8.13687
Epoch 3, Val Loss: 7.94930
Epoch 4, Val Loss: 7.76528
Epoch 5, Val Loss: 7.64669
Epoch 6, Val Loss: 7.60996
Epoch 7, Val Loss: 7.46630
Epoch 8, Val Loss: 7.60826
Epoch 9, Val Loss: 7.39435
Epoch 10, Val Loss: 7.43340
Epoch 11, Val Loss: 7.19783
Epoch 12, Val Loss: 7.32957
Epoch 13, Val Loss: 7.05314
Epoch 14, Val Loss: 7.19975
Epoch 15, Val Loss: 7.14480
Epoch 16, Val Loss: 7.02231
Epoch 17, Val Loss: 6.78607
Epoch 18, Val Loss: 7.04193
Epoch 19, Val Loss: 6.70944
Epoch 20, Val Loss: 6.92729
Epoch 21, Val Loss: 7.15492
Epoch 22, Val Loss: 6.63409
Epoch 23, Val Loss: 7.11592
Epoch 24, Val Loss: 6.51829
Epoch 25, Val Loss: 6.72104
Epoch 26, Val Loss: 6.58479
Epoch 27, Val Loss: 6.85671
Epoch 28, Val Loss: 6.44546
Epoch 29, Val Loss: 6.50612
Epoch 30, Val Loss: 6.70649
Epoch 31, Val Loss: 6.44783
Epoch 32, Val Loss: 6.64881
Epoch 33, Val Loss: 6.88836
Epoch 34, Val Loss: 6.41602
Epoch 35, Val Loss: 6.79810
Epoch 36, Val Loss: 6.49405
Epoch 37, Val Loss: 6.42867
Epoch 38, Val Loss: 6.49057
Epoch 39, Val Loss: 6.28014
Epoch 40, Val Loss: 6.54367
Epoch 41, Val Loss: 6.33899
Epoch 42, Val Loss: 6.48576
Epoch 43, Val Loss: 6.32028
Epoch 44, Val Loss: 6.33830
Epoch 45, Val Loss: 6.51899
Epoch 46, Val Loss: 6.27496
Epoch 47, Val Loss: 6.44974
Epoch 48, Val Loss: 6.42500
Epoch 49, Val Loss: 6.19816
Epoch 50, Val Loss: 6.17042
Epoch 51, Val Loss: 6.11778
Epoch 52, Val Loss: 6.51613
Epoch 53, Val Loss: 6.00483
Epoch 54, Val Loss: 6.08914
Epoch 55, Val Loss: 6.15352
Epoch 56, Val Loss: 6.52773
Epoch 57, Val Loss: 6.22198
Epoch 58, Val Loss: 6.03924
Epoch 59, Val Loss: 6.08453
Epoch 60, Val Loss: 5.93176
Epoch 61, Val Loss: 6.05904
Epoch 62, Val Loss: 6.10291
Epoch 63, Val Loss: 6.10102
Epoch 64, Val Loss: 6.39477
Epoch 65, Val Loss: 6.24139
Epoch 66, Val Loss: 6.02543
Epoch 67, Val Loss: 6.27738
Epoch 68, Val Loss: 6.22785
Epoch 69, Val Loss: 6.27692
Epoch 70, Val Loss: 5.83173
Epoch 71, Val Loss: 5.93267
Epoch 72, Val Loss: 5.93247
Epoch 73, Val Loss: 6.09085
Epoch 74, Val Loss: 6.45276
Epoch 75, Val Loss: 6.09266
Epoch 76, Val Loss: 5.80811
Epoch 77, Val Loss: 5.96473
Epoch 78, Val Loss: 5.92950
Epoch 79, Val Loss: 6.09627
Epoch 80, Val Loss: 5.73871
Epoch 81, Val Loss: 5.82084
Epoch 82, Val Loss: 5.91588
Epoch 83, Val Loss: 5.94795
Epoch 84, Val Loss: 6.20815
Epoch 85, Val Loss: 6.24584
Epoch 86, Val Loss: 5.85020
Epoch 87, Val Loss: 6.01015
Epoch 88, Val Loss: 5.64097
Epoch 89, Val Loss: 5.70496
Epoch 90, Val Loss: 6.23499
Epoch 91, Val Loss: 5.85522
Epoch 92, Val Loss: 5.79556
Epoch 93, Val Loss: 5.82760
Epoch 94, Val Loss: 5.95310
Epoch 95, Val Loss: 5.76927
Epoch 96, Val Loss: 5.52809
Epoch 97, Val Loss: 5.94052
Epoch 98, Val Loss: 5.91246
Epoch 99, Val Loss: 5.64139
DID NOT SAVE RESULTS
{'MSE - mean': 4.752779196749225, 'MSE - std': 0.46975707161286434, 'R2 - mean': 0.54233004024677, 'R2 - std': 0.014428619784486346} 
 

Results After CV: {'MSE - mean': 4.752779196749225, 'MSE - std': 0.46975707161286434, 'R2 - mean': 0.54233004024677, 'R2 - std': 0.014428619784486346}
Train time: 26.08077150599929
Inference time: 0.04636671120024403
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 63 finished with value: 4.752779196749225 and parameters: {'p_m': 0.46600494788184754, 'alpha': 4.268443562777188, 'K': 2, 'beta': 0.184762447185262}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.13905
Epoch 1, Val Loss: 14.99263
Epoch 2, Val Loss: 7.35844
Epoch 3, Val Loss: 7.09311
Epoch 4, Val Loss: 6.99601
Epoch 5, Val Loss: 6.70825
Epoch 6, Val Loss: 6.68965
Epoch 7, Val Loss: 6.84208
Epoch 8, Val Loss: 6.44774
Epoch 9, Val Loss: 6.43152
Epoch 10, Val Loss: 6.68459
Epoch 11, Val Loss: 6.44102
Epoch 12, Val Loss: 6.51229
Epoch 13, Val Loss: 6.36960
Epoch 14, Val Loss: 6.13644
Epoch 15, Val Loss: 6.03861
Epoch 16, Val Loss: 6.18051
Epoch 17, Val Loss: 6.23380
Epoch 18, Val Loss: 5.99089
Epoch 19, Val Loss: 5.91286
Epoch 20, Val Loss: 6.21686
Epoch 21, Val Loss: 5.98338
Epoch 22, Val Loss: 6.24062
Epoch 23, Val Loss: 5.87613
Epoch 24, Val Loss: 6.09706
Epoch 25, Val Loss: 5.92172
Epoch 26, Val Loss: 5.84100
Epoch 27, Val Loss: 5.95443
Epoch 28, Val Loss: 5.88604
Epoch 29, Val Loss: 6.02474
Epoch 30, Val Loss: 5.74911
Epoch 31, Val Loss: 5.67145
Epoch 32, Val Loss: 5.70245
Epoch 33, Val Loss: 5.77310
Epoch 34, Val Loss: 6.17355
Epoch 35, Val Loss: 5.64526
Epoch 36, Val Loss: 5.80692
Epoch 37, Val Loss: 5.65688
Epoch 38, Val Loss: 5.91045
Epoch 39, Val Loss: 5.85919
Epoch 40, Val Loss: 5.54234
Epoch 41, Val Loss: 5.51179
Epoch 42, Val Loss: 5.76654
Epoch 43, Val Loss: 6.18678
Epoch 44, Val Loss: 5.54891
Epoch 45, Val Loss: 5.47613
Epoch 46, Val Loss: 5.72406
Epoch 47, Val Loss: 5.60953
Epoch 48, Val Loss: 5.81777
Epoch 49, Val Loss: 5.39582
Epoch 50, Val Loss: 5.52236
Epoch 51, Val Loss: 5.62024
Epoch 52, Val Loss: 5.78967
Epoch 53, Val Loss: 5.33183
Epoch 54, Val Loss: 5.57225
Epoch 55, Val Loss: 5.55131
Epoch 56, Val Loss: 5.29501
Epoch 57, Val Loss: 5.39453
Epoch 58, Val Loss: 5.38059
Epoch 59, Val Loss: 5.38220
Epoch 60, Val Loss: 5.46911
Epoch 61, Val Loss: 5.43658
Epoch 62, Val Loss: 5.36087
Epoch 63, Val Loss: 5.27771
Epoch 64, Val Loss: 5.61068
Epoch 65, Val Loss: 5.21743
Epoch 66, Val Loss: 5.32825
Epoch 67, Val Loss: 5.18185
Epoch 68, Val Loss: 5.21102
Epoch 69, Val Loss: 5.85460
Epoch 70, Val Loss: 5.26336
Epoch 71, Val Loss: 5.34823
Epoch 72, Val Loss: 5.68859
Epoch 73, Val Loss: 5.10041
Epoch 74, Val Loss: 5.17881
Epoch 75, Val Loss: 5.18772
Epoch 76, Val Loss: 5.24060
Epoch 77, Val Loss: 5.03290
Epoch 78, Val Loss: 5.19058
Epoch 79, Val Loss: 5.61524
Epoch 80, Val Loss: 5.19351
Epoch 81, Val Loss: 5.00882
Epoch 82, Val Loss: 5.06570
Epoch 83, Val Loss: 5.14876
Epoch 84, Val Loss: 5.09989
Epoch 85, Val Loss: 5.14058
Epoch 86, Val Loss: 5.19261
Epoch 87, Val Loss: 5.25725
Epoch 88, Val Loss: 5.51734
Epoch 89, Val Loss: 5.11507
Epoch 90, Val Loss: 5.37269
Epoch 91, Val Loss: 5.76451
Epoch 92, Val Loss: 4.94642
Epoch 93, Val Loss: 4.94601
Epoch 94, Val Loss: 5.46884
Epoch 95, Val Loss: 4.99212
Epoch 96, Val Loss: 5.10634
Epoch 97, Val Loss: 5.29862
Epoch 98, Val Loss: 5.02889
Epoch 99, Val Loss: 5.03130
DID NOT SAVE RESULTS
{'MSE - mean': 5.10500341606954, 'MSE - std': 0.0, 'R2 - mean': 0.5344405571371855, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.64980
Epoch 1, Val Loss: 7.65781
Epoch 2, Val Loss: 5.26344
Epoch 3, Val Loss: 5.05273
Epoch 4, Val Loss: 5.09954
Epoch 5, Val Loss: 4.98463
Epoch 6, Val Loss: 5.23724
Epoch 7, Val Loss: 5.04877
Epoch 8, Val Loss: 5.40530
Epoch 9, Val Loss: 5.14282
Epoch 10, Val Loss: 4.99048
Epoch 11, Val Loss: 4.95613
Epoch 12, Val Loss: 4.99429
Epoch 13, Val Loss: 4.89146
Epoch 14, Val Loss: 4.96831
Epoch 15, Val Loss: 4.90315
Epoch 16, Val Loss: 5.07366
Epoch 17, Val Loss: 4.89458
Epoch 18, Val Loss: 4.94314
Epoch 19, Val Loss: 4.80969
Epoch 20, Val Loss: 5.00950
Epoch 21, Val Loss: 4.98109
Epoch 22, Val Loss: 4.61538
Epoch 23, Val Loss: 4.63414
Epoch 24, Val Loss: 5.26733
Epoch 25, Val Loss: 4.54631
Epoch 26, Val Loss: 4.76016
Epoch 27, Val Loss: 4.66793
Epoch 28, Val Loss: 4.83354
Epoch 29, Val Loss: 4.50020
Epoch 30, Val Loss: 4.45337
Epoch 31, Val Loss: 4.40688
Epoch 32, Val Loss: 4.42684
Epoch 33, Val Loss: 4.95054
Epoch 34, Val Loss: 4.31946
Epoch 35, Val Loss: 4.43227
Epoch 36, Val Loss: 4.31122
Epoch 37, Val Loss: 5.19440
Epoch 38, Val Loss: 4.29650
Epoch 39, Val Loss: 4.33481
Epoch 40, Val Loss: 4.35391
Epoch 41, Val Loss: 4.22633
Epoch 42, Val Loss: 4.31034
Epoch 43, Val Loss: 4.27352
Epoch 44, Val Loss: 4.22142
Epoch 45, Val Loss: 4.22867
Epoch 46, Val Loss: 4.21403
Epoch 47, Val Loss: 4.23476
Epoch 48, Val Loss: 4.21842
Epoch 49, Val Loss: 4.16059
Epoch 50, Val Loss: 4.35145
Epoch 51, Val Loss: 4.16084
Epoch 52, Val Loss: 4.24527
Epoch 53, Val Loss: 4.16570
Epoch 54, Val Loss: 4.30322
Epoch 55, Val Loss: 4.22476
Epoch 56, Val Loss: 4.10033
Epoch 57, Val Loss: 4.19050
Epoch 58, Val Loss: 4.41548
Epoch 59, Val Loss: 4.15452
Epoch 60, Val Loss: 4.35343
Epoch 61, Val Loss: 4.12211
Epoch 62, Val Loss: 4.16213
Epoch 63, Val Loss: 4.09733
Epoch 64, Val Loss: 4.37855
Epoch 65, Val Loss: 4.14118
Epoch 66, Val Loss: 4.17043
Epoch 67, Val Loss: 4.27209
Epoch 68, Val Loss: 3.95472
Epoch 69, Val Loss: 4.01722
Epoch 70, Val Loss: 4.29920
Epoch 71, Val Loss: 4.07404
Epoch 72, Val Loss: 4.08983
Epoch 73, Val Loss: 4.03697
Epoch 74, Val Loss: 4.11279
Epoch 75, Val Loss: 4.42910
Epoch 76, Val Loss: 4.07031
Epoch 77, Val Loss: 3.98972
Epoch 78, Val Loss: 4.22216
Epoch 79, Val Loss: 3.98809
Epoch 80, Val Loss: 4.09818
Epoch 81, Val Loss: 4.45734
Epoch 82, Val Loss: 4.22740
Epoch 83, Val Loss: 4.15834
Epoch 84, Val Loss: 4.26605
Epoch 85, Val Loss: 4.13513
Epoch 86, Val Loss: 3.98830
Epoch 87, Val Loss: 4.12472
Epoch 88, Val Loss: 4.13437
Epoch 89, Val Loss: 4.34905
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.619030276463079, 'MSE - std': 0.4859731396064606, 'R2 - mean': 0.546935434209729, 'R2 - std': 0.012494877072543487} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.61564
Epoch 1, Val Loss: 13.56401
Epoch 2, Val Loss: 6.48080
Epoch 3, Val Loss: 6.24730
Epoch 4, Val Loss: 6.10219
Epoch 5, Val Loss: 6.00001
Epoch 6, Val Loss: 5.94328
Epoch 7, Val Loss: 5.95550
Epoch 8, Val Loss: 5.87113
Epoch 9, Val Loss: 5.92814
Epoch 10, Val Loss: 5.79090
Epoch 11, Val Loss: 6.12075
Epoch 12, Val Loss: 5.82630
Epoch 13, Val Loss: 5.75985
Epoch 14, Val Loss: 5.64408
Epoch 15, Val Loss: 5.86914
Epoch 16, Val Loss: 5.59209
Epoch 17, Val Loss: 5.86289
Epoch 18, Val Loss: 5.71561
Epoch 19, Val Loss: 5.52772
Epoch 20, Val Loss: 5.64995
Epoch 21, Val Loss: 5.70075
Epoch 22, Val Loss: 5.44631
Epoch 23, Val Loss: 5.56950
Epoch 24, Val Loss: 5.71191
Epoch 25, Val Loss: 5.44725
Epoch 26, Val Loss: 5.47378
Epoch 27, Val Loss: 5.35093
Epoch 28, Val Loss: 5.27424
Epoch 29, Val Loss: 5.53201
Epoch 30, Val Loss: 5.26112
Epoch 31, Val Loss: 5.20621
Epoch 32, Val Loss: 5.13422
Epoch 33, Val Loss: 5.45802
Epoch 34, Val Loss: 5.08866
Epoch 35, Val Loss: 5.23070
Epoch 36, Val Loss: 5.44019
Epoch 37, Val Loss: 5.04255
Epoch 38, Val Loss: 5.20428
Epoch 39, Val Loss: 5.03562
Epoch 40, Val Loss: 5.17990
Epoch 41, Val Loss: 5.10045
Epoch 42, Val Loss: 5.08831
Epoch 43, Val Loss: 4.90857
Epoch 44, Val Loss: 5.02488
Epoch 45, Val Loss: 4.99206
Epoch 46, Val Loss: 4.90367
Epoch 47, Val Loss: 4.95735
Epoch 48, Val Loss: 4.85209
Epoch 49, Val Loss: 4.84737
Epoch 50, Val Loss: 4.85097
Epoch 51, Val Loss: 4.85700
Epoch 52, Val Loss: 4.81459
Epoch 53, Val Loss: 4.89565
Epoch 54, Val Loss: 4.82684
Epoch 55, Val Loss: 4.91292
Epoch 56, Val Loss: 5.14163
Epoch 57, Val Loss: 4.81295
Epoch 58, Val Loss: 4.76910
Epoch 59, Val Loss: 4.77440
Epoch 60, Val Loss: 4.89405
Epoch 61, Val Loss: 4.80182
Epoch 62, Val Loss: 4.84739
Epoch 63, Val Loss: 4.96808
Epoch 64, Val Loss: 4.70903
Epoch 65, Val Loss: 4.74470
Epoch 66, Val Loss: 4.69286
Epoch 67, Val Loss: 4.85512
Epoch 68, Val Loss: 4.77300
Epoch 69, Val Loss: 4.83187
Epoch 70, Val Loss: 4.78591
Epoch 71, Val Loss: 4.88615
Epoch 72, Val Loss: 4.68823
Epoch 73, Val Loss: 4.87951
Epoch 74, Val Loss: 4.92033
Epoch 75, Val Loss: 4.65092
Epoch 76, Val Loss: 4.94913
Epoch 77, Val Loss: 4.69482
Epoch 78, Val Loss: 4.70076
Epoch 79, Val Loss: 4.87390
Epoch 80, Val Loss: 5.36287
Epoch 81, Val Loss: 4.65693
Epoch 82, Val Loss: 4.90727
Epoch 83, Val Loss: 4.58928
Epoch 84, Val Loss: 4.53456
Epoch 85, Val Loss: 4.78235
Epoch 86, Val Loss: 4.62820
Epoch 87, Val Loss: 4.59716
Epoch 88, Val Loss: 4.57637
Epoch 89, Val Loss: 4.63125
Epoch 90, Val Loss: 4.75192
Epoch 91, Val Loss: 4.71243
Epoch 92, Val Loss: 4.62857
Epoch 93, Val Loss: 4.67289
Epoch 94, Val Loss: 5.12652
Epoch 95, Val Loss: 4.64138
Epoch 96, Val Loss: 4.51600
Epoch 97, Val Loss: 4.58779
Epoch 98, Val Loss: 4.69340
Epoch 99, Val Loss: 4.65687
DID NOT SAVE RESULTS
{'MSE - mean': 4.613385990906047, 'MSE - std': 0.39687568691578007, 'R2 - mean': 0.5470101650088919, 'R2 - std': 0.010202571804370486} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 42.10500
Epoch 1, Val Loss: 13.70851
Epoch 2, Val Loss: 5.47710
Epoch 3, Val Loss: 5.36635
Epoch 4, Val Loss: 5.20730
Epoch 5, Val Loss: 5.15679
Epoch 6, Val Loss: 5.06618
Epoch 7, Val Loss: 5.21770
Epoch 8, Val Loss: 5.02999
Epoch 9, Val Loss: 5.07518
Epoch 10, Val Loss: 4.92619
Epoch 11, Val Loss: 4.95768
Epoch 12, Val Loss: 5.06835
Epoch 13, Val Loss: 4.90715
Epoch 14, Val Loss: 4.95973
Epoch 15, Val Loss: 4.88872
Epoch 16, Val Loss: 4.96066
Epoch 17, Val Loss: 4.72619
Epoch 18, Val Loss: 5.03170
Epoch 19, Val Loss: 4.87222
Epoch 20, Val Loss: 5.02831
Epoch 21, Val Loss: 4.99062
Epoch 22, Val Loss: 4.61411
Epoch 23, Val Loss: 4.89212
Epoch 24, Val Loss: 4.53198
Epoch 25, Val Loss: 4.59967
Epoch 26, Val Loss: 4.55108
Epoch 27, Val Loss: 4.95546
Epoch 28, Val Loss: 4.44250
Epoch 29, Val Loss: 4.40883
Epoch 30, Val Loss: 4.48598
Epoch 31, Val Loss: 4.39397
Epoch 32, Val Loss: 4.30099
Epoch 33, Val Loss: 4.27929
Epoch 34, Val Loss: 4.25501
Epoch 35, Val Loss: 4.91340
Epoch 36, Val Loss: 4.55692
Epoch 37, Val Loss: 4.30397
Epoch 38, Val Loss: 4.57785
Epoch 39, Val Loss: 4.11848
Epoch 40, Val Loss: 4.35899
Epoch 41, Val Loss: 4.35065
Epoch 42, Val Loss: 4.15923
Epoch 43, Val Loss: 4.10822
Epoch 44, Val Loss: 4.19407
Epoch 45, Val Loss: 4.18040
Epoch 46, Val Loss: 4.40183
Epoch 47, Val Loss: 4.09968
Epoch 48, Val Loss: 4.25788
Epoch 49, Val Loss: 4.04204
Epoch 50, Val Loss: 4.28165
Epoch 51, Val Loss: 4.06358
Epoch 52, Val Loss: 4.20392
Epoch 53, Val Loss: 4.33826
Epoch 54, Val Loss: 4.48276
Epoch 55, Val Loss: 4.18714
Epoch 56, Val Loss: 4.14363
Epoch 57, Val Loss: 4.24922
Epoch 58, Val Loss: 4.08206
Epoch 59, Val Loss: 4.23679
Epoch 60, Val Loss: 4.14540
Epoch 61, Val Loss: 3.96610
Epoch 62, Val Loss: 4.06444
Epoch 63, Val Loss: 4.08499
Epoch 64, Val Loss: 3.98614
Epoch 65, Val Loss: 4.11370
Epoch 66, Val Loss: 4.29286
Epoch 67, Val Loss: 4.35519
Epoch 68, Val Loss: 4.21573
Epoch 69, Val Loss: 3.89715
Epoch 70, Val Loss: 3.99940
Epoch 71, Val Loss: 4.34502
Epoch 72, Val Loss: 4.21056
Epoch 73, Val Loss: 4.24809
Epoch 74, Val Loss: 4.03544
Epoch 75, Val Loss: 3.87920
Epoch 76, Val Loss: 4.38918
Epoch 77, Val Loss: 4.50761
Epoch 78, Val Loss: 4.00888
Epoch 79, Val Loss: 4.08677
Epoch 80, Val Loss: 3.90899
Epoch 81, Val Loss: 4.03859
Epoch 82, Val Loss: 3.99330
Epoch 83, Val Loss: 4.15921
Epoch 84, Val Loss: 4.06580
Epoch 85, Val Loss: 4.19839
Epoch 86, Val Loss: 3.91660
Epoch 87, Val Loss: 4.17089
Epoch 88, Val Loss: 4.00225
Epoch 89, Val Loss: 4.64452
Epoch 90, Val Loss: 3.87367
Epoch 91, Val Loss: 4.41939
Epoch 92, Val Loss: 4.07589
Epoch 93, Val Loss: 4.18046
Epoch 94, Val Loss: 4.18480
Epoch 95, Val Loss: 4.11500
Epoch 96, Val Loss: 4.11994
Epoch 97, Val Loss: 4.28612
Epoch 98, Val Loss: 3.89563
Epoch 99, Val Loss: 3.88930
DID NOT SAVE RESULTS
{'MSE - mean': 4.5117188075908645, 'MSE - std': 0.38618827226934627, 'R2 - mean': 0.5478115367826777, 'R2 - std': 0.0089440451545687} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 36.10154
Epoch 1, Val Loss: 11.15739
Epoch 2, Val Loss: 9.24113
Epoch 3, Val Loss: 7.60435
Epoch 4, Val Loss: 7.50697
Epoch 5, Val Loss: 7.62591
Epoch 6, Val Loss: 7.22906
Epoch 7, Val Loss: 7.44654
Epoch 8, Val Loss: 7.03381
Epoch 9, Val Loss: 7.14625
Epoch 10, Val Loss: 7.31550
Epoch 11, Val Loss: 6.93641
Epoch 12, Val Loss: 7.66537
Epoch 13, Val Loss: 6.97709
Epoch 14, Val Loss: 6.96420
Epoch 15, Val Loss: 7.05440
Epoch 16, Val Loss: 6.91634
Epoch 17, Val Loss: 7.00378
Epoch 18, Val Loss: 6.74622
Epoch 19, Val Loss: 6.81978
Epoch 20, Val Loss: 6.49666
Epoch 21, Val Loss: 7.47603
Epoch 22, Val Loss: 6.70084
Epoch 23, Val Loss: 6.75378
Epoch 24, Val Loss: 6.97740
Epoch 25, Val Loss: 6.28144
Epoch 26, Val Loss: 6.20088
Epoch 27, Val Loss: 6.35492
Epoch 28, Val Loss: 6.72213
Epoch 29, Val Loss: 6.23456
Epoch 30, Val Loss: 6.06932
Epoch 31, Val Loss: 6.71417
Epoch 32, Val Loss: 6.05641
Epoch 33, Val Loss: 6.13848
Epoch 34, Val Loss: 6.12878
Epoch 35, Val Loss: 5.96768
Epoch 36, Val Loss: 6.00102
Epoch 37, Val Loss: 6.29942
Epoch 38, Val Loss: 6.34778
Epoch 39, Val Loss: 6.23754
Epoch 40, Val Loss: 6.07211
Epoch 41, Val Loss: 5.88461
Epoch 42, Val Loss: 6.29148
Epoch 43, Val Loss: 6.12646
Epoch 44, Val Loss: 6.40774
Epoch 45, Val Loss: 6.16289
Epoch 46, Val Loss: 5.93861
Epoch 47, Val Loss: 6.10913
Epoch 48, Val Loss: 6.17674
Epoch 49, Val Loss: 6.09491
Epoch 50, Val Loss: 6.25260
Epoch 51, Val Loss: 6.27638
Epoch 52, Val Loss: 5.93320
Epoch 53, Val Loss: 5.87028
Epoch 54, Val Loss: 5.98920
Epoch 55, Val Loss: 6.10905
Epoch 56, Val Loss: 5.82021
Epoch 57, Val Loss: 6.29803
Epoch 58, Val Loss: 5.97616
Epoch 59, Val Loss: 6.03411
Epoch 60, Val Loss: 5.96108
Epoch 61, Val Loss: 5.96652
Epoch 62, Val Loss: 6.08415
Epoch 63, Val Loss: 5.92651
Epoch 64, Val Loss: 5.94010
Epoch 65, Val Loss: 5.87362
Epoch 66, Val Loss: 6.54040
Epoch 67, Val Loss: 5.87921
Epoch 68, Val Loss: 5.82885
Epoch 69, Val Loss: 5.89061
Epoch 70, Val Loss: 5.82409
Epoch 71, Val Loss: 5.97751
Epoch 72, Val Loss: 6.24088
Epoch 73, Val Loss: 6.24519
Epoch 74, Val Loss: 6.13304
Epoch 75, Val Loss: 6.02717
Epoch 76, Val Loss: 5.97208
Epoch 77, Val Loss: 5.68742
Epoch 78, Val Loss: 5.98910
Epoch 79, Val Loss: 6.08098
Epoch 80, Val Loss: 5.81445
Epoch 81, Val Loss: 5.93868
Epoch 82, Val Loss: 5.96338
Epoch 83, Val Loss: 5.87440
Epoch 84, Val Loss: 5.85021
Epoch 85, Val Loss: 5.98140
Epoch 86, Val Loss: 6.23181
Epoch 87, Val Loss: 5.93908
Epoch 88, Val Loss: 5.96617
Epoch 89, Val Loss: 5.93615
Epoch 90, Val Loss: 5.78932
Epoch 91, Val Loss: 6.13500
Epoch 92, Val Loss: 6.52608
Epoch 93, Val Loss: 6.36634
Epoch 94, Val Loss: 5.72850
Epoch 95, Val Loss: 6.11962
Epoch 96, Val Loss: 6.08295
Epoch 97, Val Loss: 5.71246
Epoch 98, Val Loss: 6.06578
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.744117855959839, 'MSE - std': 0.5790944448377361, 'R2 - mean': 0.544406356559234, 'R2 - std': 0.010506082257344977} 
 

Results After CV: {'MSE - mean': 4.744117855959839, 'MSE - std': 0.5790944448377361, 'R2 - mean': 0.544406356559234, 'R2 - std': 0.010506082257344977}
Train time: 27.15399514519886
Inference time: 0.04789487939997343
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 64 finished with value: 4.744117855959839 and parameters: {'p_m': 0.5491562660231701, 'alpha': 3.83203730126958, 'K': 2, 'beta': 0.8138765079423969}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.72023
Epoch 1, Val Loss: 13.13067
Epoch 2, Val Loss: 8.01465
Epoch 3, Val Loss: 7.03487
Epoch 4, Val Loss: 6.90628
Epoch 5, Val Loss: 7.05212
Epoch 6, Val Loss: 6.90903
Epoch 7, Val Loss: 6.67310
Epoch 8, Val Loss: 6.60855
Epoch 9, Val Loss: 6.56907
Epoch 10, Val Loss: 6.39071
Epoch 11, Val Loss: 6.16060
Epoch 12, Val Loss: 6.15799
Epoch 13, Val Loss: 6.12470
Epoch 14, Val Loss: 6.06827
Epoch 15, Val Loss: 6.27365
Epoch 16, Val Loss: 5.86086
Epoch 17, Val Loss: 5.99097
Epoch 18, Val Loss: 5.79397
Epoch 19, Val Loss: 6.19454
Epoch 20, Val Loss: 6.01230
Epoch 21, Val Loss: 5.83985
Epoch 22, Val Loss: 6.37846
Epoch 23, Val Loss: 5.68506
Epoch 24, Val Loss: 5.64083
Epoch 25, Val Loss: 5.77864
Epoch 26, Val Loss: 6.00355
Epoch 27, Val Loss: 5.70163
Epoch 28, Val Loss: 5.52644
Epoch 29, Val Loss: 5.71959
Epoch 30, Val Loss: 5.72915
Epoch 31, Val Loss: 5.81737
Epoch 32, Val Loss: 5.44232
Epoch 33, Val Loss: 5.40504
Epoch 34, Val Loss: 5.70781
Epoch 35, Val Loss: 5.37853
Epoch 36, Val Loss: 5.62804
Epoch 37, Val Loss: 5.46572
Epoch 38, Val Loss: 5.84744
Epoch 39, Val Loss: 5.26533
Epoch 40, Val Loss: 5.47307
Epoch 41, Val Loss: 5.31652
Epoch 42, Val Loss: 5.34214
Epoch 43, Val Loss: 5.47115
Epoch 44, Val Loss: 5.33914
Epoch 45, Val Loss: 5.47401
Epoch 46, Val Loss: 5.29815
Epoch 47, Val Loss: 5.10580
Epoch 48, Val Loss: 5.29937
Epoch 49, Val Loss: 5.10267
Epoch 50, Val Loss: 5.46449
Epoch 51, Val Loss: 5.11487
Epoch 52, Val Loss: 5.38523
Epoch 53, Val Loss: 5.16774
Epoch 54, Val Loss: 5.24764
Epoch 55, Val Loss: 5.27845
Epoch 56, Val Loss: 5.17169
Epoch 57, Val Loss: 5.17694
Epoch 58, Val Loss: 5.04734
Epoch 59, Val Loss: 5.27369
Epoch 60, Val Loss: 5.20381
Epoch 61, Val Loss: 5.13756
Epoch 62, Val Loss: 5.21100
Epoch 63, Val Loss: 5.04083
Epoch 64, Val Loss: 5.21669
Epoch 65, Val Loss: 4.96778
Epoch 66, Val Loss: 5.23678
Epoch 67, Val Loss: 5.22262
Epoch 68, Val Loss: 5.05328
Epoch 69, Val Loss: 5.48024
Epoch 70, Val Loss: 5.43846
Epoch 71, Val Loss: 5.01011
Epoch 72, Val Loss: 5.01891
Epoch 73, Val Loss: 4.94512
Epoch 74, Val Loss: 5.02579
Epoch 75, Val Loss: 5.24432
Epoch 76, Val Loss: 5.21123
Epoch 77, Val Loss: 5.10103
Epoch 78, Val Loss: 4.90277
Epoch 79, Val Loss: 5.01856
Epoch 80, Val Loss: 5.01104
Epoch 81, Val Loss: 5.13338
Epoch 82, Val Loss: 5.05111
Epoch 83, Val Loss: 4.99065
Epoch 84, Val Loss: 5.01556
Epoch 85, Val Loss: 5.19021
Epoch 86, Val Loss: 5.28597
Epoch 87, Val Loss: 5.09866
Epoch 88, Val Loss: 5.35773
Epoch 89, Val Loss: 5.05375
Epoch 90, Val Loss: 5.03850
Epoch 91, Val Loss: 5.02938
Epoch 92, Val Loss: 5.20096
Epoch 93, Val Loss: 5.25445
Epoch 94, Val Loss: 5.02933
Epoch 95, Val Loss: 4.91640
Epoch 96, Val Loss: 5.06605
Epoch 97, Val Loss: 4.93315
Epoch 98, Val Loss: 5.15676
Epoch 99, Val Loss: 5.61223
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 5.032111576544957, 'MSE - std': 0.0, 'R2 - mean': 0.5410880520421817, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.11217
Epoch 1, Val Loss: 14.46316
Epoch 2, Val Loss: 5.64866
Epoch 3, Val Loss: 5.25182
Epoch 4, Val Loss: 5.46744
Epoch 5, Val Loss: 5.31795
Epoch 6, Val Loss: 5.28605
Epoch 7, Val Loss: 5.51016
Epoch 8, Val Loss: 5.64574
Epoch 9, Val Loss: 5.09514
Epoch 10, Val Loss: 4.96201
Epoch 11, Val Loss: 5.00662
Epoch 12, Val Loss: 5.22337
Epoch 13, Val Loss: 5.13733
Epoch 14, Val Loss: 5.00792
Epoch 15, Val Loss: 5.23057
Epoch 16, Val Loss: 4.96424
Epoch 17, Val Loss: 4.93334
Epoch 18, Val Loss: 4.92558
Epoch 19, Val Loss: 4.92276
Epoch 20, Val Loss: 5.04531
Epoch 21, Val Loss: 5.12819
Epoch 22, Val Loss: 5.27497
Epoch 23, Val Loss: 4.93323
Epoch 24, Val Loss: 4.85414
Epoch 25, Val Loss: 4.96909
Epoch 26, Val Loss: 5.02824
Epoch 27, Val Loss: 4.76243
Epoch 28, Val Loss: 4.76577
Epoch 29, Val Loss: 4.86512
Epoch 30, Val Loss: 4.87025
Epoch 31, Val Loss: 4.71981
Epoch 32, Val Loss: 4.81872
Epoch 33, Val Loss: 4.73658
Epoch 34, Val Loss: 5.04800
Epoch 35, Val Loss: 4.81627
Epoch 36, Val Loss: 4.88110
Epoch 37, Val Loss: 4.64245
Epoch 38, Val Loss: 4.65497
Epoch 39, Val Loss: 4.71301
Epoch 40, Val Loss: 4.75994
Epoch 41, Val Loss: 4.74479
Epoch 42, Val Loss: 4.52357
Epoch 43, Val Loss: 4.51886
Epoch 44, Val Loss: 4.49864
Epoch 45, Val Loss: 4.52527
Epoch 46, Val Loss: 4.55830
Epoch 47, Val Loss: 4.55832
Epoch 48, Val Loss: 4.89547
Epoch 49, Val Loss: 5.17502
Epoch 50, Val Loss: 4.83531
Epoch 51, Val Loss: 4.38574
Epoch 52, Val Loss: 4.53007
Epoch 53, Val Loss: 4.52381
Epoch 54, Val Loss: 5.06585
Epoch 55, Val Loss: 4.46166
Epoch 56, Val Loss: 4.33486
Epoch 57, Val Loss: 4.46403
Epoch 58, Val Loss: 4.55969
Epoch 59, Val Loss: 4.53975
Epoch 60, Val Loss: 4.33198
Epoch 61, Val Loss: 5.04880
Epoch 62, Val Loss: 4.39951
Epoch 63, Val Loss: 4.58152
Epoch 64, Val Loss: 4.24706
Epoch 65, Val Loss: 4.30507
Epoch 66, Val Loss: 4.68211
Epoch 67, Val Loss: 4.33413
Epoch 68, Val Loss: 4.37421
Epoch 69, Val Loss: 4.27853
Epoch 70, Val Loss: 4.26545
Epoch 71, Val Loss: 4.29040
Epoch 72, Val Loss: 4.41942
Epoch 73, Val Loss: 4.40507
Epoch 74, Val Loss: 4.46927
Epoch 75, Val Loss: 4.46433
Epoch 76, Val Loss: 4.26691
Epoch 77, Val Loss: 4.21167
Epoch 78, Val Loss: 4.29644
Epoch 79, Val Loss: 4.56419
Epoch 80, Val Loss: 4.40890
Epoch 81, Val Loss: 4.57207
Epoch 82, Val Loss: 4.57195
Epoch 83, Val Loss: 4.13891
Epoch 84, Val Loss: 4.13815
Epoch 85, Val Loss: 4.41623
Epoch 86, Val Loss: 4.36226
Epoch 87, Val Loss: 4.27510
Epoch 88, Val Loss: 4.16836
Epoch 89, Val Loss: 4.29924
Epoch 90, Val Loss: 4.75330
Epoch 91, Val Loss: 4.45558
Epoch 92, Val Loss: 4.14509
Epoch 93, Val Loss: 4.17943
Epoch 94, Val Loss: 4.22262
Epoch 95, Val Loss: 4.39264
Epoch 96, Val Loss: 4.51705
Epoch 97, Val Loss: 4.20795
Epoch 98, Val Loss: 4.24278
Epoch 99, Val Loss: 4.45902
DID NOT SAVE RESULTS
{'MSE - mean': 4.665616895679479, 'MSE - std': 0.3664946808654781, 'R2 - mean': 0.5414081983247195, 'R2 - std': 0.0003201462825378476} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.15598
Epoch 1, Val Loss: 7.25846
Epoch 2, Val Loss: 6.83612
Epoch 3, Val Loss: 6.46827
Epoch 4, Val Loss: 6.27553
Epoch 5, Val Loss: 6.14397
Epoch 6, Val Loss: 5.96459
Epoch 7, Val Loss: 6.02096
Epoch 8, Val Loss: 6.00481
Epoch 9, Val Loss: 5.99945
Epoch 10, Val Loss: 5.92151
Epoch 11, Val Loss: 5.92635
Epoch 12, Val Loss: 6.16266
Epoch 13, Val Loss: 5.90612
Epoch 14, Val Loss: 6.06223
Epoch 15, Val Loss: 5.89649
Epoch 16, Val Loss: 5.85121
Epoch 17, Val Loss: 5.88664
Epoch 18, Val Loss: 6.01197
Epoch 19, Val Loss: 5.81168
Epoch 20, Val Loss: 5.94868
Epoch 21, Val Loss: 5.71172
Epoch 22, Val Loss: 5.80615
Epoch 23, Val Loss: 5.66162
Epoch 24, Val Loss: 5.94757
Epoch 25, Val Loss: 5.67167
Epoch 26, Val Loss: 5.99773
Epoch 27, Val Loss: 5.88827
Epoch 28, Val Loss: 5.76280
Epoch 29, Val Loss: 5.77457
Epoch 30, Val Loss: 5.87484
Epoch 31, Val Loss: 5.84547
Epoch 32, Val Loss: 6.27087
Epoch 33, Val Loss: 5.98735
Epoch 34, Val Loss: 5.64591
Epoch 35, Val Loss: 5.56862
Epoch 36, Val Loss: 5.63101
Epoch 37, Val Loss: 5.68037
Epoch 38, Val Loss: 5.61925
Epoch 39, Val Loss: 5.45679
Epoch 40, Val Loss: 5.44481
Epoch 41, Val Loss: 5.69753
Epoch 42, Val Loss: 5.55608
Epoch 43, Val Loss: 5.35647
Epoch 44, Val Loss: 5.66226
Epoch 45, Val Loss: 5.34028
Epoch 46, Val Loss: 5.42915
Epoch 47, Val Loss: 5.68220
Epoch 48, Val Loss: 5.29481
Epoch 49, Val Loss: 5.45228
Epoch 50, Val Loss: 5.87081
Epoch 51, Val Loss: 5.48217
Epoch 52, Val Loss: 5.18120
Epoch 53, Val Loss: 5.51035
Epoch 54, Val Loss: 5.30293
Epoch 55, Val Loss: 5.28993
Epoch 56, Val Loss: 5.13160
Epoch 57, Val Loss: 5.19222
Epoch 58, Val Loss: 5.36155
Epoch 59, Val Loss: 5.27491
Epoch 60, Val Loss: 5.10904
Epoch 61, Val Loss: 5.38701
Epoch 62, Val Loss: 5.29586
Epoch 63, Val Loss: 5.15068
Epoch 64, Val Loss: 5.52691
Epoch 65, Val Loss: 5.05447
Epoch 66, Val Loss: 5.25829
Epoch 67, Val Loss: 5.03534
Epoch 68, Val Loss: 5.01995
Epoch 69, Val Loss: 5.06893
Epoch 70, Val Loss: 5.10212
Epoch 71, Val Loss: 5.04408
Epoch 72, Val Loss: 4.97897
Epoch 73, Val Loss: 5.22829
Epoch 74, Val Loss: 5.03117
Epoch 75, Val Loss: 5.11486
Epoch 76, Val Loss: 5.06458
Epoch 77, Val Loss: 5.04000
Epoch 78, Val Loss: 5.15920
Epoch 79, Val Loss: 4.98873
Epoch 80, Val Loss: 5.09766
Epoch 81, Val Loss: 4.92707
Epoch 82, Val Loss: 5.04672
Epoch 83, Val Loss: 4.92703
Epoch 84, Val Loss: 6.32056
Epoch 85, Val Loss: 4.97903
Epoch 86, Val Loss: 5.36268
Epoch 87, Val Loss: 5.00777
Epoch 88, Val Loss: 5.18842
Epoch 89, Val Loss: 4.98276
Epoch 90, Val Loss: 4.84212
Epoch 91, Val Loss: 4.85074
Epoch 92, Val Loss: 4.86314
Epoch 93, Val Loss: 4.94344
Epoch 94, Val Loss: 4.84288
Epoch 95, Val Loss: 5.35560
Epoch 96, Val Loss: 4.86793
Epoch 97, Val Loss: 4.79596
Epoch 98, Val Loss: 4.84903
Epoch 99, Val Loss: 5.17727
DID NOT SAVE RESULTS
{'MSE - mean': 4.752780482722488, 'MSE - std': 0.32363644605359404, 'R2 - mean': 0.5326651468551216, 'R2 - std': 0.012367304762756264} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.28759
Epoch 1, Val Loss: 11.06161
Epoch 2, Val Loss: 6.12685
Epoch 3, Val Loss: 5.33527
Epoch 4, Val Loss: 5.15989
Epoch 5, Val Loss: 4.94213
Epoch 6, Val Loss: 5.04440
Epoch 7, Val Loss: 4.95533
Epoch 8, Val Loss: 4.94867
Epoch 9, Val Loss: 4.89737
Epoch 10, Val Loss: 5.19609
Epoch 11, Val Loss: 4.97921
Epoch 12, Val Loss: 5.03792
Epoch 13, Val Loss: 4.78644
Epoch 14, Val Loss: 4.85297
Epoch 15, Val Loss: 4.82936
Epoch 16, Val Loss: 4.71030
Epoch 17, Val Loss: 4.86181
Epoch 18, Val Loss: 4.65151
Epoch 19, Val Loss: 4.71330
Epoch 20, Val Loss: 4.66990
Epoch 21, Val Loss: 5.04639
Epoch 22, Val Loss: 4.49667
Epoch 23, Val Loss: 4.82703
Epoch 24, Val Loss: 4.67945
Epoch 25, Val Loss: 4.43229
Epoch 26, Val Loss: 4.39388
Epoch 27, Val Loss: 4.64137
Epoch 28, Val Loss: 4.45392
Epoch 29, Val Loss: 4.57010
Epoch 30, Val Loss: 4.38184
Epoch 31, Val Loss: 4.36985
Epoch 32, Val Loss: 4.69721
Epoch 33, Val Loss: 4.45170
Epoch 34, Val Loss: 4.77301
Epoch 35, Val Loss: 4.34807
Epoch 36, Val Loss: 4.37416
Epoch 37, Val Loss: 4.47806
Epoch 38, Val Loss: 4.56653
Epoch 39, Val Loss: 4.62107
Epoch 40, Val Loss: 4.27481
Epoch 41, Val Loss: 4.39713
Epoch 42, Val Loss: 4.32099
Epoch 43, Val Loss: 4.45974
Epoch 44, Val Loss: 5.11004
Epoch 45, Val Loss: 4.26595
Epoch 46, Val Loss: 4.76749
Epoch 47, Val Loss: 4.31565
Epoch 48, Val Loss: 4.25987
Epoch 49, Val Loss: 4.25545
Epoch 50, Val Loss: 4.49505
Epoch 51, Val Loss: 4.39521
Epoch 52, Val Loss: 4.35106
Epoch 53, Val Loss: 4.67698
Epoch 54, Val Loss: 4.22775
Epoch 55, Val Loss: 4.21260
Epoch 56, Val Loss: 4.24986
Epoch 57, Val Loss: 4.42426
Epoch 58, Val Loss: 4.18167
Epoch 59, Val Loss: 4.49127
Epoch 60, Val Loss: 4.16088
Epoch 61, Val Loss: 4.58661
Epoch 62, Val Loss: 4.47624
Epoch 63, Val Loss: 4.31879
Epoch 64, Val Loss: 4.21051
Epoch 65, Val Loss: 4.68207
Epoch 66, Val Loss: 4.18413
Epoch 67, Val Loss: 4.12926
Epoch 68, Val Loss: 4.61721
Epoch 69, Val Loss: 4.62449
Epoch 70, Val Loss: 4.22441
Epoch 71, Val Loss: 4.33278
Epoch 72, Val Loss: 4.22603
Epoch 73, Val Loss: 4.34847
Epoch 74, Val Loss: 4.12121
Epoch 75, Val Loss: 4.05742
Epoch 76, Val Loss: 4.18124
Epoch 77, Val Loss: 4.65232
Epoch 78, Val Loss: 4.18300
Epoch 79, Val Loss: 4.22836
Epoch 80, Val Loss: 4.12072
Epoch 81, Val Loss: 4.38512
Epoch 82, Val Loss: 4.18044
Epoch 83, Val Loss: 4.15336
Epoch 84, Val Loss: 4.49930
Epoch 85, Val Loss: 4.18339
Epoch 86, Val Loss: 4.22558
Epoch 87, Val Loss: 4.22462
Epoch 88, Val Loss: 4.17180
Epoch 89, Val Loss: 4.14061
Epoch 90, Val Loss: 4.14891
Epoch 91, Val Loss: 4.04048
Epoch 92, Val Loss: 4.25765
Epoch 93, Val Loss: 4.21008
Epoch 94, Val Loss: 4.17990
Epoch 95, Val Loss: 4.10287
Epoch 96, Val Loss: 4.13048
Epoch 97, Val Loss: 4.09138
Epoch 98, Val Loss: 4.17963
Epoch 99, Val Loss: 4.34784
DID NOT SAVE RESULTS
{'MSE - mean': 4.659631414630455, 'MSE - std': 0.3233970602369374, 'R2 - mean': 0.5324159794736488, 'R2 - std': 0.0107190915414106} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 43.37072
Epoch 1, Val Loss: 21.24709
Epoch 2, Val Loss: 10.04811
Epoch 3, Val Loss: 8.75924
Epoch 4, Val Loss: 7.56020
Epoch 5, Val Loss: 7.75268
Epoch 6, Val Loss: 7.21844
Epoch 7, Val Loss: 7.44753
Epoch 8, Val Loss: 7.31061
Epoch 9, Val Loss: 7.22294
Epoch 10, Val Loss: 7.18398
Epoch 11, Val Loss: 7.12424
Epoch 12, Val Loss: 7.25542
Epoch 13, Val Loss: 7.61753
Epoch 14, Val Loss: 7.13089
Epoch 15, Val Loss: 7.19620
Epoch 16, Val Loss: 7.19502
Epoch 17, Val Loss: 7.39231
Epoch 18, Val Loss: 7.03211
Epoch 19, Val Loss: 7.08728
Epoch 20, Val Loss: 7.27669
Epoch 21, Val Loss: 6.93630
Epoch 22, Val Loss: 7.28447
Epoch 23, Val Loss: 7.36366
Epoch 24, Val Loss: 7.05826
Epoch 25, Val Loss: 6.99191
Epoch 26, Val Loss: 6.99791
Epoch 27, Val Loss: 6.92730
Epoch 28, Val Loss: 6.93123
Epoch 29, Val Loss: 7.13677
Epoch 30, Val Loss: 7.12096
Epoch 31, Val Loss: 6.90085
Epoch 32, Val Loss: 6.98312
Epoch 33, Val Loss: 7.48073
Epoch 34, Val Loss: 6.79627
Epoch 35, Val Loss: 6.88579
Epoch 36, Val Loss: 6.84698
Epoch 37, Val Loss: 6.94371
Epoch 38, Val Loss: 6.52619
Epoch 39, Val Loss: 6.81154
Epoch 40, Val Loss: 7.38916
Epoch 41, Val Loss: 6.91087
Epoch 42, Val Loss: 6.81191
Epoch 43, Val Loss: 7.19525
Epoch 44, Val Loss: 6.47786
Epoch 45, Val Loss: 6.47359
Epoch 46, Val Loss: 6.77191
Epoch 47, Val Loss: 6.59881
Epoch 48, Val Loss: 6.42036
Epoch 49, Val Loss: 6.50092
Epoch 50, Val Loss: 6.43375
Epoch 51, Val Loss: 6.36212
Epoch 52, Val Loss: 6.47824
Epoch 53, Val Loss: 6.25798
Epoch 54, Val Loss: 6.12187
Epoch 55, Val Loss: 6.32561
Epoch 56, Val Loss: 6.69485
Epoch 57, Val Loss: 6.59057
Epoch 58, Val Loss: 6.21534
Epoch 59, Val Loss: 6.44131
Epoch 60, Val Loss: 6.10519
Epoch 61, Val Loss: 6.35013
Epoch 62, Val Loss: 6.11875
Epoch 63, Val Loss: 6.16836
Epoch 64, Val Loss: 6.57534
Epoch 65, Val Loss: 6.64171
Epoch 66, Val Loss: 6.60460
Epoch 67, Val Loss: 6.46923
Epoch 68, Val Loss: 6.85668
Epoch 69, Val Loss: 6.47207
Epoch 70, Val Loss: 6.24391
Epoch 71, Val Loss: 6.48059
Epoch 72, Val Loss: 6.12681
Epoch 73, Val Loss: 6.19202
Epoch 74, Val Loss: 6.32593
Epoch 75, Val Loss: 6.10562
Epoch 76, Val Loss: 5.88772
Epoch 77, Val Loss: 5.88880
Epoch 78, Val Loss: 6.04316
Epoch 79, Val Loss: 6.58223
Epoch 80, Val Loss: 6.08923
Epoch 81, Val Loss: 6.01498
Epoch 82, Val Loss: 6.06434
Epoch 83, Val Loss: 6.72598
Epoch 84, Val Loss: 6.32522
Epoch 85, Val Loss: 6.05688
Epoch 86, Val Loss: 6.27419
Epoch 87, Val Loss: 6.03967
Epoch 88, Val Loss: 5.95135
Epoch 89, Val Loss: 5.89518
Epoch 90, Val Loss: 5.89897
Epoch 91, Val Loss: 6.15398
Epoch 92, Val Loss: 6.11290
Epoch 93, Val Loss: 6.11211
Epoch 94, Val Loss: 6.04042
Epoch 95, Val Loss: 6.44487
Epoch 96, Val Loss: 5.82705
Epoch 97, Val Loss: 6.09759
Epoch 98, Val Loss: 6.10593
Epoch 99, Val Loss: 5.98174
DID NOT SAVE RESULTS
{'MSE - mean': 4.897381799309358, 'MSE - std': 0.5565694103306243, 'R2 - mean': 0.529200891684966, 'R2 - std': 0.011544102248952214} 
 

Results After CV: {'MSE - mean': 4.897381799309358, 'MSE - std': 0.5565694103306243, 'R2 - mean': 0.529200891684966, 'R2 - std': 0.011544102248952214}
Train time: 113.85970008360019
Inference time: 0.05142096840063459
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 65 finished with value: 4.897381799309358 and parameters: {'p_m': 0.42006800817391243, 'alpha': 1.8689169396689918, 'K': 20, 'beta': 1.2602866619948268}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.39470
Epoch 1, Val Loss: 14.67460
Epoch 2, Val Loss: 7.62837
Epoch 3, Val Loss: 7.07688
Epoch 4, Val Loss: 6.95146
Epoch 5, Val Loss: 6.79359
Epoch 6, Val Loss: 6.42773
Epoch 7, Val Loss: 6.62422
Epoch 8, Val Loss: 6.33632
Epoch 9, Val Loss: 6.21132
Epoch 10, Val Loss: 6.12799
Epoch 11, Val Loss: 5.83652
Epoch 12, Val Loss: 5.72757
Epoch 13, Val Loss: 5.75031
Epoch 14, Val Loss: 5.53510
Epoch 15, Val Loss: 5.57012
Epoch 16, Val Loss: 5.38042
Epoch 17, Val Loss: 5.49695
Epoch 18, Val Loss: 5.43987
Epoch 19, Val Loss: 5.35228
Epoch 20, Val Loss: 5.36396
Epoch 21, Val Loss: 5.50689
Epoch 22, Val Loss: 5.27637
Epoch 23, Val Loss: 5.31220
Epoch 24, Val Loss: 5.55398
Epoch 25, Val Loss: 5.11563
Epoch 26, Val Loss: 5.32847
Epoch 27, Val Loss: 5.17366
Epoch 28, Val Loss: 5.14480
Epoch 29, Val Loss: 5.41758
Epoch 30, Val Loss: 5.05660
Epoch 31, Val Loss: 5.35851
Epoch 32, Val Loss: 5.05982
Epoch 33, Val Loss: 5.25151
Epoch 34, Val Loss: 5.20511
Epoch 35, Val Loss: 5.04994
Epoch 36, Val Loss: 5.09723
Epoch 37, Val Loss: 5.24815
Epoch 38, Val Loss: 5.11600
Epoch 39, Val Loss: 5.44786
Epoch 40, Val Loss: 5.18683
Epoch 41, Val Loss: 5.00139
Epoch 42, Val Loss: 5.11186
Epoch 43, Val Loss: 5.04100
Epoch 44, Val Loss: 5.04690
Epoch 45, Val Loss: 5.01216
Epoch 46, Val Loss: 5.30613
Epoch 47, Val Loss: 5.12062
Epoch 48, Val Loss: 4.99013
Epoch 49, Val Loss: 4.96279
Epoch 50, Val Loss: 4.98929
Epoch 51, Val Loss: 4.94084
Epoch 52, Val Loss: 4.88664
Epoch 53, Val Loss: 5.12743
Epoch 54, Val Loss: 4.99860
Epoch 55, Val Loss: 4.88521
Epoch 56, Val Loss: 5.80431
Epoch 57, Val Loss: 5.16715
Epoch 58, Val Loss: 5.03751
Epoch 59, Val Loss: 4.93537
Epoch 60, Val Loss: 4.84907
Epoch 61, Val Loss: 5.09093
Epoch 62, Val Loss: 4.97463
Epoch 63, Val Loss: 5.03399
Epoch 64, Val Loss: 4.96327
Epoch 65, Val Loss: 4.86313
Epoch 66, Val Loss: 4.82045
Epoch 67, Val Loss: 5.09062
Epoch 68, Val Loss: 4.78140
Epoch 69, Val Loss: 4.78186
Epoch 70, Val Loss: 4.84466
Epoch 71, Val Loss: 4.80054
Epoch 72, Val Loss: 5.00346
Epoch 73, Val Loss: 4.89458
Epoch 74, Val Loss: 4.96001
Epoch 75, Val Loss: 4.76180
Epoch 76, Val Loss: 4.90309
Epoch 77, Val Loss: 4.75984
Epoch 78, Val Loss: 4.81811
Epoch 79, Val Loss: 5.02285
Epoch 80, Val Loss: 5.06608
Epoch 81, Val Loss: 4.70989
Epoch 82, Val Loss: 4.83938
Epoch 83, Val Loss: 4.88589
Epoch 84, Val Loss: 4.85950
Epoch 85, Val Loss: 4.89519
Epoch 86, Val Loss: 4.69556
Epoch 87, Val Loss: 4.79999
Epoch 88, Val Loss: 5.39660
Epoch 89, Val Loss: 4.76759
Epoch 90, Val Loss: 4.67902
Epoch 91, Val Loss: 4.69266
Epoch 92, Val Loss: 4.62227
Epoch 93, Val Loss: 4.83411
Epoch 94, Val Loss: 5.01933
Epoch 95, Val Loss: 4.61075
Epoch 96, Val Loss: 4.85340
Epoch 97, Val Loss: 4.66292
Epoch 98, Val Loss: 4.68829
Epoch 99, Val Loss: 4.68303
DID NOT SAVE RESULTS
{'MSE - mean': 4.665548465494258, 'MSE - std': 0.0, 'R2 - mean': 0.5745173965197249, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.01198
Epoch 1, Val Loss: 9.69661
Epoch 2, Val Loss: 6.65781
Epoch 3, Val Loss: 5.62323
Epoch 4, Val Loss: 5.44703
Epoch 5, Val Loss: 5.10749
Epoch 6, Val Loss: 4.91620
Epoch 7, Val Loss: 4.79198
Epoch 8, Val Loss: 4.92353
Epoch 9, Val Loss: 4.90792
Epoch 10, Val Loss: 4.91323
Epoch 11, Val Loss: 5.02776
Epoch 12, Val Loss: 4.68117
Epoch 13, Val Loss: 4.75295
Epoch 14, Val Loss: 4.61998
Epoch 15, Val Loss: 4.75451
Epoch 16, Val Loss: 5.04965
Epoch 17, Val Loss: 4.67826
Epoch 18, Val Loss: 4.68537
Epoch 19, Val Loss: 5.06342
Epoch 20, Val Loss: 4.62036
Epoch 21, Val Loss: 4.85480
Epoch 22, Val Loss: 4.59126
Epoch 23, Val Loss: 4.45892
Epoch 24, Val Loss: 4.43803
Epoch 25, Val Loss: 4.79151
Epoch 26, Val Loss: 4.63170
Epoch 27, Val Loss: 4.42228
Epoch 28, Val Loss: 4.48325
Epoch 29, Val Loss: 4.38293
Epoch 30, Val Loss: 4.56255
Epoch 31, Val Loss: 4.32182
Epoch 32, Val Loss: 4.40577
Epoch 33, Val Loss: 4.29751
Epoch 34, Val Loss: 4.34794
Epoch 35, Val Loss: 4.59431
Epoch 36, Val Loss: 4.29544
Epoch 37, Val Loss: 4.37038
Epoch 38, Val Loss: 4.44083
Epoch 39, Val Loss: 4.41995
Epoch 40, Val Loss: 4.15000
Epoch 41, Val Loss: 4.44697
Epoch 42, Val Loss: 4.13662
Epoch 43, Val Loss: 4.21156
Epoch 44, Val Loss: 4.38825
Epoch 45, Val Loss: 4.13015
Epoch 46, Val Loss: 4.23595
Epoch 47, Val Loss: 4.24988
Epoch 48, Val Loss: 4.14635
Epoch 49, Val Loss: 4.14607
Epoch 50, Val Loss: 4.12275
Epoch 51, Val Loss: 4.51384
Epoch 52, Val Loss: 4.40967
Epoch 53, Val Loss: 4.24479
Epoch 54, Val Loss: 4.04608
Epoch 55, Val Loss: 4.16825
Epoch 56, Val Loss: 4.14677
Epoch 57, Val Loss: 4.24267
Epoch 58, Val Loss: 4.07923
Epoch 59, Val Loss: 4.47705
Epoch 60, Val Loss: 4.41627
Epoch 61, Val Loss: 4.22763
Epoch 62, Val Loss: 4.19040
Epoch 63, Val Loss: 4.19577
Epoch 64, Val Loss: 4.22160
Epoch 65, Val Loss: 4.49369
Epoch 66, Val Loss: 4.15507
Epoch 67, Val Loss: 4.12440
Epoch 68, Val Loss: 3.97518
Epoch 69, Val Loss: 4.55292
Epoch 70, Val Loss: 4.02388
Epoch 71, Val Loss: 4.06570
Epoch 72, Val Loss: 3.99430
Epoch 73, Val Loss: 4.23267
Epoch 74, Val Loss: 4.30569
Epoch 75, Val Loss: 3.91849
Epoch 76, Val Loss: 4.15751
Epoch 77, Val Loss: 4.01586
Epoch 78, Val Loss: 3.91158
Epoch 79, Val Loss: 3.94431
Epoch 80, Val Loss: 3.99967
Epoch 81, Val Loss: 4.06977
Epoch 82, Val Loss: 4.21458
Epoch 83, Val Loss: 3.92143
Epoch 84, Val Loss: 4.28878
Epoch 85, Val Loss: 3.99864
Epoch 86, Val Loss: 4.04866
Epoch 87, Val Loss: 4.03889
Epoch 88, Val Loss: 3.93102
Epoch 89, Val Loss: 3.88146
Epoch 90, Val Loss: 4.19596
Epoch 91, Val Loss: 3.94768
Epoch 92, Val Loss: 4.37438
Epoch 93, Val Loss: 4.24499
Epoch 94, Val Loss: 4.27468
Epoch 95, Val Loss: 4.48548
Epoch 96, Val Loss: 3.89189
Epoch 97, Val Loss: 4.04340
Epoch 98, Val Loss: 3.98872
Epoch 99, Val Loss: 3.95836
DID NOT SAVE RESULTS
{'MSE - mean': 4.354924433104079, 'MSE - std': 0.31062403239017833, 'R2 - mean': 0.5717044354438101, 'R2 - std': 0.0028129610759147217} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.28467
Epoch 1, Val Loss: 17.25565
Epoch 2, Val Loss: 7.30706
Epoch 3, Val Loss: 7.14297
Epoch 4, Val Loss: 6.55737
Epoch 5, Val Loss: 6.42630
Epoch 6, Val Loss: 6.22071
Epoch 7, Val Loss: 6.23555
Epoch 8, Val Loss: 6.00377
Epoch 9, Val Loss: 6.05617
Epoch 10, Val Loss: 6.05018
Epoch 11, Val Loss: 5.91187
Epoch 12, Val Loss: 5.86073
Epoch 13, Val Loss: 5.92269
Epoch 14, Val Loss: 5.79791
Epoch 15, Val Loss: 6.16129
Epoch 16, Val Loss: 5.71384
Epoch 17, Val Loss: 5.73648
Epoch 18, Val Loss: 5.81595
Epoch 19, Val Loss: 5.57178
Epoch 20, Val Loss: 5.55090
Epoch 21, Val Loss: 5.51467
Epoch 22, Val Loss: 5.42363
Epoch 23, Val Loss: 5.44051
Epoch 24, Val Loss: 5.51301
Epoch 25, Val Loss: 5.64795
Epoch 26, Val Loss: 5.40010
Epoch 27, Val Loss: 5.37506
Epoch 28, Val Loss: 5.21855
Epoch 29, Val Loss: 5.35212
Epoch 30, Val Loss: 5.17474
Epoch 31, Val Loss: 5.33087
Epoch 32, Val Loss: 5.71133
Epoch 33, Val Loss: 5.15571
Epoch 34, Val Loss: 5.24183
Epoch 35, Val Loss: 5.29310
Epoch 36, Val Loss: 5.69061
Epoch 37, Val Loss: 5.36434
Epoch 38, Val Loss: 4.99640
Epoch 39, Val Loss: 5.16499
Epoch 40, Val Loss: 5.17423
Epoch 41, Val Loss: 5.04565
Epoch 42, Val Loss: 5.15095
Epoch 43, Val Loss: 5.03669
Epoch 44, Val Loss: 4.92406
Epoch 45, Val Loss: 5.06003
Epoch 46, Val Loss: 5.05169
Epoch 47, Val Loss: 5.10852
Epoch 48, Val Loss: 5.06952
Epoch 49, Val Loss: 5.03082
Epoch 50, Val Loss: 5.45336
Epoch 51, Val Loss: 4.99819
Epoch 52, Val Loss: 5.22159
Epoch 53, Val Loss: 5.22065
Epoch 54, Val Loss: 5.00579
Epoch 55, Val Loss: 4.89792
Epoch 56, Val Loss: 5.23285
Epoch 57, Val Loss: 4.98014
Epoch 58, Val Loss: 5.02722
Epoch 59, Val Loss: 5.07606
Epoch 60, Val Loss: 5.73273
Epoch 61, Val Loss: 4.97080
Epoch 62, Val Loss: 4.87443
Epoch 63, Val Loss: 4.89640
Epoch 64, Val Loss: 4.91899
Epoch 65, Val Loss: 5.11787
Epoch 66, Val Loss: 4.92799
Epoch 67, Val Loss: 4.75746
Epoch 68, Val Loss: 5.00976
Epoch 69, Val Loss: 5.20906
Epoch 70, Val Loss: 4.91110
Epoch 71, Val Loss: 5.07720
Epoch 72, Val Loss: 5.32104
Epoch 73, Val Loss: 4.83638
Epoch 74, Val Loss: 5.11203
Epoch 75, Val Loss: 4.91686
Epoch 76, Val Loss: 4.92165
Epoch 77, Val Loss: 4.90126
Epoch 78, Val Loss: 4.88007
Epoch 79, Val Loss: 5.01235
Epoch 80, Val Loss: 5.31281
Epoch 81, Val Loss: 5.00975
Epoch 82, Val Loss: 4.84594
Epoch 83, Val Loss: 4.80613
Epoch 84, Val Loss: 5.09383
Epoch 85, Val Loss: 4.72244
Epoch 86, Val Loss: 4.68759
Epoch 87, Val Loss: 4.74336
Epoch 88, Val Loss: 4.98540
Epoch 89, Val Loss: 4.71044
Epoch 90, Val Loss: 4.79390
Epoch 91, Val Loss: 4.70219
Epoch 92, Val Loss: 4.74096
Epoch 93, Val Loss: 4.88702
Epoch 94, Val Loss: 4.96586
Epoch 95, Val Loss: 4.66233
Epoch 96, Val Loss: 4.82650
Epoch 97, Val Loss: 4.88385
Epoch 98, Val Loss: 5.11450
Epoch 99, Val Loss: 5.12347
DID NOT SAVE RESULTS
{'MSE - mean': 4.513478574508745, 'MSE - std': 0.33853166938810586, 'R2 - mean': 0.5560284784558059, 'R2 - std': 0.02228780881235125} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 39.17008
Epoch 1, Val Loss: 14.48114
Epoch 2, Val Loss: 6.32954
Epoch 3, Val Loss: 6.16093
Epoch 4, Val Loss: 5.89874
Epoch 5, Val Loss: 5.35670
Epoch 6, Val Loss: 5.07440
Epoch 7, Val Loss: 4.97499
Epoch 8, Val Loss: 5.06048
Epoch 9, Val Loss: 4.99452
Epoch 10, Val Loss: 4.77248
Epoch 11, Val Loss: 4.68944
Epoch 12, Val Loss: 4.57089
Epoch 13, Val Loss: 4.72550
Epoch 14, Val Loss: 4.57361
Epoch 15, Val Loss: 4.56229
Epoch 16, Val Loss: 4.54968
Epoch 17, Val Loss: 4.55208
Epoch 18, Val Loss: 4.49611
Epoch 19, Val Loss: 4.44250
Epoch 20, Val Loss: 4.48997
Epoch 21, Val Loss: 4.59996
Epoch 22, Val Loss: 4.64136
Epoch 23, Val Loss: 4.44905
Epoch 24, Val Loss: 4.26299
Epoch 25, Val Loss: 4.75760
Epoch 26, Val Loss: 4.31096
Epoch 27, Val Loss: 4.35870
Epoch 28, Val Loss: 4.41345
Epoch 29, Val Loss: 4.31726
Epoch 30, Val Loss: 4.20278
Epoch 31, Val Loss: 4.27405
Epoch 32, Val Loss: 4.22889
Epoch 33, Val Loss: 4.85659
Epoch 34, Val Loss: 4.15994
Epoch 35, Val Loss: 4.29097
Epoch 36, Val Loss: 4.47654
Epoch 37, Val Loss: 4.36178
Epoch 38, Val Loss: 4.05732
Epoch 39, Val Loss: 4.11282
Epoch 40, Val Loss: 4.26423
Epoch 41, Val Loss: 4.35504
Epoch 42, Val Loss: 4.05647
Epoch 43, Val Loss: 4.08429
Epoch 44, Val Loss: 3.99800
Epoch 45, Val Loss: 4.11275
Epoch 46, Val Loss: 4.09999
Epoch 47, Val Loss: 4.03709
Epoch 48, Val Loss: 4.00999
Epoch 49, Val Loss: 4.05340
Epoch 50, Val Loss: 3.90963
Epoch 51, Val Loss: 4.15664
Epoch 52, Val Loss: 4.19303
Epoch 53, Val Loss: 4.31536
Epoch 54, Val Loss: 4.17631
Epoch 55, Val Loss: 3.94383
Epoch 56, Val Loss: 4.11527
Epoch 57, Val Loss: 4.12247
Epoch 58, Val Loss: 3.99156
Epoch 59, Val Loss: 4.06660
Epoch 60, Val Loss: 4.16670
Epoch 61, Val Loss: 4.20223
Epoch 62, Val Loss: 3.91535
Epoch 63, Val Loss: 4.06712
Epoch 64, Val Loss: 4.25563
Epoch 65, Val Loss: 4.50095
Epoch 66, Val Loss: 4.04719
Epoch 67, Val Loss: 3.95026
Epoch 68, Val Loss: 3.90874
Epoch 69, Val Loss: 4.11381
Epoch 70, Val Loss: 3.92627
Epoch 71, Val Loss: 3.97090
Epoch 72, Val Loss: 3.95499
Epoch 73, Val Loss: 3.99387
Epoch 74, Val Loss: 4.05664
Epoch 75, Val Loss: 3.88076
Epoch 76, Val Loss: 4.00815
Epoch 77, Val Loss: 4.11669
Epoch 78, Val Loss: 4.08366
Epoch 79, Val Loss: 3.97429
Epoch 80, Val Loss: 4.12853
Epoch 81, Val Loss: 4.05678
Epoch 82, Val Loss: 4.24034
Epoch 83, Val Loss: 3.97973
Epoch 84, Val Loss: 3.89293
Epoch 85, Val Loss: 4.03869
Epoch 86, Val Loss: 3.93162
Epoch 87, Val Loss: 3.86337
Epoch 88, Val Loss: 3.93043
Epoch 89, Val Loss: 4.02293
Epoch 90, Val Loss: 3.81478
Epoch 91, Val Loss: 3.86930
Epoch 92, Val Loss: 3.91694
Epoch 93, Val Loss: 4.20294
Epoch 94, Val Loss: 4.19401
Epoch 95, Val Loss: 3.98819
Epoch 96, Val Loss: 3.91227
Epoch 97, Val Loss: 3.89226
Epoch 98, Val Loss: 3.84962
Epoch 99, Val Loss: 3.89746
DID NOT SAVE RESULTS
{'MSE - mean': 4.409259219226218, 'MSE - std': 0.34429317511466884, 'R2 - mean': 0.5575186893307567, 'R2 - std': 0.019473623227263228} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 37.07095
Epoch 1, Val Loss: 18.76347
Epoch 2, Val Loss: 8.44103
Epoch 3, Val Loss: 8.07642
Epoch 4, Val Loss: 8.05460
Epoch 5, Val Loss: 7.32655
Epoch 6, Val Loss: 7.24387
Epoch 7, Val Loss: 6.91830
Epoch 8, Val Loss: 7.01905
Epoch 9, Val Loss: 6.82592
Epoch 10, Val Loss: 6.75587
Epoch 11, Val Loss: 6.70219
Epoch 12, Val Loss: 7.11932
Epoch 13, Val Loss: 6.73246
Epoch 14, Val Loss: 6.64542
Epoch 15, Val Loss: 6.64775
Epoch 16, Val Loss: 6.36623
Epoch 17, Val Loss: 6.57086
Epoch 18, Val Loss: 6.40183
Epoch 19, Val Loss: 6.39726
Epoch 20, Val Loss: 6.44270
Epoch 21, Val Loss: 6.73682
Epoch 22, Val Loss: 6.24859
Epoch 23, Val Loss: 6.12424
Epoch 24, Val Loss: 6.07331
Epoch 25, Val Loss: 6.21914
Epoch 26, Val Loss: 6.07358
Epoch 27, Val Loss: 6.29393
Epoch 28, Val Loss: 6.15784
Epoch 29, Val Loss: 6.04487
Epoch 30, Val Loss: 6.45640
Epoch 31, Val Loss: 6.33476
Epoch 32, Val Loss: 6.21664
Epoch 33, Val Loss: 6.11319
Epoch 34, Val Loss: 6.64184
Epoch 35, Val Loss: 6.08537
Epoch 36, Val Loss: 6.77347
Epoch 37, Val Loss: 6.15802
Epoch 38, Val Loss: 6.48154
Epoch 39, Val Loss: 6.22425
Epoch 40, Val Loss: 6.12614
Epoch 41, Val Loss: 6.28527
Epoch 42, Val Loss: 6.04983
Epoch 43, Val Loss: 6.43965
Epoch 44, Val Loss: 5.99834
Epoch 45, Val Loss: 6.07782
Epoch 46, Val Loss: 6.29652
Epoch 47, Val Loss: 5.93738
Epoch 48, Val Loss: 6.27207
Epoch 49, Val Loss: 6.06306
Epoch 50, Val Loss: 6.01153
Epoch 51, Val Loss: 6.23102
Epoch 52, Val Loss: 6.12611
Epoch 53, Val Loss: 6.03360
Epoch 54, Val Loss: 5.84567
Epoch 55, Val Loss: 6.24493
Epoch 56, Val Loss: 5.84225
Epoch 57, Val Loss: 6.16806
Epoch 58, Val Loss: 5.75633
Epoch 59, Val Loss: 5.88952
Epoch 60, Val Loss: 5.87277
Epoch 61, Val Loss: 5.99874
Epoch 62, Val Loss: 6.11694
Epoch 63, Val Loss: 5.92259
Epoch 64, Val Loss: 6.02374
Epoch 65, Val Loss: 6.00339
Epoch 66, Val Loss: 6.15573
Epoch 67, Val Loss: 5.96245
Epoch 68, Val Loss: 6.85719
Epoch 69, Val Loss: 5.85309
Epoch 70, Val Loss: 5.89505
Epoch 71, Val Loss: 6.01142
Epoch 72, Val Loss: 5.87174
Epoch 73, Val Loss: 6.01301
Epoch 74, Val Loss: 5.94436
Epoch 75, Val Loss: 5.99447
Epoch 76, Val Loss: 6.10008
Epoch 77, Val Loss: 6.59982
Epoch 78, Val Loss: 6.22510
Epoch 79, Val Loss: 6.02163
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.674091142015927, 'MSE - std': 0.6126777469913602, 'R2 - mean': 0.5511845652367577, 'R2 - std': 0.021537458379080752} 
 

Results After CV: {'MSE - mean': 4.674091142015927, 'MSE - std': 0.6126777469913602, 'R2 - mean': 0.5511845652367577, 'R2 - std': 0.021537458379080752}
Train time: 31.60696449060051
Inference time: 0.04672065659833606
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 66 finished with value: 4.674091142015927 and parameters: {'p_m': 0.4804217555592652, 'alpha': 3.2100050433627905, 'K': 3, 'beta': 0.5892907142428595}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.88199
Epoch 1, Val Loss: 12.81762
Epoch 2, Val Loss: 7.94712
Epoch 3, Val Loss: 7.20278
Epoch 4, Val Loss: 6.93321
Epoch 5, Val Loss: 6.70085
Epoch 6, Val Loss: 6.60516
Epoch 7, Val Loss: 6.59238
Epoch 8, Val Loss: 6.33074
Epoch 9, Val Loss: 6.32873
Epoch 10, Val Loss: 6.17880
Epoch 11, Val Loss: 6.21095
Epoch 12, Val Loss: 6.07354
Epoch 13, Val Loss: 6.01375
Epoch 14, Val Loss: 6.31985
Epoch 15, Val Loss: 5.90934
Epoch 16, Val Loss: 6.15965
Epoch 17, Val Loss: 5.89532
Epoch 18, Val Loss: 5.84354
Epoch 19, Val Loss: 5.73984
Epoch 20, Val Loss: 5.75036
Epoch 21, Val Loss: 5.73546
Epoch 22, Val Loss: 5.51999
Epoch 23, Val Loss: 5.55599
Epoch 24, Val Loss: 5.47199
Epoch 25, Val Loss: 5.49518
Epoch 26, Val Loss: 6.21404
Epoch 27, Val Loss: 5.42260
Epoch 28, Val Loss: 5.59947
Epoch 29, Val Loss: 5.65032
Epoch 30, Val Loss: 5.35641
Epoch 31, Val Loss: 5.36484
Epoch 32, Val Loss: 5.36681
Epoch 33, Val Loss: 5.23653
Epoch 34, Val Loss: 5.08610
Epoch 35, Val Loss: 5.21695
Epoch 36, Val Loss: 5.32432
Epoch 37, Val Loss: 5.03960
Epoch 38, Val Loss: 5.07863
Epoch 39, Val Loss: 5.16744
Epoch 40, Val Loss: 4.99115
Epoch 41, Val Loss: 5.40278
Epoch 42, Val Loss: 5.03063
Epoch 43, Val Loss: 4.97458
Epoch 44, Val Loss: 4.93715
Epoch 45, Val Loss: 4.88652
Epoch 46, Val Loss: 4.90910
Epoch 47, Val Loss: 4.84610
Epoch 48, Val Loss: 4.86272
Epoch 49, Val Loss: 5.13778
Epoch 50, Val Loss: 4.80785
Epoch 51, Val Loss: 4.73458
Epoch 52, Val Loss: 5.15923
Epoch 53, Val Loss: 4.76276
Epoch 54, Val Loss: 4.87958
Epoch 55, Val Loss: 4.72197
Epoch 56, Val Loss: 4.83591
Epoch 57, Val Loss: 5.08005
Epoch 58, Val Loss: 4.80644
Epoch 59, Val Loss: 4.97090
Epoch 60, Val Loss: 4.72712
Epoch 61, Val Loss: 5.60216
Epoch 62, Val Loss: 4.69190
Epoch 63, Val Loss: 4.77890
Epoch 64, Val Loss: 4.66159
Epoch 65, Val Loss: 4.96514
Epoch 66, Val Loss: 4.83852
Epoch 67, Val Loss: 4.78561
Epoch 68, Val Loss: 4.76971
Epoch 69, Val Loss: 4.86062
Epoch 70, Val Loss: 4.86609
Epoch 71, Val Loss: 4.70542
Epoch 72, Val Loss: 4.70719
Epoch 73, Val Loss: 4.95468
Epoch 74, Val Loss: 4.67552
Epoch 75, Val Loss: 4.75422
Epoch 76, Val Loss: 4.97736
Epoch 77, Val Loss: 4.76433
Epoch 78, Val Loss: 4.76695
Epoch 79, Val Loss: 5.11874
Epoch 80, Val Loss: 4.67189
Epoch 81, Val Loss: 4.70938
Epoch 82, Val Loss: 4.75811
Epoch 83, Val Loss: 4.76169
Epoch 84, Val Loss: 4.60705
Epoch 85, Val Loss: 4.60648
Epoch 86, Val Loss: 4.84431
Epoch 87, Val Loss: 4.89581
Epoch 88, Val Loss: 4.68097
Epoch 89, Val Loss: 4.82801
Epoch 90, Val Loss: 4.84188
Epoch 91, Val Loss: 4.69941
Epoch 92, Val Loss: 4.63964
Epoch 93, Val Loss: 4.81352
Epoch 94, Val Loss: 4.64546
Epoch 95, Val Loss: 4.79458
Epoch 96, Val Loss: 4.87162
Epoch 97, Val Loss: 4.74487
Epoch 98, Val Loss: 4.82194
Epoch 99, Val Loss: 4.76093
DID NOT SAVE RESULTS
{'MSE - mean': 4.712955613373071, 'MSE - std': 0.0, 'R2 - mean': 0.5701940212826584, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 27.75294
Epoch 1, Val Loss: 8.63173
Epoch 2, Val Loss: 6.84457
Epoch 3, Val Loss: 6.24032
Epoch 4, Val Loss: 5.99053
Epoch 5, Val Loss: 5.79773
Epoch 6, Val Loss: 5.68443
Epoch 7, Val Loss: 5.66052
Epoch 8, Val Loss: 5.13744
Epoch 9, Val Loss: 5.27536
Epoch 10, Val Loss: 4.92136
Epoch 11, Val Loss: 4.72851
Epoch 12, Val Loss: 4.54322
Epoch 13, Val Loss: 4.82005
Epoch 14, Val Loss: 4.91234
Epoch 15, Val Loss: 5.04378
Epoch 16, Val Loss: 4.50438
Epoch 17, Val Loss: 4.25998
Epoch 18, Val Loss: 4.88630
Epoch 19, Val Loss: 4.55082
Epoch 20, Val Loss: 4.45744
Epoch 21, Val Loss: 4.13792
Epoch 22, Val Loss: 4.63270
Epoch 23, Val Loss: 4.24698
Epoch 24, Val Loss: 4.15220
Epoch 25, Val Loss: 4.66029
Epoch 26, Val Loss: 4.24378
Epoch 27, Val Loss: 4.41753
Epoch 28, Val Loss: 4.32659
Epoch 29, Val Loss: 4.20879
Epoch 30, Val Loss: 4.10395
Epoch 31, Val Loss: 4.19838
Epoch 32, Val Loss: 4.14217
Epoch 33, Val Loss: 4.12806
Epoch 34, Val Loss: 4.42569
Epoch 35, Val Loss: 4.47073
Epoch 36, Val Loss: 4.37305
Epoch 37, Val Loss: 4.99937
Epoch 38, Val Loss: 4.34556
Epoch 39, Val Loss: 3.94352
Epoch 40, Val Loss: 4.00878
Epoch 41, Val Loss: 4.16644
Epoch 42, Val Loss: 4.05947
Epoch 43, Val Loss: 4.10203
Epoch 44, Val Loss: 4.11050
Epoch 45, Val Loss: 4.37080
Epoch 46, Val Loss: 4.00995
Epoch 47, Val Loss: 4.10174
Epoch 48, Val Loss: 4.34202
Epoch 49, Val Loss: 4.03476
Epoch 50, Val Loss: 4.13413
Epoch 51, Val Loss: 4.02726
Epoch 52, Val Loss: 4.73280
Epoch 53, Val Loss: 4.84674
Epoch 54, Val Loss: 3.98819
Epoch 55, Val Loss: 4.09784
Epoch 56, Val Loss: 4.21523
Epoch 57, Val Loss: 4.44655
Epoch 58, Val Loss: 3.91090
Epoch 59, Val Loss: 3.87804
Epoch 60, Val Loss: 4.34146
Epoch 61, Val Loss: 4.30545
Epoch 62, Val Loss: 3.95667
Epoch 63, Val Loss: 4.59998
Epoch 64, Val Loss: 3.89298
Epoch 65, Val Loss: 4.43496
Epoch 66, Val Loss: 4.73878
Epoch 67, Val Loss: 4.28236
Epoch 68, Val Loss: 4.03351
Epoch 69, Val Loss: 4.64369
Epoch 70, Val Loss: 3.92002
Epoch 71, Val Loss: 3.86149
Epoch 72, Val Loss: 4.03789
Epoch 73, Val Loss: 4.50470
Epoch 74, Val Loss: 3.89291
Epoch 75, Val Loss: 4.13730
Epoch 76, Val Loss: 3.97892
Epoch 77, Val Loss: 3.85493
Epoch 78, Val Loss: 4.02958
Epoch 79, Val Loss: 4.10804
Epoch 80, Val Loss: 3.98278
Epoch 81, Val Loss: 3.95289
Epoch 82, Val Loss: 4.79577
Epoch 83, Val Loss: 3.88377
Epoch 84, Val Loss: 3.92613
Epoch 85, Val Loss: 3.87384
Epoch 86, Val Loss: 3.81412
Epoch 87, Val Loss: 3.89958
Epoch 88, Val Loss: 3.98543
Epoch 89, Val Loss: 4.15325
Epoch 90, Val Loss: 3.83043
Epoch 91, Val Loss: 4.07871
Epoch 92, Val Loss: 4.10344
Epoch 93, Val Loss: 4.77257
Epoch 94, Val Loss: 3.95106
Epoch 95, Val Loss: 5.10329
Epoch 96, Val Loss: 4.06325
Epoch 97, Val Loss: 4.13854
Epoch 98, Val Loss: 4.03952
Epoch 99, Val Loss: 4.22105
DID NOT SAVE RESULTS
{'MSE - mean': 4.343804841359359, 'MSE - std': 0.36915077201371194, 'R2 - mean': 0.5732547776273352, 'R2 - std': 0.0030607563446768404} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.55535
Epoch 1, Val Loss: 13.19554
Epoch 2, Val Loss: 6.33945
Epoch 3, Val Loss: 5.66920
Epoch 4, Val Loss: 5.62150
Epoch 5, Val Loss: 5.06397
Epoch 6, Val Loss: 5.02615
Epoch 7, Val Loss: 5.04845
Epoch 8, Val Loss: 5.29812
Epoch 9, Val Loss: 4.85609
Epoch 10, Val Loss: 4.99380
Epoch 11, Val Loss: 5.14586
Epoch 12, Val Loss: 5.13003
Epoch 13, Val Loss: 4.98882
Epoch 14, Val Loss: 4.82521
Epoch 15, Val Loss: 5.15265
Epoch 16, Val Loss: 4.90323
Epoch 17, Val Loss: 4.64381
Epoch 18, Val Loss: 4.73335
Epoch 19, Val Loss: 4.77253
Epoch 20, Val Loss: 4.67119
Epoch 21, Val Loss: 4.81562
Epoch 22, Val Loss: 4.61292
Epoch 23, Val Loss: 5.14761
Epoch 24, Val Loss: 4.89381
Epoch 25, Val Loss: 4.53834
Epoch 26, Val Loss: 4.65940
Epoch 27, Val Loss: 4.61714
Epoch 28, Val Loss: 4.73196
Epoch 29, Val Loss: 4.78639
Epoch 30, Val Loss: 4.63925
Epoch 31, Val Loss: 4.68609
Epoch 32, Val Loss: 4.73629
Epoch 33, Val Loss: 4.77643
Epoch 34, Val Loss: 4.58912
Epoch 35, Val Loss: 4.56307
Epoch 36, Val Loss: 5.05900
Epoch 37, Val Loss: 4.64138
Epoch 38, Val Loss: 4.53355
Epoch 39, Val Loss: 4.59478
Epoch 40, Val Loss: 4.69093
Epoch 41, Val Loss: 4.55806
Epoch 42, Val Loss: 4.61568
Epoch 43, Val Loss: 4.75821
Epoch 44, Val Loss: 4.53485
Epoch 45, Val Loss: 4.65092
Epoch 46, Val Loss: 4.63246
Epoch 47, Val Loss: 4.88263
Epoch 48, Val Loss: 4.60796
Epoch 49, Val Loss: 4.72709
Epoch 50, Val Loss: 4.73073
Epoch 51, Val Loss: 4.58852
Epoch 52, Val Loss: 4.84080
Epoch 53, Val Loss: 4.59928
Epoch 54, Val Loss: 4.80066
Epoch 55, Val Loss: 4.60750
Epoch 56, Val Loss: 4.51011
Epoch 57, Val Loss: 4.53402
Epoch 58, Val Loss: 4.65701
Epoch 59, Val Loss: 4.63924
Epoch 60, Val Loss: 4.58731
Epoch 61, Val Loss: 4.51012
Epoch 62, Val Loss: 4.61683
Epoch 63, Val Loss: 4.52323
Epoch 64, Val Loss: 4.90274
Epoch 65, Val Loss: 4.53989
Epoch 66, Val Loss: 4.45364
Epoch 67, Val Loss: 4.75318
Epoch 68, Val Loss: 4.64340
Epoch 69, Val Loss: 4.51886
Epoch 70, Val Loss: 4.48934
Epoch 71, Val Loss: 4.56688
Epoch 72, Val Loss: 4.48429
Epoch 73, Val Loss: 4.59167
Epoch 74, Val Loss: 5.11387
Epoch 75, Val Loss: 4.47662
Epoch 76, Val Loss: 4.50892
Epoch 77, Val Loss: 4.54816
Epoch 78, Val Loss: 4.58248
Epoch 79, Val Loss: 4.47697
Epoch 80, Val Loss: 4.52019
Epoch 81, Val Loss: 4.53309
Epoch 82, Val Loss: 4.58055
Epoch 83, Val Loss: 4.51461
Epoch 84, Val Loss: 4.90463
Epoch 85, Val Loss: 5.07537
Epoch 86, Val Loss: 4.92738
Epoch 87, Val Loss: 4.80571
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.401752179183215, 'MSE - std': 0.3123523377650479, 'R2 - mean': 0.5673263357060088, 'R2 - std': 0.0087486189479674} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.58850
Epoch 1, Val Loss: 9.09237
Epoch 2, Val Loss: 6.20190
Epoch 3, Val Loss: 5.82750
Epoch 4, Val Loss: 5.62387
Epoch 5, Val Loss: 5.23599
Epoch 6, Val Loss: 5.18464
Epoch 7, Val Loss: 5.08025
Epoch 8, Val Loss: 5.12391
Epoch 9, Val Loss: 4.92065
Epoch 10, Val Loss: 4.59778
Epoch 11, Val Loss: 4.44387
Epoch 12, Val Loss: 4.61102
Epoch 13, Val Loss: 4.50550
Epoch 14, Val Loss: 4.52862
Epoch 15, Val Loss: 4.39121
Epoch 16, Val Loss: 4.51335
Epoch 17, Val Loss: 4.73221
Epoch 18, Val Loss: 4.43945
Epoch 19, Val Loss: 4.31262
Epoch 20, Val Loss: 4.42132
Epoch 21, Val Loss: 4.29719
Epoch 22, Val Loss: 4.29944
Epoch 23, Val Loss: 4.66289
Epoch 24, Val Loss: 4.25308
Epoch 25, Val Loss: 4.18236
Epoch 26, Val Loss: 4.15909
Epoch 27, Val Loss: 4.22287
Epoch 28, Val Loss: 4.33898
Epoch 29, Val Loss: 4.08363
Epoch 30, Val Loss: 4.12520
Epoch 31, Val Loss: 4.14063
Epoch 32, Val Loss: 4.50213
Epoch 33, Val Loss: 4.14314
Epoch 34, Val Loss: 4.23910
Epoch 35, Val Loss: 4.05614
Epoch 36, Val Loss: 4.11336
Epoch 37, Val Loss: 4.50959
Epoch 38, Val Loss: 4.06458
Epoch 39, Val Loss: 4.14822
Epoch 40, Val Loss: 4.00897
Epoch 41, Val Loss: 4.01565
Epoch 42, Val Loss: 4.13174
Epoch 43, Val Loss: 4.17256
Epoch 44, Val Loss: 3.96610
Epoch 45, Val Loss: 3.97991
Epoch 46, Val Loss: 4.21996
Epoch 47, Val Loss: 4.10261
Epoch 48, Val Loss: 4.05666
Epoch 49, Val Loss: 4.04312
Epoch 50, Val Loss: 4.06141
Epoch 51, Val Loss: 3.97333
Epoch 52, Val Loss: 4.05323
Epoch 53, Val Loss: 4.25445
Epoch 54, Val Loss: 3.95491
Epoch 55, Val Loss: 4.19328
Epoch 56, Val Loss: 3.95859
Epoch 57, Val Loss: 4.04821
Epoch 58, Val Loss: 3.90610
Epoch 59, Val Loss: 3.96293
Epoch 60, Val Loss: 4.03896
Epoch 61, Val Loss: 3.99355
Epoch 62, Val Loss: 4.01558
Epoch 63, Val Loss: 4.23894
Epoch 64, Val Loss: 4.37242
Epoch 65, Val Loss: 3.83970
Epoch 66, Val Loss: 3.94680
Epoch 67, Val Loss: 4.03220
Epoch 68, Val Loss: 4.18110
Epoch 69, Val Loss: 3.84059
Epoch 70, Val Loss: 3.85735
Epoch 71, Val Loss: 4.12200
Epoch 72, Val Loss: 4.16801
Epoch 73, Val Loss: 3.92290
Epoch 74, Val Loss: 4.05951
Epoch 75, Val Loss: 4.15589
Epoch 76, Val Loss: 3.81215
Epoch 77, Val Loss: 4.09232
Epoch 78, Val Loss: 4.04506
Epoch 79, Val Loss: 4.52248
Epoch 80, Val Loss: 3.94682
Epoch 81, Val Loss: 3.93347
Epoch 82, Val Loss: 3.92486
Epoch 83, Val Loss: 4.09117
Epoch 84, Val Loss: 3.99552
Epoch 85, Val Loss: 3.86260
Epoch 86, Val Loss: 3.84251
Epoch 87, Val Loss: 3.84873
Epoch 88, Val Loss: 4.34343
Epoch 89, Val Loss: 4.35596
Epoch 90, Val Loss: 4.39088
Epoch 91, Val Loss: 3.90573
Epoch 92, Val Loss: 3.82210
Epoch 93, Val Loss: 4.25060
Epoch 94, Val Loss: 4.28934
Epoch 95, Val Loss: 4.16904
Epoch 96, Val Loss: 3.88526
Epoch 97, Val Loss: 3.93361
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.3348752385204055, 'MSE - std': 0.29426274442701517, 'R2 - mean': 0.5649858730598312, 'R2 - std': 0.008592848556620136} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 45.31059
Epoch 1, Val Loss: 17.22062
Epoch 2, Val Loss: 8.77357
Epoch 3, Val Loss: 8.88045
Epoch 4, Val Loss: 8.13069
Epoch 5, Val Loss: 7.84811
Epoch 6, Val Loss: 7.36534
Epoch 7, Val Loss: 7.25881
Epoch 8, Val Loss: 6.81291
Epoch 9, Val Loss: 6.64731
Epoch 10, Val Loss: 6.44743
Epoch 11, Val Loss: 6.21847
Epoch 12, Val Loss: 6.36117
Epoch 13, Val Loss: 6.29319
Epoch 14, Val Loss: 6.17809
Epoch 15, Val Loss: 6.15900
Epoch 16, Val Loss: 6.61281
Epoch 17, Val Loss: 6.74363
Epoch 18, Val Loss: 6.96892
Epoch 19, Val Loss: 6.27578
Epoch 20, Val Loss: 5.90632
Epoch 21, Val Loss: 5.86805
Epoch 22, Val Loss: 5.96873
Epoch 23, Val Loss: 5.87836
Epoch 24, Val Loss: 6.05725
Epoch 25, Val Loss: 6.44077
Epoch 26, Val Loss: 6.21756
Epoch 27, Val Loss: 5.92053
Epoch 28, Val Loss: 5.77071
Epoch 29, Val Loss: 5.99271
Epoch 30, Val Loss: 5.62319
Epoch 31, Val Loss: 5.87665
Epoch 32, Val Loss: 5.66660
Epoch 33, Val Loss: 5.67849
Epoch 34, Val Loss: 5.78776
Epoch 35, Val Loss: 5.42447
Epoch 36, Val Loss: 5.68439
Epoch 37, Val Loss: 5.57240
Epoch 38, Val Loss: 5.50039
Epoch 39, Val Loss: 5.53238
Epoch 40, Val Loss: 5.43880
Epoch 41, Val Loss: 5.42646
Epoch 42, Val Loss: 5.54822
Epoch 43, Val Loss: 5.51305
Epoch 44, Val Loss: 5.47827
Epoch 45, Val Loss: 5.55012
Epoch 46, Val Loss: 5.37848
Epoch 47, Val Loss: 5.81303
Epoch 48, Val Loss: 5.64302
Epoch 49, Val Loss: 6.04173
Epoch 50, Val Loss: 5.62282
Epoch 51, Val Loss: 5.99436
Epoch 52, Val Loss: 5.56232
Epoch 53, Val Loss: 5.67783
Epoch 54, Val Loss: 5.50725
Epoch 55, Val Loss: 6.15051
Epoch 56, Val Loss: 5.57851
Epoch 57, Val Loss: 5.44733
Epoch 58, Val Loss: 5.52307
Epoch 59, Val Loss: 5.48742
Epoch 60, Val Loss: 5.59462
Epoch 61, Val Loss: 5.46498
Epoch 62, Val Loss: 5.41348
Epoch 63, Val Loss: 5.51841
Epoch 64, Val Loss: 6.00010
Epoch 65, Val Loss: 5.42818
Epoch 66, Val Loss: 5.59597
Epoch 67, Val Loss: 5.98181
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.538122824084438, 'MSE - std': 0.4842631251258039, 'R2 - mean': 0.5634816238596987, 'R2 - std': 0.008253526499503406} 
 

Results After CV: {'MSE - mean': 4.538122824084438, 'MSE - std': 0.4842631251258039, 'R2 - mean': 0.5634816238596987, 'R2 - std': 0.008253526499503406}
Train time: 44.34011955440074
Inference time: 0.04775458039948717
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 67 finished with value: 4.538122824084438 and parameters: {'p_m': 0.5257937445247223, 'alpha': 0.9073130083243313, 'K': 5, 'beta': 0.11019073958812683}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 32.83554
Epoch 1, Val Loss: 12.83007
Epoch 2, Val Loss: 7.91591
Epoch 3, Val Loss: 6.94981
Epoch 4, Val Loss: 6.85771
Epoch 5, Val Loss: 6.93064
Epoch 6, Val Loss: 6.67190
Epoch 7, Val Loss: 6.83541
Epoch 8, Val Loss: 6.55221
Epoch 9, Val Loss: 6.47003
Epoch 10, Val Loss: 6.65045
Epoch 11, Val Loss: 6.45744
Epoch 12, Val Loss: 6.73062
Epoch 13, Val Loss: 6.19472
Epoch 14, Val Loss: 6.42613
Epoch 15, Val Loss: 6.43711
Epoch 16, Val Loss: 6.30539
Epoch 17, Val Loss: 6.21711
Epoch 18, Val Loss: 6.70768
Epoch 19, Val Loss: 6.08948
Epoch 20, Val Loss: 6.33330
Epoch 21, Val Loss: 6.10441
Epoch 22, Val Loss: 6.25054
Epoch 23, Val Loss: 6.14655
Epoch 24, Val Loss: 5.93923
Epoch 25, Val Loss: 5.98694
Epoch 26, Val Loss: 6.02492
Epoch 27, Val Loss: 5.81286
Epoch 28, Val Loss: 5.83060
Epoch 29, Val Loss: 5.98001
Epoch 30, Val Loss: 6.28462
Epoch 31, Val Loss: 5.84022
Epoch 32, Val Loss: 6.23126
Epoch 33, Val Loss: 5.96273
Epoch 34, Val Loss: 5.76832
Epoch 35, Val Loss: 5.78771
Epoch 36, Val Loss: 5.60225
Epoch 37, Val Loss: 5.62835
Epoch 38, Val Loss: 5.60834
Epoch 39, Val Loss: 5.62194
Epoch 40, Val Loss: 5.76504
Epoch 41, Val Loss: 5.59538
Epoch 42, Val Loss: 5.53970
Epoch 43, Val Loss: 5.49570
Epoch 44, Val Loss: 6.04081
Epoch 45, Val Loss: 5.51001
Epoch 46, Val Loss: 5.92795
Epoch 47, Val Loss: 5.50258
Epoch 48, Val Loss: 5.55274
Epoch 49, Val Loss: 5.54951
Epoch 50, Val Loss: 5.53201
Epoch 51, Val Loss: 5.68504
Epoch 52, Val Loss: 5.71082
Epoch 53, Val Loss: 5.47062
Epoch 54, Val Loss: 5.82603
Epoch 55, Val Loss: 5.43445
Epoch 56, Val Loss: 5.43962
Epoch 57, Val Loss: 5.25968
Epoch 58, Val Loss: 5.55930
Epoch 59, Val Loss: 5.54202
Epoch 60, Val Loss: 5.88075
Epoch 61, Val Loss: 5.91277
Epoch 62, Val Loss: 5.75271
Epoch 63, Val Loss: 5.38952
Epoch 64, Val Loss: 5.26547
Epoch 65, Val Loss: 5.45426
Epoch 66, Val Loss: 5.61568
Epoch 67, Val Loss: 5.84261
Epoch 68, Val Loss: 5.76983
Epoch 69, Val Loss: 5.97026
Epoch 70, Val Loss: 5.57289
Epoch 71, Val Loss: 5.69469
Epoch 72, Val Loss: 5.19698
Epoch 73, Val Loss: 5.32357
Epoch 74, Val Loss: 5.47011
Epoch 75, Val Loss: 5.26697
Epoch 76, Val Loss: 5.25410
Epoch 77, Val Loss: 5.54963
Epoch 78, Val Loss: 5.22642
Epoch 79, Val Loss: 5.28201
Epoch 80, Val Loss: 5.52755
Epoch 81, Val Loss: 5.55378
Epoch 82, Val Loss: 5.21716
Epoch 83, Val Loss: 5.20965
Epoch 84, Val Loss: 5.59259
Epoch 85, Val Loss: 5.49164
Epoch 86, Val Loss: 5.51510
Epoch 87, Val Loss: 5.24650
Epoch 88, Val Loss: 5.20023
Epoch 89, Val Loss: 5.34585
Epoch 90, Val Loss: 5.15265
Epoch 91, Val Loss: 5.28816
Epoch 92, Val Loss: 5.08978
Epoch 93, Val Loss: 5.60981
Epoch 94, Val Loss: 5.21547
Epoch 95, Val Loss: 5.20683
Epoch 96, Val Loss: 5.23444
Epoch 97, Val Loss: 5.12275
Epoch 98, Val Loss: 5.38253
Epoch 99, Val Loss: 5.10108
DID NOT SAVE RESULTS
{'MSE - mean': 5.265589381294904, 'MSE - std': 0.0, 'R2 - mean': 0.5197956477397556, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 29.62439
Epoch 1, Val Loss: 11.02958
Epoch 2, Val Loss: 5.97993
Epoch 3, Val Loss: 5.88195
Epoch 4, Val Loss: 5.66909
Epoch 5, Val Loss: 5.45720
Epoch 6, Val Loss: 5.48557
Epoch 7, Val Loss: 5.51695
Epoch 8, Val Loss: 5.53765
Epoch 9, Val Loss: 5.30782
Epoch 10, Val Loss: 5.40091
Epoch 11, Val Loss: 5.35729
Epoch 12, Val Loss: 5.19126
Epoch 13, Val Loss: 5.13543
Epoch 14, Val Loss: 5.49465
Epoch 15, Val Loss: 5.44424
Epoch 16, Val Loss: 5.56891
Epoch 17, Val Loss: 5.18370
Epoch 18, Val Loss: 5.13786
Epoch 19, Val Loss: 5.67374
Epoch 20, Val Loss: 5.12953
Epoch 21, Val Loss: 5.18680
Epoch 22, Val Loss: 5.37574
Epoch 23, Val Loss: 4.92025
Epoch 24, Val Loss: 5.50100
Epoch 25, Val Loss: 4.92203
Epoch 26, Val Loss: 5.03353
Epoch 27, Val Loss: 5.01259
Epoch 28, Val Loss: 4.89840
Epoch 29, Val Loss: 4.88458
Epoch 30, Val Loss: 4.92214
Epoch 31, Val Loss: 5.03808
Epoch 32, Val Loss: 4.85747
Epoch 33, Val Loss: 5.45233
Epoch 34, Val Loss: 4.97889
Epoch 35, Val Loss: 5.07707
Epoch 36, Val Loss: 5.36824
Epoch 37, Val Loss: 4.76306
Epoch 38, Val Loss: 4.90941
Epoch 39, Val Loss: 5.07633
Epoch 40, Val Loss: 5.11444
Epoch 41, Val Loss: 4.77261
Epoch 42, Val Loss: 4.89230
Epoch 43, Val Loss: 4.76984
Epoch 44, Val Loss: 4.71787
Epoch 45, Val Loss: 4.84911
Epoch 46, Val Loss: 4.72005
Epoch 47, Val Loss: 4.70964
Epoch 48, Val Loss: 4.69760
Epoch 49, Val Loss: 4.69817
Epoch 50, Val Loss: 4.73981
Epoch 51, Val Loss: 4.99829
Epoch 52, Val Loss: 5.00782
Epoch 53, Val Loss: 4.60407
Epoch 54, Val Loss: 4.69968
Epoch 55, Val Loss: 4.66344
Epoch 56, Val Loss: 4.71415
Epoch 57, Val Loss: 4.76331
Epoch 58, Val Loss: 4.82418
Epoch 59, Val Loss: 5.04334
Epoch 60, Val Loss: 4.73829
Epoch 61, Val Loss: 5.11493
Epoch 62, Val Loss: 5.09186
Epoch 63, Val Loss: 4.77035
Epoch 64, Val Loss: 4.61715
Epoch 65, Val Loss: 4.86181
Epoch 66, Val Loss: 4.65443
Epoch 67, Val Loss: 4.61049
Epoch 68, Val Loss: 4.63934
Epoch 69, Val Loss: 4.74106
Epoch 70, Val Loss: 4.75091
Epoch 71, Val Loss: 4.59956
Epoch 72, Val Loss: 4.48175
Epoch 73, Val Loss: 4.57164
Epoch 74, Val Loss: 4.90539
Epoch 75, Val Loss: 4.53131
Epoch 76, Val Loss: 4.47096
Epoch 77, Val Loss: 4.47905
Epoch 78, Val Loss: 4.54807
Epoch 79, Val Loss: 4.72122
Epoch 80, Val Loss: 4.75142
Epoch 81, Val Loss: 4.93660
Epoch 82, Val Loss: 4.49701
Epoch 83, Val Loss: 4.57532
Epoch 84, Val Loss: 4.76667
Epoch 85, Val Loss: 4.50847
Epoch 86, Val Loss: 4.51988
Epoch 87, Val Loss: 4.73738
Epoch 88, Val Loss: 4.40019
Epoch 89, Val Loss: 4.50681
Epoch 90, Val Loss: 4.64619
Epoch 91, Val Loss: 4.30282
Epoch 92, Val Loss: 5.15084
Epoch 93, Val Loss: 4.45303
Epoch 94, Val Loss: 4.31899
Epoch 95, Val Loss: 4.40333
Epoch 96, Val Loss: 4.53844
Epoch 97, Val Loss: 4.95099
Epoch 98, Val Loss: 4.71004
Epoch 99, Val Loss: 4.43072
DID NOT SAVE RESULTS
{'MSE - mean': 4.930518532427676, 'MSE - std': 0.3350708488672276, 'R2 - mean': 0.5149683578082687, 'R2 - std': 0.0048272899314869555} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 35.26464
Epoch 1, Val Loss: 10.95298
Epoch 2, Val Loss: 7.30599
Epoch 3, Val Loss: 6.27544
Epoch 4, Val Loss: 6.51748
Epoch 5, Val Loss: 6.31543
Epoch 6, Val Loss: 6.80427
Epoch 7, Val Loss: 6.24659
Epoch 8, Val Loss: 6.47877
Epoch 9, Val Loss: 6.10522
Epoch 10, Val Loss: 6.23825
Epoch 11, Val Loss: 6.19349
Epoch 12, Val Loss: 6.24613
Epoch 13, Val Loss: 5.95359
Epoch 14, Val Loss: 6.51628
Epoch 15, Val Loss: 5.97587
Epoch 16, Val Loss: 6.20591
Epoch 17, Val Loss: 6.54642
Epoch 18, Val Loss: 6.00712
Epoch 19, Val Loss: 6.07706
Epoch 20, Val Loss: 6.42539
Epoch 21, Val Loss: 5.78190
Epoch 22, Val Loss: 5.83853
Epoch 23, Val Loss: 5.85352
Epoch 24, Val Loss: 5.80498
Epoch 25, Val Loss: 5.69653
Epoch 26, Val Loss: 5.94567
Epoch 27, Val Loss: 5.70446
Epoch 28, Val Loss: 5.61573
Epoch 29, Val Loss: 5.72060
Epoch 30, Val Loss: 5.53205
Epoch 31, Val Loss: 5.55025
Epoch 32, Val Loss: 5.54147
Epoch 33, Val Loss: 5.40554
Epoch 34, Val Loss: 5.39172
Epoch 35, Val Loss: 6.15374
Epoch 36, Val Loss: 5.40961
Epoch 37, Val Loss: 5.50652
Epoch 38, Val Loss: 5.53481
Epoch 39, Val Loss: 5.66580
Epoch 40, Val Loss: 5.78130
Epoch 41, Val Loss: 5.34478
Epoch 42, Val Loss: 5.39443
Epoch 43, Val Loss: 5.85628
Epoch 44, Val Loss: 6.47184
Epoch 45, Val Loss: 5.21005
Epoch 46, Val Loss: 5.12964
Epoch 47, Val Loss: 5.42763
Epoch 48, Val Loss: 5.14689
Epoch 49, Val Loss: 5.23117
Epoch 50, Val Loss: 5.40604
Epoch 51, Val Loss: 5.12694
Epoch 52, Val Loss: 5.36101
Epoch 53, Val Loss: 6.23430
Epoch 54, Val Loss: 5.46734
Epoch 55, Val Loss: 5.60788
Epoch 56, Val Loss: 5.56703
Epoch 57, Val Loss: 5.24146
Epoch 58, Val Loss: 5.06695
Epoch 59, Val Loss: 5.26407
Epoch 60, Val Loss: 5.39499
Epoch 61, Val Loss: 5.07932
Epoch 62, Val Loss: 5.08690
Epoch 63, Val Loss: 5.55141
Epoch 64, Val Loss: 5.02502
Epoch 65, Val Loss: 5.62341
Epoch 66, Val Loss: 5.11598
Epoch 67, Val Loss: 5.26151
Epoch 68, Val Loss: 5.21037
Epoch 69, Val Loss: 5.17854
Epoch 70, Val Loss: 5.36832
Epoch 71, Val Loss: 5.51873
Epoch 72, Val Loss: 5.06842
Epoch 73, Val Loss: 5.21451
Epoch 74, Val Loss: 4.91896
Epoch 75, Val Loss: 4.95621
Epoch 76, Val Loss: 5.18464
Epoch 77, Val Loss: 5.13813
Epoch 78, Val Loss: 4.98540
Epoch 79, Val Loss: 5.07623
Epoch 80, Val Loss: 5.23435
Epoch 81, Val Loss: 5.11606
Epoch 82, Val Loss: 4.76602
Epoch 83, Val Loss: 4.77672
Epoch 84, Val Loss: 5.12809
Epoch 85, Val Loss: 5.52211
Epoch 86, Val Loss: 4.67323
Epoch 87, Val Loss: 5.12316
Epoch 88, Val Loss: 5.31511
Epoch 89, Val Loss: 4.89749
Epoch 90, Val Loss: 5.11753
Epoch 91, Val Loss: 5.35678
Epoch 92, Val Loss: 5.03697
Epoch 93, Val Loss: 5.22303
Epoch 94, Val Loss: 5.03349
Epoch 95, Val Loss: 4.98942
Epoch 96, Val Loss: 4.70719
Epoch 97, Val Loss: 4.89063
Epoch 98, Val Loss: 4.79926
Epoch 99, Val Loss: 5.06369
DID NOT SAVE RESULTS
{'MSE - mean': 4.900828878818966, 'MSE - std': 0.2767874038015702, 'R2 - mean': 0.5178481344010512, 'R2 - std': 0.005667572540670912} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 26.61743
Epoch 1, Val Loss: 8.22027
Epoch 2, Val Loss: 6.12964
Epoch 3, Val Loss: 5.61583
Epoch 4, Val Loss: 5.63768
Epoch 5, Val Loss: 5.52099
Epoch 6, Val Loss: 5.74115
Epoch 7, Val Loss: 5.37996
Epoch 8, Val Loss: 5.72864
Epoch 9, Val Loss: 5.36271
Epoch 10, Val Loss: 5.33340
Epoch 11, Val Loss: 5.40659
Epoch 12, Val Loss: 5.25067
Epoch 13, Val Loss: 5.72778
Epoch 14, Val Loss: 5.27044
Epoch 15, Val Loss: 5.26716
Epoch 16, Val Loss: 5.65730
Epoch 17, Val Loss: 5.22826
Epoch 18, Val Loss: 5.20316
Epoch 19, Val Loss: 5.37829
Epoch 20, Val Loss: 5.18886
Epoch 21, Val Loss: 5.19401
Epoch 22, Val Loss: 5.11293
Epoch 23, Val Loss: 5.48037
Epoch 24, Val Loss: 5.21703
Epoch 25, Val Loss: 5.17241
Epoch 26, Val Loss: 5.07752
Epoch 27, Val Loss: 5.06764
Epoch 28, Val Loss: 4.99066
Epoch 29, Val Loss: 4.94466
Epoch 30, Val Loss: 4.99795
Epoch 31, Val Loss: 5.16047
Epoch 32, Val Loss: 5.13598
Epoch 33, Val Loss: 5.62241
Epoch 34, Val Loss: 4.85053
Epoch 35, Val Loss: 5.03766
Epoch 36, Val Loss: 5.03249
Epoch 37, Val Loss: 4.86385
Epoch 38, Val Loss: 4.87046
Epoch 39, Val Loss: 5.13509
Epoch 40, Val Loss: 4.88166
Epoch 41, Val Loss: 4.93919
Epoch 42, Val Loss: 4.90382
Epoch 43, Val Loss: 4.91772
Epoch 44, Val Loss: 4.86075
Epoch 45, Val Loss: 4.97277
Epoch 46, Val Loss: 4.82191
Epoch 47, Val Loss: 4.76660
Epoch 48, Val Loss: 4.79482
Epoch 49, Val Loss: 4.83265
Epoch 50, Val Loss: 4.89067
Epoch 51, Val Loss: 4.71231
Epoch 52, Val Loss: 5.09900
Epoch 53, Val Loss: 5.32805
Epoch 54, Val Loss: 5.16395
Epoch 55, Val Loss: 5.00954
Epoch 56, Val Loss: 4.78287
Epoch 57, Val Loss: 5.24203
Epoch 58, Val Loss: 4.72582
Epoch 59, Val Loss: 4.81654
Epoch 60, Val Loss: 4.68470
Epoch 61, Val Loss: 4.82946
Epoch 62, Val Loss: 4.75586
Epoch 63, Val Loss: 4.89352
Epoch 64, Val Loss: 4.67558
Epoch 65, Val Loss: 4.79794
Epoch 66, Val Loss: 4.74814
Epoch 67, Val Loss: 4.72987
Epoch 68, Val Loss: 4.70202
Epoch 69, Val Loss: 4.68727
Epoch 70, Val Loss: 4.86321
Epoch 71, Val Loss: 4.66003
Epoch 72, Val Loss: 4.87381
Epoch 73, Val Loss: 4.84347
Epoch 74, Val Loss: 4.74674
Epoch 75, Val Loss: 4.80509
Epoch 76, Val Loss: 4.66426
Epoch 77, Val Loss: 4.96915
Epoch 78, Val Loss: 4.61510
Epoch 79, Val Loss: 4.97096
Epoch 80, Val Loss: 4.69127
Epoch 81, Val Loss: 4.65862
Epoch 82, Val Loss: 4.91418
Epoch 83, Val Loss: 4.73689
Epoch 84, Val Loss: 4.60108
Epoch 85, Val Loss: 4.56462
Epoch 86, Val Loss: 4.59289
Epoch 87, Val Loss: 4.67437
Epoch 88, Val Loss: 4.71408
Epoch 89, Val Loss: 4.56799
Epoch 90, Val Loss: 4.61099
Epoch 91, Val Loss: 4.61718
Epoch 92, Val Loss: 4.61331
Epoch 93, Val Loss: 4.78418
Epoch 94, Val Loss: 4.68437
Epoch 95, Val Loss: 4.61930
Epoch 96, Val Loss: 5.04734
Epoch 97, Val Loss: 4.48975
Epoch 98, Val Loss: 4.56897
Epoch 99, Val Loss: 4.57039
DID NOT SAVE RESULTS
{'MSE - mean': 4.895778754834566, 'MSE - std': 0.23986446471743894, 'R2 - mean': 0.5079262837945939, 'R2 - std': 0.01787233594828597} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.67503
Epoch 1, Val Loss: 10.89761
Epoch 2, Val Loss: 9.08343
Epoch 3, Val Loss: 8.20218
Epoch 4, Val Loss: 8.12883
Epoch 5, Val Loss: 8.36002
Epoch 6, Val Loss: 7.98198
Epoch 7, Val Loss: 7.99764
Epoch 8, Val Loss: 7.50301
Epoch 9, Val Loss: 8.04014
Epoch 10, Val Loss: 7.61754
Epoch 11, Val Loss: 7.62386
Epoch 12, Val Loss: 7.88667
Epoch 13, Val Loss: 7.86074
Epoch 14, Val Loss: 7.58902
Epoch 15, Val Loss: 7.45749
Epoch 16, Val Loss: 7.68486
Epoch 17, Val Loss: 7.77919
Epoch 18, Val Loss: 7.89246
Epoch 19, Val Loss: 7.54511
Epoch 20, Val Loss: 7.48820
Epoch 21, Val Loss: 7.41317
Epoch 22, Val Loss: 7.34081
Epoch 23, Val Loss: 7.26507
Epoch 24, Val Loss: 7.22688
Epoch 25, Val Loss: 7.26753
Epoch 26, Val Loss: 8.33758
Epoch 27, Val Loss: 7.05590
Epoch 28, Val Loss: 7.20427
Epoch 29, Val Loss: 7.09552
Epoch 30, Val Loss: 7.18068
Epoch 31, Val Loss: 7.31905
Epoch 32, Val Loss: 7.19474
Epoch 33, Val Loss: 7.10495
Epoch 34, Val Loss: 7.16079
Epoch 35, Val Loss: 6.76439
Epoch 36, Val Loss: 7.21119
Epoch 37, Val Loss: 7.04753
Epoch 38, Val Loss: 7.48626
Epoch 39, Val Loss: 7.05824
Epoch 40, Val Loss: 7.12653
Epoch 41, Val Loss: 7.34617
Epoch 42, Val Loss: 7.16731
Epoch 43, Val Loss: 7.10649
Epoch 44, Val Loss: 6.86111
Epoch 45, Val Loss: 7.02871
Epoch 46, Val Loss: 6.94941
Epoch 47, Val Loss: 6.72103
Epoch 48, Val Loss: 6.70903
Epoch 49, Val Loss: 6.82772
Epoch 50, Val Loss: 6.79556
Epoch 51, Val Loss: 7.04496
Epoch 52, Val Loss: 6.74285
Epoch 53, Val Loss: 7.31720
Epoch 54, Val Loss: 7.70942
Epoch 55, Val Loss: 7.12201
Epoch 56, Val Loss: 7.12461
Epoch 57, Val Loss: 7.08958
Epoch 58, Val Loss: 6.61544
Epoch 59, Val Loss: 7.07643
Epoch 60, Val Loss: 6.70105
Epoch 61, Val Loss: 6.72298
Epoch 62, Val Loss: 6.61259
Epoch 63, Val Loss: 6.43413
Epoch 64, Val Loss: 6.56365
Epoch 65, Val Loss: 6.57297
Epoch 66, Val Loss: 7.37604
Epoch 67, Val Loss: 6.62572
Epoch 68, Val Loss: 6.67335
Epoch 69, Val Loss: 6.62075
Epoch 70, Val Loss: 6.99677
Epoch 71, Val Loss: 6.54579
Epoch 72, Val Loss: 6.44829
Epoch 73, Val Loss: 6.52193
Epoch 74, Val Loss: 6.77427
Epoch 75, Val Loss: 6.50127
Epoch 76, Val Loss: 6.39687
Epoch 77, Val Loss: 6.49937
Epoch 78, Val Loss: 6.57772
Epoch 79, Val Loss: 6.25166
Epoch 80, Val Loss: 6.64145
Epoch 81, Val Loss: 6.45800
Epoch 82, Val Loss: 6.47197
Epoch 83, Val Loss: 6.32328
Epoch 84, Val Loss: 6.17119
Epoch 85, Val Loss: 6.71763
Epoch 86, Val Loss: 6.64434
Epoch 87, Val Loss: 6.18742
Epoch 88, Val Loss: 6.49131
Epoch 89, Val Loss: 6.46841
Epoch 90, Val Loss: 6.38432
Epoch 91, Val Loss: 6.70655
Epoch 92, Val Loss: 6.27187
Epoch 93, Val Loss: 6.41591
Epoch 94, Val Loss: 6.09536
Epoch 95, Val Loss: 6.39526
Epoch 96, Val Loss: 6.26155
Epoch 97, Val Loss: 6.99460
Epoch 98, Val Loss: 6.18586
Epoch 99, Val Loss: 6.15105
DID NOT SAVE RESULTS
{'MSE - mean': 5.133741743718624, 'MSE - std': 0.5220474168711907, 'R2 - mean': 0.5056856907140241, 'R2 - std': 0.016601727115258355} 
 

Results After CV: {'MSE - mean': 5.133741743718624, 'MSE - std': 0.5220474168711907, 'R2 - mean': 0.5056856907140241, 'R2 - std': 0.016601727115258355}
Train time: 48.30048633679981
Inference time: 0.050291700800153195
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 68 finished with value: 5.133741743718624 and parameters: {'p_m': 0.34057262867751265, 'alpha': 1.0932171164921054, 'K': 5, 'beta': 3.3358678232462666}. Best is trial 36 with value: 4.48540081526779.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.08867
Epoch 1, Val Loss: 10.34794
Epoch 2, Val Loss: 7.16277
Epoch 3, Val Loss: 6.62152
Epoch 4, Val Loss: 6.39289
Epoch 5, Val Loss: 6.69644
Epoch 6, Val Loss: 6.58345
Epoch 7, Val Loss: 6.21747
Epoch 8, Val Loss: 6.28718
Epoch 9, Val Loss: 6.19870
Epoch 10, Val Loss: 6.02842
Epoch 11, Val Loss: 6.25229
Epoch 12, Val Loss: 5.97212
Epoch 13, Val Loss: 5.95948
Epoch 14, Val Loss: 6.12879
Epoch 15, Val Loss: 5.92419
Epoch 16, Val Loss: 6.00221
Epoch 17, Val Loss: 6.06931
Epoch 18, Val Loss: 5.92510
Epoch 19, Val Loss: 5.84935
Epoch 20, Val Loss: 5.75869
Epoch 21, Val Loss: 5.74126
Epoch 22, Val Loss: 5.62702
Epoch 23, Val Loss: 5.81103
Epoch 24, Val Loss: 5.55438
Epoch 25, Val Loss: 5.52170
Epoch 26, Val Loss: 5.52042
Epoch 27, Val Loss: 5.58409
Epoch 28, Val Loss: 5.55235
Epoch 29, Val Loss: 5.45164
Epoch 30, Val Loss: 5.53182
Epoch 31, Val Loss: 5.41901
Epoch 32, Val Loss: 5.48302
Epoch 33, Val Loss: 5.78193
Epoch 34, Val Loss: 5.35594
Epoch 35, Val Loss: 5.52173
Epoch 36, Val Loss: 5.62910
Epoch 37, Val Loss: 5.49811
Epoch 38, Val Loss: 5.83759
Epoch 39, Val Loss: 5.64598
Epoch 40, Val Loss: 5.42156
Epoch 41, Val Loss: 6.26437
Epoch 42, Val Loss: 5.44715
Epoch 43, Val Loss: 5.53101
Epoch 44, Val Loss: 5.21357
Epoch 45, Val Loss: 5.28225
Epoch 46, Val Loss: 5.34586
Epoch 47, Val Loss: 5.50690
Epoch 48, Val Loss: 5.41191
Epoch 49, Val Loss: 5.37139
Epoch 50, Val Loss: 5.46305
Epoch 51, Val Loss: 5.25744
Epoch 52, Val Loss: 5.13560
Epoch 53, Val Loss: 5.42040
Epoch 54, Val Loss: 5.63636
Epoch 55, Val Loss: 5.38144
Epoch 56, Val Loss: 5.31448
Epoch 57, Val Loss: 5.19938
Epoch 58, Val Loss: 5.17274
Epoch 59, Val Loss: 5.17876
Epoch 60, Val Loss: 5.14805
Epoch 61, Val Loss: 5.15013
Epoch 62, Val Loss: 5.34225
Epoch 63, Val Loss: 5.48929
Epoch 64, Val Loss: 5.12438
Epoch 65, Val Loss: 5.82048
Epoch 66, Val Loss: 5.57510
Epoch 67, Val Loss: 5.24931
Epoch 68, Val Loss: 5.11773
Epoch 69, Val Loss: 5.01593
Epoch 70, Val Loss: 5.01824
Epoch 71, Val Loss: 5.08810
Epoch 72, Val Loss: 5.93787
Epoch 73, Val Loss: 5.25736
Epoch 74, Val Loss: 5.16574
Epoch 75, Val Loss: 5.11618
Epoch 76, Val Loss: 5.11683
Epoch 77, Val Loss: 5.08629
Epoch 78, Val Loss: 5.11381
Epoch 79, Val Loss: 5.06437
Epoch 80, Val Loss: 5.21034
Epoch 81, Val Loss: 5.16348
Epoch 82, Val Loss: 5.15608
Epoch 83, Val Loss: 5.06251
Epoch 84, Val Loss: 5.32350
Epoch 85, Val Loss: 4.97437
Epoch 86, Val Loss: 5.00939
Epoch 87, Val Loss: 5.06757
Epoch 88, Val Loss: 5.07432
Epoch 89, Val Loss: 5.27944
Epoch 90, Val Loss: 5.05410
Epoch 91, Val Loss: 5.06045
Epoch 92, Val Loss: 4.93078
Epoch 93, Val Loss: 4.91440
Epoch 94, Val Loss: 5.42577
Epoch 95, Val Loss: 5.09268
Epoch 96, Val Loss: 4.93508
Epoch 97, Val Loss: 4.92230
Epoch 98, Val Loss: 5.30031
Epoch 99, Val Loss: 5.10273
DID NOT SAVE RESULTS
{'MSE - mean': 5.066053177120046, 'MSE - std': 0.0, 'R2 - mean': 0.5379926902244266, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.01680
Epoch 1, Val Loss: 6.57164
Epoch 2, Val Loss: 5.90724
Epoch 3, Val Loss: 5.53827
Epoch 4, Val Loss: 5.27851
Epoch 5, Val Loss: 5.30887
Epoch 6, Val Loss: 5.36457
Epoch 7, Val Loss: 5.36093
Epoch 8, Val Loss: 5.27687
Epoch 9, Val Loss: 5.14583
Epoch 10, Val Loss: 5.27686
Epoch 11, Val Loss: 4.98854
Epoch 12, Val Loss: 4.85986
Epoch 13, Val Loss: 4.83099
Epoch 14, Val Loss: 5.21622
Epoch 15, Val Loss: 4.76345
Epoch 16, Val Loss: 5.24378
Epoch 17, Val Loss: 4.98302
Epoch 18, Val Loss: 5.50747
Epoch 19, Val Loss: 4.78438
Epoch 20, Val Loss: 4.93547
Epoch 21, Val Loss: 4.84600
Epoch 22, Val Loss: 4.64532
Epoch 23, Val Loss: 4.82196
Epoch 24, Val Loss: 4.72873
Epoch 25, Val Loss: 4.55875
Epoch 26, Val Loss: 4.57016
Epoch 27, Val Loss: 5.02062
Epoch 28, Val Loss: 4.56498
Epoch 29, Val Loss: 4.67622
Epoch 30, Val Loss: 4.70765
Epoch 31, Val Loss: 4.55673
Epoch 32, Val Loss: 4.58417
Epoch 33, Val Loss: 4.97210
Epoch 34, Val Loss: 4.53029
Epoch 35, Val Loss: 4.60723
Epoch 36, Val Loss: 4.32537
Epoch 37, Val Loss: 4.44038
Epoch 38, Val Loss: 4.54378
Epoch 39, Val Loss: 4.57822
Epoch 40, Val Loss: 4.35643
Epoch 41, Val Loss: 4.51720
Epoch 42, Val Loss: 4.75788
Epoch 43, Val Loss: 5.02395
Epoch 44, Val Loss: 4.43300
Epoch 45, Val Loss: 4.56766
Epoch 46, Val Loss: 4.45840
Epoch 47, Val Loss: 4.35285
Epoch 48, Val Loss: 4.41806
Epoch 49, Val Loss: 4.39575
Epoch 50, Val Loss: 4.33875
Epoch 51, Val Loss: 4.23447
Epoch 52, Val Loss: 4.39428
Epoch 53, Val Loss: 4.25535
Epoch 54, Val Loss: 4.42428
Epoch 55, Val Loss: 4.49115
Epoch 56, Val Loss: 4.31242
Epoch 57, Val Loss: 4.19475
Epoch 58, Val Loss: 4.46529
Epoch 59, Val Loss: 4.28249
Epoch 60, Val Loss: 4.67061
Epoch 61, Val Loss: 4.15487
Epoch 62, Val Loss: 4.19312
Epoch 63, Val Loss: 4.70290
Epoch 64, Val Loss: 4.40871
Epoch 65, Val Loss: 4.17202
Epoch 66, Val Loss: 4.16539
Epoch 67, Val Loss: 4.21290
Epoch 68, Val Loss: 4.29971
Epoch 69, Val Loss: 4.16720
Epoch 70, Val Loss: 4.37850
Epoch 71, Val Loss: 4.41667
Epoch 72, Val Loss: 4.50670
Epoch 73, Val Loss: 5.26250
Epoch 74, Val Loss: 4.23311
Epoch 75, Val Loss: 4.35857
Epoch 76, Val Loss: 4.42235
Epoch 77, Val Loss: 4.41138
Epoch 78, Val Loss: 4.55745
Epoch 79, Val Loss: 4.79841
Epoch 80, Val Loss: 4.29810
Epoch 81, Val Loss: 4.32165
Epoch 82, Val Loss: 4.62400
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 4.696737374885794, 'MSE - std': 0.36931580223425176, 'R2 - mean': 0.538352210264434, 'R2 - std': 0.00035952004000733284} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 28.15957
Epoch 1, Val Loss: 7.97323
Epoch 2, Val Loss: 6.63402
Epoch 3, Val Loss: 6.11423
Epoch 4, Val Loss: 6.12488
Epoch 5, Val Loss: 6.02477
Epoch 6, Val Loss: 5.89894
Epoch 7, Val Loss: 6.08371
Epoch 8, Val Loss: 6.01787
Epoch 9, Val Loss: 5.92050
Epoch 10, Val Loss: 5.73837
Epoch 11, Val Loss: 5.74185
Epoch 12, Val Loss: 5.65233
Epoch 13, Val Loss: 5.70406
Epoch 14, Val Loss: 5.75775
Epoch 15, Val Loss: 5.71301
Epoch 16, Val Loss: 5.61778
Epoch 17, Val Loss: 5.76933
Epoch 18, Val Loss: 5.45121
Epoch 19, Val Loss: 5.40380
Epoch 20, Val Loss: 5.48168
Epoch 21, Val Loss: 5.32372
Epoch 22, Val Loss: 5.64034
Epoch 23, Val Loss: 5.35684
Epoch 24, Val Loss: 5.81613
Epoch 25, Val Loss: 5.33472
Epoch 26, Val Loss: 5.32559
Epoch 27, Val Loss: 5.31234
Epoch 28, Val Loss: 5.19806
Epoch 29, Val Loss: 5.27977
Epoch 30, Val Loss: 5.45947
Epoch 31, Val Loss: 5.15202
Epoch 32, Val Loss: 5.27463
Epoch 33, Val Loss: 5.20770
Epoch 34, Val Loss: 5.13811
Epoch 35, Val Loss: 5.51791
Epoch 36, Val Loss: 5.11271
Epoch 37, Val Loss: 5.11465
Epoch 38, Val Loss: 5.23435
Epoch 39, Val Loss: 5.05550
Epoch 40, Val Loss: 5.12193
Epoch 41, Val Loss: 4.98382
Epoch 42, Val Loss: 5.01049
Epoch 43, Val Loss: 5.06660
Epoch 44, Val Loss: 5.15842
Epoch 45, Val Loss: 4.97351
Epoch 46, Val Loss: 5.67377
Epoch 47, Val Loss: 5.09631
Epoch 48, Val Loss: 5.17219
Epoch 49, Val Loss: 5.09431
Epoch 50, Val Loss: 5.40997
Epoch 51, Val Loss: 4.97852
Epoch 52, Val Loss: 5.00595
Epoch 53, Val Loss: 4.97670
Epoch 54, Val Loss: 5.10582
Epoch 55, Val Loss: 5.28089
Epoch 56, Val Loss: 4.86285
Epoch 57, Val Loss: 4.89766
Epoch 58, Val Loss: 4.89659
Epoch 59, Val Loss: 4.90847
Epoch 60, Val Loss: 4.86599
Epoch 61, Val Loss: 5.09878
Epoch 62, Val Loss: 4.96130
Epoch 63, Val Loss: 5.22618
Epoch 64, Val Loss: 5.11376
Epoch 65, Val Loss: 5.75041
Epoch 66, Val Loss: 5.04206
Epoch 67, Val Loss: 4.91928
Epoch 68, Val Loss: 5.22008
Epoch 69, Val Loss: 5.07597
Epoch 70, Val Loss: 4.90265
Epoch 71, Val Loss: 4.87378
Epoch 72, Val Loss: 4.96456
Epoch 73, Val Loss: 5.31175
Epoch 74, Val Loss: 4.80548
Epoch 75, Val Loss: 5.16494
Epoch 76, Val Loss: 5.02520
Epoch 77, Val Loss: 4.81711
Epoch 78, Val Loss: 4.94129
Epoch 79, Val Loss: 4.82581
Epoch 80, Val Loss: 5.09474
Epoch 81, Val Loss: 4.92764
Epoch 82, Val Loss: 4.95506
Epoch 83, Val Loss: 4.81756
Epoch 84, Val Loss: 4.96616
Epoch 85, Val Loss: 4.98640
Epoch 86, Val Loss: 4.72697
Epoch 87, Val Loss: 5.05787
Epoch 88, Val Loss: 5.60948
Epoch 89, Val Loss: 5.06810
Epoch 90, Val Loss: 4.94199
Epoch 91, Val Loss: 5.06561
Epoch 92, Val Loss: 4.84184
Epoch 93, Val Loss: 4.91903
Epoch 94, Val Loss: 4.78287
Epoch 95, Val Loss: 4.87639
Epoch 96, Val Loss: 5.43474
Epoch 97, Val Loss: 4.77310
Epoch 98, Val Loss: 5.07248
Epoch 99, Val Loss: 4.83826
DID NOT SAVE RESULTS
{'MSE - mean': 4.751900396260911, 'MSE - std': 0.3114728865263917, 'R2 - mean': 0.5327558971692311, 'R2 - std': 0.007919823880103503} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 30.30704
Epoch 1, Val Loss: 8.01142
Epoch 2, Val Loss: 5.80039
Epoch 3, Val Loss: 5.52537
Epoch 4, Val Loss: 5.63987
Epoch 5, Val Loss: 5.57478
Epoch 6, Val Loss: 5.38700
Epoch 7, Val Loss: 5.41485
Epoch 8, Val Loss: 5.65134
Epoch 9, Val Loss: 5.35427
Epoch 10, Val Loss: 5.15581
Epoch 11, Val Loss: 5.46427
Epoch 12, Val Loss: 5.22930
Epoch 13, Val Loss: 5.23573
Epoch 14, Val Loss: 5.14170
Epoch 15, Val Loss: 5.30082
Epoch 16, Val Loss: 5.38355
Epoch 17, Val Loss: 5.10113
Epoch 18, Val Loss: 5.13573
Epoch 19, Val Loss: 5.10924
Epoch 20, Val Loss: 5.03257
Epoch 21, Val Loss: 5.28857
Epoch 22, Val Loss: 5.11540
Epoch 23, Val Loss: 5.30377
Epoch 24, Val Loss: 5.08599
Epoch 25, Val Loss: 5.04792
Epoch 26, Val Loss: 5.00548
Epoch 27, Val Loss: 4.97901
Epoch 28, Val Loss: 5.22498
Epoch 29, Val Loss: 5.22926
Epoch 30, Val Loss: 5.00133
Epoch 31, Val Loss: 5.37498
Epoch 32, Val Loss: 4.83190
Epoch 33, Val Loss: 4.96809
Epoch 34, Val Loss: 5.48329
Epoch 35, Val Loss: 5.62576
Epoch 36, Val Loss: 4.86792
Epoch 37, Val Loss: 4.75690
Epoch 38, Val Loss: 4.83605
Epoch 39, Val Loss: 4.85595
Epoch 40, Val Loss: 4.91825
Epoch 41, Val Loss: 4.78935
Epoch 42, Val Loss: 4.88436
Epoch 43, Val Loss: 4.88717
Epoch 44, Val Loss: 4.83950
Epoch 45, Val Loss: 4.68155
Epoch 46, Val Loss: 4.86095
Epoch 47, Val Loss: 4.86039
Epoch 48, Val Loss: 4.69757
Epoch 49, Val Loss: 4.76038
Epoch 50, Val Loss: 4.79814
Epoch 51, Val Loss: 4.72756
Epoch 52, Val Loss: 4.77271
Epoch 53, Val Loss: 5.47745
Epoch 54, Val Loss: 4.79236
Epoch 55, Val Loss: 4.71623
Epoch 56, Val Loss: 4.75586
Epoch 57, Val Loss: 4.60155
Epoch 58, Val Loss: 5.22580
Epoch 59, Val Loss: 4.96545
Epoch 60, Val Loss: 4.66244
Epoch 61, Val Loss: 4.81966
Epoch 62, Val Loss: 4.64861
Epoch 63, Val Loss: 4.58423
Epoch 64, Val Loss: 4.68019
Epoch 65, Val Loss: 4.81410
Epoch 66, Val Loss: 4.70300
Epoch 67, Val Loss: 4.78082
Epoch 68, Val Loss: 4.92276
Epoch 69, Val Loss: 5.02054
Epoch 70, Val Loss: 4.53224
Epoch 71, Val Loss: 4.59918
Epoch 72, Val Loss: 4.61433
Epoch 73, Val Loss: 4.70946
Epoch 74, Val Loss: 4.52851
Epoch 75, Val Loss: 4.69270
Epoch 76, Val Loss: 4.50033
Epoch 77, Val Loss: 4.76167
Epoch 78, Val Loss: 4.65600
Epoch 79, Val Loss: 4.78542
Epoch 80, Val Loss: 4.61747
Epoch 81, Val Loss: 4.73606
Epoch 82, Val Loss: 4.53375
Epoch 83, Val Loss: 4.62969
Epoch 84, Val Loss: 4.72453
Epoch 85, Val Loss: 4.53068
Epoch 86, Val Loss: 4.51147
Epoch 87, Val Loss: 4.51872
Epoch 88, Val Loss: 4.59459
Epoch 89, Val Loss: 4.57378
Epoch 90, Val Loss: 4.53341
Epoch 91, Val Loss: 4.58062
Epoch 92, Val Loss: 4.58200
Epoch 93, Val Loss: 4.57072
Epoch 94, Val Loss: 4.52194
Epoch 95, Val Loss: 4.81813
Epoch 96, Val Loss: 4.44161
Epoch 97, Val Loss: 4.51874
Epoch 98, Val Loss: 4.92624
Epoch 99, Val Loss: 4.43702
DID NOT SAVE RESULTS
{'MSE - mean': 4.771089126257144, 'MSE - std': 0.271783261731507, 'R2 - mean': 0.5204963525477149, 'R2 - std': 0.022314390215727006} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 44.53103
Epoch 1, Val Loss: 19.97333
Epoch 2, Val Loss: 8.53359
Epoch 3, Val Loss: 8.28785
Epoch 4, Val Loss: 7.62752
Epoch 5, Val Loss: 7.26213
Epoch 6, Val Loss: 7.17970
Epoch 7, Val Loss: 7.21692
Epoch 8, Val Loss: 7.33609
Epoch 9, Val Loss: 7.30897
Epoch 10, Val Loss: 7.09663
Epoch 11, Val Loss: 6.91906
Epoch 12, Val Loss: 7.09181
Epoch 13, Val Loss: 7.04180
Epoch 14, Val Loss: 6.87883
Epoch 15, Val Loss: 6.90091
Epoch 16, Val Loss: 6.93298
Epoch 17, Val Loss: 6.89783
Epoch 18, Val Loss: 6.42957
Epoch 19, Val Loss: 6.55063
Epoch 20, Val Loss: 6.48676
Epoch 21, Val Loss: 6.74394
Epoch 22, Val Loss: 6.67760
Epoch 23, Val Loss: 6.51180
Epoch 24, Val Loss: 6.33486
Epoch 25, Val Loss: 6.34504
Epoch 26, Val Loss: 6.26230
Epoch 27, Val Loss: 6.16537
Epoch 28, Val Loss: 6.46808
Epoch 29, Val Loss: 6.25386
Epoch 30, Val Loss: 6.19190
Epoch 31, Val Loss: 6.32930
Epoch 32, Val Loss: 6.84453
Epoch 33, Val Loss: 6.20821
Epoch 34, Val Loss: 6.51911
Epoch 35, Val Loss: 6.20623
Epoch 36, Val Loss: 6.18679
Epoch 37, Val Loss: 6.11675
Epoch 38, Val Loss: 6.17614
Epoch 39, Val Loss: 6.77880
Epoch 40, Val Loss: 6.22297
Epoch 41, Val Loss: 6.59224
Epoch 42, Val Loss: 6.52686
Epoch 43, Val Loss: 6.08299
Epoch 44, Val Loss: 6.13457
Epoch 45, Val Loss: 6.19739
Epoch 46, Val Loss: 6.17349
Epoch 47, Val Loss: 6.06200
Epoch 48, Val Loss: 6.09094
Epoch 49, Val Loss: 6.02692
Epoch 50, Val Loss: 6.29309
Epoch 51, Val Loss: 6.17818
Epoch 52, Val Loss: 6.05970
Epoch 53, Val Loss: 6.42005
Epoch 54, Val Loss: 6.01525
Epoch 55, Val Loss: 5.93849
Epoch 56, Val Loss: 5.99221
Epoch 57, Val Loss: 6.29720
Epoch 58, Val Loss: 6.34624
Epoch 59, Val Loss: 5.98763
Epoch 60, Val Loss: 6.50137
Epoch 61, Val Loss: 6.12065
Epoch 62, Val Loss: 6.21698
Epoch 63, Val Loss: 5.88972
Epoch 64, Val Loss: 5.86504
Epoch 65, Val Loss: 6.08190
Epoch 66, Val Loss: 6.07816
Epoch 67, Val Loss: 6.36432
Epoch 68, Val Loss: 5.99461
Epoch 69, Val Loss: 5.86244
Epoch 70, Val Loss: 5.89977
Epoch 71, Val Loss: 6.10419
Epoch 72, Val Loss: 5.85398
Epoch 73, Val Loss: 5.83042
Epoch 74, Val Loss: 5.84580
Epoch 75, Val Loss: 6.13975
Epoch 76, Val Loss: 5.93765
Epoch 77, Val Loss: 5.97285
Epoch 78, Val Loss: 6.39334
Epoch 79, Val Loss: 5.91364
Epoch 80, Val Loss: 5.85035
Epoch 81, Val Loss: 5.92435
Epoch 82, Val Loss: 6.03402
Epoch 83, Val Loss: 5.87363
Epoch 84, Val Loss: 5.70991
Epoch 85, Val Loss: 5.82245
Epoch 86, Val Loss: 6.12853
Epoch 87, Val Loss: 5.74511
Epoch 88, Val Loss: 5.82305
Epoch 89, Val Loss: 5.91498
Epoch 90, Val Loss: 6.03758
Epoch 91, Val Loss: 6.14857
Epoch 92, Val Loss: 6.07244
Epoch 93, Val Loss: 5.77490
Epoch 94, Val Loss: 5.96440
Epoch 95, Val Loss: 5.73947
Epoch 96, Val Loss: 5.93462
Epoch 97, Val Loss: 5.97507
Epoch 98, Val Loss: 5.70836
Epoch 99, Val Loss: 6.04635
DID NOT SAVE RESULTS
{'MSE - mean': 4.951964075520449, 'MSE - std': 0.43583930773846674, 'R2 - mean': 0.5225252672068218, 'R2 - std': 0.020366923855495284} 
 

Results After CV: {'MSE - mean': 4.951964075520449, 'MSE - std': 0.43583930773846674, 'R2 - mean': 0.5225252672068218, 'R2 - std': 0.020366923855495284}
Train time: 46.849420384599945
Inference time: 0.05161299199971836
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 69 finished with value: 4.951964075520449 and parameters: {'p_m': 0.29863042494367564, 'alpha': 0.8358084620989186, 'K': 5, 'beta': 1.752274939160942}. Best is trial 36 with value: 4.48540081526779.
Best parameters: {'p_m': 0.8721504351545861, 'alpha': 3.038715869332491, 'K': 10, 'beta': 1.2414847045108695}
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 33.72908
Epoch 1, Val Loss: 12.31397
Epoch 2, Val Loss: 7.10775
Epoch 3, Val Loss: 6.93533
Epoch 4, Val Loss: 6.77571
Epoch 5, Val Loss: 6.66440
Epoch 6, Val Loss: 6.40551
Epoch 7, Val Loss: 6.80946
Epoch 8, Val Loss: 6.23647
Epoch 9, Val Loss: 6.19078
Epoch 10, Val Loss: 6.07113
Epoch 11, Val Loss: 5.88560
Epoch 12, Val Loss: 5.91949
Epoch 13, Val Loss: 5.75973
Epoch 14, Val Loss: 5.75667
Epoch 15, Val Loss: 5.89514
Epoch 16, Val Loss: 5.59944
Epoch 17, Val Loss: 5.91589
Epoch 18, Val Loss: 5.42608
Epoch 19, Val Loss: 5.39879
Epoch 20, Val Loss: 5.40407
Epoch 21, Val Loss: 5.35328
Epoch 22, Val Loss: 5.34290
Epoch 23, Val Loss: 5.40953
Epoch 24, Val Loss: 5.73954
Epoch 25, Val Loss: 5.22631
Epoch 26, Val Loss: 5.47252
Epoch 27, Val Loss: 5.22378
Epoch 28, Val Loss: 5.82063
Epoch 29, Val Loss: 5.34393
Epoch 30, Val Loss: 5.05929
Epoch 31, Val Loss: 5.04194
Epoch 32, Val Loss: 5.02941
Epoch 33, Val Loss: 4.94241
Epoch 34, Val Loss: 4.88463
Epoch 35, Val Loss: 5.25636
Epoch 36, Val Loss: 4.86802
Epoch 37, Val Loss: 4.88670
Epoch 38, Val Loss: 4.84157
Epoch 39, Val Loss: 4.83163
Epoch 40, Val Loss: 4.89541
Epoch 41, Val Loss: 5.11809
Epoch 42, Val Loss: 4.79595
Epoch 43, Val Loss: 4.81731
Epoch 44, Val Loss: 4.74972
Epoch 45, Val Loss: 4.68166
Epoch 46, Val Loss: 5.22920
Epoch 47, Val Loss: 4.99811
Epoch 48, Val Loss: 4.70643
Epoch 49, Val Loss: 4.86182
Epoch 50, Val Loss: 4.81677
Epoch 51, Val Loss: 4.84683
Epoch 52, Val Loss: 4.74802
Epoch 53, Val Loss: 4.66749
Epoch 54, Val Loss: 5.09231
Epoch 55, Val Loss: 4.87536
Epoch 56, Val Loss: 4.72276
Epoch 57, Val Loss: 4.67307
Epoch 58, Val Loss: 4.59724
Epoch 59, Val Loss: 4.68134
Epoch 60, Val Loss: 4.59107
Epoch 61, Val Loss: 4.61393
Epoch 62, Val Loss: 5.03647
Epoch 63, Val Loss: 4.71280
Epoch 64, Val Loss: 4.69236
Epoch 65, Val Loss: 5.12181
Epoch 66, Val Loss: 4.73101
Epoch 67, Val Loss: 4.93043
Epoch 68, Val Loss: 4.67050
Epoch 69, Val Loss: 4.57102
Epoch 70, Val Loss: 4.62473
Epoch 71, Val Loss: 4.77498
Epoch 72, Val Loss: 4.58132
Epoch 73, Val Loss: 4.61603
Epoch 74, Val Loss: 4.64723
Epoch 75, Val Loss: 4.60026
Epoch 76, Val Loss: 4.58168
Epoch 77, Val Loss: 4.53640
Epoch 78, Val Loss: 4.73905
Epoch 79, Val Loss: 4.60428
Epoch 80, Val Loss: 4.52836
Epoch 81, Val Loss: 4.53347
Epoch 82, Val Loss: 4.60193
Epoch 83, Val Loss: 4.61942
Epoch 84, Val Loss: 4.91521
Epoch 85, Val Loss: 4.59745
Epoch 86, Val Loss: 4.74232
Epoch 87, Val Loss: 4.66584
Epoch 88, Val Loss: 4.97551
Epoch 89, Val Loss: 4.59972
Epoch 90, Val Loss: 4.76996
Epoch 91, Val Loss: 4.90755
Epoch 92, Val Loss: 4.67290
Epoch 93, Val Loss: 4.57540
Epoch 94, Val Loss: 4.77067
Epoch 95, Val Loss: 4.77382
Epoch 96, Val Loss: 4.63252
Epoch 97, Val Loss: 4.58749
Epoch 98, Val Loss: 4.63679
Epoch 99, Val Loss: 4.67718
Saved Losses
{'MSE - mean': 4.6501139920085635, 'MSE - std': 0.0, 'R2 - mean': 0.5759249695008244, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 24.26348
Epoch 1, Val Loss: 7.67346
Epoch 2, Val Loss: 5.28967
Epoch 3, Val Loss: 5.48260
Epoch 4, Val Loss: 4.99859
Epoch 5, Val Loss: 4.95981
Epoch 6, Val Loss: 5.04301
Epoch 7, Val Loss: 5.14612
Epoch 8, Val Loss: 4.70260
Epoch 9, Val Loss: 5.05258
Epoch 10, Val Loss: 4.64213
Epoch 11, Val Loss: 4.49564
Epoch 12, Val Loss: 4.65189
Epoch 13, Val Loss: 4.44122
Epoch 14, Val Loss: 4.69819
Epoch 15, Val Loss: 4.88397
Epoch 16, Val Loss: 4.44764
Epoch 17, Val Loss: 4.57588
Epoch 18, Val Loss: 4.35280
Epoch 19, Val Loss: 4.33690
Epoch 20, Val Loss: 4.31658
Epoch 21, Val Loss: 4.27970
Epoch 22, Val Loss: 4.26961
Epoch 23, Val Loss: 4.27468
Epoch 24, Val Loss: 4.48880
Epoch 25, Val Loss: 4.39670
Epoch 26, Val Loss: 5.41287
Epoch 27, Val Loss: 4.99018
Epoch 28, Val Loss: 4.41722
Epoch 29, Val Loss: 4.51208
Epoch 30, Val Loss: 4.51652
Epoch 31, Val Loss: 4.37842
Epoch 32, Val Loss: 4.24432
Epoch 33, Val Loss: 4.15973
Epoch 34, Val Loss: 4.23252
Epoch 35, Val Loss: 4.28490
Epoch 36, Val Loss: 4.09089
Epoch 37, Val Loss: 4.06750
Epoch 38, Val Loss: 4.11029
Epoch 39, Val Loss: 4.14858
Epoch 40, Val Loss: 4.27017
Epoch 41, Val Loss: 4.23407
Epoch 42, Val Loss: 4.21969
Epoch 43, Val Loss: 4.12669
Epoch 44, Val Loss: 4.58923
Epoch 45, Val Loss: 4.49577
Epoch 46, Val Loss: 4.02306
Epoch 47, Val Loss: 4.20490
Epoch 48, Val Loss: 4.10563
Epoch 49, Val Loss: 4.32687
Epoch 50, Val Loss: 4.03644
Epoch 51, Val Loss: 4.50360
Epoch 52, Val Loss: 4.09456
Epoch 53, Val Loss: 4.21504
Epoch 54, Val Loss: 4.01280
Epoch 55, Val Loss: 4.29775
Epoch 56, Val Loss: 4.03142
Epoch 57, Val Loss: 4.50138
Epoch 58, Val Loss: 4.27818
Epoch 59, Val Loss: 4.53602
Epoch 60, Val Loss: 4.13020
Epoch 61, Val Loss: 4.05853
Epoch 62, Val Loss: 4.07287
Epoch 63, Val Loss: 4.00413
Epoch 64, Val Loss: 4.05591
Epoch 65, Val Loss: 4.07796
Epoch 66, Val Loss: 3.98693
Epoch 67, Val Loss: 4.36611
Epoch 68, Val Loss: 4.00414
Epoch 69, Val Loss: 4.29636
Epoch 70, Val Loss: 4.33877
Epoch 71, Val Loss: 4.41969
Epoch 72, Val Loss: 4.05426
Epoch 73, Val Loss: 4.01408
Epoch 74, Val Loss: 4.14785
Epoch 75, Val Loss: 4.23900
Epoch 76, Val Loss: 4.07376
Epoch 77, Val Loss: 4.49301
Epoch 78, Val Loss: 4.51835
Epoch 79, Val Loss: 3.97477
Epoch 80, Val Loss: 3.99365
Epoch 81, Val Loss: 3.97883
Epoch 82, Val Loss: 4.32956
Epoch 83, Val Loss: 4.11724
Epoch 84, Val Loss: 4.51632
Epoch 85, Val Loss: 4.01265
Epoch 86, Val Loss: 4.09129
Epoch 87, Val Loss: 4.07095
Epoch 88, Val Loss: 4.12414
Epoch 89, Val Loss: 4.08924
Epoch 90, Val Loss: 4.02137
Epoch 91, Val Loss: 4.23680
Epoch 92, Val Loss: 4.04995
Epoch 93, Val Loss: 4.13585
Epoch 94, Val Loss: 4.33376
Epoch 95, Val Loss: 4.12397
Epoch 96, Val Loss: 3.98035
Epoch 97, Val Loss: 4.22764
Epoch 98, Val Loss: 4.26989
Epoch 99, Val Loss: 4.16996
Saved Losses
{'MSE - mean': 4.406060235644204, 'MSE - std': 0.24405375636435966, 'R2 - mean': 0.5661346901784667, 'R2 - std': 0.009790279322357653} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 48.31005
Epoch 1, Val Loss: 17.82716
Epoch 2, Val Loss: 7.08855
Epoch 3, Val Loss: 6.16338
Epoch 4, Val Loss: 5.97202
Epoch 5, Val Loss: 5.89344
Epoch 6, Val Loss: 5.69434
Epoch 7, Val Loss: 5.71736
Epoch 8, Val Loss: 5.62970
Epoch 9, Val Loss: 5.77248
Epoch 10, Val Loss: 5.22019
Epoch 11, Val Loss: 5.12319
Epoch 12, Val Loss: 5.35192
Epoch 13, Val Loss: 5.87982
Epoch 14, Val Loss: 5.11036
Epoch 15, Val Loss: 5.03103
Epoch 16, Val Loss: 4.86028
Epoch 17, Val Loss: 4.94758
Epoch 18, Val Loss: 4.91879
Epoch 19, Val Loss: 4.81195
Epoch 20, Val Loss: 4.91385
Epoch 21, Val Loss: 4.80932
Epoch 22, Val Loss: 4.81215
Epoch 23, Val Loss: 4.71274
Epoch 24, Val Loss: 4.77873
Epoch 25, Val Loss: 4.68974
Epoch 26, Val Loss: 4.78537
Epoch 27, Val Loss: 4.80592
Epoch 28, Val Loss: 4.95617
Epoch 29, Val Loss: 4.76417
Epoch 30, Val Loss: 4.58532
Epoch 31, Val Loss: 4.73059
Epoch 32, Val Loss: 4.61650
Epoch 33, Val Loss: 5.06477
Epoch 34, Val Loss: 4.66341
Epoch 35, Val Loss: 4.52186
Epoch 36, Val Loss: 4.57360
Epoch 37, Val Loss: 5.42719
Epoch 38, Val Loss: 4.57925
Epoch 39, Val Loss: 4.60506
Epoch 40, Val Loss: 4.52057
Epoch 41, Val Loss: 4.64382
Epoch 42, Val Loss: 5.12918
Epoch 43, Val Loss: 4.82926
Epoch 44, Val Loss: 4.68718
Epoch 45, Val Loss: 4.54993
Epoch 46, Val Loss: 4.52890
Epoch 47, Val Loss: 4.44005
Epoch 48, Val Loss: 4.43053
Epoch 49, Val Loss: 4.46071
Epoch 50, Val Loss: 4.67990
Epoch 51, Val Loss: 4.65062
Epoch 52, Val Loss: 4.50437
Epoch 53, Val Loss: 4.47806
Epoch 54, Val Loss: 4.58291
Epoch 55, Val Loss: 4.43064
Epoch 56, Val Loss: 4.60989
Epoch 57, Val Loss: 4.48110
Epoch 58, Val Loss: 4.46679
Epoch 59, Val Loss: 4.45999
Epoch 60, Val Loss: 4.61690
Epoch 61, Val Loss: 4.62218
Epoch 62, Val Loss: 4.40990
Epoch 63, Val Loss: 4.41640
Epoch 64, Val Loss: 4.65453
Epoch 65, Val Loss: 4.40772
Epoch 66, Val Loss: 4.40140
Epoch 67, Val Loss: 4.38139
Epoch 68, Val Loss: 4.36481
Epoch 69, Val Loss: 4.71400
Epoch 70, Val Loss: 4.53659
Epoch 71, Val Loss: 4.74594
Epoch 72, Val Loss: 4.52036
Epoch 73, Val Loss: 4.43652
Epoch 74, Val Loss: 4.45859
Epoch 75, Val Loss: 4.62843
Epoch 76, Val Loss: 4.46957
Epoch 77, Val Loss: 4.45987
Epoch 78, Val Loss: 4.41173
Epoch 79, Val Loss: 4.40241
Epoch 80, Val Loss: 4.60327
Epoch 81, Val Loss: 4.61794
Epoch 82, Val Loss: 4.76690
Epoch 83, Val Loss: 4.46723
Epoch 84, Val Loss: 4.37698
Epoch 85, Val Loss: 4.72355
Epoch 86, Val Loss: 4.41522
Epoch 87, Val Loss: 4.43392
Epoch 88, Val Loss: 4.41423
Epoch 89, Val Loss: 4.56076
Early stopping applies.
Saved Losses
{'MSE - mean': 4.421715749165293, 'MSE - std': 0.20049525564857512, 'R2 - mean': 0.564699121176553, 'R2 - std': 0.00824751050469375} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 31.53175
Epoch 1, Val Loss: 11.19162
Epoch 2, Val Loss: 5.84800
Epoch 3, Val Loss: 5.23591
Epoch 4, Val Loss: 5.55404
Epoch 5, Val Loss: 5.18831
Epoch 6, Val Loss: 5.10520
Epoch 7, Val Loss: 4.99039
Epoch 8, Val Loss: 5.11211
Epoch 9, Val Loss: 5.02497
Epoch 10, Val Loss: 5.12361
Epoch 11, Val Loss: 4.79015
Epoch 12, Val Loss: 4.72948
Epoch 13, Val Loss: 4.83386
Epoch 14, Val Loss: 4.68428
Epoch 15, Val Loss: 4.82009
Epoch 16, Val Loss: 4.72343
Epoch 17, Val Loss: 4.75909
Epoch 18, Val Loss: 5.26363
Epoch 19, Val Loss: 4.58760
Epoch 20, Val Loss: 4.60646
Epoch 21, Val Loss: 4.56301
Epoch 22, Val Loss: 4.69741
Epoch 23, Val Loss: 4.48631
Epoch 24, Val Loss: 4.66844
Epoch 25, Val Loss: 4.44759
Epoch 26, Val Loss: 4.65478
Epoch 27, Val Loss: 4.60491
Epoch 28, Val Loss: 4.62756
Epoch 29, Val Loss: 4.48138
Epoch 30, Val Loss: 4.64561
Epoch 31, Val Loss: 4.44150
Epoch 32, Val Loss: 4.56066
Epoch 33, Val Loss: 4.57397
Epoch 34, Val Loss: 4.55584
Epoch 35, Val Loss: 4.42288
Epoch 36, Val Loss: 4.58901
Epoch 37, Val Loss: 4.42567
Epoch 38, Val Loss: 4.42578
Epoch 39, Val Loss: 4.35769
Epoch 40, Val Loss: 4.35986
Epoch 41, Val Loss: 4.59760
Epoch 42, Val Loss: 4.74005
Epoch 43, Val Loss: 4.82541
Epoch 44, Val Loss: 4.35824
Epoch 45, Val Loss: 4.36441
Epoch 46, Val Loss: 4.82740
Epoch 47, Val Loss: 4.55543
Epoch 48, Val Loss: 4.32566
Epoch 49, Val Loss: 4.44389
Epoch 50, Val Loss: 4.56688
Epoch 51, Val Loss: 4.67310
Epoch 52, Val Loss: 4.34437
Epoch 53, Val Loss: 4.27217
Epoch 54, Val Loss: 4.43260
Epoch 55, Val Loss: 4.47495
Epoch 56, Val Loss: 4.34169
Epoch 57, Val Loss: 4.31896
Epoch 58, Val Loss: 4.28234
Epoch 59, Val Loss: 4.37826
Epoch 60, Val Loss: 4.37035
Epoch 61, Val Loss: 4.28446
Epoch 62, Val Loss: 4.92279
Epoch 63, Val Loss: 4.40598
Epoch 64, Val Loss: 4.27006
Epoch 65, Val Loss: 4.26248
Epoch 66, Val Loss: 4.39494
Epoch 67, Val Loss: 4.33791
Epoch 68, Val Loss: 4.39078
Epoch 69, Val Loss: 4.29363
Epoch 70, Val Loss: 4.35302
Epoch 71, Val Loss: 4.33041
Epoch 72, Val Loss: 4.62162
Epoch 73, Val Loss: 4.25524
Epoch 74, Val Loss: 4.40324
Epoch 75, Val Loss: 4.24943
Epoch 76, Val Loss: 4.34377
Epoch 77, Val Loss: 4.28915
Epoch 78, Val Loss: 4.46771
Epoch 79, Val Loss: 4.43381
Epoch 80, Val Loss: 4.38266
Epoch 81, Val Loss: 4.33425
Epoch 82, Val Loss: 4.50593
Epoch 83, Val Loss: 4.30431
Epoch 84, Val Loss: 4.23204
Epoch 85, Val Loss: 4.67850
Epoch 86, Val Loss: 4.20397
Epoch 87, Val Loss: 4.35532
Epoch 88, Val Loss: 4.58467
Epoch 89, Val Loss: 5.06687
Epoch 90, Val Loss: 4.38530
Epoch 91, Val Loss: 4.24487
Epoch 92, Val Loss: 4.57888
Epoch 93, Val Loss: 4.18046
Epoch 94, Val Loss: 4.19686
Epoch 95, Val Loss: 4.18428
Epoch 96, Val Loss: 4.31190
Epoch 97, Val Loss: 4.48998
Epoch 98, Val Loss: 4.19244
Epoch 99, Val Loss: 4.18290
Saved Losses
{'MSE - mean': 4.42362692193218, 'MSE - std': 0.17366553600880427, 'R2 - mean': 0.5551269733397324, 'R2 - std': 0.018052537626982744} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 34.31843
Epoch 1, Val Loss: 12.40204
Epoch 2, Val Loss: 8.40972
Epoch 3, Val Loss: 7.25325
Epoch 4, Val Loss: 6.88454
Epoch 5, Val Loss: 6.89707
Epoch 6, Val Loss: 6.69612
Epoch 7, Val Loss: 6.59167
Epoch 8, Val Loss: 6.32253
Epoch 9, Val Loss: 6.23825
Epoch 10, Val Loss: 6.12638
Epoch 11, Val Loss: 6.16357
Epoch 12, Val Loss: 6.07812
Epoch 13, Val Loss: 6.18258
Epoch 14, Val Loss: 5.85196
Epoch 15, Val Loss: 5.88333
Epoch 16, Val Loss: 5.95637
Epoch 17, Val Loss: 5.93939
Epoch 18, Val Loss: 5.78061
Epoch 19, Val Loss: 5.96119
Epoch 20, Val Loss: 5.72489
Epoch 21, Val Loss: 5.75216
Epoch 22, Val Loss: 5.93631
Epoch 23, Val Loss: 5.91039
Epoch 24, Val Loss: 6.05479
Epoch 25, Val Loss: 5.77152
Epoch 26, Val Loss: 5.77120
Epoch 27, Val Loss: 5.79627
Epoch 28, Val Loss: 5.90942
Epoch 29, Val Loss: 5.79100
Epoch 30, Val Loss: 5.63652
Epoch 31, Val Loss: 6.02373
Epoch 32, Val Loss: 6.30105
Epoch 33, Val Loss: 5.65589
Epoch 34, Val Loss: 5.60967
Epoch 35, Val Loss: 5.68675
Epoch 36, Val Loss: 5.80818
Epoch 37, Val Loss: 5.80093
Epoch 38, Val Loss: 5.90159
Epoch 39, Val Loss: 5.59177
Epoch 40, Val Loss: 6.00312
Epoch 41, Val Loss: 5.79272
Epoch 42, Val Loss: 5.67716
Epoch 43, Val Loss: 5.77752
Epoch 44, Val Loss: 6.16275
Epoch 45, Val Loss: 5.83287
Epoch 46, Val Loss: 5.76681
Epoch 47, Val Loss: 5.95428
Epoch 48, Val Loss: 5.70102
Epoch 49, Val Loss: 6.07052
Epoch 50, Val Loss: 5.80225
Epoch 51, Val Loss: 5.72056
Epoch 52, Val Loss: 6.25378
Epoch 53, Val Loss: 5.62158
Epoch 54, Val Loss: 5.79453
Epoch 55, Val Loss: 5.82016
Epoch 56, Val Loss: 5.74855
Epoch 57, Val Loss: 6.01113
Epoch 58, Val Loss: 5.61265
Epoch 59, Val Loss: 5.75949
Epoch 60, Val Loss: 5.66891
Early stopping applies.
Saved Losses
{'MSE - mean': 4.656204306563873, 'MSE - std': 0.4904046636057342, 'R2 - mean': 0.5517009916901066, 'R2 - std': 0.017540373225025604} 
 

Results After CV: {'MSE - mean': 4.656204306563873, 'MSE - std': 0.4904046636057342, 'R2 - mean': 0.5517009916901066, 'R2 - std': 0.017540373225025604}
Train time: 73.32751858400079
Inference time: 0.0516115059996082
Finished cross validation
