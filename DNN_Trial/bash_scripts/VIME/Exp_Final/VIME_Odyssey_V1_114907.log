

----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/brazillian_houses.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/brazillian_houses.yml', data_parallel=False, dataset='Brazillian_Houses', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=60, nominal_idx=[0, 6], num_bins=10, num_classes=1, num_features=12, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[7], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='skewed')
Start hyperparameter optimization
Loading dataset Brazillian_Houses...
Dataset loaded! 

(10692, 12)
Using an existing study with name 'VIME_Brazillian_Houses' instead of creating a new one.
In get_device
On Device: cuda
Fold 1
num_features : 12
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 6]
ordinal_idx : [7]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :12
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 6]
ordinal_idx : [7]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (8553, 12)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 8, 9, 10, 11]
Cat Dims V1 : [3]
Cat Idx V1 : [0, 6, 7] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 8, 9, 10, 11] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7]


Ordinal Idx V2: [0]


Cat Dims V2 : [3]
Cat Idx V2 : [0] 
 

Train: [['furnished' 0.0 0.0 0.0 0.0]
 ['not furnished' 0.0 0.0 0.0 0.0]
 ['not furnished' 0.0 0.0 1.0 0.0]
 ['not furnished' 0.0 0.0 1.0 0.0]
 ['not furnished' 0.0 0.0 0.0 0.0]
 ['not furnished' 0.0 0.0 0.0 0.0]
 ['not furnished' 0.0 0.0 0.0 1.0]
 ['furnished' 0.0 0.0 0.0 1.0]
 ['furnished' 0.0 0.0 0.0 0.0]
 ['not furnished' 0.0 1.0 0.0 0.0]] 
 
 
Val : (8553, 17) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 8, 9, 10, 11] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7]


Ordinal Idx V2: [0]


Cat Dims V2 : [3]
Cat Idx V2 : [0] 
 

Train: [[2.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 -0.1364589317102596 -0.4290206216694779
  -0.8773235341642969 -0.38210703008482383 0.3143900838473033
  0.0476157378803886 -0.17368651042805008 -0.046656181656635924
  -0.2352115095409037]
 [1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.2822814325909617 1.2768898279535086
  1.2505944697228086 -1.009393292717357 2.412884442887873
  -0.0020341198085244675 0.3121416365292454 0.39819148158011797
  0.20226436146634846]
 [1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 -0.11970931713821076
  -1.2819758464809712 -0.8773235341642969 -0.38210703008482383
  0.15296744084418257 -0.013513855690354078 -0.32002028963205476
  -0.10764569234081725 -0.25604369387458237]
 [1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 -0.16828319939715244
  -0.4290206216694779 -0.8773235341642969 -1.009393292717357
  -0.49272313116830035 -0.055414891659032156 -0.8140431282247745
  -0.10128659644009692 -0.7560161178828705]
 [1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 -0.21183219728447947
  -1.2819758464809712 -0.8773235341642969 -1.009393292717357
  -0.6541457741714212 -0.07091253509950213 -0.9053554064480734
  -0.10041944699908961 -0.8810092238849426]
 [1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.3760792741944353 0.42393460314201536
  0.5412884684271068 3.3816105457103753 -0.8155684171745419
  -0.07091253509950213 1.201851014089594 0.13342185225921702
  1.4105310528197117]
 [1.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 -0.13310900879584986
  -0.4290206216694779 -0.8773235341642969 -1.009393292717357
  0.3143900838473033 -0.02843751233673257 -0.5834210921992632
  -0.08307645817894325 -0.5893586432134411]
 [2.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 -0.19508258271243062
  -1.2819758464809712 -0.8773235341642969 -1.009393292717357
  -0.49272313116830035 -0.03704731424810478 -0.46635406883605945
  -0.09752894886239855 -0.48519772154504776]
 [2.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 -0.21015723582727458
  -1.2819758464809712 -0.8773235341642969 -1.009393292717357
  -0.49272313116830035 -0.04393515577720254 -0.5248875805176613
  -0.06428822029045138 -0.5476942745460838]
 [1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 -0.17665800668317688
  -1.2819758464809712 -0.8773235341642969 -0.38210703008482383
  0.7986580128566655 -0.0393432614244707 -0.9697422692978356
  -0.0952165503530457 -0.9435057768859786]] 
 
 
Val : (8553, 17) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :17
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 2, 3, 4, 5, 6, 7]
ordinal_idx : [0]
num_idx : [8, 9, 10, 11, 12, 13, 14, 15, 16]
cat_dims : [3]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 1416
Unique values in y_train: (array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.401e+03, 1.402e+03,
       1.403e+03]), 1400)
Unique values in y_test: (array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.400e+03, 1.401e+03,
       1.402e+03]), 1026)
MAX : 1403 , Max diff : 3, LEN : 1400 , BINS : 1416
WE ARE HERE
IN THE SHIIIIIT II
Train after shift II : [  -2   -1    0 ... 1398 1399 1400],  Length : 1399
Test after shift II : [  -2   -1    0 ... 1397 1398 1399], Length : 1025 

VERIFY SHIFT
Train after shift : [  -2   -1    0 ... 1398 1399 1400], Length : 1399
Test after shift : [  -2   -1    0 ... 1397 1398 1399], Length : 1025
Number of Classes After Bin Verifier: 1416
In get_device
On Device: cuda
{'p_m': 0.579292276216013, 'alpha': 2.798652820540567, 'K': 10, 'beta': 5.783148258363777}
Fitted encoder
Trial 1 failed with parameters: {'p_m': 0.579292276216013, 'alpha': 2.798652820540567, 'K': 10, 'beta': 5.783148258363777} because of the following error: RuntimeError('CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 380, in __call__
    sc, time = cross_validation(model, self.X, self.y, args_cp, visual=False, save_model=False)#Dont save model during HPT
  File "train.py", line 275, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/vime.py", line 56, in fit
    loss_history, val_loss_history, _ = self.fit_semi(X, y, X, X_val, y_val, p_m=self.params["p_m"],
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/vime.py", line 211, in fit_semi
    loss = y_loss + beta * yu_loss + penalty  # Add the penalty term
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Trial 1 failed with value None.


----------------------------------------------------------------------------
Training VIME Vesion 1 with Dataset: config/abalone.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/abalone.yml', data_parallel=False, dataset='Abalone', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=60, nominal_idx=[0], num_bins=10, num_classes=1, num_features=8, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset Abalone...
Dataset loaded! 

(4177, 8)
Using an existing study with name 'VIME_Abalone' instead of creating a new one.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}
Fitted encoder
Epoch 0, Val Loss: 2.15964
Epoch 1, Val Loss: 2.14092
Epoch 2, Val Loss: 2.11318
Epoch 3, Val Loss: 2.11944
Epoch 4, Val Loss: 2.10174
Epoch 5, Val Loss: 2.11241
Epoch 6, Val Loss: 2.09594
Epoch 7, Val Loss: 2.09992
Epoch 8, Val Loss: 2.09259
Epoch 9, Val Loss: 2.07893
Epoch 10, Val Loss: 2.12065
Epoch 11, Val Loss: 2.07254
Epoch 12, Val Loss: 2.10796
Epoch 13, Val Loss: 2.14010
Epoch 14, Val Loss: 2.09163
Epoch 15, Val Loss: 2.08296
Epoch 16, Val Loss: 2.10622
Epoch 17, Val Loss: 2.09021
Epoch 18, Val Loss: 2.08759
Epoch 19, Val Loss: 2.05967
Epoch 20, Val Loss: 2.06335
Epoch 21, Val Loss: 2.09274
Epoch 22, Val Loss: 2.07296
Epoch 23, Val Loss: 2.07185
Epoch 24, Val Loss: 2.06134
Epoch 25, Val Loss: 2.07027
Epoch 26, Val Loss: 2.09867
Epoch 27, Val Loss: 2.09498
Epoch 28, Val Loss: 2.04966
Epoch 29, Val Loss: 2.06480
Epoch 30, Val Loss: 2.07624
Epoch 31, Val Loss: 2.05185
Epoch 32, Val Loss: 2.07758
Epoch 33, Val Loss: 2.05093
Epoch 34, Val Loss: 2.04570
Epoch 35, Val Loss: 2.06107
Epoch 36, Val Loss: 2.05133
Epoch 37, Val Loss: 2.06602
Epoch 38, Val Loss: 2.05857
Epoch 39, Val Loss: 2.04567
Epoch 40, Val Loss: 2.04389
Epoch 41, Val Loss: 2.05426
Epoch 42, Val Loss: 2.04982
Epoch 43, Val Loss: 2.05887
Epoch 44, Val Loss: 2.06430
Epoch 45, Val Loss: 2.05539
Epoch 46, Val Loss: 2.04676
Epoch 47, Val Loss: 2.05566
Epoch 48, Val Loss: 2.04527
Epoch 49, Val Loss: 2.08245
Epoch 50, Val Loss: 2.07146
Epoch 51, Val Loss: 2.04435
Epoch 52, Val Loss: 2.06111
Epoch 53, Val Loss: 2.05718
Epoch 54, Val Loss: 2.05939
Epoch 55, Val Loss: 2.05788
Epoch 56, Val Loss: 2.09303
Epoch 57, Val Loss: 2.07218
Epoch 58, Val Loss: 2.08081
Epoch 59, Val Loss: 2.06512
Epoch 60, Val Loss: 2.06326
Epoch 61, Val Loss: 2.04597
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.1867, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}
Fitted encoder
Epoch 0, Val Loss: 1.99383
Epoch 1, Val Loss: 1.95600
Epoch 2, Val Loss: 1.94909
Epoch 3, Val Loss: 1.96548
Epoch 4, Val Loss: 1.93951
Epoch 5, Val Loss: 1.95475
Epoch 6, Val Loss: 1.94810
Epoch 7, Val Loss: 1.94695
Epoch 8, Val Loss: 1.94881
Epoch 9, Val Loss: 1.94838
Epoch 10, Val Loss: 1.94306
Epoch 11, Val Loss: 1.94360
Epoch 12, Val Loss: 1.94075
Epoch 13, Val Loss: 1.93034
Epoch 14, Val Loss: 1.94218
Epoch 15, Val Loss: 1.93518
Epoch 16, Val Loss: 1.93087
Epoch 17, Val Loss: 1.90953
Epoch 18, Val Loss: 1.91444
Epoch 19, Val Loss: 1.94274
Epoch 20, Val Loss: 1.97836
Epoch 21, Val Loss: 1.93027
Epoch 22, Val Loss: 1.95466
Epoch 23, Val Loss: 1.94171
Epoch 24, Val Loss: 1.92307
Epoch 25, Val Loss: 1.90620
Epoch 26, Val Loss: 1.92620
Epoch 27, Val Loss: 1.90768
Epoch 28, Val Loss: 1.90853
Epoch 29, Val Loss: 1.94371
Epoch 30, Val Loss: 1.92240
Epoch 31, Val Loss: 1.93857
Epoch 32, Val Loss: 1.94278
Epoch 33, Val Loss: 1.94086
Epoch 34, Val Loss: 1.92317
Epoch 35, Val Loss: 1.95444
Epoch 36, Val Loss: 1.99978
Epoch 37, Val Loss: 2.00951
Epoch 38, Val Loss: 1.90460
Epoch 39, Val Loss: 1.90796
Epoch 40, Val Loss: 1.91848
Epoch 41, Val Loss: 1.91277
Epoch 42, Val Loss: 1.91449
Epoch 43, Val Loss: 1.90544
Epoch 44, Val Loss: 1.90778
Epoch 45, Val Loss: 1.92936
Epoch 46, Val Loss: 1.90252
Epoch 47, Val Loss: 1.92008
Epoch 48, Val Loss: 1.90872
Epoch 49, Val Loss: 1.92791
Epoch 50, Val Loss: 1.91323
Epoch 51, Val Loss: 1.92868
Epoch 52, Val Loss: 1.92009
Epoch 53, Val Loss: 1.90175
Epoch 54, Val Loss: 1.89794
Epoch 55, Val Loss: 1.91508
Epoch 56, Val Loss: 1.90410
Epoch 57, Val Loss: 1.89760
Epoch 58, Val Loss: 1.89804
Epoch 59, Val Loss: 1.90249
Epoch 60, Val Loss: 1.91509
Epoch 61, Val Loss: 1.90491
Epoch 62, Val Loss: 1.93105
Epoch 63, Val Loss: 1.89263
Epoch 64, Val Loss: 1.89869
Epoch 65, Val Loss: 1.90257
Epoch 66, Val Loss: 1.94112
Epoch 67, Val Loss: 1.90582
Epoch 68, Val Loss: 1.89134
Epoch 69, Val Loss: 1.90623
Epoch 70, Val Loss: 1.91881
Epoch 71, Val Loss: 1.88907
Epoch 72, Val Loss: 1.90078
Epoch 73, Val Loss: 1.90103
Epoch 74, Val Loss: 1.90368
Epoch 75, Val Loss: 1.89423
Epoch 76, Val Loss: 1.89530
Epoch 77, Val Loss: 1.90583
Epoch 78, Val Loss: 1.91720
Epoch 79, Val Loss: 1.89316
Epoch 80, Val Loss: 1.88694
Epoch 81, Val Loss: 1.91376
Epoch 82, Val Loss: 1.89891
Epoch 83, Val Loss: 1.90730
Epoch 84, Val Loss: 1.90452
Epoch 85, Val Loss: 1.90002
Epoch 86, Val Loss: 1.89142
Epoch 87, Val Loss: 1.91043
Epoch 88, Val Loss: 1.90576
Epoch 89, Val Loss: 1.89510
Epoch 90, Val Loss: 1.89863
Epoch 91, Val Loss: 1.90394
Epoch 92, Val Loss: 1.89135
Epoch 93, Val Loss: 1.91198
Epoch 94, Val Loss: 1.93081
Epoch 95, Val Loss: 1.90890
Epoch 96, Val Loss: 1.89484
Epoch 97, Val Loss: 1.89460
Epoch 98, Val Loss: 1.91683
Epoch 99, Val Loss: 1.89970
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3613, 'Log Loss - std': 0.17459999999999987} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}
Fitted encoder
Epoch 0, Val Loss: 2.13639
Epoch 1, Val Loss: 2.14667
Epoch 2, Val Loss: 2.11703
Epoch 3, Val Loss: 2.12115
Epoch 4, Val Loss: 2.11130
Epoch 5, Val Loss: 2.10570
Epoch 6, Val Loss: 2.11194
Epoch 7, Val Loss: 2.11087
Epoch 8, Val Loss: 2.10110
Epoch 9, Val Loss: 2.09747
Epoch 10, Val Loss: 2.10567
Epoch 11, Val Loss: 2.09849
Epoch 12, Val Loss: 2.10617
Epoch 13, Val Loss: 2.11869
Epoch 14, Val Loss: 2.12518
Epoch 15, Val Loss: 2.08792
Epoch 16, Val Loss: 2.09449
Epoch 17, Val Loss: 2.10081
Epoch 18, Val Loss: 2.09514
Epoch 19, Val Loss: 2.08028
Epoch 20, Val Loss: 2.07115
Epoch 21, Val Loss: 2.08188
Epoch 22, Val Loss: 2.08741
Epoch 23, Val Loss: 2.09446
Epoch 24, Val Loss: 2.08106
Epoch 25, Val Loss: 2.11946
Epoch 26, Val Loss: 2.09099
Epoch 27, Val Loss: 2.08430
Epoch 28, Val Loss: 2.11969
Epoch 29, Val Loss: 2.06996
Epoch 30, Val Loss: 2.07860
Epoch 31, Val Loss: 2.07003
Epoch 32, Val Loss: 2.09124
Epoch 33, Val Loss: 2.07747
Epoch 34, Val Loss: 2.09588
Epoch 35, Val Loss: 2.05494
Epoch 36, Val Loss: 2.11593
Epoch 37, Val Loss: 2.08433
Epoch 38, Val Loss: 2.09238
Epoch 39, Val Loss: 2.12006
Epoch 40, Val Loss: 2.14800
Epoch 41, Val Loss: 2.11972
Epoch 42, Val Loss: 2.08125
Epoch 43, Val Loss: 2.07865
Epoch 44, Val Loss: 2.08164
Epoch 45, Val Loss: 2.07915
Epoch 46, Val Loss: 2.05692
Epoch 47, Val Loss: 2.05744
Epoch 48, Val Loss: 2.05992
Epoch 49, Val Loss: 2.10095
Epoch 50, Val Loss: 2.14978
Epoch 51, Val Loss: 2.10339
Epoch 52, Val Loss: 2.12428
Epoch 53, Val Loss: 2.06132
Epoch 54, Val Loss: 2.06646
Epoch 55, Val Loss: 2.06507
Epoch 56, Val Loss: 2.08211
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3254333333333332, 'Log Loss - std': 0.15131515309299173} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}
Fitted encoder
Epoch 0, Val Loss: 2.10938
Epoch 1, Val Loss: 2.08895
Epoch 2, Val Loss: 2.06779
Epoch 3, Val Loss: 2.06792
Epoch 4, Val Loss: 2.05828
Epoch 5, Val Loss: 2.05953
Epoch 6, Val Loss: 2.05535
Epoch 7, Val Loss: 2.05499
Epoch 8, Val Loss: 2.05845
Epoch 9, Val Loss: 2.05234
Epoch 10, Val Loss: 2.06406
Epoch 11, Val Loss: 2.05677
Epoch 12, Val Loss: 2.06524
Epoch 13, Val Loss: 2.04945
Epoch 14, Val Loss: 2.04592
Epoch 15, Val Loss: 2.04965
Epoch 16, Val Loss: 2.05545
Epoch 17, Val Loss: 2.06176
Epoch 18, Val Loss: 2.04734
Epoch 19, Val Loss: 2.04091
Epoch 20, Val Loss: 2.04609
Epoch 21, Val Loss: 2.04919
Epoch 22, Val Loss: 2.07526
Epoch 23, Val Loss: 2.06710
Epoch 24, Val Loss: 2.03796
Epoch 25, Val Loss: 2.03726
Epoch 26, Val Loss: 2.06970
Epoch 27, Val Loss: 2.04259
Epoch 28, Val Loss: 2.04665
Epoch 29, Val Loss: 2.03539
Epoch 30, Val Loss: 2.03470
Epoch 31, Val Loss: 2.03956
Epoch 32, Val Loss: 2.03653
Epoch 33, Val Loss: 2.03931
Epoch 34, Val Loss: 2.02298
Epoch 35, Val Loss: 2.02322
Epoch 36, Val Loss: 2.06776
Epoch 37, Val Loss: 2.06352
Epoch 38, Val Loss: 2.03478
Epoch 39, Val Loss: 2.03929
Epoch 40, Val Loss: 2.01921
Epoch 41, Val Loss: 2.01140
Epoch 42, Val Loss: 2.02560
Epoch 43, Val Loss: 2.02195
Epoch 44, Val Loss: 2.05729
Epoch 45, Val Loss: 2.02987
Epoch 46, Val Loss: 2.03941
Epoch 47, Val Loss: 2.04506
Epoch 48, Val Loss: 2.03162
Epoch 49, Val Loss: 2.00377
Epoch 50, Val Loss: 2.02895
Epoch 51, Val Loss: 2.01985
Epoch 52, Val Loss: 2.03167
Epoch 53, Val Loss: 2.01783
Epoch 54, Val Loss: 2.02586
Epoch 55, Val Loss: 2.01769
Epoch 56, Val Loss: 2.02969
Epoch 57, Val Loss: 2.01414
Epoch 58, Val Loss: 2.01629
Epoch 59, Val Loss: 2.06460
Epoch 60, Val Loss: 2.08477
Epoch 61, Val Loss: 2.07797
Epoch 62, Val Loss: 2.08771
Epoch 63, Val Loss: 2.09849
Epoch 64, Val Loss: 2.10729
Epoch 65, Val Loss: 2.09679
Epoch 66, Val Loss: 2.08799
Epoch 67, Val Loss: 2.02560
Epoch 68, Val Loss: 2.08337
Epoch 69, Val Loss: 2.07873
Epoch 70, Val Loss: 2.02111
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2060500000000003, 'Log Loss - std': 0.24480471298567752} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}
Fitted encoder
Epoch 0, Val Loss: 1.95187
Epoch 1, Val Loss: 1.95823
Epoch 2, Val Loss: 1.98301
Epoch 3, Val Loss: 1.95182
Epoch 4, Val Loss: 1.96284
Epoch 5, Val Loss: 1.95507
Epoch 6, Val Loss: 2.05286
Epoch 7, Val Loss: 2.02474
Epoch 8, Val Loss: 1.97058
Epoch 9, Val Loss: 1.93729
Epoch 10, Val Loss: 1.97713
Epoch 11, Val Loss: 1.93331
Epoch 12, Val Loss: 1.91499
Epoch 13, Val Loss: 1.90786
Epoch 14, Val Loss: 1.90748
Epoch 15, Val Loss: 1.89590
Epoch 16, Val Loss: 1.95407
Epoch 17, Val Loss: 1.95120
Epoch 18, Val Loss: 1.95952
Epoch 19, Val Loss: 1.94576
Epoch 20, Val Loss: 1.90842
Epoch 21, Val Loss: 1.91938
Epoch 22, Val Loss: 1.90386
Epoch 23, Val Loss: 1.94068
Epoch 24, Val Loss: 1.92312
Epoch 25, Val Loss: 1.89737
Epoch 26, Val Loss: 1.92742
Epoch 27, Val Loss: 1.89099
Epoch 28, Val Loss: 1.90159
Epoch 29, Val Loss: 1.90376
Epoch 30, Val Loss: 1.90151
Epoch 31, Val Loss: 1.92826
Epoch 32, Val Loss: 1.89335
Epoch 33, Val Loss: 1.89250
Epoch 34, Val Loss: 1.92950
Epoch 35, Val Loss: 1.88678
Epoch 36, Val Loss: 1.88333
Epoch 37, Val Loss: 1.90872
Epoch 38, Val Loss: 1.90272
Epoch 39, Val Loss: 1.91225
Epoch 40, Val Loss: 1.91664
Epoch 41, Val Loss: 1.88525
Epoch 42, Val Loss: 1.89258
Epoch 43, Val Loss: 1.90446
Epoch 44, Val Loss: 1.90096
Epoch 45, Val Loss: 1.88775
Epoch 46, Val Loss: 1.89555
Epoch 47, Val Loss: 1.89621
Epoch 48, Val Loss: 1.89594
Epoch 49, Val Loss: 1.99708
Epoch 50, Val Loss: 1.89227
Epoch 51, Val Loss: 1.90532
Epoch 52, Val Loss: 1.87957
Epoch 53, Val Loss: 1.90062
Epoch 54, Val Loss: 1.93067
Epoch 55, Val Loss: 1.89355
Epoch 56, Val Loss: 1.88438
Epoch 57, Val Loss: 1.89679
Epoch 58, Val Loss: 1.88283
Epoch 59, Val Loss: 1.89084
Epoch 60, Val Loss: 1.89635
Epoch 61, Val Loss: 1.90610
Epoch 62, Val Loss: 1.90536
Epoch 63, Val Loss: 1.89243
Epoch 64, Val Loss: 1.88224
Epoch 65, Val Loss: 1.89300
Epoch 66, Val Loss: 1.90323
Epoch 67, Val Loss: 1.89340
Epoch 68, Val Loss: 1.89284
Epoch 69, Val Loss: 1.87089
Epoch 70, Val Loss: 1.88188
Epoch 71, Val Loss: 1.88412
Epoch 72, Val Loss: 1.88866
Epoch 73, Val Loss: 1.88643
Epoch 74, Val Loss: 1.88297
Epoch 75, Val Loss: 1.88498
Epoch 76, Val Loss: 1.87383
Epoch 77, Val Loss: 1.89423
Epoch 78, Val Loss: 1.87435
Epoch 79, Val Loss: 1.88467
Epoch 80, Val Loss: 1.90599
Epoch 81, Val Loss: 1.91067
Epoch 82, Val Loss: 1.91423
Epoch 83, Val Loss: 1.89821
Epoch 84, Val Loss: 1.87382
Epoch 85, Val Loss: 1.89733
Epoch 86, Val Loss: 1.89078
Epoch 87, Val Loss: 1.88261
Epoch 88, Val Loss: 1.89874
Epoch 89, Val Loss: 1.88083
Epoch 90, Val Loss: 1.87411
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.2526800000000002, 'Log Loss - std': 0.2379934990708779} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 2 finished with value: 3.2526800000000002 and parameters: {'p_m': 0.6905041219714153, 'alpha': 2.1352794008342704, 'K': 2, 'beta': 1.157326077486521}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}
Fitted encoder
Epoch 0, Val Loss: 2.14685
Epoch 1, Val Loss: 2.14244
Epoch 2, Val Loss: 2.14612
Epoch 3, Val Loss: 2.15085
Epoch 4, Val Loss: 2.13528
Epoch 5, Val Loss: 2.12091
Epoch 6, Val Loss: 2.12111
Epoch 7, Val Loss: 2.12235
Epoch 8, Val Loss: 2.12486
Epoch 9, Val Loss: 2.12220
Epoch 10, Val Loss: 2.12510
Epoch 11, Val Loss: 2.11569
Epoch 12, Val Loss: 2.11448
Epoch 13, Val Loss: 2.11644
Epoch 14, Val Loss: 2.09348
Epoch 15, Val Loss: 2.09369
Epoch 16, Val Loss: 2.10658
Epoch 17, Val Loss: 2.09872
Epoch 18, Val Loss: 2.10029
Epoch 19, Val Loss: 2.10683
Epoch 20, Val Loss: 2.09843
Epoch 21, Val Loss: 2.09155
Epoch 22, Val Loss: 2.09173
Epoch 23, Val Loss: 2.06964
Epoch 24, Val Loss: 2.08485
Epoch 25, Val Loss: 2.08510
Epoch 26, Val Loss: 2.09306
Epoch 27, Val Loss: 2.07710
Epoch 28, Val Loss: 2.09332
Epoch 29, Val Loss: 2.07178
Epoch 30, Val Loss: 2.06356
Epoch 31, Val Loss: 2.07945
Epoch 32, Val Loss: 2.07599
Epoch 33, Val Loss: 2.06716
Epoch 34, Val Loss: 2.09337
Epoch 35, Val Loss: 2.06723
Epoch 36, Val Loss: 2.07714
Epoch 37, Val Loss: 2.05763
Epoch 38, Val Loss: 2.05498
Epoch 39, Val Loss: 2.06839
Epoch 40, Val Loss: 2.09790
Epoch 41, Val Loss: 2.06877
Epoch 42, Val Loss: 2.06535
Epoch 43, Val Loss: 2.05570
Epoch 44, Val Loss: 2.04729
Epoch 45, Val Loss: 2.09173
Epoch 46, Val Loss: 2.04879
Epoch 47, Val Loss: 2.05988
Epoch 48, Val Loss: 2.07481
Epoch 49, Val Loss: 2.05370
Epoch 50, Val Loss: 2.04625
Epoch 51, Val Loss: 2.05129
Epoch 52, Val Loss: 2.06675
Epoch 53, Val Loss: 2.05413
Epoch 54, Val Loss: 2.04614
Epoch 55, Val Loss: 2.06452
Epoch 56, Val Loss: 2.06962
Epoch 57, Val Loss: 2.04193
Epoch 58, Val Loss: 2.05335
Epoch 59, Val Loss: 2.10916
Epoch 60, Val Loss: 2.06770
Epoch 61, Val Loss: 2.07719
Epoch 62, Val Loss: 2.05651
Epoch 63, Val Loss: 2.04444
Epoch 64, Val Loss: 2.07051
Epoch 65, Val Loss: 2.04895
Epoch 66, Val Loss: 2.04464
Epoch 67, Val Loss: 2.07338
Epoch 68, Val Loss: 2.04929
Epoch 69, Val Loss: 2.05694
Epoch 70, Val Loss: 2.04332
Epoch 71, Val Loss: 2.05641
Epoch 72, Val Loss: 2.07236
Epoch 73, Val Loss: 2.05305
Epoch 74, Val Loss: 2.04252
Epoch 75, Val Loss: 2.06171
Epoch 76, Val Loss: 2.05022
Epoch 77, Val Loss: 2.05851
Epoch 78, Val Loss: 2.05822
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.9881, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}
Fitted encoder
Epoch 0, Val Loss: 1.96561
Epoch 1, Val Loss: 1.95302
Epoch 2, Val Loss: 1.96333
Epoch 3, Val Loss: 1.96291
Epoch 4, Val Loss: 1.97006
Epoch 5, Val Loss: 1.94023
Epoch 6, Val Loss: 1.94235
Epoch 7, Val Loss: 1.94582
Epoch 8, Val Loss: 1.95440
Epoch 9, Val Loss: 1.93449
Epoch 10, Val Loss: 1.93942
Epoch 11, Val Loss: 1.93641
Epoch 12, Val Loss: 1.94406
Epoch 13, Val Loss: 1.94255
Epoch 14, Val Loss: 2.07551
Epoch 15, Val Loss: 1.95333
Epoch 16, Val Loss: 1.92885
Epoch 17, Val Loss: 1.92865
Epoch 18, Val Loss: 1.92227
Epoch 19, Val Loss: 1.92664
Epoch 20, Val Loss: 1.91985
Epoch 21, Val Loss: 1.93084
Epoch 22, Val Loss: 1.91592
Epoch 23, Val Loss: 1.93217
Epoch 24, Val Loss: 1.91855
Epoch 25, Val Loss: 1.91746
Epoch 26, Val Loss: 1.93479
Epoch 27, Val Loss: 1.91364
Epoch 28, Val Loss: 1.91747
Epoch 29, Val Loss: 1.90946
Epoch 30, Val Loss: 1.92108
Epoch 31, Val Loss: 1.91099
Epoch 32, Val Loss: 1.92084
Epoch 33, Val Loss: 1.94089
Epoch 34, Val Loss: 1.91720
Epoch 35, Val Loss: 1.90966
Epoch 36, Val Loss: 1.93123
Epoch 37, Val Loss: 1.90887
Epoch 38, Val Loss: 1.91342
Epoch 39, Val Loss: 1.92350
Epoch 40, Val Loss: 1.92071
Epoch 41, Val Loss: 1.91380
Epoch 42, Val Loss: 1.91156
Epoch 43, Val Loss: 1.90244
Epoch 44, Val Loss: 1.91760
Epoch 45, Val Loss: 1.91159
Epoch 46, Val Loss: 1.90642
Epoch 47, Val Loss: 1.90868
Epoch 48, Val Loss: 1.90164
Epoch 49, Val Loss: 1.91568
Epoch 50, Val Loss: 1.90778
Epoch 51, Val Loss: 1.90966
Epoch 52, Val Loss: 1.90265
Epoch 53, Val Loss: 1.91354
Epoch 54, Val Loss: 1.91014
Epoch 55, Val Loss: 1.91289
Epoch 56, Val Loss: 1.91705
Epoch 57, Val Loss: 1.91675
Epoch 58, Val Loss: 1.90866
Epoch 59, Val Loss: 1.91074
Epoch 60, Val Loss: 1.91472
Epoch 61, Val Loss: 1.90421
Epoch 62, Val Loss: 1.90917
Epoch 63, Val Loss: 1.89598
Epoch 64, Val Loss: 1.91016
Epoch 65, Val Loss: 1.91114
Epoch 66, Val Loss: 1.90557
Epoch 67, Val Loss: 1.90006
Epoch 68, Val Loss: 1.92667
Epoch 69, Val Loss: 1.90676
Epoch 70, Val Loss: 1.93000
Epoch 71, Val Loss: 1.90188
Epoch 72, Val Loss: 1.90588
Epoch 73, Val Loss: 1.89988
Epoch 74, Val Loss: 1.90161
Epoch 75, Val Loss: 1.90706
Epoch 76, Val Loss: 1.92435
Epoch 77, Val Loss: 1.90044
Epoch 78, Val Loss: 1.90788
Epoch 79, Val Loss: 1.90008
Epoch 80, Val Loss: 1.91268
Epoch 81, Val Loss: 1.91275
Epoch 82, Val Loss: 1.92153
Epoch 83, Val Loss: 1.91774
Epoch 84, Val Loss: 1.90613
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.0387500000000003, 'Log Loss - std': 0.05064999999999986} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}
Fitted encoder
Epoch 0, Val Loss: 2.12748
Epoch 1, Val Loss: 2.12648
Epoch 2, Val Loss: 2.13091
Epoch 3, Val Loss: 2.12067
Epoch 4, Val Loss: 2.11408
Epoch 5, Val Loss: 2.10400
Epoch 6, Val Loss: 2.11543
Epoch 7, Val Loss: 2.08774
Epoch 8, Val Loss: 2.11072
Epoch 9, Val Loss: 2.10038
Epoch 10, Val Loss: 2.09086
Epoch 11, Val Loss: 2.10246
Epoch 12, Val Loss: 2.10080
Epoch 13, Val Loss: 2.07087
Epoch 14, Val Loss: 2.11761
Epoch 15, Val Loss: 2.08049
Epoch 16, Val Loss: 2.06927
Epoch 17, Val Loss: 2.07594
Epoch 18, Val Loss: 2.07658
Epoch 19, Val Loss: 2.09382
Epoch 20, Val Loss: 2.07295
Epoch 21, Val Loss: 2.06548
Epoch 22, Val Loss: 2.08298
Epoch 23, Val Loss: 2.07665
Epoch 24, Val Loss: 2.07540
Epoch 25, Val Loss: 2.07828
Epoch 26, Val Loss: 2.06119
Epoch 27, Val Loss: 2.07014
Epoch 28, Val Loss: 2.07804
Epoch 29, Val Loss: 2.09154
Epoch 30, Val Loss: 2.06601
Epoch 31, Val Loss: 2.06670
Epoch 32, Val Loss: 2.06782
Epoch 33, Val Loss: 2.06357
Epoch 34, Val Loss: 2.06457
Epoch 35, Val Loss: 2.06525
Epoch 36, Val Loss: 2.06020
Epoch 37, Val Loss: 2.07132
Epoch 38, Val Loss: 2.06908
Epoch 39, Val Loss: 2.08358
Epoch 40, Val Loss: 2.06390
Epoch 41, Val Loss: 2.05912
Epoch 42, Val Loss: 2.09393
Epoch 43, Val Loss: 2.07948
Epoch 44, Val Loss: 2.05535
Epoch 45, Val Loss: 2.06810
Epoch 46, Val Loss: 2.08553
Epoch 47, Val Loss: 2.07019
Epoch 48, Val Loss: 2.05727
Epoch 49, Val Loss: 2.08182
Epoch 50, Val Loss: 2.07663
Epoch 51, Val Loss: 2.06620
Epoch 52, Val Loss: 2.05614
Epoch 53, Val Loss: 2.06120
Epoch 54, Val Loss: 2.07521
Epoch 55, Val Loss: 2.07934
Epoch 56, Val Loss: 2.06592
Epoch 57, Val Loss: 2.07456
Epoch 58, Val Loss: 2.07462
Epoch 59, Val Loss: 2.06173
Epoch 60, Val Loss: 2.07132
Epoch 61, Val Loss: 2.09292
Epoch 62, Val Loss: 2.07419
Epoch 63, Val Loss: 2.06455
Epoch 64, Val Loss: 2.06248
Epoch 65, Val Loss: 2.06006
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.9912000000000005, 'Log Loss - std': 0.07894483305870406} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}
Fitted encoder
Epoch 0, Val Loss: 2.07134
Epoch 1, Val Loss: 2.08076
Epoch 2, Val Loss: 2.08604
Epoch 3, Val Loss: 2.07198
Epoch 4, Val Loss: 2.05478
Epoch 5, Val Loss: 2.05963
Epoch 6, Val Loss: 2.05708
Epoch 7, Val Loss: 2.07081
Epoch 8, Val Loss: 2.05804
Epoch 9, Val Loss: 2.09990
Epoch 10, Val Loss: 2.10659
Epoch 11, Val Loss: 2.10680
Epoch 12, Val Loss: 2.09468
Epoch 13, Val Loss: 2.09401
Epoch 14, Val Loss: 2.09293
Epoch 15, Val Loss: 2.10213
Epoch 16, Val Loss: 2.10316
Epoch 17, Val Loss: 2.09127
Epoch 18, Val Loss: 2.10515
Epoch 19, Val Loss: 2.09495
Epoch 20, Val Loss: 2.05372
Epoch 21, Val Loss: 2.03830
Epoch 22, Val Loss: 2.05148
Epoch 23, Val Loss: 2.04242
Epoch 24, Val Loss: 2.04983
Epoch 25, Val Loss: 2.03501
Epoch 26, Val Loss: 2.03240
Epoch 27, Val Loss: 2.02952
Epoch 28, Val Loss: 2.03449
Epoch 29, Val Loss: 2.03290
Epoch 30, Val Loss: 2.03173
Epoch 31, Val Loss: 2.02961
Epoch 32, Val Loss: 2.02569
Epoch 33, Val Loss: 2.03981
Epoch 34, Val Loss: 2.04311
Epoch 35, Val Loss: 2.03374
Epoch 36, Val Loss: 2.03849
Epoch 37, Val Loss: 2.04158
Epoch 38, Val Loss: 2.02391
Epoch 39, Val Loss: 2.03618
Epoch 40, Val Loss: 2.05066
Epoch 41, Val Loss: 2.04924
Epoch 42, Val Loss: 2.04124
Epoch 43, Val Loss: 2.03026
Epoch 44, Val Loss: 2.02421
Epoch 45, Val Loss: 2.02852
Epoch 46, Val Loss: 2.02783
Epoch 47, Val Loss: 2.02495
Epoch 48, Val Loss: 2.02797
Epoch 49, Val Loss: 2.02024
Epoch 50, Val Loss: 2.05131
Epoch 51, Val Loss: 2.04007
Epoch 52, Val Loss: 2.03628
Epoch 53, Val Loss: 2.01904
Epoch 54, Val Loss: 2.01580
Epoch 55, Val Loss: 2.03808
Epoch 56, Val Loss: 2.08667
Epoch 57, Val Loss: 2.02181
Epoch 58, Val Loss: 2.03268
Epoch 59, Val Loss: 2.04166
Epoch 60, Val Loss: 2.02701
Epoch 61, Val Loss: 2.03136
Epoch 62, Val Loss: 2.02710
Epoch 63, Val Loss: 2.01891
Epoch 64, Val Loss: 2.03684
Epoch 65, Val Loss: 2.01822
Epoch 66, Val Loss: 2.02431
Epoch 67, Val Loss: 2.03067
Epoch 68, Val Loss: 2.02246
Epoch 69, Val Loss: 2.01479
Epoch 70, Val Loss: 2.02762
Epoch 71, Val Loss: 2.04484
Epoch 72, Val Loss: 2.01027
Epoch 73, Val Loss: 2.01038
Epoch 74, Val Loss: 2.05163
Epoch 75, Val Loss: 2.04401
Epoch 76, Val Loss: 2.05310
Epoch 77, Val Loss: 2.02113
Epoch 78, Val Loss: 2.01431
Epoch 79, Val Loss: 2.01451
Epoch 80, Val Loss: 2.03562
Epoch 81, Val Loss: 2.02422
Epoch 82, Val Loss: 2.02672
Epoch 83, Val Loss: 2.04662
Epoch 84, Val Loss: 2.04007
Epoch 85, Val Loss: 2.04816
Epoch 86, Val Loss: 2.01144
Epoch 87, Val Loss: 2.01935
Epoch 88, Val Loss: 2.02671
Epoch 89, Val Loss: 2.01373
Epoch 90, Val Loss: 2.01694
Epoch 91, Val Loss: 2.01694
Epoch 92, Val Loss: 2.02031
Epoch 93, Val Loss: 2.01528
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.9728000000000003, 'Log Loss - std': 0.07543139266910022} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}
Fitted encoder
Epoch 0, Val Loss: 1.96043
Epoch 1, Val Loss: 1.95594
Epoch 2, Val Loss: 1.99859
Epoch 3, Val Loss: 1.95069
Epoch 4, Val Loss: 1.94837
Epoch 5, Val Loss: 1.96729
Epoch 6, Val Loss: 1.94522
Epoch 7, Val Loss: 1.94855
Epoch 8, Val Loss: 1.94896
Epoch 9, Val Loss: 1.94133
Epoch 10, Val Loss: 1.93580
Epoch 11, Val Loss: 1.93702
Epoch 12, Val Loss: 1.92106
Epoch 13, Val Loss: 1.92799
Epoch 14, Val Loss: 1.90929
Epoch 15, Val Loss: 1.90778
Epoch 16, Val Loss: 1.95797
Epoch 17, Val Loss: 1.92874
Epoch 18, Val Loss: 1.92017
Epoch 19, Val Loss: 1.95203
Epoch 20, Val Loss: 1.90694
Epoch 21, Val Loss: 1.91802
Epoch 22, Val Loss: 1.92184
Epoch 23, Val Loss: 1.91482
Epoch 24, Val Loss: 1.91110
Epoch 25, Val Loss: 1.90135
Epoch 26, Val Loss: 1.90203
Epoch 27, Val Loss: 1.91606
Epoch 28, Val Loss: 1.91042
Epoch 29, Val Loss: 1.89222
Epoch 30, Val Loss: 1.90560
Epoch 31, Val Loss: 1.89951
Epoch 32, Val Loss: 1.90727
Epoch 33, Val Loss: 1.90479
Epoch 34, Val Loss: 1.90912
Epoch 35, Val Loss: 1.90349
Epoch 36, Val Loss: 1.89704
Epoch 37, Val Loss: 1.90809
Epoch 38, Val Loss: 1.91436
Epoch 39, Val Loss: 1.89801
Epoch 40, Val Loss: 1.90980
Epoch 41, Val Loss: 1.89388
Epoch 42, Val Loss: 1.90201
Epoch 43, Val Loss: 1.90266
Epoch 44, Val Loss: 1.89822
Epoch 45, Val Loss: 1.88895
Epoch 46, Val Loss: 1.90109
Epoch 47, Val Loss: 1.92838
Epoch 48, Val Loss: 1.89483
Epoch 49, Val Loss: 1.89479
Epoch 50, Val Loss: 1.91594
Epoch 51, Val Loss: 1.90432
Epoch 52, Val Loss: 1.90178
Epoch 53, Val Loss: 1.90017
Epoch 54, Val Loss: 1.90066
Epoch 55, Val Loss: 1.89983
Epoch 56, Val Loss: 1.90758
Epoch 57, Val Loss: 1.90781
Epoch 58, Val Loss: 1.89403
Epoch 59, Val Loss: 1.90448
Epoch 60, Val Loss: 1.95414
Epoch 61, Val Loss: 1.88465
Epoch 62, Val Loss: 1.89789
Epoch 63, Val Loss: 1.89951
Epoch 64, Val Loss: 1.90096
Epoch 65, Val Loss: 1.89616
Epoch 66, Val Loss: 1.90533
Epoch 67, Val Loss: 1.93168
Epoch 68, Val Loss: 1.90246
Epoch 69, Val Loss: 1.89601
Epoch 70, Val Loss: 1.92941
Epoch 71, Val Loss: 1.89020
Epoch 72, Val Loss: 1.89658
Epoch 73, Val Loss: 1.88669
Epoch 74, Val Loss: 1.89165
Epoch 75, Val Loss: 1.89747
Epoch 76, Val Loss: 1.89229
Epoch 77, Val Loss: 2.00084
Epoch 78, Val Loss: 1.92093
Epoch 79, Val Loss: 1.89990
Epoch 80, Val Loss: 1.90839
Epoch 81, Val Loss: 1.89787
Epoch 82, Val Loss: 1.89935
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.9551000000000003, 'Log Loss - std': 0.07619104934308223} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 3 finished with value: 2.9551000000000003 and parameters: {'p_m': 0.4850039353011184, 'alpha': 9.739946057674654, 'K': 5, 'beta': 1.6644305245233249}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}
Fitted encoder
Epoch 0, Val Loss: 2.15553
Epoch 1, Val Loss: 2.14005
Epoch 2, Val Loss: 2.15589
Epoch 3, Val Loss: 2.12473
Epoch 4, Val Loss: 2.13582
Epoch 5, Val Loss: 2.12529
Epoch 6, Val Loss: 2.12258
Epoch 7, Val Loss: 2.12760
Epoch 8, Val Loss: 2.12294
Epoch 9, Val Loss: 2.14145
Epoch 10, Val Loss: 2.12402
Epoch 11, Val Loss: 2.13504
Epoch 12, Val Loss: 2.11185
Epoch 13, Val Loss: 2.11524
Epoch 14, Val Loss: 2.11078
Epoch 15, Val Loss: 2.10992
Epoch 16, Val Loss: 2.12454
Epoch 17, Val Loss: 2.10066
Epoch 18, Val Loss: 2.09646
Epoch 19, Val Loss: 2.10073
Epoch 20, Val Loss: 2.10667
Epoch 21, Val Loss: 2.10382
Epoch 22, Val Loss: 2.10671
Epoch 23, Val Loss: 2.09485
Epoch 24, Val Loss: 2.10655
Epoch 25, Val Loss: 2.08501
Epoch 26, Val Loss: 2.09605
Epoch 27, Val Loss: 2.07688
Epoch 28, Val Loss: 2.10029
Epoch 29, Val Loss: 2.09533
Epoch 30, Val Loss: 2.08504
Epoch 31, Val Loss: 2.08166
Epoch 32, Val Loss: 2.09759
Epoch 33, Val Loss: 2.07162
Epoch 34, Val Loss: 2.08659
Epoch 35, Val Loss: 2.08751
Epoch 36, Val Loss: 2.08745
Epoch 37, Val Loss: 2.08138
Epoch 38, Val Loss: 2.07890
Epoch 39, Val Loss: 2.07901
Epoch 40, Val Loss: 2.07645
Epoch 41, Val Loss: 2.07455
Epoch 42, Val Loss: 2.06840
Epoch 43, Val Loss: 2.07433
Epoch 44, Val Loss: 2.08068
Epoch 45, Val Loss: 2.08114
Epoch 46, Val Loss: 2.09037
Epoch 47, Val Loss: 2.10392
Epoch 48, Val Loss: 2.09464
Epoch 49, Val Loss: 2.06958
Epoch 50, Val Loss: 2.06991
Epoch 51, Val Loss: 2.04356
Epoch 52, Val Loss: 2.05966
Epoch 53, Val Loss: 2.06342
Epoch 54, Val Loss: 2.07200
Epoch 55, Val Loss: 2.08316
Epoch 56, Val Loss: 2.06826
Epoch 57, Val Loss: 2.04006
Epoch 58, Val Loss: 2.05282
Epoch 59, Val Loss: 2.05204
Epoch 60, Val Loss: 2.05092
Epoch 61, Val Loss: 2.05608
Epoch 62, Val Loss: 2.05761
Epoch 63, Val Loss: 2.07612
Epoch 64, Val Loss: 2.05118
Epoch 65, Val Loss: 2.05196
Epoch 66, Val Loss: 2.03378
Epoch 67, Val Loss: 2.09575
Epoch 68, Val Loss: 2.03426
Epoch 69, Val Loss: 2.02995
Epoch 70, Val Loss: 2.05097
Epoch 71, Val Loss: 2.04719
Epoch 72, Val Loss: 2.02856
Epoch 73, Val Loss: 2.02308
Epoch 74, Val Loss: 2.03999
Epoch 75, Val Loss: 2.03805
Epoch 76, Val Loss: 2.02427
Epoch 77, Val Loss: 2.03240
Epoch 78, Val Loss: 2.02954
Epoch 79, Val Loss: 2.07558
Epoch 80, Val Loss: 2.07460
Epoch 81, Val Loss: 2.06846
Epoch 82, Val Loss: 2.03583
Epoch 83, Val Loss: 2.02328
Epoch 84, Val Loss: 2.04732
Epoch 85, Val Loss: 2.02328
Epoch 86, Val Loss: 2.02301
Epoch 87, Val Loss: 2.03403
Epoch 88, Val Loss: 2.02734
Epoch 89, Val Loss: 2.02420
Epoch 90, Val Loss: 2.02285
Epoch 91, Val Loss: 2.04636
Epoch 92, Val Loss: 2.04721
Epoch 93, Val Loss: 2.02449
Epoch 94, Val Loss: 2.02540
Epoch 95, Val Loss: 2.02010
Epoch 96, Val Loss: 2.02294
Epoch 97, Val Loss: 2.02174
Epoch 98, Val Loss: 2.05039
Epoch 99, Val Loss: 2.01588
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.5946, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}
Fitted encoder
Epoch 0, Val Loss: 1.95442
Epoch 1, Val Loss: 1.95914
Epoch 2, Val Loss: 1.94568
Epoch 3, Val Loss: 1.94002
Epoch 4, Val Loss: 1.95915
Epoch 5, Val Loss: 1.95803
Epoch 6, Val Loss: 1.93641
Epoch 7, Val Loss: 1.94669
Epoch 8, Val Loss: 1.95056
Epoch 9, Val Loss: 1.93196
Epoch 10, Val Loss: 1.93763
Epoch 11, Val Loss: 1.93127
Epoch 12, Val Loss: 1.93678
Epoch 13, Val Loss: 1.92923
Epoch 14, Val Loss: 1.92924
Epoch 15, Val Loss: 1.93503
Epoch 16, Val Loss: 1.91963
Epoch 17, Val Loss: 1.94119
Epoch 18, Val Loss: 1.92241
Epoch 19, Val Loss: 1.92778
Epoch 20, Val Loss: 1.92060
Epoch 21, Val Loss: 1.91701
Epoch 22, Val Loss: 1.90682
Epoch 23, Val Loss: 1.91712
Epoch 24, Val Loss: 1.95853
Epoch 25, Val Loss: 2.02717
Epoch 26, Val Loss: 1.91794
Epoch 27, Val Loss: 1.92103
Epoch 28, Val Loss: 1.91706
Epoch 29, Val Loss: 1.92402
Epoch 30, Val Loss: 1.94911
Epoch 31, Val Loss: 1.92201
Epoch 32, Val Loss: 1.93289
Epoch 33, Val Loss: 1.92288
Epoch 34, Val Loss: 1.91272
Epoch 35, Val Loss: 1.92108
Epoch 36, Val Loss: 1.91672
Epoch 37, Val Loss: 1.91344
Epoch 38, Val Loss: 1.91236
Epoch 39, Val Loss: 1.92794
Epoch 40, Val Loss: 1.92090
Epoch 41, Val Loss: 1.92314
Epoch 42, Val Loss: 1.90557
Epoch 43, Val Loss: 1.91949
Epoch 44, Val Loss: 1.91370
Epoch 45, Val Loss: 1.90611
Epoch 46, Val Loss: 1.91770
Epoch 47, Val Loss: 1.90574
Epoch 48, Val Loss: 1.90116
Epoch 49, Val Loss: 1.90157
Epoch 50, Val Loss: 1.91156
Epoch 51, Val Loss: 1.90439
Epoch 52, Val Loss: 1.92249
Epoch 53, Val Loss: 1.89985
Epoch 54, Val Loss: 1.90469
Epoch 55, Val Loss: 1.91429
Epoch 56, Val Loss: 1.90758
Epoch 57, Val Loss: 1.90461
Epoch 58, Val Loss: 1.90787
Epoch 59, Val Loss: 1.90635
Epoch 60, Val Loss: 1.91875
Epoch 61, Val Loss: 1.91896
Epoch 62, Val Loss: 1.90468
Epoch 63, Val Loss: 1.90910
Epoch 64, Val Loss: 1.90099
Epoch 65, Val Loss: 1.90464
Epoch 66, Val Loss: 1.90443
Epoch 67, Val Loss: 1.90439
Epoch 68, Val Loss: 1.89418
Epoch 69, Val Loss: 1.89855
Epoch 70, Val Loss: 1.89916
Epoch 71, Val Loss: 1.90083
Epoch 72, Val Loss: 1.90441
Epoch 73, Val Loss: 1.90560
Epoch 74, Val Loss: 1.89825
Epoch 75, Val Loss: 1.90108
Epoch 76, Val Loss: 1.92369
Epoch 77, Val Loss: 1.90446
Epoch 78, Val Loss: 1.90489
Epoch 79, Val Loss: 1.91238
Epoch 80, Val Loss: 1.90086
Epoch 81, Val Loss: 1.89739
Epoch 82, Val Loss: 1.90558
Epoch 83, Val Loss: 1.89842
Epoch 84, Val Loss: 1.90261
Epoch 85, Val Loss: 1.90492
Epoch 86, Val Loss: 1.90636
Epoch 87, Val Loss: 1.91086
Epoch 88, Val Loss: 1.90515
Epoch 89, Val Loss: 1.90543
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.71635, 'Log Loss - std': 0.12175000000000002} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}
Fitted encoder
Epoch 0, Val Loss: 2.16767
Epoch 1, Val Loss: 2.16338
Epoch 2, Val Loss: 2.11453
Epoch 3, Val Loss: 2.11713
Epoch 4, Val Loss: 2.12709
Epoch 5, Val Loss: 2.11987
Epoch 6, Val Loss: 2.11353
Epoch 7, Val Loss: 2.11028
Epoch 8, Val Loss: 2.12655
Epoch 9, Val Loss: 2.10640
Epoch 10, Val Loss: 2.12274
Epoch 11, Val Loss: 2.10892
Epoch 12, Val Loss: 2.10927
Epoch 13, Val Loss: 2.10686
Epoch 14, Val Loss: 2.10763
Epoch 15, Val Loss: 2.11452
Epoch 16, Val Loss: 2.11354
Epoch 17, Val Loss: 2.10648
Epoch 18, Val Loss: 2.10752
Epoch 19, Val Loss: 2.11115
Epoch 20, Val Loss: 2.10390
Epoch 21, Val Loss: 2.10355
Epoch 22, Val Loss: 2.10942
Epoch 23, Val Loss: 2.10193
Epoch 24, Val Loss: 2.10514
Epoch 25, Val Loss: 2.10755
Epoch 26, Val Loss: 2.10482
Epoch 27, Val Loss: 2.10305
Epoch 28, Val Loss: 2.11420
Epoch 29, Val Loss: 2.10307
Epoch 30, Val Loss: 2.10038
Epoch 31, Val Loss: 2.10311
Epoch 32, Val Loss: 2.10039
Epoch 33, Val Loss: 2.10510
Epoch 34, Val Loss: 2.10249
Epoch 35, Val Loss: 2.10078
Epoch 36, Val Loss: 2.10409
Epoch 37, Val Loss: 2.11004
Epoch 38, Val Loss: 2.10026
Epoch 39, Val Loss: 2.10376
Epoch 40, Val Loss: 2.10006
Epoch 41, Val Loss: 2.10204
Epoch 42, Val Loss: 2.10959
Epoch 43, Val Loss: 2.10516
Epoch 44, Val Loss: 2.09720
Epoch 45, Val Loss: 2.10089
Epoch 46, Val Loss: 2.10012
Epoch 47, Val Loss: 2.10344
Epoch 48, Val Loss: 2.10458
Epoch 49, Val Loss: 2.09439
Epoch 50, Val Loss: 2.09158
Epoch 51, Val Loss: 2.09806
Epoch 52, Val Loss: 2.09508
Epoch 53, Val Loss: 2.09282
Epoch 54, Val Loss: 2.09099
Epoch 55, Val Loss: 2.08536
Epoch 56, Val Loss: 2.09470
Epoch 57, Val Loss: 2.09787
Epoch 58, Val Loss: 2.09612
Epoch 59, Val Loss: 2.09537
Epoch 60, Val Loss: 2.09234
Epoch 61, Val Loss: 2.10667
Epoch 62, Val Loss: 2.09031
Epoch 63, Val Loss: 2.10210
Epoch 64, Val Loss: 2.08875
Epoch 65, Val Loss: 2.08542
Epoch 66, Val Loss: 2.08822
Epoch 67, Val Loss: 2.08918
Epoch 68, Val Loss: 2.08565
Epoch 69, Val Loss: 2.08038
Epoch 70, Val Loss: 2.08019
Epoch 71, Val Loss: 2.09828
Epoch 72, Val Loss: 2.08170
Epoch 73, Val Loss: 2.09272
Epoch 74, Val Loss: 2.07671
Epoch 75, Val Loss: 2.08934
Epoch 76, Val Loss: 2.08758
Epoch 77, Val Loss: 2.08830
Epoch 78, Val Loss: 2.08503
Epoch 79, Val Loss: 2.07562
Epoch 80, Val Loss: 2.07532
Epoch 81, Val Loss: 2.07612
Epoch 82, Val Loss: 2.07713
Epoch 83, Val Loss: 2.07922
Epoch 84, Val Loss: 2.07476
Epoch 85, Val Loss: 2.07441
Epoch 86, Val Loss: 2.07563
Epoch 87, Val Loss: 2.07059
Epoch 88, Val Loss: 2.08211
Epoch 89, Val Loss: 2.08946
Epoch 90, Val Loss: 2.08211
Epoch 91, Val Loss: 2.07769
Epoch 92, Val Loss: 2.07322
Epoch 93, Val Loss: 2.07054
Epoch 94, Val Loss: 2.07388
Epoch 95, Val Loss: 2.07410
Epoch 96, Val Loss: 2.08091
Epoch 97, Val Loss: 2.06567
Epoch 98, Val Loss: 2.07703
Epoch 99, Val Loss: 2.08369
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.8809, 'Log Loss - std': 0.2530522607420584} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}
Fitted encoder
Epoch 0, Val Loss: 2.10177
Epoch 1, Val Loss: 2.05503
Epoch 2, Val Loss: 2.06682
Epoch 3, Val Loss: 2.05749
Epoch 4, Val Loss: 2.04115
Epoch 5, Val Loss: 2.03278
Epoch 6, Val Loss: 2.07409
Epoch 7, Val Loss: 2.03571
Epoch 8, Val Loss: 2.04590
Epoch 9, Val Loss: 2.04135
Epoch 10, Val Loss: 2.04123
Epoch 11, Val Loss: 2.03859
Epoch 12, Val Loss: 2.03057
Epoch 13, Val Loss: 2.03535
Epoch 14, Val Loss: 2.02804
Epoch 15, Val Loss: 2.02695
Epoch 16, Val Loss: 2.02368
Epoch 17, Val Loss: 2.04109
Epoch 18, Val Loss: 2.03485
Epoch 19, Val Loss: 2.02493
Epoch 20, Val Loss: 2.02149
Epoch 21, Val Loss: 2.03386
Epoch 22, Val Loss: 2.03376
Epoch 23, Val Loss: 2.03227
Epoch 24, Val Loss: 2.02130
Epoch 25, Val Loss: 2.03753
Epoch 26, Val Loss: 2.02430
Epoch 27, Val Loss: 2.02207
Epoch 28, Val Loss: 2.04021
Epoch 29, Val Loss: 2.01972
Epoch 30, Val Loss: 2.03191
Epoch 31, Val Loss: 2.02959
Epoch 32, Val Loss: 2.02912
Epoch 33, Val Loss: 2.01797
Epoch 34, Val Loss: 2.03421
Epoch 35, Val Loss: 2.02892
Epoch 36, Val Loss: 2.03315
Epoch 37, Val Loss: 2.02263
Epoch 38, Val Loss: 2.02941
Epoch 39, Val Loss: 2.03074
Epoch 40, Val Loss: 2.02049
Epoch 41, Val Loss: 2.02426
Epoch 42, Val Loss: 2.01259
Epoch 43, Val Loss: 2.01976
Epoch 44, Val Loss: 2.01776
Epoch 45, Val Loss: 2.02874
Epoch 46, Val Loss: 2.02298
Epoch 47, Val Loss: 2.01552
Epoch 48, Val Loss: 2.02201
Epoch 49, Val Loss: 2.02050
Epoch 50, Val Loss: 2.03637
Epoch 51, Val Loss: 2.02293
Epoch 52, Val Loss: 2.01113
Epoch 53, Val Loss: 2.02449
Epoch 54, Val Loss: 2.02445
Epoch 55, Val Loss: 2.03475
Epoch 56, Val Loss: 2.03670
Epoch 57, Val Loss: 2.04623
Epoch 58, Val Loss: 2.03402
Epoch 59, Val Loss: 2.00779
Epoch 60, Val Loss: 2.01820
Epoch 61, Val Loss: 2.03577
Epoch 62, Val Loss: 2.01874
Epoch 63, Val Loss: 2.01129
Epoch 64, Val Loss: 2.02800
Epoch 65, Val Loss: 2.01675
Epoch 66, Val Loss: 2.02117
Epoch 67, Val Loss: 2.01565
Epoch 68, Val Loss: 2.02382
Epoch 69, Val Loss: 2.02962
Epoch 70, Val Loss: 2.03278
Epoch 71, Val Loss: 2.01460
Epoch 72, Val Loss: 2.02901
Epoch 73, Val Loss: 2.02053
Epoch 74, Val Loss: 2.02724
Epoch 75, Val Loss: 2.02132
Epoch 76, Val Loss: 2.01445
Epoch 77, Val Loss: 2.02020
Epoch 78, Val Loss: 2.00975
Epoch 79, Val Loss: 2.05000
Epoch 80, Val Loss: 2.01267
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.869475, 'Log Loss - std': 0.22004130720162526} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}
Fitted encoder
Epoch 0, Val Loss: 1.96938
Epoch 1, Val Loss: 1.95290
Epoch 2, Val Loss: 1.95359
Epoch 3, Val Loss: 1.94580
Epoch 4, Val Loss: 1.94286
Epoch 5, Val Loss: 1.93942
Epoch 6, Val Loss: 1.93560
Epoch 7, Val Loss: 1.92227
Epoch 8, Val Loss: 1.91672
Epoch 9, Val Loss: 1.91931
Epoch 10, Val Loss: 1.92863
Epoch 11, Val Loss: 1.90563
Epoch 12, Val Loss: 1.93388
Epoch 13, Val Loss: 1.93067
Epoch 14, Val Loss: 1.90559
Epoch 15, Val Loss: 1.93937
Epoch 16, Val Loss: 1.91303
Epoch 17, Val Loss: 1.90509
Epoch 18, Val Loss: 1.91211
Epoch 19, Val Loss: 1.90198
Epoch 20, Val Loss: 1.90748
Epoch 21, Val Loss: 1.89693
Epoch 22, Val Loss: 1.89219
Epoch 23, Val Loss: 1.89501
Epoch 24, Val Loss: 1.90790
Epoch 25, Val Loss: 1.89482
Epoch 26, Val Loss: 1.91517
Epoch 27, Val Loss: 1.88554
Epoch 28, Val Loss: 1.89915
Epoch 29, Val Loss: 1.89633
Epoch 30, Val Loss: 1.89838
Epoch 31, Val Loss: 1.89092
Epoch 32, Val Loss: 1.89203
Epoch 33, Val Loss: 1.90685
Epoch 34, Val Loss: 1.89526
Epoch 35, Val Loss: 1.91105
Epoch 36, Val Loss: 1.90930
Epoch 37, Val Loss: 1.89366
Epoch 38, Val Loss: 1.90318
Epoch 39, Val Loss: 1.89448
Epoch 40, Val Loss: 1.89627
Epoch 41, Val Loss: 1.89242
Epoch 42, Val Loss: 1.88937
Epoch 43, Val Loss: 1.89662
Epoch 44, Val Loss: 1.89351
Epoch 45, Val Loss: 1.89119
Epoch 46, Val Loss: 1.89094
Epoch 47, Val Loss: 1.90346
Epoch 48, Val Loss: 1.88990
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.8878399999999997, 'Log Loss - std': 0.20020897682172004} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 4 finished with value: 2.8878399999999997 and parameters: {'p_m': 0.19716198864620227, 'alpha': 9.383405662994031, 'K': 15, 'beta': 1.9405500157011166}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}
Fitted encoder
Epoch 0, Val Loss: 2.11636
Epoch 1, Val Loss: 2.11110
Epoch 2, Val Loss: 2.09338
Epoch 3, Val Loss: 2.09163
Epoch 4, Val Loss: 2.09959
Epoch 5, Val Loss: 2.10965
Epoch 6, Val Loss: 2.08797
Epoch 7, Val Loss: 2.08218
Epoch 8, Val Loss: 2.08587
Epoch 9, Val Loss: 2.07706
Epoch 10, Val Loss: 2.07961
Epoch 11, Val Loss: 2.09450
Epoch 12, Val Loss: 2.06192
Epoch 13, Val Loss: 2.08668
Epoch 14, Val Loss: 2.09197
Epoch 15, Val Loss: 2.10363
Epoch 16, Val Loss: 2.07607
Epoch 17, Val Loss: 2.07540
Epoch 18, Val Loss: 2.05864
Epoch 19, Val Loss: 2.07868
Epoch 20, Val Loss: 2.08983
Epoch 21, Val Loss: 2.08951
Epoch 22, Val Loss: 2.06941
Epoch 23, Val Loss: 2.06080
Epoch 24, Val Loss: 2.07363
Epoch 25, Val Loss: 2.09120
Epoch 26, Val Loss: 2.06224
Epoch 27, Val Loss: 2.07369
Epoch 28, Val Loss: 2.06202
Epoch 29, Val Loss: 2.06828
Epoch 30, Val Loss: 2.05131
Epoch 31, Val Loss: 2.07639
Epoch 32, Val Loss: 2.03468
Epoch 33, Val Loss: 2.05619
Epoch 34, Val Loss: 2.06558
Epoch 35, Val Loss: 2.05700
Epoch 36, Val Loss: 2.07641
Epoch 37, Val Loss: 2.04213
Epoch 38, Val Loss: 2.05156
Epoch 39, Val Loss: 2.04988
Epoch 40, Val Loss: 2.05389
Epoch 41, Val Loss: 2.05005
Epoch 42, Val Loss: 2.07326
Epoch 43, Val Loss: 2.03352
Epoch 44, Val Loss: 2.07527
Epoch 45, Val Loss: 2.08145
Epoch 46, Val Loss: 2.05396
Epoch 47, Val Loss: 2.04272
Epoch 48, Val Loss: 2.05410
Epoch 49, Val Loss: 2.05565
Epoch 50, Val Loss: 2.04521
Epoch 51, Val Loss: 2.05555
Epoch 52, Val Loss: 2.04820
Epoch 53, Val Loss: 2.05122
Epoch 54, Val Loss: 2.04521
Epoch 55, Val Loss: 2.04409
Epoch 56, Val Loss: 2.03481
Epoch 57, Val Loss: 2.03448
Epoch 58, Val Loss: 2.03505
Epoch 59, Val Loss: 2.04446
Epoch 60, Val Loss: 2.04128
Epoch 61, Val Loss: 2.05646
Epoch 62, Val Loss: 2.05895
Epoch 63, Val Loss: 2.07747
Epoch 64, Val Loss: 2.03898
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.2694, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}
Fitted encoder
Epoch 0, Val Loss: 1.97813
Epoch 1, Val Loss: 1.95991
Epoch 2, Val Loss: 1.96062
Epoch 3, Val Loss: 1.95808
Epoch 4, Val Loss: 1.97525
Epoch 5, Val Loss: 1.95545
Epoch 6, Val Loss: 1.95145
Epoch 7, Val Loss: 1.93939
Epoch 8, Val Loss: 1.94793
Epoch 9, Val Loss: 1.92799
Epoch 10, Val Loss: 1.93578
Epoch 11, Val Loss: 1.93733
Epoch 12, Val Loss: 1.92697
Epoch 13, Val Loss: 1.95463
Epoch 14, Val Loss: 1.93469
Epoch 15, Val Loss: 1.90916
Epoch 16, Val Loss: 1.91182
Epoch 17, Val Loss: 1.93776
Epoch 18, Val Loss: 1.91416
Epoch 19, Val Loss: 1.92299
Epoch 20, Val Loss: 1.90582
Epoch 21, Val Loss: 1.93150
Epoch 22, Val Loss: 1.90269
Epoch 23, Val Loss: 1.90598
Epoch 24, Val Loss: 1.91661
Epoch 25, Val Loss: 1.91808
Epoch 26, Val Loss: 1.91994
Epoch 27, Val Loss: 1.92960
Epoch 28, Val Loss: 1.90462
Epoch 29, Val Loss: 1.91075
Epoch 30, Val Loss: 1.91053
Epoch 31, Val Loss: 1.90272
Epoch 32, Val Loss: 1.90121
Epoch 33, Val Loss: 1.90395
Epoch 34, Val Loss: 1.90208
Epoch 35, Val Loss: 1.90938
Epoch 36, Val Loss: 1.90783
Epoch 37, Val Loss: 1.92993
Epoch 38, Val Loss: 1.91652
Epoch 39, Val Loss: 1.91132
Epoch 40, Val Loss: 1.89844
Epoch 41, Val Loss: 1.90805
Epoch 42, Val Loss: 1.88585
Epoch 43, Val Loss: 1.93648
Epoch 44, Val Loss: 1.90125
Epoch 45, Val Loss: 1.92659
Epoch 46, Val Loss: 1.91005
Epoch 47, Val Loss: 1.91133
Epoch 48, Val Loss: 1.91316
Epoch 49, Val Loss: 1.90137
Epoch 50, Val Loss: 1.91919
Epoch 51, Val Loss: 1.90212
Epoch 52, Val Loss: 1.89840
Epoch 53, Val Loss: 1.89450
Epoch 54, Val Loss: 1.89981
Epoch 55, Val Loss: 1.90572
Epoch 56, Val Loss: 1.90275
Epoch 57, Val Loss: 1.90476
Epoch 58, Val Loss: 1.92499
Epoch 59, Val Loss: 1.91197
Epoch 60, Val Loss: 1.91183
Epoch 61, Val Loss: 1.91608
Epoch 62, Val Loss: 1.90135
Epoch 63, Val Loss: 1.90907
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.57485, 'Log Loss - std': 0.30545} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}
Fitted encoder
Epoch 0, Val Loss: 2.12536
Epoch 1, Val Loss: 2.12270
Epoch 2, Val Loss: 2.13915
Epoch 3, Val Loss: 2.13566
Epoch 4, Val Loss: 2.12761
Epoch 5, Val Loss: 2.12330
Epoch 6, Val Loss: 2.11546
Epoch 7, Val Loss: 2.12374
Epoch 8, Val Loss: 2.11911
Epoch 9, Val Loss: 2.11691
Epoch 10, Val Loss: 2.12176
Epoch 11, Val Loss: 2.09919
Epoch 12, Val Loss: 2.08345
Epoch 13, Val Loss: 2.10890
Epoch 14, Val Loss: 2.08474
Epoch 15, Val Loss: 2.08960
Epoch 16, Val Loss: 2.08366
Epoch 17, Val Loss: 2.08636
Epoch 18, Val Loss: 2.12235
Epoch 19, Val Loss: 2.08879
Epoch 20, Val Loss: 2.08286
Epoch 21, Val Loss: 2.08800
Epoch 22, Val Loss: 2.08531
Epoch 23, Val Loss: 2.08331
Epoch 24, Val Loss: 2.08725
Epoch 25, Val Loss: 2.07808
Epoch 26, Val Loss: 2.09428
Epoch 27, Val Loss: 2.08017
Epoch 28, Val Loss: 2.08649
Epoch 29, Val Loss: 2.07541
Epoch 30, Val Loss: 2.11376
Epoch 31, Val Loss: 2.08184
Epoch 32, Val Loss: 2.09378
Epoch 33, Val Loss: 2.08219
Epoch 34, Val Loss: 2.07757
Epoch 35, Val Loss: 2.08740
Epoch 36, Val Loss: 2.08260
Epoch 37, Val Loss: 2.08260
Epoch 38, Val Loss: 2.08169
Epoch 39, Val Loss: 2.08151
Epoch 40, Val Loss: 2.07988
Epoch 41, Val Loss: 2.07742
Epoch 42, Val Loss: 2.07593
Epoch 43, Val Loss: 2.07876
Epoch 44, Val Loss: 2.08074
Epoch 45, Val Loss: 2.07632
Epoch 46, Val Loss: 2.08305
Epoch 47, Val Loss: 2.07710
Epoch 48, Val Loss: 2.08780
Epoch 49, Val Loss: 2.06821
Epoch 50, Val Loss: 2.08262
Epoch 51, Val Loss: 2.08186
Epoch 52, Val Loss: 2.08232
Epoch 53, Val Loss: 2.08580
Epoch 54, Val Loss: 2.07365
Epoch 55, Val Loss: 2.07428
Epoch 56, Val Loss: 2.07904
Epoch 57, Val Loss: 2.07848
Epoch 58, Val Loss: 2.07505
Epoch 59, Val Loss: 2.08643
Epoch 60, Val Loss: 2.07217
Epoch 61, Val Loss: 2.06838
Epoch 62, Val Loss: 2.07571
Epoch 63, Val Loss: 2.08508
Epoch 64, Val Loss: 2.07964
Epoch 65, Val Loss: 2.07158
Epoch 66, Val Loss: 2.06687
Epoch 67, Val Loss: 2.06126
Epoch 68, Val Loss: 2.08410
Epoch 69, Val Loss: 2.07290
Epoch 70, Val Loss: 2.08858
Epoch 71, Val Loss: 2.08968
Epoch 72, Val Loss: 2.05718
Epoch 73, Val Loss: 2.07856
Epoch 74, Val Loss: 2.08399
Epoch 75, Val Loss: 2.06225
Epoch 76, Val Loss: 2.10181
Epoch 77, Val Loss: 2.07745
Epoch 78, Val Loss: 2.07528
Epoch 79, Val Loss: 2.08960
Epoch 80, Val Loss: 2.09044
Epoch 81, Val Loss: 2.07063
Epoch 82, Val Loss: 2.05837
Epoch 83, Val Loss: 2.05710
Epoch 84, Val Loss: 2.07394
Epoch 85, Val Loss: 2.05426
Epoch 86, Val Loss: 2.07578
Epoch 87, Val Loss: 2.05652
Epoch 88, Val Loss: 2.06518
Epoch 89, Val Loss: 2.05875
Epoch 90, Val Loss: 2.06064
Epoch 91, Val Loss: 2.05989
Epoch 92, Val Loss: 2.07153
Epoch 93, Val Loss: 2.06369
Epoch 94, Val Loss: 2.06466
Epoch 95, Val Loss: 2.06664
Epoch 96, Val Loss: 2.06377
Epoch 97, Val Loss: 2.05714
Epoch 98, Val Loss: 2.04502
Epoch 99, Val Loss: 2.05162
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.3336333333333332, 'Log Loss - std': 0.42257633892850915} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}
Fitted encoder
Epoch 0, Val Loss: 2.07702
Epoch 1, Val Loss: 2.07776
Epoch 2, Val Loss: 2.08841
Epoch 3, Val Loss: 2.07110
Epoch 4, Val Loss: 2.07189
Epoch 5, Val Loss: 2.06013
Epoch 6, Val Loss: 2.07540
Epoch 7, Val Loss: 2.05004
Epoch 8, Val Loss: 2.05502
Epoch 9, Val Loss: 2.06604
Epoch 10, Val Loss: 2.04277
Epoch 11, Val Loss: 2.06016
Epoch 12, Val Loss: 2.06667
Epoch 13, Val Loss: 2.05396
Epoch 14, Val Loss: 2.04177
Epoch 15, Val Loss: 2.05140
Epoch 16, Val Loss: 2.04497
Epoch 17, Val Loss: 2.05844
Epoch 18, Val Loss: 2.03031
Epoch 19, Val Loss: 2.04693
Epoch 20, Val Loss: 2.04658
Epoch 21, Val Loss: 2.04486
Epoch 22, Val Loss: 2.03761
Epoch 23, Val Loss: 2.05875
Epoch 24, Val Loss: 2.03520
Epoch 25, Val Loss: 2.05526
Epoch 26, Val Loss: 2.04647
Epoch 27, Val Loss: 2.03728
Epoch 28, Val Loss: 2.04455
Epoch 29, Val Loss: 2.04378
Epoch 30, Val Loss: 2.03491
Epoch 31, Val Loss: 2.01577
Epoch 32, Val Loss: 2.03028
Epoch 33, Val Loss: 2.03597
Epoch 34, Val Loss: 2.01821
Epoch 35, Val Loss: 2.04382
Epoch 36, Val Loss: 2.02265
Epoch 37, Val Loss: 2.03477
Epoch 38, Val Loss: 2.04647
Epoch 39, Val Loss: 2.03386
Epoch 40, Val Loss: 2.02874
Epoch 41, Val Loss: 2.03082
Epoch 42, Val Loss: 2.01990
Epoch 43, Val Loss: 2.02255
Epoch 44, Val Loss: 2.02824
Epoch 45, Val Loss: 2.02944
Epoch 46, Val Loss: 2.01924
Epoch 47, Val Loss: 2.03844
Epoch 48, Val Loss: 2.02152
Epoch 49, Val Loss: 2.02873
Epoch 50, Val Loss: 2.03794
Epoch 51, Val Loss: 2.03606
Epoch 52, Val Loss: 2.02023
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.274175, 'Log Loss - std': 0.3801762116111423} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}
Fitted encoder
Epoch 0, Val Loss: 1.96607
Epoch 1, Val Loss: 1.97337
Epoch 2, Val Loss: 1.95343
Epoch 3, Val Loss: 1.95875
Epoch 4, Val Loss: 1.95280
Epoch 5, Val Loss: 1.98272
Epoch 6, Val Loss: 1.95820
Epoch 7, Val Loss: 1.96796
Epoch 8, Val Loss: 1.95661
Epoch 9, Val Loss: 1.94807
Epoch 10, Val Loss: 1.95167
Epoch 11, Val Loss: 1.94553
Epoch 12, Val Loss: 1.95672
Epoch 13, Val Loss: 1.94371
Epoch 14, Val Loss: 1.94815
Epoch 15, Val Loss: 1.95512
Epoch 16, Val Loss: 1.96977
Epoch 17, Val Loss: 1.93507
Epoch 18, Val Loss: 1.92606
Epoch 19, Val Loss: 1.93907
Epoch 20, Val Loss: 1.94528
Epoch 21, Val Loss: 1.96332
Epoch 22, Val Loss: 1.93277
Epoch 23, Val Loss: 1.94949
Epoch 24, Val Loss: 1.92039
Epoch 25, Val Loss: 1.93205
Epoch 26, Val Loss: 1.92121
Epoch 27, Val Loss: 1.93594
Epoch 28, Val Loss: 1.94564
Epoch 29, Val Loss: 1.93975
Epoch 30, Val Loss: 1.93029
Epoch 31, Val Loss: 1.94321
Epoch 32, Val Loss: 1.92076
Epoch 33, Val Loss: 1.94203
Epoch 34, Val Loss: 1.92442
Epoch 35, Val Loss: 1.93395
Epoch 36, Val Loss: 1.91498
Epoch 37, Val Loss: 1.94497
Epoch 38, Val Loss: 1.92540
Epoch 39, Val Loss: 1.91995
Epoch 40, Val Loss: 1.90472
Epoch 41, Val Loss: 1.91947
Epoch 42, Val Loss: 1.93852
Epoch 43, Val Loss: 1.94381
Epoch 44, Val Loss: 1.93012
Epoch 45, Val Loss: 1.95651
Epoch 46, Val Loss: 1.94152
Epoch 47, Val Loss: 1.91677
Epoch 48, Val Loss: 1.94764
Epoch 49, Val Loss: 1.94282
Epoch 50, Val Loss: 1.93479
Epoch 51, Val Loss: 1.91580
Epoch 52, Val Loss: 1.90024
Epoch 53, Val Loss: 1.91016
Epoch 54, Val Loss: 1.90088
Epoch 55, Val Loss: 1.91075
Epoch 56, Val Loss: 1.90846
Epoch 57, Val Loss: 1.89312
Epoch 58, Val Loss: 1.93068
Epoch 59, Val Loss: 1.91369
Epoch 60, Val Loss: 1.90134
Epoch 61, Val Loss: 1.90449
Epoch 62, Val Loss: 1.91280
Epoch 63, Val Loss: 1.90663
Epoch 64, Val Loss: 1.91618
Epoch 65, Val Loss: 1.90772
Epoch 66, Val Loss: 1.92666
Epoch 67, Val Loss: 1.91200
Epoch 68, Val Loss: 1.90250
Epoch 69, Val Loss: 1.91348
Epoch 70, Val Loss: 1.89479
Epoch 71, Val Loss: 1.91279
Epoch 72, Val Loss: 1.90639
Epoch 73, Val Loss: 1.91803
Epoch 74, Val Loss: 1.90716
Epoch 75, Val Loss: 1.90615
Epoch 76, Val Loss: 1.92224
Epoch 77, Val Loss: 1.90318
Epoch 78, Val Loss: 1.90268
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.42474, 'Log Loss - std': 0.4542096854977886} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 5 finished with value: 2.42474 and parameters: {'p_m': 0.46276549882050577, 'alpha': 1.7798130663604126, 'K': 20, 'beta': 7.8045711915495675}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}
Fitted encoder
Epoch 0, Val Loss: 2.13780
Epoch 1, Val Loss: 2.13525
Epoch 2, Val Loss: 2.12037
Epoch 3, Val Loss: 2.10508
Epoch 4, Val Loss: 2.10299
Epoch 5, Val Loss: 2.09954
Epoch 6, Val Loss: 2.09475
Epoch 7, Val Loss: 2.10746
Epoch 8, Val Loss: 2.09569
Epoch 9, Val Loss: 2.08945
Epoch 10, Val Loss: 2.08549
Epoch 11, Val Loss: 2.09359
Epoch 12, Val Loss: 2.10734
Epoch 13, Val Loss: 2.09080
Epoch 14, Val Loss: 2.08468
Epoch 15, Val Loss: 2.09453
Epoch 16, Val Loss: 2.08908
Epoch 17, Val Loss: 2.09520
Epoch 18, Val Loss: 2.09092
Epoch 19, Val Loss: 2.07992
Epoch 20, Val Loss: 2.08227
Epoch 21, Val Loss: 2.08812
Epoch 22, Val Loss: 2.07919
Epoch 23, Val Loss: 2.09011
Epoch 24, Val Loss: 2.09277
Epoch 25, Val Loss: 2.08875
Epoch 26, Val Loss: 2.07149
Epoch 27, Val Loss: 2.07033
Epoch 28, Val Loss: 2.07239
Epoch 29, Val Loss: 2.06479
Epoch 30, Val Loss: 2.06525
Epoch 31, Val Loss: 2.06579
Epoch 32, Val Loss: 2.07539
Epoch 33, Val Loss: 2.06266
Epoch 34, Val Loss: 2.06459
Epoch 35, Val Loss: 2.10951
Epoch 36, Val Loss: 2.06657
Epoch 37, Val Loss: 2.05282
Epoch 38, Val Loss: 2.06319
Epoch 39, Val Loss: 2.04274
Epoch 40, Val Loss: 2.08017
Epoch 41, Val Loss: 2.04431
Epoch 42, Val Loss: 2.07545
Epoch 43, Val Loss: 2.07771
Epoch 44, Val Loss: 2.06069
Epoch 45, Val Loss: 2.06677
Epoch 46, Val Loss: 2.06812
Epoch 47, Val Loss: 2.06066
Epoch 48, Val Loss: 2.04201
Epoch 49, Val Loss: 2.06803
Epoch 50, Val Loss: 2.05714
Epoch 51, Val Loss: 2.07015
Epoch 52, Val Loss: 2.06932
Epoch 53, Val Loss: 2.05876
Epoch 54, Val Loss: 2.06218
Epoch 55, Val Loss: 2.03446
Epoch 56, Val Loss: 2.06189
Epoch 57, Val Loss: 2.05912
Epoch 58, Val Loss: 2.05714
Epoch 59, Val Loss: 2.05206
Epoch 60, Val Loss: 2.05506
Epoch 61, Val Loss: 2.04142
Epoch 62, Val Loss: 2.04430
Epoch 63, Val Loss: 2.04734
Epoch 64, Val Loss: 2.04823
Epoch 65, Val Loss: 2.04563
Epoch 66, Val Loss: 2.04781
Epoch 67, Val Loss: 2.06797
Epoch 68, Val Loss: 2.06949
Epoch 69, Val Loss: 2.04865
Epoch 70, Val Loss: 2.04040
Epoch 71, Val Loss: 2.04355
Epoch 72, Val Loss: 2.05295
Epoch 73, Val Loss: 2.04665
Epoch 74, Val Loss: 2.06245
Epoch 75, Val Loss: 2.04392
Epoch 76, Val Loss: 2.05599
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.3195, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}
Fitted encoder
Epoch 0, Val Loss: 1.97093
Epoch 1, Val Loss: 2.00934
Epoch 2, Val Loss: 1.95919
Epoch 3, Val Loss: 1.96969
Epoch 4, Val Loss: 1.95883
Epoch 5, Val Loss: 1.94679
Epoch 6, Val Loss: 1.94905
Epoch 7, Val Loss: 1.94533
Epoch 8, Val Loss: 1.95430
Epoch 9, Val Loss: 1.94666
Epoch 10, Val Loss: 1.93815
Epoch 11, Val Loss: 1.94083
Epoch 12, Val Loss: 1.94642
Epoch 13, Val Loss: 1.94997
Epoch 14, Val Loss: 1.93456
Epoch 15, Val Loss: 1.92984
Epoch 16, Val Loss: 1.94116
Epoch 17, Val Loss: 1.94059
Epoch 18, Val Loss: 1.93659
Epoch 19, Val Loss: 1.94097
Epoch 20, Val Loss: 1.92938
Epoch 21, Val Loss: 1.92532
Epoch 22, Val Loss: 1.95106
Epoch 23, Val Loss: 1.94118
Epoch 24, Val Loss: 1.91977
Epoch 25, Val Loss: 1.93654
Epoch 26, Val Loss: 1.93007
Epoch 27, Val Loss: 1.94541
Epoch 28, Val Loss: 1.94526
Epoch 29, Val Loss: 1.93492
Epoch 30, Val Loss: 1.95203
Epoch 31, Val Loss: 1.98085
Epoch 32, Val Loss: 1.95333
Epoch 33, Val Loss: 1.92875
Epoch 34, Val Loss: 1.92622
Epoch 35, Val Loss: 1.93332
Epoch 36, Val Loss: 1.96135
Epoch 37, Val Loss: 1.91741
Epoch 38, Val Loss: 1.92652
Epoch 39, Val Loss: 1.93140
Epoch 40, Val Loss: 1.91819
Epoch 41, Val Loss: 1.92872
Epoch 42, Val Loss: 1.91488
Epoch 43, Val Loss: 1.93547
Epoch 44, Val Loss: 1.92537
Epoch 45, Val Loss: 1.91606
Epoch 46, Val Loss: 1.93277
Epoch 47, Val Loss: 1.92615
Epoch 48, Val Loss: 1.92716
Epoch 49, Val Loss: 1.92416
Epoch 50, Val Loss: 1.91711
Epoch 51, Val Loss: 1.92152
Epoch 52, Val Loss: 1.91995
Epoch 53, Val Loss: 1.89832
Epoch 54, Val Loss: 1.91812
Epoch 55, Val Loss: 1.92796
Epoch 56, Val Loss: 1.90821
Epoch 57, Val Loss: 1.91806
Epoch 58, Val Loss: 1.94085
Epoch 59, Val Loss: 1.90123
Epoch 60, Val Loss: 1.89605
Epoch 61, Val Loss: 1.90857
Epoch 62, Val Loss: 1.90865
Epoch 63, Val Loss: 1.91127
Epoch 64, Val Loss: 1.91350
Epoch 65, Val Loss: 1.90586
Epoch 66, Val Loss: 1.91764
Epoch 67, Val Loss: 1.91324
Epoch 68, Val Loss: 1.91025
Epoch 69, Val Loss: 1.91676
Epoch 70, Val Loss: 1.92999
Epoch 71, Val Loss: 1.91676
Epoch 72, Val Loss: 1.90974
Epoch 73, Val Loss: 1.91075
Epoch 74, Val Loss: 1.91058
Epoch 75, Val Loss: 1.90688
Epoch 76, Val Loss: 1.92315
Epoch 77, Val Loss: 1.90224
Epoch 78, Val Loss: 1.91996
Epoch 79, Val Loss: 1.91860
Epoch 80, Val Loss: 1.91286
Epoch 81, Val Loss: 1.90031
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.6126500000000004, 'Log Loss - std': 0.29315} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}
Fitted encoder
Epoch 0, Val Loss: 2.12111
Epoch 1, Val Loss: 2.12609
Epoch 2, Val Loss: 2.12161
Epoch 3, Val Loss: 2.12334
Epoch 4, Val Loss: 2.11411
Epoch 5, Val Loss: 2.11772
Epoch 6, Val Loss: 2.11924
Epoch 7, Val Loss: 2.11335
Epoch 8, Val Loss: 2.11359
Epoch 9, Val Loss: 2.12053
Epoch 10, Val Loss: 2.11698
Epoch 11, Val Loss: 2.11468
Epoch 12, Val Loss: 2.11631
Epoch 13, Val Loss: 2.11218
Epoch 14, Val Loss: 2.11357
Epoch 15, Val Loss: 2.11866
Epoch 16, Val Loss: 2.12457
Epoch 17, Val Loss: 2.11625
Epoch 18, Val Loss: 2.11152
Epoch 19, Val Loss: 2.11557
Epoch 20, Val Loss: 2.11552
Epoch 21, Val Loss: 2.11087
Epoch 22, Val Loss: 2.12483
Epoch 23, Val Loss: 2.12543
Epoch 24, Val Loss: 2.11326
Epoch 25, Val Loss: 2.11622
Epoch 26, Val Loss: 2.11901
Epoch 27, Val Loss: 2.11669
Epoch 28, Val Loss: 2.11178
Epoch 29, Val Loss: 2.11346
Epoch 30, Val Loss: 2.11012
Epoch 31, Val Loss: 2.10913
Epoch 32, Val Loss: 2.10747
Epoch 33, Val Loss: 2.10733
Epoch 34, Val Loss: 2.10680
Epoch 35, Val Loss: 2.10190
Epoch 36, Val Loss: 2.10366
Epoch 37, Val Loss: 2.10913
Epoch 38, Val Loss: 2.11349
Epoch 39, Val Loss: 2.10596
Epoch 40, Val Loss: 2.10065
Epoch 41, Val Loss: 2.10280
Epoch 42, Val Loss: 2.09480
Epoch 43, Val Loss: 2.09716
Epoch 44, Val Loss: 2.08774
Epoch 45, Val Loss: 2.09884
Epoch 46, Val Loss: 2.09663
Epoch 47, Val Loss: 2.10104
Epoch 48, Val Loss: 2.10728
Epoch 49, Val Loss: 2.10199
Epoch 50, Val Loss: 2.08938
Epoch 51, Val Loss: 2.08810
Epoch 52, Val Loss: 2.08285
Epoch 53, Val Loss: 2.08725
Epoch 54, Val Loss: 2.07775
Epoch 55, Val Loss: 2.07955
Epoch 56, Val Loss: 2.08231
Epoch 57, Val Loss: 2.07955
Epoch 58, Val Loss: 2.08357
Epoch 59, Val Loss: 2.07756
Epoch 60, Val Loss: 2.06618
Epoch 61, Val Loss: 2.07827
Epoch 62, Val Loss: 2.07443
Epoch 63, Val Loss: 2.08947
Epoch 64, Val Loss: 2.08486
Epoch 65, Val Loss: 2.07287
Epoch 66, Val Loss: 2.08764
Epoch 67, Val Loss: 2.09794
Epoch 68, Val Loss: 2.07727
Epoch 69, Val Loss: 2.06595
Epoch 70, Val Loss: 2.06245
Epoch 71, Val Loss: 2.10790
Epoch 72, Val Loss: 2.08472
Epoch 73, Val Loss: 2.07008
Epoch 74, Val Loss: 2.08209
Epoch 75, Val Loss: 2.08685
Epoch 76, Val Loss: 2.06552
Epoch 77, Val Loss: 2.06792
Epoch 78, Val Loss: 2.06063
Epoch 79, Val Loss: 2.08012
Epoch 80, Val Loss: 2.07406
Epoch 81, Val Loss: 2.05979
Epoch 82, Val Loss: 2.06404
Epoch 83, Val Loss: 2.06953
Epoch 84, Val Loss: 2.06519
Epoch 85, Val Loss: 2.05988
Epoch 86, Val Loss: 2.07319
Epoch 87, Val Loss: 2.06650
Epoch 88, Val Loss: 2.06191
Epoch 89, Val Loss: 2.05782
Epoch 90, Val Loss: 2.06458
Epoch 91, Val Loss: 2.06549
Epoch 92, Val Loss: 2.05694
Epoch 93, Val Loss: 2.06674
Epoch 94, Val Loss: 2.05122
Epoch 95, Val Loss: 2.06012
Epoch 96, Val Loss: 2.07480
Epoch 97, Val Loss: 2.04918
Epoch 98, Val Loss: 2.07607
Epoch 99, Val Loss: 2.04876
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6143666666666667, 'Log Loss - std': 0.2393682843560432} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}
Fitted encoder
Epoch 0, Val Loss: 2.09943
Epoch 1, Val Loss: 2.06918
Epoch 2, Val Loss: 2.07294
Epoch 3, Val Loss: 2.06879
Epoch 4, Val Loss: 2.07024
Epoch 5, Val Loss: 2.07041
Epoch 6, Val Loss: 2.06463
Epoch 7, Val Loss: 2.07865
Epoch 8, Val Loss: 2.06733
Epoch 9, Val Loss: 2.05136
Epoch 10, Val Loss: 2.05845
Epoch 11, Val Loss: 2.05813
Epoch 12, Val Loss: 2.07997
Epoch 13, Val Loss: 2.06355
Epoch 14, Val Loss: 2.05644
Epoch 15, Val Loss: 2.04710
Epoch 16, Val Loss: 2.04865
Epoch 17, Val Loss: 2.03670
Epoch 18, Val Loss: 2.06733
Epoch 19, Val Loss: 2.03494
Epoch 20, Val Loss: 2.04687
Epoch 21, Val Loss: 2.04566
Epoch 22, Val Loss: 2.04690
Epoch 23, Val Loss: 2.05232
Epoch 24, Val Loss: 2.04045
Epoch 25, Val Loss: 2.05793
Epoch 26, Val Loss: 2.03713
Epoch 27, Val Loss: 2.04100
Epoch 28, Val Loss: 2.03680
Epoch 29, Val Loss: 2.05305
Epoch 30, Val Loss: 2.04302
Epoch 31, Val Loss: 2.03572
Epoch 32, Val Loss: 2.04806
Epoch 33, Val Loss: 2.04229
Epoch 34, Val Loss: 2.02427
Epoch 35, Val Loss: 2.05475
Epoch 36, Val Loss: 2.02011
Epoch 37, Val Loss: 2.04426
Epoch 38, Val Loss: 2.03152
Epoch 39, Val Loss: 2.03040
Epoch 40, Val Loss: 2.03401
Epoch 41, Val Loss: 2.01945
Epoch 42, Val Loss: 2.02046
Epoch 43, Val Loss: 2.05908
Epoch 44, Val Loss: 2.03102
Epoch 45, Val Loss: 2.03981
Epoch 46, Val Loss: 2.03029
Epoch 47, Val Loss: 2.02750
Epoch 48, Val Loss: 2.03048
Epoch 49, Val Loss: 2.02243
Epoch 50, Val Loss: 2.03892
Epoch 51, Val Loss: 2.04828
Epoch 52, Val Loss: 2.03100
Epoch 53, Val Loss: 2.03988
Epoch 54, Val Loss: 2.02996
Epoch 55, Val Loss: 2.04771
Epoch 56, Val Loss: 2.02362
Epoch 57, Val Loss: 2.02065
Epoch 58, Val Loss: 2.01777
Epoch 59, Val Loss: 2.02954
Epoch 60, Val Loss: 2.03288
Epoch 61, Val Loss: 2.04214
Epoch 62, Val Loss: 2.02172
Epoch 63, Val Loss: 2.04548
Epoch 64, Val Loss: 2.03589
Epoch 65, Val Loss: 2.01992
Epoch 66, Val Loss: 2.01621
Epoch 67, Val Loss: 2.02941
Epoch 68, Val Loss: 2.03858
Epoch 69, Val Loss: 2.01944
Epoch 70, Val Loss: 2.04748
Epoch 71, Val Loss: 2.03069
Epoch 72, Val Loss: 2.04853
Epoch 73, Val Loss: 2.02459
Epoch 74, Val Loss: 2.02140
Epoch 75, Val Loss: 2.01327
Epoch 76, Val Loss: 2.03071
Epoch 77, Val Loss: 2.01240
Epoch 78, Val Loss: 2.03075
Epoch 79, Val Loss: 2.01835
Epoch 80, Val Loss: 2.02457
Epoch 81, Val Loss: 2.01320
Epoch 82, Val Loss: 2.03522
Epoch 83, Val Loss: 2.02330
Epoch 84, Val Loss: 2.02931
Epoch 85, Val Loss: 2.03658
Epoch 86, Val Loss: 2.03026
Epoch 87, Val Loss: 2.02350
Epoch 88, Val Loss: 2.01714
Epoch 89, Val Loss: 2.02399
Epoch 90, Val Loss: 2.03278
Epoch 91, Val Loss: 2.02072
Epoch 92, Val Loss: 2.04198
Epoch 93, Val Loss: 2.01161
Epoch 94, Val Loss: 2.01591
Epoch 95, Val Loss: 2.03631
Epoch 96, Val Loss: 2.03607
Epoch 97, Val Loss: 2.02945
Epoch 98, Val Loss: 2.02666
Epoch 99, Val Loss: 2.00900
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.514275, 'Log Loss - std': 0.27023676077654574} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}
Fitted encoder
Epoch 0, Val Loss: 2.00586
Epoch 1, Val Loss: 1.96171
Epoch 2, Val Loss: 1.98347
Epoch 3, Val Loss: 1.95130
Epoch 4, Val Loss: 1.95443
Epoch 5, Val Loss: 1.95749
Epoch 6, Val Loss: 1.95681
Epoch 7, Val Loss: 1.95395
Epoch 8, Val Loss: 1.95661
Epoch 9, Val Loss: 1.97772
Epoch 10, Val Loss: 1.96162
Epoch 11, Val Loss: 1.94723
Epoch 12, Val Loss: 1.95729
Epoch 13, Val Loss: 1.95186
Epoch 14, Val Loss: 1.95354
Epoch 15, Val Loss: 1.95266
Epoch 16, Val Loss: 1.94034
Epoch 17, Val Loss: 1.94735
Epoch 18, Val Loss: 1.94426
Epoch 19, Val Loss: 1.94967
Epoch 20, Val Loss: 1.94090
Epoch 21, Val Loss: 1.98002
Epoch 22, Val Loss: 1.92459
Epoch 23, Val Loss: 1.91135
Epoch 24, Val Loss: 1.92931
Epoch 25, Val Loss: 1.94569
Epoch 26, Val Loss: 1.91241
Epoch 27, Val Loss: 1.89778
Epoch 28, Val Loss: 1.92946
Epoch 29, Val Loss: 1.92788
Epoch 30, Val Loss: 1.91939
Epoch 31, Val Loss: 1.90914
Epoch 32, Val Loss: 1.90747
Epoch 33, Val Loss: 1.90691
Epoch 34, Val Loss: 1.89174
Epoch 35, Val Loss: 1.88847
Epoch 36, Val Loss: 1.93272
Epoch 37, Val Loss: 1.94300
Epoch 38, Val Loss: 1.92316
Epoch 39, Val Loss: 1.93006
Epoch 40, Val Loss: 1.90502
Epoch 41, Val Loss: 1.91200
Epoch 42, Val Loss: 1.91278
Epoch 43, Val Loss: 1.90229
Epoch 44, Val Loss: 1.91383
Epoch 45, Val Loss: 1.92088
Epoch 46, Val Loss: 1.94457
Epoch 47, Val Loss: 1.89177
Epoch 48, Val Loss: 1.90684
Epoch 49, Val Loss: 1.89505
Epoch 50, Val Loss: 1.90944
Epoch 51, Val Loss: 1.88650
Epoch 52, Val Loss: 1.89362
Epoch 53, Val Loss: 1.92844
Epoch 54, Val Loss: 1.88436
Epoch 55, Val Loss: 1.89672
Epoch 56, Val Loss: 1.89946
Epoch 57, Val Loss: 1.89332
Epoch 58, Val Loss: 1.88764
Epoch 59, Val Loss: 1.88691
Epoch 60, Val Loss: 1.91389
Epoch 61, Val Loss: 1.92301
Epoch 62, Val Loss: 1.89980
Epoch 63, Val Loss: 1.88307
Epoch 64, Val Loss: 1.89877
Epoch 65, Val Loss: 1.90937
Epoch 66, Val Loss: 1.90864
Epoch 67, Val Loss: 1.89034
Epoch 68, Val Loss: 1.89597
Epoch 69, Val Loss: 1.91654
Epoch 70, Val Loss: 1.88892
Epoch 71, Val Loss: 1.89176
Epoch 72, Val Loss: 1.89762
Epoch 73, Val Loss: 1.89517
Epoch 74, Val Loss: 1.89985
Epoch 75, Val Loss: 1.89454
Epoch 76, Val Loss: 1.90999
Epoch 77, Val Loss: 1.88123
Epoch 78, Val Loss: 1.89582
Epoch 79, Val Loss: 1.90117
Epoch 80, Val Loss: 1.91375
Epoch 81, Val Loss: 1.89525
Epoch 82, Val Loss: 1.89018
Epoch 83, Val Loss: 1.89370
Epoch 84, Val Loss: 1.93541
Epoch 85, Val Loss: 1.92004
Epoch 86, Val Loss: 1.88565
Epoch 87, Val Loss: 1.89348
Epoch 88, Val Loss: 1.89517
Epoch 89, Val Loss: 1.90162
Epoch 90, Val Loss: 1.88771
Epoch 91, Val Loss: 1.88778
Epoch 92, Val Loss: 1.92968
Epoch 93, Val Loss: 1.88828
Epoch 94, Val Loss: 1.89122
Epoch 95, Val Loss: 1.89214
Epoch 96, Val Loss: 1.89310
Epoch 97, Val Loss: 1.88726
Epoch 98, Val Loss: 1.88588
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.5720199999999998, 'Log Loss - std': 0.2678810661469004} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 6 finished with value: 2.5720199999999998 and parameters: {'p_m': 0.4245791297416619, 'alpha': 2.9608136611796017, 'K': 5, 'beta': 6.170823060451894}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}
Fitted encoder
Epoch 0, Val Loss: 2.13580
Epoch 1, Val Loss: 2.11880
Epoch 2, Val Loss: 2.09304
Epoch 3, Val Loss: 2.12262
Epoch 4, Val Loss: 2.08773
Epoch 5, Val Loss: 2.10265
Epoch 6, Val Loss: 2.10212
Epoch 7, Val Loss: 2.08665
Epoch 8, Val Loss: 2.08921
Epoch 9, Val Loss: 2.09594
Epoch 10, Val Loss: 2.08997
Epoch 11, Val Loss: 2.10026
Epoch 12, Val Loss: 2.10530
Epoch 13, Val Loss: 2.08629
Epoch 14, Val Loss: 2.10366
Epoch 15, Val Loss: 2.10095
Epoch 16, Val Loss: 2.08624
Epoch 17, Val Loss: 2.08232
Epoch 18, Val Loss: 2.09629
Epoch 19, Val Loss: 2.09520
Epoch 20, Val Loss: 2.09795
Epoch 21, Val Loss: 2.08990
Epoch 22, Val Loss: 2.07678
Epoch 23, Val Loss: 2.10126
Epoch 24, Val Loss: 2.07506
Epoch 25, Val Loss: 2.09257
Epoch 26, Val Loss: 2.07503
Epoch 27, Val Loss: 2.11016
Epoch 28, Val Loss: 2.06066
Epoch 29, Val Loss: 2.07674
Epoch 30, Val Loss: 2.04950
Epoch 31, Val Loss: 2.08362
Epoch 32, Val Loss: 2.07649
Epoch 33, Val Loss: 2.07975
Epoch 34, Val Loss: 2.09987
Epoch 35, Val Loss: 2.06737
Epoch 36, Val Loss: 2.04925
Epoch 37, Val Loss: 2.06094
Epoch 38, Val Loss: 2.08218
Epoch 39, Val Loss: 2.05851
Epoch 40, Val Loss: 2.10997
Epoch 41, Val Loss: 2.06890
Epoch 42, Val Loss: 2.10027
Epoch 43, Val Loss: 2.08582
Epoch 44, Val Loss: 2.06679
Epoch 45, Val Loss: 2.04730
Epoch 46, Val Loss: 2.07126
Epoch 47, Val Loss: 2.05319
Epoch 48, Val Loss: 2.08059
Epoch 49, Val Loss: 2.06699
Epoch 50, Val Loss: 2.04734
Epoch 51, Val Loss: 2.05945
Epoch 52, Val Loss: 2.04098
Epoch 53, Val Loss: 2.04432
Epoch 54, Val Loss: 2.05483
Epoch 55, Val Loss: 2.04821
Epoch 56, Val Loss: 2.05119
Epoch 57, Val Loss: 2.04256
Epoch 58, Val Loss: 2.02485
Epoch 59, Val Loss: 2.06097
Epoch 60, Val Loss: 2.05123
Epoch 61, Val Loss: 2.03240
Epoch 62, Val Loss: 2.05296
Epoch 63, Val Loss: 2.03268
Epoch 64, Val Loss: 2.08516
Epoch 65, Val Loss: 2.06385
Epoch 66, Val Loss: 2.04156
Epoch 67, Val Loss: 2.08271
Epoch 68, Val Loss: 2.02540
Epoch 69, Val Loss: 2.05998
Epoch 70, Val Loss: 2.04440
Epoch 71, Val Loss: 2.07322
Epoch 72, Val Loss: 2.06750
Epoch 73, Val Loss: 2.06022
Epoch 74, Val Loss: 2.03179
Epoch 75, Val Loss: 2.03795
Epoch 76, Val Loss: 2.08579
Epoch 77, Val Loss: 2.05856
Epoch 78, Val Loss: 2.02883
Epoch 79, Val Loss: 2.06343
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.639, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}
Fitted encoder
Epoch 0, Val Loss: 1.96168
Epoch 1, Val Loss: 1.95394
Epoch 2, Val Loss: 1.96219
Epoch 3, Val Loss: 1.96137
Epoch 4, Val Loss: 1.94243
Epoch 5, Val Loss: 1.94360
Epoch 6, Val Loss: 1.95401
Epoch 7, Val Loss: 1.93598
Epoch 8, Val Loss: 1.94410
Epoch 9, Val Loss: 1.92676
Epoch 10, Val Loss: 1.92531
Epoch 11, Val Loss: 1.94041
Epoch 12, Val Loss: 1.93248
Epoch 13, Val Loss: 1.91510
Epoch 14, Val Loss: 1.94176
Epoch 15, Val Loss: 1.93266
Epoch 16, Val Loss: 1.94029
Epoch 17, Val Loss: 1.94672
Epoch 18, Val Loss: 1.92597
Epoch 19, Val Loss: 1.94233
Epoch 20, Val Loss: 1.90983
Epoch 21, Val Loss: 1.91519
Epoch 22, Val Loss: 1.94459
Epoch 23, Val Loss: 1.93837
Epoch 24, Val Loss: 1.94239
Epoch 25, Val Loss: 1.94076
Epoch 26, Val Loss: 1.92288
Epoch 27, Val Loss: 1.90735
Epoch 28, Val Loss: 1.94522
Epoch 29, Val Loss: 1.91384
Epoch 30, Val Loss: 1.90437
Epoch 31, Val Loss: 1.91620
Epoch 32, Val Loss: 1.91770
Epoch 33, Val Loss: 1.94471
Epoch 34, Val Loss: 1.91795
Epoch 35, Val Loss: 1.92868
Epoch 36, Val Loss: 1.91391
Epoch 37, Val Loss: 1.95994
Epoch 38, Val Loss: 1.92144
Epoch 39, Val Loss: 1.93173
Epoch 40, Val Loss: 1.91156
Epoch 41, Val Loss: 1.89836
Epoch 42, Val Loss: 1.90877
Epoch 43, Val Loss: 1.90417
Epoch 44, Val Loss: 1.90412
Epoch 45, Val Loss: 1.90409
Epoch 46, Val Loss: 1.93105
Epoch 47, Val Loss: 1.92134
Epoch 48, Val Loss: 1.89781
Epoch 49, Val Loss: 1.91466
Epoch 50, Val Loss: 1.91027
Epoch 51, Val Loss: 1.93573
Epoch 52, Val Loss: 1.90657
Epoch 53, Val Loss: 1.90952
Epoch 54, Val Loss: 1.90438
Epoch 55, Val Loss: 1.91424
Epoch 56, Val Loss: 1.91159
Epoch 57, Val Loss: 1.92342
Epoch 58, Val Loss: 1.89495
Epoch 59, Val Loss: 1.90859
Epoch 60, Val Loss: 1.91782
Epoch 61, Val Loss: 1.90751
Epoch 62, Val Loss: 1.89730
Epoch 63, Val Loss: 1.92722
Epoch 64, Val Loss: 1.89771
Epoch 65, Val Loss: 1.91704
Epoch 66, Val Loss: 1.90668
Epoch 67, Val Loss: 1.90738
Epoch 68, Val Loss: 1.93967
Epoch 69, Val Loss: 1.92319
Epoch 70, Val Loss: 1.91132
Epoch 71, Val Loss: 1.89641
Epoch 72, Val Loss: 1.90349
Epoch 73, Val Loss: 1.89362
Epoch 74, Val Loss: 1.91834
Epoch 75, Val Loss: 1.90407
Epoch 76, Val Loss: 1.90397
Epoch 77, Val Loss: 1.90889
Epoch 78, Val Loss: 1.89480
Epoch 79, Val Loss: 1.90476
Epoch 80, Val Loss: 1.89867
Epoch 81, Val Loss: 1.91446
Epoch 82, Val Loss: 1.90945
Epoch 83, Val Loss: 1.92077
Epoch 84, Val Loss: 1.89166
Epoch 85, Val Loss: 1.93305
Epoch 86, Val Loss: 1.89888
Epoch 87, Val Loss: 1.89144
Epoch 88, Val Loss: 1.89458
Epoch 89, Val Loss: 1.90553
Epoch 90, Val Loss: 1.91881
Epoch 91, Val Loss: 1.90561
Epoch 92, Val Loss: 1.89912
Epoch 93, Val Loss: 1.90646
Epoch 94, Val Loss: 1.90490
Epoch 95, Val Loss: 1.91168
Epoch 96, Val Loss: 1.90606
Epoch 97, Val Loss: 1.89635
Epoch 98, Val Loss: 1.89948
Epoch 99, Val Loss: 1.89224
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.05785, 'Log Loss - std': 0.41885000000000017} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}
Fitted encoder
Epoch 0, Val Loss: 2.14870
Epoch 1, Val Loss: 2.11004
Epoch 2, Val Loss: 2.12268
Epoch 3, Val Loss: 2.13343
Epoch 4, Val Loss: 2.11125
Epoch 5, Val Loss: 2.12623
Epoch 6, Val Loss: 2.11595
Epoch 7, Val Loss: 2.11004
Epoch 8, Val Loss: 2.11591
Epoch 9, Val Loss: 2.11557
Epoch 10, Val Loss: 2.10893
Epoch 11, Val Loss: 2.11109
Epoch 12, Val Loss: 2.11437
Epoch 13, Val Loss: 2.11428
Epoch 14, Val Loss: 2.10533
Epoch 15, Val Loss: 2.10862
Epoch 16, Val Loss: 2.10528
Epoch 17, Val Loss: 2.11187
Epoch 18, Val Loss: 2.11121
Epoch 19, Val Loss: 2.10189
Epoch 20, Val Loss: 2.10902
Epoch 21, Val Loss: 2.10063
Epoch 22, Val Loss: 2.11343
Epoch 23, Val Loss: 2.10810
Epoch 24, Val Loss: 2.11043
Epoch 25, Val Loss: 2.11389
Epoch 26, Val Loss: 2.10375
Epoch 27, Val Loss: 2.10569
Epoch 28, Val Loss: 2.10322
Epoch 29, Val Loss: 2.10598
Epoch 30, Val Loss: 2.10263
Epoch 31, Val Loss: 2.10282
Epoch 32, Val Loss: 2.09818
Epoch 33, Val Loss: 2.08206
Epoch 34, Val Loss: 2.09270
Epoch 35, Val Loss: 2.12146
Epoch 36, Val Loss: 2.09729
Epoch 37, Val Loss: 2.09538
Epoch 38, Val Loss: 2.09326
Epoch 39, Val Loss: 2.10584
Epoch 40, Val Loss: 2.07867
Epoch 41, Val Loss: 2.09717
Epoch 42, Val Loss: 2.09263
Epoch 43, Val Loss: 2.11691
Epoch 44, Val Loss: 2.08469
Epoch 45, Val Loss: 2.07257
Epoch 46, Val Loss: 2.07239
Epoch 47, Val Loss: 2.07581
Epoch 48, Val Loss: 2.09363
Epoch 49, Val Loss: 2.12176
Epoch 50, Val Loss: 2.09636
Epoch 51, Val Loss: 2.08233
Epoch 52, Val Loss: 2.06830
Epoch 53, Val Loss: 2.04275
Epoch 54, Val Loss: 2.06304
Epoch 55, Val Loss: 2.04653
Epoch 56, Val Loss: 2.02868
Epoch 57, Val Loss: 2.04242
Epoch 58, Val Loss: 2.04625
Epoch 59, Val Loss: 2.04376
Epoch 60, Val Loss: 2.04600
Epoch 61, Val Loss: 2.09151
Epoch 62, Val Loss: 2.06690
Epoch 63, Val Loss: 2.03277
Epoch 64, Val Loss: 2.03884
Epoch 65, Val Loss: 2.04909
Epoch 66, Val Loss: 2.02950
Epoch 67, Val Loss: 2.02101
Epoch 68, Val Loss: 2.03134
Epoch 69, Val Loss: 2.03260
Epoch 70, Val Loss: 2.03381
Epoch 71, Val Loss: 2.05927
Epoch 72, Val Loss: 2.04018
Epoch 73, Val Loss: 2.02461
Epoch 74, Val Loss: 2.03888
Epoch 75, Val Loss: 2.02542
Epoch 76, Val Loss: 2.03889
Epoch 77, Val Loss: 2.03173
Epoch 78, Val Loss: 2.04430
Epoch 79, Val Loss: 2.04872
Epoch 80, Val Loss: 2.05553
Epoch 81, Val Loss: 2.03666
Epoch 82, Val Loss: 2.02691
Epoch 83, Val Loss: 2.02950
Epoch 84, Val Loss: 2.03038
Epoch 85, Val Loss: 2.04143
Epoch 86, Val Loss: 2.01765
Epoch 87, Val Loss: 2.04498
Epoch 88, Val Loss: 2.05251
Epoch 89, Val Loss: 2.02776
Epoch 90, Val Loss: 2.02804
Epoch 91, Val Loss: 2.02386
Epoch 92, Val Loss: 2.02926
Epoch 93, Val Loss: 2.03702
Epoch 94, Val Loss: 2.02450
Epoch 95, Val Loss: 2.01418
Epoch 96, Val Loss: 2.03256
Epoch 97, Val Loss: 2.01628
Epoch 98, Val Loss: 2.01508
Epoch 99, Val Loss: 2.01677
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.8382, 'Log Loss - std': 0.4620055483072328} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}
Fitted encoder
Epoch 0, Val Loss: 2.08729
Epoch 1, Val Loss: 2.06448
Epoch 2, Val Loss: 2.05878
Epoch 3, Val Loss: 2.05618
Epoch 4, Val Loss: 2.06081
Epoch 5, Val Loss: 2.06531
Epoch 6, Val Loss: 2.07396
Epoch 7, Val Loss: 2.05680
Epoch 8, Val Loss: 2.05828
Epoch 9, Val Loss: 2.04983
Epoch 10, Val Loss: 2.06243
Epoch 11, Val Loss: 2.05562
Epoch 12, Val Loss: 2.06203
Epoch 13, Val Loss: 2.05638
Epoch 14, Val Loss: 2.05844
Epoch 15, Val Loss: 2.05481
Epoch 16, Val Loss: 2.06751
Epoch 17, Val Loss: 2.06966
Epoch 18, Val Loss: 2.06280
Epoch 19, Val Loss: 2.05780
Epoch 20, Val Loss: 2.06730
Epoch 21, Val Loss: 2.05497
Epoch 22, Val Loss: 2.04373
Epoch 23, Val Loss: 2.04154
Epoch 24, Val Loss: 2.03773
Epoch 25, Val Loss: 2.05190
Epoch 26, Val Loss: 2.06027
Epoch 27, Val Loss: 2.03751
Epoch 28, Val Loss: 2.03988
Epoch 29, Val Loss: 2.02962
Epoch 30, Val Loss: 2.05460
Epoch 31, Val Loss: 2.06098
Epoch 32, Val Loss: 2.04191
Epoch 33, Val Loss: 2.04833
Epoch 34, Val Loss: 2.03053
Epoch 35, Val Loss: 2.05236
Epoch 36, Val Loss: 2.03733
Epoch 37, Val Loss: 2.03216
Epoch 38, Val Loss: 2.03822
Epoch 39, Val Loss: 2.04131
Epoch 40, Val Loss: 2.02194
Epoch 41, Val Loss: 2.04566
Epoch 42, Val Loss: 2.10086
Epoch 43, Val Loss: 2.06457
Epoch 44, Val Loss: 2.07226
Epoch 45, Val Loss: 2.02739
Epoch 46, Val Loss: 2.01265
Epoch 47, Val Loss: 2.03774
Epoch 48, Val Loss: 2.04242
Epoch 49, Val Loss: 2.02815
Epoch 50, Val Loss: 2.02089
Epoch 51, Val Loss: 2.05082
Epoch 52, Val Loss: 2.02242
Epoch 53, Val Loss: 2.03088
Epoch 54, Val Loss: 2.03229
Epoch 55, Val Loss: 2.05819
Epoch 56, Val Loss: 2.02666
Epoch 57, Val Loss: 2.04048
Epoch 58, Val Loss: 2.01944
Epoch 59, Val Loss: 2.02119
Epoch 60, Val Loss: 2.01610
Epoch 61, Val Loss: 2.02819
Epoch 62, Val Loss: 2.04109
Epoch 63, Val Loss: 2.04420
Epoch 64, Val Loss: 2.02442
Epoch 65, Val Loss: 2.02937
Epoch 66, Val Loss: 2.05714
Epoch 67, Val Loss: 2.02097
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.8555, 'Log Loss - std': 0.4012290056812943} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}
Fitted encoder
Epoch 0, Val Loss: 1.98189
Epoch 1, Val Loss: 1.96438
Epoch 2, Val Loss: 1.96544
Epoch 3, Val Loss: 1.97816
Epoch 4, Val Loss: 1.96269
Epoch 5, Val Loss: 1.94526
Epoch 6, Val Loss: 1.94525
Epoch 7, Val Loss: 1.96198
Epoch 8, Val Loss: 1.94341
Epoch 9, Val Loss: 1.92261
Epoch 10, Val Loss: 1.95261
Epoch 11, Val Loss: 1.94972
Epoch 12, Val Loss: 1.93397
Epoch 13, Val Loss: 1.94350
Epoch 14, Val Loss: 1.93924
Epoch 15, Val Loss: 1.96988
Epoch 16, Val Loss: 1.97916
Epoch 17, Val Loss: 1.93341
Epoch 18, Val Loss: 1.92825
Epoch 19, Val Loss: 1.91935
Epoch 20, Val Loss: 1.93498
Epoch 21, Val Loss: 1.92417
Epoch 22, Val Loss: 1.92035
Epoch 23, Val Loss: 1.96135
Epoch 24, Val Loss: 1.92814
Epoch 25, Val Loss: 1.95012
Epoch 26, Val Loss: 1.90749
Epoch 27, Val Loss: 1.92514
Epoch 28, Val Loss: 1.93129
Epoch 29, Val Loss: 1.92499
Epoch 30, Val Loss: 1.94745
Epoch 31, Val Loss: 1.91109
Epoch 32, Val Loss: 1.92511
Epoch 33, Val Loss: 1.93485
Epoch 34, Val Loss: 1.91030
Epoch 35, Val Loss: 1.90618
Epoch 36, Val Loss: 1.91087
Epoch 37, Val Loss: 1.90149
Epoch 38, Val Loss: 1.89706
Epoch 39, Val Loss: 1.90568
Epoch 40, Val Loss: 1.90324
Epoch 41, Val Loss: 1.89899
Epoch 42, Val Loss: 1.92574
Epoch 43, Val Loss: 1.92740
Epoch 44, Val Loss: 1.89758
Epoch 45, Val Loss: 1.90964
Epoch 46, Val Loss: 1.88781
Epoch 47, Val Loss: 1.91053
Epoch 48, Val Loss: 1.90764
Epoch 49, Val Loss: 1.89314
Epoch 50, Val Loss: 1.89751
Epoch 51, Val Loss: 1.90025
Epoch 52, Val Loss: 1.90979
Epoch 53, Val Loss: 1.91051
Epoch 54, Val Loss: 1.91344
Epoch 55, Val Loss: 2.00450
Epoch 56, Val Loss: 1.94657
Epoch 57, Val Loss: 1.91717
Epoch 58, Val Loss: 1.89576
Epoch 59, Val Loss: 1.89934
Epoch 60, Val Loss: 1.92485
Epoch 61, Val Loss: 1.90866
Epoch 62, Val Loss: 1.91959
Epoch 63, Val Loss: 1.90174
Epoch 64, Val Loss: 1.88795
Epoch 65, Val Loss: 1.89295
Epoch 66, Val Loss: 1.90328
Epoch 67, Val Loss: 1.89598
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.9242800000000004, 'Log Loss - std': 0.384331270650724} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 7 finished with value: 2.9242800000000004 and parameters: {'p_m': 0.5895510997120288, 'alpha': 5.985392905092364, 'K': 10, 'beta': 4.183562801258397}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}
Fitted encoder
Epoch 0, Val Loss: 2.11930
Epoch 1, Val Loss: 2.13866
Epoch 2, Val Loss: 2.12391
Epoch 3, Val Loss: 2.13130
Epoch 4, Val Loss: 2.13431
Epoch 5, Val Loss: 2.12876
Epoch 6, Val Loss: 2.11098
Epoch 7, Val Loss: 2.11111
Epoch 8, Val Loss: 2.12358
Epoch 9, Val Loss: 2.11498
Epoch 10, Val Loss: 2.10728
Epoch 11, Val Loss: 2.11081
Epoch 12, Val Loss: 2.12254
Epoch 13, Val Loss: 2.11719
Epoch 14, Val Loss: 2.11867
Epoch 15, Val Loss: 2.11724
Epoch 16, Val Loss: 2.11727
Epoch 17, Val Loss: 2.10992
Epoch 18, Val Loss: 2.09921
Epoch 19, Val Loss: 2.11271
Epoch 20, Val Loss: 2.10070
Epoch 21, Val Loss: 2.09021
Epoch 22, Val Loss: 2.09018
Epoch 23, Val Loss: 2.09766
Epoch 24, Val Loss: 2.09641
Epoch 25, Val Loss: 2.11105
Epoch 26, Val Loss: 2.09019
Epoch 27, Val Loss: 2.09096
Epoch 28, Val Loss: 2.09544
Epoch 29, Val Loss: 2.09034
Epoch 30, Val Loss: 2.08979
Epoch 31, Val Loss: 2.10225
Epoch 32, Val Loss: 2.09021
Epoch 33, Val Loss: 2.09334
Epoch 34, Val Loss: 2.09065
Epoch 35, Val Loss: 2.08988
Epoch 36, Val Loss: 2.08723
Epoch 37, Val Loss: 2.09086
Epoch 38, Val Loss: 2.09223
Epoch 39, Val Loss: 2.09577
Epoch 40, Val Loss: 2.09892
Epoch 41, Val Loss: 2.08977
Epoch 42, Val Loss: 2.09836
Epoch 43, Val Loss: 2.08810
Epoch 44, Val Loss: 2.09297
Epoch 45, Val Loss: 2.09012
Epoch 46, Val Loss: 2.10361
Epoch 47, Val Loss: 2.09376
Epoch 48, Val Loss: 2.08819
Epoch 49, Val Loss: 2.12693
Epoch 50, Val Loss: 2.09407
Epoch 51, Val Loss: 2.09959
Epoch 52, Val Loss: 2.08989
Epoch 53, Val Loss: 2.09810
Epoch 54, Val Loss: 2.08867
Epoch 55, Val Loss: 2.09321
Epoch 56, Val Loss: 2.08984
Epoch 57, Val Loss: 2.10071
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.0591, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}
Fitted encoder
Epoch 0, Val Loss: 1.96987
Epoch 1, Val Loss: 1.97888
Epoch 2, Val Loss: 1.98437
Epoch 3, Val Loss: 1.96438
Epoch 4, Val Loss: 1.95605
Epoch 5, Val Loss: 1.98188
Epoch 6, Val Loss: 1.95178
Epoch 7, Val Loss: 1.98629
Epoch 8, Val Loss: 1.95244
Epoch 9, Val Loss: 1.95288
Epoch 10, Val Loss: 1.98862
Epoch 11, Val Loss: 1.97294
Epoch 12, Val Loss: 1.94851
Epoch 13, Val Loss: 1.95861
Epoch 14, Val Loss: 1.95820
Epoch 15, Val Loss: 1.96046
Epoch 16, Val Loss: 1.95194
Epoch 17, Val Loss: 1.96348
Epoch 18, Val Loss: 1.96158
Epoch 19, Val Loss: 1.96102
Epoch 20, Val Loss: 1.95179
Epoch 21, Val Loss: 1.95322
Epoch 22, Val Loss: 1.94533
Epoch 23, Val Loss: 1.95049
Epoch 24, Val Loss: 1.94702
Epoch 25, Val Loss: 1.95460
Epoch 26, Val Loss: 1.92870
Epoch 27, Val Loss: 1.95135
Epoch 28, Val Loss: 1.92895
Epoch 29, Val Loss: 1.93308
Epoch 30, Val Loss: 1.93884
Epoch 31, Val Loss: 1.93944
Epoch 32, Val Loss: 1.95778
Epoch 33, Val Loss: 1.94738
Epoch 34, Val Loss: 1.96532
Epoch 35, Val Loss: 1.96047
Epoch 36, Val Loss: 1.98032
Epoch 37, Val Loss: 1.94601
Epoch 38, Val Loss: 1.94494
Epoch 39, Val Loss: 1.94686
Epoch 40, Val Loss: 1.98708
Epoch 41, Val Loss: 1.93721
Epoch 42, Val Loss: 1.96069
Epoch 43, Val Loss: 1.94316
Epoch 44, Val Loss: 1.93664
Epoch 45, Val Loss: 1.92234
Epoch 46, Val Loss: 1.93246
Epoch 47, Val Loss: 1.92420
Epoch 48, Val Loss: 1.91169
Epoch 49, Val Loss: 1.96235
Epoch 50, Val Loss: 1.92997
Epoch 51, Val Loss: 1.92147
Epoch 52, Val Loss: 1.91960
Epoch 53, Val Loss: 1.91600
Epoch 54, Val Loss: 1.94992
Epoch 55, Val Loss: 1.91546
Epoch 56, Val Loss: 1.91549
Epoch 57, Val Loss: 1.91481
Epoch 58, Val Loss: 1.93076
Epoch 59, Val Loss: 1.92125
Epoch 60, Val Loss: 1.91483
Epoch 61, Val Loss: 1.90809
Epoch 62, Val Loss: 1.91114
Epoch 63, Val Loss: 1.91469
Epoch 64, Val Loss: 1.91561
Epoch 65, Val Loss: 1.93948
Epoch 66, Val Loss: 1.90629
Epoch 67, Val Loss: 1.92098
Epoch 68, Val Loss: 1.91820
Epoch 69, Val Loss: 1.94684
Epoch 70, Val Loss: 1.90577
Epoch 71, Val Loss: 1.91832
Epoch 72, Val Loss: 1.90545
Epoch 73, Val Loss: 1.93257
Epoch 74, Val Loss: 1.91749
Epoch 75, Val Loss: 1.93211
Epoch 76, Val Loss: 1.91480
Epoch 77, Val Loss: 1.91241
Epoch 78, Val Loss: 1.91395
Epoch 79, Val Loss: 1.92463
Epoch 80, Val Loss: 1.91063
Epoch 81, Val Loss: 1.93374
Epoch 82, Val Loss: 1.97194
Epoch 83, Val Loss: 1.90543
Epoch 84, Val Loss: 1.91375
Epoch 85, Val Loss: 1.91799
Epoch 86, Val Loss: 1.94354
Epoch 87, Val Loss: 1.91585
Epoch 88, Val Loss: 1.90791
Epoch 89, Val Loss: 1.93871
Epoch 90, Val Loss: 1.89875
Epoch 91, Val Loss: 1.90164
Epoch 92, Val Loss: 1.92038
Epoch 93, Val Loss: 1.90549
Epoch 94, Val Loss: 1.90674
Epoch 95, Val Loss: 1.90329
Epoch 96, Val Loss: 1.90341
Epoch 97, Val Loss: 1.91474
Epoch 98, Val Loss: 1.90585
Epoch 99, Val Loss: 1.93793
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.4231, 'Log Loss - std': 0.3640000000000001} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}
Fitted encoder
Epoch 0, Val Loss: 2.12455
Epoch 1, Val Loss: 2.10674
Epoch 2, Val Loss: 2.10041
Epoch 3, Val Loss: 2.09758
Epoch 4, Val Loss: 2.10657
Epoch 5, Val Loss: 2.09798
Epoch 6, Val Loss: 2.09022
Epoch 7, Val Loss: 2.09431
Epoch 8, Val Loss: 2.10394
Epoch 9, Val Loss: 2.08797
Epoch 10, Val Loss: 2.09177
Epoch 11, Val Loss: 2.09172
Epoch 12, Val Loss: 2.11469
Epoch 13, Val Loss: 2.08660
Epoch 14, Val Loss: 2.09000
Epoch 15, Val Loss: 2.09410
Epoch 16, Val Loss: 2.09996
Epoch 17, Val Loss: 2.08912
Epoch 18, Val Loss: 2.12507
Epoch 19, Val Loss: 2.09397
Epoch 20, Val Loss: 2.11960
Epoch 21, Val Loss: 2.09197
Epoch 22, Val Loss: 2.08509
Epoch 23, Val Loss: 2.09703
Epoch 24, Val Loss: 2.08561
Epoch 25, Val Loss: 2.08516
Epoch 26, Val Loss: 2.08708
Epoch 27, Val Loss: 2.08418
Epoch 28, Val Loss: 2.12372
Epoch 29, Val Loss: 2.08950
Epoch 30, Val Loss: 2.08446
Epoch 31, Val Loss: 2.08552
Epoch 32, Val Loss: 2.08599
Epoch 33, Val Loss: 2.08317
Epoch 34, Val Loss: 2.08291
Epoch 35, Val Loss: 2.08136
Epoch 36, Val Loss: 2.10129
Epoch 37, Val Loss: 2.08414
Epoch 38, Val Loss: 2.08143
Epoch 39, Val Loss: 2.08347
Epoch 40, Val Loss: 2.11023
Epoch 41, Val Loss: 2.08289
Epoch 42, Val Loss: 2.08394
Epoch 43, Val Loss: 2.08688
Epoch 44, Val Loss: 2.08432
Epoch 45, Val Loss: 2.08586
Epoch 46, Val Loss: 2.08506
Epoch 47, Val Loss: 2.10325
Epoch 48, Val Loss: 2.10587
Epoch 49, Val Loss: 2.09244
Epoch 50, Val Loss: 2.08664
Epoch 51, Val Loss: 2.12277
Epoch 52, Val Loss: 2.12009
Epoch 53, Val Loss: 2.10479
Epoch 54, Val Loss: 2.15371
Epoch 55, Val Loss: 2.12699
Epoch 56, Val Loss: 2.13859
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.308833333333333, 'Log Loss - std': 0.3382963329521752} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}
Fitted encoder
Epoch 0, Val Loss: 2.08284
Epoch 1, Val Loss: 2.08332
Epoch 2, Val Loss: 2.07727
Epoch 3, Val Loss: 2.07871
Epoch 4, Val Loss: 2.06288
Epoch 5, Val Loss: 2.07534
Epoch 6, Val Loss: 2.08700
Epoch 7, Val Loss: 2.08934
Epoch 8, Val Loss: 2.07477
Epoch 9, Val Loss: 2.07850
Epoch 10, Val Loss: 2.06556
Epoch 11, Val Loss: 2.06801
Epoch 12, Val Loss: 2.06678
Epoch 13, Val Loss: 2.07254
Epoch 14, Val Loss: 2.07093
Epoch 15, Val Loss: 2.07103
Epoch 16, Val Loss: 2.08456
Epoch 17, Val Loss: 2.06237
Epoch 18, Val Loss: 2.06500
Epoch 19, Val Loss: 2.06007
Epoch 20, Val Loss: 2.04914
Epoch 21, Val Loss: 2.05171
Epoch 22, Val Loss: 2.06311
Epoch 23, Val Loss: 2.05795
Epoch 24, Val Loss: 2.06021
Epoch 25, Val Loss: 2.06780
Epoch 26, Val Loss: 2.05778
Epoch 27, Val Loss: 2.04526
Epoch 28, Val Loss: 2.05133
Epoch 29, Val Loss: 2.04474
Epoch 30, Val Loss: 2.05915
Epoch 31, Val Loss: 2.07640
Epoch 32, Val Loss: 2.06239
Epoch 33, Val Loss: 2.05205
Epoch 34, Val Loss: 2.07548
Epoch 35, Val Loss: 2.03831
Epoch 36, Val Loss: 2.05011
Epoch 37, Val Loss: 2.06236
Epoch 38, Val Loss: 2.03013
Epoch 39, Val Loss: 2.04187
Epoch 40, Val Loss: 2.04033
Epoch 41, Val Loss: 2.05085
Epoch 42, Val Loss: 2.05599
Epoch 43, Val Loss: 2.05802
Epoch 44, Val Loss: 2.05615
Epoch 45, Val Loss: 2.06176
Epoch 46, Val Loss: 2.03552
Epoch 47, Val Loss: 2.03521
Epoch 48, Val Loss: 2.04696
Epoch 49, Val Loss: 2.05526
Epoch 50, Val Loss: 2.04450
Epoch 51, Val Loss: 2.04158
Epoch 52, Val Loss: 2.03148
Epoch 53, Val Loss: 2.05567
Epoch 54, Val Loss: 2.04888
Epoch 55, Val Loss: 2.06079
Epoch 56, Val Loss: 2.04589
Epoch 57, Val Loss: 2.03510
Epoch 58, Val Loss: 2.02184
Epoch 59, Val Loss: 2.03133
Epoch 60, Val Loss: 2.05318
Epoch 61, Val Loss: 2.03385
Epoch 62, Val Loss: 2.05405
Epoch 63, Val Loss: 2.03824
Epoch 64, Val Loss: 2.04110
Epoch 65, Val Loss: 2.02687
Epoch 66, Val Loss: 2.05981
Epoch 67, Val Loss: 2.02428
Epoch 68, Val Loss: 2.01997
Epoch 69, Val Loss: 2.03185
Epoch 70, Val Loss: 2.03998
Epoch 71, Val Loss: 2.02765
Epoch 72, Val Loss: 2.01807
Epoch 73, Val Loss: 2.06692
Epoch 74, Val Loss: 2.02157
Epoch 75, Val Loss: 2.02482
Epoch 76, Val Loss: 2.02095
Epoch 77, Val Loss: 2.02602
Epoch 78, Val Loss: 2.04829
Epoch 79, Val Loss: 2.04317
Epoch 80, Val Loss: 2.03226
Epoch 81, Val Loss: 2.04092
Epoch 82, Val Loss: 2.06032
Epoch 83, Val Loss: 2.01685
Epoch 84, Val Loss: 2.03526
Epoch 85, Val Loss: 2.02747
Epoch 86, Val Loss: 2.04112
Epoch 87, Val Loss: 2.08161
Epoch 88, Val Loss: 2.04908
Epoch 89, Val Loss: 2.04519
Epoch 90, Val Loss: 2.04639
Epoch 91, Val Loss: 2.03401
Epoch 92, Val Loss: 2.03516
Epoch 93, Val Loss: 2.02423
Epoch 94, Val Loss: 2.02102
Epoch 95, Val Loss: 2.03633
Epoch 96, Val Loss: 2.03528
Epoch 97, Val Loss: 2.02128
Epoch 98, Val Loss: 2.02177
Epoch 99, Val Loss: 2.03898
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.2652249999999996, 'Log Loss - std': 0.3025530810866088} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}
Fitted encoder
Epoch 0, Val Loss: 1.97189
Epoch 1, Val Loss: 1.97886
Epoch 2, Val Loss: 1.98227
Epoch 3, Val Loss: 1.97702
Epoch 4, Val Loss: 1.96819
Epoch 5, Val Loss: 1.97004
Epoch 6, Val Loss: 1.99031
Epoch 7, Val Loss: 1.95877
Epoch 8, Val Loss: 1.96596
Epoch 9, Val Loss: 1.97190
Epoch 10, Val Loss: 1.97823
Epoch 11, Val Loss: 1.95832
Epoch 12, Val Loss: 1.95721
Epoch 13, Val Loss: 1.96131
Epoch 14, Val Loss: 1.96241
Epoch 15, Val Loss: 1.95272
Epoch 16, Val Loss: 1.95130
Epoch 17, Val Loss: 1.96426
Epoch 18, Val Loss: 1.96253
Epoch 19, Val Loss: 1.95944
Epoch 20, Val Loss: 1.96002
Epoch 21, Val Loss: 1.95147
Epoch 22, Val Loss: 1.95039
Epoch 23, Val Loss: 1.95247
Epoch 24, Val Loss: 1.95544
Epoch 25, Val Loss: 1.93831
Epoch 26, Val Loss: 1.94543
Epoch 27, Val Loss: 1.94741
Epoch 28, Val Loss: 1.96350
Epoch 29, Val Loss: 1.95172
Epoch 30, Val Loss: 1.94598
Epoch 31, Val Loss: 1.95256
Epoch 32, Val Loss: 1.99040
Epoch 33, Val Loss: 1.96487
Epoch 34, Val Loss: 1.95536
Epoch 35, Val Loss: 1.94382
Epoch 36, Val Loss: 1.94073
Epoch 37, Val Loss: 1.94201
Epoch 38, Val Loss: 1.95386
Epoch 39, Val Loss: 1.96835
Epoch 40, Val Loss: 1.94942
Epoch 41, Val Loss: 1.95699
Epoch 42, Val Loss: 1.94612
Epoch 43, Val Loss: 1.94468
Epoch 44, Val Loss: 1.93898
Epoch 45, Val Loss: 1.92648
Epoch 46, Val Loss: 1.95137
Epoch 47, Val Loss: 1.92658
Epoch 48, Val Loss: 1.94044
Epoch 49, Val Loss: 1.92873
Epoch 50, Val Loss: 1.92855
Epoch 51, Val Loss: 1.95415
Epoch 52, Val Loss: 1.93015
Epoch 53, Val Loss: 1.93762
Epoch 54, Val Loss: 1.94230
Epoch 55, Val Loss: 1.91620
Epoch 56, Val Loss: 1.95724
Epoch 57, Val Loss: 1.92698
Epoch 58, Val Loss: 1.92632
Epoch 59, Val Loss: 1.91997
Epoch 60, Val Loss: 1.94425
Epoch 61, Val Loss: 1.91152
Epoch 62, Val Loss: 1.94270
Epoch 63, Val Loss: 1.91821
Epoch 64, Val Loss: 1.93753
Epoch 65, Val Loss: 1.93499
Epoch 66, Val Loss: 1.91541
Epoch 67, Val Loss: 1.91372
Epoch 68, Val Loss: 1.93695
Epoch 69, Val Loss: 1.93101
Epoch 70, Val Loss: 1.92521
Epoch 71, Val Loss: 1.92807
Epoch 72, Val Loss: 1.91772
Epoch 73, Val Loss: 1.92287
Epoch 74, Val Loss: 1.94860
Epoch 75, Val Loss: 1.92207
Epoch 76, Val Loss: 1.93958
Epoch 77, Val Loss: 1.93148
Epoch 78, Val Loss: 1.91761
Epoch 79, Val Loss: 1.93949
Epoch 80, Val Loss: 1.91363
Epoch 81, Val Loss: 1.91685
Epoch 82, Val Loss: 1.90430
Epoch 83, Val Loss: 1.92737
Epoch 84, Val Loss: 1.91861
Epoch 85, Val Loss: 1.91842
Epoch 86, Val Loss: 1.91441
Epoch 87, Val Loss: 1.91635
Epoch 88, Val Loss: 1.90270
Epoch 89, Val Loss: 1.94170
Epoch 90, Val Loss: 1.91644
Epoch 91, Val Loss: 1.91371
Epoch 92, Val Loss: 1.91178
Epoch 93, Val Loss: 1.91048
Epoch 94, Val Loss: 1.90691
Epoch 95, Val Loss: 1.94689
Epoch 96, Val Loss: 1.91707
Epoch 97, Val Loss: 1.92288
Epoch 98, Val Loss: 1.91249
Epoch 99, Val Loss: 1.91644
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.3739399999999997, 'Log Loss - std': 0.34714045918043046} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 8 finished with value: 2.3739399999999997 and parameters: {'p_m': 0.48510806820457086, 'alpha': 7.343192935039053, 'K': 2, 'beta': 8.813705907353661}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}
Fitted encoder
Epoch 0, Val Loss: 2.15808
Epoch 1, Val Loss: 2.11387
Epoch 2, Val Loss: 2.11740
Epoch 3, Val Loss: 2.11696
Epoch 4, Val Loss: 2.09163
Epoch 5, Val Loss: 2.13518
Epoch 6, Val Loss: 2.12944
Epoch 7, Val Loss: 2.11010
Epoch 8, Val Loss: 2.09139
Epoch 9, Val Loss: 2.07948
Epoch 10, Val Loss: 2.09545
Epoch 11, Val Loss: 2.06918
Epoch 12, Val Loss: 2.09650
Epoch 13, Val Loss: 2.06875
Epoch 14, Val Loss: 2.06410
Epoch 15, Val Loss: 2.05662
Epoch 16, Val Loss: 2.07788
Epoch 17, Val Loss: 2.09545
Epoch 18, Val Loss: 2.04698
Epoch 19, Val Loss: 2.08269
Epoch 20, Val Loss: 2.06556
Epoch 21, Val Loss: 2.08513
Epoch 22, Val Loss: 2.05771
Epoch 23, Val Loss: 2.06417
Epoch 24, Val Loss: 2.06580
Epoch 25, Val Loss: 2.05434
Epoch 26, Val Loss: 2.04314
Epoch 27, Val Loss: 2.04939
Epoch 28, Val Loss: 2.07149
Epoch 29, Val Loss: 2.06373
Epoch 30, Val Loss: 2.04604
Epoch 31, Val Loss: 2.05772
Epoch 32, Val Loss: 2.05589
Epoch 33, Val Loss: 2.05363
Epoch 34, Val Loss: 2.04296
Epoch 35, Val Loss: 2.05330
Epoch 36, Val Loss: 2.04853
Epoch 37, Val Loss: 2.03551
Epoch 38, Val Loss: 2.06162
Epoch 39, Val Loss: 2.04133
Epoch 40, Val Loss: 2.06463
Epoch 41, Val Loss: 2.06063
Epoch 42, Val Loss: 2.04840
Epoch 43, Val Loss: 2.05551
Epoch 44, Val Loss: 2.05828
Epoch 45, Val Loss: 2.04398
Epoch 46, Val Loss: 2.03849
Epoch 47, Val Loss: 2.05252
Epoch 48, Val Loss: 2.03518
Epoch 49, Val Loss: 2.07391
Epoch 50, Val Loss: 2.04350
Epoch 51, Val Loss: 2.02068
Epoch 52, Val Loss: 2.04504
Epoch 53, Val Loss: 2.04226
Epoch 54, Val Loss: 2.02987
Epoch 55, Val Loss: 2.05584
Epoch 56, Val Loss: 2.04690
Epoch 57, Val Loss: 2.06241
Epoch 58, Val Loss: 2.04735
Epoch 59, Val Loss: 2.07378
Epoch 60, Val Loss: 2.04625
Epoch 61, Val Loss: 2.04669
Epoch 62, Val Loss: 2.03244
Epoch 63, Val Loss: 2.04587
Epoch 64, Val Loss: 2.03704
Epoch 65, Val Loss: 2.05390
Epoch 66, Val Loss: 2.08468
Epoch 67, Val Loss: 2.04476
Epoch 68, Val Loss: 2.04070
Epoch 69, Val Loss: 2.05583
Epoch 70, Val Loss: 2.04582
Epoch 71, Val Loss: 2.03220
Epoch 72, Val Loss: 2.08189
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.8902, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}
Fitted encoder
Epoch 0, Val Loss: 1.98530
Epoch 1, Val Loss: 1.96334
Epoch 2, Val Loss: 1.95651
Epoch 3, Val Loss: 1.97000
Epoch 4, Val Loss: 2.01237
Epoch 5, Val Loss: 1.94872
Epoch 6, Val Loss: 1.96108
Epoch 7, Val Loss: 1.94904
Epoch 8, Val Loss: 1.95068
Epoch 9, Val Loss: 1.95288
Epoch 10, Val Loss: 1.94780
Epoch 11, Val Loss: 1.95738
Epoch 12, Val Loss: 1.94711
Epoch 13, Val Loss: 1.94208
Epoch 14, Val Loss: 1.96252
Epoch 15, Val Loss: 1.95861
Epoch 16, Val Loss: 1.96736
Epoch 17, Val Loss: 1.95157
Epoch 18, Val Loss: 1.94641
Epoch 19, Val Loss: 1.93190
Epoch 20, Val Loss: 1.94388
Epoch 21, Val Loss: 2.04198
Epoch 22, Val Loss: 2.02170
Epoch 23, Val Loss: 2.00410
Epoch 24, Val Loss: 1.97500
Epoch 25, Val Loss: 1.95354
Epoch 26, Val Loss: 1.93866
Epoch 27, Val Loss: 1.93560
Epoch 28, Val Loss: 1.95664
Epoch 29, Val Loss: 1.96752
Epoch 30, Val Loss: 1.93508
Epoch 31, Val Loss: 1.94811
Epoch 32, Val Loss: 1.93245
Epoch 33, Val Loss: 1.93891
Epoch 34, Val Loss: 1.92496
Epoch 35, Val Loss: 1.93177
Epoch 36, Val Loss: 1.91602
Epoch 37, Val Loss: 1.93145
Epoch 38, Val Loss: 1.92150
Epoch 39, Val Loss: 1.91142
Epoch 40, Val Loss: 1.93387
Epoch 41, Val Loss: 1.92447
Epoch 42, Val Loss: 1.92918
Epoch 43, Val Loss: 1.91507
Epoch 44, Val Loss: 1.91750
Epoch 45, Val Loss: 1.93646
Epoch 46, Val Loss: 1.90082
Epoch 47, Val Loss: 1.91104
Epoch 48, Val Loss: 1.90525
Epoch 49, Val Loss: 1.91017
Epoch 50, Val Loss: 1.91611
Epoch 51, Val Loss: 1.92436
Epoch 52, Val Loss: 1.92486
Epoch 53, Val Loss: 1.90412
Epoch 54, Val Loss: 1.89264
Epoch 55, Val Loss: 1.91777
Epoch 56, Val Loss: 1.90027
Epoch 57, Val Loss: 1.90324
Epoch 58, Val Loss: 1.90714
Epoch 59, Val Loss: 1.91647
Epoch 60, Val Loss: 1.90919
Epoch 61, Val Loss: 1.90728
Epoch 62, Val Loss: 1.91352
Epoch 63, Val Loss: 1.90191
Epoch 64, Val Loss: 1.91837
Epoch 65, Val Loss: 1.91431
Epoch 66, Val Loss: 1.91699
Epoch 67, Val Loss: 1.94371
Epoch 68, Val Loss: 1.92071
Epoch 69, Val Loss: 1.91816
Epoch 70, Val Loss: 1.90820
Epoch 71, Val Loss: 1.90982
Epoch 72, Val Loss: 1.92111
Epoch 73, Val Loss: 1.91143
Epoch 74, Val Loss: 1.91871
Epoch 75, Val Loss: 1.91034
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.9941, 'Log Loss - std': 0.10389999999999988} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}
Fitted encoder
Epoch 0, Val Loss: 2.15359
Epoch 1, Val Loss: 2.14018
Epoch 2, Val Loss: 2.09060
Epoch 3, Val Loss: 2.11689
Epoch 4, Val Loss: 2.09479
Epoch 5, Val Loss: 2.08845
Epoch 6, Val Loss: 2.10661
Epoch 7, Val Loss: 2.08201
Epoch 8, Val Loss: 2.08245
Epoch 9, Val Loss: 2.12149
Epoch 10, Val Loss: 2.08230
Epoch 11, Val Loss: 2.07700
Epoch 12, Val Loss: 2.08732
Epoch 13, Val Loss: 2.05886
Epoch 14, Val Loss: 2.10315
Epoch 15, Val Loss: 2.06955
Epoch 16, Val Loss: 2.06499
Epoch 17, Val Loss: 2.07717
Epoch 18, Val Loss: 2.08321
Epoch 19, Val Loss: 2.09226
Epoch 20, Val Loss: 2.08622
Epoch 21, Val Loss: 2.06763
Epoch 22, Val Loss: 2.09154
Epoch 23, Val Loss: 2.06997
Epoch 24, Val Loss: 2.08265
Epoch 25, Val Loss: 2.06799
Epoch 26, Val Loss: 2.07333
Epoch 27, Val Loss: 2.09221
Epoch 28, Val Loss: 2.06875
Epoch 29, Val Loss: 2.06778
Epoch 30, Val Loss: 2.09220
Epoch 31, Val Loss: 2.06571
Epoch 32, Val Loss: 2.14413
Epoch 33, Val Loss: 2.08663
Epoch 34, Val Loss: 2.07427
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.7707333333333337, 'Log Loss - std': 0.32708124712710485} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}
Fitted encoder
Epoch 0, Val Loss: 2.09168
Epoch 1, Val Loss: 2.14690
Epoch 2, Val Loss: 2.12138
Epoch 3, Val Loss: 2.12350
Epoch 4, Val Loss: 2.08347
Epoch 5, Val Loss: 2.05931
Epoch 6, Val Loss: 2.07447
Epoch 7, Val Loss: 2.05626
Epoch 8, Val Loss: 2.04710
Epoch 9, Val Loss: 2.07588
Epoch 10, Val Loss: 2.04856
Epoch 11, Val Loss: 2.03906
Epoch 12, Val Loss: 2.04907
Epoch 13, Val Loss: 2.02620
Epoch 14, Val Loss: 2.12867
Epoch 15, Val Loss: 2.10700
Epoch 16, Val Loss: 2.07707
Epoch 17, Val Loss: 2.05639
Epoch 18, Val Loss: 2.02991
Epoch 19, Val Loss: 2.04639
Epoch 20, Val Loss: 2.03970
Epoch 21, Val Loss: 2.02641
Epoch 22, Val Loss: 2.03115
Epoch 23, Val Loss: 2.04837
Epoch 24, Val Loss: 2.06039
Epoch 25, Val Loss: 2.02000
Epoch 26, Val Loss: 2.02412
Epoch 27, Val Loss: 2.02529
Epoch 28, Val Loss: 2.02442
Epoch 29, Val Loss: 2.06250
Epoch 30, Val Loss: 2.02558
Epoch 31, Val Loss: 2.01833
Epoch 32, Val Loss: 2.03670
Epoch 33, Val Loss: 2.01104
Epoch 34, Val Loss: 2.02104
Epoch 35, Val Loss: 2.03888
Epoch 36, Val Loss: 2.02113
Epoch 37, Val Loss: 2.02194
Epoch 38, Val Loss: 2.01541
Epoch 39, Val Loss: 2.02679
Epoch 40, Val Loss: 2.01658
Epoch 41, Val Loss: 2.01923
Epoch 42, Val Loss: 2.02033
Epoch 43, Val Loss: 2.02349
Epoch 44, Val Loss: 2.03176
Epoch 45, Val Loss: 2.02602
Epoch 46, Val Loss: 2.01897
Epoch 47, Val Loss: 2.00434
Epoch 48, Val Loss: 2.05023
Epoch 49, Val Loss: 2.04260
Epoch 50, Val Loss: 2.01201
Epoch 51, Val Loss: 2.00952
Epoch 52, Val Loss: 2.02490
Epoch 53, Val Loss: 2.03211
Epoch 54, Val Loss: 2.03345
Epoch 55, Val Loss: 2.03472
Epoch 56, Val Loss: 2.03519
Epoch 57, Val Loss: 2.02237
Epoch 58, Val Loss: 2.02280
Epoch 59, Val Loss: 2.03551
Epoch 60, Val Loss: 2.05441
Epoch 61, Val Loss: 2.04626
Epoch 62, Val Loss: 2.01766
Epoch 63, Val Loss: 2.03520
Epoch 64, Val Loss: 2.03936
Epoch 65, Val Loss: 2.03958
Epoch 66, Val Loss: 2.04791
Epoch 67, Val Loss: 2.02296
Epoch 68, Val Loss: 2.00797
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.867675, 'Log Loss - std': 0.3292866029388381} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}
Fitted encoder
Epoch 0, Val Loss: 1.95928
Epoch 1, Val Loss: 1.95892
Epoch 2, Val Loss: 1.96777
Epoch 3, Val Loss: 1.95951
Epoch 4, Val Loss: 1.96594
Epoch 5, Val Loss: 1.94354
Epoch 6, Val Loss: 1.96255
Epoch 7, Val Loss: 1.96144
Epoch 8, Val Loss: 2.02312
Epoch 9, Val Loss: 1.95229
Epoch 10, Val Loss: 1.94521
Epoch 11, Val Loss: 1.93059
Epoch 12, Val Loss: 1.94659
Epoch 13, Val Loss: 1.91425
Epoch 14, Val Loss: 1.92144
Epoch 15, Val Loss: 1.96876
Epoch 16, Val Loss: 1.94890
Epoch 17, Val Loss: 1.92946
Epoch 18, Val Loss: 1.91878
Epoch 19, Val Loss: 1.91201
Epoch 20, Val Loss: 1.90438
Epoch 21, Val Loss: 1.90542
Epoch 22, Val Loss: 1.90329
Epoch 23, Val Loss: 1.92746
Epoch 24, Val Loss: 1.89769
Epoch 25, Val Loss: 1.90431
Epoch 26, Val Loss: 1.89002
Epoch 27, Val Loss: 1.88154
Epoch 28, Val Loss: 1.90435
Epoch 29, Val Loss: 1.90371
Epoch 30, Val Loss: 1.91809
Epoch 31, Val Loss: 1.92583
Epoch 32, Val Loss: 1.92516
Epoch 33, Val Loss: 1.88959
Epoch 34, Val Loss: 1.90885
Epoch 35, Val Loss: 1.90148
Epoch 36, Val Loss: 1.89237
Epoch 37, Val Loss: 1.90244
Epoch 38, Val Loss: 1.88672
Epoch 39, Val Loss: 1.89766
Epoch 40, Val Loss: 1.90375
Epoch 41, Val Loss: 1.90478
Epoch 42, Val Loss: 1.92209
Epoch 43, Val Loss: 1.92415
Epoch 44, Val Loss: 1.90085
Epoch 45, Val Loss: 1.90241
Epoch 46, Val Loss: 1.89710
Epoch 47, Val Loss: 1.89571
Epoch 48, Val Loss: 1.90181
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.90164, 'Log Loss - std': 0.3022552206331597} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 9 finished with value: 2.90164 and parameters: {'p_m': 0.760693153550981, 'alpha': 0.9606808936095262, 'K': 15, 'beta': 8.322696427368923}. Best is trial 0 with value: 3.2672399999999997.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}
Fitted encoder
Epoch 0, Val Loss: 2.13545
Epoch 1, Val Loss: 2.13087
Epoch 2, Val Loss: 2.13193
Epoch 3, Val Loss: 2.10635
Epoch 4, Val Loss: 2.09318
Epoch 5, Val Loss: 2.09522
Epoch 6, Val Loss: 2.11488
Epoch 7, Val Loss: 2.09965
Epoch 8, Val Loss: 2.09112
Epoch 9, Val Loss: 2.08958
Epoch 10, Val Loss: 2.13060
Epoch 11, Val Loss: 2.10738
Epoch 12, Val Loss: 2.09737
Epoch 13, Val Loss: 2.10836
Epoch 14, Val Loss: 2.08898
Epoch 15, Val Loss: 2.11782
Epoch 16, Val Loss: 2.10662
Epoch 17, Val Loss: 2.08611
Epoch 18, Val Loss: 2.08104
Epoch 19, Val Loss: 2.14675
Epoch 20, Val Loss: 2.10385
Epoch 21, Val Loss: 2.07461
Epoch 22, Val Loss: 2.07759
Epoch 23, Val Loss: 2.07893
Epoch 24, Val Loss: 2.07884
Epoch 25, Val Loss: 2.07302
Epoch 26, Val Loss: 2.10780
Epoch 27, Val Loss: 2.07693
Epoch 28, Val Loss: 2.07141
Epoch 29, Val Loss: 2.07742
Epoch 30, Val Loss: 2.05759
Epoch 31, Val Loss: 2.10584
Epoch 32, Val Loss: 2.07423
Epoch 33, Val Loss: 2.08042
Epoch 34, Val Loss: 2.07582
Epoch 35, Val Loss: 2.05676
Epoch 36, Val Loss: 2.06382
Epoch 37, Val Loss: 2.06620
Epoch 38, Val Loss: 2.06905
Epoch 39, Val Loss: 2.05709
Epoch 40, Val Loss: 2.05538
Epoch 41, Val Loss: 2.10286
Epoch 42, Val Loss: 2.08515
Epoch 43, Val Loss: 2.07343
Epoch 44, Val Loss: 2.08363
Epoch 45, Val Loss: 2.07761
Epoch 46, Val Loss: 2.08155
Epoch 47, Val Loss: 2.06925
Epoch 48, Val Loss: 2.05447
Epoch 49, Val Loss: 2.06794
Epoch 50, Val Loss: 2.09140
Epoch 51, Val Loss: 2.05273
Epoch 52, Val Loss: 2.04864
Epoch 53, Val Loss: 2.07747
Epoch 54, Val Loss: 2.07299
Epoch 55, Val Loss: 2.06774
Epoch 56, Val Loss: 2.07503
Epoch 57, Val Loss: 2.06340
Epoch 58, Val Loss: 2.04774
Epoch 59, Val Loss: 2.07519
Epoch 60, Val Loss: 2.06672
Epoch 61, Val Loss: 2.07308
Epoch 62, Val Loss: 2.04121
Epoch 63, Val Loss: 2.06662
Epoch 64, Val Loss: 2.03248
Epoch 65, Val Loss: 2.08263
Epoch 66, Val Loss: 2.06654
Epoch 67, Val Loss: 2.02906
Epoch 68, Val Loss: 2.05078
Epoch 69, Val Loss: 2.05514
Epoch 70, Val Loss: 2.02161
Epoch 71, Val Loss: 2.04203
Epoch 72, Val Loss: 2.07985
Epoch 73, Val Loss: 2.05056
Epoch 74, Val Loss: 2.04372
Epoch 75, Val Loss: 2.06233
Epoch 76, Val Loss: 2.04135
Epoch 77, Val Loss: 2.03840
Epoch 78, Val Loss: 2.04165
Epoch 79, Val Loss: 2.03838
Epoch 80, Val Loss: 2.03935
Epoch 81, Val Loss: 2.03505
Epoch 82, Val Loss: 2.01548
Epoch 83, Val Loss: 2.03429
Epoch 84, Val Loss: 2.09382
Epoch 85, Val Loss: 2.07899
Epoch 86, Val Loss: 2.03341
Epoch 87, Val Loss: 2.03221
Epoch 88, Val Loss: 2.03349
Epoch 89, Val Loss: 2.03086
Epoch 90, Val Loss: 2.08651
Epoch 91, Val Loss: 2.10820
Epoch 92, Val Loss: 2.07319
Epoch 93, Val Loss: 2.09856
Epoch 94, Val Loss: 2.07056
Epoch 95, Val Loss: 2.04736
Epoch 96, Val Loss: 2.07968
Epoch 97, Val Loss: 2.06264
Epoch 98, Val Loss: 2.01565
Epoch 99, Val Loss: 2.07266
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3386, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}
Fitted encoder
Epoch 0, Val Loss: 1.97492
Epoch 1, Val Loss: 1.95434
Epoch 2, Val Loss: 1.94796
Epoch 3, Val Loss: 1.94887
Epoch 4, Val Loss: 1.96584
Epoch 5, Val Loss: 1.97059
Epoch 6, Val Loss: 1.95839
Epoch 7, Val Loss: 1.95961
Epoch 8, Val Loss: 1.93642
Epoch 9, Val Loss: 1.94155
Epoch 10, Val Loss: 1.93057
Epoch 11, Val Loss: 1.94453
Epoch 12, Val Loss: 2.00714
Epoch 13, Val Loss: 1.96505
Epoch 14, Val Loss: 1.96203
Epoch 15, Val Loss: 1.93804
Epoch 16, Val Loss: 1.93813
Epoch 17, Val Loss: 1.92985
Epoch 18, Val Loss: 1.95132
Epoch 19, Val Loss: 1.94445
Epoch 20, Val Loss: 1.91519
Epoch 21, Val Loss: 1.94323
Epoch 22, Val Loss: 1.97721
Epoch 23, Val Loss: 1.93156
Epoch 24, Val Loss: 1.92444
Epoch 25, Val Loss: 1.91974
Epoch 26, Val Loss: 1.95465
Epoch 27, Val Loss: 1.95662
Epoch 28, Val Loss: 1.96271
Epoch 29, Val Loss: 1.92455
Epoch 30, Val Loss: 1.93363
Epoch 31, Val Loss: 1.92812
Epoch 32, Val Loss: 1.92745
Epoch 33, Val Loss: 1.94309
Epoch 34, Val Loss: 1.98441
Epoch 35, Val Loss: 1.93926
Epoch 36, Val Loss: 1.91707
Epoch 37, Val Loss: 1.91433
Epoch 38, Val Loss: 1.91870
Epoch 39, Val Loss: 1.90754
Epoch 40, Val Loss: 1.95252
Epoch 41, Val Loss: 1.92907
Epoch 42, Val Loss: 1.91652
Epoch 43, Val Loss: 1.90432
Epoch 44, Val Loss: 1.96196
Epoch 45, Val Loss: 1.91743
Epoch 46, Val Loss: 1.92132
Epoch 47, Val Loss: 1.90076
Epoch 48, Val Loss: 1.89937
Epoch 49, Val Loss: 1.92368
Epoch 50, Val Loss: 1.91528
Epoch 51, Val Loss: 1.91739
Epoch 52, Val Loss: 1.90903
Epoch 53, Val Loss: 1.91283
Epoch 54, Val Loss: 1.92248
Epoch 55, Val Loss: 2.00367
Epoch 56, Val Loss: 1.92436
Epoch 57, Val Loss: 1.93605
Epoch 58, Val Loss: 1.91463
Epoch 59, Val Loss: 1.90945
Epoch 60, Val Loss: 1.92637
Epoch 61, Val Loss: 1.92878
Epoch 62, Val Loss: 1.91236
Epoch 63, Val Loss: 1.94864
Epoch 64, Val Loss: 1.91773
Epoch 65, Val Loss: 1.90870
Epoch 66, Val Loss: 1.90459
Epoch 67, Val Loss: 1.90506
Epoch 68, Val Loss: 1.93113
Epoch 69, Val Loss: 1.89991
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.22875, 'Log Loss - std': 0.10985} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}
Fitted encoder
Epoch 0, Val Loss: 2.11775
Epoch 1, Val Loss: 2.11555
Epoch 2, Val Loss: 2.12263
Epoch 3, Val Loss: 2.11924
Epoch 4, Val Loss: 2.12734
Epoch 5, Val Loss: 2.11233
Epoch 6, Val Loss: 2.13393
Epoch 7, Val Loss: 2.11020
Epoch 8, Val Loss: 2.11376
Epoch 9, Val Loss: 2.10200
Epoch 10, Val Loss: 2.10428
Epoch 11, Val Loss: 2.13643
Epoch 12, Val Loss: 2.10557
Epoch 13, Val Loss: 2.11469
Epoch 14, Val Loss: 2.13110
Epoch 15, Val Loss: 2.09792
Epoch 16, Val Loss: 2.08193
Epoch 17, Val Loss: 2.07075
Epoch 18, Val Loss: 2.08328
Epoch 19, Val Loss: 2.08309
Epoch 20, Val Loss: 2.11309
Epoch 21, Val Loss: 2.08967
Epoch 22, Val Loss: 2.08187
Epoch 23, Val Loss: 2.10025
Epoch 24, Val Loss: 2.10299
Epoch 25, Val Loss: 2.06963
Epoch 26, Val Loss: 2.11258
Epoch 27, Val Loss: 2.07981
Epoch 28, Val Loss: 2.08822
Epoch 29, Val Loss: 2.08795
Epoch 30, Val Loss: 2.06564
Epoch 31, Val Loss: 2.09048
Epoch 32, Val Loss: 2.09571
Epoch 33, Val Loss: 2.08506
Epoch 34, Val Loss: 2.10365
Epoch 35, Val Loss: 2.09664
Epoch 36, Val Loss: 2.09238
Epoch 37, Val Loss: 2.07863
Epoch 38, Val Loss: 2.07416
Epoch 39, Val Loss: 2.07680
Epoch 40, Val Loss: 2.07225
Epoch 41, Val Loss: 2.12095
Epoch 42, Val Loss: 2.07022
Epoch 43, Val Loss: 2.07544
Epoch 44, Val Loss: 2.06529
Epoch 45, Val Loss: 2.06298
Epoch 46, Val Loss: 2.07538
Epoch 47, Val Loss: 2.07289
Epoch 48, Val Loss: 2.09847
Epoch 49, Val Loss: 2.08648
Epoch 50, Val Loss: 2.09673
Epoch 51, Val Loss: 2.06781
Epoch 52, Val Loss: 2.06208
Epoch 53, Val Loss: 2.08113
Epoch 54, Val Loss: 2.07175
Epoch 55, Val Loss: 2.06424
Epoch 56, Val Loss: 2.07017
Epoch 57, Val Loss: 2.07439
Epoch 58, Val Loss: 2.05961
Epoch 59, Val Loss: 2.07835
Epoch 60, Val Loss: 2.08434
Epoch 61, Val Loss: 2.06399
Epoch 62, Val Loss: 2.07110
Epoch 63, Val Loss: 2.10093
Epoch 64, Val Loss: 2.07696
Epoch 65, Val Loss: 2.06005
Epoch 66, Val Loss: 2.06889
Epoch 67, Val Loss: 2.07509
Epoch 68, Val Loss: 2.07277
Epoch 69, Val Loss: 2.06038
Epoch 70, Val Loss: 2.06277
Epoch 71, Val Loss: 2.06174
Epoch 72, Val Loss: 2.07512
Epoch 73, Val Loss: 2.07329
Epoch 74, Val Loss: 2.06628
Epoch 75, Val Loss: 2.06419
Epoch 76, Val Loss: 2.07196
Epoch 77, Val Loss: 2.06710
Epoch 78, Val Loss: 2.06009
Epoch 79, Val Loss: 2.06905
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2987, 'Log Loss - std': 0.13353159426392944} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}
Fitted encoder
Epoch 0, Val Loss: 2.09418
Epoch 1, Val Loss: 2.06609
Epoch 2, Val Loss: 2.08000
Epoch 3, Val Loss: 2.06203
Epoch 4, Val Loss: 2.05913
Epoch 5, Val Loss: 2.07294
Epoch 6, Val Loss: 2.06284
Epoch 7, Val Loss: 2.05897
Epoch 8, Val Loss: 2.06831
Epoch 9, Val Loss: 2.09538
Epoch 10, Val Loss: 2.06621
Epoch 11, Val Loss: 2.06061
Epoch 12, Val Loss: 2.05703
Epoch 13, Val Loss: 2.11396
Epoch 14, Val Loss: 2.07017
Epoch 15, Val Loss: 2.05802
Epoch 16, Val Loss: 2.08395
Epoch 17, Val Loss: 2.05440
Epoch 18, Val Loss: 2.05053
Epoch 19, Val Loss: 2.03979
Epoch 20, Val Loss: 2.04036
Epoch 21, Val Loss: 2.05775
Epoch 22, Val Loss: 2.12361
Epoch 23, Val Loss: 2.05050
Epoch 24, Val Loss: 2.04683
Epoch 25, Val Loss: 2.03350
Epoch 26, Val Loss: 2.03538
Epoch 27, Val Loss: 2.04165
Epoch 28, Val Loss: 2.07162
Epoch 29, Val Loss: 2.03382
Epoch 30, Val Loss: 2.02500
Epoch 31, Val Loss: 2.03260
Epoch 32, Val Loss: 2.04597
Epoch 33, Val Loss: 2.01946
Epoch 34, Val Loss: 2.01201
Epoch 35, Val Loss: 2.02335
Epoch 36, Val Loss: 2.01970
Epoch 37, Val Loss: 2.02440
Epoch 38, Val Loss: 2.02511
Epoch 39, Val Loss: 2.03736
Epoch 40, Val Loss: 2.02166
Epoch 41, Val Loss: 2.03082
Epoch 42, Val Loss: 2.02424
Epoch 43, Val Loss: 2.05931
Epoch 44, Val Loss: 2.03816
Epoch 45, Val Loss: 2.02260
Epoch 46, Val Loss: 2.03010
Epoch 47, Val Loss: 2.01974
Epoch 48, Val Loss: 2.02047
Epoch 49, Val Loss: 2.01926
Epoch 50, Val Loss: 2.01438
Epoch 51, Val Loss: 2.00076
Epoch 52, Val Loss: 2.00548
Epoch 53, Val Loss: 2.04121
Epoch 54, Val Loss: 2.05728
Epoch 55, Val Loss: 2.01658
Epoch 56, Val Loss: 2.00848
Epoch 57, Val Loss: 2.02975
Epoch 58, Val Loss: 2.02055
Epoch 59, Val Loss: 2.03232
Epoch 60, Val Loss: 2.03624
Epoch 61, Val Loss: 2.01777
Epoch 62, Val Loss: 2.01221
Epoch 63, Val Loss: 2.01459
Epoch 64, Val Loss: 2.05706
Epoch 65, Val Loss: 2.03672
Epoch 66, Val Loss: 2.01542
Epoch 67, Val Loss: 2.00741
Epoch 68, Val Loss: 2.01842
Epoch 69, Val Loss: 2.03126
Epoch 70, Val Loss: 2.08965
Epoch 71, Val Loss: 2.09576
Epoch 72, Val Loss: 2.01509
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.268475, 'Log Loss - std': 0.1269396190123478} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}
Fitted encoder
Epoch 0, Val Loss: 1.95787
Epoch 1, Val Loss: 2.06529
Epoch 2, Val Loss: 2.03920
Epoch 3, Val Loss: 2.03853
Epoch 4, Val Loss: 1.93471
Epoch 5, Val Loss: 1.92508
Epoch 6, Val Loss: 1.94699
Epoch 7, Val Loss: 1.92157
Epoch 8, Val Loss: 1.93438
Epoch 9, Val Loss: 1.91175
Epoch 10, Val Loss: 1.93720
Epoch 11, Val Loss: 1.94520
Epoch 12, Val Loss: 1.91329
Epoch 13, Val Loss: 1.93828
Epoch 14, Val Loss: 1.95250
Epoch 15, Val Loss: 1.93984
Epoch 16, Val Loss: 1.93382
Epoch 17, Val Loss: 1.92879
Epoch 18, Val Loss: 1.92235
Epoch 19, Val Loss: 1.93119
Epoch 20, Val Loss: 1.91698
Epoch 21, Val Loss: 1.90725
Epoch 22, Val Loss: 1.91355
Epoch 23, Val Loss: 1.90478
Epoch 24, Val Loss: 1.93012
Epoch 25, Val Loss: 1.90835
Epoch 26, Val Loss: 1.94567
Epoch 27, Val Loss: 1.91320
Epoch 28, Val Loss: 1.89621
Epoch 29, Val Loss: 1.90385
Epoch 30, Val Loss: 1.98311
Epoch 31, Val Loss: 1.90709
Epoch 32, Val Loss: 1.91909
Epoch 33, Val Loss: 1.98129
Epoch 34, Val Loss: 1.89654
Epoch 35, Val Loss: 1.91891
Epoch 36, Val Loss: 1.89452
Epoch 37, Val Loss: 1.88869
Epoch 38, Val Loss: 1.91915
Epoch 39, Val Loss: 1.89885
Epoch 40, Val Loss: 1.90058
Epoch 41, Val Loss: 1.92438
Epoch 42, Val Loss: 1.90261
Epoch 43, Val Loss: 1.89962
Epoch 44, Val Loss: 1.89269
Epoch 45, Val Loss: 1.91917
Epoch 46, Val Loss: 1.91301
Epoch 47, Val Loss: 1.91641
Epoch 48, Val Loss: 1.89678
Epoch 49, Val Loss: 1.90452
Epoch 50, Val Loss: 1.89622
Epoch 51, Val Loss: 1.87867
Epoch 52, Val Loss: 1.91370
Epoch 53, Val Loss: 1.90850
Epoch 54, Val Loss: 1.90496
Epoch 55, Val Loss: 1.91054
Epoch 56, Val Loss: 1.87972
Epoch 57, Val Loss: 1.90916
Epoch 58, Val Loss: 1.92440
Epoch 59, Val Loss: 1.88597
Epoch 60, Val Loss: 1.89424
Epoch 61, Val Loss: 1.88269
Epoch 62, Val Loss: 1.88605
Epoch 63, Val Loss: 1.88591
Epoch 64, Val Loss: 1.94424
Epoch 65, Val Loss: 1.88063
Epoch 66, Val Loss: 1.90854
Epoch 67, Val Loss: 1.89348
Epoch 68, Val Loss: 1.88673
Epoch 69, Val Loss: 1.89313
Epoch 70, Val Loss: 1.88051
Epoch 71, Val Loss: 1.89612
Epoch 72, Val Loss: 1.87559
Epoch 73, Val Loss: 1.90961
Epoch 74, Val Loss: 1.87708
Epoch 75, Val Loss: 1.87356
Epoch 76, Val Loss: 1.90283
Epoch 77, Val Loss: 1.87837
Epoch 78, Val Loss: 1.88423
Epoch 79, Val Loss: 1.89502
Epoch 80, Val Loss: 1.88136
Epoch 81, Val Loss: 1.88949
Epoch 82, Val Loss: 1.89818
Epoch 83, Val Loss: 1.88292
Epoch 84, Val Loss: 1.89634
Epoch 85, Val Loss: 1.88315
Epoch 86, Val Loss: 1.90134
Epoch 87, Val Loss: 1.87891
Epoch 88, Val Loss: 1.90340
Epoch 89, Val Loss: 1.90094
Epoch 90, Val Loss: 1.88369
Epoch 91, Val Loss: 1.94164
Epoch 92, Val Loss: 1.91888
Epoch 93, Val Loss: 1.89665
Epoch 94, Val Loss: 1.88906
Epoch 95, Val Loss: 1.88208
Epoch 96, Val Loss: 1.88484
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.3334, 'Log Loss - std': 0.17248755317413492} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 10 finished with value: 3.3334 and parameters: {'p_m': 0.8486070392780803, 'alpha': 6.664520903332803, 'K': 5, 'beta': 5.083790195403291}. Best is trial 10 with value: 3.3334.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}
Fitted encoder
Epoch 0, Val Loss: 2.14255
Epoch 1, Val Loss: 2.16485
Epoch 2, Val Loss: 2.13145
Epoch 3, Val Loss: 2.12073
Epoch 4, Val Loss: 2.11512
Epoch 5, Val Loss: 2.14808
Epoch 6, Val Loss: 2.11426
Epoch 7, Val Loss: 2.15311
Epoch 8, Val Loss: 2.11877
Epoch 9, Val Loss: 2.09549
Epoch 10, Val Loss: 2.12448
Epoch 11, Val Loss: 2.12250
Epoch 12, Val Loss: 2.13480
Epoch 13, Val Loss: 2.09164
Epoch 14, Val Loss: 2.15130
Epoch 15, Val Loss: 2.11715
Epoch 16, Val Loss: 2.09222
Epoch 17, Val Loss: 2.09323
Epoch 18, Val Loss: 2.14645
Epoch 19, Val Loss: 2.13949
Epoch 20, Val Loss: 2.17801
Epoch 21, Val Loss: 2.11792
Epoch 22, Val Loss: 2.12035
Epoch 23, Val Loss: 2.10864
Epoch 24, Val Loss: 2.11952
Epoch 25, Val Loss: 2.10965
Epoch 26, Val Loss: 2.09993
Epoch 27, Val Loss: 2.10391
Epoch 28, Val Loss: 2.14785
Epoch 29, Val Loss: 2.14817
Epoch 30, Val Loss: 2.12437
Epoch 31, Val Loss: 2.09742
Epoch 32, Val Loss: 2.11478
Epoch 33, Val Loss: 2.14286
Epoch 34, Val Loss: 2.13960
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.6754, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}
Fitted encoder
Epoch 0, Val Loss: 1.98048
Epoch 1, Val Loss: 1.97270
Epoch 2, Val Loss: 1.98806
Epoch 3, Val Loss: 1.95653
Epoch 4, Val Loss: 1.95668
Epoch 5, Val Loss: 1.94844
Epoch 6, Val Loss: 1.96643
Epoch 7, Val Loss: 1.95100
Epoch 8, Val Loss: 1.94763
Epoch 9, Val Loss: 1.97047
Epoch 10, Val Loss: 1.95422
Epoch 11, Val Loss: 1.95038
Epoch 12, Val Loss: 1.94369
Epoch 13, Val Loss: 1.95328
Epoch 14, Val Loss: 1.93412
Epoch 15, Val Loss: 1.94995
Epoch 16, Val Loss: 1.93122
Epoch 17, Val Loss: 1.91754
Epoch 18, Val Loss: 1.96212
Epoch 19, Val Loss: 1.94607
Epoch 20, Val Loss: 1.95478
Epoch 21, Val Loss: 1.93935
Epoch 22, Val Loss: 1.92081
Epoch 23, Val Loss: 2.02776
Epoch 24, Val Loss: 1.96024
Epoch 25, Val Loss: 1.93697
Epoch 26, Val Loss: 1.92996
Epoch 27, Val Loss: 1.91645
Epoch 28, Val Loss: 1.92644
Epoch 29, Val Loss: 1.94131
Epoch 30, Val Loss: 1.92216
Epoch 31, Val Loss: 1.94840
Epoch 32, Val Loss: 1.95906
Epoch 33, Val Loss: 1.93722
Epoch 34, Val Loss: 1.91374
Epoch 35, Val Loss: 1.92539
Epoch 36, Val Loss: 1.90745
Epoch 37, Val Loss: 1.89989
Epoch 38, Val Loss: 1.91286
Epoch 39, Val Loss: 1.92587
Epoch 40, Val Loss: 1.93081
Epoch 41, Val Loss: 1.94310
Epoch 42, Val Loss: 1.92794
Epoch 43, Val Loss: 1.91233
Epoch 44, Val Loss: 1.93509
Epoch 45, Val Loss: 1.92924
Epoch 46, Val Loss: 1.90426
Epoch 47, Val Loss: 1.90949
Epoch 48, Val Loss: 1.89363
Epoch 49, Val Loss: 1.91126
Epoch 50, Val Loss: 1.89234
Epoch 51, Val Loss: 1.91358
Epoch 52, Val Loss: 1.92317
Epoch 53, Val Loss: 1.90204
Epoch 54, Val Loss: 1.92703
Epoch 55, Val Loss: 1.91041
Epoch 56, Val Loss: 1.90757
Epoch 57, Val Loss: 1.90493
Epoch 58, Val Loss: 1.90985
Epoch 59, Val Loss: 1.91877
Epoch 60, Val Loss: 1.91181
Epoch 61, Val Loss: 1.92546
Epoch 62, Val Loss: 1.92544
Epoch 63, Val Loss: 1.91430
Epoch 64, Val Loss: 1.91967
Epoch 65, Val Loss: 1.89736
Epoch 66, Val Loss: 1.91272
Epoch 67, Val Loss: 1.92105
Epoch 68, Val Loss: 1.91763
Epoch 69, Val Loss: 1.90193
Epoch 70, Val Loss: 1.90294
Epoch 71, Val Loss: 1.92886
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.26355, 'Log Loss - std': 0.5881500000000002} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}
Fitted encoder
Epoch 0, Val Loss: 2.12882
Epoch 1, Val Loss: 2.08758
Epoch 2, Val Loss: 2.10574
Epoch 3, Val Loss: 2.08581
Epoch 4, Val Loss: 2.09798
Epoch 5, Val Loss: 2.10036
Epoch 6, Val Loss: 2.10246
Epoch 7, Val Loss: 2.11949
Epoch 8, Val Loss: 2.07380
Epoch 9, Val Loss: 2.07411
Epoch 10, Val Loss: 2.15148
Epoch 11, Val Loss: 2.11128
Epoch 12, Val Loss: 2.11386
Epoch 13, Val Loss: 2.09436
Epoch 14, Val Loss: 2.09320
Epoch 15, Val Loss: 2.08291
Epoch 16, Val Loss: 2.10680
Epoch 17, Val Loss: 2.09435
Epoch 18, Val Loss: 2.12557
Epoch 19, Val Loss: 2.08663
Epoch 20, Val Loss: 2.08803
Epoch 21, Val Loss: 2.08350
Epoch 22, Val Loss: 2.13725
Epoch 23, Val Loss: 2.10381
Epoch 24, Val Loss: 2.10509
Epoch 25, Val Loss: 2.08376
Epoch 26, Val Loss: 2.08996
Epoch 27, Val Loss: 2.07780
Epoch 28, Val Loss: 2.06309
Epoch 29, Val Loss: 2.04917
Epoch 30, Val Loss: 2.08284
Epoch 31, Val Loss: 2.07361
Epoch 32, Val Loss: 2.05926
Epoch 33, Val Loss: 2.06743
Epoch 34, Val Loss: 2.10158
Epoch 35, Val Loss: 2.11125
Epoch 36, Val Loss: 2.09367
Epoch 37, Val Loss: 2.09713
Epoch 38, Val Loss: 2.09399
Epoch 39, Val Loss: 2.08351
Epoch 40, Val Loss: 2.08215
Epoch 41, Val Loss: 2.07384
Epoch 42, Val Loss: 2.07793
Epoch 43, Val Loss: 2.08337
Epoch 44, Val Loss: 2.09077
Epoch 45, Val Loss: 2.07825
Epoch 46, Val Loss: 2.07816
Epoch 47, Val Loss: 2.12110
Epoch 48, Val Loss: 2.06908
Epoch 49, Val Loss: 2.06993
Epoch 50, Val Loss: 2.07756
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2711333333333332, 'Log Loss - std': 0.480342199779375} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}
Fitted encoder
Epoch 0, Val Loss: 2.09581
Epoch 1, Val Loss: 2.05869
Epoch 2, Val Loss: 2.07140
Epoch 3, Val Loss: 2.03811
Epoch 4, Val Loss: 2.07356
Epoch 5, Val Loss: 2.06151
Epoch 6, Val Loss: 2.02998
Epoch 7, Val Loss: 2.07209
Epoch 8, Val Loss: 2.05921
Epoch 9, Val Loss: 2.06138
Epoch 10, Val Loss: 2.12317
Epoch 11, Val Loss: 2.13241
Epoch 12, Val Loss: 2.15737
Epoch 13, Val Loss: 2.15590
Epoch 14, Val Loss: 2.15705
Epoch 15, Val Loss: 2.15514
Epoch 16, Val Loss: 2.15217
Epoch 17, Val Loss: 2.10875
Epoch 18, Val Loss: 2.08999
Epoch 19, Val Loss: 2.02453
Epoch 20, Val Loss: 2.03892
Epoch 21, Val Loss: 2.03946
Epoch 22, Val Loss: 2.03769
Epoch 23, Val Loss: 2.01916
Epoch 24, Val Loss: 2.04317
Epoch 25, Val Loss: 2.01371
Epoch 26, Val Loss: 1.99405
Epoch 27, Val Loss: 2.03367
Epoch 28, Val Loss: 2.10895
Epoch 29, Val Loss: 2.07994
Epoch 30, Val Loss: 2.08091
Epoch 31, Val Loss: 2.08121
Epoch 32, Val Loss: 2.04292
Epoch 33, Val Loss: 2.02763
Epoch 34, Val Loss: 2.08490
Epoch 35, Val Loss: 2.01040
Epoch 36, Val Loss: 2.02444
Epoch 37, Val Loss: 2.02848
Epoch 38, Val Loss: 2.05588
Epoch 39, Val Loss: 2.02686
Epoch 40, Val Loss: 2.02473
Epoch 41, Val Loss: 2.01134
Epoch 42, Val Loss: 2.03501
Epoch 43, Val Loss: 2.01664
Epoch 44, Val Loss: 2.01472
Epoch 45, Val Loss: 2.03547
Epoch 46, Val Loss: 2.06456
Epoch 47, Val Loss: 2.00964
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2742999999999998, 'Log Loss - std': 0.4160247047952803} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}
Fitted encoder
Epoch 0, Val Loss: 1.98780
Epoch 1, Val Loss: 1.96885
Epoch 2, Val Loss: 1.94644
Epoch 3, Val Loss: 1.92782
Epoch 4, Val Loss: 1.91213
Epoch 5, Val Loss: 1.94631
Epoch 6, Val Loss: 1.93363
Epoch 7, Val Loss: 1.92528
Epoch 8, Val Loss: 1.92244
Epoch 9, Val Loss: 1.91666
Epoch 10, Val Loss: 1.88976
Epoch 11, Val Loss: 1.91262
Epoch 12, Val Loss: 1.89508
Epoch 13, Val Loss: 1.91984
Epoch 14, Val Loss: 1.90097
Epoch 15, Val Loss: 1.91295
Epoch 16, Val Loss: 1.89810
Epoch 17, Val Loss: 1.91508
Epoch 18, Val Loss: 1.91220
Epoch 19, Val Loss: 1.88719
Epoch 20, Val Loss: 1.93591
Epoch 21, Val Loss: 1.87960
Epoch 22, Val Loss: 1.92065
Epoch 23, Val Loss: 1.88137
Epoch 24, Val Loss: 1.91425
Epoch 25, Val Loss: 1.89222
Epoch 26, Val Loss: 1.88941
Epoch 27, Val Loss: 1.91038
Epoch 28, Val Loss: 1.90755
Epoch 29, Val Loss: 1.88639
Epoch 30, Val Loss: 1.92892
Epoch 31, Val Loss: 1.90497
Epoch 32, Val Loss: 1.89727
Epoch 33, Val Loss: 1.88917
Epoch 34, Val Loss: 1.89527
Epoch 35, Val Loss: 1.89001
Epoch 36, Val Loss: 1.89347
Epoch 37, Val Loss: 1.88818
Epoch 38, Val Loss: 1.87597
Epoch 39, Val Loss: 1.89163
Epoch 40, Val Loss: 1.89694
Epoch 41, Val Loss: 1.87972
Epoch 42, Val Loss: 1.87472
Epoch 43, Val Loss: 1.90079
Epoch 44, Val Loss: 1.91163
Epoch 45, Val Loss: 1.87502
Epoch 46, Val Loss: 1.90026
Epoch 47, Val Loss: 1.90196
Epoch 48, Val Loss: 1.88457
Epoch 49, Val Loss: 1.88632
Epoch 50, Val Loss: 1.91878
Epoch 51, Val Loss: 1.88637
Epoch 52, Val Loss: 1.87833
Epoch 53, Val Loss: 1.90113
Epoch 54, Val Loss: 1.87742
Epoch 55, Val Loss: 1.88954
Epoch 56, Val Loss: 1.88291
Epoch 57, Val Loss: 1.89518
Epoch 58, Val Loss: 1.92362
Epoch 59, Val Loss: 1.90462
Epoch 60, Val Loss: 1.89749
Epoch 61, Val Loss: 1.87941
Epoch 62, Val Loss: 1.89278
Epoch 63, Val Loss: 1.90570
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.2504999999999997, 'Log Loss - std': 0.3751359806790067} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 11 finished with value: 3.2504999999999997 and parameters: {'p_m': 0.8756858975627569, 'alpha': 6.894131114192356, 'K': 3, 'beta': 5.087717126147876}. Best is trial 10 with value: 3.3334.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}
Fitted encoder
Epoch 0, Val Loss: 2.17397
Epoch 1, Val Loss: 2.11370
Epoch 2, Val Loss: 2.10236
Epoch 3, Val Loss: 2.10184
Epoch 4, Val Loss: 2.09556
Epoch 5, Val Loss: 2.09228
Epoch 6, Val Loss: 2.10683
Epoch 7, Val Loss: 2.09698
Epoch 8, Val Loss: 2.09411
Epoch 9, Val Loss: 2.13415
Epoch 10, Val Loss: 2.11075
Epoch 11, Val Loss: 2.05443
Epoch 12, Val Loss: 2.10720
Epoch 13, Val Loss: 2.08189
Epoch 14, Val Loss: 2.09255
Epoch 15, Val Loss: 2.10148
Epoch 16, Val Loss: 2.06939
Epoch 17, Val Loss: 2.09977
Epoch 18, Val Loss: 2.10360
Epoch 19, Val Loss: 2.06413
Epoch 20, Val Loss: 2.09197
Epoch 21, Val Loss: 2.07997
Epoch 22, Val Loss: 2.06526
Epoch 23, Val Loss: 2.06324
Epoch 24, Val Loss: 2.08795
Epoch 25, Val Loss: 2.08115
Epoch 26, Val Loss: 2.08917
Epoch 27, Val Loss: 2.04716
Epoch 28, Val Loss: 2.04988
Epoch 29, Val Loss: 2.06336
Epoch 30, Val Loss: 2.08656
Epoch 31, Val Loss: 2.06932
Epoch 32, Val Loss: 2.04201
Epoch 33, Val Loss: 2.16080
Epoch 34, Val Loss: 2.14584
Epoch 35, Val Loss: 2.10055
Epoch 36, Val Loss: 2.08301
Epoch 37, Val Loss: 2.05063
Epoch 38, Val Loss: 2.04557
Epoch 39, Val Loss: 2.03304
Epoch 40, Val Loss: 2.05050
Epoch 41, Val Loss: 2.04172
Epoch 42, Val Loss: 2.04413
Epoch 43, Val Loss: 2.05226
Epoch 44, Val Loss: 2.07048
Epoch 45, Val Loss: 2.08126
Epoch 46, Val Loss: 2.08132
Epoch 47, Val Loss: 2.08564
Epoch 48, Val Loss: 2.07296
Epoch 49, Val Loss: 2.04687
Epoch 50, Val Loss: 2.06835
Epoch 51, Val Loss: 2.05725
Epoch 52, Val Loss: 2.02556
Epoch 53, Val Loss: 2.03785
Epoch 54, Val Loss: 2.05303
Epoch 55, Val Loss: 2.03738
Epoch 56, Val Loss: 2.04859
Epoch 57, Val Loss: 2.03476
Epoch 58, Val Loss: 2.04379
Epoch 59, Val Loss: 2.04703
Epoch 60, Val Loss: 2.03942
Epoch 61, Val Loss: 2.04445
Epoch 62, Val Loss: 2.05821
Epoch 63, Val Loss: 2.06255
Epoch 64, Val Loss: 2.03446
Epoch 65, Val Loss: 2.03018
Epoch 66, Val Loss: 2.03348
Epoch 67, Val Loss: 2.04471
Epoch 68, Val Loss: 2.04110
Epoch 69, Val Loss: 2.03474
Epoch 70, Val Loss: 2.14215
Epoch 71, Val Loss: 2.09680
Epoch 72, Val Loss: 2.10603
Epoch 73, Val Loss: 2.10421
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3791, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}
Fitted encoder
Epoch 0, Val Loss: 1.95219
Epoch 1, Val Loss: 1.94854
Epoch 2, Val Loss: 1.96484
Epoch 3, Val Loss: 1.95806
Epoch 4, Val Loss: 1.96604
Epoch 5, Val Loss: 1.96528
Epoch 6, Val Loss: 1.96654
Epoch 7, Val Loss: 1.95590
Epoch 8, Val Loss: 1.96924
Epoch 9, Val Loss: 1.95040
Epoch 10, Val Loss: 1.93332
Epoch 11, Val Loss: 1.99712
Epoch 12, Val Loss: 1.94206
Epoch 13, Val Loss: 1.94200
Epoch 14, Val Loss: 1.92532
Epoch 15, Val Loss: 1.92278
Epoch 16, Val Loss: 1.93638
Epoch 17, Val Loss: 1.92485
Epoch 18, Val Loss: 1.92369
Epoch 19, Val Loss: 1.94442
Epoch 20, Val Loss: 1.91978
Epoch 21, Val Loss: 1.94074
Epoch 22, Val Loss: 1.92559
Epoch 23, Val Loss: 1.91068
Epoch 24, Val Loss: 1.91942
Epoch 25, Val Loss: 1.93292
Epoch 26, Val Loss: 1.91230
Epoch 27, Val Loss: 1.92571
Epoch 28, Val Loss: 1.92732
Epoch 29, Val Loss: 1.92749
Epoch 30, Val Loss: 1.93372
Epoch 31, Val Loss: 1.90940
Epoch 32, Val Loss: 1.92822
Epoch 33, Val Loss: 1.91239
Epoch 34, Val Loss: 1.90403
Epoch 35, Val Loss: 1.92130
Epoch 36, Val Loss: 1.92957
Epoch 37, Val Loss: 1.93301
Epoch 38, Val Loss: 1.91617
Epoch 39, Val Loss: 1.90637
Epoch 40, Val Loss: 1.90813
Epoch 41, Val Loss: 1.94531
Epoch 42, Val Loss: 1.93277
Epoch 43, Val Loss: 1.91661
Epoch 44, Val Loss: 1.91920
Epoch 45, Val Loss: 1.91055
Epoch 46, Val Loss: 1.92502
Epoch 47, Val Loss: 1.90874
Epoch 48, Val Loss: 1.95180
Epoch 49, Val Loss: 1.92309
Epoch 50, Val Loss: 1.90806
Epoch 51, Val Loss: 1.91957
Epoch 52, Val Loss: 1.90978
Epoch 53, Val Loss: 1.89718
Epoch 54, Val Loss: 1.90601
Epoch 55, Val Loss: 1.91201
Epoch 56, Val Loss: 1.91872
Epoch 57, Val Loss: 1.89061
Epoch 58, Val Loss: 1.91170
Epoch 59, Val Loss: 1.91076
Epoch 60, Val Loss: 1.92899
Epoch 61, Val Loss: 1.93005
Epoch 62, Val Loss: 1.92428
Epoch 63, Val Loss: 1.93182
Epoch 64, Val Loss: 1.89945
Epoch 65, Val Loss: 1.94827
Epoch 66, Val Loss: 1.90965
Epoch 67, Val Loss: 1.91550
Epoch 68, Val Loss: 1.93133
Epoch 69, Val Loss: 1.92769
Epoch 70, Val Loss: 1.92027
Epoch 71, Val Loss: 1.92283
Epoch 72, Val Loss: 1.92614
Epoch 73, Val Loss: 1.90693
Epoch 74, Val Loss: 1.90934
Epoch 75, Val Loss: 1.90088
Epoch 76, Val Loss: 1.91396
Epoch 77, Val Loss: 1.89817
Epoch 78, Val Loss: 1.90785
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.5816, 'Log Loss - std': 0.2024999999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}
Fitted encoder
Epoch 0, Val Loss: 2.14863
Epoch 1, Val Loss: 2.13042
Epoch 2, Val Loss: 2.12401
Epoch 3, Val Loss: 2.08977
Epoch 4, Val Loss: 2.07570
Epoch 5, Val Loss: 2.07430
Epoch 6, Val Loss: 2.07879
Epoch 7, Val Loss: 2.09704
Epoch 8, Val Loss: 2.11649
Epoch 9, Val Loss: 2.08047
Epoch 10, Val Loss: 2.08177
Epoch 11, Val Loss: 2.07810
Epoch 12, Val Loss: 2.06904
Epoch 13, Val Loss: 2.04812
Epoch 14, Val Loss: 2.05057
Epoch 15, Val Loss: 2.06740
Epoch 16, Val Loss: 2.02422
Epoch 17, Val Loss: 2.03769
Epoch 18, Val Loss: 2.05200
Epoch 19, Val Loss: 2.02866
Epoch 20, Val Loss: 2.06531
Epoch 21, Val Loss: 2.02911
Epoch 22, Val Loss: 2.01936
Epoch 23, Val Loss: 2.03373
Epoch 24, Val Loss: 2.03072
Epoch 25, Val Loss: 2.02687
Epoch 26, Val Loss: 2.03705
Epoch 27, Val Loss: 2.03791
Epoch 28, Val Loss: 2.02258
Epoch 29, Val Loss: 2.04137
Epoch 30, Val Loss: 2.05489
Epoch 31, Val Loss: 2.02855
Epoch 32, Val Loss: 2.03174
Epoch 33, Val Loss: 2.03723
Epoch 34, Val Loss: 2.03504
Epoch 35, Val Loss: 2.03264
Epoch 36, Val Loss: 2.02934
Epoch 37, Val Loss: 2.02748
Epoch 38, Val Loss: 2.01908
Epoch 39, Val Loss: 2.02585
Epoch 40, Val Loss: 2.02543
Epoch 41, Val Loss: 2.04056
Epoch 42, Val Loss: 2.04401
Epoch 43, Val Loss: 2.03690
Epoch 44, Val Loss: 2.03328
Epoch 45, Val Loss: 2.02875
Epoch 46, Val Loss: 2.02295
Epoch 47, Val Loss: 2.03663
Epoch 48, Val Loss: 2.03615
Epoch 49, Val Loss: 2.03017
Epoch 50, Val Loss: 2.03318
Epoch 51, Val Loss: 2.04881
Epoch 52, Val Loss: 2.02339
Epoch 53, Val Loss: 2.02930
Epoch 54, Val Loss: 2.03029
Epoch 55, Val Loss: 2.05281
Epoch 56, Val Loss: 2.02952
Epoch 57, Val Loss: 2.03436
Epoch 58, Val Loss: 2.02311
Epoch 59, Val Loss: 2.03891
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.5711999999999997, 'Log Loss - std': 0.16599343360506758} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}
Fitted encoder
Epoch 0, Val Loss: 2.08327
Epoch 1, Val Loss: 2.06797
Epoch 2, Val Loss: 2.12745
Epoch 3, Val Loss: 2.12075
Epoch 4, Val Loss: 2.11364
Epoch 5, Val Loss: 2.11233
Epoch 6, Val Loss: 2.05376
Epoch 7, Val Loss: 2.06976
Epoch 8, Val Loss: 2.07113
Epoch 9, Val Loss: 2.07097
Epoch 10, Val Loss: 2.09137
Epoch 11, Val Loss: 2.07322
Epoch 12, Val Loss: 2.06709
Epoch 13, Val Loss: 2.05769
Epoch 14, Val Loss: 2.07105
Epoch 15, Val Loss: 2.06073
Epoch 16, Val Loss: 2.06043
Epoch 17, Val Loss: 2.06728
Epoch 18, Val Loss: 2.06302
Epoch 19, Val Loss: 2.04913
Epoch 20, Val Loss: 2.05826
Epoch 21, Val Loss: 2.07187
Epoch 22, Val Loss: 2.04813
Epoch 23, Val Loss: 2.11249
Epoch 24, Val Loss: 2.03711
Epoch 25, Val Loss: 2.07688
Epoch 26, Val Loss: 2.06083
Epoch 27, Val Loss: 2.04126
Epoch 28, Val Loss: 2.07141
Epoch 29, Val Loss: 2.06318
Epoch 30, Val Loss: 2.03471
Epoch 31, Val Loss: 2.06054
Epoch 32, Val Loss: 2.05979
Epoch 33, Val Loss: 2.06345
Epoch 34, Val Loss: 2.04525
Epoch 35, Val Loss: 2.04775
Epoch 36, Val Loss: 2.03337
Epoch 37, Val Loss: 2.04433
Epoch 38, Val Loss: 2.04518
Epoch 39, Val Loss: 2.06860
Epoch 40, Val Loss: 2.03081
Epoch 41, Val Loss: 2.04935
Epoch 42, Val Loss: 2.02965
Epoch 43, Val Loss: 2.03393
Epoch 44, Val Loss: 2.05078
Epoch 45, Val Loss: 2.02104
Epoch 46, Val Loss: 2.03183
Epoch 47, Val Loss: 2.07111
Epoch 48, Val Loss: 2.02445
Epoch 49, Val Loss: 2.03042
Epoch 50, Val Loss: 2.02280
Epoch 51, Val Loss: 2.07284
Epoch 52, Val Loss: 2.08022
Epoch 53, Val Loss: 2.05400
Epoch 54, Val Loss: 2.03530
Epoch 55, Val Loss: 2.08447
Epoch 56, Val Loss: 2.02954
Epoch 57, Val Loss: 2.02041
Epoch 58, Val Loss: 2.01978
Epoch 59, Val Loss: 2.03381
Epoch 60, Val Loss: 2.04074
Epoch 61, Val Loss: 2.04119
Epoch 62, Val Loss: 2.02135
Epoch 63, Val Loss: 2.03025
Epoch 64, Val Loss: 2.03219
Epoch 65, Val Loss: 2.04252
Epoch 66, Val Loss: 2.02909
Epoch 67, Val Loss: 2.06104
Epoch 68, Val Loss: 2.02666
Epoch 69, Val Loss: 2.04171
Epoch 70, Val Loss: 2.02733
Epoch 71, Val Loss: 2.02869
Epoch 72, Val Loss: 2.02349
Epoch 73, Val Loss: 2.03697
Epoch 74, Val Loss: 2.03342
Epoch 75, Val Loss: 2.03146
Epoch 76, Val Loss: 2.02358
Epoch 77, Val Loss: 2.02059
Epoch 78, Val Loss: 2.01715
Epoch 79, Val Loss: 2.04117
Epoch 80, Val Loss: 2.02765
Epoch 81, Val Loss: 2.03119
Epoch 82, Val Loss: 2.02080
Epoch 83, Val Loss: 2.03265
Epoch 84, Val Loss: 2.04327
Epoch 85, Val Loss: 2.03086
Epoch 86, Val Loss: 2.03856
Epoch 87, Val Loss: 2.03353
Epoch 88, Val Loss: 2.01833
Epoch 89, Val Loss: 2.02341
Epoch 90, Val Loss: 2.02678
Epoch 91, Val Loss: 2.02520
Epoch 92, Val Loss: 2.03796
Epoch 93, Val Loss: 2.03473
Epoch 94, Val Loss: 2.01256
Epoch 95, Val Loss: 2.02185
Epoch 96, Val Loss: 2.03341
Epoch 97, Val Loss: 2.03395
Epoch 98, Val Loss: 2.02396
Epoch 99, Val Loss: 2.02812
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.4835, 'Log Loss - std': 0.2091392717784012} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}
Fitted encoder
Epoch 0, Val Loss: 1.96593
Epoch 1, Val Loss: 1.96570
Epoch 2, Val Loss: 1.97168
Epoch 3, Val Loss: 1.96165
Epoch 4, Val Loss: 1.96884
Epoch 5, Val Loss: 1.94703
Epoch 6, Val Loss: 1.94890
Epoch 7, Val Loss: 1.92699
Epoch 8, Val Loss: 1.92756
Epoch 9, Val Loss: 1.90801
Epoch 10, Val Loss: 1.93239
Epoch 11, Val Loss: 2.01622
Epoch 12, Val Loss: 1.91644
Epoch 13, Val Loss: 1.91625
Epoch 14, Val Loss: 1.92371
Epoch 15, Val Loss: 1.91935
Epoch 16, Val Loss: 1.91020
Epoch 17, Val Loss: 1.88649
Epoch 18, Val Loss: 1.89524
Epoch 19, Val Loss: 1.91517
Epoch 20, Val Loss: 1.90442
Epoch 21, Val Loss: 1.91780
Epoch 22, Val Loss: 1.90666
Epoch 23, Val Loss: 1.92720
Epoch 24, Val Loss: 1.91060
Epoch 25, Val Loss: 1.89490
Epoch 26, Val Loss: 1.88471
Epoch 27, Val Loss: 1.89169
Epoch 28, Val Loss: 1.89641
Epoch 29, Val Loss: 1.91230
Epoch 30, Val Loss: 1.87429
Epoch 31, Val Loss: 1.88819
Epoch 32, Val Loss: 1.89914
Epoch 33, Val Loss: 1.88809
Epoch 34, Val Loss: 1.87986
Epoch 35, Val Loss: 1.90029
Epoch 36, Val Loss: 1.89159
Epoch 37, Val Loss: 1.89026
Epoch 38, Val Loss: 1.90791
Epoch 39, Val Loss: 1.91096
Epoch 40, Val Loss: 1.89148
Epoch 41, Val Loss: 1.92251
Epoch 42, Val Loss: 1.91564
Epoch 43, Val Loss: 1.90597
Epoch 44, Val Loss: 1.88770
Epoch 45, Val Loss: 1.88184
Epoch 46, Val Loss: 1.92309
Epoch 47, Val Loss: 1.88558
Epoch 48, Val Loss: 1.88749
Epoch 49, Val Loss: 1.89892
Epoch 50, Val Loss: 1.88621
Epoch 51, Val Loss: 1.89048
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.41244, 'Log Loss - std': 0.23492441848390297} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 12 finished with value: 3.41244 and parameters: {'p_m': 0.884054494916382, 'alpha': 4.018992389463433, 'K': 5, 'beta': 3.454270652848612}. Best is trial 12 with value: 3.41244.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}
Fitted encoder
Epoch 0, Val Loss: 2.15133
Epoch 1, Val Loss: 2.09449
Epoch 2, Val Loss: 2.10478
Epoch 3, Val Loss: 2.10775
Epoch 4, Val Loss: 2.10838
Epoch 5, Val Loss: 2.11945
Epoch 6, Val Loss: 2.09820
Epoch 7, Val Loss: 2.12586
Epoch 8, Val Loss: 2.12469
Epoch 9, Val Loss: 2.09417
Epoch 10, Val Loss: 2.09978
Epoch 11, Val Loss: 2.10418
Epoch 12, Val Loss: 2.08050
Epoch 13, Val Loss: 2.07548
Epoch 14, Val Loss: 2.08798
Epoch 15, Val Loss: 2.08158
Epoch 16, Val Loss: 2.08950
Epoch 17, Val Loss: 2.06307
Epoch 18, Val Loss: 2.05985
Epoch 19, Val Loss: 2.15347
Epoch 20, Val Loss: 2.12965
Epoch 21, Val Loss: 2.12861
Epoch 22, Val Loss: 2.13120
Epoch 23, Val Loss: 2.22640
Epoch 24, Val Loss: 2.22640
Epoch 25, Val Loss: 2.22640
Epoch 26, Val Loss: 2.22640
Epoch 27, Val Loss: 2.22640
Epoch 28, Val Loss: 2.22640
Epoch 29, Val Loss: 2.22640
Epoch 30, Val Loss: 2.22640
Epoch 31, Val Loss: 2.22640
Epoch 32, Val Loss: 2.22640
Epoch 33, Val Loss: 2.22640
Epoch 34, Val Loss: 2.22640
Epoch 35, Val Loss: 2.22640
Epoch 36, Val Loss: 2.22640
Epoch 37, Val Loss: 2.22640
Epoch 38, Val Loss: 2.22640
Epoch 39, Val Loss: 2.22640
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.4876, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}
Fitted encoder
Epoch 0, Val Loss: 1.95241
Epoch 1, Val Loss: 1.96424
Epoch 2, Val Loss: 1.94940
Epoch 3, Val Loss: 1.94721
Epoch 4, Val Loss: 2.00582
Epoch 5, Val Loss: 1.96358
Epoch 6, Val Loss: 1.94495
Epoch 7, Val Loss: 1.94980
Epoch 8, Val Loss: 1.93381
Epoch 9, Val Loss: 1.94920
Epoch 10, Val Loss: 1.92618
Epoch 11, Val Loss: 1.95021
Epoch 12, Val Loss: 1.94803
Epoch 13, Val Loss: 1.95465
Epoch 14, Val Loss: 1.95778
Epoch 15, Val Loss: 1.90361
Epoch 16, Val Loss: 1.94516
Epoch 17, Val Loss: 1.99522
Epoch 18, Val Loss: 1.94538
Epoch 19, Val Loss: 1.93487
Epoch 20, Val Loss: 1.92002
Epoch 21, Val Loss: 1.97476
Epoch 22, Val Loss: 1.96030
Epoch 23, Val Loss: 1.99190
Epoch 24, Val Loss: 1.94264
Epoch 25, Val Loss: 1.92325
Epoch 26, Val Loss: 1.91550
Epoch 27, Val Loss: 1.91143
Epoch 28, Val Loss: 1.92929
Epoch 29, Val Loss: 1.91727
Epoch 30, Val Loss: 1.91894
Epoch 31, Val Loss: 1.93792
Epoch 32, Val Loss: 1.92814
Epoch 33, Val Loss: 1.93456
Epoch 34, Val Loss: 1.90791
Epoch 35, Val Loss: 1.91858
Epoch 36, Val Loss: 1.94590
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.2083, 'Log Loss - std': 0.7206999999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}
Fitted encoder
Epoch 0, Val Loss: 2.18412
Epoch 1, Val Loss: 2.22774
Epoch 2, Val Loss: 2.22578
Epoch 3, Val Loss: 2.15777
Epoch 4, Val Loss: 2.10089
Epoch 5, Val Loss: 2.06831
Epoch 6, Val Loss: 2.10396
Epoch 7, Val Loss: 2.11685
Epoch 8, Val Loss: 2.10012
Epoch 9, Val Loss: 2.10691
Epoch 10, Val Loss: 2.10701
Epoch 11, Val Loss: 2.09762
Epoch 12, Val Loss: 2.12511
Epoch 13, Val Loss: 2.10737
Epoch 14, Val Loss: 2.09732
Epoch 15, Val Loss: 2.11116
Epoch 16, Val Loss: 2.09891
Epoch 17, Val Loss: 2.12772
Epoch 18, Val Loss: 2.07919
Epoch 19, Val Loss: 2.12779
Epoch 20, Val Loss: 2.12810
Epoch 21, Val Loss: 2.11605
Epoch 22, Val Loss: 2.11742
Epoch 23, Val Loss: 2.10822
Epoch 24, Val Loss: 2.10335
Epoch 25, Val Loss: 2.07794
Epoch 26, Val Loss: 2.12162
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3195666666666668, 'Log Loss - std': 0.609124674339243} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}
Fitted encoder
Epoch 0, Val Loss: 2.07767
Epoch 1, Val Loss: 2.07500
Epoch 2, Val Loss: 2.06734
Epoch 3, Val Loss: 2.04851
Epoch 4, Val Loss: 2.06995
Epoch 5, Val Loss: 2.06972
Epoch 6, Val Loss: 2.04352
Epoch 7, Val Loss: 2.03715
Epoch 8, Val Loss: 2.05204
Epoch 9, Val Loss: 2.03233
Epoch 10, Val Loss: 2.05460
Epoch 11, Val Loss: 2.03702
Epoch 12, Val Loss: 2.04710
Epoch 13, Val Loss: 2.01195
Epoch 14, Val Loss: 2.01279
Epoch 15, Val Loss: 2.01019
Epoch 16, Val Loss: 2.03686
Epoch 17, Val Loss: 2.02719
Epoch 18, Val Loss: 2.02566
Epoch 19, Val Loss: 2.02070
Epoch 20, Val Loss: 2.02805
Epoch 21, Val Loss: 2.04583
Epoch 22, Val Loss: 2.03576
Epoch 23, Val Loss: 2.05551
Epoch 24, Val Loss: 2.02622
Epoch 25, Val Loss: 2.02551
Epoch 26, Val Loss: 2.01617
Epoch 27, Val Loss: 2.03354
Epoch 28, Val Loss: 2.00997
Epoch 29, Val Loss: 2.03497
Epoch 30, Val Loss: 2.01072
Epoch 31, Val Loss: 2.03037
Epoch 32, Val Loss: 2.01769
Epoch 33, Val Loss: 2.02506
Epoch 34, Val Loss: 2.02927
Epoch 35, Val Loss: 2.02372
Epoch 36, Val Loss: 2.01163
Epoch 37, Val Loss: 2.02326
Epoch 38, Val Loss: 2.03399
Epoch 39, Val Loss: 2.02512
Epoch 40, Val Loss: 2.02351
Epoch 41, Val Loss: 2.02245
Epoch 42, Val Loss: 2.00432
Epoch 43, Val Loss: 2.02066
Epoch 44, Val Loss: 2.04044
Epoch 45, Val Loss: 2.02944
Epoch 46, Val Loss: 2.03329
Epoch 47, Val Loss: 2.03021
Epoch 48, Val Loss: 2.03265
Epoch 49, Val Loss: 2.02729
Epoch 50, Val Loss: 2.01071
Epoch 51, Val Loss: 2.02257
Epoch 52, Val Loss: 2.01215
Epoch 53, Val Loss: 2.04069
Epoch 54, Val Loss: 2.02441
Epoch 55, Val Loss: 2.02221
Epoch 56, Val Loss: 2.02152
Epoch 57, Val Loss: 2.03060
Epoch 58, Val Loss: 2.01227
Epoch 59, Val Loss: 2.03598
Epoch 60, Val Loss: 2.01823
Epoch 61, Val Loss: 2.02093
Epoch 62, Val Loss: 2.01961
Epoch 63, Val Loss: 2.02808
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3274500000000002, 'Log Loss - std': 0.5276941277861636} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}
Fitted encoder
Epoch 0, Val Loss: 1.96960
Epoch 1, Val Loss: 1.95592
Epoch 2, Val Loss: 1.94034
Epoch 3, Val Loss: 1.94982
Epoch 4, Val Loss: 1.95335
Epoch 5, Val Loss: 1.93394
Epoch 6, Val Loss: 1.92834
Epoch 7, Val Loss: 1.97520
Epoch 8, Val Loss: 1.91349
Epoch 9, Val Loss: 1.91486
Epoch 10, Val Loss: 1.91007
Epoch 11, Val Loss: 2.00559
Epoch 12, Val Loss: 2.02653
Epoch 13, Val Loss: 1.92145
Epoch 14, Val Loss: 1.94663
Epoch 15, Val Loss: 1.92241
Epoch 16, Val Loss: 1.90003
Epoch 17, Val Loss: 1.91337
Epoch 18, Val Loss: 1.90655
Epoch 19, Val Loss: 1.90319
Epoch 20, Val Loss: 1.90389
Epoch 21, Val Loss: 1.91135
Epoch 22, Val Loss: 1.90403
Epoch 23, Val Loss: 1.93753
Epoch 24, Val Loss: 1.89240
Epoch 25, Val Loss: 1.91492
Epoch 26, Val Loss: 1.90275
Epoch 27, Val Loss: 1.92883
Epoch 28, Val Loss: 1.88982
Epoch 29, Val Loss: 1.90177
Epoch 30, Val Loss: 1.89513
Epoch 31, Val Loss: 1.90593
Epoch 32, Val Loss: 1.90303
Epoch 33, Val Loss: 1.91633
Epoch 34, Val Loss: 1.90401
Epoch 35, Val Loss: 1.91534
Epoch 36, Val Loss: 1.90588
Epoch 37, Val Loss: 1.90885
Epoch 38, Val Loss: 1.88964
Epoch 39, Val Loss: 1.89494
Epoch 40, Val Loss: 1.88893
Epoch 41, Val Loss: 1.89884
Epoch 42, Val Loss: 1.89298
Epoch 43, Val Loss: 1.90803
Epoch 44, Val Loss: 1.90138
Epoch 45, Val Loss: 1.89103
Epoch 46, Val Loss: 1.90417
Epoch 47, Val Loss: 1.90117
Epoch 48, Val Loss: 1.90085
Epoch 49, Val Loss: 2.01166
Epoch 50, Val Loss: 2.00372
Epoch 51, Val Loss: 2.01380
Epoch 52, Val Loss: 2.01996
Epoch 53, Val Loss: 1.95511
Epoch 54, Val Loss: 1.93886
Epoch 55, Val Loss: 1.96767
Epoch 56, Val Loss: 1.94718
Epoch 57, Val Loss: 1.94200
Epoch 58, Val Loss: 1.92673
Epoch 59, Val Loss: 1.94685
Epoch 60, Val Loss: 1.93815
Epoch 61, Val Loss: 1.89791
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.33818, 'Log Loss - std': 0.4724715923735521} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 13 finished with value: 3.33818 and parameters: {'p_m': 0.8988116306720382, 'alpha': 4.527348790433638, 'K': 5, 'beta': 3.8797585044388727}. Best is trial 12 with value: 3.41244.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}
Fitted encoder
Epoch 0, Val Loss: 2.10534
Epoch 1, Val Loss: 2.11529
Epoch 2, Val Loss: 2.10682
Epoch 3, Val Loss: 2.10135
Epoch 4, Val Loss: 2.11978
Epoch 5, Val Loss: 2.08894
Epoch 6, Val Loss: 2.09897
Epoch 7, Val Loss: 2.11665
Epoch 8, Val Loss: 2.08913
Epoch 9, Val Loss: 2.11993
Epoch 10, Val Loss: 2.10138
Epoch 11, Val Loss: 2.09089
Epoch 12, Val Loss: 2.09613
Epoch 13, Val Loss: 2.09199
Epoch 14, Val Loss: 2.08801
Epoch 15, Val Loss: 2.08842
Epoch 16, Val Loss: 2.09759
Epoch 17, Val Loss: 2.09021
Epoch 18, Val Loss: 2.08335
Epoch 19, Val Loss: 2.08758
Epoch 20, Val Loss: 2.08679
Epoch 21, Val Loss: 2.08213
Epoch 22, Val Loss: 2.07990
Epoch 23, Val Loss: 2.10367
Epoch 24, Val Loss: 2.07892
Epoch 25, Val Loss: 2.08598
Epoch 26, Val Loss: 2.11248
Epoch 27, Val Loss: 2.08005
Epoch 28, Val Loss: 2.07772
Epoch 29, Val Loss: 2.09051
Epoch 30, Val Loss: 2.10379
Epoch 31, Val Loss: 2.12497
Epoch 32, Val Loss: 2.08113
Epoch 33, Val Loss: 2.09627
Epoch 34, Val Loss: 2.08706
Epoch 35, Val Loss: 2.08930
Epoch 36, Val Loss: 2.11917
Epoch 37, Val Loss: 2.08962
Epoch 38, Val Loss: 2.08508
Epoch 39, Val Loss: 2.07775
Epoch 40, Val Loss: 2.09276
Epoch 41, Val Loss: 2.07552
Epoch 42, Val Loss: 2.07160
Epoch 43, Val Loss: 2.07880
Epoch 44, Val Loss: 2.08471
Epoch 45, Val Loss: 2.07484
Epoch 46, Val Loss: 2.07954
Epoch 47, Val Loss: 2.09056
Epoch 48, Val Loss: 2.07604
Epoch 49, Val Loss: 2.07940
Epoch 50, Val Loss: 2.07871
Epoch 51, Val Loss: 2.08853
Epoch 52, Val Loss: 2.08009
Epoch 53, Val Loss: 2.07766
Epoch 54, Val Loss: 2.07610
Epoch 55, Val Loss: 2.07356
Epoch 56, Val Loss: 2.08845
Epoch 57, Val Loss: 2.07197
Epoch 58, Val Loss: 2.09176
Epoch 59, Val Loss: 2.07781
Epoch 60, Val Loss: 2.07102
Epoch 61, Val Loss: 2.10642
Epoch 62, Val Loss: 2.12265
Epoch 63, Val Loss: 2.10403
Epoch 64, Val Loss: 2.06980
Epoch 65, Val Loss: 2.07846
Epoch 66, Val Loss: 2.07626
Epoch 67, Val Loss: 2.09287
Epoch 68, Val Loss: 2.09464
Epoch 69, Val Loss: 2.07834
Epoch 70, Val Loss: 2.07701
Epoch 71, Val Loss: 2.08220
Epoch 72, Val Loss: 2.08961
Epoch 73, Val Loss: 2.07360
Epoch 74, Val Loss: 2.07078
Epoch 75, Val Loss: 2.07333
Epoch 76, Val Loss: 2.07385
Epoch 77, Val Loss: 2.08567
Epoch 78, Val Loss: 2.09290
Epoch 79, Val Loss: 2.06910
Epoch 80, Val Loss: 2.07473
Epoch 81, Val Loss: 2.08541
Epoch 82, Val Loss: 2.06626
Epoch 83, Val Loss: 2.08001
Epoch 84, Val Loss: 2.09407
Epoch 85, Val Loss: 2.06924
Epoch 86, Val Loss: 2.09991
Epoch 87, Val Loss: 2.08868
Epoch 88, Val Loss: 2.08788
Epoch 89, Val Loss: 2.08409
Epoch 90, Val Loss: 2.08197
Epoch 91, Val Loss: 2.06767
Epoch 92, Val Loss: 2.07808
Epoch 93, Val Loss: 2.06875
Epoch 94, Val Loss: 2.07671
Epoch 95, Val Loss: 2.06818
Epoch 96, Val Loss: 2.07673
Epoch 97, Val Loss: 2.06714
Epoch 98, Val Loss: 2.07048
Epoch 99, Val Loss: 2.07701
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.4495, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}
Fitted encoder
Epoch 0, Val Loss: 1.98031
Epoch 1, Val Loss: 1.96034
Epoch 2, Val Loss: 1.96564
Epoch 3, Val Loss: 1.97074
Epoch 4, Val Loss: 1.95619
Epoch 5, Val Loss: 1.94781
Epoch 6, Val Loss: 1.95623
Epoch 7, Val Loss: 1.94729
Epoch 8, Val Loss: 1.94997
Epoch 9, Val Loss: 1.95081
Epoch 10, Val Loss: 1.96570
Epoch 11, Val Loss: 1.94061
Epoch 12, Val Loss: 1.94519
Epoch 13, Val Loss: 1.95048
Epoch 14, Val Loss: 1.94901
Epoch 15, Val Loss: 1.94775
Epoch 16, Val Loss: 1.94694
Epoch 17, Val Loss: 1.94955
Epoch 18, Val Loss: 1.95069
Epoch 19, Val Loss: 1.94751
Epoch 20, Val Loss: 1.94826
Epoch 21, Val Loss: 1.94658
Epoch 22, Val Loss: 1.94498
Epoch 23, Val Loss: 1.94585
Epoch 24, Val Loss: 1.95081
Epoch 25, Val Loss: 1.94825
Epoch 26, Val Loss: 1.94441
Epoch 27, Val Loss: 1.94170
Epoch 28, Val Loss: 1.94661
Epoch 29, Val Loss: 1.95633
Epoch 30, Val Loss: 1.95299
Epoch 31, Val Loss: 1.94341
Epoch 32, Val Loss: 1.95734
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.65185, 'Log Loss - std': 0.20235000000000003} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}
Fitted encoder
Epoch 0, Val Loss: 2.12580
Epoch 1, Val Loss: 2.12853
Epoch 2, Val Loss: 2.13347
Epoch 3, Val Loss: 2.11564
Epoch 4, Val Loss: 2.11585
Epoch 5, Val Loss: 2.09398
Epoch 6, Val Loss: 2.07507
Epoch 7, Val Loss: 2.09322
Epoch 8, Val Loss: 2.08552
Epoch 9, Val Loss: 2.07291
Epoch 10, Val Loss: 2.11837
Epoch 11, Val Loss: 2.09901
Epoch 12, Val Loss: 2.07629
Epoch 13, Val Loss: 2.07072
Epoch 14, Val Loss: 2.07577
Epoch 15, Val Loss: 2.15154
Epoch 16, Val Loss: 2.06541
Epoch 17, Val Loss: 2.04598
Epoch 18, Val Loss: 2.06891
Epoch 19, Val Loss: 2.04760
Epoch 20, Val Loss: 2.08510
Epoch 21, Val Loss: 2.12901
Epoch 22, Val Loss: 2.08380
Epoch 23, Val Loss: 2.05966
Epoch 24, Val Loss: 2.05543
Epoch 25, Val Loss: 2.06034
Epoch 26, Val Loss: 2.06696
Epoch 27, Val Loss: 2.06394
Epoch 28, Val Loss: 2.12309
Epoch 29, Val Loss: 2.06349
Epoch 30, Val Loss: 2.05394
Epoch 31, Val Loss: 2.05049
Epoch 32, Val Loss: 2.05199
Epoch 33, Val Loss: 2.05726
Epoch 34, Val Loss: 2.07611
Epoch 35, Val Loss: 2.06081
Epoch 36, Val Loss: 2.04460
Epoch 37, Val Loss: 2.04916
Epoch 38, Val Loss: 2.04149
Epoch 39, Val Loss: 2.04633
Epoch 40, Val Loss: 2.05758
Epoch 41, Val Loss: 2.04395
Epoch 42, Val Loss: 2.03710
Epoch 43, Val Loss: 2.05663
Epoch 44, Val Loss: 2.03903
Epoch 45, Val Loss: 2.03404
Epoch 46, Val Loss: 2.07390
Epoch 47, Val Loss: 2.05026
Epoch 48, Val Loss: 2.04459
Epoch 49, Val Loss: 2.03168
Epoch 50, Val Loss: 2.05090
Epoch 51, Val Loss: 2.03924
Epoch 52, Val Loss: 2.04759
Epoch 53, Val Loss: 2.04147
Epoch 54, Val Loss: 2.09996
Epoch 55, Val Loss: 2.07056
Epoch 56, Val Loss: 2.06235
Epoch 57, Val Loss: 2.03542
Epoch 58, Val Loss: 2.03074
Epoch 59, Val Loss: 2.03370
Epoch 60, Val Loss: 2.04453
Epoch 61, Val Loss: 2.04433
Epoch 62, Val Loss: 2.06354
Epoch 63, Val Loss: 2.05404
Epoch 64, Val Loss: 2.04819
Epoch 65, Val Loss: 2.03761
Epoch 66, Val Loss: 2.02113
Epoch 67, Val Loss: 2.02921
Epoch 68, Val Loss: 2.03389
Epoch 69, Val Loss: 2.02631
Epoch 70, Val Loss: 2.03523
Epoch 71, Val Loss: 2.04007
Epoch 72, Val Loss: 2.05828
Epoch 73, Val Loss: 2.04112
Epoch 74, Val Loss: 2.02573
Epoch 75, Val Loss: 2.03096
Epoch 76, Val Loss: 2.03279
Epoch 77, Val Loss: 2.03746
Epoch 78, Val Loss: 2.03325
Epoch 79, Val Loss: 2.03291
Epoch 80, Val Loss: 2.03639
Epoch 81, Val Loss: 2.05018
Epoch 82, Val Loss: 2.03159
Epoch 83, Val Loss: 2.06756
Epoch 84, Val Loss: 2.03695
Epoch 85, Val Loss: 2.03845
Epoch 86, Val Loss: 2.02787
Epoch 87, Val Loss: 2.03696
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6843000000000004, 'Log Loss - std': 0.17147308826751795} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}
Fitted encoder
Epoch 0, Val Loss: 2.08265
Epoch 1, Val Loss: 2.08493
Epoch 2, Val Loss: 2.08254
Epoch 3, Val Loss: 2.07144
Epoch 4, Val Loss: 2.06364
Epoch 5, Val Loss: 2.05860
Epoch 6, Val Loss: 2.05444
Epoch 7, Val Loss: 2.05830
Epoch 8, Val Loss: 2.07267
Epoch 9, Val Loss: 2.04862
Epoch 10, Val Loss: 2.06472
Epoch 11, Val Loss: 2.05812
Epoch 12, Val Loss: 2.05432
Epoch 13, Val Loss: 2.04674
Epoch 14, Val Loss: 2.04315
Epoch 15, Val Loss: 2.05853
Epoch 16, Val Loss: 2.06420
Epoch 17, Val Loss: 2.05018
Epoch 18, Val Loss: 2.02915
Epoch 19, Val Loss: 2.03537
Epoch 20, Val Loss: 2.05983
Epoch 21, Val Loss: 2.00939
Epoch 22, Val Loss: 2.03931
Epoch 23, Val Loss: 2.02290
Epoch 24, Val Loss: 2.02229
Epoch 25, Val Loss: 2.02243
Epoch 26, Val Loss: 2.01498
Epoch 27, Val Loss: 2.01466
Epoch 28, Val Loss: 2.05379
Epoch 29, Val Loss: 2.04561
Epoch 30, Val Loss: 2.03048
Epoch 31, Val Loss: 2.04186
Epoch 32, Val Loss: 2.03281
Epoch 33, Val Loss: 2.02882
Epoch 34, Val Loss: 2.02700
Epoch 35, Val Loss: 2.01437
Epoch 36, Val Loss: 2.00941
Epoch 37, Val Loss: 2.02394
Epoch 38, Val Loss: 2.02907
Epoch 39, Val Loss: 2.03023
Epoch 40, Val Loss: 2.02161
Epoch 41, Val Loss: 2.02576
Epoch 42, Val Loss: 2.01256
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6647250000000002, 'Log Loss - std': 0.15232139335956724} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}
Fitted encoder
Epoch 0, Val Loss: 1.95762
Epoch 1, Val Loss: 1.97245
Epoch 2, Val Loss: 1.95477
Epoch 3, Val Loss: 1.97598
Epoch 4, Val Loss: 1.96948
Epoch 5, Val Loss: 1.94616
Epoch 6, Val Loss: 1.95781
Epoch 7, Val Loss: 1.97047
Epoch 8, Val Loss: 1.94693
Epoch 9, Val Loss: 1.96122
Epoch 10, Val Loss: 1.94553
Epoch 11, Val Loss: 1.95156
Epoch 12, Val Loss: 1.94098
Epoch 13, Val Loss: 1.94212
Epoch 14, Val Loss: 1.95327
Epoch 15, Val Loss: 1.94663
Epoch 16, Val Loss: 1.94426
Epoch 17, Val Loss: 1.94175
Epoch 18, Val Loss: 1.94870
Epoch 19, Val Loss: 1.94707
Epoch 20, Val Loss: 1.93832
Epoch 21, Val Loss: 1.93841
Epoch 22, Val Loss: 1.92161
Epoch 23, Val Loss: 1.93172
Epoch 24, Val Loss: 1.95267
Epoch 25, Val Loss: 1.94931
Epoch 26, Val Loss: 1.93264
Epoch 27, Val Loss: 1.93170
Epoch 28, Val Loss: 1.92363
Epoch 29, Val Loss: 1.92311
Epoch 30, Val Loss: 1.92712
Epoch 31, Val Loss: 1.94100
Epoch 32, Val Loss: 1.92759
Epoch 33, Val Loss: 1.92636
Epoch 34, Val Loss: 1.95816
Epoch 35, Val Loss: 1.92625
Epoch 36, Val Loss: 1.92643
Epoch 37, Val Loss: 1.91257
Epoch 38, Val Loss: 1.97018
Epoch 39, Val Loss: 1.92447
Epoch 40, Val Loss: 1.92756
Epoch 41, Val Loss: 1.90789
Epoch 42, Val Loss: 1.90519
Epoch 43, Val Loss: 1.91980
Epoch 44, Val Loss: 1.93430
Epoch 45, Val Loss: 1.92748
Epoch 46, Val Loss: 1.91318
Epoch 47, Val Loss: 1.90845
Epoch 48, Val Loss: 1.89875
Epoch 49, Val Loss: 1.93457
Epoch 50, Val Loss: 1.91049
Epoch 51, Val Loss: 1.91942
Epoch 52, Val Loss: 1.93172
Epoch 53, Val Loss: 1.91241
Epoch 54, Val Loss: 1.91746
Epoch 55, Val Loss: 1.90768
Epoch 56, Val Loss: 1.92512
Epoch 57, Val Loss: 1.91843
Epoch 58, Val Loss: 1.90385
Epoch 59, Val Loss: 1.92812
Epoch 60, Val Loss: 1.91220
Epoch 61, Val Loss: 1.91806
Epoch 62, Val Loss: 1.92333
Epoch 63, Val Loss: 1.91798
Epoch 64, Val Loss: 1.91221
Epoch 65, Val Loss: 1.93067
Epoch 66, Val Loss: 1.91272
Epoch 67, Val Loss: 1.91227
Epoch 68, Val Loss: 1.91566
Epoch 69, Val Loss: 1.90865
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.81442, 'Log Loss - std': 0.32893132657136803} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 14 finished with value: 2.81442 and parameters: {'p_m': 0.6359007655691927, 'alpha': 4.484654528333014, 'K': 5, 'beta': 3.2791965986815517}. Best is trial 12 with value: 3.41244.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}
Fitted encoder
Epoch 0, Val Loss: 2.16116
Epoch 1, Val Loss: 2.13923
Epoch 2, Val Loss: 2.13747
Epoch 3, Val Loss: 2.13275
Epoch 4, Val Loss: 2.13724
Epoch 5, Val Loss: 2.12278
Epoch 6, Val Loss: 2.09048
Epoch 7, Val Loss: 2.08037
Epoch 8, Val Loss: 2.10771
Epoch 9, Val Loss: 2.07285
Epoch 10, Val Loss: 2.07721
Epoch 11, Val Loss: 2.08418
Epoch 12, Val Loss: 2.06731
Epoch 13, Val Loss: 2.06993
Epoch 14, Val Loss: 2.07814
Epoch 15, Val Loss: 2.07791
Epoch 16, Val Loss: 2.05501
Epoch 17, Val Loss: 2.07093
Epoch 18, Val Loss: 2.07313
Epoch 19, Val Loss: 2.05926
Epoch 20, Val Loss: 2.05976
Epoch 21, Val Loss: 2.05432
Epoch 22, Val Loss: 2.05373
Epoch 23, Val Loss: 2.05631
Epoch 24, Val Loss: 2.07823
Epoch 25, Val Loss: 2.06333
Epoch 26, Val Loss: 2.06314
Epoch 27, Val Loss: 2.06726
Epoch 28, Val Loss: 2.07252
Epoch 29, Val Loss: 2.07157
Epoch 30, Val Loss: 2.05899
Epoch 31, Val Loss: 2.06688
Epoch 32, Val Loss: 2.04822
Epoch 33, Val Loss: 2.04600
Epoch 34, Val Loss: 2.05550
Epoch 35, Val Loss: 2.06707
Epoch 36, Val Loss: 2.05245
Epoch 37, Val Loss: 2.05839
Epoch 38, Val Loss: 2.05081
Epoch 39, Val Loss: 2.05986
Epoch 40, Val Loss: 2.08897
Epoch 41, Val Loss: 2.05150
Epoch 42, Val Loss: 2.05636
Epoch 43, Val Loss: 2.07787
Epoch 44, Val Loss: 2.05967
Epoch 45, Val Loss: 2.05278
Epoch 46, Val Loss: 2.04279
Epoch 47, Val Loss: 2.05130
Epoch 48, Val Loss: 2.05003
Epoch 49, Val Loss: 2.03578
Epoch 50, Val Loss: 2.05104
Epoch 51, Val Loss: 2.04483
Epoch 52, Val Loss: 2.06881
Epoch 53, Val Loss: 2.05234
Epoch 54, Val Loss: 2.04768
Epoch 55, Val Loss: 2.06572
Epoch 56, Val Loss: 2.05361
Epoch 57, Val Loss: 2.05702
Epoch 58, Val Loss: 2.04830
Epoch 59, Val Loss: 2.05496
Epoch 60, Val Loss: 2.05420
Epoch 61, Val Loss: 2.04837
Epoch 62, Val Loss: 2.03598
Epoch 63, Val Loss: 2.04895
Epoch 64, Val Loss: 2.04787
Epoch 65, Val Loss: 2.04367
Epoch 66, Val Loss: 2.04536
Epoch 67, Val Loss: 2.04776
Epoch 68, Val Loss: 2.05485
Epoch 69, Val Loss: 2.04403
Epoch 70, Val Loss: 2.03800
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.1163, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}
Fitted encoder
Epoch 0, Val Loss: 1.98683
Epoch 1, Val Loss: 1.94647
Epoch 2, Val Loss: 1.96001
Epoch 3, Val Loss: 1.96440
Epoch 4, Val Loss: 1.96178
Epoch 5, Val Loss: 1.95011
Epoch 6, Val Loss: 1.94653
Epoch 7, Val Loss: 1.95127
Epoch 8, Val Loss: 1.94726
Epoch 9, Val Loss: 1.95943
Epoch 10, Val Loss: 1.94875
Epoch 11, Val Loss: 1.94512
Epoch 12, Val Loss: 1.94204
Epoch 13, Val Loss: 1.94421
Epoch 14, Val Loss: 1.93592
Epoch 15, Val Loss: 1.94866
Epoch 16, Val Loss: 1.93533
Epoch 17, Val Loss: 1.92884
Epoch 18, Val Loss: 1.93872
Epoch 19, Val Loss: 1.93377
Epoch 20, Val Loss: 1.91667
Epoch 21, Val Loss: 1.94243
Epoch 22, Val Loss: 1.92259
Epoch 23, Val Loss: 1.92801
Epoch 24, Val Loss: 1.92900
Epoch 25, Val Loss: 1.93467
Epoch 26, Val Loss: 1.92879
Epoch 27, Val Loss: 1.92293
Epoch 28, Val Loss: 1.91974
Epoch 29, Val Loss: 1.92181
Epoch 30, Val Loss: 1.93404
Epoch 31, Val Loss: 1.93547
Epoch 32, Val Loss: 1.92884
Epoch 33, Val Loss: 1.91406
Epoch 34, Val Loss: 1.91648
Epoch 35, Val Loss: 1.93259
Epoch 36, Val Loss: 1.91192
Epoch 37, Val Loss: 1.90742
Epoch 38, Val Loss: 1.90727
Epoch 39, Val Loss: 1.90483
Epoch 40, Val Loss: 1.91940
Epoch 41, Val Loss: 1.91522
Epoch 42, Val Loss: 1.93568
Epoch 43, Val Loss: 1.91743
Epoch 44, Val Loss: 1.91249
Epoch 45, Val Loss: 1.90895
Epoch 46, Val Loss: 1.93657
Epoch 47, Val Loss: 1.91313
Epoch 48, Val Loss: 1.91763
Epoch 49, Val Loss: 1.91276
Epoch 50, Val Loss: 1.91741
Epoch 51, Val Loss: 1.91151
Epoch 52, Val Loss: 1.91736
Epoch 53, Val Loss: 1.91380
Epoch 54, Val Loss: 1.91660
Epoch 55, Val Loss: 1.91005
Epoch 56, Val Loss: 1.91196
Epoch 57, Val Loss: 1.90751
Epoch 58, Val Loss: 1.91032
Epoch 59, Val Loss: 1.92188
Epoch 60, Val Loss: 1.90063
Epoch 61, Val Loss: 1.90250
Epoch 62, Val Loss: 1.91287
Epoch 63, Val Loss: 1.92060
Epoch 64, Val Loss: 1.90113
Epoch 65, Val Loss: 1.92578
Epoch 66, Val Loss: 1.91149
Epoch 67, Val Loss: 1.91215
Epoch 68, Val Loss: 1.91488
Epoch 69, Val Loss: 1.91499
Epoch 70, Val Loss: 1.90571
Epoch 71, Val Loss: 1.91121
Epoch 72, Val Loss: 1.90497
Epoch 73, Val Loss: 1.91791
Epoch 74, Val Loss: 1.90491
Epoch 75, Val Loss: 1.91305
Epoch 76, Val Loss: 1.90379
Epoch 77, Val Loss: 1.90764
Epoch 78, Val Loss: 1.90989
Epoch 79, Val Loss: 1.90177
Epoch 80, Val Loss: 1.89794
Epoch 81, Val Loss: 1.91070
Epoch 82, Val Loss: 1.90297
Epoch 83, Val Loss: 1.90786
Epoch 84, Val Loss: 1.90392
Epoch 85, Val Loss: 1.91079
Epoch 86, Val Loss: 1.89678
Epoch 87, Val Loss: 1.90068
Epoch 88, Val Loss: 1.90427
Epoch 89, Val Loss: 1.90028
Epoch 90, Val Loss: 1.91974
Epoch 91, Val Loss: 1.91280
Epoch 92, Val Loss: 1.89909
Epoch 93, Val Loss: 1.89048
Epoch 94, Val Loss: 1.91940
Epoch 95, Val Loss: 1.90496
Epoch 96, Val Loss: 1.90616
Epoch 97, Val Loss: 1.91206
Epoch 98, Val Loss: 1.89918
Epoch 99, Val Loss: 1.91119
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.4090499999999997, 'Log Loss - std': 0.29275000000000007} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}
Fitted encoder
Epoch 0, Val Loss: 2.13233
Epoch 1, Val Loss: 2.12161
Epoch 2, Val Loss: 2.12141
Epoch 3, Val Loss: 2.12017
Epoch 4, Val Loss: 2.12168
Epoch 5, Val Loss: 2.12739
Epoch 6, Val Loss: 2.11572
Epoch 7, Val Loss: 2.10589
Epoch 8, Val Loss: 2.10968
Epoch 9, Val Loss: 2.11136
Epoch 10, Val Loss: 2.10634
Epoch 11, Val Loss: 2.10293
Epoch 12, Val Loss: 2.11298
Epoch 13, Val Loss: 2.11091
Epoch 14, Val Loss: 2.09858
Epoch 15, Val Loss: 2.10023
Epoch 16, Val Loss: 2.10019
Epoch 17, Val Loss: 2.10315
Epoch 18, Val Loss: 2.09657
Epoch 19, Val Loss: 2.09781
Epoch 20, Val Loss: 2.09381
Epoch 21, Val Loss: 2.08875
Epoch 22, Val Loss: 2.09660
Epoch 23, Val Loss: 2.09261
Epoch 24, Val Loss: 2.09215
Epoch 25, Val Loss: 2.09864
Epoch 26, Val Loss: 2.09686
Epoch 27, Val Loss: 2.08490
Epoch 28, Val Loss: 2.08891
Epoch 29, Val Loss: 2.08634
Epoch 30, Val Loss: 2.07913
Epoch 31, Val Loss: 2.10033
Epoch 32, Val Loss: 2.07946
Epoch 33, Val Loss: 2.08031
Epoch 34, Val Loss: 2.08299
Epoch 35, Val Loss: 2.08330
Epoch 36, Val Loss: 2.08245
Epoch 37, Val Loss: 2.08890
Epoch 38, Val Loss: 2.10019
Epoch 39, Val Loss: 2.08180
Epoch 40, Val Loss: 2.07756
Epoch 41, Val Loss: 2.08464
Epoch 42, Val Loss: 2.08002
Epoch 43, Val Loss: 2.07739
Epoch 44, Val Loss: 2.07185
Epoch 45, Val Loss: 2.07678
Epoch 46, Val Loss: 2.08381
Epoch 47, Val Loss: 2.07864
Epoch 48, Val Loss: 2.08196
Epoch 49, Val Loss: 2.08150
Epoch 50, Val Loss: 2.07377
Epoch 51, Val Loss: 2.08339
Epoch 52, Val Loss: 2.10592
Epoch 53, Val Loss: 2.07151
Epoch 54, Val Loss: 2.07892
Epoch 55, Val Loss: 2.07369
Epoch 56, Val Loss: 2.07875
Epoch 57, Val Loss: 2.07675
Epoch 58, Val Loss: 2.07119
Epoch 59, Val Loss: 2.06446
Epoch 60, Val Loss: 2.07254
Epoch 61, Val Loss: 2.08303
Epoch 62, Val Loss: 2.08103
Epoch 63, Val Loss: 2.06316
Epoch 64, Val Loss: 2.07973
Epoch 65, Val Loss: 2.06212
Epoch 66, Val Loss: 2.07089
Epoch 67, Val Loss: 2.06722
Epoch 68, Val Loss: 2.10185
Epoch 69, Val Loss: 2.08166
Epoch 70, Val Loss: 2.06757
Epoch 71, Val Loss: 2.07528
Epoch 72, Val Loss: 2.06736
Epoch 73, Val Loss: 2.08217
Epoch 74, Val Loss: 2.08255
Epoch 75, Val Loss: 2.06354
Epoch 76, Val Loss: 2.07109
Epoch 77, Val Loss: 2.07479
Epoch 78, Val Loss: 2.06618
Epoch 79, Val Loss: 2.06918
Epoch 80, Val Loss: 2.06528
Epoch 81, Val Loss: 2.07130
Epoch 82, Val Loss: 2.07789
Epoch 83, Val Loss: 2.07705
Epoch 84, Val Loss: 2.07069
Epoch 85, Val Loss: 2.07004
Epoch 86, Val Loss: 2.06822
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.4404999999999997, 'Log Loss - std': 0.24313215884918782} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}
Fitted encoder
Epoch 0, Val Loss: 2.07779
Epoch 1, Val Loss: 2.07847
Epoch 2, Val Loss: 2.07480
Epoch 3, Val Loss: 2.06822
Epoch 4, Val Loss: 2.07434
Epoch 5, Val Loss: 2.06556
Epoch 6, Val Loss: 2.06656
Epoch 7, Val Loss: 2.06886
Epoch 8, Val Loss: 2.07069
Epoch 9, Val Loss: 2.07286
Epoch 10, Val Loss: 2.06563
Epoch 11, Val Loss: 2.07320
Epoch 12, Val Loss: 2.06390
Epoch 13, Val Loss: 2.06585
Epoch 14, Val Loss: 2.06309
Epoch 15, Val Loss: 2.06941
Epoch 16, Val Loss: 2.06035
Epoch 17, Val Loss: 2.06222
Epoch 18, Val Loss: 2.06218
Epoch 19, Val Loss: 2.06264
Epoch 20, Val Loss: 2.05838
Epoch 21, Val Loss: 2.06077
Epoch 22, Val Loss: 2.06391
Epoch 23, Val Loss: 2.06311
Epoch 24, Val Loss: 2.05730
Epoch 25, Val Loss: 2.06488
Epoch 26, Val Loss: 2.06407
Epoch 27, Val Loss: 2.05454
Epoch 28, Val Loss: 2.05760
Epoch 29, Val Loss: 2.06197
Epoch 30, Val Loss: 2.04494
Epoch 31, Val Loss: 2.04674
Epoch 32, Val Loss: 2.04581
Epoch 33, Val Loss: 2.04682
Epoch 34, Val Loss: 2.04503
Epoch 35, Val Loss: 2.06016
Epoch 36, Val Loss: 2.05380
Epoch 37, Val Loss: 2.04105
Epoch 38, Val Loss: 2.05510
Epoch 39, Val Loss: 2.04291
Epoch 40, Val Loss: 2.04705
Epoch 41, Val Loss: 2.04289
Epoch 42, Val Loss: 2.04225
Epoch 43, Val Loss: 2.04940
Epoch 44, Val Loss: 2.04822
Epoch 45, Val Loss: 2.04785
Epoch 46, Val Loss: 2.03661
Epoch 47, Val Loss: 2.04993
Epoch 48, Val Loss: 2.03446
Epoch 49, Val Loss: 2.03929
Epoch 50, Val Loss: 2.03550
Epoch 51, Val Loss: 2.04205
Epoch 52, Val Loss: 2.04475
Epoch 53, Val Loss: 2.03623
Epoch 54, Val Loss: 2.03994
Epoch 55, Val Loss: 2.04976
Epoch 56, Val Loss: 2.05387
Epoch 57, Val Loss: 2.04362
Epoch 58, Val Loss: 2.03983
Epoch 59, Val Loss: 2.04020
Epoch 60, Val Loss: 2.03475
Epoch 61, Val Loss: 2.04550
Epoch 62, Val Loss: 2.03553
Epoch 63, Val Loss: 2.05478
Epoch 64, Val Loss: 2.04628
Epoch 65, Val Loss: 2.04293
Epoch 66, Val Loss: 2.03394
Epoch 67, Val Loss: 2.04258
Epoch 68, Val Loss: 2.03468
Epoch 69, Val Loss: 2.03981
Epoch 70, Val Loss: 2.02764
Epoch 71, Val Loss: 2.03083
Epoch 72, Val Loss: 2.03959
Epoch 73, Val Loss: 2.04378
Epoch 74, Val Loss: 2.03963
Epoch 75, Val Loss: 2.03285
Epoch 76, Val Loss: 2.04760
Epoch 77, Val Loss: 2.04499
Epoch 78, Val Loss: 2.04442
Epoch 79, Val Loss: 2.03284
Epoch 80, Val Loss: 2.04069
Epoch 81, Val Loss: 2.04439
Epoch 82, Val Loss: 2.03958
Epoch 83, Val Loss: 2.04750
Epoch 84, Val Loss: 2.05025
Epoch 85, Val Loss: 2.03992
Epoch 86, Val Loss: 2.04514
Epoch 87, Val Loss: 2.04870
Epoch 88, Val Loss: 2.03771
Epoch 89, Val Loss: 2.03097
Epoch 90, Val Loss: 2.05021
Epoch 91, Val Loss: 2.03515
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.3453749999999998, 'Log Loss - std': 0.2673597424351692} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}
Fitted encoder
Epoch 0, Val Loss: 1.96603
Epoch 1, Val Loss: 1.95954
Epoch 2, Val Loss: 1.95875
Epoch 3, Val Loss: 1.95294
Epoch 4, Val Loss: 1.94758
Epoch 5, Val Loss: 1.95916
Epoch 6, Val Loss: 1.96260
Epoch 7, Val Loss: 1.94913
Epoch 8, Val Loss: 1.94678
Epoch 9, Val Loss: 1.95501
Epoch 10, Val Loss: 1.95040
Epoch 11, Val Loss: 1.96067
Epoch 12, Val Loss: 1.94679
Epoch 13, Val Loss: 1.95527
Epoch 14, Val Loss: 1.94421
Epoch 15, Val Loss: 1.94789
Epoch 16, Val Loss: 1.94607
Epoch 17, Val Loss: 1.94230
Epoch 18, Val Loss: 1.95646
Epoch 19, Val Loss: 1.94523
Epoch 20, Val Loss: 1.94110
Epoch 21, Val Loss: 1.93559
Epoch 22, Val Loss: 1.93677
Epoch 23, Val Loss: 1.93412
Epoch 24, Val Loss: 1.96160
Epoch 25, Val Loss: 1.93674
Epoch 26, Val Loss: 1.93110
Epoch 27, Val Loss: 1.93533
Epoch 28, Val Loss: 1.92996
Epoch 29, Val Loss: 1.93753
Epoch 30, Val Loss: 1.94114
Epoch 31, Val Loss: 1.94129
Epoch 32, Val Loss: 1.93302
Epoch 33, Val Loss: 1.92252
Epoch 34, Val Loss: 1.92890
Epoch 35, Val Loss: 1.93059
Epoch 36, Val Loss: 1.92402
Epoch 37, Val Loss: 1.92960
Epoch 38, Val Loss: 1.94194
Epoch 39, Val Loss: 1.92893
Epoch 40, Val Loss: 1.93588
Epoch 41, Val Loss: 1.92144
Epoch 42, Val Loss: 1.93075
Epoch 43, Val Loss: 1.92746
Epoch 44, Val Loss: 1.91253
Epoch 45, Val Loss: 1.91883
Epoch 46, Val Loss: 1.91971
Epoch 47, Val Loss: 1.92194
Epoch 48, Val Loss: 1.91521
Epoch 49, Val Loss: 1.93749
Epoch 50, Val Loss: 1.90336
Epoch 51, Val Loss: 1.93166
Epoch 52, Val Loss: 1.91535
Epoch 53, Val Loss: 1.90089
Epoch 54, Val Loss: 1.91800
Epoch 55, Val Loss: 1.90462
Epoch 56, Val Loss: 1.91623
Epoch 57, Val Loss: 1.90148
Epoch 58, Val Loss: 1.91131
Epoch 59, Val Loss: 1.91584
Epoch 60, Val Loss: 1.90295
Epoch 61, Val Loss: 1.91937
Epoch 62, Val Loss: 1.90821
Epoch 63, Val Loss: 1.91555
Epoch 64, Val Loss: 1.90609
Epoch 65, Val Loss: 1.92150
Epoch 66, Val Loss: 1.90335
Epoch 67, Val Loss: 1.90558
Epoch 68, Val Loss: 1.91319
Epoch 69, Val Loss: 1.89793
Epoch 70, Val Loss: 1.90801
Epoch 71, Val Loss: 1.92985
Epoch 72, Val Loss: 1.91281
Epoch 73, Val Loss: 1.90000
Epoch 74, Val Loss: 1.91088
Epoch 75, Val Loss: 1.90859
Epoch 76, Val Loss: 1.90840
Epoch 77, Val Loss: 1.89798
Epoch 78, Val Loss: 1.89973
Epoch 79, Val Loss: 1.90373
Epoch 80, Val Loss: 1.89537
Epoch 81, Val Loss: 1.89235
Epoch 82, Val Loss: 1.90747
Epoch 83, Val Loss: 1.90185
Epoch 84, Val Loss: 1.89672
Epoch 85, Val Loss: 1.89803
Epoch 86, Val Loss: 1.90297
Epoch 87, Val Loss: 1.90699
Epoch 88, Val Loss: 1.92480
Epoch 89, Val Loss: 1.88583
Epoch 90, Val Loss: 1.90562
Epoch 91, Val Loss: 1.88700
Epoch 92, Val Loss: 1.90812
Epoch 93, Val Loss: 1.89479
Epoch 94, Val Loss: 1.90152
Epoch 95, Val Loss: 1.88665
Epoch 96, Val Loss: 1.91720
Epoch 97, Val Loss: 1.89687
Epoch 98, Val Loss: 1.90378
Epoch 99, Val Loss: 1.90373
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.38618, 'Log Loss - std': 0.2526760328958803} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 15 finished with value: 2.38618 and parameters: {'p_m': 0.27197488897939015, 'alpha': 4.6019883517512, 'K': 5, 'beta': 6.4014651115487045}. Best is trial 12 with value: 3.41244.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}
Fitted encoder
Epoch 0, Val Loss: 2.15961
Epoch 1, Val Loss: 2.14343
Epoch 2, Val Loss: 2.12652
Epoch 3, Val Loss: 2.11730
Epoch 4, Val Loss: 2.08159
Epoch 5, Val Loss: 2.15427
Epoch 6, Val Loss: 2.08998
Epoch 7, Val Loss: 2.04266
Epoch 8, Val Loss: 2.10500
Epoch 9, Val Loss: 2.09617
Epoch 10, Val Loss: 2.12331
Epoch 11, Val Loss: 2.08120
Epoch 12, Val Loss: 2.09172
Epoch 13, Val Loss: 2.07685
Epoch 14, Val Loss: 2.03038
Epoch 15, Val Loss: 2.06842
Epoch 16, Val Loss: 2.03336
Epoch 17, Val Loss: 2.04919
Epoch 18, Val Loss: 2.06342
Epoch 19, Val Loss: 2.04159
Epoch 20, Val Loss: 2.07746
Epoch 21, Val Loss: 2.04756
Epoch 22, Val Loss: 2.07379
Epoch 23, Val Loss: 2.10856
Epoch 24, Val Loss: 2.08230
Epoch 25, Val Loss: 2.07325
Epoch 26, Val Loss: 2.07658
Epoch 27, Val Loss: 2.03188
Epoch 28, Val Loss: 2.05539
Epoch 29, Val Loss: 2.03635
Epoch 30, Val Loss: 2.04549
Epoch 31, Val Loss: 2.04318
Epoch 32, Val Loss: 2.04949
Epoch 33, Val Loss: 2.06070
Epoch 34, Val Loss: 2.04618
Epoch 35, Val Loss: 2.03332
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.5872, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}
Fitted encoder
Epoch 0, Val Loss: 1.97351
Epoch 1, Val Loss: 1.99233
Epoch 2, Val Loss: 1.95294
Epoch 3, Val Loss: 2.02641
Epoch 4, Val Loss: 1.96450
Epoch 5, Val Loss: 1.94862
Epoch 6, Val Loss: 1.93289
Epoch 7, Val Loss: 1.96638
Epoch 8, Val Loss: 1.91682
Epoch 9, Val Loss: 1.95248
Epoch 10, Val Loss: 1.92994
Epoch 11, Val Loss: 1.92541
Epoch 12, Val Loss: 1.93877
Epoch 13, Val Loss: 1.96207
Epoch 14, Val Loss: 1.90471
Epoch 15, Val Loss: 1.90868
Epoch 16, Val Loss: 1.90429
Epoch 17, Val Loss: 1.97835
Epoch 18, Val Loss: 1.92792
Epoch 19, Val Loss: 1.92996
Epoch 20, Val Loss: 1.96836
Epoch 21, Val Loss: 1.93162
Epoch 22, Val Loss: 1.94389
Epoch 23, Val Loss: 1.90932
Epoch 24, Val Loss: 1.92506
Epoch 25, Val Loss: 1.91556
Epoch 26, Val Loss: 1.92968
Epoch 27, Val Loss: 1.91963
Epoch 28, Val Loss: 1.91767
Epoch 29, Val Loss: 1.91938
Epoch 30, Val Loss: 1.91040
Epoch 31, Val Loss: 1.92360
Epoch 32, Val Loss: 1.90570
Epoch 33, Val Loss: 1.91103
Epoch 34, Val Loss: 1.90510
Epoch 35, Val Loss: 1.90657
Epoch 36, Val Loss: 1.90879
Epoch 37, Val Loss: 1.90784
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.22885, 'Log Loss - std': 0.6416499999999998} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}
Fitted encoder
Epoch 0, Val Loss: 2.13754
Epoch 1, Val Loss: 2.12971
Epoch 2, Val Loss: 2.12771
Epoch 3, Val Loss: 2.09622
Epoch 4, Val Loss: 2.10570
Epoch 5, Val Loss: 2.13650
Epoch 6, Val Loss: 2.07793
Epoch 7, Val Loss: 2.10649
Epoch 8, Val Loss: 2.10728
Epoch 9, Val Loss: 2.08642
Epoch 10, Val Loss: 2.09452
Epoch 11, Val Loss: 2.06323
Epoch 12, Val Loss: 2.06774
Epoch 13, Val Loss: 2.07897
Epoch 14, Val Loss: 2.11729
Epoch 15, Val Loss: 2.12878
Epoch 16, Val Loss: 2.09090
Epoch 17, Val Loss: 2.08669
Epoch 18, Val Loss: 2.07855
Epoch 19, Val Loss: 2.06319
Epoch 20, Val Loss: 2.06725
Epoch 21, Val Loss: 2.07841
Epoch 22, Val Loss: 2.07068
Epoch 23, Val Loss: 2.04139
Epoch 24, Val Loss: 2.06572
Epoch 25, Val Loss: 2.06094
Epoch 26, Val Loss: 2.06578
Epoch 27, Val Loss: 2.06275
Epoch 28, Val Loss: 2.06443
Epoch 29, Val Loss: 2.07030
Epoch 30, Val Loss: 2.08840
Epoch 31, Val Loss: 2.06104
Epoch 32, Val Loss: 2.04529
Epoch 33, Val Loss: 2.06695
Epoch 34, Val Loss: 2.07401
Epoch 35, Val Loss: 2.05865
Epoch 36, Val Loss: 2.06271
Epoch 37, Val Loss: 2.05643
Epoch 38, Val Loss: 2.05031
Epoch 39, Val Loss: 2.07608
Epoch 40, Val Loss: 2.06573
Epoch 41, Val Loss: 2.05410
Epoch 42, Val Loss: 2.09724
Epoch 43, Val Loss: 2.06142
Epoch 44, Val Loss: 2.05814
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.157966666666667, 'Log Loss - std': 0.5334092008538617} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}
Fitted encoder
Epoch 0, Val Loss: 2.08053
Epoch 1, Val Loss: 2.04804
Epoch 2, Val Loss: 2.07298
Epoch 3, Val Loss: 2.04442
Epoch 4, Val Loss: 2.04427
Epoch 5, Val Loss: 2.04713
Epoch 6, Val Loss: 2.05430
Epoch 7, Val Loss: 2.10954
Epoch 8, Val Loss: 2.03418
Epoch 9, Val Loss: 2.07808
Epoch 10, Val Loss: 2.07363
Epoch 11, Val Loss: 2.03087
Epoch 12, Val Loss: 2.06250
Epoch 13, Val Loss: 2.04632
Epoch 14, Val Loss: 2.08948
Epoch 15, Val Loss: 2.10470
Epoch 16, Val Loss: 2.08850
Epoch 17, Val Loss: 2.08379
Epoch 18, Val Loss: 2.11611
Epoch 19, Val Loss: 2.11207
Epoch 20, Val Loss: 2.11082
Epoch 21, Val Loss: 2.05080
Epoch 22, Val Loss: 2.07657
Epoch 23, Val Loss: 2.06144
Epoch 24, Val Loss: 2.10523
Epoch 25, Val Loss: 2.06734
Epoch 26, Val Loss: 2.03673
Epoch 27, Val Loss: 2.04971
Epoch 28, Val Loss: 2.05441
Epoch 29, Val Loss: 2.04298
Epoch 30, Val Loss: 2.07379
Epoch 31, Val Loss: 2.09388
Epoch 32, Val Loss: 2.03044
Epoch 33, Val Loss: 2.11551
Epoch 34, Val Loss: 2.06725
Epoch 35, Val Loss: 2.09057
Epoch 36, Val Loss: 2.08466
Epoch 37, Val Loss: 2.03963
Epoch 38, Val Loss: 2.10633
Epoch 39, Val Loss: 2.10462
Epoch 40, Val Loss: 2.09490
Epoch 41, Val Loss: 2.04188
Epoch 42, Val Loss: 2.09666
Epoch 43, Val Loss: 2.06961
Epoch 44, Val Loss: 2.05267
Epoch 45, Val Loss: 2.07875
Epoch 46, Val Loss: 2.04451
Epoch 47, Val Loss: 2.07739
Epoch 48, Val Loss: 2.04616
Epoch 49, Val Loss: 2.03980
Epoch 50, Val Loss: 2.04923
Epoch 51, Val Loss: 2.04343
Epoch 52, Val Loss: 2.04657
Epoch 53, Val Loss: 2.07572
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.29045, 'Log Loss - std': 0.5157998957929323} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}
Fitted encoder
Epoch 0, Val Loss: 1.95471
Epoch 1, Val Loss: 2.00173
Epoch 2, Val Loss: 1.94308
Epoch 3, Val Loss: 1.94408
Epoch 4, Val Loss: 1.94287
Epoch 5, Val Loss: 1.95395
Epoch 6, Val Loss: 1.93360
Epoch 7, Val Loss: 1.93212
Epoch 8, Val Loss: 1.92009
Epoch 9, Val Loss: 1.95987
Epoch 10, Val Loss: 1.90806
Epoch 11, Val Loss: 1.90425
Epoch 12, Val Loss: 1.90099
Epoch 13, Val Loss: 1.92814
Epoch 14, Val Loss: 1.89002
Epoch 15, Val Loss: 1.91137
Epoch 16, Val Loss: 1.91035
Epoch 17, Val Loss: 1.91500
Epoch 18, Val Loss: 1.91534
Epoch 19, Val Loss: 1.92042
Epoch 20, Val Loss: 1.94616
Epoch 21, Val Loss: 1.90568
Epoch 22, Val Loss: 1.90501
Epoch 23, Val Loss: 1.90256
Epoch 24, Val Loss: 1.89616
Epoch 25, Val Loss: 1.89807
Epoch 26, Val Loss: 1.96445
Epoch 27, Val Loss: 1.90099
Epoch 28, Val Loss: 1.91438
Epoch 29, Val Loss: 1.90044
Epoch 30, Val Loss: 1.93987
Epoch 31, Val Loss: 1.89652
Epoch 32, Val Loss: 1.88971
Epoch 33, Val Loss: 1.92684
Epoch 34, Val Loss: 1.90490
Epoch 35, Val Loss: 1.89246
Epoch 36, Val Loss: 1.89971
Epoch 37, Val Loss: 1.90438
Epoch 38, Val Loss: 1.89972
Epoch 39, Val Loss: 1.90559
Epoch 40, Val Loss: 1.89357
Epoch 41, Val Loss: 1.90093
Epoch 42, Val Loss: 1.90293
Epoch 43, Val Loss: 1.93034
Epoch 44, Val Loss: 1.89308
Epoch 45, Val Loss: 1.93273
Epoch 46, Val Loss: 1.90352
Epoch 47, Val Loss: 1.89102
Epoch 48, Val Loss: 1.90087
Epoch 49, Val Loss: 1.92817
Epoch 50, Val Loss: 1.88540
Epoch 51, Val Loss: 1.92209
Epoch 52, Val Loss: 1.88767
Epoch 53, Val Loss: 1.90570
Epoch 54, Val Loss: 1.89913
Epoch 55, Val Loss: 1.89273
Epoch 56, Val Loss: 1.88916
Epoch 57, Val Loss: 1.89668
Epoch 58, Val Loss: 1.89956
Epoch 59, Val Loss: 1.92875
Epoch 60, Val Loss: 1.89374
Epoch 61, Val Loss: 1.88566
Epoch 62, Val Loss: 1.91381
Epoch 63, Val Loss: 1.90728
Epoch 64, Val Loss: 1.89081
Epoch 65, Val Loss: 1.89767
Epoch 66, Val Loss: 1.88995
Epoch 67, Val Loss: 1.90344
Epoch 68, Val Loss: 1.91216
Epoch 69, Val Loss: 1.90130
Epoch 70, Val Loss: 1.90564
Epoch 71, Val Loss: 1.88982
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.33594, 'Log Loss - std': 0.4702307799368305} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 16 finished with value: 3.33594 and parameters: {'p_m': 0.8949118526695936, 'alpha': 5.294092410518794, 'K': 20, 'beta': 3.4989882190885213}. Best is trial 12 with value: 3.41244.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}
Fitted encoder
Epoch 0, Val Loss: 2.14691
Epoch 1, Val Loss: 2.14116
Epoch 2, Val Loss: 2.13950
Epoch 3, Val Loss: 2.10362
Epoch 4, Val Loss: 2.12163
Epoch 5, Val Loss: 2.14831
Epoch 6, Val Loss: 2.17387
Epoch 7, Val Loss: 2.16653
Epoch 8, Val Loss: 2.14395
Epoch 9, Val Loss: 2.14471
Epoch 10, Val Loss: 2.15312
Epoch 11, Val Loss: 2.14531
Epoch 12, Val Loss: 2.12764
Epoch 13, Val Loss: 2.09545
Epoch 14, Val Loss: 2.10099
Epoch 15, Val Loss: 2.09298
Epoch 16, Val Loss: 2.13442
Epoch 17, Val Loss: 2.10482
Epoch 18, Val Loss: 2.06635
Epoch 19, Val Loss: 2.05777
Epoch 20, Val Loss: 2.14619
Epoch 21, Val Loss: 2.15001
Epoch 22, Val Loss: 2.13000
Epoch 23, Val Loss: 2.13256
Epoch 24, Val Loss: 2.12117
Epoch 25, Val Loss: 2.13495
Epoch 26, Val Loss: 2.11236
Epoch 27, Val Loss: 2.10435
Epoch 28, Val Loss: 2.10779
Epoch 29, Val Loss: 2.11725
Epoch 30, Val Loss: 2.11739
Epoch 31, Val Loss: 2.12171
Epoch 32, Val Loss: 2.12422
Epoch 33, Val Loss: 2.11999
Epoch 34, Val Loss: 2.09580
Epoch 35, Val Loss: 2.12988
Epoch 36, Val Loss: 2.10624
Epoch 37, Val Loss: 2.09573
Epoch 38, Val Loss: 2.07766
Epoch 39, Val Loss: 2.07614
Epoch 40, Val Loss: 2.07489
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.5676, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}
Fitted encoder
Epoch 0, Val Loss: 1.97293
Epoch 1, Val Loss: 1.95043
Epoch 2, Val Loss: 1.93817
Epoch 3, Val Loss: 2.01367
Epoch 4, Val Loss: 2.04620
Epoch 5, Val Loss: 1.91375
Epoch 6, Val Loss: 1.92526
Epoch 7, Val Loss: 1.92808
Epoch 8, Val Loss: 1.92687
Epoch 9, Val Loss: 1.93113
Epoch 10, Val Loss: 1.96751
Epoch 11, Val Loss: 1.96390
Epoch 12, Val Loss: 1.92376
Epoch 13, Val Loss: 1.92055
Epoch 14, Val Loss: 1.94096
Epoch 15, Val Loss: 1.94327
Epoch 16, Val Loss: 1.90572
Epoch 17, Val Loss: 1.91821
Epoch 18, Val Loss: 1.92071
Epoch 19, Val Loss: 1.89791
Epoch 20, Val Loss: 1.94941
Epoch 21, Val Loss: 1.92806
Epoch 22, Val Loss: 1.94111
Epoch 23, Val Loss: 1.94628
Epoch 24, Val Loss: 1.95871
Epoch 25, Val Loss: 1.92753
Epoch 26, Val Loss: 1.92871
Epoch 27, Val Loss: 2.00978
Epoch 28, Val Loss: 2.02311
Epoch 29, Val Loss: 1.99268
Epoch 30, Val Loss: 1.93772
Epoch 31, Val Loss: 1.93015
Epoch 32, Val Loss: 1.95658
Epoch 33, Val Loss: 1.95838
Epoch 34, Val Loss: 2.06394
Epoch 35, Val Loss: 2.06896
Epoch 36, Val Loss: 2.06027
Epoch 37, Val Loss: 2.06690
Epoch 38, Val Loss: 2.01590
Epoch 39, Val Loss: 1.98690
Epoch 40, Val Loss: 1.95053
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 4.1617999999999995, 'Log Loss - std': 0.40579999999999994} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}
Fitted encoder
Epoch 0, Val Loss: 2.13139
Epoch 1, Val Loss: 2.12046
Epoch 2, Val Loss: 2.12366
Epoch 3, Val Loss: 2.10209
Epoch 4, Val Loss: 2.10972
Epoch 5, Val Loss: 2.13612
Epoch 6, Val Loss: 2.11840
Epoch 7, Val Loss: 2.10274
Epoch 8, Val Loss: 2.09102
Epoch 9, Val Loss: 2.11553
Epoch 10, Val Loss: 2.10251
Epoch 11, Val Loss: 2.11067
Epoch 12, Val Loss: 2.13017
Epoch 13, Val Loss: 2.10530
Epoch 14, Val Loss: 2.12936
Epoch 15, Val Loss: 2.10625
Epoch 16, Val Loss: 2.09845
Epoch 17, Val Loss: 2.10926
Epoch 18, Val Loss: 2.10171
Epoch 19, Val Loss: 2.16771
Epoch 20, Val Loss: 2.13969
Epoch 21, Val Loss: 2.13497
Epoch 22, Val Loss: 2.14093
Epoch 23, Val Loss: 2.09413
Epoch 24, Val Loss: 2.08944
Epoch 25, Val Loss: 2.08705
Epoch 26, Val Loss: 2.11590
Epoch 27, Val Loss: 2.09390
Epoch 28, Val Loss: 2.08106
Epoch 29, Val Loss: 2.04379
Epoch 30, Val Loss: 2.03489
Epoch 31, Val Loss: 2.03291
Epoch 32, Val Loss: 2.03537
Epoch 33, Val Loss: 2.04603
Epoch 34, Val Loss: 2.08626
Epoch 35, Val Loss: 2.04098
Epoch 36, Val Loss: 2.08172
Epoch 37, Val Loss: 2.02265
Epoch 38, Val Loss: 2.02725
Epoch 39, Val Loss: 2.03009
Epoch 40, Val Loss: 2.02722
Epoch 41, Val Loss: 2.04932
Epoch 42, Val Loss: 2.01867
Epoch 43, Val Loss: 2.03677
Epoch 44, Val Loss: 2.03436
Epoch 45, Val Loss: 2.01706
Epoch 46, Val Loss: 2.04182
Epoch 47, Val Loss: 2.02807
Epoch 48, Val Loss: 2.02714
Epoch 49, Val Loss: 2.02324
Epoch 50, Val Loss: 2.03450
Epoch 51, Val Loss: 2.03039
Epoch 52, Val Loss: 2.05367
Epoch 53, Val Loss: 2.06359
Epoch 54, Val Loss: 2.01989
Epoch 55, Val Loss: 2.02246
Epoch 56, Val Loss: 2.03142
Epoch 57, Val Loss: 2.01909
Epoch 58, Val Loss: 2.04471
Epoch 59, Val Loss: 2.03629
Epoch 60, Val Loss: 2.01785
Epoch 61, Val Loss: 2.02175
Epoch 62, Val Loss: 2.02986
Epoch 63, Val Loss: 2.04224
Epoch 64, Val Loss: 2.03386
Epoch 65, Val Loss: 2.04184
Epoch 66, Val Loss: 2.04966
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.8379, 'Log Loss - std': 0.5653360475563772} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}
Fitted encoder
Epoch 0, Val Loss: 2.14335
Epoch 1, Val Loss: 2.14719
Epoch 2, Val Loss: 2.10438
Epoch 3, Val Loss: 2.06377
Epoch 4, Val Loss: 2.08756
Epoch 5, Val Loss: 2.11277
Epoch 6, Val Loss: 2.10596
Epoch 7, Val Loss: 2.09077
Epoch 8, Val Loss: 2.04875
Epoch 9, Val Loss: 2.08098
Epoch 10, Val Loss: 2.06290
Epoch 11, Val Loss: 2.07232
Epoch 12, Val Loss: 2.12730
Epoch 13, Val Loss: 2.14724
Epoch 14, Val Loss: 2.12734
Epoch 15, Val Loss: 2.13376
Epoch 16, Val Loss: 2.11798
Epoch 17, Val Loss: 2.11884
Epoch 18, Val Loss: 2.09511
Epoch 19, Val Loss: 2.02687
Epoch 20, Val Loss: 2.01983
Epoch 21, Val Loss: 2.15549
Epoch 22, Val Loss: 2.09246
Epoch 23, Val Loss: 2.10404
Epoch 24, Val Loss: 2.07508
Epoch 25, Val Loss: 2.06581
Epoch 26, Val Loss: 2.08626
Epoch 27, Val Loss: 2.10788
Epoch 28, Val Loss: 2.12164
Epoch 29, Val Loss: 2.15056
Epoch 30, Val Loss: 2.13259
Epoch 31, Val Loss: 2.11244
Epoch 32, Val Loss: 2.12404
Epoch 33, Val Loss: 2.17515
Epoch 34, Val Loss: 2.15595
Epoch 35, Val Loss: 2.12718
Epoch 36, Val Loss: 2.12119
Epoch 37, Val Loss: 2.13628
Epoch 38, Val Loss: 2.13419
Epoch 39, Val Loss: 2.12803
Epoch 40, Val Loss: 2.15853
Epoch 41, Val Loss: 2.13815
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.9284499999999998, 'Log Loss - std': 0.5141026575500266} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}
Fitted encoder
Epoch 0, Val Loss: 1.95592
Epoch 1, Val Loss: 1.95248
Epoch 2, Val Loss: 1.92859
Epoch 3, Val Loss: 1.93106
Epoch 4, Val Loss: 1.89184
Epoch 5, Val Loss: 1.99453
Epoch 6, Val Loss: 1.99839
Epoch 7, Val Loss: 1.88818
Epoch 8, Val Loss: 1.90465
Epoch 9, Val Loss: 1.89353
Epoch 10, Val Loss: 1.89325
Epoch 11, Val Loss: 1.89585
Epoch 12, Val Loss: 1.89742
Epoch 13, Val Loss: 1.90496
Epoch 14, Val Loss: 1.89151
Epoch 15, Val Loss: 1.89510
Epoch 16, Val Loss: 1.89110
Epoch 17, Val Loss: 1.88582
Epoch 18, Val Loss: 1.99047
Epoch 19, Val Loss: 1.88762
Epoch 20, Val Loss: 1.89292
Epoch 21, Val Loss: 1.87304
Epoch 22, Val Loss: 1.87834
Epoch 23, Val Loss: 1.91320
Epoch 24, Val Loss: 1.97445
Epoch 25, Val Loss: 1.99851
Epoch 26, Val Loss: 1.98028
Epoch 27, Val Loss: 2.00174
Epoch 28, Val Loss: 2.01511
Epoch 29, Val Loss: 2.02013
Epoch 30, Val Loss: 2.01053
Epoch 31, Val Loss: 2.01561
Epoch 32, Val Loss: 2.03285
Epoch 33, Val Loss: 1.99677
Epoch 34, Val Loss: 2.00845
Epoch 35, Val Loss: 1.96506
Epoch 36, Val Loss: 1.95312
Epoch 37, Val Loss: 1.92723
Epoch 38, Val Loss: 1.89399
Epoch 39, Val Loss: 1.89730
Epoch 40, Val Loss: 1.88840
Epoch 41, Val Loss: 1.88949
Epoch 42, Val Loss: 2.00839
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.82294, 'Log Loss - std': 0.5059354448939112} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 17 finished with value: 3.82294 and parameters: {'p_m': 0.7301498544425202, 'alpha': 0.18923834215627622, 'K': 3, 'beta': 0.2042511647817271}. Best is trial 17 with value: 3.82294.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}
Fitted encoder
Epoch 0, Val Loss: 2.13983
Epoch 1, Val Loss: 2.12886
Epoch 2, Val Loss: 2.13483
Epoch 3, Val Loss: 2.14722
Epoch 4, Val Loss: 2.13026
Epoch 5, Val Loss: 2.12841
Epoch 6, Val Loss: 2.13151
Epoch 7, Val Loss: 2.12838
Epoch 8, Val Loss: 2.13234
Epoch 9, Val Loss: 2.12401
Epoch 10, Val Loss: 2.12771
Epoch 11, Val Loss: 2.12323
Epoch 12, Val Loss: 2.12220
Epoch 13, Val Loss: 2.10629
Epoch 14, Val Loss: 2.09791
Epoch 15, Val Loss: 2.10841
Epoch 16, Val Loss: 2.09774
Epoch 17, Val Loss: 2.14330
Epoch 18, Val Loss: 2.13132
Epoch 19, Val Loss: 2.11439
Epoch 20, Val Loss: 2.12942
Epoch 21, Val Loss: 2.11288
Epoch 22, Val Loss: 2.09813
Epoch 23, Val Loss: 2.09746
Epoch 24, Val Loss: 2.10230
Epoch 25, Val Loss: 2.09546
Epoch 26, Val Loss: 2.11089
Epoch 27, Val Loss: 2.10190
Epoch 28, Val Loss: 2.11113
Epoch 29, Val Loss: 2.11250
Epoch 30, Val Loss: 2.09862
Epoch 31, Val Loss: 2.11583
Epoch 32, Val Loss: 2.22515
Epoch 33, Val Loss: 2.22637
Epoch 34, Val Loss: 2.22637
Epoch 35, Val Loss: 2.22635
Epoch 36, Val Loss: 2.22634
Epoch 37, Val Loss: 2.22634
Epoch 38, Val Loss: 2.22631
Epoch 39, Val Loss: 2.22626
Epoch 40, Val Loss: 2.22623
Epoch 41, Val Loss: 2.22612
Epoch 42, Val Loss: 2.22630
Epoch 43, Val Loss: 2.22632
Epoch 44, Val Loss: 2.22631
Epoch 45, Val Loss: 2.22629
Epoch 46, Val Loss: 2.22629
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 5.1397, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}
Fitted encoder
Epoch 0, Val Loss: 1.97344
Epoch 1, Val Loss: 1.96277
Epoch 2, Val Loss: 1.94078
Epoch 3, Val Loss: 1.93608
Epoch 4, Val Loss: 1.94099
Epoch 5, Val Loss: 1.93545
Epoch 6, Val Loss: 1.91389
Epoch 7, Val Loss: 1.92391
Epoch 8, Val Loss: 1.91476
Epoch 9, Val Loss: 1.91573
Epoch 10, Val Loss: 1.99725
Epoch 11, Val Loss: 2.09166
Epoch 12, Val Loss: 2.06375
Epoch 13, Val Loss: 2.08527
Epoch 14, Val Loss: 2.07783
Epoch 15, Val Loss: 2.07445
Epoch 16, Val Loss: 2.08180
Epoch 17, Val Loss: 2.02005
Epoch 18, Val Loss: 2.06202
Epoch 19, Val Loss: 2.03344
Epoch 20, Val Loss: 1.96059
Epoch 21, Val Loss: 1.94407
Epoch 22, Val Loss: 2.01765
Epoch 23, Val Loss: 2.06494
Epoch 24, Val Loss: 2.07494
Epoch 25, Val Loss: 2.08965
Epoch 26, Val Loss: 2.06109
Epoch 27, Val Loss: 2.06794
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 4.107200000000001, 'Log Loss - std': 1.0325000000000002} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}
Fitted encoder
Epoch 0, Val Loss: 2.15345
Epoch 1, Val Loss: 2.14468
Epoch 2, Val Loss: 2.15352
Epoch 3, Val Loss: 2.16352
Epoch 4, Val Loss: 2.13665
Epoch 5, Val Loss: 2.12937
Epoch 6, Val Loss: 2.18154
Epoch 7, Val Loss: 2.15794
Epoch 8, Val Loss: 2.13794
Epoch 9, Val Loss: 2.14735
Epoch 10, Val Loss: 2.12037
Epoch 11, Val Loss: 2.11840
Epoch 12, Val Loss: 2.12224
Epoch 13, Val Loss: 2.13430
Epoch 14, Val Loss: 2.13095
Epoch 15, Val Loss: 2.15416
Epoch 16, Val Loss: 2.12578
Epoch 17, Val Loss: 2.14886
Epoch 18, Val Loss: 2.14736
Epoch 19, Val Loss: 2.15359
Epoch 20, Val Loss: 2.14144
Epoch 21, Val Loss: 2.16915
Epoch 22, Val Loss: 2.20794
Epoch 23, Val Loss: 2.26429
Epoch 24, Val Loss: 2.26429
Epoch 25, Val Loss: 2.26429
Epoch 26, Val Loss: 2.26429
Epoch 27, Val Loss: 2.26429
Epoch 28, Val Loss: 2.26429
Epoch 29, Val Loss: 2.26429
Epoch 30, Val Loss: 2.26429
Epoch 31, Val Loss: 2.26429
Epoch 32, Val Loss: 2.26429
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.480200000000001, 'Log Loss - std': 0.9944657694796071} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}
Fitted encoder
Epoch 0, Val Loss: 2.14645
Epoch 1, Val Loss: 2.12227
Epoch 2, Val Loss: 2.09950
Epoch 3, Val Loss: 2.02553
Epoch 4, Val Loss: 2.03135
Epoch 5, Val Loss: 2.05935
Epoch 6, Val Loss: 2.05030
Epoch 7, Val Loss: 2.03211
Epoch 8, Val Loss: 2.02527
Epoch 9, Val Loss: 2.04196
Epoch 10, Val Loss: 2.02042
Epoch 11, Val Loss: 2.02027
Epoch 12, Val Loss: 2.08642
Epoch 13, Val Loss: 2.06275
Epoch 14, Val Loss: 2.05260
Epoch 15, Val Loss: 2.03608
Epoch 16, Val Loss: 2.06622
Epoch 17, Val Loss: 2.01891
Epoch 18, Val Loss: 2.01407
Epoch 19, Val Loss: 2.03652
Epoch 20, Val Loss: 2.03191
Epoch 21, Val Loss: 2.00630
Epoch 22, Val Loss: 2.04208
Epoch 23, Val Loss: 2.03174
Epoch 24, Val Loss: 2.07194
Epoch 25, Val Loss: 2.09203
Epoch 26, Val Loss: 2.07805
Epoch 27, Val Loss: 2.06291
Epoch 28, Val Loss: 2.07378
Epoch 29, Val Loss: 2.05622
Epoch 30, Val Loss: 2.01176
Epoch 31, Val Loss: 2.01785
Epoch 32, Val Loss: 2.02326
Epoch 33, Val Loss: 2.05030
Epoch 34, Val Loss: 2.05379
Epoch 35, Val Loss: 2.01950
Epoch 36, Val Loss: 2.00962
Epoch 37, Val Loss: 2.02195
Epoch 38, Val Loss: 2.02778
Epoch 39, Val Loss: 2.02631
Epoch 40, Val Loss: 2.01896
Epoch 41, Val Loss: 2.03586
Epoch 42, Val Loss: 2.04672
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.1294, 'Log Loss - std': 1.0539940915394168} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}
Fitted encoder
Epoch 0, Val Loss: 1.96118
Epoch 1, Val Loss: 1.94972
Epoch 2, Val Loss: 1.94899
Epoch 3, Val Loss: 1.94850
Epoch 4, Val Loss: 1.94981
Epoch 5, Val Loss: 1.95379
Epoch 6, Val Loss: 1.98680
Epoch 7, Val Loss: 1.94092
Epoch 8, Val Loss: 1.94528
Epoch 9, Val Loss: 1.94366
Epoch 10, Val Loss: 1.95360
Epoch 11, Val Loss: 1.95707
Epoch 12, Val Loss: 2.06835
Epoch 13, Val Loss: 1.94053
Epoch 14, Val Loss: 1.96100
Epoch 15, Val Loss: 1.95459
Epoch 16, Val Loss: 1.95195
Epoch 17, Val Loss: 2.07829
Epoch 18, Val Loss: 2.05695
Epoch 19, Val Loss: 1.93998
Epoch 20, Val Loss: 1.95003
Epoch 21, Val Loss: 1.94676
Epoch 22, Val Loss: 1.95561
Epoch 23, Val Loss: 1.94067
Epoch 24, Val Loss: 1.94283
Epoch 25, Val Loss: 1.94033
Epoch 26, Val Loss: 1.94119
Epoch 27, Val Loss: 1.94135
Epoch 28, Val Loss: 1.93332
Epoch 29, Val Loss: 1.94953
Epoch 30, Val Loss: 1.94986
Epoch 31, Val Loss: 1.94261
Epoch 32, Val Loss: 1.92985
Epoch 33, Val Loss: 1.93260
Epoch 34, Val Loss: 1.95436
Epoch 35, Val Loss: 1.94645
Epoch 36, Val Loss: 2.03280
Epoch 37, Val Loss: 2.03203
Epoch 38, Val Loss: 2.03234
Epoch 39, Val Loss: 2.03105
Epoch 40, Val Loss: 2.03068
Epoch 41, Val Loss: 2.03613
Epoch 42, Val Loss: 2.03617
Epoch 43, Val Loss: 2.03090
Epoch 44, Val Loss: 2.05470
Epoch 45, Val Loss: 2.03314
Epoch 46, Val Loss: 2.02978
Epoch 47, Val Loss: 2.01869
Epoch 48, Val Loss: 1.93817
Epoch 49, Val Loss: 1.93098
Epoch 50, Val Loss: 1.94002
Epoch 51, Val Loss: 1.93153
Epoch 52, Val Loss: 1.96177
Epoch 53, Val Loss: 1.92790
Epoch 54, Val Loss: 1.92497
Epoch 55, Val Loss: 1.93653
Epoch 56, Val Loss: 1.94398
Epoch 57, Val Loss: 1.95486
Epoch 58, Val Loss: 1.93564
Epoch 59, Val Loss: 1.94584
Epoch 60, Val Loss: 1.92348
Epoch 61, Val Loss: 1.92833
Epoch 62, Val Loss: 1.94627
Epoch 63, Val Loss: 1.92101
Epoch 64, Val Loss: 1.93951
Epoch 65, Val Loss: 1.93404
Epoch 66, Val Loss: 1.93609
Epoch 67, Val Loss: 1.93375
Epoch 68, Val Loss: 1.91511
Epoch 69, Val Loss: 1.93265
Epoch 70, Val Loss: 1.94494
Epoch 71, Val Loss: 1.93394
Epoch 72, Val Loss: 1.91873
Epoch 73, Val Loss: 1.92921
Epoch 74, Val Loss: 1.91565
Epoch 75, Val Loss: 1.92999
Epoch 76, Val Loss: 1.91680
Epoch 77, Val Loss: 1.91602
Epoch 78, Val Loss: 1.92763
Epoch 79, Val Loss: 1.93661
Epoch 80, Val Loss: 1.93030
Epoch 81, Val Loss: 1.93798
Epoch 82, Val Loss: 1.94187
Epoch 83, Val Loss: 1.92967
Epoch 84, Val Loss: 1.92553
Epoch 85, Val Loss: 1.91351
Epoch 86, Val Loss: 2.00830
Epoch 87, Val Loss: 1.91310
Epoch 88, Val Loss: 1.91100
Epoch 89, Val Loss: 1.93276
Epoch 90, Val Loss: 1.91339
Epoch 91, Val Loss: 1.90892
Epoch 92, Val Loss: 1.90631
Epoch 93, Val Loss: 1.91279
Epoch 94, Val Loss: 1.91976
Epoch 95, Val Loss: 1.91013
Epoch 96, Val Loss: 1.91154
Epoch 97, Val Loss: 1.91326
Epoch 98, Val Loss: 1.91183
Epoch 99, Val Loss: 1.90894
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 4.07674, 'Log Loss - std': 0.9485858624289107} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 18 finished with value: 4.07674 and parameters: {'p_m': 0.7147084298264705, 'alpha': 0.9901025233673525, 'K': 3, 'beta': 0.2687722001681544}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}
Fitted encoder
Epoch 0, Val Loss: 2.14365
Epoch 1, Val Loss: 2.12334
Epoch 2, Val Loss: 2.11819
Epoch 3, Val Loss: 2.11670
Epoch 4, Val Loss: 2.12719
Epoch 5, Val Loss: 2.09771
Epoch 6, Val Loss: 2.09225
Epoch 7, Val Loss: 2.08950
Epoch 8, Val Loss: 2.09214
Epoch 9, Val Loss: 2.08959
Epoch 10, Val Loss: 2.08516
Epoch 11, Val Loss: 2.08717
Epoch 12, Val Loss: 2.07956
Epoch 13, Val Loss: 2.06887
Epoch 14, Val Loss: 2.07732
Epoch 15, Val Loss: 2.08723
Epoch 16, Val Loss: 2.07406
Epoch 17, Val Loss: 2.08977
Epoch 18, Val Loss: 2.08195
Epoch 19, Val Loss: 2.05888
Epoch 20, Val Loss: 2.08572
Epoch 21, Val Loss: 2.07098
Epoch 22, Val Loss: 2.10009
Epoch 23, Val Loss: 2.10122
Epoch 24, Val Loss: 2.07968
Epoch 25, Val Loss: 2.08920
Epoch 26, Val Loss: 2.07344
Epoch 27, Val Loss: 2.10177
Epoch 28, Val Loss: 2.06687
Epoch 29, Val Loss: 2.08573
Epoch 30, Val Loss: 2.06920
Epoch 31, Val Loss: 2.08520
Epoch 32, Val Loss: 2.08498
Epoch 33, Val Loss: 2.10450
Epoch 34, Val Loss: 2.07839
Epoch 35, Val Loss: 2.08168
Epoch 36, Val Loss: 2.15462
Epoch 37, Val Loss: 2.09535
Epoch 38, Val Loss: 2.09418
Epoch 39, Val Loss: 2.09857
Epoch 40, Val Loss: 2.08552
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.0047, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}
Fitted encoder
Epoch 0, Val Loss: 1.97218
Epoch 1, Val Loss: 1.95247
Epoch 2, Val Loss: 1.95649
Epoch 3, Val Loss: 2.03444
Epoch 4, Val Loss: 2.02723
Epoch 5, Val Loss: 2.02803
Epoch 6, Val Loss: 2.02116
Epoch 7, Val Loss: 2.02609
Epoch 8, Val Loss: 2.08101
Epoch 9, Val Loss: 2.02667
Epoch 10, Val Loss: 1.94212
Epoch 11, Val Loss: 1.93870
Epoch 12, Val Loss: 2.07832
Epoch 13, Val Loss: 1.93599
Epoch 14, Val Loss: 1.94764
Epoch 15, Val Loss: 1.94150
Epoch 16, Val Loss: 1.94866
Epoch 17, Val Loss: 1.94049
Epoch 18, Val Loss: 1.94968
Epoch 19, Val Loss: 1.95184
Epoch 20, Val Loss: 1.95566
Epoch 21, Val Loss: 2.07799
Epoch 22, Val Loss: 2.02300
Epoch 23, Val Loss: 1.94118
Epoch 24, Val Loss: 1.95299
Epoch 25, Val Loss: 1.97048
Epoch 26, Val Loss: 1.93642
Epoch 27, Val Loss: 1.95401
Epoch 28, Val Loss: 1.93960
Epoch 29, Val Loss: 1.93178
Epoch 30, Val Loss: 1.93853
Epoch 31, Val Loss: 1.93062
Epoch 32, Val Loss: 1.93180
Epoch 33, Val Loss: 1.93082
Epoch 34, Val Loss: 1.96633
Epoch 35, Val Loss: 1.94366
Epoch 36, Val Loss: 1.93284
Epoch 37, Val Loss: 1.92874
Epoch 38, Val Loss: 1.93161
Epoch 39, Val Loss: 1.92923
Epoch 40, Val Loss: 1.94229
Epoch 41, Val Loss: 1.93002
Epoch 42, Val Loss: 1.93774
Epoch 43, Val Loss: 1.94722
Epoch 44, Val Loss: 1.93088
Epoch 45, Val Loss: 1.92969
Epoch 46, Val Loss: 1.93323
Epoch 47, Val Loss: 1.93369
Epoch 48, Val Loss: 1.94012
Epoch 49, Val Loss: 1.93741
Epoch 50, Val Loss: 1.95579
Epoch 51, Val Loss: 1.97078
Epoch 52, Val Loss: 1.93989
Epoch 53, Val Loss: 1.95180
Epoch 54, Val Loss: 1.93714
Epoch 55, Val Loss: 2.03375
Epoch 56, Val Loss: 2.03819
Epoch 57, Val Loss: 2.02519
Epoch 58, Val Loss: 2.02460
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.7314999999999996, 'Log Loss - std': 0.2731999999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}
Fitted encoder
Epoch 0, Val Loss: 2.12712
Epoch 1, Val Loss: 2.11822
Epoch 2, Val Loss: 2.11656
Epoch 3, Val Loss: 2.11843
Epoch 4, Val Loss: 2.13863
Epoch 5, Val Loss: 2.07878
Epoch 6, Val Loss: 2.08861
Epoch 7, Val Loss: 2.10262
Epoch 8, Val Loss: 2.09081
Epoch 9, Val Loss: 2.08150
Epoch 10, Val Loss: 2.10789
Epoch 11, Val Loss: 2.06415
Epoch 12, Val Loss: 2.11054
Epoch 13, Val Loss: 2.10428
Epoch 14, Val Loss: 2.09703
Epoch 15, Val Loss: 2.06137
Epoch 16, Val Loss: 2.07480
Epoch 17, Val Loss: 2.07436
Epoch 18, Val Loss: 2.08364
Epoch 19, Val Loss: 2.08001
Epoch 20, Val Loss: 2.09241
Epoch 21, Val Loss: 2.08375
Epoch 22, Val Loss: 2.08493
Epoch 23, Val Loss: 2.06521
Epoch 24, Val Loss: 2.06119
Epoch 25, Val Loss: 2.07256
Epoch 26, Val Loss: 2.08125
Epoch 27, Val Loss: 2.05973
Epoch 28, Val Loss: 2.07610
Epoch 29, Val Loss: 2.08136
Epoch 30, Val Loss: 2.06210
Epoch 31, Val Loss: 2.06867
Epoch 32, Val Loss: 2.10188
Epoch 33, Val Loss: 2.10305
Epoch 34, Val Loss: 2.09719
Epoch 35, Val Loss: 2.07595
Epoch 36, Val Loss: 2.09416
Epoch 37, Val Loss: 2.09302
Epoch 38, Val Loss: 2.11186
Epoch 39, Val Loss: 2.09238
Epoch 40, Val Loss: 2.06772
Epoch 41, Val Loss: 2.06892
Epoch 42, Val Loss: 2.09170
Epoch 43, Val Loss: 2.08842
Epoch 44, Val Loss: 2.07814
Epoch 45, Val Loss: 2.06148
Epoch 46, Val Loss: 2.06540
Epoch 47, Val Loss: 2.08061
Epoch 48, Val Loss: 2.07021
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.779833333333333, 'Log Loss - std': 0.2333046268055755} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}
Fitted encoder
Epoch 0, Val Loss: 2.11126
Epoch 1, Val Loss: 2.14566
Epoch 2, Val Loss: 2.17347
Epoch 3, Val Loss: 2.11318
Epoch 4, Val Loss: 2.12459
Epoch 5, Val Loss: 2.05007
Epoch 6, Val Loss: 2.08118
Epoch 7, Val Loss: 2.07574
Epoch 8, Val Loss: 2.05980
Epoch 9, Val Loss: 2.09367
Epoch 10, Val Loss: 2.05776
Epoch 11, Val Loss: 2.05539
Epoch 12, Val Loss: 2.05712
Epoch 13, Val Loss: 2.02928
Epoch 14, Val Loss: 2.04946
Epoch 15, Val Loss: 2.20210
Epoch 16, Val Loss: 2.19968
Epoch 17, Val Loss: 2.12680
Epoch 18, Val Loss: 2.06037
Epoch 19, Val Loss: 2.04955
Epoch 20, Val Loss: 2.04334
Epoch 21, Val Loss: 2.02781
Epoch 22, Val Loss: 2.06754
Epoch 23, Val Loss: 2.06676
Epoch 24, Val Loss: 2.05098
Epoch 25, Val Loss: 2.02185
Epoch 26, Val Loss: 2.04289
Epoch 27, Val Loss: 2.03761
Epoch 28, Val Loss: 2.02337
Epoch 29, Val Loss: 2.01977
Epoch 30, Val Loss: 2.04354
Epoch 31, Val Loss: 2.02504
Epoch 32, Val Loss: 2.09376
Epoch 33, Val Loss: 2.08927
Epoch 34, Val Loss: 2.08098
Epoch 35, Val Loss: 2.07236
Epoch 36, Val Loss: 2.06300
Epoch 37, Val Loss: 2.07905
Epoch 38, Val Loss: 2.02027
Epoch 39, Val Loss: 2.02875
Epoch 40, Val Loss: 2.07739
Epoch 41, Val Loss: 2.05852
Epoch 42, Val Loss: 2.03579
Epoch 43, Val Loss: 2.03529
Epoch 44, Val Loss: 2.00951
Epoch 45, Val Loss: 2.03066
Epoch 46, Val Loss: 2.07538
Epoch 47, Val Loss: 2.07485
Epoch 48, Val Loss: 2.02690
Epoch 49, Val Loss: 2.04743
Epoch 50, Val Loss: 2.05399
Epoch 51, Val Loss: 2.04990
Epoch 52, Val Loss: 2.03842
Epoch 53, Val Loss: 2.02561
Epoch 54, Val Loss: 2.03974
Epoch 55, Val Loss: 2.04488
Epoch 56, Val Loss: 2.03279
Epoch 57, Val Loss: 2.05491
Epoch 58, Val Loss: 2.02791
Epoch 59, Val Loss: 2.02542
Epoch 60, Val Loss: 2.03885
Epoch 61, Val Loss: 2.03037
Epoch 62, Val Loss: 2.05563
Epoch 63, Val Loss: 2.04988
Epoch 64, Val Loss: 2.05775
Epoch 65, Val Loss: 2.04146
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.5999999999999996, 'Log Loss - std': 0.3712726356735706} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}
Fitted encoder
Epoch 0, Val Loss: 1.95592
Epoch 1, Val Loss: 1.96059
Epoch 2, Val Loss: 1.93588
Epoch 3, Val Loss: 1.91114
Epoch 4, Val Loss: 1.96209
Epoch 5, Val Loss: 1.92126
Epoch 6, Val Loss: 1.91279
Epoch 7, Val Loss: 1.91348
Epoch 8, Val Loss: 1.89280
Epoch 9, Val Loss: 1.89351
Epoch 10, Val Loss: 1.89241
Epoch 11, Val Loss: 1.90057
Epoch 12, Val Loss: 1.93846
Epoch 13, Val Loss: 1.91208
Epoch 14, Val Loss: 1.89572
Epoch 15, Val Loss: 1.89996
Epoch 16, Val Loss: 1.91702
Epoch 17, Val Loss: 1.88894
Epoch 18, Val Loss: 1.89967
Epoch 19, Val Loss: 1.93234
Epoch 20, Val Loss: 1.92486
Epoch 21, Val Loss: 1.89516
Epoch 22, Val Loss: 1.90504
Epoch 23, Val Loss: 1.90417
Epoch 24, Val Loss: 1.91476
Epoch 25, Val Loss: 1.88507
Epoch 26, Val Loss: 1.93197
Epoch 27, Val Loss: 1.92588
Epoch 28, Val Loss: 1.90204
Epoch 29, Val Loss: 1.89366
Epoch 30, Val Loss: 1.90185
Epoch 31, Val Loss: 1.89291
Epoch 32, Val Loss: 1.89546
Epoch 33, Val Loss: 1.91539
Epoch 34, Val Loss: 2.07251
Epoch 35, Val Loss: 1.91730
Epoch 36, Val Loss: 1.89626
Epoch 37, Val Loss: 1.92912
Epoch 38, Val Loss: 1.89490
Epoch 39, Val Loss: 1.91837
Epoch 40, Val Loss: 1.91124
Epoch 41, Val Loss: 1.88567
Epoch 42, Val Loss: 1.90568
Epoch 43, Val Loss: 1.90972
Epoch 44, Val Loss: 1.90667
Epoch 45, Val Loss: 1.90780
Epoch 46, Val Loss: 1.94653
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.5416799999999995, 'Log Loss - std': 0.35196531874603776} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 19 finished with value: 3.5416799999999995 and parameters: {'p_m': 0.7080223345362315, 'alpha': 0.7765033053133418, 'K': 3, 'beta': 0.2103636829249478}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}
Fitted encoder
Epoch 0, Val Loss: 2.12026
Epoch 1, Val Loss: 2.11572
Epoch 2, Val Loss: 2.11698
Epoch 3, Val Loss: 2.12344
Epoch 4, Val Loss: 2.12391
Epoch 5, Val Loss: 2.12586
Epoch 6, Val Loss: 2.12954
Epoch 7, Val Loss: 2.12479
Epoch 8, Val Loss: 2.12051
Epoch 9, Val Loss: 2.12397
Epoch 10, Val Loss: 2.12290
Epoch 11, Val Loss: 2.12674
Epoch 12, Val Loss: 2.12785
Epoch 13, Val Loss: 2.13349
Epoch 14, Val Loss: 2.12548
Epoch 15, Val Loss: 2.13848
Epoch 16, Val Loss: 2.13243
Epoch 17, Val Loss: 2.14244
Epoch 18, Val Loss: 2.14065
Epoch 19, Val Loss: 2.12899
Epoch 20, Val Loss: 2.12157
Epoch 21, Val Loss: 2.08994
Epoch 22, Val Loss: 2.11118
Epoch 23, Val Loss: 2.12186
Epoch 24, Val Loss: 2.09398
Epoch 25, Val Loss: 2.12521
Epoch 26, Val Loss: 2.08343
Epoch 27, Val Loss: 2.08314
Epoch 28, Val Loss: 2.08096
Epoch 29, Val Loss: 2.06463
Epoch 30, Val Loss: 2.08380
Epoch 31, Val Loss: 2.07206
Epoch 32, Val Loss: 2.05611
Epoch 33, Val Loss: 2.06915
Epoch 34, Val Loss: 2.14356
Epoch 35, Val Loss: 2.14039
Epoch 36, Val Loss: 2.13379
Epoch 37, Val Loss: 2.13169
Epoch 38, Val Loss: 2.08602
Epoch 39, Val Loss: 2.08225
Epoch 40, Val Loss: 2.07688
Epoch 41, Val Loss: 2.07084
Epoch 42, Val Loss: 2.08452
Epoch 43, Val Loss: 2.10481
Epoch 44, Val Loss: 2.08081
Epoch 45, Val Loss: 2.06866
Epoch 46, Val Loss: 2.08320
Epoch 47, Val Loss: 2.10289
Epoch 48, Val Loss: 2.12096
Epoch 49, Val Loss: 2.09045
Epoch 50, Val Loss: 2.06559
Epoch 51, Val Loss: 2.07035
Epoch 52, Val Loss: 2.13725
Epoch 53, Val Loss: 2.11740
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.5545, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}
Fitted encoder
Epoch 0, Val Loss: 1.95010
Epoch 1, Val Loss: 1.94195
Epoch 2, Val Loss: 1.93969
Epoch 3, Val Loss: 1.93217
Epoch 4, Val Loss: 1.94963
Epoch 5, Val Loss: 1.94413
Epoch 6, Val Loss: 1.93639
Epoch 7, Val Loss: 1.93650
Epoch 8, Val Loss: 1.91962
Epoch 9, Val Loss: 1.94588
Epoch 10, Val Loss: 1.90724
Epoch 11, Val Loss: 1.89968
Epoch 12, Val Loss: 1.92936
Epoch 13, Val Loss: 1.91000
Epoch 14, Val Loss: 1.92309
Epoch 15, Val Loss: 1.90159
Epoch 16, Val Loss: 1.93634
Epoch 17, Val Loss: 1.91418
Epoch 18, Val Loss: 1.92876
Epoch 19, Val Loss: 1.91918
Epoch 20, Val Loss: 1.92112
Epoch 21, Val Loss: 1.95404
Epoch 22, Val Loss: 2.09272
Epoch 23, Val Loss: 2.08082
Epoch 24, Val Loss: 2.11146
Epoch 25, Val Loss: 2.09946
Epoch 26, Val Loss: 1.96749
Epoch 27, Val Loss: 2.12235
Epoch 28, Val Loss: 2.09124
Epoch 29, Val Loss: 2.10193
Epoch 30, Val Loss: 2.11742
Epoch 31, Val Loss: 2.10606
Epoch 32, Val Loss: 2.09152
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.7213000000000003, 'Log Loss - std': 0.16680000000000006} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}
Fitted encoder
Epoch 0, Val Loss: 2.15904
Epoch 1, Val Loss: 2.16566
Epoch 2, Val Loss: 2.16063
Epoch 3, Val Loss: 2.15341
Epoch 4, Val Loss: 2.13330
Epoch 5, Val Loss: 2.14530
Epoch 6, Val Loss: 2.13887
Epoch 7, Val Loss: 2.12945
Epoch 8, Val Loss: 2.13544
Epoch 9, Val Loss: 2.14309
Epoch 10, Val Loss: 2.14340
Epoch 11, Val Loss: 2.12833
Epoch 12, Val Loss: 2.12617
Epoch 13, Val Loss: 2.13199
Epoch 14, Val Loss: 2.12750
Epoch 15, Val Loss: 2.11548
Epoch 16, Val Loss: 2.11966
Epoch 17, Val Loss: 2.13300
Epoch 18, Val Loss: 2.12023
Epoch 19, Val Loss: 2.10650
Epoch 20, Val Loss: 2.12295
Epoch 21, Val Loss: 2.10741
Epoch 22, Val Loss: 2.10894
Epoch 23, Val Loss: 2.11894
Epoch 24, Val Loss: 2.12164
Epoch 25, Val Loss: 2.11458
Epoch 26, Val Loss: 2.12188
Epoch 27, Val Loss: 2.11262
Epoch 28, Val Loss: 2.13424
Epoch 29, Val Loss: 2.11607
Epoch 30, Val Loss: 2.09764
Epoch 31, Val Loss: 2.11741
Epoch 32, Val Loss: 2.09533
Epoch 33, Val Loss: 2.09858
Epoch 34, Val Loss: 2.09808
Epoch 35, Val Loss: 2.10278
Epoch 36, Val Loss: 2.11048
Epoch 37, Val Loss: 2.10930
Epoch 38, Val Loss: 2.12064
Epoch 39, Val Loss: 2.11634
Epoch 40, Val Loss: 2.12110
Epoch 41, Val Loss: 2.09787
Epoch 42, Val Loss: 2.12015
Epoch 43, Val Loss: 2.09239
Epoch 44, Val Loss: 2.09772
Epoch 45, Val Loss: 2.11878
Epoch 46, Val Loss: 2.10136
Epoch 47, Val Loss: 2.10660
Epoch 48, Val Loss: 2.13802
Epoch 49, Val Loss: 2.11305
Epoch 50, Val Loss: 2.11638
Epoch 51, Val Loss: 2.09052
Epoch 52, Val Loss: 2.06822
Epoch 53, Val Loss: 2.12731
Epoch 54, Val Loss: 2.11388
Epoch 55, Val Loss: 2.10668
Epoch 56, Val Loss: 2.10159
Epoch 57, Val Loss: 2.10006
Epoch 58, Val Loss: 2.11884
Epoch 59, Val Loss: 2.10378
Epoch 60, Val Loss: 2.09094
Epoch 61, Val Loss: 2.09925
Epoch 62, Val Loss: 2.11373
Epoch 63, Val Loss: 2.14893
Epoch 64, Val Loss: 2.14039
Epoch 65, Val Loss: 2.14581
Epoch 66, Val Loss: 2.10754
Epoch 67, Val Loss: 2.13614
Epoch 68, Val Loss: 2.14580
Epoch 69, Val Loss: 2.15627
Epoch 70, Val Loss: 2.14637
Epoch 71, Val Loss: 2.16537
Epoch 72, Val Loss: 2.13129
Epoch 73, Val Loss: 2.12659
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.468666666666667, 'Log Loss - std': 0.3823550211808683} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}
Fitted encoder
Epoch 0, Val Loss: 2.07977
Epoch 1, Val Loss: 2.06472
Epoch 2, Val Loss: 2.07895
Epoch 3, Val Loss: 2.07964
Epoch 4, Val Loss: 2.06280
Epoch 5, Val Loss: 2.04807
Epoch 6, Val Loss: 2.07555
Epoch 7, Val Loss: 2.06166
Epoch 8, Val Loss: 2.02997
Epoch 9, Val Loss: 2.03942
Epoch 10, Val Loss: 2.09615
Epoch 11, Val Loss: 2.07364
Epoch 12, Val Loss: 2.10595
Epoch 13, Val Loss: 2.08674
Epoch 14, Val Loss: 2.11280
Epoch 15, Val Loss: 2.09860
Epoch 16, Val Loss: 2.07350
Epoch 17, Val Loss: 2.10401
Epoch 18, Val Loss: 2.03537
Epoch 19, Val Loss: 2.11453
Epoch 20, Val Loss: 2.12635
Epoch 21, Val Loss: 2.08076
Epoch 22, Val Loss: 2.03097
Epoch 23, Val Loss: 2.02293
Epoch 24, Val Loss: 2.08092
Epoch 25, Val Loss: 2.03020
Epoch 26, Val Loss: 2.11855
Epoch 27, Val Loss: 2.10668
Epoch 28, Val Loss: 2.09191
Epoch 29, Val Loss: 2.10341
Epoch 30, Val Loss: 2.11054
Epoch 31, Val Loss: 2.08979
Epoch 32, Val Loss: 2.09782
Epoch 33, Val Loss: 2.08593
Epoch 34, Val Loss: 2.09425
Epoch 35, Val Loss: 2.08444
Epoch 36, Val Loss: 2.08288
Epoch 37, Val Loss: 2.09098
Epoch 38, Val Loss: 2.09045
Epoch 39, Val Loss: 2.07926
Epoch 40, Val Loss: 2.07767
Epoch 41, Val Loss: 2.06656
Epoch 42, Val Loss: 2.12376
Epoch 43, Val Loss: 2.02788
Epoch 44, Val Loss: 2.09721
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.623475, 'Log Loss - std': 0.42607907936790335} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}
Fitted encoder
Epoch 0, Val Loss: 2.02925
Epoch 1, Val Loss: 1.95397
Epoch 2, Val Loss: 1.96499
Epoch 3, Val Loss: 1.93696
Epoch 4, Val Loss: 1.94527
Epoch 5, Val Loss: 1.93507
Epoch 6, Val Loss: 1.89165
Epoch 7, Val Loss: 1.91955
Epoch 8, Val Loss: 1.88600
Epoch 9, Val Loss: 1.91175
Epoch 10, Val Loss: 1.87560
Epoch 11, Val Loss: 1.89953
Epoch 12, Val Loss: 1.90485
Epoch 13, Val Loss: 1.95318
Epoch 14, Val Loss: 1.89948
Epoch 15, Val Loss: 1.89444
Epoch 16, Val Loss: 1.89085
Epoch 17, Val Loss: 1.88272
Epoch 18, Val Loss: 1.87953
Epoch 19, Val Loss: 1.93489
Epoch 20, Val Loss: 1.88085
Epoch 21, Val Loss: 1.87001
Epoch 22, Val Loss: 1.88602
Epoch 23, Val Loss: 1.89225
Epoch 24, Val Loss: 1.87922
Epoch 25, Val Loss: 1.89807
Epoch 26, Val Loss: 1.88310
Epoch 27, Val Loss: 1.87744
Epoch 28, Val Loss: 1.89930
Epoch 29, Val Loss: 1.89431
Epoch 30, Val Loss: 1.88513
Epoch 31, Val Loss: 1.88502
Epoch 32, Val Loss: 1.87627
Epoch 33, Val Loss: 1.93913
Epoch 34, Val Loss: 1.88007
Epoch 35, Val Loss: 1.90240
Epoch 36, Val Loss: 1.88919
Epoch 37, Val Loss: 1.88334
Epoch 38, Val Loss: 1.92608
Epoch 39, Val Loss: 1.91180
Epoch 40, Val Loss: 1.91716
Epoch 41, Val Loss: 1.91924
Epoch 42, Val Loss: 1.89334
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.53666, 'Log Loss - std': 0.41878644008611365} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 20 finished with value: 3.53666 and parameters: {'p_m': 0.5923876308223508, 'alpha': 0.2645402104032748, 'K': 3, 'beta': 0.2104230332550223}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}
Fitted encoder
Epoch 0, Val Loss: 2.15317
Epoch 1, Val Loss: 2.14292
Epoch 2, Val Loss: 2.17516
Epoch 3, Val Loss: 2.13482
Epoch 4, Val Loss: 2.13552
Epoch 5, Val Loss: 2.13659
Epoch 6, Val Loss: 2.13014
Epoch 7, Val Loss: 2.13173
Epoch 8, Val Loss: 2.12543
Epoch 9, Val Loss: 2.11867
Epoch 10, Val Loss: 2.11889
Epoch 11, Val Loss: 2.11454
Epoch 12, Val Loss: 2.09009
Epoch 13, Val Loss: 2.09505
Epoch 14, Val Loss: 2.11059
Epoch 15, Val Loss: 2.10704
Epoch 16, Val Loss: 2.08115
Epoch 17, Val Loss: 2.10074
Epoch 18, Val Loss: 2.08114
Epoch 19, Val Loss: 2.09049
Epoch 20, Val Loss: 2.09136
Epoch 21, Val Loss: 2.07713
Epoch 22, Val Loss: 2.06920
Epoch 23, Val Loss: 2.08588
Epoch 24, Val Loss: 2.11090
Epoch 25, Val Loss: 2.07650
Epoch 26, Val Loss: 2.07700
Epoch 27, Val Loss: 2.06328
Epoch 28, Val Loss: 2.10133
Epoch 29, Val Loss: 2.07288
Epoch 30, Val Loss: 2.07609
Epoch 31, Val Loss: 2.08509
Epoch 32, Val Loss: 2.09319
Epoch 33, Val Loss: 2.08381
Epoch 34, Val Loss: 2.09372
Epoch 35, Val Loss: 2.07342
Epoch 36, Val Loss: 2.07885
Epoch 37, Val Loss: 2.08188
Epoch 38, Val Loss: 2.08279
Epoch 39, Val Loss: 2.07419
Epoch 40, Val Loss: 2.08547
Epoch 41, Val Loss: 2.08289
Epoch 42, Val Loss: 2.09381
Epoch 43, Val Loss: 2.07329
Epoch 44, Val Loss: 2.06860
Epoch 45, Val Loss: 2.06177
Epoch 46, Val Loss: 2.07183
Epoch 47, Val Loss: 2.07458
Epoch 48, Val Loss: 2.06658
Epoch 49, Val Loss: 2.07456
Epoch 50, Val Loss: 2.08312
Epoch 51, Val Loss: 2.09328
Epoch 52, Val Loss: 2.07237
Epoch 53, Val Loss: 2.06304
Epoch 54, Val Loss: 2.06712
Epoch 55, Val Loss: 2.08183
Epoch 56, Val Loss: 2.14367
Epoch 57, Val Loss: 2.11956
Epoch 58, Val Loss: 2.08260
Epoch 59, Val Loss: 2.06602
Epoch 60, Val Loss: 2.10073
Epoch 61, Val Loss: 2.08765
Epoch 62, Val Loss: 2.08446
Epoch 63, Val Loss: 2.06656
Epoch 64, Val Loss: 2.09527
Epoch 65, Val Loss: 2.06605
Epoch 66, Val Loss: 2.07357
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.7456, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}
Fitted encoder
Epoch 0, Val Loss: 1.95699
Epoch 1, Val Loss: 1.95573
Epoch 2, Val Loss: 1.95185
Epoch 3, Val Loss: 1.93719
Epoch 4, Val Loss: 1.94454
Epoch 5, Val Loss: 1.94161
Epoch 6, Val Loss: 1.93931
Epoch 7, Val Loss: 1.92610
Epoch 8, Val Loss: 1.91931
Epoch 9, Val Loss: 1.93803
Epoch 10, Val Loss: 1.92747
Epoch 11, Val Loss: 1.91574
Epoch 12, Val Loss: 1.91136
Epoch 13, Val Loss: 1.90030
Epoch 14, Val Loss: 1.90365
Epoch 15, Val Loss: 1.93420
Epoch 16, Val Loss: 1.89223
Epoch 17, Val Loss: 1.92766
Epoch 18, Val Loss: 1.91534
Epoch 19, Val Loss: 1.90534
Epoch 20, Val Loss: 1.91661
Epoch 21, Val Loss: 1.89841
Epoch 22, Val Loss: 1.89874
Epoch 23, Val Loss: 1.90940
Epoch 24, Val Loss: 1.90382
Epoch 25, Val Loss: 1.89776
Epoch 26, Val Loss: 1.89268
Epoch 27, Val Loss: 1.93188
Epoch 28, Val Loss: 1.90043
Epoch 29, Val Loss: 1.89302
Epoch 30, Val Loss: 1.90327
Epoch 31, Val Loss: 1.89871
Epoch 32, Val Loss: 1.90777
Epoch 33, Val Loss: 1.90072
Epoch 34, Val Loss: 1.89736
Epoch 35, Val Loss: 1.90328
Epoch 36, Val Loss: 1.89948
Epoch 37, Val Loss: 1.90718
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.18785, 'Log Loss - std': 0.55775} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}
Fitted encoder
Epoch 0, Val Loss: 2.14255
Epoch 1, Val Loss: 2.13044
Epoch 2, Val Loss: 2.13330
Epoch 3, Val Loss: 2.11758
Epoch 4, Val Loss: 2.10512
Epoch 5, Val Loss: 2.11800
Epoch 6, Val Loss: 2.09006
Epoch 7, Val Loss: 2.10972
Epoch 8, Val Loss: 2.07729
Epoch 9, Val Loss: 2.07814
Epoch 10, Val Loss: 2.09927
Epoch 11, Val Loss: 2.08201
Epoch 12, Val Loss: 2.07123
Epoch 13, Val Loss: 2.09019
Epoch 14, Val Loss: 2.08914
Epoch 15, Val Loss: 2.08080
Epoch 16, Val Loss: 2.07024
Epoch 17, Val Loss: 2.08862
Epoch 18, Val Loss: 2.07446
Epoch 19, Val Loss: 2.06994
Epoch 20, Val Loss: 2.06956
Epoch 21, Val Loss: 2.08116
Epoch 22, Val Loss: 2.07037
Epoch 23, Val Loss: 2.06654
Epoch 24, Val Loss: 2.07528
Epoch 25, Val Loss: 2.10005
Epoch 26, Val Loss: 2.09741
Epoch 27, Val Loss: 2.06743
Epoch 28, Val Loss: 2.07310
Epoch 29, Val Loss: 2.06640
Epoch 30, Val Loss: 2.06766
Epoch 31, Val Loss: 2.07561
Epoch 32, Val Loss: 2.05966
Epoch 33, Val Loss: 2.07018
Epoch 34, Val Loss: 2.06735
Epoch 35, Val Loss: 2.06674
Epoch 36, Val Loss: 2.06007
Epoch 37, Val Loss: 2.02994
Epoch 38, Val Loss: 2.03939
Epoch 39, Val Loss: 2.07260
Epoch 40, Val Loss: 2.06813
Epoch 41, Val Loss: 2.03542
Epoch 42, Val Loss: 2.08411
Epoch 43, Val Loss: 2.06839
Epoch 44, Val Loss: 2.09771
Epoch 45, Val Loss: 2.07772
Epoch 46, Val Loss: 2.07120
Epoch 47, Val Loss: 2.06853
Epoch 48, Val Loss: 2.07170
Epoch 49, Val Loss: 2.06524
Epoch 50, Val Loss: 2.09616
Epoch 51, Val Loss: 2.08311
Epoch 52, Val Loss: 2.14931
Epoch 53, Val Loss: 2.15708
Epoch 54, Val Loss: 2.13503
Epoch 55, Val Loss: 2.09673
Epoch 56, Val Loss: 2.09898
Epoch 57, Val Loss: 2.10929
Epoch 58, Val Loss: 2.11410
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.9591666666666665, 'Log Loss - std': 0.558553646085634} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}
Fitted encoder
Epoch 0, Val Loss: 2.09292
Epoch 1, Val Loss: 2.07993
Epoch 2, Val Loss: 2.05672
Epoch 3, Val Loss: 2.05926
Epoch 4, Val Loss: 2.04776
Epoch 5, Val Loss: 2.05558
Epoch 6, Val Loss: 2.07934
Epoch 7, Val Loss: 2.06099
Epoch 8, Val Loss: 2.03816
Epoch 9, Val Loss: 2.03531
Epoch 10, Val Loss: 2.04705
Epoch 11, Val Loss: 2.03471
Epoch 12, Val Loss: 2.03696
Epoch 13, Val Loss: 2.02496
Epoch 14, Val Loss: 2.03733
Epoch 15, Val Loss: 2.03641
Epoch 16, Val Loss: 2.04452
Epoch 17, Val Loss: 2.02087
Epoch 18, Val Loss: 2.05248
Epoch 19, Val Loss: 2.04495
Epoch 20, Val Loss: 2.01871
Epoch 21, Val Loss: 2.02795
Epoch 22, Val Loss: 2.02794
Epoch 23, Val Loss: 2.02424
Epoch 24, Val Loss: 2.03365
Epoch 25, Val Loss: 2.03216
Epoch 26, Val Loss: 2.01783
Epoch 27, Val Loss: 2.02113
Epoch 28, Val Loss: 2.01553
Epoch 29, Val Loss: 2.02615
Epoch 30, Val Loss: 2.01098
Epoch 31, Val Loss: 2.02410
Epoch 32, Val Loss: 2.02351
Epoch 33, Val Loss: 2.01690
Epoch 34, Val Loss: 2.02489
Epoch 35, Val Loss: 2.01118
Epoch 36, Val Loss: 2.03368
Epoch 37, Val Loss: 2.02170
Epoch 38, Val Loss: 2.02838
Epoch 39, Val Loss: 2.01385
Epoch 40, Val Loss: 2.01826
Epoch 41, Val Loss: 2.01510
Epoch 42, Val Loss: 2.07769
Epoch 43, Val Loss: 2.03027
Epoch 44, Val Loss: 2.01779
Epoch 45, Val Loss: 2.02706
Epoch 46, Val Loss: 2.02017
Epoch 47, Val Loss: 2.03039
Epoch 48, Val Loss: 2.03077
Epoch 49, Val Loss: 2.04035
Epoch 50, Val Loss: 2.01982
Epoch 51, Val Loss: 2.03534
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.96135, 'Log Loss - std': 0.48373642875020284} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}
Fitted encoder
Epoch 0, Val Loss: 1.95680
Epoch 1, Val Loss: 1.94288
Epoch 2, Val Loss: 1.94925
Epoch 3, Val Loss: 1.93390
Epoch 4, Val Loss: 1.95034
Epoch 5, Val Loss: 1.92780
Epoch 6, Val Loss: 1.93618
Epoch 7, Val Loss: 1.92596
Epoch 8, Val Loss: 1.93084
Epoch 9, Val Loss: 1.91193
Epoch 10, Val Loss: 1.92733
Epoch 11, Val Loss: 1.95584
Epoch 12, Val Loss: 1.91634
Epoch 13, Val Loss: 1.91261
Epoch 14, Val Loss: 1.90106
Epoch 15, Val Loss: 1.94029
Epoch 16, Val Loss: 1.91117
Epoch 17, Val Loss: 1.90790
Epoch 18, Val Loss: 1.91163
Epoch 19, Val Loss: 1.90224
Epoch 20, Val Loss: 1.90734
Epoch 21, Val Loss: 1.90462
Epoch 22, Val Loss: 1.91418
Epoch 23, Val Loss: 1.91250
Epoch 24, Val Loss: 1.91411
Epoch 25, Val Loss: 1.92658
Epoch 26, Val Loss: 1.90719
Epoch 27, Val Loss: 1.93337
Epoch 28, Val Loss: 1.92000
Epoch 29, Val Loss: 1.92078
Epoch 30, Val Loss: 1.91716
Epoch 31, Val Loss: 1.90290
Epoch 32, Val Loss: 1.91723
Epoch 33, Val Loss: 1.90990
Epoch 34, Val Loss: 1.91245
Epoch 35, Val Loss: 1.90926
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.9142, 'Log Loss - std': 0.4428241592325333} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 21 finished with value: 2.9142 and parameters: {'p_m': 0.34203226140159554, 'alpha': 1.9117153590973128, 'K': 3, 'beta': 1.0155392293047683}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}
Fitted encoder
Epoch 0, Val Loss: 2.16506
Epoch 1, Val Loss: 2.14610
Epoch 2, Val Loss: 2.13510
Epoch 3, Val Loss: 2.11546
Epoch 4, Val Loss: 2.10482
Epoch 5, Val Loss: 2.10329
Epoch 6, Val Loss: 2.07996
Epoch 7, Val Loss: 2.06684
Epoch 8, Val Loss: 2.09162
Epoch 9, Val Loss: 2.08545
Epoch 10, Val Loss: 2.07536
Epoch 11, Val Loss: 2.08793
Epoch 12, Val Loss: 2.07881
Epoch 13, Val Loss: 2.08686
Epoch 14, Val Loss: 2.08408
Epoch 15, Val Loss: 2.06574
Epoch 16, Val Loss: 2.11528
Epoch 17, Val Loss: 2.13527
Epoch 18, Val Loss: 2.11045
Epoch 19, Val Loss: 2.08496
Epoch 20, Val Loss: 2.13985
Epoch 21, Val Loss: 2.06679
Epoch 22, Val Loss: 2.11924
Epoch 23, Val Loss: 2.06182
Epoch 24, Val Loss: 2.07846
Epoch 25, Val Loss: 2.07667
Epoch 26, Val Loss: 2.09631
Epoch 27, Val Loss: 2.08892
Epoch 28, Val Loss: 2.09931
Epoch 29, Val Loss: 2.09267
Epoch 30, Val Loss: 2.07166
Epoch 31, Val Loss: 2.09294
Epoch 32, Val Loss: 2.08804
Epoch 33, Val Loss: 2.09914
Epoch 34, Val Loss: 2.08663
Epoch 35, Val Loss: 2.07680
Epoch 36, Val Loss: 2.14593
Epoch 37, Val Loss: 2.12319
Epoch 38, Val Loss: 2.12536
Epoch 39, Val Loss: 2.14203
Epoch 40, Val Loss: 2.11158
Epoch 41, Val Loss: 2.11729
Epoch 42, Val Loss: 2.11611
Epoch 43, Val Loss: 2.12828
Epoch 44, Val Loss: 2.07874
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.751, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}
Fitted encoder
Epoch 0, Val Loss: 1.96224
Epoch 1, Val Loss: 1.94065
Epoch 2, Val Loss: 1.93858
Epoch 3, Val Loss: 1.92745
Epoch 4, Val Loss: 1.91845
Epoch 5, Val Loss: 1.95091
Epoch 6, Val Loss: 1.91946
Epoch 7, Val Loss: 1.93829
Epoch 8, Val Loss: 1.90758
Epoch 9, Val Loss: 1.90934
Epoch 10, Val Loss: 1.93554
Epoch 11, Val Loss: 1.96321
Epoch 12, Val Loss: 1.92428
Epoch 13, Val Loss: 1.95482
Epoch 14, Val Loss: 1.93721
Epoch 15, Val Loss: 1.92799
Epoch 16, Val Loss: 1.95622
Epoch 17, Val Loss: 1.96553
Epoch 18, Val Loss: 1.96669
Epoch 19, Val Loss: 1.90825
Epoch 20, Val Loss: 1.94570
Epoch 21, Val Loss: 1.91870
Epoch 22, Val Loss: 1.91088
Epoch 23, Val Loss: 1.91257
Epoch 24, Val Loss: 1.90256
Epoch 25, Val Loss: 1.89836
Epoch 26, Val Loss: 1.92891
Epoch 27, Val Loss: 1.89242
Epoch 28, Val Loss: 1.93806
Epoch 29, Val Loss: 1.96357
Epoch 30, Val Loss: 1.92867
Epoch 31, Val Loss: 1.93191
Epoch 32, Val Loss: 1.90150
Epoch 33, Val Loss: 1.89974
Epoch 34, Val Loss: 1.90441
Epoch 35, Val Loss: 1.89289
Epoch 36, Val Loss: 1.90591
Epoch 37, Val Loss: 1.93325
Epoch 38, Val Loss: 1.91340
Epoch 39, Val Loss: 1.94515
Epoch 40, Val Loss: 1.92665
Epoch 41, Val Loss: 1.91331
Epoch 42, Val Loss: 1.91364
Epoch 43, Val Loss: 1.94493
Epoch 44, Val Loss: 1.91041
Epoch 45, Val Loss: 1.89989
Epoch 46, Val Loss: 1.92125
Epoch 47, Val Loss: 1.89692
Epoch 48, Val Loss: 1.91182
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.85555, 'Log Loss - std': 0.10455000000000014} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}
Fitted encoder
Epoch 0, Val Loss: 2.15968
Epoch 1, Val Loss: 2.14999
Epoch 2, Val Loss: 2.12122
Epoch 3, Val Loss: 2.12843
Epoch 4, Val Loss: 2.15557
Epoch 5, Val Loss: 2.15830
Epoch 6, Val Loss: 2.17545
Epoch 7, Val Loss: 2.17381
Epoch 8, Val Loss: 2.15369
Epoch 9, Val Loss: 2.14323
Epoch 10, Val Loss: 2.15327
Epoch 11, Val Loss: 2.12786
Epoch 12, Val Loss: 2.10344
Epoch 13, Val Loss: 2.18973
Epoch 14, Val Loss: 2.19689
Epoch 15, Val Loss: 2.21563
Epoch 16, Val Loss: 2.17738
Epoch 17, Val Loss: 2.14723
Epoch 18, Val Loss: 2.16423
Epoch 19, Val Loss: 2.14526
Epoch 20, Val Loss: 2.15443
Epoch 21, Val Loss: 2.13417
Epoch 22, Val Loss: 2.11652
Epoch 23, Val Loss: 2.14690
Epoch 24, Val Loss: 2.12222
Epoch 25, Val Loss: 2.10356
Epoch 26, Val Loss: 2.10989
Epoch 27, Val Loss: 2.10878
Epoch 28, Val Loss: 2.10908
Epoch 29, Val Loss: 2.11047
Epoch 30, Val Loss: 2.11119
Epoch 31, Val Loss: 2.10678
Epoch 32, Val Loss: 2.09906
Epoch 33, Val Loss: 2.09726
Epoch 34, Val Loss: 2.09801
Epoch 35, Val Loss: 2.11344
Epoch 36, Val Loss: 2.13563
Epoch 37, Val Loss: 2.09738
Epoch 38, Val Loss: 2.09595
Epoch 39, Val Loss: 2.12393
Epoch 40, Val Loss: 2.11469
Epoch 41, Val Loss: 2.11752
Epoch 42, Val Loss: 2.09956
Epoch 43, Val Loss: 2.06559
Epoch 44, Val Loss: 2.07621
Epoch 45, Val Loss: 2.09413
Epoch 46, Val Loss: 2.09262
Epoch 47, Val Loss: 2.13754
Epoch 48, Val Loss: 2.09645
Epoch 49, Val Loss: 2.09505
Epoch 50, Val Loss: 2.10380
Epoch 51, Val Loss: 2.10640
Epoch 52, Val Loss: 2.10589
Epoch 53, Val Loss: 2.10709
Epoch 54, Val Loss: 2.11253
Epoch 55, Val Loss: 2.08933
Epoch 56, Val Loss: 2.10839
Epoch 57, Val Loss: 2.12001
Epoch 58, Val Loss: 2.13886
Epoch 59, Val Loss: 2.17537
Epoch 60, Val Loss: 2.16571
Epoch 61, Val Loss: 2.16608
Epoch 62, Val Loss: 2.16541
Epoch 63, Val Loss: 2.17756
Epoch 64, Val Loss: 2.23615
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.7541666666666664, 'Log Loss - std': 0.16686610067822513} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}
Fitted encoder
Epoch 0, Val Loss: 2.13854
Epoch 1, Val Loss: 2.13374
Epoch 2, Val Loss: 2.12403
Epoch 3, Val Loss: 2.11995
Epoch 4, Val Loss: 2.11676
Epoch 5, Val Loss: 2.06499
Epoch 6, Val Loss: 2.05285
Epoch 7, Val Loss: 2.05930
Epoch 8, Val Loss: 2.04651
Epoch 9, Val Loss: 2.05205
Epoch 10, Val Loss: 2.05473
Epoch 11, Val Loss: 2.05139
Epoch 12, Val Loss: 2.06321
Epoch 13, Val Loss: 2.06472
Epoch 14, Val Loss: 2.04902
Epoch 15, Val Loss: 2.06690
Epoch 16, Val Loss: 2.06628
Epoch 17, Val Loss: 2.07054
Epoch 18, Val Loss: 2.05530
Epoch 19, Val Loss: 2.04572
Epoch 20, Val Loss: 2.05918
Epoch 21, Val Loss: 2.05854
Epoch 22, Val Loss: 2.05588
Epoch 23, Val Loss: 2.05672
Epoch 24, Val Loss: 2.05669
Epoch 25, Val Loss: 2.05397
Epoch 26, Val Loss: 2.04942
Epoch 27, Val Loss: 2.04892
Epoch 28, Val Loss: 2.05189
Epoch 29, Val Loss: 2.04958
Epoch 30, Val Loss: 2.05840
Epoch 31, Val Loss: 2.04491
Epoch 32, Val Loss: 2.04997
Epoch 33, Val Loss: 2.04200
Epoch 34, Val Loss: 2.04699
Epoch 35, Val Loss: 2.04299
Epoch 36, Val Loss: 2.05660
Epoch 37, Val Loss: 2.04173
Epoch 38, Val Loss: 2.02958
Epoch 39, Val Loss: 2.04001
Epoch 40, Val Loss: 2.04219
Epoch 41, Val Loss: 2.04032
Epoch 42, Val Loss: 2.03234
Epoch 43, Val Loss: 2.08052
Epoch 44, Val Loss: 2.03311
Epoch 45, Val Loss: 2.05650
Epoch 46, Val Loss: 2.02468
Epoch 47, Val Loss: 2.03814
Epoch 48, Val Loss: 2.13358
Epoch 49, Val Loss: 2.09032
Epoch 50, Val Loss: 2.04521
Epoch 51, Val Loss: 2.06709
Epoch 52, Val Loss: 2.03238
Epoch 53, Val Loss: 2.02085
Epoch 54, Val Loss: 2.02556
Epoch 55, Val Loss: 2.02738
Epoch 56, Val Loss: 2.02195
Epoch 57, Val Loss: 2.02556
Epoch 58, Val Loss: 2.02002
Epoch 59, Val Loss: 2.01557
Epoch 60, Val Loss: 2.06424
Epoch 61, Val Loss: 2.03588
Epoch 62, Val Loss: 2.01625
Epoch 63, Val Loss: 2.04438
Epoch 64, Val Loss: 2.01702
Epoch 65, Val Loss: 2.01459
Epoch 66, Val Loss: 2.00437
Epoch 67, Val Loss: 2.00626
Epoch 68, Val Loss: 2.01181
Epoch 69, Val Loss: 2.02710
Epoch 70, Val Loss: 2.02695
Epoch 71, Val Loss: 2.05112
Epoch 72, Val Loss: 2.00395
Epoch 73, Val Loss: 2.05786
Epoch 74, Val Loss: 2.03690
Epoch 75, Val Loss: 2.00807
Epoch 76, Val Loss: 2.02878
Epoch 77, Val Loss: 2.04586
Epoch 78, Val Loss: 2.00511
Epoch 79, Val Loss: 2.00655
Epoch 80, Val Loss: 2.00654
Epoch 81, Val Loss: 2.00878
Epoch 82, Val Loss: 2.04681
Epoch 83, Val Loss: 2.01406
Epoch 84, Val Loss: 2.00838
Epoch 85, Val Loss: 2.02269
Epoch 86, Val Loss: 2.06010
Epoch 87, Val Loss: 2.00674
Epoch 88, Val Loss: 2.02112
Epoch 89, Val Loss: 2.01402
Epoch 90, Val Loss: 2.01093
Epoch 91, Val Loss: 2.01945
Epoch 92, Val Loss: 2.05426
Epoch 93, Val Loss: 2.03691
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.67055, 'Log Loss - std': 0.20459340776281132} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}
Fitted encoder
Epoch 0, Val Loss: 1.95609
Epoch 1, Val Loss: 1.95601
Epoch 2, Val Loss: 1.95176
Epoch 3, Val Loss: 1.91949
Epoch 4, Val Loss: 1.95820
Epoch 5, Val Loss: 1.91269
Epoch 6, Val Loss: 2.01580
Epoch 7, Val Loss: 1.99335
Epoch 8, Val Loss: 1.98939
Epoch 9, Val Loss: 1.90221
Epoch 10, Val Loss: 1.89973
Epoch 11, Val Loss: 1.91782
Epoch 12, Val Loss: 1.89814
Epoch 13, Val Loss: 1.89029
Epoch 14, Val Loss: 1.90054
Epoch 15, Val Loss: 1.91117
Epoch 16, Val Loss: 1.87933
Epoch 17, Val Loss: 1.89850
Epoch 18, Val Loss: 1.88549
Epoch 19, Val Loss: 1.88767
Epoch 20, Val Loss: 1.89623
Epoch 21, Val Loss: 1.89973
Epoch 22, Val Loss: 1.88470
Epoch 23, Val Loss: 1.93113
Epoch 24, Val Loss: 1.93313
Epoch 25, Val Loss: 1.89602
Epoch 26, Val Loss: 1.89718
Epoch 27, Val Loss: 1.88292
Epoch 28, Val Loss: 1.93350
Epoch 29, Val Loss: 1.87914
Epoch 30, Val Loss: 1.87902
Epoch 31, Val Loss: 1.88092
Epoch 32, Val Loss: 1.88201
Epoch 33, Val Loss: 1.88286
Epoch 34, Val Loss: 1.87697
Epoch 35, Val Loss: 1.89320
Epoch 36, Val Loss: 1.87113
Epoch 37, Val Loss: 1.87286
Epoch 38, Val Loss: 1.88662
Epoch 39, Val Loss: 1.88723
Epoch 40, Val Loss: 1.90653
Epoch 41, Val Loss: 1.87656
Epoch 42, Val Loss: 1.88906
Epoch 43, Val Loss: 1.88629
Epoch 44, Val Loss: 1.88751
Epoch 45, Val Loss: 1.88101
Epoch 46, Val Loss: 1.89588
Epoch 47, Val Loss: 1.89691
Epoch 48, Val Loss: 1.88541
Epoch 49, Val Loss: 1.88688
Epoch 50, Val Loss: 1.88245
Epoch 51, Val Loss: 1.90072
Epoch 52, Val Loss: 1.87502
Epoch 53, Val Loss: 1.88404
Epoch 54, Val Loss: 1.88579
Epoch 55, Val Loss: 1.89287
Epoch 56, Val Loss: 1.87100
Epoch 57, Val Loss: 1.88713
Epoch 58, Val Loss: 1.87378
Epoch 59, Val Loss: 1.87778
Epoch 60, Val Loss: 1.88336
Epoch 61, Val Loss: 1.87532
Epoch 62, Val Loss: 1.88810
Epoch 63, Val Loss: 1.88561
Epoch 64, Val Loss: 1.88211
Epoch 65, Val Loss: 1.87685
Epoch 66, Val Loss: 1.87421
Epoch 67, Val Loss: 1.88303
Epoch 68, Val Loss: 1.87035
Epoch 69, Val Loss: 1.90285
Epoch 70, Val Loss: 1.89340
Epoch 71, Val Loss: 1.90254
Epoch 72, Val Loss: 1.87780
Epoch 73, Val Loss: 1.87772
Epoch 74, Val Loss: 1.99454
Epoch 75, Val Loss: 1.94758
Epoch 76, Val Loss: 1.89354
Epoch 77, Val Loss: 1.90744
Epoch 78, Val Loss: 1.90522
Epoch 79, Val Loss: 1.88501
Epoch 80, Val Loss: 1.87602
Epoch 81, Val Loss: 1.89482
Epoch 82, Val Loss: 1.88281
Epoch 83, Val Loss: 1.87948
Epoch 84, Val Loss: 1.88231
Epoch 85, Val Loss: 1.88348
Epoch 86, Val Loss: 1.87690
Epoch 87, Val Loss: 1.87879
Epoch 88, Val Loss: 1.88075
Epoch 89, Val Loss: 1.88070
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.69198, 'Log Loss - std': 0.1879461348365536} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 22 finished with value: 3.69198 and parameters: {'p_m': 0.7169842339870526, 'alpha': 0.5167592817571666, 'K': 3, 'beta': 0.19436402587040064}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}
Fitted encoder
Epoch 0, Val Loss: 2.13756
Epoch 1, Val Loss: 2.13835
Epoch 2, Val Loss: 2.12199
Epoch 3, Val Loss: 2.12048
Epoch 4, Val Loss: 2.11327
Epoch 5, Val Loss: 2.11769
Epoch 6, Val Loss: 2.12337
Epoch 7, Val Loss: 2.14137
Epoch 8, Val Loss: 2.12545
Epoch 9, Val Loss: 2.12315
Epoch 10, Val Loss: 2.15338
Epoch 11, Val Loss: 2.14415
Epoch 12, Val Loss: 2.11763
Epoch 13, Val Loss: 2.13156
Epoch 14, Val Loss: 2.12536
Epoch 15, Val Loss: 2.11693
Epoch 16, Val Loss: 2.09865
Epoch 17, Val Loss: 2.11892
Epoch 18, Val Loss: 2.08509
Epoch 19, Val Loss: 2.08023
Epoch 20, Val Loss: 2.12050
Epoch 21, Val Loss: 2.10007
Epoch 22, Val Loss: 2.08242
Epoch 23, Val Loss: 2.08191
Epoch 24, Val Loss: 2.08837
Epoch 25, Val Loss: 2.10341
Epoch 26, Val Loss: 2.08451
Epoch 27, Val Loss: 2.07420
Epoch 28, Val Loss: 2.07962
Epoch 29, Val Loss: 2.09549
Epoch 30, Val Loss: 2.04040
Epoch 31, Val Loss: 2.02760
Epoch 32, Val Loss: 2.10643
Epoch 33, Val Loss: 2.08874
Epoch 34, Val Loss: 2.06576
Epoch 35, Val Loss: 2.04346
Epoch 36, Val Loss: 2.02876
Epoch 37, Val Loss: 2.04587
Epoch 38, Val Loss: 2.03132
Epoch 39, Val Loss: 2.02519
Epoch 40, Val Loss: 2.04491
Epoch 41, Val Loss: 2.03306
Epoch 42, Val Loss: 2.03512
Epoch 43, Val Loss: 2.01962
Epoch 44, Val Loss: 2.01492
Epoch 45, Val Loss: 2.03830
Epoch 46, Val Loss: 2.04429
Epoch 47, Val Loss: 2.04724
Epoch 48, Val Loss: 2.03624
Epoch 49, Val Loss: 2.03433
Epoch 50, Val Loss: 2.02752
Epoch 51, Val Loss: 2.02081
Epoch 52, Val Loss: 2.02929
Epoch 53, Val Loss: 2.02781
Epoch 54, Val Loss: 2.02403
Epoch 55, Val Loss: 2.02139
Epoch 56, Val Loss: 2.02594
Epoch 57, Val Loss: 2.02840
Epoch 58, Val Loss: 2.03312
Epoch 59, Val Loss: 2.01978
Epoch 60, Val Loss: 2.03446
Epoch 61, Val Loss: 2.02160
Epoch 62, Val Loss: 2.05166
Epoch 63, Val Loss: 2.02505
Epoch 64, Val Loss: 2.02440
Epoch 65, Val Loss: 2.03671
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3172, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}
Fitted encoder
Epoch 0, Val Loss: 1.96516
Epoch 1, Val Loss: 2.04962
Epoch 2, Val Loss: 1.96484
Epoch 3, Val Loss: 1.95874
Epoch 4, Val Loss: 1.94922
Epoch 5, Val Loss: 1.93868
Epoch 6, Val Loss: 1.94153
Epoch 7, Val Loss: 2.04970
Epoch 8, Val Loss: 1.92315
Epoch 9, Val Loss: 1.92015
Epoch 10, Val Loss: 1.92171
Epoch 11, Val Loss: 1.92359
Epoch 12, Val Loss: 1.91523
Epoch 13, Val Loss: 1.92558
Epoch 14, Val Loss: 1.91220
Epoch 15, Val Loss: 1.93866
Epoch 16, Val Loss: 1.90505
Epoch 17, Val Loss: 1.91822
Epoch 18, Val Loss: 1.90137
Epoch 19, Val Loss: 1.91188
Epoch 20, Val Loss: 1.90444
Epoch 21, Val Loss: 1.89464
Epoch 22, Val Loss: 1.90225
Epoch 23, Val Loss: 1.90719
Epoch 24, Val Loss: 1.89883
Epoch 25, Val Loss: 1.89599
Epoch 26, Val Loss: 1.92818
Epoch 27, Val Loss: 1.90798
Epoch 28, Val Loss: 1.91523
Epoch 29, Val Loss: 1.90839
Epoch 30, Val Loss: 1.90291
Epoch 31, Val Loss: 1.90903
Epoch 32, Val Loss: 1.90163
Epoch 33, Val Loss: 1.89359
Epoch 34, Val Loss: 1.90153
Epoch 35, Val Loss: 1.90585
Epoch 36, Val Loss: 1.91973
Epoch 37, Val Loss: 1.91130
Epoch 38, Val Loss: 1.90011
Epoch 39, Val Loss: 1.90618
Epoch 40, Val Loss: 1.91530
Epoch 41, Val Loss: 1.88863
Epoch 42, Val Loss: 1.90689
Epoch 43, Val Loss: 1.92987
Epoch 44, Val Loss: 1.94781
Epoch 45, Val Loss: 1.91539
Epoch 46, Val Loss: 1.91273
Epoch 47, Val Loss: 1.89830
Epoch 48, Val Loss: 1.90202
Epoch 49, Val Loss: 1.90067
Epoch 50, Val Loss: 1.94397
Epoch 51, Val Loss: 1.90667
Epoch 52, Val Loss: 1.90639
Epoch 53, Val Loss: 1.91440
Epoch 54, Val Loss: 1.96842
Epoch 55, Val Loss: 2.03260
Epoch 56, Val Loss: 1.94802
Epoch 57, Val Loss: 1.93548
Epoch 58, Val Loss: 1.91866
Epoch 59, Val Loss: 1.90359
Epoch 60, Val Loss: 1.91884
Epoch 61, Val Loss: 1.93134
Epoch 62, Val Loss: 2.04737
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.7055499999999997, 'Log Loss - std': 0.38834999999999975} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}
Fitted encoder
Epoch 0, Val Loss: 2.16063
Epoch 1, Val Loss: 2.12980
Epoch 2, Val Loss: 2.11997
Epoch 3, Val Loss: 2.15103
Epoch 4, Val Loss: 2.15688
Epoch 5, Val Loss: 2.11810
Epoch 6, Val Loss: 2.11909
Epoch 7, Val Loss: 2.12504
Epoch 8, Val Loss: 2.12097
Epoch 9, Val Loss: 2.13098
Epoch 10, Val Loss: 2.10840
Epoch 11, Val Loss: 2.13273
Epoch 12, Val Loss: 2.10514
Epoch 13, Val Loss: 2.11355
Epoch 14, Val Loss: 2.10800
Epoch 15, Val Loss: 2.09681
Epoch 16, Val Loss: 2.09980
Epoch 17, Val Loss: 2.08509
Epoch 18, Val Loss: 2.08044
Epoch 19, Val Loss: 2.07366
Epoch 20, Val Loss: 2.07449
Epoch 21, Val Loss: 2.07038
Epoch 22, Val Loss: 2.06386
Epoch 23, Val Loss: 2.07424
Epoch 24, Val Loss: 2.08729
Epoch 25, Val Loss: 2.05553
Epoch 26, Val Loss: 2.06435
Epoch 27, Val Loss: 2.06258
Epoch 28, Val Loss: 2.06157
Epoch 29, Val Loss: 2.06676
Epoch 30, Val Loss: 2.06352
Epoch 31, Val Loss: 2.06311
Epoch 32, Val Loss: 2.07643
Epoch 33, Val Loss: 2.06767
Epoch 34, Val Loss: 2.06370
Epoch 35, Val Loss: 2.06976
Epoch 36, Val Loss: 2.08384
Epoch 37, Val Loss: 2.08737
Epoch 38, Val Loss: 2.09237
Epoch 39, Val Loss: 2.06388
Epoch 40, Val Loss: 2.09027
Epoch 41, Val Loss: 2.07219
Epoch 42, Val Loss: 2.05631
Epoch 43, Val Loss: 2.07750
Epoch 44, Val Loss: 2.07805
Epoch 45, Val Loss: 2.04948
Epoch 46, Val Loss: 2.08021
Epoch 47, Val Loss: 2.05411
Epoch 48, Val Loss: 2.06431
Epoch 49, Val Loss: 2.07188
Epoch 50, Val Loss: 2.05669
Epoch 51, Val Loss: 2.05819
Epoch 52, Val Loss: 2.07630
Epoch 53, Val Loss: 2.05882
Epoch 54, Val Loss: 2.05384
Epoch 55, Val Loss: 2.05386
Epoch 56, Val Loss: 2.06361
Epoch 57, Val Loss: 2.07349
Epoch 58, Val Loss: 2.07524
Epoch 59, Val Loss: 2.09976
Epoch 60, Val Loss: 2.05246
Epoch 61, Val Loss: 2.07016
Epoch 62, Val Loss: 2.12318
Epoch 63, Val Loss: 2.06897
Epoch 64, Val Loss: 2.06841
Epoch 65, Val Loss: 2.05309
Epoch 66, Val Loss: 2.06013
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.659233333333333, 'Log Loss - std': 0.32378122586435126} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}
Fitted encoder
Epoch 0, Val Loss: 2.06517
Epoch 1, Val Loss: 2.05331
Epoch 2, Val Loss: 2.05061
Epoch 3, Val Loss: 2.03354
Epoch 4, Val Loss: 2.02820
Epoch 5, Val Loss: 2.03942
Epoch 6, Val Loss: 2.11605
Epoch 7, Val Loss: 2.10556
Epoch 8, Val Loss: 2.11294
Epoch 9, Val Loss: 2.16632
Epoch 10, Val Loss: 2.14554
Epoch 11, Val Loss: 2.07282
Epoch 12, Val Loss: 2.03760
Epoch 13, Val Loss: 2.04340
Epoch 14, Val Loss: 2.02895
Epoch 15, Val Loss: 2.08557
Epoch 16, Val Loss: 2.04394
Epoch 17, Val Loss: 2.04639
Epoch 18, Val Loss: 2.03182
Epoch 19, Val Loss: 2.02985
Epoch 20, Val Loss: 2.02603
Epoch 21, Val Loss: 2.02340
Epoch 22, Val Loss: 2.04806
Epoch 23, Val Loss: 2.08035
Epoch 24, Val Loss: 2.08931
Epoch 25, Val Loss: 2.09381
Epoch 26, Val Loss: 2.08681
Epoch 27, Val Loss: 2.08556
Epoch 28, Val Loss: 2.11153
Epoch 29, Val Loss: 2.08268
Epoch 30, Val Loss: 2.07419
Epoch 31, Val Loss: 2.11221
Epoch 32, Val Loss: 2.09562
Epoch 33, Val Loss: 2.13106
Epoch 34, Val Loss: 2.13474
Epoch 35, Val Loss: 2.13025
Epoch 36, Val Loss: 2.08740
Epoch 37, Val Loss: 2.13071
Epoch 38, Val Loss: 2.11538
Epoch 39, Val Loss: 2.08328
Epoch 40, Val Loss: 2.07957
Epoch 41, Val Loss: 2.08534
Epoch 42, Val Loss: 2.10115
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.46425, 'Log Loss - std': 0.438954681601643} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}
Fitted encoder
Epoch 0, Val Loss: 1.96625
Epoch 1, Val Loss: 1.96040
Epoch 2, Val Loss: 2.01253
Epoch 3, Val Loss: 1.99608
Epoch 4, Val Loss: 2.01502
Epoch 5, Val Loss: 1.94329
Epoch 6, Val Loss: 1.91231
Epoch 7, Val Loss: 1.92023
Epoch 8, Val Loss: 1.91371
Epoch 9, Val Loss: 1.89725
Epoch 10, Val Loss: 1.88300
Epoch 11, Val Loss: 1.88346
Epoch 12, Val Loss: 1.91360
Epoch 13, Val Loss: 1.88705
Epoch 14, Val Loss: 1.90373
Epoch 15, Val Loss: 1.87370
Epoch 16, Val Loss: 1.89154
Epoch 17, Val Loss: 1.89303
Epoch 18, Val Loss: 1.89226
Epoch 19, Val Loss: 1.87261
Epoch 20, Val Loss: 1.93419
Epoch 21, Val Loss: 1.93139
Epoch 22, Val Loss: 1.90691
Epoch 23, Val Loss: 1.90410
Epoch 24, Val Loss: 1.87243
Epoch 25, Val Loss: 1.90730
Epoch 26, Val Loss: 1.88046
Epoch 27, Val Loss: 1.89566
Epoch 28, Val Loss: 1.89080
Epoch 29, Val Loss: 1.88420
Epoch 30, Val Loss: 1.88583
Epoch 31, Val Loss: 1.89494
Epoch 32, Val Loss: 1.87223
Epoch 33, Val Loss: 1.87588
Epoch 34, Val Loss: 1.88793
Epoch 35, Val Loss: 1.89550
Epoch 36, Val Loss: 1.88069
Epoch 37, Val Loss: 1.87479
Epoch 38, Val Loss: 1.87654
Epoch 39, Val Loss: 1.87938
Epoch 40, Val Loss: 1.89185
Epoch 41, Val Loss: 1.87810
Epoch 42, Val Loss: 1.88709
Epoch 43, Val Loss: 1.87090
Epoch 44, Val Loss: 1.88519
Epoch 45, Val Loss: 1.90243
Epoch 46, Val Loss: 1.89981
Epoch 47, Val Loss: 1.88004
Epoch 48, Val Loss: 1.87556
Epoch 49, Val Loss: 1.87335
Epoch 50, Val Loss: 1.99106
Epoch 51, Val Loss: 1.96506
Epoch 52, Val Loss: 1.93697
Epoch 53, Val Loss: 1.93652
Epoch 54, Val Loss: 1.89484
Epoch 55, Val Loss: 1.89604
Epoch 56, Val Loss: 1.88424
Epoch 57, Val Loss: 1.90121
Epoch 58, Val Loss: 1.89096
Epoch 59, Val Loss: 1.89043
Epoch 60, Val Loss: 1.88290
Epoch 61, Val Loss: 1.90181
Epoch 62, Val Loss: 1.96610
Epoch 63, Val Loss: 2.06862
Epoch 64, Val Loss: 2.08790
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.5394799999999997, 'Log Loss - std': 0.42045592111421126} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 23 finished with value: 3.5394799999999997 and parameters: {'p_m': 0.7465311223620954, 'alpha': 0.1962894994320763, 'K': 3, 'beta': 0.17992610012284255}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}
Fitted encoder
Epoch 0, Val Loss: 2.14330
Epoch 1, Val Loss: 2.12859
Epoch 2, Val Loss: 2.13968
Epoch 3, Val Loss: 2.14286
Epoch 4, Val Loss: 2.14048
Epoch 5, Val Loss: 2.12353
Epoch 6, Val Loss: 2.15517
Epoch 7, Val Loss: 2.13648
Epoch 8, Val Loss: 2.13970
Epoch 9, Val Loss: 2.10644
Epoch 10, Val Loss: 2.12977
Epoch 11, Val Loss: 2.09736
Epoch 12, Val Loss: 2.09260
Epoch 13, Val Loss: 2.11211
Epoch 14, Val Loss: 2.08886
Epoch 15, Val Loss: 2.06475
Epoch 16, Val Loss: 2.10217
Epoch 17, Val Loss: 2.06504
Epoch 18, Val Loss: 2.08452
Epoch 19, Val Loss: 2.09370
Epoch 20, Val Loss: 2.07326
Epoch 21, Val Loss: 2.07865
Epoch 22, Val Loss: 2.05384
Epoch 23, Val Loss: 2.06735
Epoch 24, Val Loss: 2.09242
Epoch 25, Val Loss: 2.07784
Epoch 26, Val Loss: 2.07935
Epoch 27, Val Loss: 2.07238
Epoch 28, Val Loss: 2.05128
Epoch 29, Val Loss: 2.04059
Epoch 30, Val Loss: 2.03776
Epoch 31, Val Loss: 2.08805
Epoch 32, Val Loss: 2.05174
Epoch 33, Val Loss: 2.05831
Epoch 34, Val Loss: 2.03436
Epoch 35, Val Loss: 2.08519
Epoch 36, Val Loss: 2.06086
Epoch 37, Val Loss: 2.08038
Epoch 38, Val Loss: 2.05898
Epoch 39, Val Loss: 2.06158
Epoch 40, Val Loss: 2.05720
Epoch 41, Val Loss: 2.04226
Epoch 42, Val Loss: 2.04089
Epoch 43, Val Loss: 2.05728
Epoch 44, Val Loss: 2.04313
Epoch 45, Val Loss: 2.05764
Epoch 46, Val Loss: 2.04591
Epoch 47, Val Loss: 2.06447
Epoch 48, Val Loss: 2.04346
Epoch 49, Val Loss: 2.06148
Epoch 50, Val Loss: 2.04962
Epoch 51, Val Loss: 2.07145
Epoch 52, Val Loss: 2.08124
Epoch 53, Val Loss: 2.04659
Epoch 54, Val Loss: 2.06802
Epoch 55, Val Loss: 2.06237
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.9583, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}
Fitted encoder
Epoch 0, Val Loss: 1.96851
Epoch 1, Val Loss: 1.96469
Epoch 2, Val Loss: 1.94808
Epoch 3, Val Loss: 1.95654
Epoch 4, Val Loss: 1.94465
Epoch 5, Val Loss: 1.95016
Epoch 6, Val Loss: 1.95046
Epoch 7, Val Loss: 1.94661
Epoch 8, Val Loss: 1.97320
Epoch 9, Val Loss: 1.94302
Epoch 10, Val Loss: 1.94920
Epoch 11, Val Loss: 1.95324
Epoch 12, Val Loss: 1.93943
Epoch 13, Val Loss: 1.95740
Epoch 14, Val Loss: 1.94148
Epoch 15, Val Loss: 1.93486
Epoch 16, Val Loss: 1.93259
Epoch 17, Val Loss: 1.93243
Epoch 18, Val Loss: 1.92335
Epoch 19, Val Loss: 2.01046
Epoch 20, Val Loss: 1.92082
Epoch 21, Val Loss: 1.92042
Epoch 22, Val Loss: 2.01169
Epoch 23, Val Loss: 1.95126
Epoch 24, Val Loss: 1.94223
Epoch 25, Val Loss: 1.95887
Epoch 26, Val Loss: 1.91651
Epoch 27, Val Loss: 1.92957
Epoch 28, Val Loss: 1.91677
Epoch 29, Val Loss: 1.92652
Epoch 30, Val Loss: 1.92391
Epoch 31, Val Loss: 1.93424
Epoch 32, Val Loss: 1.92187
Epoch 33, Val Loss: 1.92533
Epoch 34, Val Loss: 1.90659
Epoch 35, Val Loss: 1.90777
Epoch 36, Val Loss: 1.95148
Epoch 37, Val Loss: 1.91807
Epoch 38, Val Loss: 1.91643
Epoch 39, Val Loss: 1.92376
Epoch 40, Val Loss: 1.90824
Epoch 41, Val Loss: 1.92010
Epoch 42, Val Loss: 1.91929
Epoch 43, Val Loss: 1.91876
Epoch 44, Val Loss: 1.93182
Epoch 45, Val Loss: 1.93516
Epoch 46, Val Loss: 1.90354
Epoch 47, Val Loss: 1.90622
Epoch 48, Val Loss: 1.89765
Epoch 49, Val Loss: 1.90595
Epoch 50, Val Loss: 1.90704
Epoch 51, Val Loss: 1.93111
Epoch 52, Val Loss: 1.90056
Epoch 53, Val Loss: 1.91211
Epoch 54, Val Loss: 1.90798
Epoch 55, Val Loss: 1.91406
Epoch 56, Val Loss: 1.91798
Epoch 57, Val Loss: 1.91021
Epoch 58, Val Loss: 1.91343
Epoch 59, Val Loss: 1.89915
Epoch 60, Val Loss: 1.89919
Epoch 61, Val Loss: 1.91100
Epoch 62, Val Loss: 1.91078
Epoch 63, Val Loss: 1.90383
Epoch 64, Val Loss: 1.92503
Epoch 65, Val Loss: 1.91700
Epoch 66, Val Loss: 1.91827
Epoch 67, Val Loss: 1.89225
Epoch 68, Val Loss: 1.89924
Epoch 69, Val Loss: 1.92340
Epoch 70, Val Loss: 1.92106
Epoch 71, Val Loss: 1.89403
Epoch 72, Val Loss: 1.91059
Epoch 73, Val Loss: 1.89492
Epoch 74, Val Loss: 1.91880
Epoch 75, Val Loss: 1.89491
Epoch 76, Val Loss: 1.90788
Epoch 77, Val Loss: 1.89824
Epoch 78, Val Loss: 1.89422
Epoch 79, Val Loss: 1.89353
Epoch 80, Val Loss: 1.90446
Epoch 81, Val Loss: 1.90029
Epoch 82, Val Loss: 1.89479
Epoch 83, Val Loss: 1.91080
Epoch 84, Val Loss: 1.91071
Epoch 85, Val Loss: 1.90165
Epoch 86, Val Loss: 1.91668
Epoch 87, Val Loss: 1.90423
Epoch 88, Val Loss: 1.90101
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.03845, 'Log Loss - std': 0.08014999999999994} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}
Fitted encoder
Epoch 0, Val Loss: 2.14097
Epoch 1, Val Loss: 2.14493
Epoch 2, Val Loss: 2.12222
Epoch 3, Val Loss: 2.11406
Epoch 4, Val Loss: 2.11445
Epoch 5, Val Loss: 2.10879
Epoch 6, Val Loss: 2.11124
Epoch 7, Val Loss: 2.11721
Epoch 8, Val Loss: 2.11562
Epoch 9, Val Loss: 2.11478
Epoch 10, Val Loss: 2.10829
Epoch 11, Val Loss: 2.09577
Epoch 12, Val Loss: 2.10813
Epoch 13, Val Loss: 2.10003
Epoch 14, Val Loss: 2.10113
Epoch 15, Val Loss: 2.09016
Epoch 16, Val Loss: 2.08324
Epoch 17, Val Loss: 2.08992
Epoch 18, Val Loss: 2.10271
Epoch 19, Val Loss: 2.11771
Epoch 20, Val Loss: 2.11428
Epoch 21, Val Loss: 2.10071
Epoch 22, Val Loss: 2.10701
Epoch 23, Val Loss: 2.08562
Epoch 24, Val Loss: 2.11479
Epoch 25, Val Loss: 2.08731
Epoch 26, Val Loss: 2.08599
Epoch 27, Val Loss: 2.08937
Epoch 28, Val Loss: 2.09518
Epoch 29, Val Loss: 2.10276
Epoch 30, Val Loss: 2.09115
Epoch 31, Val Loss: 2.10071
Epoch 32, Val Loss: 2.09594
Epoch 33, Val Loss: 2.08419
Epoch 34, Val Loss: 2.08338
Epoch 35, Val Loss: 2.09231
Epoch 36, Val Loss: 2.08301
Epoch 37, Val Loss: 2.08030
Epoch 38, Val Loss: 2.08282
Epoch 39, Val Loss: 2.10102
Epoch 40, Val Loss: 2.07576
Epoch 41, Val Loss: 2.06763
Epoch 42, Val Loss: 2.07359
Epoch 43, Val Loss: 2.08625
Epoch 44, Val Loss: 2.07966
Epoch 45, Val Loss: 2.09064
Epoch 46, Val Loss: 2.10739
Epoch 47, Val Loss: 2.09505
Epoch 48, Val Loss: 2.09426
Epoch 49, Val Loss: 2.11640
Epoch 50, Val Loss: 2.11979
Epoch 51, Val Loss: 2.11520
Epoch 52, Val Loss: 2.09553
Epoch 53, Val Loss: 2.09289
Epoch 54, Val Loss: 2.07526
Epoch 55, Val Loss: 2.09449
Epoch 56, Val Loss: 2.09216
Epoch 57, Val Loss: 2.09169
Epoch 58, Val Loss: 2.08415
Epoch 59, Val Loss: 2.09245
Epoch 60, Val Loss: 2.07286
Epoch 61, Val Loss: 2.09004
Epoch 62, Val Loss: 2.07173
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2313666666666667, 'Log Loss - std': 0.2805643637781218} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}
Fitted encoder
Epoch 0, Val Loss: 2.09324
Epoch 1, Val Loss: 2.06604
Epoch 2, Val Loss: 2.06931
Epoch 3, Val Loss: 2.06182
Epoch 4, Val Loss: 2.06932
Epoch 5, Val Loss: 2.09321
Epoch 6, Val Loss: 2.05428
Epoch 7, Val Loss: 2.07021
Epoch 8, Val Loss: 2.05863
Epoch 9, Val Loss: 2.07148
Epoch 10, Val Loss: 2.05612
Epoch 11, Val Loss: 2.05781
Epoch 12, Val Loss: 2.04405
Epoch 13, Val Loss: 2.04030
Epoch 14, Val Loss: 2.04505
Epoch 15, Val Loss: 2.04752
Epoch 16, Val Loss: 2.05208
Epoch 17, Val Loss: 2.05339
Epoch 18, Val Loss: 2.06746
Epoch 19, Val Loss: 2.05718
Epoch 20, Val Loss: 2.04665
Epoch 21, Val Loss: 2.02096
Epoch 22, Val Loss: 2.02001
Epoch 23, Val Loss: 2.03678
Epoch 24, Val Loss: 2.04161
Epoch 25, Val Loss: 2.02790
Epoch 26, Val Loss: 2.04680
Epoch 27, Val Loss: 2.03328
Epoch 28, Val Loss: 2.03409
Epoch 29, Val Loss: 2.03260
Epoch 30, Val Loss: 2.04702
Epoch 31, Val Loss: 2.01201
Epoch 32, Val Loss: 2.03214
Epoch 33, Val Loss: 2.02053
Epoch 34, Val Loss: 2.06526
Epoch 35, Val Loss: 2.03072
Epoch 36, Val Loss: 2.01759
Epoch 37, Val Loss: 2.02858
Epoch 38, Val Loss: 2.02345
Epoch 39, Val Loss: 2.02080
Epoch 40, Val Loss: 2.01576
Epoch 41, Val Loss: 2.04441
Epoch 42, Val Loss: 2.01721
Epoch 43, Val Loss: 2.03130
Epoch 44, Val Loss: 2.04236
Epoch 45, Val Loss: 2.04796
Epoch 46, Val Loss: 2.03506
Epoch 47, Val Loss: 2.01360
Epoch 48, Val Loss: 2.05868
Epoch 49, Val Loss: 2.03677
Epoch 50, Val Loss: 2.03723
Epoch 51, Val Loss: 2.03906
Epoch 52, Val Loss: 2.03259
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.117775, 'Log Loss - std': 0.312644321674007} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}
Fitted encoder
Epoch 0, Val Loss: 1.95594
Epoch 1, Val Loss: 1.96100
Epoch 2, Val Loss: 1.95877
Epoch 3, Val Loss: 1.94047
Epoch 4, Val Loss: 1.95526
Epoch 5, Val Loss: 1.94497
Epoch 6, Val Loss: 1.95153
Epoch 7, Val Loss: 1.93710
Epoch 8, Val Loss: 1.95283
Epoch 9, Val Loss: 1.96355
Epoch 10, Val Loss: 1.94110
Epoch 11, Val Loss: 1.91838
Epoch 12, Val Loss: 1.94604
Epoch 13, Val Loss: 1.94453
Epoch 14, Val Loss: 1.92094
Epoch 15, Val Loss: 1.94330
Epoch 16, Val Loss: 1.92099
Epoch 17, Val Loss: 1.91298
Epoch 18, Val Loss: 1.90181
Epoch 19, Val Loss: 1.92802
Epoch 20, Val Loss: 1.90515
Epoch 21, Val Loss: 1.95110
Epoch 22, Val Loss: 1.92856
Epoch 23, Val Loss: 1.92132
Epoch 24, Val Loss: 1.92233
Epoch 25, Val Loss: 1.90137
Epoch 26, Val Loss: 1.89218
Epoch 27, Val Loss: 1.94082
Epoch 28, Val Loss: 1.95100
Epoch 29, Val Loss: 1.90895
Epoch 30, Val Loss: 1.88930
Epoch 31, Val Loss: 1.91338
Epoch 32, Val Loss: 1.92086
Epoch 33, Val Loss: 1.93120
Epoch 34, Val Loss: 1.88918
Epoch 35, Val Loss: 1.87635
Epoch 36, Val Loss: 1.90502
Epoch 37, Val Loss: 1.91407
Epoch 38, Val Loss: 1.89029
Epoch 39, Val Loss: 1.89473
Epoch 40, Val Loss: 1.92233
Epoch 41, Val Loss: 1.88367
Epoch 42, Val Loss: 1.89614
Epoch 43, Val Loss: 1.96376
Epoch 44, Val Loss: 1.88696
Epoch 45, Val Loss: 1.90553
Epoch 46, Val Loss: 1.90313
Epoch 47, Val Loss: 1.88695
Epoch 48, Val Loss: 1.88816
Epoch 49, Val Loss: 1.90255
Epoch 50, Val Loss: 1.88942
Epoch 51, Val Loss: 1.92068
Epoch 52, Val Loss: 1.87941
Epoch 53, Val Loss: 1.87963
Epoch 54, Val Loss: 1.88831
Epoch 55, Val Loss: 1.92803
Epoch 56, Val Loss: 1.88774
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.12044, 'Log Loss - std': 0.2796883737304788} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 24 finished with value: 3.12044 and parameters: {'p_m': 0.6426457774395251, 'alpha': 2.8324586517316597, 'K': 3, 'beta': 2.3829523162033257}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}
Fitted encoder
Epoch 0, Val Loss: 2.13114
Epoch 1, Val Loss: 2.13626
Epoch 2, Val Loss: 2.12544
Epoch 3, Val Loss: 2.12916
Epoch 4, Val Loss: 2.13237
Epoch 5, Val Loss: 2.12123
Epoch 6, Val Loss: 2.12051
Epoch 7, Val Loss: 2.12266
Epoch 8, Val Loss: 2.13172
Epoch 9, Val Loss: 2.11511
Epoch 10, Val Loss: 2.12015
Epoch 11, Val Loss: 2.11546
Epoch 12, Val Loss: 2.11228
Epoch 13, Val Loss: 2.11021
Epoch 14, Val Loss: 2.11958
Epoch 15, Val Loss: 2.13409
Epoch 16, Val Loss: 2.11494
Epoch 17, Val Loss: 2.11870
Epoch 18, Val Loss: 2.14118
Epoch 19, Val Loss: 2.10862
Epoch 20, Val Loss: 2.09334
Epoch 21, Val Loss: 2.10566
Epoch 22, Val Loss: 2.09296
Epoch 23, Val Loss: 2.11890
Epoch 24, Val Loss: 2.11069
Epoch 25, Val Loss: 2.10502
Epoch 26, Val Loss: 2.10261
Epoch 27, Val Loss: 2.12216
Epoch 28, Val Loss: 2.13660
Epoch 29, Val Loss: 2.10028
Epoch 30, Val Loss: 2.08376
Epoch 31, Val Loss: 2.09838
Epoch 32, Val Loss: 2.07166
Epoch 33, Val Loss: 2.13620
Epoch 34, Val Loss: 2.09586
Epoch 35, Val Loss: 2.08357
Epoch 36, Val Loss: 2.10993
Epoch 37, Val Loss: 2.12575
Epoch 38, Val Loss: 2.08570
Epoch 39, Val Loss: 2.07666
Epoch 40, Val Loss: 2.06649
Epoch 41, Val Loss: 2.13084
Epoch 42, Val Loss: 2.11591
Epoch 43, Val Loss: 2.08521
Epoch 44, Val Loss: 2.08485
Epoch 45, Val Loss: 2.07486
Epoch 46, Val Loss: 2.08350
Epoch 47, Val Loss: 2.07683
Epoch 48, Val Loss: 2.08624
Epoch 49, Val Loss: 2.10461
Epoch 50, Val Loss: 2.07632
Epoch 51, Val Loss: 2.07860
Epoch 52, Val Loss: 2.07165
Epoch 53, Val Loss: 2.07377
Epoch 54, Val Loss: 2.07776
Epoch 55, Val Loss: 2.10351
Epoch 56, Val Loss: 2.08470
Epoch 57, Val Loss: 2.07662
Epoch 58, Val Loss: 2.06437
Epoch 59, Val Loss: 2.12952
Epoch 60, Val Loss: 2.12160
Epoch 61, Val Loss: 2.10501
Epoch 62, Val Loss: 2.09141
Epoch 63, Val Loss: 2.07301
Epoch 64, Val Loss: 2.06585
Epoch 65, Val Loss: 2.06159
Epoch 66, Val Loss: 2.05784
Epoch 67, Val Loss: 2.07676
Epoch 68, Val Loss: 2.07628
Epoch 69, Val Loss: 2.11297
Epoch 70, Val Loss: 2.06153
Epoch 71, Val Loss: 2.09017
Epoch 72, Val Loss: 2.07643
Epoch 73, Val Loss: 2.09904
Epoch 74, Val Loss: 2.07484
Epoch 75, Val Loss: 2.07033
Epoch 76, Val Loss: 2.07085
Epoch 77, Val Loss: 2.06906
Epoch 78, Val Loss: 2.07431
Epoch 79, Val Loss: 2.07210
Epoch 80, Val Loss: 2.06982
Epoch 81, Val Loss: 2.07077
Epoch 82, Val Loss: 2.08375
Epoch 83, Val Loss: 2.06840
Epoch 84, Val Loss: 2.08144
Epoch 85, Val Loss: 2.08685
Epoch 86, Val Loss: 2.07241
Epoch 87, Val Loss: 2.13879
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.7738, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}
Fitted encoder
Epoch 0, Val Loss: 1.95822
Epoch 1, Val Loss: 1.95120
Epoch 2, Val Loss: 1.96524
Epoch 3, Val Loss: 1.95236
Epoch 4, Val Loss: 1.96024
Epoch 5, Val Loss: 1.96775
Epoch 6, Val Loss: 1.95156
Epoch 7, Val Loss: 1.93551
Epoch 8, Val Loss: 1.95241
Epoch 9, Val Loss: 1.94924
Epoch 10, Val Loss: 1.94668
Epoch 11, Val Loss: 1.93989
Epoch 12, Val Loss: 1.94028
Epoch 13, Val Loss: 1.94252
Epoch 14, Val Loss: 1.94799
Epoch 15, Val Loss: 1.93261
Epoch 16, Val Loss: 1.98885
Epoch 17, Val Loss: 1.93665
Epoch 18, Val Loss: 1.92861
Epoch 19, Val Loss: 1.93698
Epoch 20, Val Loss: 1.93978
Epoch 21, Val Loss: 1.93598
Epoch 22, Val Loss: 1.91290
Epoch 23, Val Loss: 1.94526
Epoch 24, Val Loss: 1.93653
Epoch 25, Val Loss: 1.92624
Epoch 26, Val Loss: 1.92845
Epoch 27, Val Loss: 1.92733
Epoch 28, Val Loss: 1.92116
Epoch 29, Val Loss: 1.90976
Epoch 30, Val Loss: 1.92285
Epoch 31, Val Loss: 1.91877
Epoch 32, Val Loss: 1.90951
Epoch 33, Val Loss: 1.92530
Epoch 34, Val Loss: 1.92480
Epoch 35, Val Loss: 1.92272
Epoch 36, Val Loss: 1.91393
Epoch 37, Val Loss: 1.93194
Epoch 38, Val Loss: 1.91728
Epoch 39, Val Loss: 1.91704
Epoch 40, Val Loss: 1.94732
Epoch 41, Val Loss: 1.94285
Epoch 42, Val Loss: 1.91790
Epoch 43, Val Loss: 1.90206
Epoch 44, Val Loss: 1.90853
Epoch 45, Val Loss: 1.91089
Epoch 46, Val Loss: 1.93765
Epoch 47, Val Loss: 1.90839
Epoch 48, Val Loss: 1.90331
Epoch 49, Val Loss: 1.90891
Epoch 50, Val Loss: 1.90666
Epoch 51, Val Loss: 1.90826
Epoch 52, Val Loss: 1.90596
Epoch 53, Val Loss: 1.90663
Epoch 54, Val Loss: 1.90558
Epoch 55, Val Loss: 1.90587
Epoch 56, Val Loss: 1.92293
Epoch 57, Val Loss: 1.90969
Epoch 58, Val Loss: 1.91478
Epoch 59, Val Loss: 1.92000
Epoch 60, Val Loss: 1.89595
Epoch 61, Val Loss: 1.90326
Epoch 62, Val Loss: 1.91620
Epoch 63, Val Loss: 1.90535
Epoch 64, Val Loss: 1.91317
Epoch 65, Val Loss: 1.91578
Epoch 66, Val Loss: 1.94223
Epoch 67, Val Loss: 1.94213
Epoch 68, Val Loss: 1.95681
Epoch 69, Val Loss: 1.95823
Epoch 70, Val Loss: 1.94833
Epoch 71, Val Loss: 1.94443
Epoch 72, Val Loss: 1.94315
Epoch 73, Val Loss: 1.90126
Epoch 74, Val Loss: 1.90241
Epoch 75, Val Loss: 1.89776
Epoch 76, Val Loss: 1.94291
Epoch 77, Val Loss: 1.93293
Epoch 78, Val Loss: 1.91783
Epoch 79, Val Loss: 1.89765
Epoch 80, Val Loss: 1.92111
Epoch 81, Val Loss: 1.91143
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.46345, 'Log Loss - std': 0.3103500000000001} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}
Fitted encoder
Epoch 0, Val Loss: 2.14593
Epoch 1, Val Loss: 2.13999
Epoch 2, Val Loss: 2.11633
Epoch 3, Val Loss: 2.11651
Epoch 4, Val Loss: 2.11592
Epoch 5, Val Loss: 2.10672
Epoch 6, Val Loss: 2.11389
Epoch 7, Val Loss: 2.10664
Epoch 8, Val Loss: 2.09213
Epoch 9, Val Loss: 2.09494
Epoch 10, Val Loss: 2.08838
Epoch 11, Val Loss: 2.09067
Epoch 12, Val Loss: 2.07765
Epoch 13, Val Loss: 2.10688
Epoch 14, Val Loss: 2.07450
Epoch 15, Val Loss: 2.09816
Epoch 16, Val Loss: 2.07215
Epoch 17, Val Loss: 2.07613
Epoch 18, Val Loss: 2.07474
Epoch 19, Val Loss: 2.08466
Epoch 20, Val Loss: 2.06531
Epoch 21, Val Loss: 2.07124
Epoch 22, Val Loss: 2.12810
Epoch 23, Val Loss: 2.15110
Epoch 24, Val Loss: 2.11712
Epoch 25, Val Loss: 2.09140
Epoch 26, Val Loss: 2.08324
Epoch 27, Val Loss: 2.08348
Epoch 28, Val Loss: 2.08050
Epoch 29, Val Loss: 2.08353
Epoch 30, Val Loss: 2.08214
Epoch 31, Val Loss: 2.07153
Epoch 32, Val Loss: 2.07274
Epoch 33, Val Loss: 2.08608
Epoch 34, Val Loss: 2.08130
Epoch 35, Val Loss: 2.08848
Epoch 36, Val Loss: 2.09274
Epoch 37, Val Loss: 2.10395
Epoch 38, Val Loss: 2.07021
Epoch 39, Val Loss: 2.06831
Epoch 40, Val Loss: 2.08229
Epoch 41, Val Loss: 2.06802
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2684666666666664, 'Log Loss - std': 0.3744975508004767} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}
Fitted encoder
Epoch 0, Val Loss: 2.09004
Epoch 1, Val Loss: 2.07400
Epoch 2, Val Loss: 2.07302
Epoch 3, Val Loss: 2.05886
Epoch 4, Val Loss: 2.06756
Epoch 5, Val Loss: 2.07127
Epoch 6, Val Loss: 2.05603
Epoch 7, Val Loss: 2.07265
Epoch 8, Val Loss: 2.04006
Epoch 9, Val Loss: 2.05732
Epoch 10, Val Loss: 2.03995
Epoch 11, Val Loss: 2.04771
Epoch 12, Val Loss: 2.03347
Epoch 13, Val Loss: 2.04087
Epoch 14, Val Loss: 2.02702
Epoch 15, Val Loss: 2.05209
Epoch 16, Val Loss: 2.05220
Epoch 17, Val Loss: 2.04753
Epoch 18, Val Loss: 2.03356
Epoch 19, Val Loss: 2.03099
Epoch 20, Val Loss: 2.03473
Epoch 21, Val Loss: 2.03453
Epoch 22, Val Loss: 2.02211
Epoch 23, Val Loss: 2.05310
Epoch 24, Val Loss: 2.05203
Epoch 25, Val Loss: 2.04038
Epoch 26, Val Loss: 2.01988
Epoch 27, Val Loss: 2.04376
Epoch 28, Val Loss: 2.03065
Epoch 29, Val Loss: 2.03924
Epoch 30, Val Loss: 2.05309
Epoch 31, Val Loss: 2.07071
Epoch 32, Val Loss: 2.05207
Epoch 33, Val Loss: 2.01655
Epoch 34, Val Loss: 2.01353
Epoch 35, Val Loss: 2.03291
Epoch 36, Val Loss: 2.02199
Epoch 37, Val Loss: 2.07256
Epoch 38, Val Loss: 2.03901
Epoch 39, Val Loss: 2.02378
Epoch 40, Val Loss: 2.01290
Epoch 41, Val Loss: 2.02613
Epoch 42, Val Loss: 2.03144
Epoch 43, Val Loss: 2.01508
Epoch 44, Val Loss: 2.01167
Epoch 45, Val Loss: 2.06188
Epoch 46, Val Loss: 2.01639
Epoch 47, Val Loss: 2.02295
Epoch 48, Val Loss: 2.03361
Epoch 49, Val Loss: 2.01853
Epoch 50, Val Loss: 2.02902
Epoch 51, Val Loss: 2.04005
Epoch 52, Val Loss: 2.01812
Epoch 53, Val Loss: 2.00532
Epoch 54, Val Loss: 2.02927
Epoch 55, Val Loss: 2.02339
Epoch 56, Val Loss: 2.01138
Epoch 57, Val Loss: 2.01924
Epoch 58, Val Loss: 2.04444
Epoch 59, Val Loss: 2.01929
Epoch 60, Val Loss: 2.02823
Epoch 61, Val Loss: 2.02278
Epoch 62, Val Loss: 2.01674
Epoch 63, Val Loss: 2.01810
Epoch 64, Val Loss: 2.01298
Epoch 65, Val Loss: 2.02394
Epoch 66, Val Loss: 2.02508
Epoch 67, Val Loss: 2.02920
Epoch 68, Val Loss: 2.02254
Epoch 69, Val Loss: 2.04949
Epoch 70, Val Loss: 2.01798
Epoch 71, Val Loss: 2.03670
Epoch 72, Val Loss: 2.01784
Epoch 73, Val Loss: 2.02429
Epoch 74, Val Loss: 2.03802
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2352999999999996, 'Log Loss - std': 0.32937272959369307} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}
Fitted encoder
Epoch 0, Val Loss: 1.96755
Epoch 1, Val Loss: 1.96108
Epoch 2, Val Loss: 1.95077
Epoch 3, Val Loss: 1.94210
Epoch 4, Val Loss: 1.94159
Epoch 5, Val Loss: 1.94146
Epoch 6, Val Loss: 1.93938
Epoch 7, Val Loss: 1.96817
Epoch 8, Val Loss: 1.93948
Epoch 9, Val Loss: 1.93328
Epoch 10, Val Loss: 1.93717
Epoch 11, Val Loss: 1.92436
Epoch 12, Val Loss: 1.94126
Epoch 13, Val Loss: 1.91757
Epoch 14, Val Loss: 1.90141
Epoch 15, Val Loss: 1.92858
Epoch 16, Val Loss: 1.92901
Epoch 17, Val Loss: 1.93611
Epoch 18, Val Loss: 1.92727
Epoch 19, Val Loss: 1.93221
Epoch 20, Val Loss: 1.89567
Epoch 21, Val Loss: 1.90550
Epoch 22, Val Loss: 1.88350
Epoch 23, Val Loss: 1.90637
Epoch 24, Val Loss: 1.90140
Epoch 25, Val Loss: 1.91186
Epoch 26, Val Loss: 1.94178
Epoch 27, Val Loss: 1.90307
Epoch 28, Val Loss: 1.89170
Epoch 29, Val Loss: 1.89667
Epoch 30, Val Loss: 1.93107
Epoch 31, Val Loss: 1.90102
Epoch 32, Val Loss: 1.91022
Epoch 33, Val Loss: 1.89720
Epoch 34, Val Loss: 1.89143
Epoch 35, Val Loss: 1.87912
Epoch 36, Val Loss: 1.91304
Epoch 37, Val Loss: 1.88753
Epoch 38, Val Loss: 1.89733
Epoch 39, Val Loss: 1.91912
Epoch 40, Val Loss: 1.89170
Epoch 41, Val Loss: 1.91119
Epoch 42, Val Loss: 1.91606
Epoch 43, Val Loss: 1.89278
Epoch 44, Val Loss: 1.89737
Epoch 45, Val Loss: 1.89120
Epoch 46, Val Loss: 1.89260
Epoch 47, Val Loss: 1.88330
Epoch 48, Val Loss: 1.89072
Epoch 49, Val Loss: 1.91931
Epoch 50, Val Loss: 1.88766
Epoch 51, Val Loss: 1.89764
Epoch 52, Val Loss: 1.88574
Epoch 53, Val Loss: 1.88594
Epoch 54, Val Loss: 1.89264
Epoch 55, Val Loss: 1.88337
Epoch 56, Val Loss: 1.90089
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.1882599999999996, 'Log Loss - std': 0.30925743709731546} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 25 finished with value: 3.1882599999999996 and parameters: {'p_m': 0.5452912615188802, 'alpha': 1.298507796793706, 'K': 3, 'beta': 1.0850293320877162}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}
Fitted encoder
Epoch 0, Val Loss: 2.16623
Epoch 1, Val Loss: 2.13567
Epoch 2, Val Loss: 2.11661
Epoch 3, Val Loss: 2.10163
Epoch 4, Val Loss: 2.12199
Epoch 5, Val Loss: 2.08540
Epoch 6, Val Loss: 2.08738
Epoch 7, Val Loss: 2.04530
Epoch 8, Val Loss: 2.16068
Epoch 9, Val Loss: 2.09143
Epoch 10, Val Loss: 2.08578
Epoch 11, Val Loss: 2.07298
Epoch 12, Val Loss: 2.06901
Epoch 13, Val Loss: 2.06797
Epoch 14, Val Loss: 2.08423
Epoch 15, Val Loss: 2.04210
Epoch 16, Val Loss: 2.06496
Epoch 17, Val Loss: 2.03253
Epoch 18, Val Loss: 2.04280
Epoch 19, Val Loss: 2.08249
Epoch 20, Val Loss: 2.08147
Epoch 21, Val Loss: 2.10169
Epoch 22, Val Loss: 2.06618
Epoch 23, Val Loss: 2.07512
Epoch 24, Val Loss: 2.02758
Epoch 25, Val Loss: 2.05850
Epoch 26, Val Loss: 2.04576
Epoch 27, Val Loss: 2.08110
Epoch 28, Val Loss: 2.05216
Epoch 29, Val Loss: 2.06285
Epoch 30, Val Loss: 2.07270
Epoch 31, Val Loss: 2.03371
Epoch 32, Val Loss: 2.05731
Epoch 33, Val Loss: 2.09869
Epoch 34, Val Loss: 2.06033
Epoch 35, Val Loss: 2.08413
Epoch 36, Val Loss: 2.07184
Epoch 37, Val Loss: 2.04921
Epoch 38, Val Loss: 2.02583
Epoch 39, Val Loss: 2.03341
Epoch 40, Val Loss: 2.04882
Epoch 41, Val Loss: 2.01678
Epoch 42, Val Loss: 2.02141
Epoch 43, Val Loss: 2.07818
Epoch 44, Val Loss: 2.06371
Epoch 45, Val Loss: 2.09803
Epoch 46, Val Loss: 2.07796
Epoch 47, Val Loss: 2.05102
Epoch 48, Val Loss: 2.03827
Epoch 49, Val Loss: 2.03241
Epoch 50, Val Loss: 2.03822
Epoch 51, Val Loss: 2.05245
Epoch 52, Val Loss: 2.09326
Epoch 53, Val Loss: 2.07443
Epoch 54, Val Loss: 2.12687
Epoch 55, Val Loss: 2.02946
Epoch 56, Val Loss: 2.04588
Epoch 57, Val Loss: 2.03134
Epoch 58, Val Loss: 2.04942
Epoch 59, Val Loss: 2.05695
Epoch 60, Val Loss: 2.03213
Epoch 61, Val Loss: 2.02820
Epoch 62, Val Loss: 2.08023
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.9285, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}
Fitted encoder
Epoch 0, Val Loss: 1.96534
Epoch 1, Val Loss: 1.94900
Epoch 2, Val Loss: 1.94816
Epoch 3, Val Loss: 1.94391
Epoch 4, Val Loss: 2.02311
Epoch 5, Val Loss: 2.02222
Epoch 6, Val Loss: 1.92982
Epoch 7, Val Loss: 1.94427
Epoch 8, Val Loss: 1.91762
Epoch 9, Val Loss: 1.94462
Epoch 10, Val Loss: 1.93923
Epoch 11, Val Loss: 1.94905
Epoch 12, Val Loss: 1.91689
Epoch 13, Val Loss: 1.92256
Epoch 14, Val Loss: 1.91563
Epoch 15, Val Loss: 1.90307
Epoch 16, Val Loss: 2.02575
Epoch 17, Val Loss: 1.91268
Epoch 18, Val Loss: 1.90447
Epoch 19, Val Loss: 1.91085
Epoch 20, Val Loss: 1.89940
Epoch 21, Val Loss: 1.89528
Epoch 22, Val Loss: 1.91912
Epoch 23, Val Loss: 1.92641
Epoch 24, Val Loss: 1.91114
Epoch 25, Val Loss: 1.91318
Epoch 26, Val Loss: 1.94025
Epoch 27, Val Loss: 1.91394
Epoch 28, Val Loss: 1.89927
Epoch 29, Val Loss: 1.91491
Epoch 30, Val Loss: 1.90633
Epoch 31, Val Loss: 2.03680
Epoch 32, Val Loss: 1.90392
Epoch 33, Val Loss: 1.96551
Epoch 34, Val Loss: 1.90383
Epoch 35, Val Loss: 1.90154
Epoch 36, Val Loss: 1.90786
Epoch 37, Val Loss: 1.90226
Epoch 38, Val Loss: 1.91083
Epoch 39, Val Loss: 1.88984
Epoch 40, Val Loss: 1.88912
Epoch 41, Val Loss: 1.90756
Epoch 42, Val Loss: 1.90554
Epoch 43, Val Loss: 1.89843
Epoch 44, Val Loss: 1.90889
Epoch 45, Val Loss: 1.91035
Epoch 46, Val Loss: 1.91300
Epoch 47, Val Loss: 1.90087
Epoch 48, Val Loss: 1.90683
Epoch 49, Val Loss: 1.89765
Epoch 50, Val Loss: 1.91491
Epoch 51, Val Loss: 1.89743
Epoch 52, Val Loss: 1.92130
Epoch 53, Val Loss: 1.90653
Epoch 54, Val Loss: 1.91163
Epoch 55, Val Loss: 1.91003
Epoch 56, Val Loss: 1.91117
Epoch 57, Val Loss: 1.94228
Epoch 58, Val Loss: 1.89358
Epoch 59, Val Loss: 1.90341
Epoch 60, Val Loss: 1.90726
Epoch 61, Val Loss: 1.89522
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.42105, 'Log Loss - std': 0.49255000000000004} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}
Fitted encoder
Epoch 0, Val Loss: 2.11342
Epoch 1, Val Loss: 2.13689
Epoch 2, Val Loss: 2.09912
Epoch 3, Val Loss: 2.08583
Epoch 4, Val Loss: 2.09622
Epoch 5, Val Loss: 2.11047
Epoch 6, Val Loss: 2.10858
Epoch 7, Val Loss: 2.08082
Epoch 8, Val Loss: 2.09467
Epoch 9, Val Loss: 2.11468
Epoch 10, Val Loss: 2.08225
Epoch 11, Val Loss: 2.07717
Epoch 12, Val Loss: 2.07932
Epoch 13, Val Loss: 2.07162
Epoch 14, Val Loss: 2.10014
Epoch 15, Val Loss: 2.07968
Epoch 16, Val Loss: 2.07428
Epoch 17, Val Loss: 2.08675
Epoch 18, Val Loss: 2.06747
Epoch 19, Val Loss: 2.07178
Epoch 20, Val Loss: 2.07255
Epoch 21, Val Loss: 2.07472
Epoch 22, Val Loss: 2.08042
Epoch 23, Val Loss: 2.07220
Epoch 24, Val Loss: 2.09963
Epoch 25, Val Loss: 2.06872
Epoch 26, Val Loss: 2.07684
Epoch 27, Val Loss: 2.06939
Epoch 28, Val Loss: 2.10517
Epoch 29, Val Loss: 2.08145
Epoch 30, Val Loss: 2.07945
Epoch 31, Val Loss: 2.09618
Epoch 32, Val Loss: 2.07004
Epoch 33, Val Loss: 2.07887
Epoch 34, Val Loss: 2.07641
Epoch 35, Val Loss: 2.06036
Epoch 36, Val Loss: 2.06395
Epoch 37, Val Loss: 2.07640
Epoch 38, Val Loss: 2.10790
Epoch 39, Val Loss: 2.08452
Epoch 40, Val Loss: 2.09764
Epoch 41, Val Loss: 2.09971
Epoch 42, Val Loss: 2.12508
Epoch 43, Val Loss: 2.10604
Epoch 44, Val Loss: 2.08907
Epoch 45, Val Loss: 2.07406
Epoch 46, Val Loss: 2.07383
Epoch 47, Val Loss: 2.08982
Epoch 48, Val Loss: 2.08871
Epoch 49, Val Loss: 2.13429
Epoch 50, Val Loss: 2.10302
Epoch 51, Val Loss: 2.11079
Epoch 52, Val Loss: 2.08793
Epoch 53, Val Loss: 2.12674
Epoch 54, Val Loss: 2.11271
Epoch 55, Val Loss: 2.09145
Epoch 56, Val Loss: 2.10566
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.6956333333333333, 'Log Loss - std': 0.5590429460744097} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}
Fitted encoder
Epoch 0, Val Loss: 2.12802
Epoch 1, Val Loss: 2.11710
Epoch 2, Val Loss: 2.10171
Epoch 3, Val Loss: 2.12802
Epoch 4, Val Loss: 2.10047
Epoch 5, Val Loss: 2.12528
Epoch 6, Val Loss: 2.09046
Epoch 7, Val Loss: 2.07817
Epoch 8, Val Loss: 2.06050
Epoch 9, Val Loss: 2.03554
Epoch 10, Val Loss: 2.02900
Epoch 11, Val Loss: 2.11519
Epoch 12, Val Loss: 2.14269
Epoch 13, Val Loss: 2.13107
Epoch 14, Val Loss: 2.12168
Epoch 15, Val Loss: 2.05133
Epoch 16, Val Loss: 2.05136
Epoch 17, Val Loss: 2.04379
Epoch 18, Val Loss: 2.03439
Epoch 19, Val Loss: 2.01451
Epoch 20, Val Loss: 2.04663
Epoch 21, Val Loss: 2.04585
Epoch 22, Val Loss: 2.03267
Epoch 23, Val Loss: 2.03316
Epoch 24, Val Loss: 2.02522
Epoch 25, Val Loss: 2.04395
Epoch 26, Val Loss: 2.02862
Epoch 27, Val Loss: 2.01503
Epoch 28, Val Loss: 2.02548
Epoch 29, Val Loss: 2.02238
Epoch 30, Val Loss: 2.02879
Epoch 31, Val Loss: 2.02408
Epoch 32, Val Loss: 2.03119
Epoch 33, Val Loss: 2.03521
Epoch 34, Val Loss: 2.04041
Epoch 35, Val Loss: 2.03434
Epoch 36, Val Loss: 2.02875
Epoch 37, Val Loss: 2.04615
Epoch 38, Val Loss: 2.01751
Epoch 39, Val Loss: 2.04334
Epoch 40, Val Loss: 2.04080
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.41905, 'Log Loss - std': 0.6810960156248161} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}
Fitted encoder
Epoch 0, Val Loss: 1.96384
Epoch 1, Val Loss: 1.95407
Epoch 2, Val Loss: 1.94889
Epoch 3, Val Loss: 1.95061
Epoch 4, Val Loss: 1.92963
Epoch 5, Val Loss: 2.01646
Epoch 6, Val Loss: 1.92769
Epoch 7, Val Loss: 1.97711
Epoch 8, Val Loss: 1.91598
Epoch 9, Val Loss: 1.93433
Epoch 10, Val Loss: 2.01230
Epoch 11, Val Loss: 1.99512
Epoch 12, Val Loss: 1.95502
Epoch 13, Val Loss: 1.90415
Epoch 14, Val Loss: 1.92106
Epoch 15, Val Loss: 1.94139
Epoch 16, Val Loss: 1.90502
Epoch 17, Val Loss: 1.92299
Epoch 18, Val Loss: 1.90118
Epoch 19, Val Loss: 1.90871
Epoch 20, Val Loss: 1.98927
Epoch 21, Val Loss: 1.91439
Epoch 22, Val Loss: 1.90711
Epoch 23, Val Loss: 1.90239
Epoch 24, Val Loss: 1.90779
Epoch 25, Val Loss: 1.95430
Epoch 26, Val Loss: 1.99316
Epoch 27, Val Loss: 1.90556
Epoch 28, Val Loss: 1.89992
Epoch 29, Val Loss: 1.91173
Epoch 30, Val Loss: 1.88981
Epoch 31, Val Loss: 1.93373
Epoch 32, Val Loss: 1.89726
Epoch 33, Val Loss: 1.91704
Epoch 34, Val Loss: 1.89798
Epoch 35, Val Loss: 1.88382
Epoch 36, Val Loss: 1.90145
Epoch 37, Val Loss: 1.90231
Epoch 38, Val Loss: 1.88270
Epoch 39, Val Loss: 1.98487
Epoch 40, Val Loss: 1.88758
Epoch 41, Val Loss: 1.88659
Epoch 42, Val Loss: 1.90248
Epoch 43, Val Loss: 1.88799
Epoch 44, Val Loss: 1.95602
Epoch 45, Val Loss: 1.91300
Epoch 46, Val Loss: 1.89913
Epoch 47, Val Loss: 1.90703
Epoch 48, Val Loss: 1.89557
Epoch 49, Val Loss: 1.89439
Epoch 50, Val Loss: 1.89589
Epoch 51, Val Loss: 1.90365
Epoch 52, Val Loss: 1.90301
Epoch 53, Val Loss: 1.87951
Epoch 54, Val Loss: 1.87949
Epoch 55, Val Loss: 1.99167
Epoch 56, Val Loss: 1.93288
Epoch 57, Val Loss: 1.95596
Epoch 58, Val Loss: 1.95820
Epoch 59, Val Loss: 1.91336
Epoch 60, Val Loss: 1.91405
Epoch 61, Val Loss: 1.92544
Epoch 62, Val Loss: 1.90402
Epoch 63, Val Loss: 1.88324
Epoch 64, Val Loss: 1.87715
Epoch 65, Val Loss: 1.88934
Epoch 66, Val Loss: 1.88755
Epoch 67, Val Loss: 1.89620
Epoch 68, Val Loss: 1.89843
Epoch 69, Val Loss: 1.89842
Epoch 70, Val Loss: 1.91896
Epoch 71, Val Loss: 1.91084
Epoch 72, Val Loss: 1.92467
Epoch 73, Val Loss: 1.93613
Epoch 74, Val Loss: 1.92876
Epoch 75, Val Loss: 1.94505
Epoch 76, Val Loss: 1.89028
Epoch 77, Val Loss: 1.89675
Epoch 78, Val Loss: 1.88024
Epoch 79, Val Loss: 1.89651
Epoch 80, Val Loss: 1.92438
Epoch 81, Val Loss: 1.89117
Epoch 82, Val Loss: 1.96522
Epoch 83, Val Loss: 1.89045
Epoch 84, Val Loss: 1.92377
Epoch 85, Val Loss: 1.90367
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.46892, 'Log Loss - std': 0.6173017848670129} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 26 finished with value: 3.46892 and parameters: {'p_m': 0.8075361254706521, 'alpha': 2.7178877735627966, 'K': 10, 'beta': 0.9121522407509663}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}
Fitted encoder
Epoch 0, Val Loss: 2.17189
Epoch 1, Val Loss: 2.17262
Epoch 2, Val Loss: 2.16330
Epoch 3, Val Loss: 2.22640
Epoch 4, Val Loss: 2.22640
Epoch 5, Val Loss: 2.22640
Epoch 6, Val Loss: 2.22640
Epoch 7, Val Loss: 2.22640
Epoch 8, Val Loss: 2.22640
Epoch 9, Val Loss: 2.22640
Epoch 10, Val Loss: 2.22640
Epoch 11, Val Loss: 2.22640
Epoch 12, Val Loss: 2.22640
Epoch 13, Val Loss: 2.22640
Epoch 14, Val Loss: 2.22640
Epoch 15, Val Loss: 2.22640
Epoch 16, Val Loss: 2.22640
Epoch 17, Val Loss: 2.22640
Epoch 18, Val Loss: 2.22640
Epoch 19, Val Loss: 2.22640
Epoch 20, Val Loss: 2.22640
Epoch 21, Val Loss: 2.22640
Epoch 22, Val Loss: 2.22640
Epoch 23, Val Loss: 2.22640
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 7.6487, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}
Fitted encoder
Epoch 0, Val Loss: 1.94649
Epoch 1, Val Loss: 1.97768
Epoch 2, Val Loss: 1.94545
Epoch 3, Val Loss: 1.95934
Epoch 4, Val Loss: 1.93230
Epoch 5, Val Loss: 1.95147
Epoch 6, Val Loss: 1.93311
Epoch 7, Val Loss: 1.92477
Epoch 8, Val Loss: 1.91021
Epoch 9, Val Loss: 1.92332
Epoch 10, Val Loss: 1.91220
Epoch 11, Val Loss: 1.89559
Epoch 12, Val Loss: 1.90841
Epoch 13, Val Loss: 1.91894
Epoch 14, Val Loss: 1.93537
Epoch 15, Val Loss: 1.91732
Epoch 16, Val Loss: 1.90374
Epoch 17, Val Loss: 1.90187
Epoch 18, Val Loss: 1.90524
Epoch 19, Val Loss: 1.92134
Epoch 20, Val Loss: 1.90349
Epoch 21, Val Loss: 1.89689
Epoch 22, Val Loss: 1.90359
Epoch 23, Val Loss: 1.91333
Epoch 24, Val Loss: 1.89414
Epoch 25, Val Loss: 1.92736
Epoch 26, Val Loss: 1.89361
Epoch 27, Val Loss: 1.89834
Epoch 28, Val Loss: 1.89833
Epoch 29, Val Loss: 1.89213
Epoch 30, Val Loss: 1.90262
Epoch 31, Val Loss: 1.94002
Epoch 32, Val Loss: 1.89680
Epoch 33, Val Loss: 1.89511
Epoch 34, Val Loss: 1.89804
Epoch 35, Val Loss: 1.90860
Epoch 36, Val Loss: 1.90661
Epoch 37, Val Loss: 1.89937
Epoch 38, Val Loss: 1.94532
Epoch 39, Val Loss: 1.91217
Epoch 40, Val Loss: 1.90606
Epoch 41, Val Loss: 1.91040
Epoch 42, Val Loss: 1.89709
Epoch 43, Val Loss: 1.91673
Epoch 44, Val Loss: 1.90387
Epoch 45, Val Loss: 1.90245
Epoch 46, Val Loss: 1.92295
Epoch 47, Val Loss: 1.89417
Epoch 48, Val Loss: 1.90353
Epoch 49, Val Loss: 1.90314
Epoch 50, Val Loss: 1.92033
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 5.5388, 'Log Loss - std': 2.1098999999999997} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}
Fitted encoder
Epoch 0, Val Loss: 2.11478
Epoch 1, Val Loss: 2.10064
Epoch 2, Val Loss: 2.07513
Epoch 3, Val Loss: 2.04121
Epoch 4, Val Loss: 2.06237
Epoch 5, Val Loss: 2.09982
Epoch 6, Val Loss: 2.08179
Epoch 7, Val Loss: 2.06540
Epoch 8, Val Loss: 2.12652
Epoch 9, Val Loss: 2.07561
Epoch 10, Val Loss: 2.08220
Epoch 11, Val Loss: 2.07089
Epoch 12, Val Loss: 2.08081
Epoch 13, Val Loss: 2.06449
Epoch 14, Val Loss: 2.08269
Epoch 15, Val Loss: 2.07534
Epoch 16, Val Loss: 2.05655
Epoch 17, Val Loss: 2.05359
Epoch 18, Val Loss: 2.10317
Epoch 19, Val Loss: 2.05534
Epoch 20, Val Loss: 2.06193
Epoch 21, Val Loss: 2.06503
Epoch 22, Val Loss: 2.06981
Epoch 23, Val Loss: 2.06951
Epoch 24, Val Loss: 2.07320
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.4568666666666665, 'Log Loss - std': 2.3041147574623} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}
Fitted encoder
Epoch 0, Val Loss: 2.09193
Epoch 1, Val Loss: 2.07220
Epoch 2, Val Loss: 2.08968
Epoch 3, Val Loss: 2.06306
Epoch 4, Val Loss: 2.05005
Epoch 5, Val Loss: 2.04328
Epoch 6, Val Loss: 2.03228
Epoch 7, Val Loss: 2.03582
Epoch 8, Val Loss: 2.03457
Epoch 9, Val Loss: 2.02654
Epoch 10, Val Loss: 2.05535
Epoch 11, Val Loss: 2.02698
Epoch 12, Val Loss: 2.02484
Epoch 13, Val Loss: 2.09509
Epoch 14, Val Loss: 2.07370
Epoch 15, Val Loss: 2.07393
Epoch 16, Val Loss: 2.07544
Epoch 17, Val Loss: 2.09893
Epoch 18, Val Loss: 2.08030
Epoch 19, Val Loss: 2.07578
Epoch 20, Val Loss: 2.03047
Epoch 21, Val Loss: 2.01848
Epoch 22, Val Loss: 2.02504
Epoch 23, Val Loss: 2.01399
Epoch 24, Val Loss: 2.01485
Epoch 25, Val Loss: 2.02377
Epoch 26, Val Loss: 2.02008
Epoch 27, Val Loss: 2.05668
Epoch 28, Val Loss: 2.02104
Epoch 29, Val Loss: 2.01990
Epoch 30, Val Loss: 2.00239
Epoch 31, Val Loss: 2.07383
Epoch 32, Val Loss: 2.01829
Epoch 33, Val Loss: 2.04848
Epoch 34, Val Loss: 2.01600
Epoch 35, Val Loss: 2.02290
Epoch 36, Val Loss: 2.00894
Epoch 37, Val Loss: 2.02795
Epoch 38, Val Loss: 2.01714
Epoch 39, Val Loss: 2.03767
Epoch 40, Val Loss: 2.01388
Epoch 41, Val Loss: 2.02177
Epoch 42, Val Loss: 2.02939
Epoch 43, Val Loss: 2.03463
Epoch 44, Val Loss: 2.03398
Epoch 45, Val Loss: 2.02446
Epoch 46, Val Loss: 2.03702
Epoch 47, Val Loss: 2.02199
Epoch 48, Val Loss: 2.01811
Epoch 49, Val Loss: 2.02342
Epoch 50, Val Loss: 2.02166
Epoch 51, Val Loss: 2.02860
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.03935, 'Log Loss - std': 2.122420578608302} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}
Fitted encoder
Epoch 0, Val Loss: 1.95386
Epoch 1, Val Loss: 1.95237
Epoch 2, Val Loss: 1.94301
Epoch 3, Val Loss: 1.91544
Epoch 4, Val Loss: 1.91268
Epoch 5, Val Loss: 1.93895
Epoch 6, Val Loss: 1.90940
Epoch 7, Val Loss: 1.92750
Epoch 8, Val Loss: 1.92897
Epoch 9, Val Loss: 1.95896
Epoch 10, Val Loss: 1.91445
Epoch 11, Val Loss: 1.92311
Epoch 12, Val Loss: 1.90709
Epoch 13, Val Loss: 1.92714
Epoch 14, Val Loss: 1.91568
Epoch 15, Val Loss: 1.90942
Epoch 16, Val Loss: 1.91037
Epoch 17, Val Loss: 1.92373
Epoch 18, Val Loss: 1.91143
Epoch 19, Val Loss: 1.93609
Epoch 20, Val Loss: 1.91006
Epoch 21, Val Loss: 1.91250
Epoch 22, Val Loss: 1.91466
Epoch 23, Val Loss: 1.91108
Epoch 24, Val Loss: 1.89275
Epoch 25, Val Loss: 1.90081
Epoch 26, Val Loss: 1.89679
Epoch 27, Val Loss: 1.91341
Epoch 28, Val Loss: 1.90004
Epoch 29, Val Loss: 1.90789
Epoch 30, Val Loss: 1.89321
Epoch 31, Val Loss: 1.89892
Epoch 32, Val Loss: 1.90928
Epoch 33, Val Loss: 1.91603
Epoch 34, Val Loss: 1.89770
Epoch 35, Val Loss: 1.91765
Epoch 36, Val Loss: 1.90035
Epoch 37, Val Loss: 1.88442
Epoch 38, Val Loss: 1.90657
Epoch 39, Val Loss: 1.91136
Epoch 40, Val Loss: 1.89819
Epoch 41, Val Loss: 1.89343
Epoch 42, Val Loss: 1.90230
Epoch 43, Val Loss: 1.89959
Epoch 44, Val Loss: 1.90147
Epoch 45, Val Loss: 1.89191
Epoch 46, Val Loss: 1.90253
Epoch 47, Val Loss: 1.90296
Epoch 48, Val Loss: 1.89325
Epoch 49, Val Loss: 1.90170
Epoch 50, Val Loss: 1.89946
Epoch 51, Val Loss: 1.90067
Epoch 52, Val Loss: 1.90634
Epoch 53, Val Loss: 1.89453
Epoch 54, Val Loss: 1.89971
Epoch 55, Val Loss: 1.93046
Epoch 56, Val Loss: 1.89194
Epoch 57, Val Loss: 1.90640
Epoch 58, Val Loss: 1.90812
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.93606, 'Log Loss - std': 1.9095576939176253} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 27 finished with value: 3.93606 and parameters: {'p_m': 0.6730904562267327, 'alpha': 0.1958158061392561, 'K': 3, 'beta': 2.5860997559376266}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}
Fitted encoder
Epoch 0, Val Loss: 2.12233
Epoch 1, Val Loss: 2.12074
Epoch 2, Val Loss: 2.11385
Epoch 3, Val Loss: 2.11885
Epoch 4, Val Loss: 2.16533
Epoch 5, Val Loss: 2.09185
Epoch 6, Val Loss: 2.11962
Epoch 7, Val Loss: 2.07887
Epoch 8, Val Loss: 2.08788
Epoch 9, Val Loss: 2.10280
Epoch 10, Val Loss: 2.05660
Epoch 11, Val Loss: 2.07746
Epoch 12, Val Loss: 2.03723
Epoch 13, Val Loss: 2.06640
Epoch 14, Val Loss: 2.07022
Epoch 15, Val Loss: 2.05527
Epoch 16, Val Loss: 2.09194
Epoch 17, Val Loss: 2.11013
Epoch 18, Val Loss: 2.04151
Epoch 19, Val Loss: 2.05492
Epoch 20, Val Loss: 2.08770
Epoch 21, Val Loss: 2.05463
Epoch 22, Val Loss: 2.06688
Epoch 23, Val Loss: 2.06279
Epoch 24, Val Loss: 2.08439
Epoch 25, Val Loss: 2.04846
Epoch 26, Val Loss: 2.03186
Epoch 27, Val Loss: 2.05070
Epoch 28, Val Loss: 2.06363
Epoch 29, Val Loss: 2.05764
Epoch 30, Val Loss: 2.04255
Epoch 31, Val Loss: 2.04937
Epoch 32, Val Loss: 2.04917
Epoch 33, Val Loss: 2.04191
Epoch 34, Val Loss: 2.03362
Epoch 35, Val Loss: 2.03572
Epoch 36, Val Loss: 2.04158
Epoch 37, Val Loss: 2.03677
Epoch 38, Val Loss: 2.06007
Epoch 39, Val Loss: 2.07164
Epoch 40, Val Loss: 2.04123
Epoch 41, Val Loss: 2.04606
Epoch 42, Val Loss: 2.06710
Epoch 43, Val Loss: 2.02768
Epoch 44, Val Loss: 2.05507
Epoch 45, Val Loss: 2.05179
Epoch 46, Val Loss: 2.04038
Epoch 47, Val Loss: 2.05146
Epoch 48, Val Loss: 2.06244
Epoch 49, Val Loss: 2.07094
Epoch 50, Val Loss: 2.03376
Epoch 51, Val Loss: 2.02838
Epoch 52, Val Loss: 2.04094
Epoch 53, Val Loss: 2.08903
Epoch 54, Val Loss: 2.03065
Epoch 55, Val Loss: 2.05819
Epoch 56, Val Loss: 2.04823
Epoch 57, Val Loss: 2.04885
Epoch 58, Val Loss: 2.03024
Epoch 59, Val Loss: 2.04122
Epoch 60, Val Loss: 2.05938
Epoch 61, Val Loss: 2.05321
Epoch 62, Val Loss: 2.04479
Epoch 63, Val Loss: 2.05908
Epoch 64, Val Loss: 2.03762
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.2959, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}
Fitted encoder
Epoch 0, Val Loss: 1.96898
Epoch 1, Val Loss: 1.95347
Epoch 2, Val Loss: 1.95853
Epoch 3, Val Loss: 1.95323
Epoch 4, Val Loss: 1.95220
Epoch 5, Val Loss: 1.94241
Epoch 6, Val Loss: 1.96026
Epoch 7, Val Loss: 1.94462
Epoch 8, Val Loss: 1.95956
Epoch 9, Val Loss: 1.95624
Epoch 10, Val Loss: 1.94468
Epoch 11, Val Loss: 1.95264
Epoch 12, Val Loss: 1.95362
Epoch 13, Val Loss: 1.94484
Epoch 14, Val Loss: 1.95398
Epoch 15, Val Loss: 1.94830
Epoch 16, Val Loss: 1.95330
Epoch 17, Val Loss: 1.94337
Epoch 18, Val Loss: 1.93670
Epoch 19, Val Loss: 1.94734
Epoch 20, Val Loss: 1.94141
Epoch 21, Val Loss: 1.93894
Epoch 22, Val Loss: 1.95372
Epoch 23, Val Loss: 1.93607
Epoch 24, Val Loss: 1.93306
Epoch 25, Val Loss: 1.93793
Epoch 26, Val Loss: 1.96607
Epoch 27, Val Loss: 1.93471
Epoch 28, Val Loss: 1.94306
Epoch 29, Val Loss: 1.94167
Epoch 30, Val Loss: 1.92869
Epoch 31, Val Loss: 1.92131
Epoch 32, Val Loss: 1.92320
Epoch 33, Val Loss: 1.91929
Epoch 34, Val Loss: 1.91398
Epoch 35, Val Loss: 1.93788
Epoch 36, Val Loss: 1.93848
Epoch 37, Val Loss: 1.94196
Epoch 38, Val Loss: 1.91689
Epoch 39, Val Loss: 1.93485
Epoch 40, Val Loss: 1.91338
Epoch 41, Val Loss: 1.93445
Epoch 42, Val Loss: 1.93033
Epoch 43, Val Loss: 1.93413
Epoch 44, Val Loss: 1.92966
Epoch 45, Val Loss: 1.91687
Epoch 46, Val Loss: 1.91606
Epoch 47, Val Loss: 1.91010
Epoch 48, Val Loss: 1.92118
Epoch 49, Val Loss: 1.91200
Epoch 50, Val Loss: 1.91205
Epoch 51, Val Loss: 1.91509
Epoch 52, Val Loss: 1.91041
Epoch 53, Val Loss: 1.91793
Epoch 54, Val Loss: 1.90424
Epoch 55, Val Loss: 1.91163
Epoch 56, Val Loss: 1.90681
Epoch 57, Val Loss: 1.90828
Epoch 58, Val Loss: 1.91044
Epoch 59, Val Loss: 1.90823
Epoch 60, Val Loss: 1.91597
Epoch 61, Val Loss: 1.89215
Epoch 62, Val Loss: 1.91405
Epoch 63, Val Loss: 1.92533
Epoch 64, Val Loss: 1.90527
Epoch 65, Val Loss: 1.93777
Epoch 66, Val Loss: 1.91993
Epoch 67, Val Loss: 1.89810
Epoch 68, Val Loss: 1.91385
Epoch 69, Val Loss: 1.90065
Epoch 70, Val Loss: 1.90452
Epoch 71, Val Loss: 1.90518
Epoch 72, Val Loss: 1.90567
Epoch 73, Val Loss: 1.89926
Epoch 74, Val Loss: 1.92436
Epoch 75, Val Loss: 1.89987
Epoch 76, Val Loss: 1.91261
Epoch 77, Val Loss: 1.91973
Epoch 78, Val Loss: 1.90441
Epoch 79, Val Loss: 1.92133
Epoch 80, Val Loss: 1.92434
Epoch 81, Val Loss: 1.90197
Epoch 82, Val Loss: 1.91174
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.2361500000000003, 'Log Loss - std': 0.05974999999999997} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}
Fitted encoder
Epoch 0, Val Loss: 2.12960
Epoch 1, Val Loss: 2.11439
Epoch 2, Val Loss: 2.13675
Epoch 3, Val Loss: 2.11118
Epoch 4, Val Loss: 2.11511
Epoch 5, Val Loss: 2.11853
Epoch 6, Val Loss: 2.11234
Epoch 7, Val Loss: 2.11760
Epoch 8, Val Loss: 2.11288
Epoch 9, Val Loss: 2.12047
Epoch 10, Val Loss: 2.11003
Epoch 11, Val Loss: 2.11897
Epoch 12, Val Loss: 2.12565
Epoch 13, Val Loss: 2.10659
Epoch 14, Val Loss: 2.10177
Epoch 15, Val Loss: 2.10492
Epoch 16, Val Loss: 2.10315
Epoch 17, Val Loss: 2.11049
Epoch 18, Val Loss: 2.10346
Epoch 19, Val Loss: 2.11129
Epoch 20, Val Loss: 2.10843
Epoch 21, Val Loss: 2.10568
Epoch 22, Val Loss: 2.10258
Epoch 23, Val Loss: 2.11242
Epoch 24, Val Loss: 2.10952
Epoch 25, Val Loss: 2.10366
Epoch 26, Val Loss: 2.10223
Epoch 27, Val Loss: 2.10245
Epoch 28, Val Loss: 2.10344
Epoch 29, Val Loss: 2.10666
Epoch 30, Val Loss: 2.11686
Epoch 31, Val Loss: 2.10257
Epoch 32, Val Loss: 2.10122
Epoch 33, Val Loss: 2.10373
Epoch 34, Val Loss: 2.09663
Epoch 35, Val Loss: 2.09890
Epoch 36, Val Loss: 2.10535
Epoch 37, Val Loss: 2.12920
Epoch 38, Val Loss: 2.11770
Epoch 39, Val Loss: 2.09829
Epoch 40, Val Loss: 2.10586
Epoch 41, Val Loss: 2.10095
Epoch 42, Val Loss: 2.09200
Epoch 43, Val Loss: 2.10122
Epoch 44, Val Loss: 2.10816
Epoch 45, Val Loss: 2.09908
Epoch 46, Val Loss: 2.09631
Epoch 47, Val Loss: 2.10957
Epoch 48, Val Loss: 2.10245
Epoch 49, Val Loss: 2.08795
Epoch 50, Val Loss: 2.09566
Epoch 51, Val Loss: 2.09416
Epoch 52, Val Loss: 2.10192
Epoch 53, Val Loss: 2.08892
Epoch 54, Val Loss: 2.14575
Epoch 55, Val Loss: 2.13644
Epoch 56, Val Loss: 2.12837
Epoch 57, Val Loss: 2.11656
Epoch 58, Val Loss: 2.11648
Epoch 59, Val Loss: 2.13715
Epoch 60, Val Loss: 2.13022
Epoch 61, Val Loss: 2.10768
Epoch 62, Val Loss: 2.13709
Epoch 63, Val Loss: 2.15328
Epoch 64, Val Loss: 2.15352
Epoch 65, Val Loss: 2.14128
Epoch 66, Val Loss: 2.14327
Epoch 67, Val Loss: 2.13995
Epoch 68, Val Loss: 2.13120
Epoch 69, Val Loss: 2.13260
Epoch 70, Val Loss: 2.13585
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.124166666666667, 'Log Loss - std': 0.16571232771147587} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}
Fitted encoder
Epoch 0, Val Loss: 2.10677
Epoch 1, Val Loss: 2.08280
Epoch 2, Val Loss: 2.06953
Epoch 3, Val Loss: 2.06638
Epoch 4, Val Loss: 2.06515
Epoch 5, Val Loss: 2.05753
Epoch 6, Val Loss: 2.04824
Epoch 7, Val Loss: 2.06313
Epoch 8, Val Loss: 2.03992
Epoch 9, Val Loss: 2.07256
Epoch 10, Val Loss: 2.10233
Epoch 11, Val Loss: 2.10594
Epoch 12, Val Loss: 2.08292
Epoch 13, Val Loss: 2.08783
Epoch 14, Val Loss: 2.07459
Epoch 15, Val Loss: 2.11797
Epoch 16, Val Loss: 2.11768
Epoch 17, Val Loss: 2.05096
Epoch 18, Val Loss: 2.03942
Epoch 19, Val Loss: 2.05395
Epoch 20, Val Loss: 2.03658
Epoch 21, Val Loss: 2.02627
Epoch 22, Val Loss: 2.03169
Epoch 23, Val Loss: 2.04808
Epoch 24, Val Loss: 2.04634
Epoch 25, Val Loss: 2.03047
Epoch 26, Val Loss: 2.04082
Epoch 27, Val Loss: 2.09751
Epoch 28, Val Loss: 2.11428
Epoch 29, Val Loss: 2.07625
Epoch 30, Val Loss: 2.01976
Epoch 31, Val Loss: 2.04980
Epoch 32, Val Loss: 2.02956
Epoch 33, Val Loss: 2.02799
Epoch 34, Val Loss: 2.03915
Epoch 35, Val Loss: 2.02816
Epoch 36, Val Loss: 2.03277
Epoch 37, Val Loss: 2.05413
Epoch 38, Val Loss: 2.02171
Epoch 39, Val Loss: 2.05644
Epoch 40, Val Loss: 2.03793
Epoch 41, Val Loss: 2.01758
Epoch 42, Val Loss: 2.02737
Epoch 43, Val Loss: 2.03108
Epoch 44, Val Loss: 2.03021
Epoch 45, Val Loss: 2.02370
Epoch 46, Val Loss: 2.02285
Epoch 47, Val Loss: 2.02321
Epoch 48, Val Loss: 2.02848
Epoch 49, Val Loss: 2.02467
Epoch 50, Val Loss: 2.01968
Epoch 51, Val Loss: 2.02923
Epoch 52, Val Loss: 2.03727
Epoch 53, Val Loss: 2.04751
Epoch 54, Val Loss: 2.04067
Epoch 55, Val Loss: 2.02785
Epoch 56, Val Loss: 2.04035
Epoch 57, Val Loss: 2.04529
Epoch 58, Val Loss: 2.03771
Epoch 59, Val Loss: 2.02082
Epoch 60, Val Loss: 2.02738
Epoch 61, Val Loss: 2.03469
Epoch 62, Val Loss: 2.04360
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.149925, 'Log Loss - std': 0.1502860834375559} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}
Fitted encoder
Epoch 0, Val Loss: 1.97288
Epoch 1, Val Loss: 1.94853
Epoch 2, Val Loss: 1.97375
Epoch 3, Val Loss: 1.94928
Epoch 4, Val Loss: 1.94902
Epoch 5, Val Loss: 1.95165
Epoch 6, Val Loss: 1.98893
Epoch 7, Val Loss: 1.96506
Epoch 8, Val Loss: 1.95152
Epoch 9, Val Loss: 1.96112
Epoch 10, Val Loss: 1.95110
Epoch 11, Val Loss: 1.95307
Epoch 12, Val Loss: 1.95858
Epoch 13, Val Loss: 1.94742
Epoch 14, Val Loss: 1.94851
Epoch 15, Val Loss: 1.95197
Epoch 16, Val Loss: 1.95005
Epoch 17, Val Loss: 1.95980
Epoch 18, Val Loss: 1.95197
Epoch 19, Val Loss: 1.96018
Epoch 20, Val Loss: 1.94839
Epoch 21, Val Loss: 1.94879
Epoch 22, Val Loss: 1.94513
Epoch 23, Val Loss: 1.94364
Epoch 24, Val Loss: 1.94064
Epoch 25, Val Loss: 1.93937
Epoch 26, Val Loss: 1.92564
Epoch 27, Val Loss: 1.92096
Epoch 28, Val Loss: 1.94765
Epoch 29, Val Loss: 1.95837
Epoch 30, Val Loss: 1.94562
Epoch 31, Val Loss: 1.92448
Epoch 32, Val Loss: 2.02585
Epoch 33, Val Loss: 1.94635
Epoch 34, Val Loss: 1.91338
Epoch 35, Val Loss: 1.91934
Epoch 36, Val Loss: 1.92677
Epoch 37, Val Loss: 1.94611
Epoch 38, Val Loss: 1.95779
Epoch 39, Val Loss: 1.93514
Epoch 40, Val Loss: 1.92212
Epoch 41, Val Loss: 1.94433
Epoch 42, Val Loss: 1.92932
Epoch 43, Val Loss: 1.91824
Epoch 44, Val Loss: 1.91481
Epoch 45, Val Loss: 1.92280
Epoch 46, Val Loss: 1.94342
Epoch 47, Val Loss: 1.93002
Epoch 48, Val Loss: 1.94308
Epoch 49, Val Loss: 1.90705
Epoch 50, Val Loss: 1.91513
Epoch 51, Val Loss: 1.90549
Epoch 52, Val Loss: 1.93021
Epoch 53, Val Loss: 1.91496
Epoch 54, Val Loss: 1.89747
Epoch 55, Val Loss: 1.90526
Epoch 56, Val Loss: 1.91288
Epoch 57, Val Loss: 1.90473
Epoch 58, Val Loss: 1.90965
Epoch 59, Val Loss: 1.89708
Epoch 60, Val Loss: 1.90776
Epoch 61, Val Loss: 1.94539
Epoch 62, Val Loss: 1.94080
Epoch 63, Val Loss: 1.90141
Epoch 64, Val Loss: 1.92886
Epoch 65, Val Loss: 1.90061
Epoch 66, Val Loss: 1.90801
Epoch 67, Val Loss: 1.93042
Epoch 68, Val Loss: 1.92977
Epoch 69, Val Loss: 1.90475
Epoch 70, Val Loss: 1.90877
Epoch 71, Val Loss: 1.91579
Epoch 72, Val Loss: 1.93027
Epoch 73, Val Loss: 1.88792
Epoch 74, Val Loss: 1.92231
Epoch 75, Val Loss: 1.89633
Epoch 76, Val Loss: 1.90217
Epoch 77, Val Loss: 1.92489
Epoch 78, Val Loss: 1.90844
Epoch 79, Val Loss: 1.88580
Epoch 80, Val Loss: 1.89642
Epoch 81, Val Loss: 1.90793
Epoch 82, Val Loss: 1.89241
Epoch 83, Val Loss: 1.89007
Epoch 84, Val Loss: 1.89258
Epoch 85, Val Loss: 1.90802
Epoch 86, Val Loss: 1.89427
Epoch 87, Val Loss: 1.91415
Epoch 88, Val Loss: 1.90106
Epoch 89, Val Loss: 1.88970
Epoch 90, Val Loss: 1.89703
Epoch 91, Val Loss: 1.92881
Epoch 92, Val Loss: 1.89801
Epoch 93, Val Loss: 1.93905
Epoch 94, Val Loss: 1.91197
Epoch 95, Val Loss: 1.89103
Epoch 96, Val Loss: 1.90155
Epoch 97, Val Loss: 1.89792
Epoch 98, Val Loss: 1.89996
Epoch 99, Val Loss: 1.90669
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.12188, 'Log Loss - std': 0.14565305901353395} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 28 finished with value: 3.12188 and parameters: {'p_m': 0.6559740419094625, 'alpha': 1.3953184375799077, 'K': 3, 'beta': 2.201099739792967}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}
Fitted encoder
Epoch 0, Val Loss: 2.19457
Epoch 1, Val Loss: 2.17630
Epoch 2, Val Loss: 2.18632
Epoch 3, Val Loss: 2.18224
Epoch 4, Val Loss: 2.17179
Epoch 5, Val Loss: 2.17595
Epoch 6, Val Loss: 2.13221
Epoch 7, Val Loss: 2.13283
Epoch 8, Val Loss: 2.10148
Epoch 9, Val Loss: 2.11712
Epoch 10, Val Loss: 2.10055
Epoch 11, Val Loss: 2.08970
Epoch 12, Val Loss: 2.07695
Epoch 13, Val Loss: 2.07403
Epoch 14, Val Loss: 2.08834
Epoch 15, Val Loss: 2.08009
Epoch 16, Val Loss: 2.07996
Epoch 17, Val Loss: 2.10055
Epoch 18, Val Loss: 2.07654
Epoch 19, Val Loss: 2.07483
Epoch 20, Val Loss: 2.07066
Epoch 21, Val Loss: 2.09297
Epoch 22, Val Loss: 2.07384
Epoch 23, Val Loss: 2.06584
Epoch 24, Val Loss: 2.07626
Epoch 25, Val Loss: 2.08517
Epoch 26, Val Loss: 2.06907
Epoch 27, Val Loss: 2.07755
Epoch 28, Val Loss: 2.07188
Epoch 29, Val Loss: 2.05786
Epoch 30, Val Loss: 2.07676
Epoch 31, Val Loss: 2.07202
Epoch 32, Val Loss: 2.06646
Epoch 33, Val Loss: 2.07163
Epoch 34, Val Loss: 2.07639
Epoch 35, Val Loss: 2.07776
Epoch 36, Val Loss: 2.06693
Epoch 37, Val Loss: 2.07317
Epoch 38, Val Loss: 2.06505
Epoch 39, Val Loss: 2.06734
Epoch 40, Val Loss: 2.07515
Epoch 41, Val Loss: 2.07793
Epoch 42, Val Loss: 2.06783
Epoch 43, Val Loss: 2.06135
Epoch 44, Val Loss: 2.05977
Epoch 45, Val Loss: 2.06367
Epoch 46, Val Loss: 2.06759
Epoch 47, Val Loss: 2.06766
Epoch 48, Val Loss: 2.07351
Epoch 49, Val Loss: 2.06927
Epoch 50, Val Loss: 2.06456
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.4854, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}
Fitted encoder
Epoch 0, Val Loss: 1.96417
Epoch 1, Val Loss: 1.96375
Epoch 2, Val Loss: 1.95775
Epoch 3, Val Loss: 1.94749
Epoch 4, Val Loss: 1.93596
Epoch 5, Val Loss: 1.93264
Epoch 6, Val Loss: 1.93445
Epoch 7, Val Loss: 1.95051
Epoch 8, Val Loss: 1.92541
Epoch 9, Val Loss: 1.94199
Epoch 10, Val Loss: 1.91505
Epoch 11, Val Loss: 1.91613
Epoch 12, Val Loss: 1.91544
Epoch 13, Val Loss: 1.92834
Epoch 14, Val Loss: 1.91333
Epoch 15, Val Loss: 1.90741
Epoch 16, Val Loss: 1.90994
Epoch 17, Val Loss: 1.91636
Epoch 18, Val Loss: 1.91394
Epoch 19, Val Loss: 1.91825
Epoch 20, Val Loss: 1.92378
Epoch 21, Val Loss: 1.90735
Epoch 22, Val Loss: 1.89601
Epoch 23, Val Loss: 1.91472
Epoch 24, Val Loss: 1.90511
Epoch 25, Val Loss: 1.91657
Epoch 26, Val Loss: 1.90238
Epoch 27, Val Loss: 1.90682
Epoch 28, Val Loss: 1.90025
Epoch 29, Val Loss: 1.90475
Epoch 30, Val Loss: 1.89741
Epoch 31, Val Loss: 1.90035
Epoch 32, Val Loss: 1.92254
Epoch 33, Val Loss: 1.90034
Epoch 34, Val Loss: 1.89935
Epoch 35, Val Loss: 1.89203
Epoch 36, Val Loss: 1.90117
Epoch 37, Val Loss: 1.90083
Epoch 38, Val Loss: 1.90471
Epoch 39, Val Loss: 1.90349
Epoch 40, Val Loss: 1.90536
Epoch 41, Val Loss: 1.89788
Epoch 42, Val Loss: 1.92057
Epoch 43, Val Loss: 1.90138
Epoch 44, Val Loss: 1.88936
Epoch 45, Val Loss: 1.91290
Epoch 46, Val Loss: 1.89387
Epoch 47, Val Loss: 1.89599
Epoch 48, Val Loss: 1.90750
Epoch 49, Val Loss: 1.90071
Epoch 50, Val Loss: 1.89377
Epoch 51, Val Loss: 1.89937
Epoch 52, Val Loss: 1.89420
Epoch 53, Val Loss: 1.89495
Epoch 54, Val Loss: 1.89441
Epoch 55, Val Loss: 1.91000
Epoch 56, Val Loss: 1.89761
Epoch 57, Val Loss: 1.90376
Epoch 58, Val Loss: 1.90354
Epoch 59, Val Loss: 1.89398
Epoch 60, Val Loss: 1.90837
Epoch 61, Val Loss: 1.89572
Epoch 62, Val Loss: 1.91453
Epoch 63, Val Loss: 1.89762
Epoch 64, Val Loss: 1.89841
Epoch 65, Val Loss: 1.89666
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.2522, 'Log Loss - std': 0.23319999999999985} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}
Fitted encoder
Epoch 0, Val Loss: 2.13233
Epoch 1, Val Loss: 2.12284
Epoch 2, Val Loss: 2.14881
Epoch 3, Val Loss: 2.12361
Epoch 4, Val Loss: 2.11603
Epoch 5, Val Loss: 2.11510
Epoch 6, Val Loss: 2.12643
Epoch 7, Val Loss: 2.11375
Epoch 8, Val Loss: 2.10730
Epoch 9, Val Loss: 2.11694
Epoch 10, Val Loss: 2.11964
Epoch 11, Val Loss: 2.11405
Epoch 12, Val Loss: 2.08288
Epoch 13, Val Loss: 2.12589
Epoch 14, Val Loss: 2.10787
Epoch 15, Val Loss: 2.09438
Epoch 16, Val Loss: 2.08652
Epoch 17, Val Loss: 2.09411
Epoch 18, Val Loss: 2.10523
Epoch 19, Val Loss: 2.08755
Epoch 20, Val Loss: 2.07560
Epoch 21, Val Loss: 2.09090
Epoch 22, Val Loss: 2.08038
Epoch 23, Val Loss: 2.09256
Epoch 24, Val Loss: 2.08612
Epoch 25, Val Loss: 2.08481
Epoch 26, Val Loss: 2.08329
Epoch 27, Val Loss: 2.09073
Epoch 28, Val Loss: 2.07536
Epoch 29, Val Loss: 2.10288
Epoch 30, Val Loss: 2.07820
Epoch 31, Val Loss: 2.07602
Epoch 32, Val Loss: 2.07185
Epoch 33, Val Loss: 2.07336
Epoch 34, Val Loss: 2.08005
Epoch 35, Val Loss: 2.08246
Epoch 36, Val Loss: 2.06936
Epoch 37, Val Loss: 2.08184
Epoch 38, Val Loss: 2.08073
Epoch 39, Val Loss: 2.07252
Epoch 40, Val Loss: 2.08322
Epoch 41, Val Loss: 2.06973
Epoch 42, Val Loss: 2.07533
Epoch 43, Val Loss: 2.06927
Epoch 44, Val Loss: 2.07379
Epoch 45, Val Loss: 2.07793
Epoch 46, Val Loss: 2.06988
Epoch 47, Val Loss: 2.06973
Epoch 48, Val Loss: 2.06439
Epoch 49, Val Loss: 2.07348
Epoch 50, Val Loss: 2.07339
Epoch 51, Val Loss: 2.07317
Epoch 52, Val Loss: 2.07752
Epoch 53, Val Loss: 2.07054
Epoch 54, Val Loss: 2.06295
Epoch 55, Val Loss: 2.07551
Epoch 56, Val Loss: 2.06926
Epoch 57, Val Loss: 2.06832
Epoch 58, Val Loss: 2.08193
Epoch 59, Val Loss: 2.07338
Epoch 60, Val Loss: 2.06390
Epoch 61, Val Loss: 2.07793
Epoch 62, Val Loss: 2.06917
Epoch 63, Val Loss: 2.07231
Epoch 64, Val Loss: 2.07107
Epoch 65, Val Loss: 2.06444
Epoch 66, Val Loss: 2.06976
Epoch 67, Val Loss: 2.06547
Epoch 68, Val Loss: 2.06227
Epoch 69, Val Loss: 2.07147
Epoch 70, Val Loss: 2.06838
Epoch 71, Val Loss: 2.07893
Epoch 72, Val Loss: 2.06712
Epoch 73, Val Loss: 2.06427
Epoch 74, Val Loss: 2.05941
Epoch 75, Val Loss: 2.07361
Epoch 76, Val Loss: 2.06860
Epoch 77, Val Loss: 2.06876
Epoch 78, Val Loss: 2.06430
Epoch 79, Val Loss: 2.06670
Epoch 80, Val Loss: 2.06631
Epoch 81, Val Loss: 2.06215
Epoch 82, Val Loss: 2.07007
Epoch 83, Val Loss: 2.06360
Epoch 84, Val Loss: 2.06660
Epoch 85, Val Loss: 2.07134
Epoch 86, Val Loss: 2.06834
Epoch 87, Val Loss: 2.06476
Epoch 88, Val Loss: 2.06754
Epoch 89, Val Loss: 2.06335
Epoch 90, Val Loss: 2.05842
Epoch 91, Val Loss: 2.06319
Epoch 92, Val Loss: 2.07076
Epoch 93, Val Loss: 2.06903
Epoch 94, Val Loss: 2.06566
Epoch 95, Val Loss: 2.06847
Epoch 96, Val Loss: 2.06362
Epoch 97, Val Loss: 2.06032
Epoch 98, Val Loss: 2.06690
Epoch 99, Val Loss: 2.06546
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.360566666666667, 'Log Loss - std': 0.24442073470873033} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}
Fitted encoder
Epoch 0, Val Loss: 2.08219
Epoch 1, Val Loss: 2.07581
Epoch 2, Val Loss: 2.06952
Epoch 3, Val Loss: 2.05035
Epoch 4, Val Loss: 2.05774
Epoch 5, Val Loss: 2.05019
Epoch 6, Val Loss: 2.03371
Epoch 7, Val Loss: 2.04402
Epoch 8, Val Loss: 2.03970
Epoch 9, Val Loss: 2.03966
Epoch 10, Val Loss: 2.02854
Epoch 11, Val Loss: 2.04724
Epoch 12, Val Loss: 2.03230
Epoch 13, Val Loss: 2.03004
Epoch 14, Val Loss: 2.03254
Epoch 15, Val Loss: 2.03206
Epoch 16, Val Loss: 2.02855
Epoch 17, Val Loss: 2.02683
Epoch 18, Val Loss: 2.02778
Epoch 19, Val Loss: 2.01733
Epoch 20, Val Loss: 2.02412
Epoch 21, Val Loss: 2.01475
Epoch 22, Val Loss: 2.03591
Epoch 23, Val Loss: 2.02576
Epoch 24, Val Loss: 2.04139
Epoch 25, Val Loss: 2.01970
Epoch 26, Val Loss: 2.02534
Epoch 27, Val Loss: 2.02629
Epoch 28, Val Loss: 2.02582
Epoch 29, Val Loss: 2.01668
Epoch 30, Val Loss: 2.03375
Epoch 31, Val Loss: 2.02566
Epoch 32, Val Loss: 2.02574
Epoch 33, Val Loss: 2.01266
Epoch 34, Val Loss: 2.01952
Epoch 35, Val Loss: 2.02683
Epoch 36, Val Loss: 2.02130
Epoch 37, Val Loss: 2.02242
Epoch 38, Val Loss: 2.01664
Epoch 39, Val Loss: 2.02524
Epoch 40, Val Loss: 2.02087
Epoch 41, Val Loss: 2.01473
Epoch 42, Val Loss: 2.02029
Epoch 43, Val Loss: 2.02176
Epoch 44, Val Loss: 2.02548
Epoch 45, Val Loss: 2.00992
Epoch 46, Val Loss: 2.01588
Epoch 47, Val Loss: 2.01889
Epoch 48, Val Loss: 2.01368
Epoch 49, Val Loss: 2.01680
Epoch 50, Val Loss: 2.01517
Epoch 51, Val Loss: 2.03109
Epoch 52, Val Loss: 2.00911
Epoch 53, Val Loss: 2.01771
Epoch 54, Val Loss: 2.01840
Epoch 55, Val Loss: 2.01920
Epoch 56, Val Loss: 2.02559
Epoch 57, Val Loss: 2.02815
Epoch 58, Val Loss: 2.02401
Epoch 59, Val Loss: 2.02336
Epoch 60, Val Loss: 2.02016
Epoch 61, Val Loss: 2.02197
Epoch 62, Val Loss: 2.02802
Epoch 63, Val Loss: 2.02682
Epoch 64, Val Loss: 2.02025
Epoch 65, Val Loss: 2.01393
Epoch 66, Val Loss: 2.02548
Epoch 67, Val Loss: 2.02251
Epoch 68, Val Loss: 2.02159
Epoch 69, Val Loss: 2.03085
Epoch 70, Val Loss: 2.01883
Epoch 71, Val Loss: 2.01935
Epoch 72, Val Loss: 2.01938
Epoch 73, Val Loss: 2.02040
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.1445250000000002, 'Log Loss - std': 0.42991641847573114} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}
Fitted encoder
Epoch 0, Val Loss: 2.04487
Epoch 1, Val Loss: 2.03706
Epoch 2, Val Loss: 2.04021
Epoch 3, Val Loss: 1.94321
Epoch 4, Val Loss: 1.95733
Epoch 5, Val Loss: 1.95743
Epoch 6, Val Loss: 1.93810
Epoch 7, Val Loss: 1.94137
Epoch 8, Val Loss: 1.94579
Epoch 9, Val Loss: 1.94552
Epoch 10, Val Loss: 1.93983
Epoch 11, Val Loss: 1.94086
Epoch 12, Val Loss: 1.93913
Epoch 13, Val Loss: 1.94548
Epoch 14, Val Loss: 1.93708
Epoch 15, Val Loss: 1.93936
Epoch 16, Val Loss: 1.92870
Epoch 17, Val Loss: 1.93615
Epoch 18, Val Loss: 1.93712
Epoch 19, Val Loss: 1.91382
Epoch 20, Val Loss: 1.90907
Epoch 21, Val Loss: 1.92138
Epoch 22, Val Loss: 1.89871
Epoch 23, Val Loss: 1.89258
Epoch 24, Val Loss: 1.90869
Epoch 25, Val Loss: 1.91682
Epoch 26, Val Loss: 1.90148
Epoch 27, Val Loss: 1.89180
Epoch 28, Val Loss: 1.92386
Epoch 29, Val Loss: 1.90551
Epoch 30, Val Loss: 1.88965
Epoch 31, Val Loss: 1.90311
Epoch 32, Val Loss: 1.89945
Epoch 33, Val Loss: 1.91453
Epoch 34, Val Loss: 1.89168
Epoch 35, Val Loss: 1.89821
Epoch 36, Val Loss: 1.90159
Epoch 37, Val Loss: 1.90707
Epoch 38, Val Loss: 1.88849
Epoch 39, Val Loss: 1.89744
Epoch 40, Val Loss: 1.88638
Epoch 41, Val Loss: 1.88900
Epoch 42, Val Loss: 1.90121
Epoch 43, Val Loss: 1.89661
Epoch 44, Val Loss: 1.89460
Epoch 45, Val Loss: 1.88387
Epoch 46, Val Loss: 1.89253
Epoch 47, Val Loss: 1.88799
Epoch 48, Val Loss: 1.87915
Epoch 49, Val Loss: 1.89332
Epoch 50, Val Loss: 1.89890
Epoch 51, Val Loss: 1.88494
Epoch 52, Val Loss: 1.89136
Epoch 53, Val Loss: 1.90472
Epoch 54, Val Loss: 1.89580
Epoch 55, Val Loss: 1.88245
Epoch 56, Val Loss: 1.89302
Epoch 57, Val Loss: 1.88668
Epoch 58, Val Loss: 1.88609
Epoch 59, Val Loss: 1.89267
Epoch 60, Val Loss: 1.88308
Epoch 61, Val Loss: 1.88145
Epoch 62, Val Loss: 1.88710
Epoch 63, Val Loss: 1.88852
Epoch 64, Val Loss: 1.88564
Epoch 65, Val Loss: 1.88370
Epoch 66, Val Loss: 1.88545
Epoch 67, Val Loss: 1.88310
Epoch 68, Val Loss: 1.90796
Epoch 69, Val Loss: 1.88715
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.10336, 'Log Loss - std': 0.3932438561503536} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 29 finished with value: 3.10336 and parameters: {'p_m': 0.10930479067193222, 'alpha': 0.19385878636231002, 'K': 3, 'beta': 2.863868642447464}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}
Fitted encoder
Epoch 0, Val Loss: 2.13879
Epoch 1, Val Loss: 2.13043
Epoch 2, Val Loss: 2.12825
Epoch 3, Val Loss: 2.11893
Epoch 4, Val Loss: 2.11446
Epoch 5, Val Loss: 2.13462
Epoch 6, Val Loss: 2.11912
Epoch 7, Val Loss: 2.08573
Epoch 8, Val Loss: 2.11912
Epoch 9, Val Loss: 2.10188
Epoch 10, Val Loss: 2.08957
Epoch 11, Val Loss: 2.08535
Epoch 12, Val Loss: 2.10242
Epoch 13, Val Loss: 2.10974
Epoch 14, Val Loss: 2.11375
Epoch 15, Val Loss: 2.07037
Epoch 16, Val Loss: 2.08195
Epoch 17, Val Loss: 2.08330
Epoch 18, Val Loss: 2.11663
Epoch 19, Val Loss: 2.10445
Epoch 20, Val Loss: 2.08609
Epoch 21, Val Loss: 2.10907
Epoch 22, Val Loss: 2.11370
Epoch 23, Val Loss: 2.10436
Epoch 24, Val Loss: 2.08626
Epoch 25, Val Loss: 2.08643
Epoch 26, Val Loss: 2.09203
Epoch 27, Val Loss: 2.06195
Epoch 28, Val Loss: 2.10945
Epoch 29, Val Loss: 2.06082
Epoch 30, Val Loss: 2.11331
Epoch 31, Val Loss: 2.07773
Epoch 32, Val Loss: 2.08067
Epoch 33, Val Loss: 2.08176
Epoch 34, Val Loss: 2.07960
Epoch 35, Val Loss: 2.08982
Epoch 36, Val Loss: 2.08530
Epoch 37, Val Loss: 2.09265
Epoch 38, Val Loss: 2.10552
Epoch 39, Val Loss: 2.08406
Epoch 40, Val Loss: 2.10538
Epoch 41, Val Loss: 2.06365
Epoch 42, Val Loss: 2.07063
Epoch 43, Val Loss: 2.07631
Epoch 44, Val Loss: 2.07805
Epoch 45, Val Loss: 2.06052
Epoch 46, Val Loss: 2.06797
Epoch 47, Val Loss: 2.09021
Epoch 48, Val Loss: 2.09355
Epoch 49, Val Loss: 2.05922
Epoch 50, Val Loss: 2.06052
Epoch 51, Val Loss: 2.05426
Epoch 52, Val Loss: 2.06420
Epoch 53, Val Loss: 2.07465
Epoch 54, Val Loss: 2.07541
Epoch 55, Val Loss: 2.06772
Epoch 56, Val Loss: 2.06084
Epoch 57, Val Loss: 2.06604
Epoch 58, Val Loss: 2.06350
Epoch 59, Val Loss: 2.05289
Epoch 60, Val Loss: 2.06836
Epoch 61, Val Loss: 2.07260
Epoch 62, Val Loss: 2.08055
Epoch 63, Val Loss: 2.05792
Epoch 64, Val Loss: 2.05288
Epoch 65, Val Loss: 2.06622
Epoch 66, Val Loss: 2.05565
Epoch 67, Val Loss: 2.07376
Epoch 68, Val Loss: 2.11711
Epoch 69, Val Loss: 2.10249
Epoch 70, Val Loss: 2.08844
Epoch 71, Val Loss: 2.08601
Epoch 72, Val Loss: 2.06679
Epoch 73, Val Loss: 2.11676
Epoch 74, Val Loss: 2.14593
Epoch 75, Val Loss: 2.12863
Epoch 76, Val Loss: 2.12856
Epoch 77, Val Loss: 2.13491
Epoch 78, Val Loss: 2.14958
Epoch 79, Val Loss: 2.15705
Epoch 80, Val Loss: 2.14603
Epoch 81, Val Loss: 2.12440
Epoch 82, Val Loss: 2.11834
Epoch 83, Val Loss: 2.12686
Epoch 84, Val Loss: 2.12426
Epoch 85, Val Loss: 2.11048
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.0625, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}
Fitted encoder
Epoch 0, Val Loss: 1.96203
Epoch 1, Val Loss: 1.95742
Epoch 2, Val Loss: 1.95206
Epoch 3, Val Loss: 1.93375
Epoch 4, Val Loss: 1.95070
Epoch 5, Val Loss: 1.95551
Epoch 6, Val Loss: 1.92228
Epoch 7, Val Loss: 1.92504
Epoch 8, Val Loss: 2.01576
Epoch 9, Val Loss: 1.92634
Epoch 10, Val Loss: 1.92551
Epoch 11, Val Loss: 1.91047
Epoch 12, Val Loss: 1.91452
Epoch 13, Val Loss: 1.93282
Epoch 14, Val Loss: 1.91706
Epoch 15, Val Loss: 1.93991
Epoch 16, Val Loss: 1.90829
Epoch 17, Val Loss: 1.92006
Epoch 18, Val Loss: 1.90170
Epoch 19, Val Loss: 1.92172
Epoch 20, Val Loss: 1.90609
Epoch 21, Val Loss: 1.91565
Epoch 22, Val Loss: 1.91022
Epoch 23, Val Loss: 1.92866
Epoch 24, Val Loss: 1.95038
Epoch 25, Val Loss: 1.93082
Epoch 26, Val Loss: 1.93978
Epoch 27, Val Loss: 1.92941
Epoch 28, Val Loss: 1.92294
Epoch 29, Val Loss: 1.91716
Epoch 30, Val Loss: 1.95705
Epoch 31, Val Loss: 1.91782
Epoch 32, Val Loss: 1.95544
Epoch 33, Val Loss: 1.94243
Epoch 34, Val Loss: 1.91358
Epoch 35, Val Loss: 1.94881
Epoch 36, Val Loss: 1.92098
Epoch 37, Val Loss: 1.94067
Epoch 38, Val Loss: 1.92043
Epoch 39, Val Loss: 1.93886
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.64865, 'Log Loss - std': 0.41385000000000005} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}
Fitted encoder
Epoch 0, Val Loss: 2.15797
Epoch 1, Val Loss: 2.12076
Epoch 2, Val Loss: 2.11366
Epoch 3, Val Loss: 2.13039
Epoch 4, Val Loss: 2.13906
Epoch 5, Val Loss: 2.13816
Epoch 6, Val Loss: 2.10959
Epoch 7, Val Loss: 2.12201
Epoch 8, Val Loss: 2.11778
Epoch 9, Val Loss: 2.10538
Epoch 10, Val Loss: 2.13289
Epoch 11, Val Loss: 2.11286
Epoch 12, Val Loss: 2.09720
Epoch 13, Val Loss: 2.08733
Epoch 14, Val Loss: 2.08633
Epoch 15, Val Loss: 2.10619
Epoch 16, Val Loss: 2.09983
Epoch 17, Val Loss: 2.08628
Epoch 18, Val Loss: 2.10747
Epoch 19, Val Loss: 2.10949
Epoch 20, Val Loss: 2.10554
Epoch 21, Val Loss: 2.12056
Epoch 22, Val Loss: 2.12105
Epoch 23, Val Loss: 2.10426
Epoch 24, Val Loss: 2.09453
Epoch 25, Val Loss: 2.08718
Epoch 26, Val Loss: 2.10721
Epoch 27, Val Loss: 2.08497
Epoch 28, Val Loss: 2.09820
Epoch 29, Val Loss: 2.11887
Epoch 30, Val Loss: 2.11014
Epoch 31, Val Loss: 2.11826
Epoch 32, Val Loss: 2.12893
Epoch 33, Val Loss: 2.12858
Epoch 34, Val Loss: 2.11227
Epoch 35, Val Loss: 2.10732
Epoch 36, Val Loss: 2.09186
Epoch 37, Val Loss: 2.08424
Epoch 38, Val Loss: 2.11546
Epoch 39, Val Loss: 2.08325
Epoch 40, Val Loss: 2.12226
Epoch 41, Val Loss: 2.11934
Epoch 42, Val Loss: 2.12989
Epoch 43, Val Loss: 2.08877
Epoch 44, Val Loss: 2.09124
Epoch 45, Val Loss: 2.07994
Epoch 46, Val Loss: 2.11280
Epoch 47, Val Loss: 2.07341
Epoch 48, Val Loss: 2.08125
Epoch 49, Val Loss: 2.07977
Epoch 50, Val Loss: 2.08237
Epoch 51, Val Loss: 2.09897
Epoch 52, Val Loss: 2.09928
Epoch 53, Val Loss: 2.11063
Epoch 54, Val Loss: 2.10530
Epoch 55, Val Loss: 2.08067
Epoch 56, Val Loss: 2.07895
Epoch 57, Val Loss: 2.10731
Epoch 58, Val Loss: 2.08493
Epoch 59, Val Loss: 2.11326
Epoch 60, Val Loss: 2.10755
Epoch 61, Val Loss: 2.10948
Epoch 62, Val Loss: 2.09519
Epoch 63, Val Loss: 2.07878
Epoch 64, Val Loss: 2.08509
Epoch 65, Val Loss: 2.07434
Epoch 66, Val Loss: 2.07519
Epoch 67, Val Loss: 2.08885
Epoch 68, Val Loss: 2.09035
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.7189666666666668, 'Log Loss - std': 0.3522358332456002} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}
Fitted encoder
Epoch 0, Val Loss: 2.07632
Epoch 1, Val Loss: 2.06699
Epoch 2, Val Loss: 2.06601
Epoch 3, Val Loss: 2.05506
Epoch 4, Val Loss: 2.06414
Epoch 5, Val Loss: 2.09234
Epoch 6, Val Loss: 2.05378
Epoch 7, Val Loss: 2.13312
Epoch 8, Val Loss: 2.04142
Epoch 9, Val Loss: 2.03928
Epoch 10, Val Loss: 2.11327
Epoch 11, Val Loss: 2.04657
Epoch 12, Val Loss: 2.10547
Epoch 13, Val Loss: 2.09489
Epoch 14, Val Loss: 2.10973
Epoch 15, Val Loss: 2.07554
Epoch 16, Val Loss: 2.06380
Epoch 17, Val Loss: 2.15300
Epoch 18, Val Loss: 2.09118
Epoch 19, Val Loss: 2.05543
Epoch 20, Val Loss: 2.05380
Epoch 21, Val Loss: 2.04051
Epoch 22, Val Loss: 2.04370
Epoch 23, Val Loss: 2.03759
Epoch 24, Val Loss: 2.03695
Epoch 25, Val Loss: 2.03427
Epoch 26, Val Loss: 2.04669
Epoch 27, Val Loss: 2.04237
Epoch 28, Val Loss: 2.03804
Epoch 29, Val Loss: 2.02826
Epoch 30, Val Loss: 2.01779
Epoch 31, Val Loss: 2.03367
Epoch 32, Val Loss: 2.12285
Epoch 33, Val Loss: 2.05387
Epoch 34, Val Loss: 2.03427
Epoch 35, Val Loss: 2.02527
Epoch 36, Val Loss: 2.03176
Epoch 37, Val Loss: 2.04132
Epoch 38, Val Loss: 2.02853
Epoch 39, Val Loss: 2.04220
Epoch 40, Val Loss: 2.02347
Epoch 41, Val Loss: 2.03454
Epoch 42, Val Loss: 2.02357
Epoch 43, Val Loss: 2.05855
Epoch 44, Val Loss: 2.04627
Epoch 45, Val Loss: 2.01369
Epoch 46, Val Loss: 2.02190
Epoch 47, Val Loss: 2.05982
Epoch 48, Val Loss: 2.01847
Epoch 49, Val Loss: 2.02530
Epoch 50, Val Loss: 2.04617
Epoch 51, Val Loss: 2.07980
Epoch 52, Val Loss: 2.02771
Epoch 53, Val Loss: 2.03578
Epoch 54, Val Loss: 2.01938
Epoch 55, Val Loss: 2.01710
Epoch 56, Val Loss: 2.04480
Epoch 57, Val Loss: 2.02933
Epoch 58, Val Loss: 2.04929
Epoch 59, Val Loss: 2.02241
Epoch 60, Val Loss: 2.03871
Epoch 61, Val Loss: 2.02814
Epoch 62, Val Loss: 2.04630
Epoch 63, Val Loss: 2.01831
Epoch 64, Val Loss: 2.07690
Epoch 65, Val Loss: 2.04026
Epoch 66, Val Loss: 2.03380
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.4788, 'Log Loss - std': 0.5158416859851479} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}
Fitted encoder
Epoch 0, Val Loss: 1.95873
Epoch 1, Val Loss: 1.95010
Epoch 2, Val Loss: 1.93349
Epoch 3, Val Loss: 1.92954
Epoch 4, Val Loss: 1.92575
Epoch 5, Val Loss: 1.93479
Epoch 6, Val Loss: 1.96019
Epoch 7, Val Loss: 1.94795
Epoch 8, Val Loss: 1.94641
Epoch 9, Val Loss: 1.95427
Epoch 10, Val Loss: 1.94445
Epoch 11, Val Loss: 1.94549
Epoch 12, Val Loss: 1.95199
Epoch 13, Val Loss: 1.90502
Epoch 14, Val Loss: 1.90202
Epoch 15, Val Loss: 1.91330
Epoch 16, Val Loss: 1.93560
Epoch 17, Val Loss: 1.90743
Epoch 18, Val Loss: 1.88871
Epoch 19, Val Loss: 1.88408
Epoch 20, Val Loss: 1.92080
Epoch 21, Val Loss: 1.89769
Epoch 22, Val Loss: 1.90928
Epoch 23, Val Loss: 1.89894
Epoch 24, Val Loss: 1.90019
Epoch 25, Val Loss: 1.89607
Epoch 26, Val Loss: 1.90183
Epoch 27, Val Loss: 1.88847
Epoch 28, Val Loss: 1.89428
Epoch 29, Val Loss: 1.89583
Epoch 30, Val Loss: 1.89969
Epoch 31, Val Loss: 1.90937
Epoch 32, Val Loss: 1.90700
Epoch 33, Val Loss: 1.89944
Epoch 34, Val Loss: 1.90194
Epoch 35, Val Loss: 1.95135
Epoch 36, Val Loss: 1.95125
Epoch 37, Val Loss: 2.02186
Epoch 38, Val Loss: 1.93689
Epoch 39, Val Loss: 1.92291
Epoch 40, Val Loss: 2.02978
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.4108400000000003, 'Log Loss - std': 0.4809868630222659} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 30 finished with value: 3.4108400000000003 and parameters: {'p_m': 0.7998923310906784, 'alpha': 3.5326955359806256, 'K': 3, 'beta': 1.4381021280787747}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}
Fitted encoder
Epoch 0, Val Loss: 2.15513
Epoch 1, Val Loss: 2.12201
Epoch 2, Val Loss: 2.12392
Epoch 3, Val Loss: 2.09694
Epoch 4, Val Loss: 2.10906
Epoch 5, Val Loss: 2.11997
Epoch 6, Val Loss: 2.11367
Epoch 7, Val Loss: 2.11426
Epoch 8, Val Loss: 2.09670
Epoch 9, Val Loss: 2.10613
Epoch 10, Val Loss: 2.09938
Epoch 11, Val Loss: 2.10153
Epoch 12, Val Loss: 2.09557
Epoch 13, Val Loss: 2.08755
Epoch 14, Val Loss: 2.08536
Epoch 15, Val Loss: 2.09824
Epoch 16, Val Loss: 2.09351
Epoch 17, Val Loss: 2.10465
Epoch 18, Val Loss: 2.10123
Epoch 19, Val Loss: 2.09886
Epoch 20, Val Loss: 2.08901
Epoch 21, Val Loss: 2.09662
Epoch 22, Val Loss: 2.09458
Epoch 23, Val Loss: 2.08579
Epoch 24, Val Loss: 2.08479
Epoch 25, Val Loss: 2.08543
Epoch 26, Val Loss: 2.08279
Epoch 27, Val Loss: 2.10498
Epoch 28, Val Loss: 2.08618
Epoch 29, Val Loss: 2.08644
Epoch 30, Val Loss: 2.08882
Epoch 31, Val Loss: 2.12197
Epoch 32, Val Loss: 2.08330
Epoch 33, Val Loss: 2.08726
Epoch 34, Val Loss: 2.09532
Epoch 35, Val Loss: 2.10291
Epoch 36, Val Loss: 2.09288
Epoch 37, Val Loss: 2.08789
Epoch 38, Val Loss: 2.08760
Epoch 39, Val Loss: 2.09313
Epoch 40, Val Loss: 2.08198
Epoch 41, Val Loss: 2.09695
Epoch 42, Val Loss: 2.12422
Epoch 43, Val Loss: 2.08188
Epoch 44, Val Loss: 2.11878
Epoch 45, Val Loss: 2.11192
Epoch 46, Val Loss: 2.09376
Epoch 47, Val Loss: 2.08912
Epoch 48, Val Loss: 2.10081
Epoch 49, Val Loss: 2.08486
Epoch 50, Val Loss: 2.08972
Epoch 51, Val Loss: 2.08786
Epoch 52, Val Loss: 2.09386
Epoch 53, Val Loss: 2.08414
Epoch 54, Val Loss: 2.09414
Epoch 55, Val Loss: 2.08489
Epoch 56, Val Loss: 2.08219
Epoch 57, Val Loss: 2.12712
Epoch 58, Val Loss: 2.08150
Epoch 59, Val Loss: 2.07256
Epoch 60, Val Loss: 2.09630
Epoch 61, Val Loss: 2.09076
Epoch 62, Val Loss: 2.06802
Epoch 63, Val Loss: 2.07646
Epoch 64, Val Loss: 2.06704
Epoch 65, Val Loss: 2.07487
Epoch 66, Val Loss: 2.07837
Epoch 67, Val Loss: 2.08630
Epoch 68, Val Loss: 2.06306
Epoch 69, Val Loss: 2.07330
Epoch 70, Val Loss: 2.10185
Epoch 71, Val Loss: 2.11186
Epoch 72, Val Loss: 2.11019
Epoch 73, Val Loss: 2.08795
Epoch 74, Val Loss: 2.07348
Epoch 75, Val Loss: 2.07253
Epoch 76, Val Loss: 2.05830
Epoch 77, Val Loss: 2.05572
Epoch 78, Val Loss: 2.04421
Epoch 79, Val Loss: 2.05755
Epoch 80, Val Loss: 2.09992
Epoch 81, Val Loss: 2.04383
Epoch 82, Val Loss: 2.04217
Epoch 83, Val Loss: 2.05931
Epoch 84, Val Loss: 2.07040
Epoch 85, Val Loss: 2.07230
Epoch 86, Val Loss: 2.05761
Epoch 87, Val Loss: 2.03243
Epoch 88, Val Loss: 2.05805
Epoch 89, Val Loss: 2.05033
Epoch 90, Val Loss: 2.05433
Epoch 91, Val Loss: 2.05838
Epoch 92, Val Loss: 2.05443
Epoch 93, Val Loss: 2.04586
Epoch 94, Val Loss: 2.06365
Epoch 95, Val Loss: 2.14462
Epoch 96, Val Loss: 2.08247
Epoch 97, Val Loss: 2.08830
Epoch 98, Val Loss: 2.05440
Epoch 99, Val Loss: 2.06086
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.4977, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}
Fitted encoder
Epoch 0, Val Loss: 1.97052
Epoch 1, Val Loss: 1.98595
Epoch 2, Val Loss: 1.96048
Epoch 3, Val Loss: 1.96782
Epoch 4, Val Loss: 1.96643
Epoch 5, Val Loss: 1.95526
Epoch 6, Val Loss: 1.95266
Epoch 7, Val Loss: 1.94475
Epoch 8, Val Loss: 1.95406
Epoch 9, Val Loss: 1.93493
Epoch 10, Val Loss: 1.97026
Epoch 11, Val Loss: 1.95627
Epoch 12, Val Loss: 1.93956
Epoch 13, Val Loss: 1.94124
Epoch 14, Val Loss: 1.94772
Epoch 15, Val Loss: 1.94347
Epoch 16, Val Loss: 1.95870
Epoch 17, Val Loss: 2.00949
Epoch 18, Val Loss: 1.94300
Epoch 19, Val Loss: 1.94365
Epoch 20, Val Loss: 1.93908
Epoch 21, Val Loss: 1.95672
Epoch 22, Val Loss: 1.95605
Epoch 23, Val Loss: 1.95705
Epoch 24, Val Loss: 1.94545
Epoch 25, Val Loss: 1.93262
Epoch 26, Val Loss: 1.92784
Epoch 27, Val Loss: 1.94101
Epoch 28, Val Loss: 1.91840
Epoch 29, Val Loss: 1.91964
Epoch 30, Val Loss: 1.92735
Epoch 31, Val Loss: 1.93826
Epoch 32, Val Loss: 1.92233
Epoch 33, Val Loss: 1.93101
Epoch 34, Val Loss: 1.91399
Epoch 35, Val Loss: 1.94598
Epoch 36, Val Loss: 1.93055
Epoch 37, Val Loss: 1.92654
Epoch 38, Val Loss: 1.93023
Epoch 39, Val Loss: 1.90722
Epoch 40, Val Loss: 1.90993
Epoch 41, Val Loss: 1.91018
Epoch 42, Val Loss: 1.92616
Epoch 43, Val Loss: 1.89859
Epoch 44, Val Loss: 1.93181
Epoch 45, Val Loss: 1.91345
Epoch 46, Val Loss: 1.91789
Epoch 47, Val Loss: 1.91112
Epoch 48, Val Loss: 1.92157
Epoch 49, Val Loss: 1.90360
Epoch 50, Val Loss: 1.91076
Epoch 51, Val Loss: 1.91233
Epoch 52, Val Loss: 1.90264
Epoch 53, Val Loss: 1.91796
Epoch 54, Val Loss: 1.90596
Epoch 55, Val Loss: 1.92351
Epoch 56, Val Loss: 1.90445
Epoch 57, Val Loss: 1.90680
Epoch 58, Val Loss: 1.89873
Epoch 59, Val Loss: 1.91350
Epoch 60, Val Loss: 1.92316
Epoch 61, Val Loss: 1.93451
Epoch 62, Val Loss: 1.90934
Epoch 63, Val Loss: 1.90471
Epoch 64, Val Loss: 1.92031
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.55525, 'Log Loss - std': 0.05754999999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}
Fitted encoder
Epoch 0, Val Loss: 2.15160
Epoch 1, Val Loss: 2.12747
Epoch 2, Val Loss: 2.11993
Epoch 3, Val Loss: 2.12292
Epoch 4, Val Loss: 2.12157
Epoch 5, Val Loss: 2.12497
Epoch 6, Val Loss: 2.11352
Epoch 7, Val Loss: 2.12371
Epoch 8, Val Loss: 2.11611
Epoch 9, Val Loss: 2.12001
Epoch 10, Val Loss: 2.11755
Epoch 11, Val Loss: 2.11201
Epoch 12, Val Loss: 2.11592
Epoch 13, Val Loss: 2.12914
Epoch 14, Val Loss: 2.12173
Epoch 15, Val Loss: 2.10995
Epoch 16, Val Loss: 2.11431
Epoch 17, Val Loss: 2.12224
Epoch 18, Val Loss: 2.10378
Epoch 19, Val Loss: 2.10433
Epoch 20, Val Loss: 2.11156
Epoch 21, Val Loss: 2.14001
Epoch 22, Val Loss: 2.12544
Epoch 23, Val Loss: 2.11839
Epoch 24, Val Loss: 2.10866
Epoch 25, Val Loss: 2.11822
Epoch 26, Val Loss: 2.10203
Epoch 27, Val Loss: 2.10842
Epoch 28, Val Loss: 2.08853
Epoch 29, Val Loss: 2.09808
Epoch 30, Val Loss: 2.13604
Epoch 31, Val Loss: 2.09439
Epoch 32, Val Loss: 2.09573
Epoch 33, Val Loss: 2.10641
Epoch 34, Val Loss: 2.12397
Epoch 35, Val Loss: 2.09878
Epoch 36, Val Loss: 2.10757
Epoch 37, Val Loss: 2.09275
Epoch 38, Val Loss: 2.10038
Epoch 39, Val Loss: 2.09040
Epoch 40, Val Loss: 2.09475
Epoch 41, Val Loss: 2.09990
Epoch 42, Val Loss: 2.08835
Epoch 43, Val Loss: 2.08251
Epoch 44, Val Loss: 2.09080
Epoch 45, Val Loss: 2.07770
Epoch 46, Val Loss: 2.09444
Epoch 47, Val Loss: 2.08240
Epoch 48, Val Loss: 2.08720
Epoch 49, Val Loss: 2.10656
Epoch 50, Val Loss: 2.09159
Epoch 51, Val Loss: 2.07470
Epoch 52, Val Loss: 2.09836
Epoch 53, Val Loss: 2.08018
Epoch 54, Val Loss: 2.10151
Epoch 55, Val Loss: 2.08489
Epoch 56, Val Loss: 2.08167
Epoch 57, Val Loss: 2.08180
Epoch 58, Val Loss: 2.08898
Epoch 59, Val Loss: 2.06593
Epoch 60, Val Loss: 2.09311
Epoch 61, Val Loss: 2.07219
Epoch 62, Val Loss: 2.06829
Epoch 63, Val Loss: 2.09412
Epoch 64, Val Loss: 2.09016
Epoch 65, Val Loss: 2.09058
Epoch 66, Val Loss: 2.07685
Epoch 67, Val Loss: 2.07046
Epoch 68, Val Loss: 2.06955
Epoch 69, Val Loss: 2.07015
Epoch 70, Val Loss: 2.07729
Epoch 71, Val Loss: 2.07497
Epoch 72, Val Loss: 2.09882
Epoch 73, Val Loss: 2.10763
Epoch 74, Val Loss: 2.08829
Epoch 75, Val Loss: 2.07522
Epoch 76, Val Loss: 2.07987
Epoch 77, Val Loss: 2.06831
Epoch 78, Val Loss: 2.08382
Epoch 79, Val Loss: 2.06843
Epoch 80, Val Loss: 2.08219
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6645, 'Log Loss - std': 0.16149032994785373} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}
Fitted encoder
Epoch 0, Val Loss: 2.08121
Epoch 1, Val Loss: 2.07163
Epoch 2, Val Loss: 2.08406
Epoch 3, Val Loss: 2.06899
Epoch 4, Val Loss: 2.07445
Epoch 5, Val Loss: 2.08163
Epoch 6, Val Loss: 2.06395
Epoch 7, Val Loss: 2.07009
Epoch 8, Val Loss: 2.08782
Epoch 9, Val Loss: 2.07238
Epoch 10, Val Loss: 2.06285
Epoch 11, Val Loss: 2.06718
Epoch 12, Val Loss: 2.08358
Epoch 13, Val Loss: 2.08320
Epoch 14, Val Loss: 2.06180
Epoch 15, Val Loss: 2.07580
Epoch 16, Val Loss: 2.06825
Epoch 17, Val Loss: 2.06756
Epoch 18, Val Loss: 2.06830
Epoch 19, Val Loss: 2.09194
Epoch 20, Val Loss: 2.06860
Epoch 21, Val Loss: 2.07245
Epoch 22, Val Loss: 2.06922
Epoch 23, Val Loss: 2.05052
Epoch 24, Val Loss: 2.08640
Epoch 25, Val Loss: 2.05882
Epoch 26, Val Loss: 2.05782
Epoch 27, Val Loss: 2.06893
Epoch 28, Val Loss: 2.06385
Epoch 29, Val Loss: 2.06836
Epoch 30, Val Loss: 2.07138
Epoch 31, Val Loss: 2.06459
Epoch 32, Val Loss: 2.05925
Epoch 33, Val Loss: 2.08925
Epoch 34, Val Loss: 2.06070
Epoch 35, Val Loss: 2.06764
Epoch 36, Val Loss: 2.06547
Epoch 37, Val Loss: 2.07412
Epoch 38, Val Loss: 2.05883
Epoch 39, Val Loss: 2.05307
Epoch 40, Val Loss: 2.08941
Epoch 41, Val Loss: 2.04310
Epoch 42, Val Loss: 2.05348
Epoch 43, Val Loss: 2.05030
Epoch 44, Val Loss: 2.11894
Epoch 45, Val Loss: 2.05270
Epoch 46, Val Loss: 2.05228
Epoch 47, Val Loss: 2.07908
Epoch 48, Val Loss: 2.04908
Epoch 49, Val Loss: 2.05520
Epoch 50, Val Loss: 2.04971
Epoch 51, Val Loss: 2.05987
Epoch 52, Val Loss: 2.03807
Epoch 53, Val Loss: 2.04464
Epoch 54, Val Loss: 2.05792
Epoch 55, Val Loss: 2.05765
Epoch 56, Val Loss: 2.03013
Epoch 57, Val Loss: 2.04261
Epoch 58, Val Loss: 2.06544
Epoch 59, Val Loss: 2.06254
Epoch 60, Val Loss: 2.04953
Epoch 61, Val Loss: 2.05390
Epoch 62, Val Loss: 2.04718
Epoch 63, Val Loss: 2.04001
Epoch 64, Val Loss: 2.04452
Epoch 65, Val Loss: 2.04820
Epoch 66, Val Loss: 2.03621
Epoch 67, Val Loss: 2.06387
Epoch 68, Val Loss: 2.03884
Epoch 69, Val Loss: 2.05071
Epoch 70, Val Loss: 2.03339
Epoch 71, Val Loss: 2.03638
Epoch 72, Val Loss: 2.04509
Epoch 73, Val Loss: 2.06313
Epoch 74, Val Loss: 2.07506
Epoch 75, Val Loss: 2.04065
Epoch 76, Val Loss: 2.05668
Epoch 77, Val Loss: 2.04794
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.5148, 'Log Loss - std': 0.29460077223252484} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}
Fitted encoder
Epoch 0, Val Loss: 1.96455
Epoch 1, Val Loss: 1.96420
Epoch 2, Val Loss: 1.96614
Epoch 3, Val Loss: 1.95638
Epoch 4, Val Loss: 1.97033
Epoch 5, Val Loss: 1.96062
Epoch 6, Val Loss: 1.96357
Epoch 7, Val Loss: 1.97975
Epoch 8, Val Loss: 1.96851
Epoch 9, Val Loss: 1.95384
Epoch 10, Val Loss: 1.95117
Epoch 11, Val Loss: 1.96269
Epoch 12, Val Loss: 1.97621
Epoch 13, Val Loss: 1.94146
Epoch 14, Val Loss: 1.96814
Epoch 15, Val Loss: 1.95134
Epoch 16, Val Loss: 1.95292
Epoch 17, Val Loss: 1.92782
Epoch 18, Val Loss: 1.94624
Epoch 19, Val Loss: 1.93903
Epoch 20, Val Loss: 1.92093
Epoch 21, Val Loss: 1.94366
Epoch 22, Val Loss: 1.95403
Epoch 23, Val Loss: 1.94474
Epoch 24, Val Loss: 1.94078
Epoch 25, Val Loss: 1.94656
Epoch 26, Val Loss: 1.92888
Epoch 27, Val Loss: 1.94819
Epoch 28, Val Loss: 1.93897
Epoch 29, Val Loss: 1.95174
Epoch 30, Val Loss: 1.92083
Epoch 31, Val Loss: 1.91990
Epoch 32, Val Loss: 1.92477
Epoch 33, Val Loss: 1.91889
Epoch 34, Val Loss: 1.90556
Epoch 35, Val Loss: 1.93888
Epoch 36, Val Loss: 1.94366
Epoch 37, Val Loss: 1.92832
Epoch 38, Val Loss: 1.94583
Epoch 39, Val Loss: 1.92271
Epoch 40, Val Loss: 1.94570
Epoch 41, Val Loss: 1.91147
Epoch 42, Val Loss: 1.92395
Epoch 43, Val Loss: 1.93191
Epoch 44, Val Loss: 1.99095
Epoch 45, Val Loss: 1.91432
Epoch 46, Val Loss: 1.90894
Epoch 47, Val Loss: 1.90365
Epoch 48, Val Loss: 1.91059
Epoch 49, Val Loss: 1.92879
Epoch 50, Val Loss: 1.91976
Epoch 51, Val Loss: 1.90856
Epoch 52, Val Loss: 1.91033
Epoch 53, Val Loss: 1.91953
Epoch 54, Val Loss: 1.91230
Epoch 55, Val Loss: 1.94011
Epoch 56, Val Loss: 1.92790
Epoch 57, Val Loss: 1.92165
Epoch 58, Val Loss: 1.92690
Epoch 59, Val Loss: 1.90262
Epoch 60, Val Loss: 1.92313
Epoch 61, Val Loss: 1.89899
Epoch 62, Val Loss: 1.90491
Epoch 63, Val Loss: 1.93486
Epoch 64, Val Loss: 1.90544
Epoch 65, Val Loss: 1.89756
Epoch 66, Val Loss: 1.91713
Epoch 67, Val Loss: 1.89587
Epoch 68, Val Loss: 1.88776
Epoch 69, Val Loss: 1.90298
Epoch 70, Val Loss: 1.92730
Epoch 71, Val Loss: 1.91546
Epoch 72, Val Loss: 1.93018
Epoch 73, Val Loss: 1.91288
Epoch 74, Val Loss: 1.89912
Epoch 75, Val Loss: 1.90398
Epoch 76, Val Loss: 1.91439
Epoch 77, Val Loss: 1.90812
Epoch 78, Val Loss: 1.90668
Epoch 79, Val Loss: 1.90922
Epoch 80, Val Loss: 1.89439
Epoch 81, Val Loss: 1.89471
Epoch 82, Val Loss: 1.90727
Epoch 83, Val Loss: 1.90665
Epoch 84, Val Loss: 1.91074
Epoch 85, Val Loss: 1.90845
Epoch 86, Val Loss: 1.89173
Epoch 87, Val Loss: 1.92086
Epoch 88, Val Loss: 1.89825
Epoch 89, Val Loss: 1.90177
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.67584, 'Log Loss - std': 0.4161336544909579} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 31 finished with value: 2.67584 and parameters: {'p_m': 0.578915873225343, 'alpha': 2.292239536044167, 'K': 10, 'beta': 9.743962870628856}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}
Fitted encoder
Epoch 0, Val Loss: 2.13277
Epoch 1, Val Loss: 2.11865
Epoch 2, Val Loss: 2.10821
Epoch 3, Val Loss: 2.12765
Epoch 4, Val Loss: 2.14103
Epoch 5, Val Loss: 2.10868
Epoch 6, Val Loss: 2.11204
Epoch 7, Val Loss: 2.08225
Epoch 8, Val Loss: 2.09696
Epoch 9, Val Loss: 2.09412
Epoch 10, Val Loss: 2.07791
Epoch 11, Val Loss: 2.07262
Epoch 12, Val Loss: 2.07901
Epoch 13, Val Loss: 2.08261
Epoch 14, Val Loss: 2.09908
Epoch 15, Val Loss: 2.06125
Epoch 16, Val Loss: 2.09382
Epoch 17, Val Loss: 2.09949
Epoch 18, Val Loss: 2.09414
Epoch 19, Val Loss: 2.08570
Epoch 20, Val Loss: 2.07543
Epoch 21, Val Loss: 2.05463
Epoch 22, Val Loss: 2.08112
Epoch 23, Val Loss: 2.07738
Epoch 24, Val Loss: 2.09773
Epoch 25, Val Loss: 2.09309
Epoch 26, Val Loss: 2.13339
Epoch 27, Val Loss: 2.12320
Epoch 28, Val Loss: 2.11857
Epoch 29, Val Loss: 2.10462
Epoch 30, Val Loss: 2.11658
Epoch 31, Val Loss: 2.11176
Epoch 32, Val Loss: 2.08918
Epoch 33, Val Loss: 2.13150
Epoch 34, Val Loss: 2.13260
Epoch 35, Val Loss: 2.11229
Epoch 36, Val Loss: 2.08338
Epoch 37, Val Loss: 2.11343
Epoch 38, Val Loss: 2.08361
Epoch 39, Val Loss: 2.08038
Epoch 40, Val Loss: 2.07578
Epoch 41, Val Loss: 2.04637
Epoch 42, Val Loss: 2.11424
Epoch 43, Val Loss: 2.07187
Epoch 44, Val Loss: 2.06459
Epoch 45, Val Loss: 2.08600
Epoch 46, Val Loss: 2.09571
Epoch 47, Val Loss: 2.11273
Epoch 48, Val Loss: 2.10689
Epoch 49, Val Loss: 2.06554
Epoch 50, Val Loss: 2.08646
Epoch 51, Val Loss: 2.06535
Epoch 52, Val Loss: 2.05382
Epoch 53, Val Loss: 2.07389
Epoch 54, Val Loss: 2.10456
Epoch 55, Val Loss: 2.08213
Epoch 56, Val Loss: 2.11693
Epoch 57, Val Loss: 2.08765
Epoch 58, Val Loss: 2.10220
Epoch 59, Val Loss: 2.08034
Epoch 60, Val Loss: 2.08122
Epoch 61, Val Loss: 2.09098
Epoch 62, Val Loss: 2.06223
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3533, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}
Fitted encoder
Epoch 0, Val Loss: 1.97280
Epoch 1, Val Loss: 1.94439
Epoch 2, Val Loss: 1.93362
Epoch 3, Val Loss: 1.93607
Epoch 4, Val Loss: 1.93229
Epoch 5, Val Loss: 1.95997
Epoch 6, Val Loss: 1.92698
Epoch 7, Val Loss: 1.91023
Epoch 8, Val Loss: 1.92569
Epoch 9, Val Loss: 1.90582
Epoch 10, Val Loss: 1.90083
Epoch 11, Val Loss: 1.99132
Epoch 12, Val Loss: 1.92497
Epoch 13, Val Loss: 1.96146
Epoch 14, Val Loss: 1.94124
Epoch 15, Val Loss: 1.90923
Epoch 16, Val Loss: 1.94328
Epoch 17, Val Loss: 1.91139
Epoch 18, Val Loss: 1.91660
Epoch 19, Val Loss: 1.90975
Epoch 20, Val Loss: 1.94404
Epoch 21, Val Loss: 1.91948
Epoch 22, Val Loss: 1.90259
Epoch 23, Val Loss: 1.90298
Epoch 24, Val Loss: 1.89847
Epoch 25, Val Loss: 1.94500
Epoch 26, Val Loss: 1.89401
Epoch 27, Val Loss: 1.89830
Epoch 28, Val Loss: 1.90223
Epoch 29, Val Loss: 1.88912
Epoch 30, Val Loss: 1.91010
Epoch 31, Val Loss: 1.90017
Epoch 32, Val Loss: 1.90306
Epoch 33, Val Loss: 1.92656
Epoch 34, Val Loss: 1.90641
Epoch 35, Val Loss: 1.91187
Epoch 36, Val Loss: 1.91020
Epoch 37, Val Loss: 1.90716
Epoch 38, Val Loss: 1.90997
Epoch 39, Val Loss: 1.89976
Epoch 40, Val Loss: 1.90152
Epoch 41, Val Loss: 1.90498
Epoch 42, Val Loss: 1.92259
Epoch 43, Val Loss: 1.92941
Epoch 44, Val Loss: 1.90089
Epoch 45, Val Loss: 1.89739
Epoch 46, Val Loss: 1.90126
Epoch 47, Val Loss: 1.89739
Epoch 48, Val Loss: 1.91224
Epoch 49, Val Loss: 1.90273
Epoch 50, Val Loss: 1.89809
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3617999999999997, 'Log Loss - std': 0.008499999999999952} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}
Fitted encoder
Epoch 0, Val Loss: 2.13404
Epoch 1, Val Loss: 2.12070
Epoch 2, Val Loss: 2.12848
Epoch 3, Val Loss: 2.09899
Epoch 4, Val Loss: 2.12979
Epoch 5, Val Loss: 2.11451
Epoch 6, Val Loss: 2.11554
Epoch 7, Val Loss: 2.12832
Epoch 8, Val Loss: 2.12715
Epoch 9, Val Loss: 2.11991
Epoch 10, Val Loss: 2.09407
Epoch 11, Val Loss: 2.07945
Epoch 12, Val Loss: 2.08447
Epoch 13, Val Loss: 2.13140
Epoch 14, Val Loss: 2.12265
Epoch 15, Val Loss: 2.12012
Epoch 16, Val Loss: 2.11979
Epoch 17, Val Loss: 2.11881
Epoch 18, Val Loss: 2.13112
Epoch 19, Val Loss: 2.10672
Epoch 20, Val Loss: 2.13481
Epoch 21, Val Loss: 2.10518
Epoch 22, Val Loss: 2.09852
Epoch 23, Val Loss: 2.12032
Epoch 24, Val Loss: 2.08580
Epoch 25, Val Loss: 2.08736
Epoch 26, Val Loss: 2.09365
Epoch 27, Val Loss: 2.10972
Epoch 28, Val Loss: 2.11154
Epoch 29, Val Loss: 2.10316
Epoch 30, Val Loss: 2.08316
Epoch 31, Val Loss: 2.08478
Epoch 32, Val Loss: 2.08780
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3773999999999997, 'Log Loss - std': 0.023127616969040827} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}
Fitted encoder
Epoch 0, Val Loss: 2.08705
Epoch 1, Val Loss: 2.07788
Epoch 2, Val Loss: 2.06142
Epoch 3, Val Loss: 2.05940
Epoch 4, Val Loss: 2.05654
Epoch 5, Val Loss: 2.05865
Epoch 6, Val Loss: 2.03945
Epoch 7, Val Loss: 2.02766
Epoch 8, Val Loss: 2.07025
Epoch 9, Val Loss: 2.04158
Epoch 10, Val Loss: 2.05203
Epoch 11, Val Loss: 2.02851
Epoch 12, Val Loss: 2.03938
Epoch 13, Val Loss: 2.02511
Epoch 14, Val Loss: 2.01985
Epoch 15, Val Loss: 2.02796
Epoch 16, Val Loss: 2.05287
Epoch 17, Val Loss: 2.00863
Epoch 18, Val Loss: 2.01232
Epoch 19, Val Loss: 2.02572
Epoch 20, Val Loss: 2.03817
Epoch 21, Val Loss: 2.01936
Epoch 22, Val Loss: 2.02696
Epoch 23, Val Loss: 2.02558
Epoch 24, Val Loss: 2.01779
Epoch 25, Val Loss: 2.02349
Epoch 26, Val Loss: 2.04344
Epoch 27, Val Loss: 2.02927
Epoch 28, Val Loss: 2.02727
Epoch 29, Val Loss: 2.03653
Epoch 30, Val Loss: 2.04893
Epoch 31, Val Loss: 2.00526
Epoch 32, Val Loss: 2.01754
Epoch 33, Val Loss: 2.01522
Epoch 34, Val Loss: 2.01659
Epoch 35, Val Loss: 2.04012
Epoch 36, Val Loss: 2.02954
Epoch 37, Val Loss: 2.02598
Epoch 38, Val Loss: 2.03150
Epoch 39, Val Loss: 2.03044
Epoch 40, Val Loss: 2.02786
Epoch 41, Val Loss: 2.00930
Epoch 42, Val Loss: 2.01248
Epoch 43, Val Loss: 2.02987
Epoch 44, Val Loss: 2.03006
Epoch 45, Val Loss: 2.01710
Epoch 46, Val Loss: 2.01968
Epoch 47, Val Loss: 2.01692
Epoch 48, Val Loss: 2.01723
Epoch 49, Val Loss: 2.00861
Epoch 50, Val Loss: 2.02057
Epoch 51, Val Loss: 2.02111
Epoch 52, Val Loss: 2.03883
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.1948499999999997, 'Log Loss - std': 0.316819621393625} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}
Fitted encoder
Epoch 0, Val Loss: 1.95994
Epoch 1, Val Loss: 1.94892
Epoch 2, Val Loss: 1.96704
Epoch 3, Val Loss: 1.94306
Epoch 4, Val Loss: 1.95422
Epoch 5, Val Loss: 1.94209
Epoch 6, Val Loss: 1.94274
Epoch 7, Val Loss: 1.94386
Epoch 8, Val Loss: 1.94989
Epoch 9, Val Loss: 1.96348
Epoch 10, Val Loss: 1.94812
Epoch 11, Val Loss: 1.94089
Epoch 12, Val Loss: 1.93926
Epoch 13, Val Loss: 1.95196
Epoch 14, Val Loss: 1.93902
Epoch 15, Val Loss: 1.94306
Epoch 16, Val Loss: 1.94045
Epoch 17, Val Loss: 1.94022
Epoch 18, Val Loss: 1.91333
Epoch 19, Val Loss: 2.03986
Epoch 20, Val Loss: 1.95698
Epoch 21, Val Loss: 1.92090
Epoch 22, Val Loss: 1.92221
Epoch 23, Val Loss: 2.01696
Epoch 24, Val Loss: 1.92372
Epoch 25, Val Loss: 1.95038
Epoch 26, Val Loss: 1.92588
Epoch 27, Val Loss: 1.91229
Epoch 28, Val Loss: 1.90190
Epoch 29, Val Loss: 1.89924
Epoch 30, Val Loss: 1.93471
Epoch 31, Val Loss: 1.90911
Epoch 32, Val Loss: 1.90188
Epoch 33, Val Loss: 1.92879
Epoch 34, Val Loss: 1.91856
Epoch 35, Val Loss: 1.90904
Epoch 36, Val Loss: 1.89821
Epoch 37, Val Loss: 1.93037
Epoch 38, Val Loss: 1.89839
Epoch 39, Val Loss: 1.90796
Epoch 40, Val Loss: 1.90658
Epoch 41, Val Loss: 1.89908
Epoch 42, Val Loss: 1.90913
Epoch 43, Val Loss: 1.89564
Epoch 44, Val Loss: 1.90661
Epoch 45, Val Loss: 1.90983
Epoch 46, Val Loss: 1.91909
Epoch 47, Val Loss: 1.92477
Epoch 48, Val Loss: 1.88586
Epoch 49, Val Loss: 1.91192
Epoch 50, Val Loss: 1.92777
Epoch 51, Val Loss: 1.92431
Epoch 52, Val Loss: 1.91916
Epoch 53, Val Loss: 2.00867
Epoch 54, Val Loss: 1.99754
Epoch 55, Val Loss: 2.03732
Epoch 56, Val Loss: 2.04442
Epoch 57, Val Loss: 2.03889
Epoch 58, Val Loss: 2.03332
Epoch 59, Val Loss: 1.97216
Epoch 60, Val Loss: 1.90596
Epoch 61, Val Loss: 1.91181
Epoch 62, Val Loss: 1.91949
Epoch 63, Val Loss: 1.90276
Epoch 64, Val Loss: 1.90401
Epoch 65, Val Loss: 1.89707
Epoch 66, Val Loss: 1.90392
Epoch 67, Val Loss: 1.90852
Epoch 68, Val Loss: 1.91565
Epoch 69, Val Loss: 1.99531
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.2362200000000003, 'Log Loss - std': 0.2952044132461436} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 32 finished with value: 3.2362200000000003 and parameters: {'p_m': 0.7462744746001648, 'alpha': 0.8351261760785503, 'K': 3, 'beta': 0.6675716408183836}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}
Fitted encoder
Epoch 0, Val Loss: 2.14218
Epoch 1, Val Loss: 2.13113
Epoch 2, Val Loss: 2.13839
Epoch 3, Val Loss: 2.13122
Epoch 4, Val Loss: 2.12813
Epoch 5, Val Loss: 2.13724
Epoch 6, Val Loss: 2.13472
Epoch 7, Val Loss: 2.12686
Epoch 8, Val Loss: 2.11730
Epoch 9, Val Loss: 2.11465
Epoch 10, Val Loss: 2.11628
Epoch 11, Val Loss: 2.12983
Epoch 12, Val Loss: 2.12350
Epoch 13, Val Loss: 2.11406
Epoch 14, Val Loss: 2.08288
Epoch 15, Val Loss: 2.09963
Epoch 16, Val Loss: 2.13724
Epoch 17, Val Loss: 2.12806
Epoch 18, Val Loss: 2.08989
Epoch 19, Val Loss: 2.11297
Epoch 20, Val Loss: 2.09743
Epoch 21, Val Loss: 2.12149
Epoch 22, Val Loss: 2.08504
Epoch 23, Val Loss: 2.08898
Epoch 24, Val Loss: 2.10701
Epoch 25, Val Loss: 2.08854
Epoch 26, Val Loss: 2.11488
Epoch 27, Val Loss: 2.11212
Epoch 28, Val Loss: 2.11516
Epoch 29, Val Loss: 2.11571
Epoch 30, Val Loss: 2.08029
Epoch 31, Val Loss: 2.08137
Epoch 32, Val Loss: 2.08200
Epoch 33, Val Loss: 2.08963
Epoch 34, Val Loss: 2.09972
Epoch 35, Val Loss: 2.07158
Epoch 36, Val Loss: 2.08287
Epoch 37, Val Loss: 2.08219
Epoch 38, Val Loss: 2.07006
Epoch 39, Val Loss: 2.10831
Epoch 40, Val Loss: 2.07015
Epoch 41, Val Loss: 2.10279
Epoch 42, Val Loss: 2.07903
Epoch 43, Val Loss: 2.14284
Epoch 44, Val Loss: 2.14072
Epoch 45, Val Loss: 2.13407
Epoch 46, Val Loss: 2.07080
Epoch 47, Val Loss: 2.05841
Epoch 48, Val Loss: 2.06109
Epoch 49, Val Loss: 2.07894
Epoch 50, Val Loss: 2.06531
Epoch 51, Val Loss: 2.06717
Epoch 52, Val Loss: 2.07642
Epoch 53, Val Loss: 2.06245
Epoch 54, Val Loss: 2.05482
Epoch 55, Val Loss: 2.03386
Epoch 56, Val Loss: 2.03501
Epoch 57, Val Loss: 2.04956
Epoch 58, Val Loss: 2.04719
Epoch 59, Val Loss: 2.05229
Epoch 60, Val Loss: 2.05348
Epoch 61, Val Loss: 2.05214
Epoch 62, Val Loss: 2.10111
Epoch 63, Val Loss: 2.09544
Epoch 64, Val Loss: 2.06428
Epoch 65, Val Loss: 2.10094
Epoch 66, Val Loss: 2.08193
Epoch 67, Val Loss: 2.08252
Epoch 68, Val Loss: 2.03994
Epoch 69, Val Loss: 2.05047
Epoch 70, Val Loss: 2.05271
Epoch 71, Val Loss: 2.04068
Epoch 72, Val Loss: 2.04125
Epoch 73, Val Loss: 2.04509
Epoch 74, Val Loss: 2.04912
Epoch 75, Val Loss: 2.06174
Epoch 76, Val Loss: 2.04988
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.2299, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}
Fitted encoder
Epoch 0, Val Loss: 2.01166
Epoch 1, Val Loss: 1.97703
Epoch 2, Val Loss: 1.94166
Epoch 3, Val Loss: 1.95413
Epoch 4, Val Loss: 1.95244
Epoch 5, Val Loss: 1.95978
Epoch 6, Val Loss: 1.94459
Epoch 7, Val Loss: 1.94709
Epoch 8, Val Loss: 1.94254
Epoch 9, Val Loss: 1.96223
Epoch 10, Val Loss: 1.94236
Epoch 11, Val Loss: 1.93786
Epoch 12, Val Loss: 1.95806
Epoch 13, Val Loss: 1.93671
Epoch 14, Val Loss: 1.92376
Epoch 15, Val Loss: 1.92290
Epoch 16, Val Loss: 1.93223
Epoch 17, Val Loss: 1.92447
Epoch 18, Val Loss: 1.93821
Epoch 19, Val Loss: 1.92339
Epoch 20, Val Loss: 1.93244
Epoch 21, Val Loss: 1.94847
Epoch 22, Val Loss: 1.92149
Epoch 23, Val Loss: 1.92055
Epoch 24, Val Loss: 1.91359
Epoch 25, Val Loss: 1.91016
Epoch 26, Val Loss: 1.91795
Epoch 27, Val Loss: 1.94068
Epoch 28, Val Loss: 1.90502
Epoch 29, Val Loss: 1.90546
Epoch 30, Val Loss: 1.91986
Epoch 31, Val Loss: 1.92790
Epoch 32, Val Loss: 1.91713
Epoch 33, Val Loss: 1.92154
Epoch 34, Val Loss: 1.90986
Epoch 35, Val Loss: 1.92494
Epoch 36, Val Loss: 1.91517
Epoch 37, Val Loss: 1.90489
Epoch 38, Val Loss: 1.91667
Epoch 39, Val Loss: 1.91641
Epoch 40, Val Loss: 1.96657
Epoch 41, Val Loss: 1.91556
Epoch 42, Val Loss: 1.93962
Epoch 43, Val Loss: 1.93041
Epoch 44, Val Loss: 1.91776
Epoch 45, Val Loss: 1.91191
Epoch 46, Val Loss: 1.92557
Epoch 47, Val Loss: 1.93043
Epoch 48, Val Loss: 1.91531
Epoch 49, Val Loss: 1.91272
Epoch 50, Val Loss: 1.90886
Epoch 51, Val Loss: 1.94803
Epoch 52, Val Loss: 1.92607
Epoch 53, Val Loss: 1.91760
Epoch 54, Val Loss: 1.92924
Epoch 55, Val Loss: 1.92743
Epoch 56, Val Loss: 1.93041
Epoch 57, Val Loss: 1.90750
Epoch 58, Val Loss: 1.91532
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3525, 'Log Loss - std': 0.12259999999999982} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}
Fitted encoder
Epoch 0, Val Loss: 2.15138
Epoch 1, Val Loss: 2.15099
Epoch 2, Val Loss: 2.14340
Epoch 3, Val Loss: 2.13659
Epoch 4, Val Loss: 2.14287
Epoch 5, Val Loss: 2.11254
Epoch 6, Val Loss: 2.09914
Epoch 7, Val Loss: 2.12081
Epoch 8, Val Loss: 2.10136
Epoch 9, Val Loss: 2.11776
Epoch 10, Val Loss: 2.09580
Epoch 11, Val Loss: 2.10063
Epoch 12, Val Loss: 2.08470
Epoch 13, Val Loss: 2.07988
Epoch 14, Val Loss: 2.08618
Epoch 15, Val Loss: 2.09776
Epoch 16, Val Loss: 2.08826
Epoch 17, Val Loss: 2.10542
Epoch 18, Val Loss: 2.12521
Epoch 19, Val Loss: 2.10651
Epoch 20, Val Loss: 2.12589
Epoch 21, Val Loss: 2.10131
Epoch 22, Val Loss: 2.09262
Epoch 23, Val Loss: 2.08261
Epoch 24, Val Loss: 2.11751
Epoch 25, Val Loss: 2.09586
Epoch 26, Val Loss: 2.11327
Epoch 27, Val Loss: 2.07839
Epoch 28, Val Loss: 2.11675
Epoch 29, Val Loss: 2.11003
Epoch 30, Val Loss: 2.09826
Epoch 31, Val Loss: 2.08603
Epoch 32, Val Loss: 2.08749
Epoch 33, Val Loss: 2.09545
Epoch 34, Val Loss: 2.09193
Epoch 35, Val Loss: 2.07639
Epoch 36, Val Loss: 2.07373
Epoch 37, Val Loss: 2.07376
Epoch 38, Val Loss: 2.07058
Epoch 39, Val Loss: 2.07157
Epoch 40, Val Loss: 2.07576
Epoch 41, Val Loss: 2.06560
Epoch 42, Val Loss: 2.07993
Epoch 43, Val Loss: 2.07281
Epoch 44, Val Loss: 2.08650
Epoch 45, Val Loss: 2.11426
Epoch 46, Val Loss: 2.08856
Epoch 47, Val Loss: 2.11657
Epoch 48, Val Loss: 2.07559
Epoch 49, Val Loss: 2.06935
Epoch 50, Val Loss: 2.09653
Epoch 51, Val Loss: 2.07531
Epoch 52, Val Loss: 2.06661
Epoch 53, Val Loss: 2.08198
Epoch 54, Val Loss: 2.07415
Epoch 55, Val Loss: 2.07657
Epoch 56, Val Loss: 2.05831
Epoch 57, Val Loss: 2.06528
Epoch 58, Val Loss: 2.07524
Epoch 59, Val Loss: 2.07680
Epoch 60, Val Loss: 2.07565
Epoch 61, Val Loss: 2.05911
Epoch 62, Val Loss: 2.08715
Epoch 63, Val Loss: 2.06771
Epoch 64, Val Loss: 2.05962
Epoch 65, Val Loss: 2.14408
Epoch 66, Val Loss: 2.06919
Epoch 67, Val Loss: 2.09076
Epoch 68, Val Loss: 2.09306
Epoch 69, Val Loss: 2.09523
Epoch 70, Val Loss: 2.06922
Epoch 71, Val Loss: 2.06769
Epoch 72, Val Loss: 2.09733
Epoch 73, Val Loss: 2.07316
Epoch 74, Val Loss: 2.06184
Epoch 75, Val Loss: 2.06552
Epoch 76, Val Loss: 2.06659
Epoch 77, Val Loss: 2.06176
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.4422333333333337, 'Log Loss - std': 0.16163121260724636} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}
Fitted encoder
Epoch 0, Val Loss: 2.07765
Epoch 1, Val Loss: 2.08005
Epoch 2, Val Loss: 2.06383
Epoch 3, Val Loss: 2.05751
Epoch 4, Val Loss: 2.06198
Epoch 5, Val Loss: 2.05712
Epoch 6, Val Loss: 2.05913
Epoch 7, Val Loss: 2.05179
Epoch 8, Val Loss: 2.07818
Epoch 9, Val Loss: 2.10197
Epoch 10, Val Loss: 2.07654
Epoch 11, Val Loss: 2.05585
Epoch 12, Val Loss: 2.12233
Epoch 13, Val Loss: 2.04764
Epoch 14, Val Loss: 2.04331
Epoch 15, Val Loss: 2.04247
Epoch 16, Val Loss: 2.07802
Epoch 17, Val Loss: 2.02628
Epoch 18, Val Loss: 2.03044
Epoch 19, Val Loss: 2.02546
Epoch 20, Val Loss: 2.05716
Epoch 21, Val Loss: 2.10694
Epoch 22, Val Loss: 2.02836
Epoch 23, Val Loss: 2.05097
Epoch 24, Val Loss: 2.04666
Epoch 25, Val Loss: 2.03379
Epoch 26, Val Loss: 2.04317
Epoch 27, Val Loss: 2.03318
Epoch 28, Val Loss: 2.06945
Epoch 29, Val Loss: 2.08781
Epoch 30, Val Loss: 2.11901
Epoch 31, Val Loss: 2.08031
Epoch 32, Val Loss: 2.08812
Epoch 33, Val Loss: 2.07414
Epoch 34, Val Loss: 2.04532
Epoch 35, Val Loss: 2.02759
Epoch 36, Val Loss: 2.01811
Epoch 37, Val Loss: 2.01961
Epoch 38, Val Loss: 2.01750
Epoch 39, Val Loss: 2.06949
Epoch 40, Val Loss: 2.02922
Epoch 41, Val Loss: 2.07119
Epoch 42, Val Loss: 2.02411
Epoch 43, Val Loss: 2.03280
Epoch 44, Val Loss: 2.02275
Epoch 45, Val Loss: 2.02299
Epoch 46, Val Loss: 2.02610
Epoch 47, Val Loss: 2.06156
Epoch 48, Val Loss: 2.01581
Epoch 49, Val Loss: 2.02190
Epoch 50, Val Loss: 2.03362
Epoch 51, Val Loss: 2.02503
Epoch 52, Val Loss: 2.03081
Epoch 53, Val Loss: 2.04205
Epoch 54, Val Loss: 2.02571
Epoch 55, Val Loss: 2.02471
Epoch 56, Val Loss: 2.03200
Epoch 57, Val Loss: 2.05072
Epoch 58, Val Loss: 2.02730
Epoch 59, Val Loss: 2.02509
Epoch 60, Val Loss: 2.03178
Epoch 61, Val Loss: 2.05077
Epoch 62, Val Loss: 2.08237
Epoch 63, Val Loss: 2.03701
Epoch 64, Val Loss: 2.06138
Epoch 65, Val Loss: 2.04831
Epoch 66, Val Loss: 2.03665
Epoch 67, Val Loss: 2.02987
Epoch 68, Val Loss: 2.09300
Epoch 69, Val Loss: 2.08126
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3077, 'Log Loss - std': 0.2718292478744699} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}
Fitted encoder
Epoch 0, Val Loss: 1.96656
Epoch 1, Val Loss: 1.95627
Epoch 2, Val Loss: 1.95128
Epoch 3, Val Loss: 1.99063
Epoch 4, Val Loss: 1.96450
Epoch 5, Val Loss: 1.95203
Epoch 6, Val Loss: 1.94980
Epoch 7, Val Loss: 1.95118
Epoch 8, Val Loss: 1.98764
Epoch 9, Val Loss: 1.94822
Epoch 10, Val Loss: 1.95464
Epoch 11, Val Loss: 1.94864
Epoch 12, Val Loss: 1.98192
Epoch 13, Val Loss: 1.94489
Epoch 14, Val Loss: 1.94857
Epoch 15, Val Loss: 1.94489
Epoch 16, Val Loss: 1.95343
Epoch 17, Val Loss: 1.96472
Epoch 18, Val Loss: 1.94802
Epoch 19, Val Loss: 1.94768
Epoch 20, Val Loss: 1.95300
Epoch 21, Val Loss: 1.95308
Epoch 22, Val Loss: 1.95453
Epoch 23, Val Loss: 1.94068
Epoch 24, Val Loss: 1.95862
Epoch 25, Val Loss: 1.94766
Epoch 26, Val Loss: 1.94284
Epoch 27, Val Loss: 1.93868
Epoch 28, Val Loss: 1.96004
Epoch 29, Val Loss: 1.96075
Epoch 30, Val Loss: 1.94706
Epoch 31, Val Loss: 1.93663
Epoch 32, Val Loss: 1.94265
Epoch 33, Val Loss: 1.95225
Epoch 34, Val Loss: 1.94837
Epoch 35, Val Loss: 1.95101
Epoch 36, Val Loss: 1.94458
Epoch 37, Val Loss: 1.92635
Epoch 38, Val Loss: 1.94153
Epoch 39, Val Loss: 1.94239
Epoch 40, Val Loss: 1.92872
Epoch 41, Val Loss: 1.91991
Epoch 42, Val Loss: 1.92413
Epoch 43, Val Loss: 1.93698
Epoch 44, Val Loss: 1.94129
Epoch 45, Val Loss: 1.94742
Epoch 46, Val Loss: 1.94412
Epoch 47, Val Loss: 1.93626
Epoch 48, Val Loss: 1.91548
Epoch 49, Val Loss: 1.94867
Epoch 50, Val Loss: 1.92781
Epoch 51, Val Loss: 1.90360
Epoch 52, Val Loss: 1.91713
Epoch 53, Val Loss: 1.90547
Epoch 54, Val Loss: 1.94524
Epoch 55, Val Loss: 1.91194
Epoch 56, Val Loss: 1.93841
Epoch 57, Val Loss: 1.94058
Epoch 58, Val Loss: 1.91623
Epoch 59, Val Loss: 1.93747
Epoch 60, Val Loss: 2.06505
Epoch 61, Val Loss: 1.97018
Epoch 62, Val Loss: 1.95366
Epoch 63, Val Loss: 1.94222
Epoch 64, Val Loss: 2.01977
Epoch 65, Val Loss: 1.98892
Epoch 66, Val Loss: 1.96912
Epoch 67, Val Loss: 1.90939
Epoch 68, Val Loss: 1.92651
Epoch 69, Val Loss: 1.92225
Epoch 70, Val Loss: 1.89482
Epoch 71, Val Loss: 1.93145
Epoch 72, Val Loss: 1.90539
Epoch 73, Val Loss: 1.90261
Epoch 74, Val Loss: 1.89256
Epoch 75, Val Loss: 1.91667
Epoch 76, Val Loss: 1.90872
Epoch 77, Val Loss: 1.91491
Epoch 78, Val Loss: 1.88200
Epoch 79, Val Loss: 1.89842
Epoch 80, Val Loss: 1.91722
Epoch 81, Val Loss: 1.90427
Epoch 82, Val Loss: 1.90669
Epoch 83, Val Loss: 1.89712
Epoch 84, Val Loss: 1.88522
Epoch 85, Val Loss: 1.89289
Epoch 86, Val Loss: 1.88605
Epoch 87, Val Loss: 1.90122
Epoch 88, Val Loss: 1.88908
Epoch 89, Val Loss: 1.94052
Epoch 90, Val Loss: 1.90935
Epoch 91, Val Loss: 1.90201
Epoch 92, Val Loss: 1.88562
Epoch 93, Val Loss: 1.89583
Epoch 94, Val Loss: 1.89088
Epoch 95, Val Loss: 1.89842
Epoch 96, Val Loss: 1.88906
Epoch 97, Val Loss: 1.89377
Epoch 98, Val Loss: 1.88167
Epoch 99, Val Loss: 1.88290
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.2904600000000004, 'Log Loss - std': 0.2455642123763151} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 33 finished with value: 3.2904600000000004 and parameters: {'p_m': 0.7027627123914736, 'alpha': 0.8156984224545714, 'K': 2, 'beta': 1.6557026470981566}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}
Fitted encoder
Epoch 0, Val Loss: 2.15652
Epoch 1, Val Loss: 2.10591
Epoch 2, Val Loss: 2.14260
Epoch 3, Val Loss: 2.14225
Epoch 4, Val Loss: 2.13973
Epoch 5, Val Loss: 2.12573
Epoch 6, Val Loss: 2.10649
Epoch 7, Val Loss: 2.12098
Epoch 8, Val Loss: 2.08601
Epoch 9, Val Loss: 2.09564
Epoch 10, Val Loss: 2.06942
Epoch 11, Val Loss: 2.08746
Epoch 12, Val Loss: 2.05499
Epoch 13, Val Loss: 2.04943
Epoch 14, Val Loss: 2.09929
Epoch 15, Val Loss: 2.08430
Epoch 16, Val Loss: 2.18685
Epoch 17, Val Loss: 2.16245
Epoch 18, Val Loss: 2.17233
Epoch 19, Val Loss: 2.13687
Epoch 20, Val Loss: 2.09169
Epoch 21, Val Loss: 2.09901
Epoch 22, Val Loss: 2.05947
Epoch 23, Val Loss: 2.11834
Epoch 24, Val Loss: 2.08777
Epoch 25, Val Loss: 2.07689
Epoch 26, Val Loss: 2.07939
Epoch 27, Val Loss: 2.06202
Epoch 28, Val Loss: 2.08684
Epoch 29, Val Loss: 2.12934
Epoch 30, Val Loss: 2.12501
Epoch 31, Val Loss: 2.06988
Epoch 32, Val Loss: 2.06530
Epoch 33, Val Loss: 2.05575
Epoch 34, Val Loss: 2.06636
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.7418, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}
Fitted encoder
Epoch 0, Val Loss: 1.97562
Epoch 1, Val Loss: 1.95418
Epoch 2, Val Loss: 1.95150
Epoch 3, Val Loss: 1.95261
Epoch 4, Val Loss: 1.95536
Epoch 5, Val Loss: 1.94666
Epoch 6, Val Loss: 2.03474
Epoch 7, Val Loss: 2.03766
Epoch 8, Val Loss: 1.92740
Epoch 9, Val Loss: 1.96277
Epoch 10, Val Loss: 1.95406
Epoch 11, Val Loss: 1.94455
Epoch 12, Val Loss: 1.96179
Epoch 13, Val Loss: 1.97848
Epoch 14, Val Loss: 1.95625
Epoch 15, Val Loss: 1.95860
Epoch 16, Val Loss: 1.96467
Epoch 17, Val Loss: 1.95993
Epoch 18, Val Loss: 1.97081
Epoch 19, Val Loss: 1.95538
Epoch 20, Val Loss: 1.95542
Epoch 21, Val Loss: 1.96950
Epoch 22, Val Loss: 1.96749
Epoch 23, Val Loss: 1.95089
Epoch 24, Val Loss: 1.97857
Epoch 25, Val Loss: 1.96470
Epoch 26, Val Loss: 1.96097
Epoch 27, Val Loss: 1.96208
Epoch 28, Val Loss: 1.95680
Epoch 29, Val Loss: 1.95658
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.5811, 'Log Loss - std': 0.16070000000000007} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}
Fitted encoder
Epoch 0, Val Loss: 2.16695
Epoch 1, Val Loss: 2.14086
Epoch 2, Val Loss: 2.11815
Epoch 3, Val Loss: 2.10585
Epoch 4, Val Loss: 2.11158
Epoch 5, Val Loss: 2.08821
Epoch 6, Val Loss: 2.10494
Epoch 7, Val Loss: 2.13888
Epoch 8, Val Loss: 2.10026
Epoch 9, Val Loss: 2.10514
Epoch 10, Val Loss: 2.10988
Epoch 11, Val Loss: 2.08584
Epoch 12, Val Loss: 2.08806
Epoch 13, Val Loss: 2.13803
Epoch 14, Val Loss: 2.07564
Epoch 15, Val Loss: 2.07432
Epoch 16, Val Loss: 2.13384
Epoch 17, Val Loss: 2.09525
Epoch 18, Val Loss: 2.12821
Epoch 19, Val Loss: 2.10685
Epoch 20, Val Loss: 2.14912
Epoch 21, Val Loss: 2.10452
Epoch 22, Val Loss: 2.07773
Epoch 23, Val Loss: 2.08890
Epoch 24, Val Loss: 2.08440
Epoch 25, Val Loss: 2.10779
Epoch 26, Val Loss: 2.06604
Epoch 27, Val Loss: 2.06118
Epoch 28, Val Loss: 2.07388
Epoch 29, Val Loss: 2.07497
Epoch 30, Val Loss: 2.10377
Epoch 31, Val Loss: 2.08635
Epoch 32, Val Loss: 2.06835
Epoch 33, Val Loss: 2.07149
Epoch 34, Val Loss: 2.09633
Epoch 35, Val Loss: 2.07757
Epoch 36, Val Loss: 2.08472
Epoch 37, Val Loss: 2.07302
Epoch 38, Val Loss: 2.08114
Epoch 39, Val Loss: 2.07568
Epoch 40, Val Loss: 2.07481
Epoch 41, Val Loss: 2.07924
Epoch 42, Val Loss: 2.07126
Epoch 43, Val Loss: 2.08486
Epoch 44, Val Loss: 2.06853
Epoch 45, Val Loss: 2.07723
Epoch 46, Val Loss: 2.06455
Epoch 47, Val Loss: 2.08451
Epoch 48, Val Loss: 2.06289
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.6765000000000003, 'Log Loss - std': 0.18819842365616857} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}
Fitted encoder
Epoch 0, Val Loss: 2.08252
Epoch 1, Val Loss: 2.07476
Epoch 2, Val Loss: 2.06898
Epoch 3, Val Loss: 2.06050
Epoch 4, Val Loss: 2.05190
Epoch 5, Val Loss: 2.06026
Epoch 6, Val Loss: 2.06070
Epoch 7, Val Loss: 2.05293
Epoch 8, Val Loss: 2.07926
Epoch 9, Val Loss: 2.10204
Epoch 10, Val Loss: 2.09361
Epoch 11, Val Loss: 2.11870
Epoch 12, Val Loss: 2.10917
Epoch 13, Val Loss: 2.05383
Epoch 14, Val Loss: 2.04146
Epoch 15, Val Loss: 2.05320
Epoch 16, Val Loss: 2.09801
Epoch 17, Val Loss: 2.02630
Epoch 18, Val Loss: 2.10682
Epoch 19, Val Loss: 2.10844
Epoch 20, Val Loss: 2.09620
Epoch 21, Val Loss: 2.10703
Epoch 22, Val Loss: 2.07495
Epoch 23, Val Loss: 2.10037
Epoch 24, Val Loss: 2.08417
Epoch 25, Val Loss: 2.09398
Epoch 26, Val Loss: 2.08759
Epoch 27, Val Loss: 2.06952
Epoch 28, Val Loss: 2.09087
Epoch 29, Val Loss: 2.07646
Epoch 30, Val Loss: 2.07127
Epoch 31, Val Loss: 2.07119
Epoch 32, Val Loss: 2.08644
Epoch 33, Val Loss: 2.09051
Epoch 34, Val Loss: 2.07718
Epoch 35, Val Loss: 2.09159
Epoch 36, Val Loss: 2.08839
Epoch 37, Val Loss: 2.08510
Epoch 38, Val Loss: 2.10788
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.453225, 'Log Loss - std': 0.41966553572458165} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}
Fitted encoder
Epoch 0, Val Loss: 1.95652
Epoch 1, Val Loss: 1.98304
Epoch 2, Val Loss: 1.94587
Epoch 3, Val Loss: 1.93697
Epoch 4, Val Loss: 1.93601
Epoch 5, Val Loss: 1.91774
Epoch 6, Val Loss: 2.00118
Epoch 7, Val Loss: 1.91250
Epoch 8, Val Loss: 1.88898
Epoch 9, Val Loss: 1.91514
Epoch 10, Val Loss: 2.00725
Epoch 11, Val Loss: 2.02266
Epoch 12, Val Loss: 1.89711
Epoch 13, Val Loss: 1.88494
Epoch 14, Val Loss: 1.88400
Epoch 15, Val Loss: 1.89067
Epoch 16, Val Loss: 1.91277
Epoch 17, Val Loss: 1.88425
Epoch 18, Val Loss: 1.88964
Epoch 19, Val Loss: 1.89785
Epoch 20, Val Loss: 1.89828
Epoch 21, Val Loss: 1.88166
Epoch 22, Val Loss: 1.89937
Epoch 23, Val Loss: 1.91531
Epoch 24, Val Loss: 1.91105
Epoch 25, Val Loss: 2.01783
Epoch 26, Val Loss: 1.98524
Epoch 27, Val Loss: 1.90141
Epoch 28, Val Loss: 1.91711
Epoch 29, Val Loss: 1.91489
Epoch 30, Val Loss: 1.88408
Epoch 31, Val Loss: 1.91391
Epoch 32, Val Loss: 1.90640
Epoch 33, Val Loss: 1.93403
Epoch 34, Val Loss: 1.90370
Epoch 35, Val Loss: 1.89051
Epoch 36, Val Loss: 1.88577
Epoch 37, Val Loss: 1.88772
Epoch 38, Val Loss: 1.91897
Epoch 39, Val Loss: 1.90153
Epoch 40, Val Loss: 1.90541
Epoch 41, Val Loss: 1.89142
Epoch 42, Val Loss: 1.88319
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.4489000000000005, 'Log Loss - std': 0.3754599206306848} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 34 finished with value: 3.4489000000000005 and parameters: {'p_m': 0.8043216817387644, 'alpha': 1.3092786013757016, 'K': 3, 'beta': 0.5321733953387664}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}
Fitted encoder
Epoch 0, Val Loss: 2.11251
Epoch 1, Val Loss: 2.13935
Epoch 2, Val Loss: 2.14133
Epoch 3, Val Loss: 2.14384
Epoch 4, Val Loss: 2.15120
Epoch 5, Val Loss: 2.09400
Epoch 6, Val Loss: 2.10547
Epoch 7, Val Loss: 2.08422
Epoch 8, Val Loss: 2.07096
Epoch 9, Val Loss: 2.09447
Epoch 10, Val Loss: 2.07214
Epoch 11, Val Loss: 2.04741
Epoch 12, Val Loss: 2.08224
Epoch 13, Val Loss: 2.05162
Epoch 14, Val Loss: 2.05747
Epoch 15, Val Loss: 2.11459
Epoch 16, Val Loss: 2.06233
Epoch 17, Val Loss: 2.06927
Epoch 18, Val Loss: 2.06441
Epoch 19, Val Loss: 2.03611
Epoch 20, Val Loss: 2.05484
Epoch 21, Val Loss: 2.07172
Epoch 22, Val Loss: 2.05068
Epoch 23, Val Loss: 2.06721
Epoch 24, Val Loss: 2.03872
Epoch 25, Val Loss: 2.06237
Epoch 26, Val Loss: 2.03292
Epoch 27, Val Loss: 2.08868
Epoch 28, Val Loss: 2.06009
Epoch 29, Val Loss: 2.06398
Epoch 30, Val Loss: 2.08069
Epoch 31, Val Loss: 2.03870
Epoch 32, Val Loss: 2.02841
Epoch 33, Val Loss: 2.08050
Epoch 34, Val Loss: 2.05143
Epoch 35, Val Loss: 2.05676
Epoch 36, Val Loss: 2.04486
Epoch 37, Val Loss: 2.04528
Epoch 38, Val Loss: 2.07676
Epoch 39, Val Loss: 2.04723
Epoch 40, Val Loss: 2.04739
Epoch 41, Val Loss: 2.06395
Epoch 42, Val Loss: 2.03845
Epoch 43, Val Loss: 2.04172
Epoch 44, Val Loss: 2.06404
Epoch 45, Val Loss: 2.07137
Epoch 46, Val Loss: 2.04839
Epoch 47, Val Loss: 2.06741
Epoch 48, Val Loss: 2.06156
Epoch 49, Val Loss: 2.06907
Epoch 50, Val Loss: 2.04318
Epoch 51, Val Loss: 2.09257
Epoch 52, Val Loss: 2.08534
Epoch 53, Val Loss: 2.05447
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.4984, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}
Fitted encoder
Epoch 0, Val Loss: 1.95888
Epoch 1, Val Loss: 1.95879
Epoch 2, Val Loss: 1.95216
Epoch 3, Val Loss: 1.94547
Epoch 4, Val Loss: 1.95004
Epoch 5, Val Loss: 1.92805
Epoch 6, Val Loss: 1.93376
Epoch 7, Val Loss: 1.92677
Epoch 8, Val Loss: 1.92960
Epoch 9, Val Loss: 1.92350
Epoch 10, Val Loss: 1.92149
Epoch 11, Val Loss: 1.92219
Epoch 12, Val Loss: 1.89232
Epoch 13, Val Loss: 1.92737
Epoch 14, Val Loss: 1.91072
Epoch 15, Val Loss: 1.93972
Epoch 16, Val Loss: 1.92602
Epoch 17, Val Loss: 1.89453
Epoch 18, Val Loss: 1.90981
Epoch 19, Val Loss: 1.91411
Epoch 20, Val Loss: 1.92475
Epoch 21, Val Loss: 1.90274
Epoch 22, Val Loss: 1.90289
Epoch 23, Val Loss: 1.91219
Epoch 24, Val Loss: 1.91304
Epoch 25, Val Loss: 1.91277
Epoch 26, Val Loss: 1.92267
Epoch 27, Val Loss: 1.92735
Epoch 28, Val Loss: 1.92577
Epoch 29, Val Loss: 1.98759
Epoch 30, Val Loss: 1.94566
Epoch 31, Val Loss: 1.90854
Epoch 32, Val Loss: 1.91369
Epoch 33, Val Loss: 1.90780
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3723, 'Log Loss - std': 0.1261000000000001} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}
Fitted encoder
Epoch 0, Val Loss: 2.15419
Epoch 1, Val Loss: 2.11111
Epoch 2, Val Loss: 2.13191
Epoch 3, Val Loss: 2.11190
Epoch 4, Val Loss: 2.11534
Epoch 5, Val Loss: 2.10221
Epoch 6, Val Loss: 2.09975
Epoch 7, Val Loss: 2.10179
Epoch 8, Val Loss: 2.09408
Epoch 9, Val Loss: 2.07236
Epoch 10, Val Loss: 2.09063
Epoch 11, Val Loss: 2.10291
Epoch 12, Val Loss: 2.12105
Epoch 13, Val Loss: 2.07493
Epoch 14, Val Loss: 2.11338
Epoch 15, Val Loss: 2.12152
Epoch 16, Val Loss: 2.09016
Epoch 17, Val Loss: 2.07604
Epoch 18, Val Loss: 2.09025
Epoch 19, Val Loss: 2.09014
Epoch 20, Val Loss: 2.08632
Epoch 21, Val Loss: 2.05762
Epoch 22, Val Loss: 2.08179
Epoch 23, Val Loss: 2.06832
Epoch 24, Val Loss: 2.07921
Epoch 25, Val Loss: 2.05035
Epoch 26, Val Loss: 2.07526
Epoch 27, Val Loss: 2.07895
Epoch 28, Val Loss: 2.04678
Epoch 29, Val Loss: 2.03836
Epoch 30, Val Loss: 2.04052
Epoch 31, Val Loss: 2.05404
Epoch 32, Val Loss: 2.03383
Epoch 33, Val Loss: 2.03122
Epoch 34, Val Loss: 2.02630
Epoch 35, Val Loss: 2.03748
Epoch 36, Val Loss: 2.04195
Epoch 37, Val Loss: 2.04344
Epoch 38, Val Loss: 2.01633
Epoch 39, Val Loss: 2.04639
Epoch 40, Val Loss: 2.02627
Epoch 41, Val Loss: 2.03052
Epoch 42, Val Loss: 2.03068
Epoch 43, Val Loss: 2.03111
Epoch 44, Val Loss: 2.07345
Epoch 45, Val Loss: 2.06123
Epoch 46, Val Loss: 2.02783
Epoch 47, Val Loss: 2.03760
Epoch 48, Val Loss: 2.02666
Epoch 49, Val Loss: 2.01877
Epoch 50, Val Loss: 2.03411
Epoch 51, Val Loss: 2.01976
Epoch 52, Val Loss: 2.02080
Epoch 53, Val Loss: 2.01740
Epoch 54, Val Loss: 2.03662
Epoch 55, Val Loss: 2.05829
Epoch 56, Val Loss: 2.04115
Epoch 57, Val Loss: 2.02076
Epoch 58, Val Loss: 2.02989
Epoch 59, Val Loss: 2.04822
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2229666666666668, 'Log Loss - std': 0.23495041084355558} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}
Fitted encoder
Epoch 0, Val Loss: 2.09131
Epoch 1, Val Loss: 2.07258
Epoch 2, Val Loss: 2.09010
Epoch 3, Val Loss: 2.07887
Epoch 4, Val Loss: 2.05482
Epoch 5, Val Loss: 2.05618
Epoch 6, Val Loss: 2.04808
Epoch 7, Val Loss: 2.15047
Epoch 8, Val Loss: 2.07987
Epoch 9, Val Loss: 2.07683
Epoch 10, Val Loss: 2.08218
Epoch 11, Val Loss: 2.06183
Epoch 12, Val Loss: 2.07369
Epoch 13, Val Loss: 2.07727
Epoch 14, Val Loss: 2.09209
Epoch 15, Val Loss: 2.14678
Epoch 16, Val Loss: 2.11448
Epoch 17, Val Loss: 2.06106
Epoch 18, Val Loss: 2.09138
Epoch 19, Val Loss: 2.09978
Epoch 20, Val Loss: 2.08893
Epoch 21, Val Loss: 2.09229
Epoch 22, Val Loss: 2.09387
Epoch 23, Val Loss: 2.10647
Epoch 24, Val Loss: 2.10441
Epoch 25, Val Loss: 2.10955
Epoch 26, Val Loss: 2.08211
Epoch 27, Val Loss: 2.08279
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.1048750000000003, 'Log Loss - std': 0.28851030635836916} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}
Fitted encoder
Epoch 0, Val Loss: 2.05619
Epoch 1, Val Loss: 1.94878
Epoch 2, Val Loss: 1.95080
Epoch 3, Val Loss: 1.93641
Epoch 4, Val Loss: 1.92600
Epoch 5, Val Loss: 1.91862
Epoch 6, Val Loss: 1.90748
Epoch 7, Val Loss: 1.98008
Epoch 8, Val Loss: 1.90416
Epoch 9, Val Loss: 1.92378
Epoch 10, Val Loss: 1.89965
Epoch 11, Val Loss: 1.90218
Epoch 12, Val Loss: 1.91074
Epoch 13, Val Loss: 1.89369
Epoch 14, Val Loss: 1.88392
Epoch 15, Val Loss: 1.87673
Epoch 16, Val Loss: 1.88578
Epoch 17, Val Loss: 2.02164
Epoch 18, Val Loss: 1.91456
Epoch 19, Val Loss: 1.89438
Epoch 20, Val Loss: 1.90890
Epoch 21, Val Loss: 1.89472
Epoch 22, Val Loss: 1.88543
Epoch 23, Val Loss: 1.89934
Epoch 24, Val Loss: 1.88163
Epoch 25, Val Loss: 1.87912
Epoch 26, Val Loss: 1.87925
Epoch 27, Val Loss: 1.89146
Epoch 28, Val Loss: 1.89400
Epoch 29, Val Loss: 1.88020
Epoch 30, Val Loss: 1.88044
Epoch 31, Val Loss: 1.89190
Epoch 32, Val Loss: 1.89981
Epoch 33, Val Loss: 1.89367
Epoch 34, Val Loss: 1.94259
Epoch 35, Val Loss: 1.90585
Epoch 36, Val Loss: 1.89450
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.06226, 'Log Loss - std': 0.2717622313714693} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 35 finished with value: 3.06226 and parameters: {'p_m': 0.6818676795533795, 'alpha': 0.1097410178334169, 'K': 15, 'beta': 2.5392768874159657}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}
Fitted encoder
Epoch 0, Val Loss: 2.14632
Epoch 1, Val Loss: 2.13871
Epoch 2, Val Loss: 2.12785
Epoch 3, Val Loss: 2.12327
Epoch 4, Val Loss: 2.11008
Epoch 5, Val Loss: 2.10664
Epoch 6, Val Loss: 2.09784
Epoch 7, Val Loss: 2.12616
Epoch 8, Val Loss: 2.10255
Epoch 9, Val Loss: 2.09955
Epoch 10, Val Loss: 2.08260
Epoch 11, Val Loss: 2.10755
Epoch 12, Val Loss: 2.08005
Epoch 13, Val Loss: 2.09227
Epoch 14, Val Loss: 2.08661
Epoch 15, Val Loss: 2.07602
Epoch 16, Val Loss: 2.07986
Epoch 17, Val Loss: 2.08174
Epoch 18, Val Loss: 2.08058
Epoch 19, Val Loss: 2.06856
Epoch 20, Val Loss: 2.06361
Epoch 21, Val Loss: 2.07383
Epoch 22, Val Loss: 2.08892
Epoch 23, Val Loss: 2.09006
Epoch 24, Val Loss: 2.08637
Epoch 25, Val Loss: 2.07495
Epoch 26, Val Loss: 2.06044
Epoch 27, Val Loss: 2.05371
Epoch 28, Val Loss: 2.10996
Epoch 29, Val Loss: 2.08285
Epoch 30, Val Loss: 2.06307
Epoch 31, Val Loss: 2.07141
Epoch 32, Val Loss: 2.07434
Epoch 33, Val Loss: 2.08409
Epoch 34, Val Loss: 2.06870
Epoch 35, Val Loss: 2.06461
Epoch 36, Val Loss: 2.07615
Epoch 37, Val Loss: 2.06491
Epoch 38, Val Loss: 2.09335
Epoch 39, Val Loss: 2.08401
Epoch 40, Val Loss: 2.10088
Epoch 41, Val Loss: 2.07713
Epoch 42, Val Loss: 2.08954
Epoch 43, Val Loss: 2.09401
Epoch 44, Val Loss: 2.06614
Epoch 45, Val Loss: 2.08199
Epoch 46, Val Loss: 2.07156
Epoch 47, Val Loss: 2.09218
Epoch 48, Val Loss: 2.06261
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.5292, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}
Fitted encoder
Epoch 0, Val Loss: 1.95065
Epoch 1, Val Loss: 1.95540
Epoch 2, Val Loss: 1.94585
Epoch 3, Val Loss: 1.94041
Epoch 4, Val Loss: 1.93381
Epoch 5, Val Loss: 1.92322
Epoch 6, Val Loss: 1.90749
Epoch 7, Val Loss: 1.96667
Epoch 8, Val Loss: 1.92976
Epoch 9, Val Loss: 1.91761
Epoch 10, Val Loss: 1.92145
Epoch 11, Val Loss: 1.92935
Epoch 12, Val Loss: 1.94492
Epoch 13, Val Loss: 1.93452
Epoch 14, Val Loss: 1.92485
Epoch 15, Val Loss: 1.91717
Epoch 16, Val Loss: 1.90617
Epoch 17, Val Loss: 1.90919
Epoch 18, Val Loss: 1.90075
Epoch 19, Val Loss: 1.90443
Epoch 20, Val Loss: 1.91950
Epoch 21, Val Loss: 1.90028
Epoch 22, Val Loss: 1.89641
Epoch 23, Val Loss: 1.90572
Epoch 24, Val Loss: 1.90105
Epoch 25, Val Loss: 1.91793
Epoch 26, Val Loss: 1.92390
Epoch 27, Val Loss: 1.90024
Epoch 28, Val Loss: 1.91428
Epoch 29, Val Loss: 1.92827
Epoch 30, Val Loss: 1.91901
Epoch 31, Val Loss: 1.90469
Epoch 32, Val Loss: 1.90519
Epoch 33, Val Loss: 1.89027
Epoch 34, Val Loss: 1.90912
Epoch 35, Val Loss: 1.89648
Epoch 36, Val Loss: 1.91631
Epoch 37, Val Loss: 1.89174
Epoch 38, Val Loss: 1.93442
Epoch 39, Val Loss: 1.92270
Epoch 40, Val Loss: 1.90333
Epoch 41, Val Loss: 1.89586
Epoch 42, Val Loss: 1.88427
Epoch 43, Val Loss: 1.89496
Epoch 44, Val Loss: 1.89460
Epoch 45, Val Loss: 1.93918
Epoch 46, Val Loss: 1.89119
Epoch 47, Val Loss: 1.89487
Epoch 48, Val Loss: 1.92829
Epoch 49, Val Loss: 1.89579
Epoch 50, Val Loss: 1.89666
Epoch 51, Val Loss: 1.89174
Epoch 52, Val Loss: 1.90393
Epoch 53, Val Loss: 1.89179
Epoch 54, Val Loss: 1.89636
Epoch 55, Val Loss: 1.93553
Epoch 56, Val Loss: 1.90404
Epoch 57, Val Loss: 1.89258
Epoch 58, Val Loss: 1.89207
Epoch 59, Val Loss: 1.90288
Epoch 60, Val Loss: 1.90417
Epoch 61, Val Loss: 1.90660
Epoch 62, Val Loss: 1.90177
Epoch 63, Val Loss: 1.90706
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3785, 'Log Loss - std': 0.15070000000000006} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}
Fitted encoder
Epoch 0, Val Loss: 2.14726
Epoch 1, Val Loss: 2.11956
Epoch 2, Val Loss: 2.13048
Epoch 3, Val Loss: 2.12320
Epoch 4, Val Loss: 2.10884
Epoch 5, Val Loss: 2.11327
Epoch 6, Val Loss: 2.11186
Epoch 7, Val Loss: 2.11088
Epoch 8, Val Loss: 2.10782
Epoch 9, Val Loss: 2.10624
Epoch 10, Val Loss: 2.10978
Epoch 11, Val Loss: 2.10863
Epoch 12, Val Loss: 2.10297
Epoch 13, Val Loss: 2.11144
Epoch 14, Val Loss: 2.09577
Epoch 15, Val Loss: 2.10160
Epoch 16, Val Loss: 2.09286
Epoch 17, Val Loss: 2.09625
Epoch 18, Val Loss: 2.10517
Epoch 19, Val Loss: 2.09547
Epoch 20, Val Loss: 2.09391
Epoch 21, Val Loss: 2.09748
Epoch 22, Val Loss: 2.09875
Epoch 23, Val Loss: 2.10081
Epoch 24, Val Loss: 2.09002
Epoch 25, Val Loss: 2.10477
Epoch 26, Val Loss: 2.10630
Epoch 27, Val Loss: 2.08865
Epoch 28, Val Loss: 2.11329
Epoch 29, Val Loss: 2.09383
Epoch 30, Val Loss: 2.11113
Epoch 31, Val Loss: 2.09681
Epoch 32, Val Loss: 2.09177
Epoch 33, Val Loss: 2.14268
Epoch 34, Val Loss: 2.09420
Epoch 35, Val Loss: 2.11800
Epoch 36, Val Loss: 2.07948
Epoch 37, Val Loss: 2.08756
Epoch 38, Val Loss: 2.08889
Epoch 39, Val Loss: 2.08238
Epoch 40, Val Loss: 2.09027
Epoch 41, Val Loss: 2.08744
Epoch 42, Val Loss: 2.08947
Epoch 43, Val Loss: 2.07662
Epoch 44, Val Loss: 2.08608
Epoch 45, Val Loss: 2.08868
Epoch 46, Val Loss: 2.07738
Epoch 47, Val Loss: 2.08722
Epoch 48, Val Loss: 2.08215
Epoch 49, Val Loss: 2.07747
Epoch 50, Val Loss: 2.11832
Epoch 51, Val Loss: 2.07384
Epoch 52, Val Loss: 2.09811
Epoch 53, Val Loss: 2.07400
Epoch 54, Val Loss: 2.08389
Epoch 55, Val Loss: 2.08201
Epoch 56, Val Loss: 2.07512
Epoch 57, Val Loss: 2.07486
Epoch 58, Val Loss: 2.08493
Epoch 59, Val Loss: 2.09254
Epoch 60, Val Loss: 2.07487
Epoch 61, Val Loss: 2.07470
Epoch 62, Val Loss: 2.10006
Epoch 63, Val Loss: 2.07432
Epoch 64, Val Loss: 2.06736
Epoch 65, Val Loss: 2.08283
Epoch 66, Val Loss: 2.08117
Epoch 67, Val Loss: 2.07706
Epoch 68, Val Loss: 2.07365
Epoch 69, Val Loss: 2.08059
Epoch 70, Val Loss: 2.07186
Epoch 71, Val Loss: 2.06974
Epoch 72, Val Loss: 2.11447
Epoch 73, Val Loss: 2.07788
Epoch 74, Val Loss: 2.08044
Epoch 75, Val Loss: 2.08765
Epoch 76, Val Loss: 2.08223
Epoch 77, Val Loss: 2.08023
Epoch 78, Val Loss: 2.07197
Epoch 79, Val Loss: 2.07761
Epoch 80, Val Loss: 2.07748
Epoch 81, Val Loss: 2.07484
Epoch 82, Val Loss: 2.07711
Epoch 83, Val Loss: 2.09710
Epoch 84, Val Loss: 2.10285
Epoch 85, Val Loss: 2.08392
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3227999999999995, 'Log Loss - std': 0.14610033082326226} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}
Fitted encoder
Epoch 0, Val Loss: 2.08342
Epoch 1, Val Loss: 2.05713
Epoch 2, Val Loss: 2.05919
Epoch 3, Val Loss: 2.08152
Epoch 4, Val Loss: 2.06683
Epoch 5, Val Loss: 2.06280
Epoch 6, Val Loss: 2.04625
Epoch 7, Val Loss: 2.07882
Epoch 8, Val Loss: 2.05084
Epoch 9, Val Loss: 2.03593
Epoch 10, Val Loss: 2.03545
Epoch 11, Val Loss: 2.02961
Epoch 12, Val Loss: 2.08935
Epoch 13, Val Loss: 2.04138
Epoch 14, Val Loss: 2.02529
Epoch 15, Val Loss: 2.06294
Epoch 16, Val Loss: 2.03702
Epoch 17, Val Loss: 2.03618
Epoch 18, Val Loss: 2.04345
Epoch 19, Val Loss: 2.05106
Epoch 20, Val Loss: 2.01551
Epoch 21, Val Loss: 2.04171
Epoch 22, Val Loss: 2.04268
Epoch 23, Val Loss: 2.03872
Epoch 24, Val Loss: 2.02260
Epoch 25, Val Loss: 2.03310
Epoch 26, Val Loss: 2.05475
Epoch 27, Val Loss: 2.02669
Epoch 28, Val Loss: 2.02605
Epoch 29, Val Loss: 2.02883
Epoch 30, Val Loss: 2.04120
Epoch 31, Val Loss: 2.02795
Epoch 32, Val Loss: 2.02272
Epoch 33, Val Loss: 2.04110
Epoch 34, Val Loss: 2.02444
Epoch 35, Val Loss: 2.03021
Epoch 36, Val Loss: 2.02396
Epoch 37, Val Loss: 2.03003
Epoch 38, Val Loss: 2.02587
Epoch 39, Val Loss: 2.03429
Epoch 40, Val Loss: 2.03971
Epoch 41, Val Loss: 2.03559
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.11535, 'Log Loss - std': 0.38094026762735383} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}
Fitted encoder
Epoch 0, Val Loss: 2.09478
Epoch 1, Val Loss: 2.06770
Epoch 2, Val Loss: 1.95815
Epoch 3, Val Loss: 1.94394
Epoch 4, Val Loss: 1.94670
Epoch 5, Val Loss: 1.93069
Epoch 6, Val Loss: 1.91843
Epoch 7, Val Loss: 1.92874
Epoch 8, Val Loss: 1.90800
Epoch 9, Val Loss: 1.92384
Epoch 10, Val Loss: 1.90578
Epoch 11, Val Loss: 1.94262
Epoch 12, Val Loss: 1.90157
Epoch 13, Val Loss: 1.91469
Epoch 14, Val Loss: 1.91700
Epoch 15, Val Loss: 1.90286
Epoch 16, Val Loss: 1.91035
Epoch 17, Val Loss: 1.89720
Epoch 18, Val Loss: 1.90863
Epoch 19, Val Loss: 1.90198
Epoch 20, Val Loss: 1.91085
Epoch 21, Val Loss: 1.90434
Epoch 22, Val Loss: 1.90083
Epoch 23, Val Loss: 1.91023
Epoch 24, Val Loss: 1.89856
Epoch 25, Val Loss: 1.91402
Epoch 26, Val Loss: 1.89688
Epoch 27, Val Loss: 1.90779
Epoch 28, Val Loss: 1.90767
Epoch 29, Val Loss: 1.89044
Epoch 30, Val Loss: 1.90781
Epoch 31, Val Loss: 1.92453
Epoch 32, Val Loss: 1.89422
Epoch 33, Val Loss: 1.90233
Epoch 34, Val Loss: 1.89235
Epoch 35, Val Loss: 1.89459
Epoch 36, Val Loss: 1.92639
Epoch 37, Val Loss: 1.89049
Epoch 38, Val Loss: 1.90126
Epoch 39, Val Loss: 1.92532
Epoch 40, Val Loss: 1.89822
Epoch 41, Val Loss: 1.89109
Epoch 42, Val Loss: 1.89612
Epoch 43, Val Loss: 1.90583
Epoch 44, Val Loss: 1.89062
Epoch 45, Val Loss: 1.89021
Epoch 46, Val Loss: 1.88226
Epoch 47, Val Loss: 1.91692
Epoch 48, Val Loss: 1.93186
Epoch 49, Val Loss: 1.89606
Epoch 50, Val Loss: 1.88979
Epoch 51, Val Loss: 1.89335
Epoch 52, Val Loss: 1.92921
Epoch 53, Val Loss: 1.91731
Epoch 54, Val Loss: 1.89604
Epoch 55, Val Loss: 1.91672
Epoch 56, Val Loss: 1.88943
Epoch 57, Val Loss: 1.88560
Epoch 58, Val Loss: 1.88644
Epoch 59, Val Loss: 1.90437
Epoch 60, Val Loss: 1.90413
Epoch 61, Val Loss: 1.89461
Epoch 62, Val Loss: 1.89408
Epoch 63, Val Loss: 1.89332
Epoch 64, Val Loss: 1.90183
Epoch 65, Val Loss: 1.89486
Epoch 66, Val Loss: 1.88803
Epoch 67, Val Loss: 1.90169
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.12424, 'Log Loss - std': 0.3411869258925377} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 36 finished with value: 3.12424 and parameters: {'p_m': 0.5398199936670294, 'alpha': 1.917976686793204, 'K': 20, 'beta': 1.7594204641988695}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}
Fitted encoder
Epoch 0, Val Loss: 2.13493
Epoch 1, Val Loss: 2.13229
Epoch 2, Val Loss: 2.13421
Epoch 3, Val Loss: 2.12664
Epoch 4, Val Loss: 2.12852
Epoch 5, Val Loss: 2.08955
Epoch 6, Val Loss: 2.12874
Epoch 7, Val Loss: 2.11658
Epoch 8, Val Loss: 2.11500
Epoch 9, Val Loss: 2.08259
Epoch 10, Val Loss: 2.13294
Epoch 11, Val Loss: 2.11160
Epoch 12, Val Loss: 2.11210
Epoch 13, Val Loss: 2.11683
Epoch 14, Val Loss: 2.11915
Epoch 15, Val Loss: 2.10697
Epoch 16, Val Loss: 2.10435
Epoch 17, Val Loss: 2.09407
Epoch 18, Val Loss: 2.12139
Epoch 19, Val Loss: 2.10260
Epoch 20, Val Loss: 2.11101
Epoch 21, Val Loss: 2.10427
Epoch 22, Val Loss: 2.08938
Epoch 23, Val Loss: 2.11339
Epoch 24, Val Loss: 2.12757
Epoch 25, Val Loss: 2.07800
Epoch 26, Val Loss: 2.10454
Epoch 27, Val Loss: 2.10419
Epoch 28, Val Loss: 2.08894
Epoch 29, Val Loss: 2.10294
Epoch 30, Val Loss: 2.10560
Epoch 31, Val Loss: 2.10632
Epoch 32, Val Loss: 2.08564
Epoch 33, Val Loss: 2.12673
Epoch 34, Val Loss: 2.09549
Epoch 35, Val Loss: 2.10009
Epoch 36, Val Loss: 2.09101
Epoch 37, Val Loss: 2.11479
Epoch 38, Val Loss: 2.07820
Epoch 39, Val Loss: 2.10813
Epoch 40, Val Loss: 2.09323
Epoch 41, Val Loss: 2.07466
Epoch 42, Val Loss: 2.08221
Epoch 43, Val Loss: 2.09520
Epoch 44, Val Loss: 2.08880
Epoch 45, Val Loss: 2.07188
Epoch 46, Val Loss: 2.07029
Epoch 47, Val Loss: 2.08986
Epoch 48, Val Loss: 2.09851
Epoch 49, Val Loss: 2.07168
Epoch 50, Val Loss: 2.07576
Epoch 51, Val Loss: 2.06627
Epoch 52, Val Loss: 2.09023
Epoch 53, Val Loss: 2.08190
Epoch 54, Val Loss: 2.05983
Epoch 55, Val Loss: 2.06824
Epoch 56, Val Loss: 2.10092
Epoch 57, Val Loss: 2.10128
Epoch 58, Val Loss: 2.08780
Epoch 59, Val Loss: 2.07591
Epoch 60, Val Loss: 2.06630
Epoch 61, Val Loss: 2.05730
Epoch 62, Val Loss: 2.07895
Epoch 63, Val Loss: 2.07466
Epoch 64, Val Loss: 2.04167
Epoch 65, Val Loss: 2.05318
Epoch 66, Val Loss: 2.07748
Epoch 67, Val Loss: 2.06992
Epoch 68, Val Loss: 2.08608
Epoch 69, Val Loss: 2.06260
Epoch 70, Val Loss: 2.05534
Epoch 71, Val Loss: 2.09759
Epoch 72, Val Loss: 2.05190
Epoch 73, Val Loss: 2.07834
Epoch 74, Val Loss: 2.06284
Epoch 75, Val Loss: 2.05059
Epoch 76, Val Loss: 2.04782
Epoch 77, Val Loss: 2.06195
Epoch 78, Val Loss: 2.05442
Epoch 79, Val Loss: 2.07904
Epoch 80, Val Loss: 2.05797
Epoch 81, Val Loss: 2.03759
Epoch 82, Val Loss: 2.06663
Epoch 83, Val Loss: 2.03926
Epoch 84, Val Loss: 2.04903
Epoch 85, Val Loss: 2.05174
Epoch 86, Val Loss: 2.07054
Epoch 87, Val Loss: 2.04862
Epoch 88, Val Loss: 2.07291
Epoch 89, Val Loss: 2.07206
Epoch 90, Val Loss: 2.05256
Epoch 91, Val Loss: 2.04849
Epoch 92, Val Loss: 2.04581
Epoch 93, Val Loss: 2.11688
Epoch 94, Val Loss: 2.06470
Epoch 95, Val Loss: 2.05930
Epoch 96, Val Loss: 2.06144
Epoch 97, Val Loss: 2.06481
Epoch 98, Val Loss: 2.05734
Epoch 99, Val Loss: 2.07196
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.1395, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}
Fitted encoder
Epoch 0, Val Loss: 1.94989
Epoch 1, Val Loss: 1.93658
Epoch 2, Val Loss: 1.94230
Epoch 3, Val Loss: 1.91642
Epoch 4, Val Loss: 1.92133
Epoch 5, Val Loss: 1.94219
Epoch 6, Val Loss: 1.97214
Epoch 7, Val Loss: 1.92798
Epoch 8, Val Loss: 1.91960
Epoch 9, Val Loss: 1.92250
Epoch 10, Val Loss: 1.91399
Epoch 11, Val Loss: 1.91481
Epoch 12, Val Loss: 1.92595
Epoch 13, Val Loss: 1.92287
Epoch 14, Val Loss: 1.91112
Epoch 15, Val Loss: 1.91111
Epoch 16, Val Loss: 1.91633
Epoch 17, Val Loss: 1.92025
Epoch 18, Val Loss: 1.94297
Epoch 19, Val Loss: 1.93446
Epoch 20, Val Loss: 1.92658
Epoch 21, Val Loss: 1.94194
Epoch 22, Val Loss: 1.92771
Epoch 23, Val Loss: 1.92244
Epoch 24, Val Loss: 1.93046
Epoch 25, Val Loss: 1.92384
Epoch 26, Val Loss: 1.90366
Epoch 27, Val Loss: 1.90409
Epoch 28, Val Loss: 1.94349
Epoch 29, Val Loss: 1.93064
Epoch 30, Val Loss: 1.92222
Epoch 31, Val Loss: 1.91657
Epoch 32, Val Loss: 1.89613
Epoch 33, Val Loss: 1.90668
Epoch 34, Val Loss: 1.90402
Epoch 35, Val Loss: 1.89761
Epoch 36, Val Loss: 1.90115
Epoch 37, Val Loss: 1.91007
Epoch 38, Val Loss: 1.90887
Epoch 39, Val Loss: 1.91104
Epoch 40, Val Loss: 1.89903
Epoch 41, Val Loss: 1.91322
Epoch 42, Val Loss: 1.91437
Epoch 43, Val Loss: 1.90162
Epoch 44, Val Loss: 1.89389
Epoch 45, Val Loss: 1.90357
Epoch 46, Val Loss: 1.89236
Epoch 47, Val Loss: 1.90488
Epoch 48, Val Loss: 1.90168
Epoch 49, Val Loss: 1.91900
Epoch 50, Val Loss: 1.88820
Epoch 51, Val Loss: 1.89781
Epoch 52, Val Loss: 1.89857
Epoch 53, Val Loss: 1.89633
Epoch 54, Val Loss: 1.89767
Epoch 55, Val Loss: 1.90351
Epoch 56, Val Loss: 1.89677
Epoch 57, Val Loss: 1.89237
Epoch 58, Val Loss: 1.88823
Epoch 59, Val Loss: 1.89394
Epoch 60, Val Loss: 1.90571
Epoch 61, Val Loss: 1.91133
Epoch 62, Val Loss: 1.89505
Epoch 63, Val Loss: 1.88904
Epoch 64, Val Loss: 1.89363
Epoch 65, Val Loss: 1.89229
Epoch 66, Val Loss: 1.93817
Epoch 67, Val Loss: 1.91627
Epoch 68, Val Loss: 1.91266
Epoch 69, Val Loss: 1.91732
Epoch 70, Val Loss: 1.90815
Epoch 71, Val Loss: 1.92837
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.34295, 'Log Loss - std': 0.20345000000000013} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}
Fitted encoder
Epoch 0, Val Loss: 2.11178
Epoch 1, Val Loss: 2.13317
Epoch 2, Val Loss: 2.11666
Epoch 3, Val Loss: 2.11010
Epoch 4, Val Loss: 2.10664
Epoch 5, Val Loss: 2.10146
Epoch 6, Val Loss: 2.08859
Epoch 7, Val Loss: 2.08307
Epoch 8, Val Loss: 2.11726
Epoch 9, Val Loss: 2.09050
Epoch 10, Val Loss: 2.07231
Epoch 11, Val Loss: 2.08844
Epoch 12, Val Loss: 2.07187
Epoch 13, Val Loss: 2.08077
Epoch 14, Val Loss: 2.08070
Epoch 15, Val Loss: 2.08924
Epoch 16, Val Loss: 2.13153
Epoch 17, Val Loss: 2.07938
Epoch 18, Val Loss: 2.08183
Epoch 19, Val Loss: 2.09348
Epoch 20, Val Loss: 2.09423
Epoch 21, Val Loss: 2.08036
Epoch 22, Val Loss: 2.08510
Epoch 23, Val Loss: 2.07938
Epoch 24, Val Loss: 2.09395
Epoch 25, Val Loss: 2.06565
Epoch 26, Val Loss: 2.08415
Epoch 27, Val Loss: 2.08406
Epoch 28, Val Loss: 2.07727
Epoch 29, Val Loss: 2.11578
Epoch 30, Val Loss: 2.12008
Epoch 31, Val Loss: 2.15108
Epoch 32, Val Loss: 2.10949
Epoch 33, Val Loss: 2.13361
Epoch 34, Val Loss: 2.12606
Epoch 35, Val Loss: 2.16976
Epoch 36, Val Loss: 2.22166
Epoch 37, Val Loss: 2.22667
Epoch 38, Val Loss: 2.22245
Epoch 39, Val Loss: 2.20642
Epoch 40, Val Loss: 2.14297
Epoch 41, Val Loss: 2.11294
Epoch 42, Val Loss: 2.09927
Epoch 43, Val Loss: 2.09903
Epoch 44, Val Loss: 2.10620
Epoch 45, Val Loss: 2.10044
Epoch 46, Val Loss: 2.10346
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3658, 'Log Loss - std': 0.16923015885670822} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}
Fitted encoder
Epoch 0, Val Loss: 2.07222
Epoch 1, Val Loss: 2.08812
Epoch 2, Val Loss: 2.09882
Epoch 3, Val Loss: 2.08975
Epoch 4, Val Loss: 2.06319
Epoch 5, Val Loss: 2.10299
Epoch 6, Val Loss: 2.07428
Epoch 7, Val Loss: 2.05046
Epoch 8, Val Loss: 2.06438
Epoch 9, Val Loss: 2.12309
Epoch 10, Val Loss: 2.06403
Epoch 11, Val Loss: 2.05372
Epoch 12, Val Loss: 2.11289
Epoch 13, Val Loss: 2.11503
Epoch 14, Val Loss: 2.10978
Epoch 15, Val Loss: 2.09157
Epoch 16, Val Loss: 2.09155
Epoch 17, Val Loss: 2.12293
Epoch 18, Val Loss: 2.09189
Epoch 19, Val Loss: 2.10707
Epoch 20, Val Loss: 2.10531
Epoch 21, Val Loss: 2.08766
Epoch 22, Val Loss: 2.08801
Epoch 23, Val Loss: 2.04725
Epoch 24, Val Loss: 2.09405
Epoch 25, Val Loss: 2.09178
Epoch 26, Val Loss: 2.10470
Epoch 27, Val Loss: 2.04823
Epoch 28, Val Loss: 2.05629
Epoch 29, Val Loss: 2.04875
Epoch 30, Val Loss: 2.02729
Epoch 31, Val Loss: 2.06572
Epoch 32, Val Loss: 2.03441
Epoch 33, Val Loss: 2.08389
Epoch 34, Val Loss: 2.10260
Epoch 35, Val Loss: 2.08152
Epoch 36, Val Loss: 2.07602
Epoch 37, Val Loss: 2.09087
Epoch 38, Val Loss: 2.09904
Epoch 39, Val Loss: 2.07350
Epoch 40, Val Loss: 2.07071
Epoch 41, Val Loss: 2.03502
Epoch 42, Val Loss: 2.03712
Epoch 43, Val Loss: 2.04349
Epoch 44, Val Loss: 2.01441
Epoch 45, Val Loss: 2.09192
Epoch 46, Val Loss: 2.12297
Epoch 47, Val Loss: 2.09059
Epoch 48, Val Loss: 2.07823
Epoch 49, Val Loss: 2.06930
Epoch 50, Val Loss: 2.11566
Epoch 51, Val Loss: 2.03976
Epoch 52, Val Loss: 2.01528
Epoch 53, Val Loss: 2.03236
Epoch 54, Val Loss: 2.02844
Epoch 55, Val Loss: 2.07922
Epoch 56, Val Loss: 2.07788
Epoch 57, Val Loss: 2.08741
Epoch 58, Val Loss: 2.07212
Epoch 59, Val Loss: 2.09381
Epoch 60, Val Loss: 2.06926
Epoch 61, Val Loss: 2.07019
Epoch 62, Val Loss: 2.08205
Epoch 63, Val Loss: 2.07649
Epoch 64, Val Loss: 2.07833
Epoch 65, Val Loss: 2.07503
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.4585500000000002, 'Log Loss - std': 0.2174553344942359} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}
Fitted encoder
Epoch 0, Val Loss: 1.95738
Epoch 1, Val Loss: 1.93746
Epoch 2, Val Loss: 1.93854
Epoch 3, Val Loss: 1.94237
Epoch 4, Val Loss: 1.95733
Epoch 5, Val Loss: 1.97766
Epoch 6, Val Loss: 1.92845
Epoch 7, Val Loss: 1.95620
Epoch 8, Val Loss: 1.96233
Epoch 9, Val Loss: 1.94917
Epoch 10, Val Loss: 1.93627
Epoch 11, Val Loss: 1.93519
Epoch 12, Val Loss: 1.94621
Epoch 13, Val Loss: 1.93106
Epoch 14, Val Loss: 1.94209
Epoch 15, Val Loss: 1.92367
Epoch 16, Val Loss: 1.92066
Epoch 17, Val Loss: 1.93469
Epoch 18, Val Loss: 1.91801
Epoch 19, Val Loss: 1.93428
Epoch 20, Val Loss: 1.94562
Epoch 21, Val Loss: 1.92157
Epoch 22, Val Loss: 1.90605
Epoch 23, Val Loss: 1.90521
Epoch 24, Val Loss: 1.91650
Epoch 25, Val Loss: 1.89532
Epoch 26, Val Loss: 1.91634
Epoch 27, Val Loss: 1.92616
Epoch 28, Val Loss: 1.90496
Epoch 29, Val Loss: 1.92152
Epoch 30, Val Loss: 1.91766
Epoch 31, Val Loss: 1.90735
Epoch 32, Val Loss: 1.89147
Epoch 33, Val Loss: 1.93882
Epoch 34, Val Loss: 1.92743
Epoch 35, Val Loss: 1.93925
Epoch 36, Val Loss: 1.90585
Epoch 37, Val Loss: 1.91825
Epoch 38, Val Loss: 1.90355
Epoch 39, Val Loss: 1.90532
Epoch 40, Val Loss: 1.89483
Epoch 41, Val Loss: 1.88929
Epoch 42, Val Loss: 1.91691
Epoch 43, Val Loss: 1.89786
Epoch 44, Val Loss: 1.91034
Epoch 45, Val Loss: 1.91190
Epoch 46, Val Loss: 1.89495
Epoch 47, Val Loss: 1.90123
Epoch 48, Val Loss: 1.90055
Epoch 49, Val Loss: 1.91021
Epoch 50, Val Loss: 1.90625
Epoch 51, Val Loss: 1.92325
Epoch 52, Val Loss: 1.90443
Epoch 53, Val Loss: 1.89830
Epoch 54, Val Loss: 1.89790
Epoch 55, Val Loss: 1.90360
Epoch 56, Val Loss: 1.90684
Epoch 57, Val Loss: 1.91274
Epoch 58, Val Loss: 1.90639
Epoch 59, Val Loss: 1.90007
Epoch 60, Val Loss: 1.90049
Epoch 61, Val Loss: 1.91903
Epoch 62, Val Loss: 1.89594
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.4091, 'Log Loss - std': 0.21819868927195699} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 37 finished with value: 3.4091 and parameters: {'p_m': 0.7407801986963526, 'alpha': 1.4227969764383097, 'K': 3, 'beta': 1.297751381034046}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}
Fitted encoder
Epoch 0, Val Loss: 2.11729
Epoch 1, Val Loss: 2.13712
Epoch 2, Val Loss: 2.12377
Epoch 3, Val Loss: 2.10287
Epoch 4, Val Loss: 2.09768
Epoch 5, Val Loss: 2.13125
Epoch 6, Val Loss: 2.11631
Epoch 7, Val Loss: 2.08717
Epoch 8, Val Loss: 2.09106
Epoch 9, Val Loss: 2.09617
Epoch 10, Val Loss: 2.08697
Epoch 11, Val Loss: 2.10301
Epoch 12, Val Loss: 2.08652
Epoch 13, Val Loss: 2.10843
Epoch 14, Val Loss: 2.09269
Epoch 15, Val Loss: 2.08184
Epoch 16, Val Loss: 2.08037
Epoch 17, Val Loss: 2.09193
Epoch 18, Val Loss: 2.08469
Epoch 19, Val Loss: 2.08506
Epoch 20, Val Loss: 2.08653
Epoch 21, Val Loss: 2.11132
Epoch 22, Val Loss: 2.07701
Epoch 23, Val Loss: 2.08371
Epoch 24, Val Loss: 2.09076
Epoch 25, Val Loss: 2.07104
Epoch 26, Val Loss: 2.07999
Epoch 27, Val Loss: 2.08433
Epoch 28, Val Loss: 2.07467
Epoch 29, Val Loss: 2.07845
Epoch 30, Val Loss: 2.08256
Epoch 31, Val Loss: 2.10145
Epoch 32, Val Loss: 2.06682
Epoch 33, Val Loss: 2.08209
Epoch 34, Val Loss: 2.07928
Epoch 35, Val Loss: 2.06414
Epoch 36, Val Loss: 2.10729
Epoch 37, Val Loss: 2.10566
Epoch 38, Val Loss: 2.08162
Epoch 39, Val Loss: 2.06712
Epoch 40, Val Loss: 2.07267
Epoch 41, Val Loss: 2.07930
Epoch 42, Val Loss: 2.08149
Epoch 43, Val Loss: 2.06212
Epoch 44, Val Loss: 2.07834
Epoch 45, Val Loss: 2.07428
Epoch 46, Val Loss: 2.06062
Epoch 47, Val Loss: 2.08333
Epoch 48, Val Loss: 2.07556
Epoch 49, Val Loss: 2.06471
Epoch 50, Val Loss: 2.07971
Epoch 51, Val Loss: 2.08217
Epoch 52, Val Loss: 2.06988
Epoch 53, Val Loss: 2.06155
Epoch 54, Val Loss: 2.07714
Epoch 55, Val Loss: 2.07492
Epoch 56, Val Loss: 2.06294
Epoch 57, Val Loss: 2.05485
Epoch 58, Val Loss: 2.07570
Epoch 59, Val Loss: 2.05853
Epoch 60, Val Loss: 2.05753
Epoch 61, Val Loss: 2.07102
Epoch 62, Val Loss: 2.07288
Epoch 63, Val Loss: 2.06643
Epoch 64, Val Loss: 2.05839
Epoch 65, Val Loss: 2.04996
Epoch 66, Val Loss: 2.05849
Epoch 67, Val Loss: 2.06552
Epoch 68, Val Loss: 2.03890
Epoch 69, Val Loss: 2.07947
Epoch 70, Val Loss: 2.06525
Epoch 71, Val Loss: 2.11548
Epoch 72, Val Loss: 2.04256
Epoch 73, Val Loss: 2.02667
Epoch 74, Val Loss: 2.05542
Epoch 75, Val Loss: 2.09904
Epoch 76, Val Loss: 2.04429
Epoch 77, Val Loss: 2.03469
Epoch 78, Val Loss: 2.05996
Epoch 79, Val Loss: 2.07319
Epoch 80, Val Loss: 2.06142
Epoch 81, Val Loss: 2.06283
Epoch 82, Val Loss: 2.04502
Epoch 83, Val Loss: 2.04213
Epoch 84, Val Loss: 2.04824
Epoch 85, Val Loss: 2.03858
Epoch 86, Val Loss: 2.02810
Epoch 87, Val Loss: 2.03470
Epoch 88, Val Loss: 2.03917
Epoch 89, Val Loss: 2.03171
Epoch 90, Val Loss: 2.02509
Epoch 91, Val Loss: 2.03544
Epoch 92, Val Loss: 2.03673
Epoch 93, Val Loss: 2.03505
Epoch 94, Val Loss: 2.02420
Epoch 95, Val Loss: 2.02895
Epoch 96, Val Loss: 2.05375
Epoch 97, Val Loss: 2.03602
Epoch 98, Val Loss: 2.02132
Epoch 99, Val Loss: 2.03549
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.849, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}
Fitted encoder
Epoch 0, Val Loss: 1.97076
Epoch 1, Val Loss: 1.95573
Epoch 2, Val Loss: 1.98223
Epoch 3, Val Loss: 1.94154
Epoch 4, Val Loss: 1.92431
Epoch 5, Val Loss: 1.95848
Epoch 6, Val Loss: 1.93337
Epoch 7, Val Loss: 1.92087
Epoch 8, Val Loss: 1.94352
Epoch 9, Val Loss: 1.94685
Epoch 10, Val Loss: 1.91526
Epoch 11, Val Loss: 1.91038
Epoch 12, Val Loss: 1.91531
Epoch 13, Val Loss: 1.91943
Epoch 14, Val Loss: 1.93095
Epoch 15, Val Loss: 1.93196
Epoch 16, Val Loss: 1.91401
Epoch 17, Val Loss: 1.92063
Epoch 18, Val Loss: 1.91845
Epoch 19, Val Loss: 1.92105
Epoch 20, Val Loss: 1.92367
Epoch 21, Val Loss: 1.91008
Epoch 22, Val Loss: 1.93319
Epoch 23, Val Loss: 1.92314
Epoch 24, Val Loss: 1.90252
Epoch 25, Val Loss: 1.91679
Epoch 26, Val Loss: 1.90219
Epoch 27, Val Loss: 1.90397
Epoch 28, Val Loss: 1.93751
Epoch 29, Val Loss: 1.95559
Epoch 30, Val Loss: 1.91877
Epoch 31, Val Loss: 1.92466
Epoch 32, Val Loss: 1.91961
Epoch 33, Val Loss: 1.93058
Epoch 34, Val Loss: 1.94252
Epoch 35, Val Loss: 1.92100
Epoch 36, Val Loss: 1.90893
Epoch 37, Val Loss: 1.91351
Epoch 38, Val Loss: 1.91351
Epoch 39, Val Loss: 1.91917
Epoch 40, Val Loss: 1.92160
Epoch 41, Val Loss: 1.92344
Epoch 42, Val Loss: 1.90979
Epoch 43, Val Loss: 1.90597
Epoch 44, Val Loss: 1.94268
Epoch 45, Val Loss: 1.91094
Epoch 46, Val Loss: 1.90594
Epoch 47, Val Loss: 1.90364
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.0993000000000004, 'Log Loss - std': 0.25029999999999997} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}
Fitted encoder
Epoch 0, Val Loss: 2.13012
Epoch 1, Val Loss: 2.12223
Epoch 2, Val Loss: 2.12233
Epoch 3, Val Loss: 2.11704
Epoch 4, Val Loss: 2.11143
Epoch 5, Val Loss: 2.10751
Epoch 6, Val Loss: 2.11129
Epoch 7, Val Loss: 2.12123
Epoch 8, Val Loss: 2.12245
Epoch 9, Val Loss: 2.11383
Epoch 10, Val Loss: 2.10950
Epoch 11, Val Loss: 2.10897
Epoch 12, Val Loss: 2.10994
Epoch 13, Val Loss: 2.11283
Epoch 14, Val Loss: 2.11512
Epoch 15, Val Loss: 2.11528
Epoch 16, Val Loss: 2.11708
Epoch 17, Val Loss: 2.11074
Epoch 18, Val Loss: 2.11447
Epoch 19, Val Loss: 2.10992
Epoch 20, Val Loss: 2.11077
Epoch 21, Val Loss: 2.11391
Epoch 22, Val Loss: 2.10291
Epoch 23, Val Loss: 2.13774
Epoch 24, Val Loss: 2.11966
Epoch 25, Val Loss: 2.10739
Epoch 26, Val Loss: 2.11019
Epoch 27, Val Loss: 2.10911
Epoch 28, Val Loss: 2.10268
Epoch 29, Val Loss: 2.11711
Epoch 30, Val Loss: 2.11223
Epoch 31, Val Loss: 2.10952
Epoch 32, Val Loss: 2.11310
Epoch 33, Val Loss: 2.10746
Epoch 34, Val Loss: 2.11202
Epoch 35, Val Loss: 2.10645
Epoch 36, Val Loss: 2.10859
Epoch 37, Val Loss: 2.10746
Epoch 38, Val Loss: 2.10810
Epoch 39, Val Loss: 2.11041
Epoch 40, Val Loss: 2.11030
Epoch 41, Val Loss: 2.10397
Epoch 42, Val Loss: 2.10877
Epoch 43, Val Loss: 2.10522
Epoch 44, Val Loss: 2.11182
Epoch 45, Val Loss: 2.10973
Epoch 46, Val Loss: 2.10587
Epoch 47, Val Loss: 2.11016
Epoch 48, Val Loss: 2.10643
Epoch 49, Val Loss: 2.10676
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.0619666666666667, 'Log Loss - std': 0.2110788530910243} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}
Fitted encoder
Epoch 0, Val Loss: 2.07855
Epoch 1, Val Loss: 2.08085
Epoch 2, Val Loss: 2.07410
Epoch 3, Val Loss: 2.07327
Epoch 4, Val Loss: 2.06895
Epoch 5, Val Loss: 2.07625
Epoch 6, Val Loss: 2.06575
Epoch 7, Val Loss: 2.06013
Epoch 8, Val Loss: 2.07934
Epoch 9, Val Loss: 2.06757
Epoch 10, Val Loss: 2.05930
Epoch 11, Val Loss: 2.06217
Epoch 12, Val Loss: 2.05664
Epoch 13, Val Loss: 2.06672
Epoch 14, Val Loss: 2.06250
Epoch 15, Val Loss: 2.06592
Epoch 16, Val Loss: 2.06734
Epoch 17, Val Loss: 2.06115
Epoch 18, Val Loss: 2.06267
Epoch 19, Val Loss: 2.06082
Epoch 20, Val Loss: 2.05697
Epoch 21, Val Loss: 2.06144
Epoch 22, Val Loss: 2.06226
Epoch 23, Val Loss: 2.05613
Epoch 24, Val Loss: 2.06014
Epoch 25, Val Loss: 2.06357
Epoch 26, Val Loss: 2.06207
Epoch 27, Val Loss: 2.06158
Epoch 28, Val Loss: 2.05613
Epoch 29, Val Loss: 2.06645
Epoch 30, Val Loss: 2.05712
Epoch 31, Val Loss: 2.06099
Epoch 32, Val Loss: 2.05505
Epoch 33, Val Loss: 2.07463
Epoch 34, Val Loss: 2.06682
Epoch 35, Val Loss: 2.06080
Epoch 36, Val Loss: 2.06550
Epoch 37, Val Loss: 2.06745
Epoch 38, Val Loss: 2.05825
Epoch 39, Val Loss: 2.05269
Epoch 40, Val Loss: 2.05043
Epoch 41, Val Loss: 2.08212
Epoch 42, Val Loss: 2.06829
Epoch 43, Val Loss: 2.05260
Epoch 44, Val Loss: 2.05420
Epoch 45, Val Loss: 2.05058
Epoch 46, Val Loss: 2.05538
Epoch 47, Val Loss: 2.07869
Epoch 48, Val Loss: 2.07287
Epoch 49, Val Loss: 2.06766
Epoch 50, Val Loss: 2.05146
Epoch 51, Val Loss: 2.05153
Epoch 52, Val Loss: 2.05358
Epoch 53, Val Loss: 2.04597
Epoch 54, Val Loss: 2.06112
Epoch 55, Val Loss: 2.05061
Epoch 56, Val Loss: 2.05078
Epoch 57, Val Loss: 2.05001
Epoch 58, Val Loss: 2.05681
Epoch 59, Val Loss: 2.05233
Epoch 60, Val Loss: 2.05950
Epoch 61, Val Loss: 2.03489
Epoch 62, Val Loss: 2.03761
Epoch 63, Val Loss: 2.04979
Epoch 64, Val Loss: 2.05156
Epoch 65, Val Loss: 2.02842
Epoch 66, Val Loss: 2.03931
Epoch 67, Val Loss: 2.03148
Epoch 68, Val Loss: 2.02974
Epoch 69, Val Loss: 2.04502
Epoch 70, Val Loss: 2.03744
Epoch 71, Val Loss: 2.04611
Epoch 72, Val Loss: 2.03770
Epoch 73, Val Loss: 2.02894
Epoch 74, Val Loss: 2.03055
Epoch 75, Val Loss: 2.03113
Epoch 76, Val Loss: 2.03790
Epoch 77, Val Loss: 2.02805
Epoch 78, Val Loss: 2.04606
Epoch 79, Val Loss: 2.03628
Epoch 80, Val Loss: 2.03349
Epoch 81, Val Loss: 2.03867
Epoch 82, Val Loss: 2.04364
Epoch 83, Val Loss: 2.03509
Epoch 84, Val Loss: 2.04975
Epoch 85, Val Loss: 2.04126
Epoch 86, Val Loss: 2.03498
Epoch 87, Val Loss: 2.02185
Epoch 88, Val Loss: 2.01616
Epoch 89, Val Loss: 2.02029
Epoch 90, Val Loss: 2.02974
Epoch 91, Val Loss: 2.04000
Epoch 92, Val Loss: 2.05642
Epoch 93, Val Loss: 2.03404
Epoch 94, Val Loss: 2.01729
Epoch 95, Val Loss: 2.02807
Epoch 96, Val Loss: 2.04795
Epoch 97, Val Loss: 2.02172
Epoch 98, Val Loss: 2.02442
Epoch 99, Val Loss: 2.02225
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.9138, 'Log Loss - std': 0.31508061666817905} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}
Fitted encoder
Epoch 0, Val Loss: 1.97704
Epoch 1, Val Loss: 1.98029
Epoch 2, Val Loss: 1.96202
Epoch 3, Val Loss: 1.95117
Epoch 4, Val Loss: 1.95782
Epoch 5, Val Loss: 1.96883
Epoch 6, Val Loss: 1.96091
Epoch 7, Val Loss: 1.95073
Epoch 8, Val Loss: 1.95307
Epoch 9, Val Loss: 1.96771
Epoch 10, Val Loss: 1.95179
Epoch 11, Val Loss: 1.96606
Epoch 12, Val Loss: 1.94702
Epoch 13, Val Loss: 1.94327
Epoch 14, Val Loss: 1.97073
Epoch 15, Val Loss: 1.95897
Epoch 16, Val Loss: 1.96106
Epoch 17, Val Loss: 1.94939
Epoch 18, Val Loss: 1.94880
Epoch 19, Val Loss: 1.95874
Epoch 20, Val Loss: 1.96771
Epoch 21, Val Loss: 1.96032
Epoch 22, Val Loss: 1.94217
Epoch 23, Val Loss: 1.95348
Epoch 24, Val Loss: 1.94770
Epoch 25, Val Loss: 1.94351
Epoch 26, Val Loss: 1.94791
Epoch 27, Val Loss: 1.95406
Epoch 28, Val Loss: 1.94495
Epoch 29, Val Loss: 1.94849
Epoch 30, Val Loss: 1.94266
Epoch 31, Val Loss: 1.94229
Epoch 32, Val Loss: 1.95307
Epoch 33, Val Loss: 1.94834
Epoch 34, Val Loss: 1.93675
Epoch 35, Val Loss: 1.94077
Epoch 36, Val Loss: 1.93575
Epoch 37, Val Loss: 1.94560
Epoch 38, Val Loss: 1.95571
Epoch 39, Val Loss: 1.94200
Epoch 40, Val Loss: 1.95140
Epoch 41, Val Loss: 1.94822
Epoch 42, Val Loss: 1.93387
Epoch 43, Val Loss: 1.92470
Epoch 44, Val Loss: 1.94010
Epoch 45, Val Loss: 1.91607
Epoch 46, Val Loss: 1.92370
Epoch 47, Val Loss: 1.90912
Epoch 48, Val Loss: 1.95177
Epoch 49, Val Loss: 1.94735
Epoch 50, Val Loss: 1.93769
Epoch 51, Val Loss: 1.91335
Epoch 52, Val Loss: 1.92863
Epoch 53, Val Loss: 1.91098
Epoch 54, Val Loss: 1.93237
Epoch 55, Val Loss: 1.91636
Epoch 56, Val Loss: 1.92304
Epoch 57, Val Loss: 1.96879
Epoch 58, Val Loss: 1.92708
Epoch 59, Val Loss: 1.93227
Epoch 60, Val Loss: 1.92321
Epoch 61, Val Loss: 1.93945
Epoch 62, Val Loss: 1.91795
Epoch 63, Val Loss: 1.92508
Epoch 64, Val Loss: 1.96315
Epoch 65, Val Loss: 1.91631
Epoch 66, Val Loss: 1.92615
Epoch 67, Val Loss: 1.94012
Epoch 68, Val Loss: 1.92549
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.9069000000000003, 'Log Loss - std': 0.28215434783111176} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 38 finished with value: 2.9069000000000003 and parameters: {'p_m': 0.6319912784220072, 'alpha': 7.949278786213787, 'K': 3, 'beta': 4.472511371028818}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}
Fitted encoder
Epoch 0, Val Loss: 2.14207
Epoch 1, Val Loss: 2.12658
Epoch 2, Val Loss: 2.13316
Epoch 3, Val Loss: 2.10758
Epoch 4, Val Loss: 2.15012
Epoch 5, Val Loss: 2.10986
Epoch 6, Val Loss: 2.13204
Epoch 7, Val Loss: 2.11547
Epoch 8, Val Loss: 2.09781
Epoch 9, Val Loss: 2.09954
Epoch 10, Val Loss: 2.09495
Epoch 11, Val Loss: 2.10764
Epoch 12, Val Loss: 2.09593
Epoch 13, Val Loss: 2.10571
Epoch 14, Val Loss: 2.09093
Epoch 15, Val Loss: 2.12512
Epoch 16, Val Loss: 2.11192
Epoch 17, Val Loss: 2.11516
Epoch 18, Val Loss: 2.08522
Epoch 19, Val Loss: 2.14257
Epoch 20, Val Loss: 2.10831
Epoch 21, Val Loss: 2.09066
Epoch 22, Val Loss: 2.08753
Epoch 23, Val Loss: 2.08996
Epoch 24, Val Loss: 2.07757
Epoch 25, Val Loss: 2.08431
Epoch 26, Val Loss: 2.07900
Epoch 27, Val Loss: 2.07761
Epoch 28, Val Loss: 2.09007
Epoch 29, Val Loss: 2.08068
Epoch 30, Val Loss: 2.07600
Epoch 31, Val Loss: 2.08869
Epoch 32, Val Loss: 2.10466
Epoch 33, Val Loss: 2.09560
Epoch 34, Val Loss: 2.09227
Epoch 35, Val Loss: 2.08401
Epoch 36, Val Loss: 2.07208
Epoch 37, Val Loss: 2.06450
Epoch 38, Val Loss: 2.06221
Epoch 39, Val Loss: 2.06002
Epoch 40, Val Loss: 2.05009
Epoch 41, Val Loss: 2.04823
Epoch 42, Val Loss: 2.09557
Epoch 43, Val Loss: 2.06978
Epoch 44, Val Loss: 2.06284
Epoch 45, Val Loss: 2.09664
Epoch 46, Val Loss: 2.09615
Epoch 47, Val Loss: 2.09428
Epoch 48, Val Loss: 2.08209
Epoch 49, Val Loss: 2.07188
Epoch 50, Val Loss: 2.08801
Epoch 51, Val Loss: 2.08148
Epoch 52, Val Loss: 2.09861
Epoch 53, Val Loss: 2.03903
Epoch 54, Val Loss: 2.06450
Epoch 55, Val Loss: 2.07184
Epoch 56, Val Loss: 2.07909
Epoch 57, Val Loss: 2.08469
Epoch 58, Val Loss: 2.04786
Epoch 59, Val Loss: 2.07788
Epoch 60, Val Loss: 2.05666
Epoch 61, Val Loss: 2.04991
Epoch 62, Val Loss: 2.05133
Epoch 63, Val Loss: 2.05321
Epoch 64, Val Loss: 2.06615
Epoch 65, Val Loss: 2.05085
Epoch 66, Val Loss: 2.06053
Epoch 67, Val Loss: 2.03570
Epoch 68, Val Loss: 2.07143
Epoch 69, Val Loss: 2.04290
Epoch 70, Val Loss: 2.06165
Epoch 71, Val Loss: 2.06993
Epoch 72, Val Loss: 2.07936
Epoch 73, Val Loss: 2.04138
Epoch 74, Val Loss: 2.05864
Epoch 75, Val Loss: 2.06901
Epoch 76, Val Loss: 2.04652
Epoch 77, Val Loss: 2.04789
Epoch 78, Val Loss: 2.04660
Epoch 79, Val Loss: 2.08325
Epoch 80, Val Loss: 2.06832
Epoch 81, Val Loss: 2.04649
Epoch 82, Val Loss: 2.05201
Epoch 83, Val Loss: 2.07920
Epoch 84, Val Loss: 2.07563
Epoch 85, Val Loss: 2.07670
Epoch 86, Val Loss: 2.05393
Epoch 87, Val Loss: 2.06458
Epoch 88, Val Loss: 2.06127
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.7616, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}
Fitted encoder
Epoch 0, Val Loss: 1.95438
Epoch 1, Val Loss: 1.94740
Epoch 2, Val Loss: 1.93250
Epoch 3, Val Loss: 1.96979
Epoch 4, Val Loss: 1.91975
Epoch 5, Val Loss: 1.92206
Epoch 6, Val Loss: 1.91636
Epoch 7, Val Loss: 1.93075
Epoch 8, Val Loss: 1.95399
Epoch 9, Val Loss: 1.93175
Epoch 10, Val Loss: 1.90846
Epoch 11, Val Loss: 1.92488
Epoch 12, Val Loss: 1.90478
Epoch 13, Val Loss: 1.91171
Epoch 14, Val Loss: 1.93291
Epoch 15, Val Loss: 1.94757
Epoch 16, Val Loss: 1.92655
Epoch 17, Val Loss: 1.91416
Epoch 18, Val Loss: 1.93123
Epoch 19, Val Loss: 1.92549
Epoch 20, Val Loss: 1.94903
Epoch 21, Val Loss: 1.91525
Epoch 22, Val Loss: 1.92264
Epoch 23, Val Loss: 1.90291
Epoch 24, Val Loss: 1.90804
Epoch 25, Val Loss: 1.90350
Epoch 26, Val Loss: 1.92254
Epoch 27, Val Loss: 1.91025
Epoch 28, Val Loss: 1.91174
Epoch 29, Val Loss: 1.92386
Epoch 30, Val Loss: 1.89071
Epoch 31, Val Loss: 1.91174
Epoch 32, Val Loss: 1.91431
Epoch 33, Val Loss: 1.92099
Epoch 34, Val Loss: 1.91953
Epoch 35, Val Loss: 1.91881
Epoch 36, Val Loss: 1.90795
Epoch 37, Val Loss: 1.90248
Epoch 38, Val Loss: 1.91279
Epoch 39, Val Loss: 1.89375
Epoch 40, Val Loss: 1.89856
Epoch 41, Val Loss: 1.90653
Epoch 42, Val Loss: 1.89526
Epoch 43, Val Loss: 1.89773
Epoch 44, Val Loss: 1.90057
Epoch 45, Val Loss: 1.89810
Epoch 46, Val Loss: 1.91727
Epoch 47, Val Loss: 1.90113
Epoch 48, Val Loss: 1.90366
Epoch 49, Val Loss: 1.88988
Epoch 50, Val Loss: 1.90261
Epoch 51, Val Loss: 1.91698
Epoch 52, Val Loss: 1.90056
Epoch 53, Val Loss: 1.91952
Epoch 54, Val Loss: 1.90352
Epoch 55, Val Loss: 1.89999
Epoch 56, Val Loss: 1.92586
Epoch 57, Val Loss: 1.90654
Epoch 58, Val Loss: 1.90260
Epoch 59, Val Loss: 1.90423
Epoch 60, Val Loss: 1.89567
Epoch 61, Val Loss: 1.90903
Epoch 62, Val Loss: 1.90685
Epoch 63, Val Loss: 1.90903
Epoch 64, Val Loss: 1.89906
Epoch 65, Val Loss: 1.90363
Epoch 66, Val Loss: 1.90854
Epoch 67, Val Loss: 1.91056
Epoch 68, Val Loss: 1.91756
Epoch 69, Val Loss: 1.91170
Epoch 70, Val Loss: 1.89222
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.91205, 'Log Loss - std': 0.15044999999999997} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}
Fitted encoder
Epoch 0, Val Loss: 2.14939
Epoch 1, Val Loss: 2.13979
Epoch 2, Val Loss: 2.11595
Epoch 3, Val Loss: 2.11999
Epoch 4, Val Loss: 2.12316
Epoch 5, Val Loss: 2.14195
Epoch 6, Val Loss: 2.11321
Epoch 7, Val Loss: 2.13295
Epoch 8, Val Loss: 2.11865
Epoch 9, Val Loss: 2.11230
Epoch 10, Val Loss: 2.11028
Epoch 11, Val Loss: 2.11837
Epoch 12, Val Loss: 2.11188
Epoch 13, Val Loss: 2.15021
Epoch 14, Val Loss: 2.13780
Epoch 15, Val Loss: 2.11426
Epoch 16, Val Loss: 2.11270
Epoch 17, Val Loss: 2.10969
Epoch 18, Val Loss: 2.13785
Epoch 19, Val Loss: 2.13992
Epoch 20, Val Loss: 2.13513
Epoch 21, Val Loss: 2.13906
Epoch 22, Val Loss: 2.14493
Epoch 23, Val Loss: 2.13542
Epoch 24, Val Loss: 2.14231
Epoch 25, Val Loss: 2.13544
Epoch 26, Val Loss: 2.11835
Epoch 27, Val Loss: 2.13196
Epoch 28, Val Loss: 2.12148
Epoch 29, Val Loss: 2.14509
Epoch 30, Val Loss: 2.12920
Epoch 31, Val Loss: 2.12670
Epoch 32, Val Loss: 2.13453
Epoch 33, Val Loss: 2.12906
Epoch 34, Val Loss: 2.12997
Epoch 35, Val Loss: 2.12499
Epoch 36, Val Loss: 2.14119
Epoch 37, Val Loss: 2.13310
Epoch 38, Val Loss: 2.13391
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.9652999999999996, 'Log Loss - std': 0.14408768163864658} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}
Fitted encoder
Epoch 0, Val Loss: 2.07574
Epoch 1, Val Loss: 2.08056
Epoch 2, Val Loss: 2.11604
Epoch 3, Val Loss: 2.12946
Epoch 4, Val Loss: 2.12241
Epoch 5, Val Loss: 2.11682
Epoch 6, Val Loss: 2.11312
Epoch 7, Val Loss: 2.11232
Epoch 8, Val Loss: 2.12146
Epoch 9, Val Loss: 2.11985
Epoch 10, Val Loss: 2.13084
Epoch 11, Val Loss: 2.05474
Epoch 12, Val Loss: 2.12241
Epoch 13, Val Loss: 2.06137
Epoch 14, Val Loss: 2.06115
Epoch 15, Val Loss: 2.05239
Epoch 16, Val Loss: 2.05605
Epoch 17, Val Loss: 2.07207
Epoch 18, Val Loss: 2.06468
Epoch 19, Val Loss: 2.06702
Epoch 20, Val Loss: 2.05739
Epoch 21, Val Loss: 2.07575
Epoch 22, Val Loss: 2.10292
Epoch 23, Val Loss: 2.09430
Epoch 24, Val Loss: 2.06419
Epoch 25, Val Loss: 2.04447
Epoch 26, Val Loss: 2.02939
Epoch 27, Val Loss: 2.04118
Epoch 28, Val Loss: 2.05282
Epoch 29, Val Loss: 2.03954
Epoch 30, Val Loss: 2.04434
Epoch 31, Val Loss: 2.05356
Epoch 32, Val Loss: 2.04329
Epoch 33, Val Loss: 2.02459
Epoch 34, Val Loss: 2.06409
Epoch 35, Val Loss: 2.04947
Epoch 36, Val Loss: 2.05316
Epoch 37, Val Loss: 2.04016
Epoch 38, Val Loss: 2.07246
Epoch 39, Val Loss: 2.05350
Epoch 40, Val Loss: 2.04899
Epoch 41, Val Loss: 2.04254
Epoch 42, Val Loss: 2.08472
Epoch 43, Val Loss: 2.05681
Epoch 44, Val Loss: 2.07214
Epoch 45, Val Loss: 2.07153
Epoch 46, Val Loss: 2.05649
Epoch 47, Val Loss: 2.04713
Epoch 48, Val Loss: 2.07487
Epoch 49, Val Loss: 2.06447
Epoch 50, Val Loss: 2.06968
Epoch 51, Val Loss: 2.07856
Epoch 52, Val Loss: 2.07845
Epoch 53, Val Loss: 2.07964
Epoch 54, Val Loss: 2.07373
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.682175, 'Log Loss - std': 0.5060140728033162} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}
Fitted encoder
Epoch 0, Val Loss: 1.95530
Epoch 1, Val Loss: 1.95678
Epoch 2, Val Loss: 1.95867
Epoch 3, Val Loss: 1.97447
Epoch 4, Val Loss: 1.97548
Epoch 5, Val Loss: 2.01703
Epoch 6, Val Loss: 1.95487
Epoch 7, Val Loss: 1.93059
Epoch 8, Val Loss: 1.91527
Epoch 9, Val Loss: 1.95179
Epoch 10, Val Loss: 1.94509
Epoch 11, Val Loss: 1.97237
Epoch 12, Val Loss: 1.95578
Epoch 13, Val Loss: 1.91592
Epoch 14, Val Loss: 1.91717
Epoch 15, Val Loss: 1.90214
Epoch 16, Val Loss: 1.92237
Epoch 17, Val Loss: 1.90074
Epoch 18, Val Loss: 1.90115
Epoch 19, Val Loss: 1.92036
Epoch 20, Val Loss: 1.89610
Epoch 21, Val Loss: 1.89741
Epoch 22, Val Loss: 1.87876
Epoch 23, Val Loss: 1.91727
Epoch 24, Val Loss: 1.88239
Epoch 25, Val Loss: 1.93420
Epoch 26, Val Loss: 1.91515
Epoch 27, Val Loss: 1.91920
Epoch 28, Val Loss: 1.89578
Epoch 29, Val Loss: 1.90894
Epoch 30, Val Loss: 1.88393
Epoch 31, Val Loss: 1.90460
Epoch 32, Val Loss: 1.89269
Epoch 33, Val Loss: 1.90422
Epoch 34, Val Loss: 1.88229
Epoch 35, Val Loss: 1.91804
Epoch 36, Val Loss: 1.90967
Epoch 37, Val Loss: 1.89870
Epoch 38, Val Loss: 1.99566
Epoch 39, Val Loss: 1.96166
Epoch 40, Val Loss: 1.86923
Epoch 41, Val Loss: 1.90804
Epoch 42, Val Loss: 1.88970
Epoch 43, Val Loss: 1.89192
Epoch 44, Val Loss: 1.89931
Epoch 45, Val Loss: 1.89457
Epoch 46, Val Loss: 1.89737
Epoch 47, Val Loss: 1.92150
Epoch 48, Val Loss: 1.88533
Epoch 49, Val Loss: 1.89086
Epoch 50, Val Loss: 1.87642
Epoch 51, Val Loss: 1.90903
Epoch 52, Val Loss: 1.89998
Epoch 53, Val Loss: 1.89569
Epoch 54, Val Loss: 1.92686
Epoch 55, Val Loss: 1.91327
Epoch 56, Val Loss: 1.90300
Epoch 57, Val Loss: 1.90798
Epoch 58, Val Loss: 1.92079
Epoch 59, Val Loss: 1.88389
Epoch 60, Val Loss: 1.98675
Epoch 61, Val Loss: 1.99295
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.6361800000000004, 'Log Loss - std': 0.4618466775890024} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 39 finished with value: 3.6361800000000004 and parameters: {'p_m': 0.8378891513311865, 'alpha': 2.252414945451231, 'K': 2, 'beta': 1.9554840383634526}. Best is trial 18 with value: 4.07674.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}
Fitted encoder
Epoch 0, Val Loss: 2.22640
Epoch 1, Val Loss: 2.22640
Epoch 2, Val Loss: 2.22640
Epoch 3, Val Loss: 2.22640
Epoch 4, Val Loss: 2.22640
Epoch 5, Val Loss: 2.22640
Epoch 6, Val Loss: 2.22640
Epoch 7, Val Loss: 2.22640
Epoch 8, Val Loss: 2.22640
Epoch 9, Val Loss: 2.22640
Epoch 10, Val Loss: 2.22640
Epoch 11, Val Loss: 2.22640
Epoch 12, Val Loss: 2.22640
Epoch 13, Val Loss: 2.22640
Epoch 14, Val Loss: 2.22640
Epoch 15, Val Loss: 2.22640
Epoch 16, Val Loss: 2.22640
Epoch 17, Val Loss: 2.22640
Epoch 18, Val Loss: 2.22640
Epoch 19, Val Loss: 2.22640
Epoch 20, Val Loss: 2.22640
Epoch 21, Val Loss: 2.22640
Epoch 22, Val Loss: 2.22640
Epoch 23, Val Loss: 2.22640
Epoch 24, Val Loss: 2.22640
Epoch 25, Val Loss: 2.22640
Epoch 26, Val Loss: 2.22640
Epoch 27, Val Loss: 2.22640
Epoch 28, Val Loss: 2.22640
Epoch 29, Val Loss: 2.22640
Epoch 30, Val Loss: 2.22640
Epoch 31, Val Loss: 2.22640
Epoch 32, Val Loss: 2.22640
Epoch 33, Val Loss: 2.22640
Epoch 34, Val Loss: 2.22640
Epoch 35, Val Loss: 2.22640
Epoch 36, Val Loss: 2.22640
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 9.7777, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}
Fitted encoder
Epoch 0, Val Loss: 1.97652
Epoch 1, Val Loss: 2.00146
Epoch 2, Val Loss: 1.94753
Epoch 3, Val Loss: 1.95183
Epoch 4, Val Loss: 1.95069
Epoch 5, Val Loss: 1.94734
Epoch 6, Val Loss: 1.94605
Epoch 7, Val Loss: 1.93911
Epoch 8, Val Loss: 1.94682
Epoch 9, Val Loss: 1.93882
Epoch 10, Val Loss: 1.94394
Epoch 11, Val Loss: 1.93334
Epoch 12, Val Loss: 1.95630
Epoch 13, Val Loss: 1.92620
Epoch 14, Val Loss: 1.95084
Epoch 15, Val Loss: 1.92393
Epoch 16, Val Loss: 1.92110
Epoch 17, Val Loss: 1.92433
Epoch 18, Val Loss: 1.93911
Epoch 19, Val Loss: 1.93092
Epoch 20, Val Loss: 1.92181
Epoch 21, Val Loss: 1.92531
Epoch 22, Val Loss: 1.91877
Epoch 23, Val Loss: 1.92878
Epoch 24, Val Loss: 1.91598
Epoch 25, Val Loss: 1.92045
Epoch 26, Val Loss: 1.92280
Epoch 27, Val Loss: 1.90510
Epoch 28, Val Loss: 1.92164
Epoch 29, Val Loss: 1.91481
Epoch 30, Val Loss: 1.91714
Epoch 31, Val Loss: 1.91893
Epoch 32, Val Loss: 1.91526
Epoch 33, Val Loss: 1.91074
Epoch 34, Val Loss: 1.90556
Epoch 35, Val Loss: 1.92900
Epoch 36, Val Loss: 1.91446
Epoch 37, Val Loss: 1.90560
Epoch 38, Val Loss: 1.90843
Epoch 39, Val Loss: 1.91415
Epoch 40, Val Loss: 1.90646
Epoch 41, Val Loss: 1.92756
Epoch 42, Val Loss: 1.90804
Epoch 43, Val Loss: 1.90716
Epoch 44, Val Loss: 1.91673
Epoch 45, Val Loss: 1.90264
Epoch 46, Val Loss: 1.91337
Epoch 47, Val Loss: 1.89494
Epoch 48, Val Loss: 1.90547
Epoch 49, Val Loss: 1.90790
Epoch 50, Val Loss: 1.90353
Epoch 51, Val Loss: 1.90968
Epoch 52, Val Loss: 1.91510
Epoch 53, Val Loss: 1.91021
Epoch 54, Val Loss: 1.89281
Epoch 55, Val Loss: 1.90156
Epoch 56, Val Loss: 1.89856
Epoch 57, Val Loss: 1.91471
Epoch 58, Val Loss: 1.89826
Epoch 59, Val Loss: 1.89620
Epoch 60, Val Loss: 1.90414
Epoch 61, Val Loss: 1.90628
Epoch 62, Val Loss: 1.90352
Epoch 63, Val Loss: 1.91530
Epoch 64, Val Loss: 1.90074
Epoch 65, Val Loss: 1.91195
Epoch 66, Val Loss: 1.90555
Epoch 67, Val Loss: 1.91254
Epoch 68, Val Loss: 1.90460
Epoch 69, Val Loss: 1.89990
Epoch 70, Val Loss: 1.89422
Epoch 71, Val Loss: 1.90888
Epoch 72, Val Loss: 1.93442
Epoch 73, Val Loss: 1.90446
Epoch 74, Val Loss: 1.90341
Epoch 75, Val Loss: 1.90576
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 6.35135, 'Log Loss - std': 3.42635} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}
Fitted encoder
Epoch 0, Val Loss: 2.14749
Epoch 1, Val Loss: 2.12786
Epoch 2, Val Loss: 2.12930
Epoch 3, Val Loss: 2.11841
Epoch 4, Val Loss: 2.11289
Epoch 5, Val Loss: 2.12125
Epoch 6, Val Loss: 2.11300
Epoch 7, Val Loss: 2.12230
Epoch 8, Val Loss: 2.11026
Epoch 9, Val Loss: 2.11064
Epoch 10, Val Loss: 2.11129
Epoch 11, Val Loss: 2.10624
Epoch 12, Val Loss: 2.11479
Epoch 13, Val Loss: 2.11014
Epoch 14, Val Loss: 2.11243
Epoch 15, Val Loss: 2.10340
Epoch 16, Val Loss: 2.10337
Epoch 17, Val Loss: 2.10244
Epoch 18, Val Loss: 2.11465
Epoch 19, Val Loss: 2.10395
Epoch 20, Val Loss: 2.10052
Epoch 21, Val Loss: 2.09872
Epoch 22, Val Loss: 2.10447
Epoch 23, Val Loss: 2.10611
Epoch 24, Val Loss: 2.10791
Epoch 25, Val Loss: 2.10339
Epoch 26, Val Loss: 2.10534
Epoch 27, Val Loss: 2.10132
Epoch 28, Val Loss: 2.10454
Epoch 29, Val Loss: 2.10355
Epoch 30, Val Loss: 2.10359
Epoch 31, Val Loss: 2.08613
Epoch 32, Val Loss: 2.09050
Epoch 33, Val Loss: 2.10292
Epoch 34, Val Loss: 2.09690
Epoch 35, Val Loss: 2.10161
Epoch 36, Val Loss: 2.08553
Epoch 37, Val Loss: 2.09048
Epoch 38, Val Loss: 2.08910
Epoch 39, Val Loss: 2.07793
Epoch 40, Val Loss: 2.08111
Epoch 41, Val Loss: 2.09568
Epoch 42, Val Loss: 2.09576
Epoch 43, Val Loss: 2.09333
Epoch 44, Val Loss: 2.07530
Epoch 45, Val Loss: 2.08294
Epoch 46, Val Loss: 2.08231
Epoch 47, Val Loss: 2.08155
Epoch 48, Val Loss: 2.08738
Epoch 49, Val Loss: 2.07917
Epoch 50, Val Loss: 2.07428
Epoch 51, Val Loss: 2.08766
Epoch 52, Val Loss: 2.07160
Epoch 53, Val Loss: 2.08139
Epoch 54, Val Loss: 2.10684
Epoch 55, Val Loss: 2.07334
Epoch 56, Val Loss: 2.08816
Epoch 57, Val Loss: 2.10504
Epoch 58, Val Loss: 2.08293
Epoch 59, Val Loss: 2.08331
Epoch 60, Val Loss: 2.07799
Epoch 61, Val Loss: 2.07370
Epoch 62, Val Loss: 2.08030
Epoch 63, Val Loss: 2.09276
Epoch 64, Val Loss: 2.07034
Epoch 65, Val Loss: 2.07155
Epoch 66, Val Loss: 2.07108
Epoch 67, Val Loss: 2.07706
Epoch 68, Val Loss: 2.07207
Epoch 69, Val Loss: 2.07351
Epoch 70, Val Loss: 2.09086
Epoch 71, Val Loss: 2.07919
Epoch 72, Val Loss: 2.07485
Epoch 73, Val Loss: 2.09388
Epoch 74, Val Loss: 2.08302
Epoch 75, Val Loss: 2.07222
Epoch 76, Val Loss: 2.08213
Epoch 77, Val Loss: 2.06924
Epoch 78, Val Loss: 2.07314
Epoch 79, Val Loss: 2.06757
Epoch 80, Val Loss: 2.07278
Epoch 81, Val Loss: 2.07003
Epoch 82, Val Loss: 2.09533
Epoch 83, Val Loss: 2.07690
Epoch 84, Val Loss: 2.07369
Epoch 85, Val Loss: 2.08908
Epoch 86, Val Loss: 2.07877
Epoch 87, Val Loss: 2.06540
Epoch 88, Val Loss: 2.10137
Epoch 89, Val Loss: 2.07812
Epoch 90, Val Loss: 2.07566
Epoch 91, Val Loss: 2.06864
Epoch 92, Val Loss: 2.06993
Epoch 93, Val Loss: 2.06747
Epoch 94, Val Loss: 2.09009
Epoch 95, Val Loss: 2.07383
Epoch 96, Val Loss: 2.06780
Epoch 97, Val Loss: 2.07421
Epoch 98, Val Loss: 2.06405
Epoch 99, Val Loss: 2.06833
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 5.232766666666667, 'Log Loss - std': 3.213882423003195} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}
Fitted encoder
Epoch 0, Val Loss: 2.09117
Epoch 1, Val Loss: 2.07352
Epoch 2, Val Loss: 2.06994
Epoch 3, Val Loss: 2.05781
Epoch 4, Val Loss: 2.07607
Epoch 5, Val Loss: 2.06199
Epoch 6, Val Loss: 2.05894
Epoch 7, Val Loss: 2.05602
Epoch 8, Val Loss: 2.06255
Epoch 9, Val Loss: 2.05963
Epoch 10, Val Loss: 2.05974
Epoch 11, Val Loss: 2.05448
Epoch 12, Val Loss: 2.05681
Epoch 13, Val Loss: 2.05212
Epoch 14, Val Loss: 2.04904
Epoch 15, Val Loss: 2.07738
Epoch 16, Val Loss: 2.06006
Epoch 17, Val Loss: 2.05393
Epoch 18, Val Loss: 2.05127
Epoch 19, Val Loss: 2.04857
Epoch 20, Val Loss: 2.03658
Epoch 21, Val Loss: 2.03711
Epoch 22, Val Loss: 2.06501
Epoch 23, Val Loss: 2.03185
Epoch 24, Val Loss: 2.03985
Epoch 25, Val Loss: 2.05274
Epoch 26, Val Loss: 2.03245
Epoch 27, Val Loss: 2.04726
Epoch 28, Val Loss: 2.02962
Epoch 29, Val Loss: 2.04593
Epoch 30, Val Loss: 2.05205
Epoch 31, Val Loss: 2.05700
Epoch 32, Val Loss: 2.02519
Epoch 33, Val Loss: 2.02436
Epoch 34, Val Loss: 2.04052
Epoch 35, Val Loss: 2.04193
Epoch 36, Val Loss: 2.03045
Epoch 37, Val Loss: 2.03351
Epoch 38, Val Loss: 2.01977
Epoch 39, Val Loss: 2.02041
Epoch 40, Val Loss: 2.03730
Epoch 41, Val Loss: 2.02565
Epoch 42, Val Loss: 2.03736
Epoch 43, Val Loss: 2.01892
Epoch 44, Val Loss: 2.02262
Epoch 45, Val Loss: 2.01544
Epoch 46, Val Loss: 2.02768
Epoch 47, Val Loss: 2.01863
Epoch 48, Val Loss: 2.02392
Epoch 49, Val Loss: 2.02294
Epoch 50, Val Loss: 2.01966
Epoch 51, Val Loss: 2.02956
Epoch 52, Val Loss: 2.01546
Epoch 53, Val Loss: 2.02921
Epoch 54, Val Loss: 2.02512
Epoch 55, Val Loss: 2.03188
Epoch 56, Val Loss: 2.02045
Epoch 57, Val Loss: 2.01772
Epoch 58, Val Loss: 2.01684
Epoch 59, Val Loss: 2.01644
Epoch 60, Val Loss: 2.05467
Epoch 61, Val Loss: 2.02094
Epoch 62, Val Loss: 2.02627
Epoch 63, Val Loss: 2.01482
Epoch 64, Val Loss: 2.01662
Epoch 65, Val Loss: 2.01761
Epoch 66, Val Loss: 2.04596
Epoch 67, Val Loss: 2.03733
Epoch 68, Val Loss: 2.03884
Epoch 69, Val Loss: 2.02279
Epoch 70, Val Loss: 2.01350
Epoch 71, Val Loss: 2.02752
Epoch 72, Val Loss: 2.02700
Epoch 73, Val Loss: 2.05369
Epoch 74, Val Loss: 2.01299
Epoch 75, Val Loss: 2.02189
Epoch 76, Val Loss: 2.01352
Epoch 77, Val Loss: 2.02035
Epoch 78, Val Loss: 2.01927
Epoch 79, Val Loss: 2.02045
Epoch 80, Val Loss: 2.01721
Epoch 81, Val Loss: 2.01590
Epoch 82, Val Loss: 2.04391
Epoch 83, Val Loss: 2.01887
Epoch 84, Val Loss: 2.02801
Epoch 85, Val Loss: 2.03722
Epoch 86, Val Loss: 2.03080
Epoch 87, Val Loss: 2.02610
Epoch 88, Val Loss: 2.02502
Epoch 89, Val Loss: 2.02424
Epoch 90, Val Loss: 2.01450
Epoch 91, Val Loss: 2.02157
Epoch 92, Val Loss: 2.02757
Epoch 93, Val Loss: 2.02504
Epoch 94, Val Loss: 2.01419
Epoch 95, Val Loss: 2.00761
Epoch 96, Val Loss: 2.01906
Epoch 97, Val Loss: 2.02629
Epoch 98, Val Loss: 2.00316
Epoch 99, Val Loss: 2.03775
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.5550999999999995, 'Log Loss - std': 3.0206748426469208} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}
Fitted encoder
Epoch 0, Val Loss: 1.96979
Epoch 1, Val Loss: 1.95022
Epoch 2, Val Loss: 1.96651
Epoch 3, Val Loss: 1.94645
Epoch 4, Val Loss: 1.94668
Epoch 5, Val Loss: 1.94986
Epoch 6, Val Loss: 1.94709
Epoch 7, Val Loss: 1.94544
Epoch 8, Val Loss: 1.93835
Epoch 9, Val Loss: 1.94213
Epoch 10, Val Loss: 1.94683
Epoch 11, Val Loss: 1.92699
Epoch 12, Val Loss: 1.92734
Epoch 13, Val Loss: 1.92876
Epoch 14, Val Loss: 1.95445
Epoch 15, Val Loss: 1.94253
Epoch 16, Val Loss: 1.93503
Epoch 17, Val Loss: 1.93499
Epoch 18, Val Loss: 1.95308
Epoch 19, Val Loss: 1.93043
Epoch 20, Val Loss: 1.93921
Epoch 21, Val Loss: 1.93489
Epoch 22, Val Loss: 1.92446
Epoch 23, Val Loss: 1.93933
Epoch 24, Val Loss: 1.95014
Epoch 25, Val Loss: 1.92116
Epoch 26, Val Loss: 1.93090
Epoch 27, Val Loss: 1.92282
Epoch 28, Val Loss: 1.93393
Epoch 29, Val Loss: 1.93043
Epoch 30, Val Loss: 1.91685
Epoch 31, Val Loss: 1.91691
Epoch 32, Val Loss: 1.92993
Epoch 33, Val Loss: 1.91996
Epoch 34, Val Loss: 1.92702
Epoch 35, Val Loss: 1.91149
Epoch 36, Val Loss: 1.90398
Epoch 37, Val Loss: 1.91266
Epoch 38, Val Loss: 1.91309
Epoch 39, Val Loss: 1.90291
Epoch 40, Val Loss: 1.92453
Epoch 41, Val Loss: 1.91906
Epoch 42, Val Loss: 1.90733
Epoch 43, Val Loss: 1.90342
Epoch 44, Val Loss: 1.91697
Epoch 45, Val Loss: 1.90243
Epoch 46, Val Loss: 1.91464
Epoch 47, Val Loss: 1.90226
Epoch 48, Val Loss: 1.90233
Epoch 49, Val Loss: 1.91825
Epoch 50, Val Loss: 1.92224
Epoch 51, Val Loss: 1.91152
Epoch 52, Val Loss: 1.90684
Epoch 53, Val Loss: 1.91917
Epoch 54, Val Loss: 1.91055
Epoch 55, Val Loss: 1.89457
Epoch 56, Val Loss: 1.90679
Epoch 57, Val Loss: 1.91047
Epoch 58, Val Loss: 1.94597
Epoch 59, Val Loss: 1.93586
Epoch 60, Val Loss: 1.92379
Epoch 61, Val Loss: 1.91421
Epoch 62, Val Loss: 1.90517
Epoch 63, Val Loss: 1.90664
Epoch 64, Val Loss: 1.91264
Epoch 65, Val Loss: 1.93380
Epoch 66, Val Loss: 1.90211
Epoch 67, Val Loss: 1.91027
Epoch 68, Val Loss: 1.90450
Epoch 69, Val Loss: 1.90836
Epoch 70, Val Loss: 1.90300
Epoch 71, Val Loss: 1.89262
Epoch 72, Val Loss: 1.90606
Epoch 73, Val Loss: 1.92213
Epoch 74, Val Loss: 1.90390
Epoch 75, Val Loss: 1.92733
Epoch 76, Val Loss: 1.90345
Epoch 77, Val Loss: 1.89684
Epoch 78, Val Loss: 1.88989
Epoch 79, Val Loss: 1.91521
Epoch 80, Val Loss: 1.90722
Epoch 81, Val Loss: 1.89784
Epoch 82, Val Loss: 1.90188
Epoch 83, Val Loss: 1.89666
Epoch 84, Val Loss: 1.89388
Epoch 85, Val Loss: 1.89328
Epoch 86, Val Loss: 1.90006
Epoch 87, Val Loss: 1.89120
Epoch 88, Val Loss: 1.89323
Epoch 89, Val Loss: 1.90928
Epoch 90, Val Loss: 1.92047
Epoch 91, Val Loss: 1.89322
Epoch 92, Val Loss: 1.89615
Epoch 93, Val Loss: 1.88230
Epoch 94, Val Loss: 1.89057
Epoch 95, Val Loss: 1.89952
Epoch 96, Val Loss: 1.89135
Epoch 97, Val Loss: 1.93504
Epoch 98, Val Loss: 1.91381
Epoch 99, Val Loss: 1.89154
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 4.2989999999999995, 'Log Loss - std': 2.749896369683774} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 40 finished with value: 4.2989999999999995 and parameters: {'p_m': 0.38402768269413623, 'alpha': 3.3443165723423633, 'K': 15, 'beta': 2.7945374994412426}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}
Fitted encoder
Epoch 0, Val Loss: 2.15017
Epoch 1, Val Loss: 2.13610
Epoch 2, Val Loss: 2.11194
Epoch 3, Val Loss: 2.13740
Epoch 4, Val Loss: 2.11526
Epoch 5, Val Loss: 2.11558
Epoch 6, Val Loss: 2.10496
Epoch 7, Val Loss: 2.08842
Epoch 8, Val Loss: 2.08743
Epoch 9, Val Loss: 2.12540
Epoch 10, Val Loss: 2.07713
Epoch 11, Val Loss: 2.08104
Epoch 12, Val Loss: 2.09305
Epoch 13, Val Loss: 2.07019
Epoch 14, Val Loss: 2.10239
Epoch 15, Val Loss: 2.08479
Epoch 16, Val Loss: 2.08729
Epoch 17, Val Loss: 2.07949
Epoch 18, Val Loss: 2.07137
Epoch 19, Val Loss: 2.08869
Epoch 20, Val Loss: 2.07329
Epoch 21, Val Loss: 2.05456
Epoch 22, Val Loss: 2.08030
Epoch 23, Val Loss: 2.06722
Epoch 24, Val Loss: 2.05824
Epoch 25, Val Loss: 2.07385
Epoch 26, Val Loss: 2.06732
Epoch 27, Val Loss: 2.11185
Epoch 28, Val Loss: 2.08027
Epoch 29, Val Loss: 2.07080
Epoch 30, Val Loss: 2.05416
Epoch 31, Val Loss: 2.06054
Epoch 32, Val Loss: 2.05290
Epoch 33, Val Loss: 2.06296
Epoch 34, Val Loss: 2.05365
Epoch 35, Val Loss: 2.05716
Epoch 36, Val Loss: 2.07604
Epoch 37, Val Loss: 2.06803
Epoch 38, Val Loss: 2.06314
Epoch 39, Val Loss: 2.04922
Epoch 40, Val Loss: 2.08221
Epoch 41, Val Loss: 2.06115
Epoch 42, Val Loss: 2.07818
Epoch 43, Val Loss: 2.06472
Epoch 44, Val Loss: 2.06266
Epoch 45, Val Loss: 2.06449
Epoch 46, Val Loss: 2.04819
Epoch 47, Val Loss: 2.06534
Epoch 48, Val Loss: 2.05369
Epoch 49, Val Loss: 2.05216
Epoch 50, Val Loss: 2.07230
Epoch 51, Val Loss: 2.05743
Epoch 52, Val Loss: 2.04205
Epoch 53, Val Loss: 2.04966
Epoch 54, Val Loss: 2.06275
Epoch 55, Val Loss: 2.08090
Epoch 56, Val Loss: 2.06450
Epoch 57, Val Loss: 2.06254
Epoch 58, Val Loss: 2.07223
Epoch 59, Val Loss: 2.06443
Epoch 60, Val Loss: 2.05253
Epoch 61, Val Loss: 2.06560
Epoch 62, Val Loss: 2.05806
Epoch 63, Val Loss: 2.06339
Epoch 64, Val Loss: 2.06447
Epoch 65, Val Loss: 2.04917
Epoch 66, Val Loss: 2.04438
Epoch 67, Val Loss: 2.06266
Epoch 68, Val Loss: 2.07535
Epoch 69, Val Loss: 2.05191
Epoch 70, Val Loss: 2.06132
Epoch 71, Val Loss: 2.05497
Epoch 72, Val Loss: 2.06245
Epoch 73, Val Loss: 2.04794
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.1307, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}
Fitted encoder
Epoch 0, Val Loss: 1.95817
Epoch 1, Val Loss: 1.96682
Epoch 2, Val Loss: 1.95412
Epoch 3, Val Loss: 1.95698
Epoch 4, Val Loss: 1.94429
Epoch 5, Val Loss: 1.94308
Epoch 6, Val Loss: 1.94490
Epoch 7, Val Loss: 1.94546
Epoch 8, Val Loss: 1.94427
Epoch 9, Val Loss: 1.93870
Epoch 10, Val Loss: 1.94324
Epoch 11, Val Loss: 1.94446
Epoch 12, Val Loss: 1.94856
Epoch 13, Val Loss: 1.94188
Epoch 14, Val Loss: 1.94803
Epoch 15, Val Loss: 1.94531
Epoch 16, Val Loss: 1.94261
Epoch 17, Val Loss: 1.94325
Epoch 18, Val Loss: 1.94469
Epoch 19, Val Loss: 1.95833
Epoch 20, Val Loss: 1.94046
Epoch 21, Val Loss: 1.95591
Epoch 22, Val Loss: 1.93441
Epoch 23, Val Loss: 1.94219
Epoch 24, Val Loss: 1.95383
Epoch 25, Val Loss: 1.94290
Epoch 26, Val Loss: 1.94368
Epoch 27, Val Loss: 1.93219
Epoch 28, Val Loss: 1.93238
Epoch 29, Val Loss: 1.92086
Epoch 30, Val Loss: 1.95510
Epoch 31, Val Loss: 1.94175
Epoch 32, Val Loss: 1.93253
Epoch 33, Val Loss: 1.93611
Epoch 34, Val Loss: 1.92715
Epoch 35, Val Loss: 1.91833
Epoch 36, Val Loss: 1.96554
Epoch 37, Val Loss: 1.93856
Epoch 38, Val Loss: 2.02674
Epoch 39, Val Loss: 2.01291
Epoch 40, Val Loss: 1.93755
Epoch 41, Val Loss: 1.91953
Epoch 42, Val Loss: 1.93069
Epoch 43, Val Loss: 1.92752
Epoch 44, Val Loss: 1.92382
Epoch 45, Val Loss: 1.93480
Epoch 46, Val Loss: 1.94642
Epoch 47, Val Loss: 1.91764
Epoch 48, Val Loss: 1.93630
Epoch 49, Val Loss: 1.93108
Epoch 50, Val Loss: 1.92768
Epoch 51, Val Loss: 1.89863
Epoch 52, Val Loss: 1.91596
Epoch 53, Val Loss: 1.91600
Epoch 54, Val Loss: 1.94175
Epoch 55, Val Loss: 1.93255
Epoch 56, Val Loss: 1.91188
Epoch 57, Val Loss: 1.92277
Epoch 58, Val Loss: 1.90508
Epoch 59, Val Loss: 1.90746
Epoch 60, Val Loss: 1.90916
Epoch 61, Val Loss: 1.90784
Epoch 62, Val Loss: 1.91433
Epoch 63, Val Loss: 1.93278
Epoch 64, Val Loss: 1.91263
Epoch 65, Val Loss: 1.92703
Epoch 66, Val Loss: 1.91576
Epoch 67, Val Loss: 1.92359
Epoch 68, Val Loss: 1.90393
Epoch 69, Val Loss: 1.90146
Epoch 70, Val Loss: 1.90091
Epoch 71, Val Loss: 1.89942
Epoch 72, Val Loss: 1.90994
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.9767, 'Log Loss - std': 0.15399999999999991} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}
Fitted encoder
Epoch 0, Val Loss: 2.13580
Epoch 1, Val Loss: 2.12776
Epoch 2, Val Loss: 2.12661
Epoch 3, Val Loss: 2.12024
Epoch 4, Val Loss: 2.11034
Epoch 5, Val Loss: 2.10917
Epoch 6, Val Loss: 2.11502
Epoch 7, Val Loss: 2.11130
Epoch 8, Val Loss: 2.12854
Epoch 9, Val Loss: 2.09478
Epoch 10, Val Loss: 2.08705
Epoch 11, Val Loss: 2.08910
Epoch 12, Val Loss: 2.08896
Epoch 13, Val Loss: 2.09620
Epoch 14, Val Loss: 2.10161
Epoch 15, Val Loss: 2.09882
Epoch 16, Val Loss: 2.07641
Epoch 17, Val Loss: 2.08029
Epoch 18, Val Loss: 2.08277
Epoch 19, Val Loss: 2.06429
Epoch 20, Val Loss: 2.08466
Epoch 21, Val Loss: 2.07725
Epoch 22, Val Loss: 2.08046
Epoch 23, Val Loss: 2.09216
Epoch 24, Val Loss: 2.07550
Epoch 25, Val Loss: 2.06739
Epoch 26, Val Loss: 2.06959
Epoch 27, Val Loss: 2.06593
Epoch 28, Val Loss: 2.07025
Epoch 29, Val Loss: 2.07195
Epoch 30, Val Loss: 2.07027
Epoch 31, Val Loss: 2.06430
Epoch 32, Val Loss: 2.07284
Epoch 33, Val Loss: 2.09686
Epoch 34, Val Loss: 2.06632
Epoch 35, Val Loss: 2.07872
Epoch 36, Val Loss: 2.06665
Epoch 37, Val Loss: 2.06797
Epoch 38, Val Loss: 2.06925
Epoch 39, Val Loss: 2.07477
Epoch 40, Val Loss: 2.07432
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.931266666666667, 'Log Loss - std': 0.14120567347745708} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}
Fitted encoder
Epoch 0, Val Loss: 2.08090
Epoch 1, Val Loss: 2.08021
Epoch 2, Val Loss: 2.06330
Epoch 3, Val Loss: 2.06724
Epoch 4, Val Loss: 2.06314
Epoch 5, Val Loss: 2.04788
Epoch 6, Val Loss: 2.07562
Epoch 7, Val Loss: 2.05001
Epoch 8, Val Loss: 2.05825
Epoch 9, Val Loss: 2.06094
Epoch 10, Val Loss: 2.06293
Epoch 11, Val Loss: 2.05003
Epoch 12, Val Loss: 2.05338
Epoch 13, Val Loss: 2.08240
Epoch 14, Val Loss: 2.05573
Epoch 15, Val Loss: 2.05487
Epoch 16, Val Loss: 2.05081
Epoch 17, Val Loss: 2.03771
Epoch 18, Val Loss: 2.05042
Epoch 19, Val Loss: 2.06964
Epoch 20, Val Loss: 2.08078
Epoch 21, Val Loss: 2.05750
Epoch 22, Val Loss: 2.04936
Epoch 23, Val Loss: 2.05085
Epoch 24, Val Loss: 2.04430
Epoch 25, Val Loss: 2.05103
Epoch 26, Val Loss: 2.05029
Epoch 27, Val Loss: 2.03870
Epoch 28, Val Loss: 2.04348
Epoch 29, Val Loss: 2.04507
Epoch 30, Val Loss: 2.03509
Epoch 31, Val Loss: 2.04213
Epoch 32, Val Loss: 2.05521
Epoch 33, Val Loss: 2.04828
Epoch 34, Val Loss: 2.03231
Epoch 35, Val Loss: 2.04101
Epoch 36, Val Loss: 2.03827
Epoch 37, Val Loss: 2.04422
Epoch 38, Val Loss: 2.06335
Epoch 39, Val Loss: 2.05785
Epoch 40, Val Loss: 2.04582
Epoch 41, Val Loss: 2.03124
Epoch 42, Val Loss: 2.05158
Epoch 43, Val Loss: 2.11151
Epoch 44, Val Loss: 2.05808
Epoch 45, Val Loss: 2.05077
Epoch 46, Val Loss: 2.02840
Epoch 47, Val Loss: 2.02012
Epoch 48, Val Loss: 2.01509
Epoch 49, Val Loss: 2.03659
Epoch 50, Val Loss: 2.04193
Epoch 51, Val Loss: 2.03121
Epoch 52, Val Loss: 2.03097
Epoch 53, Val Loss: 2.03504
Epoch 54, Val Loss: 2.03569
Epoch 55, Val Loss: 2.02921
Epoch 56, Val Loss: 2.03416
Epoch 57, Val Loss: 2.01592
Epoch 58, Val Loss: 2.03173
Epoch 59, Val Loss: 2.02219
Epoch 60, Val Loss: 2.02683
Epoch 61, Val Loss: 2.02697
Epoch 62, Val Loss: 2.02217
Epoch 63, Val Loss: 2.02444
Epoch 64, Val Loss: 2.01571
Epoch 65, Val Loss: 2.01443
Epoch 66, Val Loss: 2.02226
Epoch 67, Val Loss: 2.03690
Epoch 68, Val Loss: 2.02400
Epoch 69, Val Loss: 2.03875
Epoch 70, Val Loss: 2.01824
Epoch 71, Val Loss: 2.02029
Epoch 72, Val Loss: 2.01468
Epoch 73, Val Loss: 2.01293
Epoch 74, Val Loss: 2.02258
Epoch 75, Val Loss: 2.02813
Epoch 76, Val Loss: 2.03126
Epoch 77, Val Loss: 2.02282
Epoch 78, Val Loss: 2.04549
Epoch 79, Val Loss: 2.02825
Epoch 80, Val Loss: 2.03170
Epoch 81, Val Loss: 2.01334
Epoch 82, Val Loss: 2.02516
Epoch 83, Val Loss: 2.02017
Epoch 84, Val Loss: 2.04073
Epoch 85, Val Loss: 2.01628
Epoch 86, Val Loss: 2.03273
Epoch 87, Val Loss: 2.01493
Epoch 88, Val Loss: 2.02502
Epoch 89, Val Loss: 2.02482
Epoch 90, Val Loss: 2.01172
Epoch 91, Val Loss: 2.02918
Epoch 92, Val Loss: 2.00964
Epoch 93, Val Loss: 2.04441
Epoch 94, Val Loss: 2.01222
Epoch 95, Val Loss: 2.03113
Epoch 96, Val Loss: 2.00836
Epoch 97, Val Loss: 2.02424
Epoch 98, Val Loss: 2.02304
Epoch 99, Val Loss: 2.02110
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.8513, 'Log Loss - std': 0.18476548649571972} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}
Fitted encoder
Epoch 0, Val Loss: 1.95183
Epoch 1, Val Loss: 1.95215
Epoch 2, Val Loss: 1.94781
Epoch 3, Val Loss: 1.96834
Epoch 4, Val Loss: 1.95273
Epoch 5, Val Loss: 1.95002
Epoch 6, Val Loss: 1.94635
Epoch 7, Val Loss: 1.94492
Epoch 8, Val Loss: 1.94570
Epoch 9, Val Loss: 1.94104
Epoch 10, Val Loss: 1.95306
Epoch 11, Val Loss: 1.95438
Epoch 12, Val Loss: 1.94311
Epoch 13, Val Loss: 1.94188
Epoch 14, Val Loss: 1.94166
Epoch 15, Val Loss: 1.94140
Epoch 16, Val Loss: 1.94244
Epoch 17, Val Loss: 1.93636
Epoch 18, Val Loss: 1.93265
Epoch 19, Val Loss: 1.94650
Epoch 20, Val Loss: 1.93527
Epoch 21, Val Loss: 1.92970
Epoch 22, Val Loss: 1.91429
Epoch 23, Val Loss: 1.95941
Epoch 24, Val Loss: 1.94256
Epoch 25, Val Loss: 1.91845
Epoch 26, Val Loss: 1.92474
Epoch 27, Val Loss: 1.91378
Epoch 28, Val Loss: 1.91748
Epoch 29, Val Loss: 1.94562
Epoch 30, Val Loss: 1.91763
Epoch 31, Val Loss: 1.91153
Epoch 32, Val Loss: 1.91206
Epoch 33, Val Loss: 1.92289
Epoch 34, Val Loss: 1.90801
Epoch 35, Val Loss: 1.91103
Epoch 36, Val Loss: 1.91300
Epoch 37, Val Loss: 1.91754
Epoch 38, Val Loss: 1.90029
Epoch 39, Val Loss: 1.91895
Epoch 40, Val Loss: 1.89666
Epoch 41, Val Loss: 1.93746
Epoch 42, Val Loss: 1.90960
Epoch 43, Val Loss: 1.90102
Epoch 44, Val Loss: 1.91400
Epoch 45, Val Loss: 1.88359
Epoch 46, Val Loss: 1.88566
Epoch 47, Val Loss: 1.90194
Epoch 48, Val Loss: 1.91936
Epoch 49, Val Loss: 1.89337
Epoch 50, Val Loss: 1.91615
Epoch 51, Val Loss: 1.88548
Epoch 52, Val Loss: 1.90840
Epoch 53, Val Loss: 1.89989
Epoch 54, Val Loss: 1.91231
Epoch 55, Val Loss: 1.90533
Epoch 56, Val Loss: 1.89627
Epoch 57, Val Loss: 1.91550
Epoch 58, Val Loss: 1.90324
Epoch 59, Val Loss: 1.88801
Epoch 60, Val Loss: 1.90253
Epoch 61, Val Loss: 1.89155
Epoch 62, Val Loss: 1.89145
Epoch 63, Val Loss: 1.90944
Epoch 64, Val Loss: 1.89965
Epoch 65, Val Loss: 1.89218
Epoch 66, Val Loss: 1.88476
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.8384, 'Log Loss - std': 0.1672610773611123} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 41 finished with value: 2.8384 and parameters: {'p_m': 0.4213005692176508, 'alpha': 3.2826628079958233, 'K': 15, 'beta': 2.6407996901818067}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}
Fitted encoder
Epoch 0, Val Loss: 2.13743
Epoch 1, Val Loss: 2.13852
Epoch 2, Val Loss: 2.15020
Epoch 3, Val Loss: 2.13644
Epoch 4, Val Loss: 2.12760
Epoch 5, Val Loss: 2.12292
Epoch 6, Val Loss: 2.12437
Epoch 7, Val Loss: 2.11942
Epoch 8, Val Loss: 2.11682
Epoch 9, Val Loss: 2.17291
Epoch 10, Val Loss: 2.14198
Epoch 11, Val Loss: 2.13483
Epoch 12, Val Loss: 2.12603
Epoch 13, Val Loss: 2.14103
Epoch 14, Val Loss: 2.11954
Epoch 15, Val Loss: 2.10573
Epoch 16, Val Loss: 2.14238
Epoch 17, Val Loss: 2.13382
Epoch 18, Val Loss: 2.09322
Epoch 19, Val Loss: 2.09269
Epoch 20, Val Loss: 2.12169
Epoch 21, Val Loss: 2.12593
Epoch 22, Val Loss: 2.10449
Epoch 23, Val Loss: 2.09941
Epoch 24, Val Loss: 2.10484
Epoch 25, Val Loss: 2.08637
Epoch 26, Val Loss: 2.13230
Epoch 27, Val Loss: 2.16505
Epoch 28, Val Loss: 2.10895
Epoch 29, Val Loss: 2.10981
Epoch 30, Val Loss: 2.08036
Epoch 31, Val Loss: 2.10096
Epoch 32, Val Loss: 2.10553
Epoch 33, Val Loss: 2.08950
Epoch 34, Val Loss: 2.10139
Epoch 35, Val Loss: 2.07845
Epoch 36, Val Loss: 2.07401
Epoch 37, Val Loss: 2.07448
Epoch 38, Val Loss: 2.09012
Epoch 39, Val Loss: 2.09916
Epoch 40, Val Loss: 2.08399
Epoch 41, Val Loss: 2.08477
Epoch 42, Val Loss: 2.10405
Epoch 43, Val Loss: 2.08002
Epoch 44, Val Loss: 2.07912
Epoch 45, Val Loss: 2.07265
Epoch 46, Val Loss: 2.10291
Epoch 47, Val Loss: 2.07456
Epoch 48, Val Loss: 2.06406
Epoch 49, Val Loss: 2.08506
Epoch 50, Val Loss: 2.10613
Epoch 51, Val Loss: 2.08023
Epoch 52, Val Loss: 2.08049
Epoch 53, Val Loss: 2.08652
Epoch 54, Val Loss: 2.07061
Epoch 55, Val Loss: 2.06645
Epoch 56, Val Loss: 2.08388
Epoch 57, Val Loss: 2.07653
Epoch 58, Val Loss: 2.08554
Epoch 59, Val Loss: 2.08738
Epoch 60, Val Loss: 2.07122
Epoch 61, Val Loss: 2.06906
Epoch 62, Val Loss: 2.09074
Epoch 63, Val Loss: 2.07511
Epoch 64, Val Loss: 2.07561
Epoch 65, Val Loss: 2.07106
Epoch 66, Val Loss: 2.08518
Epoch 67, Val Loss: 2.10511
Epoch 68, Val Loss: 2.07401
Epoch 69, Val Loss: 2.12178
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.0818, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}
Fitted encoder
Epoch 0, Val Loss: 1.96351
Epoch 1, Val Loss: 1.95937
Epoch 2, Val Loss: 1.95728
Epoch 3, Val Loss: 1.94017
Epoch 4, Val Loss: 1.93015
Epoch 5, Val Loss: 1.91930
Epoch 6, Val Loss: 1.98691
Epoch 7, Val Loss: 1.92532
Epoch 8, Val Loss: 1.91079
Epoch 9, Val Loss: 1.90360
Epoch 10, Val Loss: 1.92981
Epoch 11, Val Loss: 1.92137
Epoch 12, Val Loss: 1.92348
Epoch 13, Val Loss: 1.91977
Epoch 14, Val Loss: 1.89796
Epoch 15, Val Loss: 1.91403
Epoch 16, Val Loss: 1.91463
Epoch 17, Val Loss: 1.90128
Epoch 18, Val Loss: 1.93668
Epoch 19, Val Loss: 1.91184
Epoch 20, Val Loss: 1.93081
Epoch 21, Val Loss: 1.89822
Epoch 22, Val Loss: 1.90154
Epoch 23, Val Loss: 1.92003
Epoch 24, Val Loss: 1.90057
Epoch 25, Val Loss: 1.90707
Epoch 26, Val Loss: 1.90484
Epoch 27, Val Loss: 1.90763
Epoch 28, Val Loss: 1.90312
Epoch 29, Val Loss: 1.89569
Epoch 30, Val Loss: 1.91125
Epoch 31, Val Loss: 1.89117
Epoch 32, Val Loss: 1.90112
Epoch 33, Val Loss: 1.89848
Epoch 34, Val Loss: 1.89279
Epoch 35, Val Loss: 1.89575
Epoch 36, Val Loss: 1.91085
Epoch 37, Val Loss: 1.89501
Epoch 38, Val Loss: 1.90817
Epoch 39, Val Loss: 1.91260
Epoch 40, Val Loss: 1.88866
Epoch 41, Val Loss: 1.89545
Epoch 42, Val Loss: 1.90317
Epoch 43, Val Loss: 1.89985
Epoch 44, Val Loss: 1.90068
Epoch 45, Val Loss: 1.90047
Epoch 46, Val Loss: 1.89375
Epoch 47, Val Loss: 1.89259
Epoch 48, Val Loss: 1.90912
Epoch 49, Val Loss: 1.89637
Epoch 50, Val Loss: 1.90007
Epoch 51, Val Loss: 1.90256
Epoch 52, Val Loss: 1.90442
Epoch 53, Val Loss: 1.90857
Epoch 54, Val Loss: 1.89627
Epoch 55, Val Loss: 1.89752
Epoch 56, Val Loss: 1.89614
Epoch 57, Val Loss: 1.89513
Epoch 58, Val Loss: 1.89733
Epoch 59, Val Loss: 1.89365
Epoch 60, Val Loss: 1.89555
Epoch 61, Val Loss: 1.94334
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.77245, 'Log Loss - std': 0.30935000000000024} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}
Fitted encoder
Epoch 0, Val Loss: 2.15561
Epoch 1, Val Loss: 2.17193
Epoch 2, Val Loss: 2.17384
Epoch 3, Val Loss: 2.15307
Epoch 4, Val Loss: 2.17458
Epoch 5, Val Loss: 2.16543
Epoch 6, Val Loss: 2.16040
Epoch 7, Val Loss: 2.16307
Epoch 8, Val Loss: 2.13408
Epoch 9, Val Loss: 2.14574
Epoch 10, Val Loss: 2.14269
Epoch 11, Val Loss: 2.13677
Epoch 12, Val Loss: 2.15950
Epoch 13, Val Loss: 2.11982
Epoch 14, Val Loss: 2.12349
Epoch 15, Val Loss: 2.09714
Epoch 16, Val Loss: 2.10376
Epoch 17, Val Loss: 2.09044
Epoch 18, Val Loss: 2.12031
Epoch 19, Val Loss: 2.09413
Epoch 20, Val Loss: 2.11505
Epoch 21, Val Loss: 2.08807
Epoch 22, Val Loss: 2.08768
Epoch 23, Val Loss: 2.08281
Epoch 24, Val Loss: 2.06913
Epoch 25, Val Loss: 2.07459
Epoch 26, Val Loss: 2.07290
Epoch 27, Val Loss: 2.06977
Epoch 28, Val Loss: 2.09235
Epoch 29, Val Loss: 2.09051
Epoch 30, Val Loss: 2.08507
Epoch 31, Val Loss: 2.07648
Epoch 32, Val Loss: 2.06624
Epoch 33, Val Loss: 2.07363
Epoch 34, Val Loss: 2.06748
Epoch 35, Val Loss: 2.06038
Epoch 36, Val Loss: 2.07304
Epoch 37, Val Loss: 2.07601
Epoch 38, Val Loss: 2.06946
Epoch 39, Val Loss: 2.07697
Epoch 40, Val Loss: 2.07018
Epoch 41, Val Loss: 2.07567
Epoch 42, Val Loss: 2.07303
Epoch 43, Val Loss: 2.07822
Epoch 44, Val Loss: 2.06430
Epoch 45, Val Loss: 2.07211
Epoch 46, Val Loss: 2.07832
Epoch 47, Val Loss: 2.09061
Epoch 48, Val Loss: 2.06402
Epoch 49, Val Loss: 2.07875
Epoch 50, Val Loss: 2.06403
Epoch 51, Val Loss: 2.09673
Epoch 52, Val Loss: 2.06701
Epoch 53, Val Loss: 2.07020
Epoch 54, Val Loss: 2.05995
Epoch 55, Val Loss: 2.05889
Epoch 56, Val Loss: 2.06643
Epoch 57, Val Loss: 2.07832
Epoch 58, Val Loss: 2.06053
Epoch 59, Val Loss: 2.06342
Epoch 60, Val Loss: 2.07119
Epoch 61, Val Loss: 2.06494
Epoch 62, Val Loss: 2.06241
Epoch 63, Val Loss: 2.07129
Epoch 64, Val Loss: 2.06621
Epoch 65, Val Loss: 2.06012
Epoch 66, Val Loss: 2.05596
Epoch 67, Val Loss: 2.07019
Epoch 68, Val Loss: 2.07057
Epoch 69, Val Loss: 2.05382
Epoch 70, Val Loss: 2.07733
Epoch 71, Val Loss: 2.06405
Epoch 72, Val Loss: 2.08639
Epoch 73, Val Loss: 2.11485
Epoch 74, Val Loss: 2.10553
Epoch 75, Val Loss: 2.07654
Epoch 76, Val Loss: 2.06707
Epoch 77, Val Loss: 2.07707
Epoch 78, Val Loss: 2.08774
Epoch 79, Val Loss: 2.06445
Epoch 80, Val Loss: 2.07092
Epoch 81, Val Loss: 2.07259
Epoch 82, Val Loss: 2.06168
Epoch 83, Val Loss: 2.08856
Epoch 84, Val Loss: 2.07454
Epoch 85, Val Loss: 2.05871
Epoch 86, Val Loss: 2.06518
Epoch 87, Val Loss: 2.07451
Epoch 88, Val Loss: 2.06101
Epoch 89, Val Loss: 2.07110
Epoch 90, Val Loss: 2.06129
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.7970666666666664, 'Log Loss - std': 0.25497106153879956} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}
Fitted encoder
Epoch 0, Val Loss: 2.12201
Epoch 1, Val Loss: 2.09173
Epoch 2, Val Loss: 2.06992
Epoch 3, Val Loss: 2.06844
Epoch 4, Val Loss: 2.06086
Epoch 5, Val Loss: 2.06579
Epoch 6, Val Loss: 2.06603
Epoch 7, Val Loss: 2.07190
Epoch 8, Val Loss: 2.11091
Epoch 9, Val Loss: 2.04873
Epoch 10, Val Loss: 2.02177
Epoch 11, Val Loss: 2.08440
Epoch 12, Val Loss: 2.03653
Epoch 13, Val Loss: 2.03355
Epoch 14, Val Loss: 2.01172
Epoch 15, Val Loss: 2.01997
Epoch 16, Val Loss: 2.01636
Epoch 17, Val Loss: 2.01652
Epoch 18, Val Loss: 2.01972
Epoch 19, Val Loss: 2.00042
Epoch 20, Val Loss: 2.02067
Epoch 21, Val Loss: 2.00131
Epoch 22, Val Loss: 2.02295
Epoch 23, Val Loss: 2.00783
Epoch 24, Val Loss: 2.00494
Epoch 25, Val Loss: 2.01515
Epoch 26, Val Loss: 2.02449
Epoch 27, Val Loss: 2.01648
Epoch 28, Val Loss: 2.00469
Epoch 29, Val Loss: 2.00960
Epoch 30, Val Loss: 2.00834
Epoch 31, Val Loss: 2.02955
Epoch 32, Val Loss: 2.02590
Epoch 33, Val Loss: 2.03412
Epoch 34, Val Loss: 2.03229
Epoch 35, Val Loss: 2.03623
Epoch 36, Val Loss: 2.01196
Epoch 37, Val Loss: 2.00214
Epoch 38, Val Loss: 1.99409
Epoch 39, Val Loss: 2.02307
Epoch 40, Val Loss: 2.01724
Epoch 41, Val Loss: 2.01744
Epoch 42, Val Loss: 2.00822
Epoch 43, Val Loss: 2.02277
Epoch 44, Val Loss: 2.00568
Epoch 45, Val Loss: 2.03070
Epoch 46, Val Loss: 2.01319
Epoch 47, Val Loss: 2.01946
Epoch 48, Val Loss: 2.00997
Epoch 49, Val Loss: 2.01290
Epoch 50, Val Loss: 2.01832
Epoch 51, Val Loss: 2.02842
Epoch 52, Val Loss: 2.00605
Epoch 53, Val Loss: 2.00768
Epoch 54, Val Loss: 2.00252
Epoch 55, Val Loss: 2.02141
Epoch 56, Val Loss: 2.01547
Epoch 57, Val Loss: 2.07873
Epoch 58, Val Loss: 2.11553
Epoch 59, Val Loss: 2.09366
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.6370999999999998, 'Log Loss - std': 0.3542960414681486} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}
Fitted encoder
Epoch 0, Val Loss: 1.95632
Epoch 1, Val Loss: 1.95804
Epoch 2, Val Loss: 1.94550
Epoch 3, Val Loss: 1.94070
Epoch 4, Val Loss: 1.94559
Epoch 5, Val Loss: 1.93959
Epoch 6, Val Loss: 1.93911
Epoch 7, Val Loss: 1.94288
Epoch 8, Val Loss: 1.93036
Epoch 9, Val Loss: 1.92094
Epoch 10, Val Loss: 1.95962
Epoch 11, Val Loss: 1.95124
Epoch 12, Val Loss: 1.96948
Epoch 13, Val Loss: 1.94470
Epoch 14, Val Loss: 1.95032
Epoch 15, Val Loss: 1.91617
Epoch 16, Val Loss: 1.92932
Epoch 17, Val Loss: 1.92701
Epoch 18, Val Loss: 1.92095
Epoch 19, Val Loss: 2.06821
Epoch 20, Val Loss: 2.05951
Epoch 21, Val Loss: 2.07532
Epoch 22, Val Loss: 2.10001
Epoch 23, Val Loss: 2.08761
Epoch 24, Val Loss: 2.08219
Epoch 25, Val Loss: 2.05017
Epoch 26, Val Loss: 2.00338
Epoch 27, Val Loss: 2.05173
Epoch 28, Val Loss: 2.03957
Epoch 29, Val Loss: 1.93287
Epoch 30, Val Loss: 2.03570
Epoch 31, Val Loss: 2.08090
Epoch 32, Val Loss: 2.04780
Epoch 33, Val Loss: 2.03260
Epoch 34, Val Loss: 1.95989
Epoch 35, Val Loss: 1.92875
Epoch 36, Val Loss: 1.91051
Epoch 37, Val Loss: 1.92343
Epoch 38, Val Loss: 1.99392
Epoch 39, Val Loss: 2.03660
Epoch 40, Val Loss: 1.99536
Epoch 41, Val Loss: 1.94913
Epoch 42, Val Loss: 1.91393
Epoch 43, Val Loss: 1.92268
Epoch 44, Val Loss: 1.89782
Epoch 45, Val Loss: 1.91381
Epoch 46, Val Loss: 1.91363
Epoch 47, Val Loss: 1.91627
Epoch 48, Val Loss: 1.89529
Epoch 49, Val Loss: 1.92717
Epoch 50, Val Loss: 1.89574
Epoch 51, Val Loss: 1.91024
Epoch 52, Val Loss: 1.90007
Epoch 53, Val Loss: 1.90089
Epoch 54, Val Loss: 1.89016
Epoch 55, Val Loss: 1.89892
Epoch 56, Val Loss: 1.90450
Epoch 57, Val Loss: 1.90009
Epoch 58, Val Loss: 1.89232
Epoch 59, Val Loss: 1.90260
Epoch 60, Val Loss: 1.89089
Epoch 61, Val Loss: 1.89323
Epoch 62, Val Loss: 1.88899
Epoch 63, Val Loss: 1.90155
Epoch 64, Val Loss: 1.90601
Epoch 65, Val Loss: 1.89191
Epoch 66, Val Loss: 1.90950
Epoch 67, Val Loss: 1.90603
Epoch 68, Val Loss: 1.96285
Epoch 69, Val Loss: 1.95133
Epoch 70, Val Loss: 1.93690
Epoch 71, Val Loss: 1.88561
Epoch 72, Val Loss: 1.93265
Epoch 73, Val Loss: 1.89506
Epoch 74, Val Loss: 1.90418
Epoch 75, Val Loss: 1.89994
Epoch 76, Val Loss: 1.90092
Epoch 77, Val Loss: 1.88947
Epoch 78, Val Loss: 1.89414
Epoch 79, Val Loss: 1.92571
Epoch 80, Val Loss: 1.90895
Epoch 81, Val Loss: 1.92552
Epoch 82, Val Loss: 1.88787
Epoch 83, Val Loss: 1.92625
Epoch 84, Val Loss: 1.89510
Epoch 85, Val Loss: 1.89622
Epoch 86, Val Loss: 1.89258
Epoch 87, Val Loss: 1.89124
Epoch 88, Val Loss: 1.90549
Epoch 89, Val Loss: 1.88638
Epoch 90, Val Loss: 1.89027
Epoch 91, Val Loss: 1.89996
Epoch 92, Val Loss: 1.88786
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.6038799999999993, 'Log Loss - std': 0.3237820587988161} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 42 finished with value: 3.6038799999999993 and parameters: {'p_m': 0.37369007836393703, 'alpha': 0.7516058004915307, 'K': 15, 'beta': 0.576994007265127}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}
Fitted encoder
Epoch 0, Val Loss: 2.18696
Epoch 1, Val Loss: 2.13579
Epoch 2, Val Loss: 2.13023
Epoch 3, Val Loss: 2.13092
Epoch 4, Val Loss: 2.12245
Epoch 5, Val Loss: 2.12114
Epoch 6, Val Loss: 2.12570
Epoch 7, Val Loss: 2.13020
Epoch 8, Val Loss: 2.11981
Epoch 9, Val Loss: 2.10227
Epoch 10, Val Loss: 2.10522
Epoch 11, Val Loss: 2.10228
Epoch 12, Val Loss: 2.12866
Epoch 13, Val Loss: 2.09796
Epoch 14, Val Loss: 2.10145
Epoch 15, Val Loss: 2.10705
Epoch 16, Val Loss: 2.10283
Epoch 17, Val Loss: 2.10450
Epoch 18, Val Loss: 2.09054
Epoch 19, Val Loss: 2.08163
Epoch 20, Val Loss: 2.08792
Epoch 21, Val Loss: 2.10496
Epoch 22, Val Loss: 2.09127
Epoch 23, Val Loss: 2.08308
Epoch 24, Val Loss: 2.09188
Epoch 25, Val Loss: 2.07899
Epoch 26, Val Loss: 2.09353
Epoch 27, Val Loss: 2.09410
Epoch 28, Val Loss: 2.08969
Epoch 29, Val Loss: 2.06857
Epoch 30, Val Loss: 2.08540
Epoch 31, Val Loss: 2.07600
Epoch 32, Val Loss: 2.09599
Epoch 33, Val Loss: 2.08046
Epoch 34, Val Loss: 2.08765
Epoch 35, Val Loss: 2.08088
Epoch 36, Val Loss: 2.08284
Epoch 37, Val Loss: 2.08830
Epoch 38, Val Loss: 2.10629
Epoch 39, Val Loss: 2.08155
Epoch 40, Val Loss: 2.07362
Epoch 41, Val Loss: 2.07206
Epoch 42, Val Loss: 2.07836
Epoch 43, Val Loss: 2.07155
Epoch 44, Val Loss: 2.07902
Epoch 45, Val Loss: 2.08881
Epoch 46, Val Loss: 2.07014
Epoch 47, Val Loss: 2.07362
Epoch 48, Val Loss: 2.08541
Epoch 49, Val Loss: 2.07283
Epoch 50, Val Loss: 2.07790
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.6157, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}
Fitted encoder
Epoch 0, Val Loss: 1.96001
Epoch 1, Val Loss: 1.95415
Epoch 2, Val Loss: 1.94605
Epoch 3, Val Loss: 1.97018
Epoch 4, Val Loss: 1.95248
Epoch 5, Val Loss: 1.94034
Epoch 6, Val Loss: 1.94509
Epoch 7, Val Loss: 1.94574
Epoch 8, Val Loss: 1.93385
Epoch 9, Val Loss: 1.93168
Epoch 10, Val Loss: 1.94579
Epoch 11, Val Loss: 1.93501
Epoch 12, Val Loss: 1.93284
Epoch 13, Val Loss: 1.92091
Epoch 14, Val Loss: 1.92710
Epoch 15, Val Loss: 1.93097
Epoch 16, Val Loss: 1.92686
Epoch 17, Val Loss: 1.92274
Epoch 18, Val Loss: 1.92271
Epoch 19, Val Loss: 1.91664
Epoch 20, Val Loss: 1.92643
Epoch 21, Val Loss: 1.91743
Epoch 22, Val Loss: 1.90654
Epoch 23, Val Loss: 1.92020
Epoch 24, Val Loss: 1.92014
Epoch 25, Val Loss: 1.90529
Epoch 26, Val Loss: 1.91922
Epoch 27, Val Loss: 1.90335
Epoch 28, Val Loss: 1.91301
Epoch 29, Val Loss: 1.91281
Epoch 30, Val Loss: 1.91208
Epoch 31, Val Loss: 1.92022
Epoch 32, Val Loss: 1.91989
Epoch 33, Val Loss: 1.90747
Epoch 34, Val Loss: 1.91192
Epoch 35, Val Loss: 1.90498
Epoch 36, Val Loss: 1.92550
Epoch 37, Val Loss: 1.90341
Epoch 38, Val Loss: 1.90806
Epoch 39, Val Loss: 1.91879
Epoch 40, Val Loss: 1.91235
Epoch 41, Val Loss: 1.91306
Epoch 42, Val Loss: 1.89415
Epoch 43, Val Loss: 1.90785
Epoch 44, Val Loss: 1.90840
Epoch 45, Val Loss: 1.93167
Epoch 46, Val Loss: 1.90620
Epoch 47, Val Loss: 1.89137
Epoch 48, Val Loss: 1.91581
Epoch 49, Val Loss: 1.90276
Epoch 50, Val Loss: 1.90856
Epoch 51, Val Loss: 1.90704
Epoch 52, Val Loss: 1.90389
Epoch 53, Val Loss: 1.90562
Epoch 54, Val Loss: 1.90528
Epoch 55, Val Loss: 1.91002
Epoch 56, Val Loss: 1.90134
Epoch 57, Val Loss: 1.89402
Epoch 58, Val Loss: 1.90764
Epoch 59, Val Loss: 1.90623
Epoch 60, Val Loss: 1.90502
Epoch 61, Val Loss: 1.90294
Epoch 62, Val Loss: 1.92261
Epoch 63, Val Loss: 1.90396
Epoch 64, Val Loss: 1.90292
Epoch 65, Val Loss: 1.90138
Epoch 66, Val Loss: 1.91810
Epoch 67, Val Loss: 1.90824
Epoch 68, Val Loss: 1.89727
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.63515, 'Log Loss - std': 0.019449999999999967} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}
Fitted encoder
Epoch 0, Val Loss: 2.11006
Epoch 1, Val Loss: 2.11767
Epoch 2, Val Loss: 2.10616
Epoch 3, Val Loss: 2.08960
Epoch 4, Val Loss: 2.08193
Epoch 5, Val Loss: 2.08883
Epoch 6, Val Loss: 2.07403
Epoch 7, Val Loss: 2.09891
Epoch 8, Val Loss: 2.07323
Epoch 9, Val Loss: 2.06732
Epoch 10, Val Loss: 2.07492
Epoch 11, Val Loss: 2.07261
Epoch 12, Val Loss: 2.07772
Epoch 13, Val Loss: 2.07164
Epoch 14, Val Loss: 2.07298
Epoch 15, Val Loss: 2.07128
Epoch 16, Val Loss: 2.06855
Epoch 17, Val Loss: 2.07978
Epoch 18, Val Loss: 2.05501
Epoch 19, Val Loss: 2.08546
Epoch 20, Val Loss: 2.06902
Epoch 21, Val Loss: 2.06309
Epoch 22, Val Loss: 2.07575
Epoch 23, Val Loss: 2.06077
Epoch 24, Val Loss: 2.06003
Epoch 25, Val Loss: 2.06068
Epoch 26, Val Loss: 2.06282
Epoch 27, Val Loss: 2.04768
Epoch 28, Val Loss: 2.05100
Epoch 29, Val Loss: 2.05791
Epoch 30, Val Loss: 2.06053
Epoch 31, Val Loss: 2.04328
Epoch 32, Val Loss: 2.04521
Epoch 33, Val Loss: 2.05335
Epoch 34, Val Loss: 2.03723
Epoch 35, Val Loss: 2.05126
Epoch 36, Val Loss: 2.04288
Epoch 37, Val Loss: 2.04943
Epoch 38, Val Loss: 2.05122
Epoch 39, Val Loss: 2.05578
Epoch 40, Val Loss: 2.04088
Epoch 41, Val Loss: 2.04341
Epoch 42, Val Loss: 2.04969
Epoch 43, Val Loss: 2.03344
Epoch 44, Val Loss: 2.04293
Epoch 45, Val Loss: 2.04896
Epoch 46, Val Loss: 2.04566
Epoch 47, Val Loss: 2.04648
Epoch 48, Val Loss: 2.03624
Epoch 49, Val Loss: 2.02860
Epoch 50, Val Loss: 2.04516
Epoch 51, Val Loss: 2.02942
Epoch 52, Val Loss: 2.02751
Epoch 53, Val Loss: 2.02636
Epoch 54, Val Loss: 2.02031
Epoch 55, Val Loss: 2.04416
Epoch 56, Val Loss: 2.03345
Epoch 57, Val Loss: 2.04021
Epoch 58, Val Loss: 2.04679
Epoch 59, Val Loss: 2.03274
Epoch 60, Val Loss: 2.02886
Epoch 61, Val Loss: 2.04932
Epoch 62, Val Loss: 2.03613
Epoch 63, Val Loss: 2.04244
Epoch 64, Val Loss: 2.04572
Epoch 65, Val Loss: 2.03397
Epoch 66, Val Loss: 2.04193
Epoch 67, Val Loss: 2.03466
Epoch 68, Val Loss: 2.06021
Epoch 69, Val Loss: 2.03939
Epoch 70, Val Loss: 2.03929
Epoch 71, Val Loss: 2.03497
Epoch 72, Val Loss: 2.03629
Epoch 73, Val Loss: 2.03470
Epoch 74, Val Loss: 2.02670
Epoch 75, Val Loss: 2.03440
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.4957, 'Log Loss - std': 0.1978504654193834} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}
Fitted encoder
Epoch 0, Val Loss: 2.07834
Epoch 1, Val Loss: 2.07293
Epoch 2, Val Loss: 2.07194
Epoch 3, Val Loss: 2.07353
Epoch 4, Val Loss: 2.08284
Epoch 5, Val Loss: 2.06727
Epoch 6, Val Loss: 2.06718
Epoch 7, Val Loss: 2.05574
Epoch 8, Val Loss: 2.07416
Epoch 9, Val Loss: 2.06636
Epoch 10, Val Loss: 2.05577
Epoch 11, Val Loss: 2.06906
Epoch 12, Val Loss: 2.05804
Epoch 13, Val Loss: 2.04782
Epoch 14, Val Loss: 2.04752
Epoch 15, Val Loss: 2.05263
Epoch 16, Val Loss: 2.04492
Epoch 17, Val Loss: 2.05654
Epoch 18, Val Loss: 2.04316
Epoch 19, Val Loss: 2.05892
Epoch 20, Val Loss: 2.05571
Epoch 21, Val Loss: 2.04788
Epoch 22, Val Loss: 2.04227
Epoch 23, Val Loss: 2.05158
Epoch 24, Val Loss: 2.04136
Epoch 25, Val Loss: 2.05237
Epoch 26, Val Loss: 2.04911
Epoch 27, Val Loss: 2.03738
Epoch 28, Val Loss: 2.04158
Epoch 29, Val Loss: 2.04423
Epoch 30, Val Loss: 2.03545
Epoch 31, Val Loss: 2.04171
Epoch 32, Val Loss: 2.03907
Epoch 33, Val Loss: 2.03114
Epoch 34, Val Loss: 2.04528
Epoch 35, Val Loss: 2.04638
Epoch 36, Val Loss: 2.03746
Epoch 37, Val Loss: 2.03623
Epoch 38, Val Loss: 2.03702
Epoch 39, Val Loss: 2.03779
Epoch 40, Val Loss: 2.04166
Epoch 41, Val Loss: 2.03981
Epoch 42, Val Loss: 2.03748
Epoch 43, Val Loss: 2.03439
Epoch 44, Val Loss: 2.04157
Epoch 45, Val Loss: 2.02687
Epoch 46, Val Loss: 2.03134
Epoch 47, Val Loss: 2.04935
Epoch 48, Val Loss: 2.02395
Epoch 49, Val Loss: 2.03235
Epoch 50, Val Loss: 2.02964
Epoch 51, Val Loss: 2.02639
Epoch 52, Val Loss: 2.03200
Epoch 53, Val Loss: 2.03359
Epoch 54, Val Loss: 2.02299
Epoch 55, Val Loss: 2.02410
Epoch 56, Val Loss: 2.02563
Epoch 57, Val Loss: 2.02545
Epoch 58, Val Loss: 2.03640
Epoch 59, Val Loss: 2.03299
Epoch 60, Val Loss: 2.03594
Epoch 61, Val Loss: 2.02055
Epoch 62, Val Loss: 2.03658
Epoch 63, Val Loss: 2.02921
Epoch 64, Val Loss: 2.03908
Epoch 65, Val Loss: 2.02423
Epoch 66, Val Loss: 2.03505
Epoch 67, Val Loss: 2.03022
Epoch 68, Val Loss: 2.02771
Epoch 69, Val Loss: 2.02329
Epoch 70, Val Loss: 2.01764
Epoch 71, Val Loss: 2.01837
Epoch 72, Val Loss: 2.02725
Epoch 73, Val Loss: 2.02851
Epoch 74, Val Loss: 2.02873
Epoch 75, Val Loss: 2.01844
Epoch 76, Val Loss: 2.03010
Epoch 77, Val Loss: 2.02366
Epoch 78, Val Loss: 2.04139
Epoch 79, Val Loss: 2.02857
Epoch 80, Val Loss: 2.02891
Epoch 81, Val Loss: 2.03014
Epoch 82, Val Loss: 2.01873
Epoch 83, Val Loss: 2.03660
Epoch 84, Val Loss: 2.02036
Epoch 85, Val Loss: 2.02817
Epoch 86, Val Loss: 2.02964
Epoch 87, Val Loss: 2.02018
Epoch 88, Val Loss: 2.03088
Epoch 89, Val Loss: 2.01212
Epoch 90, Val Loss: 2.03624
Epoch 91, Val Loss: 2.02703
Epoch 92, Val Loss: 2.03020
Epoch 93, Val Loss: 2.01512
Epoch 94, Val Loss: 2.02600
Epoch 95, Val Loss: 2.02731
Epoch 96, Val Loss: 2.02685
Epoch 97, Val Loss: 2.03067
Epoch 98, Val Loss: 2.03971
Epoch 99, Val Loss: 2.03022
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.4029249999999998, 'Log Loss - std': 0.23490467614545257} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}
Fitted encoder
Epoch 0, Val Loss: 1.96145
Epoch 1, Val Loss: 1.96560
Epoch 2, Val Loss: 1.95445
Epoch 3, Val Loss: 1.95192
Epoch 4, Val Loss: 1.95530
Epoch 5, Val Loss: 1.95277
Epoch 6, Val Loss: 1.95070
Epoch 7, Val Loss: 1.95568
Epoch 8, Val Loss: 1.95697
Epoch 9, Val Loss: 1.95126
Epoch 10, Val Loss: 1.94855
Epoch 11, Val Loss: 1.96333
Epoch 12, Val Loss: 1.94542
Epoch 13, Val Loss: 1.94977
Epoch 14, Val Loss: 1.94749
Epoch 15, Val Loss: 1.95263
Epoch 16, Val Loss: 1.94432
Epoch 17, Val Loss: 1.96012
Epoch 18, Val Loss: 1.94861
Epoch 19, Val Loss: 1.94858
Epoch 20, Val Loss: 1.93787
Epoch 21, Val Loss: 1.94040
Epoch 22, Val Loss: 1.93863
Epoch 23, Val Loss: 1.94447
Epoch 24, Val Loss: 1.93673
Epoch 25, Val Loss: 1.94623
Epoch 26, Val Loss: 1.93528
Epoch 27, Val Loss: 1.92689
Epoch 28, Val Loss: 1.94611
Epoch 29, Val Loss: 1.92030
Epoch 30, Val Loss: 1.96355
Epoch 31, Val Loss: 1.92689
Epoch 32, Val Loss: 1.92386
Epoch 33, Val Loss: 1.92442
Epoch 34, Val Loss: 1.92866
Epoch 35, Val Loss: 1.92368
Epoch 36, Val Loss: 1.92497
Epoch 37, Val Loss: 1.91575
Epoch 38, Val Loss: 1.91947
Epoch 39, Val Loss: 1.93852
Epoch 40, Val Loss: 1.92549
Epoch 41, Val Loss: 1.91153
Epoch 42, Val Loss: 1.92274
Epoch 43, Val Loss: 1.90827
Epoch 44, Val Loss: 1.90588
Epoch 45, Val Loss: 1.93382
Epoch 46, Val Loss: 1.92749
Epoch 47, Val Loss: 1.90601
Epoch 48, Val Loss: 1.91611
Epoch 49, Val Loss: 1.90779
Epoch 50, Val Loss: 1.88473
Epoch 51, Val Loss: 1.90210
Epoch 52, Val Loss: 1.90968
Epoch 53, Val Loss: 1.89944
Epoch 54, Val Loss: 1.91602
Epoch 55, Val Loss: 1.88959
Epoch 56, Val Loss: 1.88659
Epoch 57, Val Loss: 1.91764
Epoch 58, Val Loss: 1.90161
Epoch 59, Val Loss: 1.90880
Epoch 60, Val Loss: 1.89325
Epoch 61, Val Loss: 1.91591
Epoch 62, Val Loss: 1.91355
Epoch 63, Val Loss: 1.89131
Epoch 64, Val Loss: 1.87489
Epoch 65, Val Loss: 1.88965
Epoch 66, Val Loss: 1.89307
Epoch 67, Val Loss: 1.92012
Epoch 68, Val Loss: 1.90306
Epoch 69, Val Loss: 1.89169
Epoch 70, Val Loss: 1.89210
Epoch 71, Val Loss: 1.88526
Epoch 72, Val Loss: 1.89434
Epoch 73, Val Loss: 1.88566
Epoch 74, Val Loss: 1.91353
Epoch 75, Val Loss: 1.88393
Epoch 76, Val Loss: 1.88698
Epoch 77, Val Loss: 1.88438
Epoch 78, Val Loss: 1.87543
Epoch 79, Val Loss: 1.89114
Epoch 80, Val Loss: 1.91006
Epoch 81, Val Loss: 1.88165
Epoch 82, Val Loss: 1.90312
Epoch 83, Val Loss: 1.89082
Epoch 84, Val Loss: 1.90180
Epoch 85, Val Loss: 1.90936
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.44212, 'Log Loss - std': 0.2242524416812445} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 43 finished with value: 2.44212 and parameters: {'p_m': 0.24756586189478408, 'alpha': 0.637280749766735, 'K': 15, 'beta': 5.719640476037917}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}
Fitted encoder
Epoch 0, Val Loss: 2.13916
Epoch 1, Val Loss: 2.14231
Epoch 2, Val Loss: 2.13342
Epoch 3, Val Loss: 2.14150
Epoch 4, Val Loss: 2.12837
Epoch 5, Val Loss: 2.14952
Epoch 6, Val Loss: 2.12402
Epoch 7, Val Loss: 2.12648
Epoch 8, Val Loss: 2.13908
Epoch 9, Val Loss: 2.12468
Epoch 10, Val Loss: 2.12368
Epoch 11, Val Loss: 2.12938
Epoch 12, Val Loss: 2.12691
Epoch 13, Val Loss: 2.13359
Epoch 14, Val Loss: 2.12412
Epoch 15, Val Loss: 2.12264
Epoch 16, Val Loss: 2.12057
Epoch 17, Val Loss: 2.12040
Epoch 18, Val Loss: 2.12115
Epoch 19, Val Loss: 2.12194
Epoch 20, Val Loss: 2.12777
Epoch 21, Val Loss: 2.11666
Epoch 22, Val Loss: 2.11760
Epoch 23, Val Loss: 2.11650
Epoch 24, Val Loss: 2.11547
Epoch 25, Val Loss: 2.12044
Epoch 26, Val Loss: 2.11783
Epoch 27, Val Loss: 2.12052
Epoch 28, Val Loss: 2.11452
Epoch 29, Val Loss: 2.11854
Epoch 30, Val Loss: 2.11826
Epoch 31, Val Loss: 2.11715
Epoch 32, Val Loss: 2.10918
Epoch 33, Val Loss: 2.12219
Epoch 34, Val Loss: 2.12793
Epoch 35, Val Loss: 2.14786
Epoch 36, Val Loss: 2.12340
Epoch 37, Val Loss: 2.11265
Epoch 38, Val Loss: 2.11449
Epoch 39, Val Loss: 2.11486
Epoch 40, Val Loss: 2.11219
Epoch 41, Val Loss: 2.12297
Epoch 42, Val Loss: 2.11876
Epoch 43, Val Loss: 2.10699
Epoch 44, Val Loss: 2.11504
Epoch 45, Val Loss: 2.11251
Epoch 46, Val Loss: 2.10415
Epoch 47, Val Loss: 2.11512
Epoch 48, Val Loss: 2.09353
Epoch 49, Val Loss: 2.11445
Epoch 50, Val Loss: 2.07881
Epoch 51, Val Loss: 2.06206
Epoch 52, Val Loss: 2.10991
Epoch 53, Val Loss: 2.09840
Epoch 54, Val Loss: 2.07214
Epoch 55, Val Loss: 2.07873
Epoch 56, Val Loss: 2.08852
Epoch 57, Val Loss: 2.07388
Epoch 58, Val Loss: 2.08468
Epoch 59, Val Loss: 2.08663
Epoch 60, Val Loss: 2.09020
Epoch 61, Val Loss: 2.09925
Epoch 62, Val Loss: 2.07015
Epoch 63, Val Loss: 2.08248
Epoch 64, Val Loss: 2.07496
Epoch 65, Val Loss: 2.07708
Epoch 66, Val Loss: 2.07955
Epoch 67, Val Loss: 2.08509
Epoch 68, Val Loss: 2.12209
Epoch 69, Val Loss: 2.08104
Epoch 70, Val Loss: 2.09693
Epoch 71, Val Loss: 2.09671
Epoch 72, Val Loss: 2.06523
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.4421, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}
Fitted encoder
Epoch 0, Val Loss: 1.95936
Epoch 1, Val Loss: 1.97168
Epoch 2, Val Loss: 1.95175
Epoch 3, Val Loss: 1.95217
Epoch 4, Val Loss: 1.95458
Epoch 5, Val Loss: 1.94833
Epoch 6, Val Loss: 1.93706
Epoch 7, Val Loss: 1.95277
Epoch 8, Val Loss: 1.95194
Epoch 9, Val Loss: 1.93782
Epoch 10, Val Loss: 1.93421
Epoch 11, Val Loss: 1.95508
Epoch 12, Val Loss: 1.93627
Epoch 13, Val Loss: 1.92048
Epoch 14, Val Loss: 1.92090
Epoch 15, Val Loss: 1.91470
Epoch 16, Val Loss: 1.93088
Epoch 17, Val Loss: 1.93994
Epoch 18, Val Loss: 1.93395
Epoch 19, Val Loss: 1.92989
Epoch 20, Val Loss: 1.92042
Epoch 21, Val Loss: 1.92223
Epoch 22, Val Loss: 1.92712
Epoch 23, Val Loss: 1.92735
Epoch 24, Val Loss: 1.90458
Epoch 25, Val Loss: 1.90359
Epoch 26, Val Loss: 1.95391
Epoch 27, Val Loss: 1.91161
Epoch 28, Val Loss: 1.91288
Epoch 29, Val Loss: 1.91198
Epoch 30, Val Loss: 1.91784
Epoch 31, Val Loss: 1.91320
Epoch 32, Val Loss: 1.89937
Epoch 33, Val Loss: 1.92383
Epoch 34, Val Loss: 1.90509
Epoch 35, Val Loss: 1.90127
Epoch 36, Val Loss: 1.91481
Epoch 37, Val Loss: 1.90938
Epoch 38, Val Loss: 1.92791
Epoch 39, Val Loss: 1.89324
Epoch 40, Val Loss: 1.93357
Epoch 41, Val Loss: 1.93998
Epoch 42, Val Loss: 1.92024
Epoch 43, Val Loss: 1.92034
Epoch 44, Val Loss: 1.90300
Epoch 45, Val Loss: 1.90847
Epoch 46, Val Loss: 1.89747
Epoch 47, Val Loss: 1.90623
Epoch 48, Val Loss: 1.90551
Epoch 49, Val Loss: 1.89561
Epoch 50, Val Loss: 1.91903
Epoch 51, Val Loss: 1.91144
Epoch 52, Val Loss: 1.91390
Epoch 53, Val Loss: 1.90067
Epoch 54, Val Loss: 1.91158
Epoch 55, Val Loss: 1.90717
Epoch 56, Val Loss: 1.90012
Epoch 57, Val Loss: 1.90632
Epoch 58, Val Loss: 1.90634
Epoch 59, Val Loss: 1.91148
Epoch 60, Val Loss: 1.89536
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.4349, 'Log Loss - std': 0.007199999999999873} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}
Fitted encoder
Epoch 0, Val Loss: 2.11607
Epoch 1, Val Loss: 2.12395
Epoch 2, Val Loss: 2.07808
Epoch 3, Val Loss: 2.07701
Epoch 4, Val Loss: 2.08386
Epoch 5, Val Loss: 2.07886
Epoch 6, Val Loss: 2.07531
Epoch 7, Val Loss: 2.07989
Epoch 8, Val Loss: 2.08578
Epoch 9, Val Loss: 2.06901
Epoch 10, Val Loss: 2.09354
Epoch 11, Val Loss: 2.08073
Epoch 12, Val Loss: 2.07374
Epoch 13, Val Loss: 2.11490
Epoch 14, Val Loss: 2.07539
Epoch 15, Val Loss: 2.08374
Epoch 16, Val Loss: 2.09696
Epoch 17, Val Loss: 2.07183
Epoch 18, Val Loss: 2.07694
Epoch 19, Val Loss: 2.09646
Epoch 20, Val Loss: 2.13597
Epoch 21, Val Loss: 2.07792
Epoch 22, Val Loss: 2.10799
Epoch 23, Val Loss: 2.07424
Epoch 24, Val Loss: 2.10990
Epoch 25, Val Loss: 2.11178
Epoch 26, Val Loss: 2.06618
Epoch 27, Val Loss: 2.07507
Epoch 28, Val Loss: 2.06773
Epoch 29, Val Loss: 2.07898
Epoch 30, Val Loss: 2.06662
Epoch 31, Val Loss: 2.07603
Epoch 32, Val Loss: 2.09354
Epoch 33, Val Loss: 2.06817
Epoch 34, Val Loss: 2.06508
Epoch 35, Val Loss: 2.07631
Epoch 36, Val Loss: 2.07549
Epoch 37, Val Loss: 2.07724
Epoch 38, Val Loss: 2.06209
Epoch 39, Val Loss: 2.06668
Epoch 40, Val Loss: 2.06302
Epoch 41, Val Loss: 2.08380
Epoch 42, Val Loss: 2.07404
Epoch 43, Val Loss: 2.07168
Epoch 44, Val Loss: 2.08210
Epoch 45, Val Loss: 2.06138
Epoch 46, Val Loss: 2.05541
Epoch 47, Val Loss: 2.06280
Epoch 48, Val Loss: 2.05206
Epoch 49, Val Loss: 2.06853
Epoch 50, Val Loss: 2.05775
Epoch 51, Val Loss: 2.06493
Epoch 52, Val Loss: 2.08867
Epoch 53, Val Loss: 2.06322
Epoch 54, Val Loss: 2.06533
Epoch 55, Val Loss: 2.05444
Epoch 56, Val Loss: 2.07956
Epoch 57, Val Loss: 2.07400
Epoch 58, Val Loss: 2.05001
Epoch 59, Val Loss: 2.05039
Epoch 60, Val Loss: 2.07667
Epoch 61, Val Loss: 2.08910
Epoch 62, Val Loss: 2.04421
Epoch 63, Val Loss: 2.03448
Epoch 64, Val Loss: 2.04293
Epoch 65, Val Loss: 2.02897
Epoch 66, Val Loss: 2.08848
Epoch 67, Val Loss: 2.05173
Epoch 68, Val Loss: 2.04350
Epoch 69, Val Loss: 2.05632
Epoch 70, Val Loss: 2.06672
Epoch 71, Val Loss: 2.03761
Epoch 72, Val Loss: 2.05975
Epoch 73, Val Loss: 2.02951
Epoch 74, Val Loss: 2.07764
Epoch 75, Val Loss: 2.07082
Epoch 76, Val Loss: 2.04655
Epoch 77, Val Loss: 2.04947
Epoch 78, Val Loss: 2.03737
Epoch 79, Val Loss: 2.04152
Epoch 80, Val Loss: 2.03072
Epoch 81, Val Loss: 2.02811
Epoch 82, Val Loss: 2.02793
Epoch 83, Val Loss: 2.03770
Epoch 84, Val Loss: 2.03132
Epoch 85, Val Loss: 2.05323
Epoch 86, Val Loss: 2.03063
Epoch 87, Val Loss: 2.02520
Epoch 88, Val Loss: 2.04329
Epoch 89, Val Loss: 2.03199
Epoch 90, Val Loss: 2.02772
Epoch 91, Val Loss: 2.01911
Epoch 92, Val Loss: 2.03169
Epoch 93, Val Loss: 2.02374
Epoch 94, Val Loss: 2.03964
Epoch 95, Val Loss: 2.03893
Epoch 96, Val Loss: 2.04368
Epoch 97, Val Loss: 2.02855
Epoch 98, Val Loss: 2.02183
Epoch 99, Val Loss: 2.02932
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.1748333333333334, 'Log Loss - std': 0.3678367874781181} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}
Fitted encoder
Epoch 0, Val Loss: 2.08396
Epoch 1, Val Loss: 2.07952
Epoch 2, Val Loss: 2.05938
Epoch 3, Val Loss: 2.05734
Epoch 4, Val Loss: 2.07313
Epoch 5, Val Loss: 2.06275
Epoch 6, Val Loss: 2.05276
Epoch 7, Val Loss: 2.06051
Epoch 8, Val Loss: 2.05534
Epoch 9, Val Loss: 2.05249
Epoch 10, Val Loss: 2.06005
Epoch 11, Val Loss: 2.06370
Epoch 12, Val Loss: 2.05826
Epoch 13, Val Loss: 2.05429
Epoch 14, Val Loss: 2.05211
Epoch 15, Val Loss: 2.06019
Epoch 16, Val Loss: 2.05706
Epoch 17, Val Loss: 2.05522
Epoch 18, Val Loss: 2.05510
Epoch 19, Val Loss: 2.06301
Epoch 20, Val Loss: 2.05793
Epoch 21, Val Loss: 2.05681
Epoch 22, Val Loss: 2.06507
Epoch 23, Val Loss: 2.05718
Epoch 24, Val Loss: 2.06516
Epoch 25, Val Loss: 2.05935
Epoch 26, Val Loss: 2.06165
Epoch 27, Val Loss: 2.05760
Epoch 28, Val Loss: 2.05571
Epoch 29, Val Loss: 2.05500
Epoch 30, Val Loss: 2.05867
Epoch 31, Val Loss: 2.05481
Epoch 32, Val Loss: 2.05345
Epoch 33, Val Loss: 2.05417
Epoch 34, Val Loss: 2.05528
Epoch 35, Val Loss: 2.05314
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.10705, 'Log Loss - std': 0.33950208762244743} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}
Fitted encoder
Epoch 0, Val Loss: 2.08039
Epoch 1, Val Loss: 1.95111
Epoch 2, Val Loss: 1.96542
Epoch 3, Val Loss: 1.95455
Epoch 4, Val Loss: 1.95138
Epoch 5, Val Loss: 1.94511
Epoch 6, Val Loss: 1.94535
Epoch 7, Val Loss: 1.94924
Epoch 8, Val Loss: 1.94583
Epoch 9, Val Loss: 1.94000
Epoch 10, Val Loss: 1.94493
Epoch 11, Val Loss: 1.94875
Epoch 12, Val Loss: 1.93571
Epoch 13, Val Loss: 1.90760
Epoch 14, Val Loss: 1.93579
Epoch 15, Val Loss: 1.90684
Epoch 16, Val Loss: 1.96173
Epoch 17, Val Loss: 1.94464
Epoch 18, Val Loss: 1.92478
Epoch 19, Val Loss: 1.91750
Epoch 20, Val Loss: 1.93153
Epoch 21, Val Loss: 1.91706
Epoch 22, Val Loss: 1.89329
Epoch 23, Val Loss: 1.92419
Epoch 24, Val Loss: 1.92197
Epoch 25, Val Loss: 1.89809
Epoch 26, Val Loss: 1.90040
Epoch 27, Val Loss: 1.89974
Epoch 28, Val Loss: 1.89232
Epoch 29, Val Loss: 1.89302
Epoch 30, Val Loss: 1.90119
Epoch 31, Val Loss: 1.90558
Epoch 32, Val Loss: 1.88981
Epoch 33, Val Loss: 1.90524
Epoch 34, Val Loss: 1.89428
Epoch 35, Val Loss: 1.89415
Epoch 36, Val Loss: 1.88730
Epoch 37, Val Loss: 1.88934
Epoch 38, Val Loss: 1.90516
Epoch 39, Val Loss: 1.88175
Epoch 40, Val Loss: 1.88366
Epoch 41, Val Loss: 1.90074
Epoch 42, Val Loss: 1.89680
Epoch 43, Val Loss: 1.90030
Epoch 44, Val Loss: 1.87878
Epoch 45, Val Loss: 1.88592
Epoch 46, Val Loss: 1.88233
Epoch 47, Val Loss: 1.89063
Epoch 48, Val Loss: 1.88016
Epoch 49, Val Loss: 1.91005
Epoch 50, Val Loss: 1.88711
Epoch 51, Val Loss: 1.91031
Epoch 52, Val Loss: 1.88679
Epoch 53, Val Loss: 1.89509
Epoch 54, Val Loss: 1.89073
Epoch 55, Val Loss: 1.90180
Epoch 56, Val Loss: 1.88513
Epoch 57, Val Loss: 1.90501
Epoch 58, Val Loss: 1.87991
Epoch 59, Val Loss: 1.91234
Epoch 60, Val Loss: 1.91004
Epoch 61, Val Loss: 1.88788
Epoch 62, Val Loss: 1.91166
Epoch 63, Val Loss: 1.89047
Epoch 64, Val Loss: 1.88057
Epoch 65, Val Loss: 1.89183
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.09438, 'Log Loss - std': 0.3047153583264224} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 44 finished with value: 3.09438 and parameters: {'p_m': 0.5227484545362692, 'alpha': 1.5907428285768632, 'K': 15, 'beta': 1.3086711023760984}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}
Fitted encoder
Epoch 0, Val Loss: 2.13580
Epoch 1, Val Loss: 2.13598
Epoch 2, Val Loss: 2.12578
Epoch 3, Val Loss: 2.11779
Epoch 4, Val Loss: 2.13370
Epoch 5, Val Loss: 2.12253
Epoch 6, Val Loss: 2.11354
Epoch 7, Val Loss: 2.10180
Epoch 8, Val Loss: 2.09653
Epoch 9, Val Loss: 2.12899
Epoch 10, Val Loss: 2.09642
Epoch 11, Val Loss: 2.10993
Epoch 12, Val Loss: 2.11437
Epoch 13, Val Loss: 2.10348
Epoch 14, Val Loss: 2.09492
Epoch 15, Val Loss: 2.09718
Epoch 16, Val Loss: 2.08107
Epoch 17, Val Loss: 2.08946
Epoch 18, Val Loss: 2.10194
Epoch 19, Val Loss: 2.08015
Epoch 20, Val Loss: 2.08634
Epoch 21, Val Loss: 2.09185
Epoch 22, Val Loss: 2.09227
Epoch 23, Val Loss: 2.08454
Epoch 24, Val Loss: 2.10102
Epoch 25, Val Loss: 2.06355
Epoch 26, Val Loss: 2.07103
Epoch 27, Val Loss: 2.08765
Epoch 28, Val Loss: 2.08950
Epoch 29, Val Loss: 2.09261
Epoch 30, Val Loss: 2.08322
Epoch 31, Val Loss: 2.08819
Epoch 32, Val Loss: 2.10614
Epoch 33, Val Loss: 2.08144
Epoch 34, Val Loss: 2.07459
Epoch 35, Val Loss: 2.08079
Epoch 36, Val Loss: 2.11155
Epoch 37, Val Loss: 2.07207
Epoch 38, Val Loss: 2.06474
Epoch 39, Val Loss: 2.10258
Epoch 40, Val Loss: 2.08841
Epoch 41, Val Loss: 2.06594
Epoch 42, Val Loss: 2.07090
Epoch 43, Val Loss: 2.06982
Epoch 44, Val Loss: 2.07593
Epoch 45, Val Loss: 2.07258
Epoch 46, Val Loss: 2.10181
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3438, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}
Fitted encoder
Epoch 0, Val Loss: 1.96515
Epoch 1, Val Loss: 1.99530
Epoch 2, Val Loss: 1.95700
Epoch 3, Val Loss: 1.95227
Epoch 4, Val Loss: 1.96630
Epoch 5, Val Loss: 1.94839
Epoch 6, Val Loss: 1.94992
Epoch 7, Val Loss: 1.94548
Epoch 8, Val Loss: 1.95420
Epoch 9, Val Loss: 1.94315
Epoch 10, Val Loss: 1.94453
Epoch 11, Val Loss: 1.94257
Epoch 12, Val Loss: 1.94568
Epoch 13, Val Loss: 1.94309
Epoch 14, Val Loss: 1.93950
Epoch 15, Val Loss: 1.94334
Epoch 16, Val Loss: 1.96051
Epoch 17, Val Loss: 1.94325
Epoch 18, Val Loss: 1.94540
Epoch 19, Val Loss: 1.94721
Epoch 20, Val Loss: 1.94327
Epoch 21, Val Loss: 1.94191
Epoch 22, Val Loss: 1.94414
Epoch 23, Val Loss: 1.93839
Epoch 24, Val Loss: 1.93888
Epoch 25, Val Loss: 1.95252
Epoch 26, Val Loss: 1.93937
Epoch 27, Val Loss: 1.94372
Epoch 28, Val Loss: 1.94349
Epoch 29, Val Loss: 1.94110
Epoch 30, Val Loss: 1.95506
Epoch 31, Val Loss: 1.94429
Epoch 32, Val Loss: 1.93312
Epoch 33, Val Loss: 1.94375
Epoch 34, Val Loss: 1.94453
Epoch 35, Val Loss: 1.94307
Epoch 36, Val Loss: 1.93625
Epoch 37, Val Loss: 1.92437
Epoch 38, Val Loss: 1.95056
Epoch 39, Val Loss: 1.93589
Epoch 40, Val Loss: 1.93218
Epoch 41, Val Loss: 1.92973
Epoch 42, Val Loss: 1.92855
Epoch 43, Val Loss: 1.92261
Epoch 44, Val Loss: 1.92195
Epoch 45, Val Loss: 1.94912
Epoch 46, Val Loss: 1.93315
Epoch 47, Val Loss: 1.93456
Epoch 48, Val Loss: 1.94844
Epoch 49, Val Loss: 1.93658
Epoch 50, Val Loss: 1.93815
Epoch 51, Val Loss: 1.92760
Epoch 52, Val Loss: 1.92279
Epoch 53, Val Loss: 1.93426
Epoch 54, Val Loss: 1.95312
Epoch 55, Val Loss: 1.92963
Epoch 56, Val Loss: 1.92439
Epoch 57, Val Loss: 1.90485
Epoch 58, Val Loss: 1.90615
Epoch 59, Val Loss: 1.90598
Epoch 60, Val Loss: 1.91170
Epoch 61, Val Loss: 1.92406
Epoch 62, Val Loss: 1.91988
Epoch 63, Val Loss: 1.91452
Epoch 64, Val Loss: 1.92051
Epoch 65, Val Loss: 1.92170
Epoch 66, Val Loss: 1.91888
Epoch 67, Val Loss: 1.90970
Epoch 68, Val Loss: 1.90622
Epoch 69, Val Loss: 1.91451
Epoch 70, Val Loss: 1.90159
Epoch 71, Val Loss: 1.90337
Epoch 72, Val Loss: 1.91835
Epoch 73, Val Loss: 1.90316
Epoch 74, Val Loss: 1.90981
Epoch 75, Val Loss: 1.91448
Epoch 76, Val Loss: 1.90724
Epoch 77, Val Loss: 1.91308
Epoch 78, Val Loss: 1.91311
Epoch 79, Val Loss: 1.90125
Epoch 80, Val Loss: 1.90502
Epoch 81, Val Loss: 1.90657
Epoch 82, Val Loss: 1.91140
Epoch 83, Val Loss: 1.92865
Epoch 84, Val Loss: 1.91082
Epoch 85, Val Loss: 1.90902
Epoch 86, Val Loss: 1.91347
Epoch 87, Val Loss: 1.92991
Epoch 88, Val Loss: 1.90932
Epoch 89, Val Loss: 1.90967
Epoch 90, Val Loss: 1.90596
Epoch 91, Val Loss: 1.90263
Epoch 92, Val Loss: 1.92197
Epoch 93, Val Loss: 1.91797
Epoch 94, Val Loss: 1.91224
Epoch 95, Val Loss: 1.89989
Epoch 96, Val Loss: 1.89990
Epoch 97, Val Loss: 1.91819
Epoch 98, Val Loss: 1.90692
Epoch 99, Val Loss: 1.90556
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.4551, 'Log Loss - std': 0.11129999999999995} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}
Fitted encoder
Epoch 0, Val Loss: 2.12939
Epoch 1, Val Loss: 2.12925
Epoch 2, Val Loss: 2.13167
Epoch 3, Val Loss: 2.12290
Epoch 4, Val Loss: 2.11472
Epoch 5, Val Loss: 2.08211
Epoch 6, Val Loss: 2.08011
Epoch 7, Val Loss: 2.10154
Epoch 8, Val Loss: 2.08362
Epoch 9, Val Loss: 2.12364
Epoch 10, Val Loss: 2.07453
Epoch 11, Val Loss: 2.09138
Epoch 12, Val Loss: 2.09080
Epoch 13, Val Loss: 2.09244
Epoch 14, Val Loss: 2.07338
Epoch 15, Val Loss: 2.06274
Epoch 16, Val Loss: 2.06224
Epoch 17, Val Loss: 2.08803
Epoch 18, Val Loss: 2.07452
Epoch 19, Val Loss: 2.08271
Epoch 20, Val Loss: 2.07233
Epoch 21, Val Loss: 2.05659
Epoch 22, Val Loss: 2.06047
Epoch 23, Val Loss: 2.08102
Epoch 24, Val Loss: 2.08010
Epoch 25, Val Loss: 2.06459
Epoch 26, Val Loss: 2.06197
Epoch 27, Val Loss: 2.05999
Epoch 28, Val Loss: 2.05790
Epoch 29, Val Loss: 2.05930
Epoch 30, Val Loss: 2.09212
Epoch 31, Val Loss: 2.06016
Epoch 32, Val Loss: 2.05906
Epoch 33, Val Loss: 2.07870
Epoch 34, Val Loss: 2.04309
Epoch 35, Val Loss: 2.05192
Epoch 36, Val Loss: 2.04233
Epoch 37, Val Loss: 2.05467
Epoch 38, Val Loss: 2.04042
Epoch 39, Val Loss: 2.04616
Epoch 40, Val Loss: 2.05657
Epoch 41, Val Loss: 2.03957
Epoch 42, Val Loss: 2.05462
Epoch 43, Val Loss: 2.08015
Epoch 44, Val Loss: 2.05878
Epoch 45, Val Loss: 2.07146
Epoch 46, Val Loss: 2.07217
Epoch 47, Val Loss: 2.04655
Epoch 48, Val Loss: 2.03278
Epoch 49, Val Loss: 2.02922
Epoch 50, Val Loss: 2.03540
Epoch 51, Val Loss: 2.03875
Epoch 52, Val Loss: 2.03095
Epoch 53, Val Loss: 2.03942
Epoch 54, Val Loss: 2.03845
Epoch 55, Val Loss: 2.03398
Epoch 56, Val Loss: 2.04038
Epoch 57, Val Loss: 2.04662
Epoch 58, Val Loss: 2.03731
Epoch 59, Val Loss: 2.03466
Epoch 60, Val Loss: 2.04279
Epoch 61, Val Loss: 2.03368
Epoch 62, Val Loss: 2.03629
Epoch 63, Val Loss: 2.03841
Epoch 64, Val Loss: 2.03840
Epoch 65, Val Loss: 2.04545
Epoch 66, Val Loss: 2.04269
Epoch 67, Val Loss: 2.04068
Epoch 68, Val Loss: 2.04709
Epoch 69, Val Loss: 2.04611
Epoch 70, Val Loss: 2.05614
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.035, 'Log Loss - std': 0.6010211976295012} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}
Fitted encoder
Epoch 0, Val Loss: 2.09164
Epoch 1, Val Loss: 2.06324
Epoch 2, Val Loss: 2.06512
Epoch 3, Val Loss: 2.06776
Epoch 4, Val Loss: 2.08558
Epoch 5, Val Loss: 2.06550
Epoch 6, Val Loss: 2.05914
Epoch 7, Val Loss: 2.05965
Epoch 8, Val Loss: 2.07276
Epoch 9, Val Loss: 2.05204
Epoch 10, Val Loss: 2.06659
Epoch 11, Val Loss: 2.07747
Epoch 12, Val Loss: 2.06255
Epoch 13, Val Loss: 2.05771
Epoch 14, Val Loss: 2.05988
Epoch 15, Val Loss: 2.04845
Epoch 16, Val Loss: 2.05454
Epoch 17, Val Loss: 2.04615
Epoch 18, Val Loss: 2.02957
Epoch 19, Val Loss: 2.05298
Epoch 20, Val Loss: 2.03365
Epoch 21, Val Loss: 2.05757
Epoch 22, Val Loss: 2.04377
Epoch 23, Val Loss: 2.04648
Epoch 24, Val Loss: 2.03948
Epoch 25, Val Loss: 2.05638
Epoch 26, Val Loss: 2.03089
Epoch 27, Val Loss: 2.04734
Epoch 28, Val Loss: 2.04807
Epoch 29, Val Loss: 2.03583
Epoch 30, Val Loss: 2.02509
Epoch 31, Val Loss: 2.02533
Epoch 32, Val Loss: 2.02251
Epoch 33, Val Loss: 2.03355
Epoch 34, Val Loss: 2.03008
Epoch 35, Val Loss: 2.04862
Epoch 36, Val Loss: 2.03931
Epoch 37, Val Loss: 2.02832
Epoch 38, Val Loss: 2.03587
Epoch 39, Val Loss: 2.03447
Epoch 40, Val Loss: 2.03707
Epoch 41, Val Loss: 2.03817
Epoch 42, Val Loss: 2.04544
Epoch 43, Val Loss: 2.02850
Epoch 44, Val Loss: 2.04972
Epoch 45, Val Loss: 2.03226
Epoch 46, Val Loss: 2.03280
Epoch 47, Val Loss: 2.04004
Epoch 48, Val Loss: 2.05148
Epoch 49, Val Loss: 2.02784
Epoch 50, Val Loss: 2.02342
Epoch 51, Val Loss: 2.02284
Epoch 52, Val Loss: 2.03337
Epoch 53, Val Loss: 2.03478
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.812125, 'Log Loss - std': 0.6480275124367791} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}
Fitted encoder
Epoch 0, Val Loss: 1.96071
Epoch 1, Val Loss: 1.95886
Epoch 2, Val Loss: 1.94794
Epoch 3, Val Loss: 1.95099
Epoch 4, Val Loss: 1.96188
Epoch 5, Val Loss: 1.95581
Epoch 6, Val Loss: 1.94995
Epoch 7, Val Loss: 1.95149
Epoch 8, Val Loss: 1.95026
Epoch 9, Val Loss: 1.95050
Epoch 10, Val Loss: 1.95763
Epoch 11, Val Loss: 1.95065
Epoch 12, Val Loss: 1.94596
Epoch 13, Val Loss: 1.94891
Epoch 14, Val Loss: 1.94598
Epoch 15, Val Loss: 1.94967
Epoch 16, Val Loss: 1.94672
Epoch 17, Val Loss: 1.94478
Epoch 18, Val Loss: 1.94257
Epoch 19, Val Loss: 1.94228
Epoch 20, Val Loss: 1.94962
Epoch 21, Val Loss: 1.94167
Epoch 22, Val Loss: 1.93445
Epoch 23, Val Loss: 1.94843
Epoch 24, Val Loss: 1.93478
Epoch 25, Val Loss: 1.94732
Epoch 26, Val Loss: 1.94000
Epoch 27, Val Loss: 1.94396
Epoch 28, Val Loss: 1.94978
Epoch 29, Val Loss: 1.93627
Epoch 30, Val Loss: 1.94102
Epoch 31, Val Loss: 1.93658
Epoch 32, Val Loss: 1.92960
Epoch 33, Val Loss: 1.94178
Epoch 34, Val Loss: 1.91990
Epoch 35, Val Loss: 1.92327
Epoch 36, Val Loss: 1.92090
Epoch 37, Val Loss: 1.91658
Epoch 38, Val Loss: 1.91408
Epoch 39, Val Loss: 1.92452
Epoch 40, Val Loss: 1.93178
Epoch 41, Val Loss: 1.93336
Epoch 42, Val Loss: 1.93128
Epoch 43, Val Loss: 1.92488
Epoch 44, Val Loss: 1.90807
Epoch 45, Val Loss: 1.93951
Epoch 46, Val Loss: 1.91498
Epoch 47, Val Loss: 1.89796
Epoch 48, Val Loss: 1.92874
Epoch 49, Val Loss: 1.90686
Epoch 50, Val Loss: 1.88929
Epoch 51, Val Loss: 1.91361
Epoch 52, Val Loss: 1.93893
Epoch 53, Val Loss: 1.91449
Epoch 54, Val Loss: 1.90479
Epoch 55, Val Loss: 1.90154
Epoch 56, Val Loss: 1.88759
Epoch 57, Val Loss: 1.89569
Epoch 58, Val Loss: 1.90850
Epoch 59, Val Loss: 1.89396
Epoch 60, Val Loss: 1.91295
Epoch 61, Val Loss: 1.90191
Epoch 62, Val Loss: 1.89555
Epoch 63, Val Loss: 1.90284
Epoch 64, Val Loss: 1.92683
Epoch 65, Val Loss: 1.89405
Epoch 66, Val Loss: 1.88726
Epoch 67, Val Loss: 1.92115
Epoch 68, Val Loss: 1.89375
Epoch 69, Val Loss: 1.90415
Epoch 70, Val Loss: 1.92641
Epoch 71, Val Loss: 1.90520
Epoch 72, Val Loss: 1.90130
Epoch 73, Val Loss: 1.91376
Epoch 74, Val Loss: 1.89178
Epoch 75, Val Loss: 1.89334
Epoch 76, Val Loss: 1.89200
Epoch 77, Val Loss: 1.90642
Epoch 78, Val Loss: 1.89699
Epoch 79, Val Loss: 1.88732
Epoch 80, Val Loss: 1.88646
Epoch 81, Val Loss: 1.90392
Epoch 82, Val Loss: 1.94115
Epoch 83, Val Loss: 1.89857
Epoch 84, Val Loss: 1.87975
Epoch 85, Val Loss: 1.90188
Epoch 86, Val Loss: 1.92460
Epoch 87, Val Loss: 1.89860
Epoch 88, Val Loss: 1.92116
Epoch 89, Val Loss: 1.92346
Epoch 90, Val Loss: 1.89051
Epoch 91, Val Loss: 1.89720
Epoch 92, Val Loss: 1.89384
Epoch 93, Val Loss: 1.89100
Epoch 94, Val Loss: 1.91985
Epoch 95, Val Loss: 1.89045
Epoch 96, Val Loss: 1.92115
Epoch 97, Val Loss: 1.89731
Epoch 98, Val Loss: 1.89494
Epoch 99, Val Loss: 1.95669
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.83794, 'Log Loss - std': 0.5819083969148409} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 45 finished with value: 2.83794 and parameters: {'p_m': 0.4314685045571801, 'alpha': 2.460933575348931, 'K': 20, 'beta': 3.001962842232472}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}
Fitted encoder
Epoch 0, Val Loss: 2.13820
Epoch 1, Val Loss: 2.10704
Epoch 2, Val Loss: 2.14159
Epoch 3, Val Loss: 2.10880
Epoch 4, Val Loss: 2.10190
Epoch 5, Val Loss: 2.11692
Epoch 6, Val Loss: 2.11169
Epoch 7, Val Loss: 2.11025
Epoch 8, Val Loss: 2.13273
Epoch 9, Val Loss: 2.09260
Epoch 10, Val Loss: 2.11308
Epoch 11, Val Loss: 2.09758
Epoch 12, Val Loss: 2.09079
Epoch 13, Val Loss: 2.10447
Epoch 14, Val Loss: 2.09063
Epoch 15, Val Loss: 2.10265
Epoch 16, Val Loss: 2.08198
Epoch 17, Val Loss: 2.11554
Epoch 18, Val Loss: 2.09879
Epoch 19, Val Loss: 2.09019
Epoch 20, Val Loss: 2.10274
Epoch 21, Val Loss: 2.10571
Epoch 22, Val Loss: 2.10525
Epoch 23, Val Loss: 2.08635
Epoch 24, Val Loss: 2.12522
Epoch 25, Val Loss: 2.12608
Epoch 26, Val Loss: 2.10757
Epoch 27, Val Loss: 2.10093
Epoch 28, Val Loss: 2.09309
Epoch 29, Val Loss: 2.10685
Epoch 30, Val Loss: 2.08728
Epoch 31, Val Loss: 2.08934
Epoch 32, Val Loss: 2.10797
Epoch 33, Val Loss: 2.07272
Epoch 34, Val Loss: 2.07316
Epoch 35, Val Loss: 2.06737
Epoch 36, Val Loss: 2.07112
Epoch 37, Val Loss: 2.10857
Epoch 38, Val Loss: 2.07497
Epoch 39, Val Loss: 2.09339
Epoch 40, Val Loss: 2.09317
Epoch 41, Val Loss: 2.09643
Epoch 42, Val Loss: 2.07946
Epoch 43, Val Loss: 2.10030
Epoch 44, Val Loss: 2.12134
Epoch 45, Val Loss: 2.10953
Epoch 46, Val Loss: 2.07056
Epoch 47, Val Loss: 2.07650
Epoch 48, Val Loss: 2.06244
Epoch 49, Val Loss: 2.07313
Epoch 50, Val Loss: 2.08395
Epoch 51, Val Loss: 2.08852
Epoch 52, Val Loss: 2.05818
Epoch 53, Val Loss: 2.06836
Epoch 54, Val Loss: 2.03824
Epoch 55, Val Loss: 2.07267
Epoch 56, Val Loss: 2.03028
Epoch 57, Val Loss: 2.06388
Epoch 58, Val Loss: 2.05847
Epoch 59, Val Loss: 2.06922
Epoch 60, Val Loss: 2.04521
Epoch 61, Val Loss: 2.05041
Epoch 62, Val Loss: 2.05630
Epoch 63, Val Loss: 2.05296
Epoch 64, Val Loss: 2.05739
Epoch 65, Val Loss: 2.03311
Epoch 66, Val Loss: 2.06911
Epoch 67, Val Loss: 2.07351
Epoch 68, Val Loss: 2.03928
Epoch 69, Val Loss: 2.04693
Epoch 70, Val Loss: 2.07944
Epoch 71, Val Loss: 2.06200
Epoch 72, Val Loss: 2.04625
Epoch 73, Val Loss: 2.03887
Epoch 74, Val Loss: 2.06901
Epoch 75, Val Loss: 2.07053
Epoch 76, Val Loss: 2.03213
Epoch 77, Val Loss: 2.04043
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.2455, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}
Fitted encoder
Epoch 0, Val Loss: 1.96025
Epoch 1, Val Loss: 2.02694
Epoch 2, Val Loss: 1.96253
Epoch 3, Val Loss: 1.96253
Epoch 4, Val Loss: 1.95376
Epoch 5, Val Loss: 1.97269
Epoch 6, Val Loss: 1.96302
Epoch 7, Val Loss: 1.95221
Epoch 8, Val Loss: 1.95067
Epoch 9, Val Loss: 1.96575
Epoch 10, Val Loss: 1.96051
Epoch 11, Val Loss: 1.94358
Epoch 12, Val Loss: 1.94423
Epoch 13, Val Loss: 1.94692
Epoch 14, Val Loss: 1.95438
Epoch 15, Val Loss: 1.94847
Epoch 16, Val Loss: 1.93981
Epoch 17, Val Loss: 1.96813
Epoch 18, Val Loss: 1.95678
Epoch 19, Val Loss: 1.93932
Epoch 20, Val Loss: 1.95546
Epoch 21, Val Loss: 1.95032
Epoch 22, Val Loss: 1.94495
Epoch 23, Val Loss: 1.95020
Epoch 24, Val Loss: 1.94997
Epoch 25, Val Loss: 1.95136
Epoch 26, Val Loss: 1.93494
Epoch 27, Val Loss: 1.93452
Epoch 28, Val Loss: 1.93738
Epoch 29, Val Loss: 1.94767
Epoch 30, Val Loss: 1.91499
Epoch 31, Val Loss: 1.91094
Epoch 32, Val Loss: 1.96170
Epoch 33, Val Loss: 1.96396
Epoch 34, Val Loss: 1.92862
Epoch 35, Val Loss: 1.92396
Epoch 36, Val Loss: 1.92718
Epoch 37, Val Loss: 1.96886
Epoch 38, Val Loss: 1.93612
Epoch 39, Val Loss: 1.93029
Epoch 40, Val Loss: 1.92351
Epoch 41, Val Loss: 1.93056
Epoch 42, Val Loss: 1.91620
Epoch 43, Val Loss: 1.96127
Epoch 44, Val Loss: 1.97884
Epoch 45, Val Loss: 1.95562
Epoch 46, Val Loss: 1.95331
Epoch 47, Val Loss: 1.95189
Epoch 48, Val Loss: 1.92295
Epoch 49, Val Loss: 1.91688
Epoch 50, Val Loss: 1.92919
Epoch 51, Val Loss: 1.94639
Epoch 52, Val Loss: 1.93932
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.4881, 'Log Loss - std': 0.24260000000000015} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}
Fitted encoder
Epoch 0, Val Loss: 2.13680
Epoch 1, Val Loss: 2.13289
Epoch 2, Val Loss: 2.14463
Epoch 3, Val Loss: 2.11847
Epoch 4, Val Loss: 2.11293
Epoch 5, Val Loss: 2.12317
Epoch 6, Val Loss: 2.11968
Epoch 7, Val Loss: 2.12350
Epoch 8, Val Loss: 2.12435
Epoch 9, Val Loss: 2.12099
Epoch 10, Val Loss: 2.11847
Epoch 11, Val Loss: 2.11089
Epoch 12, Val Loss: 2.12092
Epoch 13, Val Loss: 2.10821
Epoch 14, Val Loss: 2.11259
Epoch 15, Val Loss: 2.10424
Epoch 16, Val Loss: 2.11550
Epoch 17, Val Loss: 2.10817
Epoch 18, Val Loss: 2.10585
Epoch 19, Val Loss: 2.08728
Epoch 20, Val Loss: 2.09245
Epoch 21, Val Loss: 2.08164
Epoch 22, Val Loss: 2.09132
Epoch 23, Val Loss: 2.12441
Epoch 24, Val Loss: 2.10262
Epoch 25, Val Loss: 2.11974
Epoch 26, Val Loss: 2.11053
Epoch 27, Val Loss: 2.09744
Epoch 28, Val Loss: 2.10094
Epoch 29, Val Loss: 2.09609
Epoch 30, Val Loss: 2.09566
Epoch 31, Val Loss: 2.09996
Epoch 32, Val Loss: 2.11313
Epoch 33, Val Loss: 2.11593
Epoch 34, Val Loss: 2.09064
Epoch 35, Val Loss: 2.08796
Epoch 36, Val Loss: 2.09647
Epoch 37, Val Loss: 2.08250
Epoch 38, Val Loss: 2.09979
Epoch 39, Val Loss: 2.10066
Epoch 40, Val Loss: 2.09005
Epoch 41, Val Loss: 2.08774
Epoch 42, Val Loss: 2.09429
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6123, 'Log Loss - std': 0.2647409803310903} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}
Fitted encoder
Epoch 0, Val Loss: 2.07809
Epoch 1, Val Loss: 2.08101
Epoch 2, Val Loss: 2.06268
Epoch 3, Val Loss: 2.08597
Epoch 4, Val Loss: 2.08123
Epoch 5, Val Loss: 2.06517
Epoch 6, Val Loss: 2.06964
Epoch 7, Val Loss: 2.09854
Epoch 8, Val Loss: 2.06945
Epoch 9, Val Loss: 2.06422
Epoch 10, Val Loss: 2.06223
Epoch 11, Val Loss: 2.07186
Epoch 12, Val Loss: 2.05968
Epoch 13, Val Loss: 2.06571
Epoch 14, Val Loss: 2.07189
Epoch 15, Val Loss: 2.06452
Epoch 16, Val Loss: 2.07068
Epoch 17, Val Loss: 2.06129
Epoch 18, Val Loss: 2.08912
Epoch 19, Val Loss: 2.05877
Epoch 20, Val Loss: 2.05614
Epoch 21, Val Loss: 2.05601
Epoch 22, Val Loss: 2.06960
Epoch 23, Val Loss: 2.05794
Epoch 24, Val Loss: 2.05775
Epoch 25, Val Loss: 2.07530
Epoch 26, Val Loss: 2.05782
Epoch 27, Val Loss: 2.05953
Epoch 28, Val Loss: 2.07168
Epoch 29, Val Loss: 2.06533
Epoch 30, Val Loss: 2.06272
Epoch 31, Val Loss: 2.04747
Epoch 32, Val Loss: 2.05336
Epoch 33, Val Loss: 2.04172
Epoch 34, Val Loss: 2.04489
Epoch 35, Val Loss: 2.05236
Epoch 36, Val Loss: 2.04213
Epoch 37, Val Loss: 2.06434
Epoch 38, Val Loss: 2.06159
Epoch 39, Val Loss: 2.07570
Epoch 40, Val Loss: 2.03023
Epoch 41, Val Loss: 2.01817
Epoch 42, Val Loss: 2.03127
Epoch 43, Val Loss: 2.04398
Epoch 44, Val Loss: 2.01590
Epoch 45, Val Loss: 2.01994
Epoch 46, Val Loss: 2.06337
Epoch 47, Val Loss: 2.04659
Epoch 48, Val Loss: 2.03717
Epoch 49, Val Loss: 2.01794
Epoch 50, Val Loss: 2.05640
Epoch 51, Val Loss: 2.03540
Epoch 52, Val Loss: 2.03850
Epoch 53, Val Loss: 2.01644
Epoch 54, Val Loss: 2.05177
Epoch 55, Val Loss: 2.04024
Epoch 56, Val Loss: 2.03348
Epoch 57, Val Loss: 2.04316
Epoch 58, Val Loss: 2.02076
Epoch 59, Val Loss: 2.12132
Epoch 60, Val Loss: 2.01510
Epoch 61, Val Loss: 2.02031
Epoch 62, Val Loss: 2.02849
Epoch 63, Val Loss: 2.04590
Epoch 64, Val Loss: 2.02782
Epoch 65, Val Loss: 2.02658
Epoch 66, Val Loss: 2.03686
Epoch 67, Val Loss: 2.03190
Epoch 68, Val Loss: 2.02313
Epoch 69, Val Loss: 2.02128
Epoch 70, Val Loss: 2.04678
Epoch 71, Val Loss: 2.01123
Epoch 72, Val Loss: 2.02305
Epoch 73, Val Loss: 2.04638
Epoch 74, Val Loss: 2.05037
Epoch 75, Val Loss: 2.02232
Epoch 76, Val Loss: 2.01106
Epoch 77, Val Loss: 2.02399
Epoch 78, Val Loss: 2.05110
Epoch 79, Val Loss: 2.01950
Epoch 80, Val Loss: 2.04766
Epoch 81, Val Loss: 2.01793
Epoch 82, Val Loss: 2.02218
Epoch 83, Val Loss: 2.06234
Epoch 84, Val Loss: 2.06312
Epoch 85, Val Loss: 2.06255
Epoch 86, Val Loss: 2.02533
Epoch 87, Val Loss: 2.02278
Epoch 88, Val Loss: 2.03425
Epoch 89, Val Loss: 2.03424
Epoch 90, Val Loss: 2.06772
Epoch 91, Val Loss: 2.03320
Epoch 92, Val Loss: 2.07736
Epoch 93, Val Loss: 2.02624
Epoch 94, Val Loss: 2.01399
Epoch 95, Val Loss: 2.04880
Epoch 96, Val Loss: 2.04248
Epoch 97, Val Loss: 2.01024
Epoch 98, Val Loss: 2.03329
Epoch 99, Val Loss: 2.02490
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.7483750000000002, 'Log Loss - std': 0.3288085413656404} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}
Fitted encoder
Epoch 0, Val Loss: 1.96270
Epoch 1, Val Loss: 1.97775
Epoch 2, Val Loss: 1.95716
Epoch 3, Val Loss: 1.96454
Epoch 4, Val Loss: 1.95066
Epoch 5, Val Loss: 1.95076
Epoch 6, Val Loss: 1.95258
Epoch 7, Val Loss: 1.94977
Epoch 8, Val Loss: 1.95562
Epoch 9, Val Loss: 1.94547
Epoch 10, Val Loss: 1.94895
Epoch 11, Val Loss: 1.97718
Epoch 12, Val Loss: 1.96604
Epoch 13, Val Loss: 1.95287
Epoch 14, Val Loss: 1.96041
Epoch 15, Val Loss: 1.96270
Epoch 16, Val Loss: 1.95430
Epoch 17, Val Loss: 1.94724
Epoch 18, Val Loss: 1.94337
Epoch 19, Val Loss: 1.96395
Epoch 20, Val Loss: 1.95660
Epoch 21, Val Loss: 1.95171
Epoch 22, Val Loss: 1.94658
Epoch 23, Val Loss: 1.94619
Epoch 24, Val Loss: 1.94747
Epoch 25, Val Loss: 1.97897
Epoch 26, Val Loss: 1.94240
Epoch 27, Val Loss: 1.95705
Epoch 28, Val Loss: 1.93886
Epoch 29, Val Loss: 1.93903
Epoch 30, Val Loss: 1.94809
Epoch 31, Val Loss: 1.97462
Epoch 32, Val Loss: 1.95763
Epoch 33, Val Loss: 1.94417
Epoch 34, Val Loss: 1.96194
Epoch 35, Val Loss: 1.93448
Epoch 36, Val Loss: 1.97330
Epoch 37, Val Loss: 1.97165
Epoch 38, Val Loss: 1.92926
Epoch 39, Val Loss: 1.92931
Epoch 40, Val Loss: 1.92409
Epoch 41, Val Loss: 1.96023
Epoch 42, Val Loss: 1.93363
Epoch 43, Val Loss: 1.93371
Epoch 44, Val Loss: 1.94721
Epoch 45, Val Loss: 1.95823
Epoch 46, Val Loss: 1.94638
Epoch 47, Val Loss: 1.93925
Epoch 48, Val Loss: 1.93763
Epoch 49, Val Loss: 1.91694
Epoch 50, Val Loss: 1.96348
Epoch 51, Val Loss: 1.91533
Epoch 52, Val Loss: 1.91496
Epoch 53, Val Loss: 1.93889
Epoch 54, Val Loss: 1.91769
Epoch 55, Val Loss: 1.94016
Epoch 56, Val Loss: 1.98117
Epoch 57, Val Loss: 1.90485
Epoch 58, Val Loss: 1.93802
Epoch 59, Val Loss: 1.93234
Epoch 60, Val Loss: 1.92525
Epoch 61, Val Loss: 1.96190
Epoch 62, Val Loss: 1.90847
Epoch 63, Val Loss: 1.93294
Epoch 64, Val Loss: 1.91935
Epoch 65, Val Loss: 1.93021
Epoch 66, Val Loss: 1.90010
Epoch 67, Val Loss: 1.91715
Epoch 68, Val Loss: 1.92150
Epoch 69, Val Loss: 1.91255
Epoch 70, Val Loss: 1.93572
Epoch 71, Val Loss: 1.91148
Epoch 72, Val Loss: 1.90632
Epoch 73, Val Loss: 1.91863
Epoch 74, Val Loss: 1.90836
Epoch 75, Val Loss: 1.89699
Epoch 76, Val Loss: 1.89201
Epoch 77, Val Loss: 1.91670
Epoch 78, Val Loss: 1.89808
Epoch 79, Val Loss: 1.90468
Epoch 80, Val Loss: 1.91088
Epoch 81, Val Loss: 1.90751
Epoch 82, Val Loss: 1.91142
Epoch 83, Val Loss: 1.89766
Epoch 84, Val Loss: 1.91849
Epoch 85, Val Loss: 1.90129
Epoch 86, Val Loss: 1.90065
Epoch 87, Val Loss: 1.90338
Epoch 88, Val Loss: 1.90743
Epoch 89, Val Loss: 1.90803
Epoch 90, Val Loss: 1.91592
Epoch 91, Val Loss: 1.90998
Epoch 92, Val Loss: 1.93457
Epoch 93, Val Loss: 1.91070
Epoch 94, Val Loss: 1.90072
Epoch 95, Val Loss: 1.92550
Epoch 96, Val Loss: 1.90307
Epoch 97, Val Loss: 1.90733
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.88106, 'Log Loss - std': 0.39612281226912444} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 46 finished with value: 2.88106 and parameters: {'p_m': 0.6867501264768, 'alpha': 5.6781759781283325, 'K': 3, 'beta': 4.567529151391249}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}
Fitted encoder
Epoch 0, Val Loss: 2.13718
Epoch 1, Val Loss: 2.10975
Epoch 2, Val Loss: 2.10585
Epoch 3, Val Loss: 2.09104
Epoch 4, Val Loss: 2.12785
Epoch 5, Val Loss: 2.09547
Epoch 6, Val Loss: 2.10769
Epoch 7, Val Loss: 2.13368
Epoch 8, Val Loss: 2.07402
Epoch 9, Val Loss: 2.12509
Epoch 10, Val Loss: 2.08947
Epoch 11, Val Loss: 2.08474
Epoch 12, Val Loss: 2.07995
Epoch 13, Val Loss: 2.07299
Epoch 14, Val Loss: 2.09437
Epoch 15, Val Loss: 2.05780
Epoch 16, Val Loss: 2.06417
Epoch 17, Val Loss: 2.06262
Epoch 18, Val Loss: 2.06616
Epoch 19, Val Loss: 2.07553
Epoch 20, Val Loss: 2.06986
Epoch 21, Val Loss: 2.06114
Epoch 22, Val Loss: 2.05226
Epoch 23, Val Loss: 2.06301
Epoch 24, Val Loss: 2.05024
Epoch 25, Val Loss: 2.10086
Epoch 26, Val Loss: 2.05128
Epoch 27, Val Loss: 2.04572
Epoch 28, Val Loss: 2.02890
Epoch 29, Val Loss: 2.03934
Epoch 30, Val Loss: 2.04892
Epoch 31, Val Loss: 2.04485
Epoch 32, Val Loss: 2.04268
Epoch 33, Val Loss: 2.05377
Epoch 34, Val Loss: 2.04444
Epoch 35, Val Loss: 2.04661
Epoch 36, Val Loss: 2.05030
Epoch 37, Val Loss: 2.03343
Epoch 38, Val Loss: 2.03034
Epoch 39, Val Loss: 2.07032
Epoch 40, Val Loss: 2.08018
Epoch 41, Val Loss: 2.04397
Epoch 42, Val Loss: 2.05785
Epoch 43, Val Loss: 2.05606
Epoch 44, Val Loss: 2.04324
Epoch 45, Val Loss: 2.03903
Epoch 46, Val Loss: 2.03957
Epoch 47, Val Loss: 2.04566
Epoch 48, Val Loss: 2.03542
Epoch 49, Val Loss: 2.02988
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.1941, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}
Fitted encoder
Epoch 0, Val Loss: 1.97060
Epoch 1, Val Loss: 1.96715
Epoch 2, Val Loss: 1.96987
Epoch 3, Val Loss: 1.96333
Epoch 4, Val Loss: 1.96266
Epoch 5, Val Loss: 1.97320
Epoch 6, Val Loss: 1.95106
Epoch 7, Val Loss: 1.94837
Epoch 8, Val Loss: 1.99144
Epoch 9, Val Loss: 1.95660
Epoch 10, Val Loss: 1.96259
Epoch 11, Val Loss: 1.96123
Epoch 12, Val Loss: 1.95201
Epoch 13, Val Loss: 1.96908
Epoch 14, Val Loss: 1.95938
Epoch 15, Val Loss: 1.94923
Epoch 16, Val Loss: 1.96993
Epoch 17, Val Loss: 1.99241
Epoch 18, Val Loss: 1.98083
Epoch 19, Val Loss: 1.98025
Epoch 20, Val Loss: 1.97384
Epoch 21, Val Loss: 1.96670
Epoch 22, Val Loss: 1.96511
Epoch 23, Val Loss: 1.97002
Epoch 24, Val Loss: 1.97412
Epoch 25, Val Loss: 1.96925
Epoch 26, Val Loss: 1.96997
Epoch 27, Val Loss: 1.96636
Epoch 28, Val Loss: 1.96421
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.3205, 'Log Loss - std': 0.12639999999999985} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}
Fitted encoder
Epoch 0, Val Loss: 2.14283
Epoch 1, Val Loss: 2.10523
Epoch 2, Val Loss: 2.08084
Epoch 3, Val Loss: 2.10920
Epoch 4, Val Loss: 2.08231
Epoch 5, Val Loss: 2.10735
Epoch 6, Val Loss: 2.07337
Epoch 7, Val Loss: 2.06877
Epoch 8, Val Loss: 2.06803
Epoch 9, Val Loss: 2.05998
Epoch 10, Val Loss: 2.06806
Epoch 11, Val Loss: 2.05269
Epoch 12, Val Loss: 2.06601
Epoch 13, Val Loss: 2.06658
Epoch 14, Val Loss: 2.13054
Epoch 15, Val Loss: 2.10443
Epoch 16, Val Loss: 2.09099
Epoch 17, Val Loss: 2.09596
Epoch 18, Val Loss: 2.06202
Epoch 19, Val Loss: 2.04997
Epoch 20, Val Loss: 2.04982
Epoch 21, Val Loss: 2.05095
Epoch 22, Val Loss: 2.04620
Epoch 23, Val Loss: 2.04825
Epoch 24, Val Loss: 2.03342
Epoch 25, Val Loss: 2.04306
Epoch 26, Val Loss: 2.03848
Epoch 27, Val Loss: 2.08590
Epoch 28, Val Loss: 2.07912
Epoch 29, Val Loss: 2.09062
Epoch 30, Val Loss: 2.10630
Epoch 31, Val Loss: 2.04088
Epoch 32, Val Loss: 2.05579
Epoch 33, Val Loss: 2.07688
Epoch 34, Val Loss: 2.06240
Epoch 35, Val Loss: 2.06189
Epoch 36, Val Loss: 2.06016
Epoch 37, Val Loss: 2.06715
Epoch 38, Val Loss: 2.06110
Epoch 39, Val Loss: 2.05758
Epoch 40, Val Loss: 2.05157
Epoch 41, Val Loss: 2.01980
Epoch 42, Val Loss: 2.05439
Epoch 43, Val Loss: 2.05472
Epoch 44, Val Loss: 2.10314
Epoch 45, Val Loss: 2.06711
Epoch 46, Val Loss: 2.05621
Epoch 47, Val Loss: 2.02957
Epoch 48, Val Loss: 2.03089
Epoch 49, Val Loss: 2.08573
Epoch 50, Val Loss: 2.06874
Epoch 51, Val Loss: 2.02786
Epoch 52, Val Loss: 2.02752
Epoch 53, Val Loss: 2.05775
Epoch 54, Val Loss: 2.03637
Epoch 55, Val Loss: 2.05521
Epoch 56, Val Loss: 2.07741
Epoch 57, Val Loss: 2.01300
Epoch 58, Val Loss: 2.09550
Epoch 59, Val Loss: 2.02022
Epoch 60, Val Loss: 2.06610
Epoch 61, Val Loss: 2.04895
Epoch 62, Val Loss: 2.02768
Epoch 63, Val Loss: 2.02908
Epoch 64, Val Loss: 2.02914
Epoch 65, Val Loss: 2.03097
Epoch 66, Val Loss: 2.07116
Epoch 67, Val Loss: 2.04371
Epoch 68, Val Loss: 2.05058
Epoch 69, Val Loss: 2.13822
Epoch 70, Val Loss: 2.03566
Epoch 71, Val Loss: 2.04603
Epoch 72, Val Loss: 2.03456
Epoch 73, Val Loss: 2.02973
Epoch 74, Val Loss: 2.02681
Epoch 75, Val Loss: 2.02407
Epoch 76, Val Loss: 2.02519
Epoch 77, Val Loss: 2.02228
Epoch 78, Val Loss: 2.01900
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.1611666666666665, 'Log Loss - std': 0.24784174161930211} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}
Fitted encoder
Epoch 0, Val Loss: 2.07099
Epoch 1, Val Loss: 2.13430
Epoch 2, Val Loss: 2.06960
Epoch 3, Val Loss: 2.05856
Epoch 4, Val Loss: 2.05111
Epoch 5, Val Loss: 2.06390
Epoch 6, Val Loss: 2.05426
Epoch 7, Val Loss: 2.05109
Epoch 8, Val Loss: 2.05560
Epoch 9, Val Loss: 2.07946
Epoch 10, Val Loss: 2.04415
Epoch 11, Val Loss: 2.03864
Epoch 12, Val Loss: 2.07713
Epoch 13, Val Loss: 2.14732
Epoch 14, Val Loss: 2.11956
Epoch 15, Val Loss: 2.11569
Epoch 16, Val Loss: 2.08818
Epoch 17, Val Loss: 2.09776
Epoch 18, Val Loss: 2.08417
Epoch 19, Val Loss: 2.03955
Epoch 20, Val Loss: 2.03549
Epoch 21, Val Loss: 2.02968
Epoch 22, Val Loss: 2.04374
Epoch 23, Val Loss: 2.04013
Epoch 24, Val Loss: 2.02542
Epoch 25, Val Loss: 2.02847
Epoch 26, Val Loss: 2.02442
Epoch 27, Val Loss: 2.02919
Epoch 28, Val Loss: 2.03611
Epoch 29, Val Loss: 2.03063
Epoch 30, Val Loss: 2.02819
Epoch 31, Val Loss: 2.03165
Epoch 32, Val Loss: 2.04942
Epoch 33, Val Loss: 2.01737
Epoch 34, Val Loss: 2.03043
Epoch 35, Val Loss: 2.01857
Epoch 36, Val Loss: 2.04683
Epoch 37, Val Loss: 2.02086
Epoch 38, Val Loss: 2.02793
Epoch 39, Val Loss: 2.02583
Epoch 40, Val Loss: 2.00994
Epoch 41, Val Loss: 2.03114
Epoch 42, Val Loss: 2.04561
Epoch 43, Val Loss: 2.02222
Epoch 44, Val Loss: 2.03460
Epoch 45, Val Loss: 2.02079
Epoch 46, Val Loss: 2.03680
Epoch 47, Val Loss: 2.04748
Epoch 48, Val Loss: 2.03287
Epoch 49, Val Loss: 2.03423
Epoch 50, Val Loss: 2.02258
Epoch 51, Val Loss: 2.03835
Epoch 52, Val Loss: 2.01877
Epoch 53, Val Loss: 2.05264
Epoch 54, Val Loss: 2.00727
Epoch 55, Val Loss: 2.01476
Epoch 56, Val Loss: 2.02909
Epoch 57, Val Loss: 2.03192
Epoch 58, Val Loss: 2.04740
Epoch 59, Val Loss: 2.01917
Epoch 60, Val Loss: 2.01658
Epoch 61, Val Loss: 2.02812
Epoch 62, Val Loss: 2.01823
Epoch 63, Val Loss: 2.01606
Epoch 64, Val Loss: 2.01498
Epoch 65, Val Loss: 2.02212
Epoch 66, Val Loss: 2.02956
Epoch 67, Val Loss: 2.01407
Epoch 68, Val Loss: 2.01674
Epoch 69, Val Loss: 2.03039
Epoch 70, Val Loss: 2.02778
Epoch 71, Val Loss: 2.02350
Epoch 72, Val Loss: 2.02307
Epoch 73, Val Loss: 2.03131
Epoch 74, Val Loss: 2.01110
Epoch 75, Val Loss: 2.02946
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.086875, 'Log Loss - std': 0.25025367504794016} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}
Fitted encoder
Epoch 0, Val Loss: 1.98652
Epoch 1, Val Loss: 1.96410
Epoch 2, Val Loss: 1.95438
Epoch 3, Val Loss: 1.94844
Epoch 4, Val Loss: 1.93949
Epoch 5, Val Loss: 1.96010
Epoch 6, Val Loss: 1.94599
Epoch 7, Val Loss: 1.92677
Epoch 8, Val Loss: 1.91542
Epoch 9, Val Loss: 1.94914
Epoch 10, Val Loss: 1.93332
Epoch 11, Val Loss: 1.92756
Epoch 12, Val Loss: 1.91846
Epoch 13, Val Loss: 1.93591
Epoch 14, Val Loss: 1.92405
Epoch 15, Val Loss: 1.92684
Epoch 16, Val Loss: 1.92112
Epoch 17, Val Loss: 1.89910
Epoch 18, Val Loss: 1.93335
Epoch 19, Val Loss: 1.91051
Epoch 20, Val Loss: 1.90786
Epoch 21, Val Loss: 1.90863
Epoch 22, Val Loss: 1.88846
Epoch 23, Val Loss: 1.90861
Epoch 24, Val Loss: 1.91806
Epoch 25, Val Loss: 1.92505
Epoch 26, Val Loss: 1.91332
Epoch 27, Val Loss: 1.93400
Epoch 28, Val Loss: 1.90613
Epoch 29, Val Loss: 1.90337
Epoch 30, Val Loss: 1.92563
Epoch 31, Val Loss: 1.90387
Epoch 32, Val Loss: 1.91852
Epoch 33, Val Loss: 1.92501
Epoch 34, Val Loss: 1.92728
Epoch 35, Val Loss: 1.90108
Epoch 36, Val Loss: 1.93665
Epoch 37, Val Loss: 1.91164
Epoch 38, Val Loss: 1.91029
Epoch 39, Val Loss: 1.93098
Epoch 40, Val Loss: 1.89962
Epoch 41, Val Loss: 1.88426
Epoch 42, Val Loss: 1.91607
Epoch 43, Val Loss: 1.90447
Epoch 44, Val Loss: 1.90208
Epoch 45, Val Loss: 1.89637
Epoch 46, Val Loss: 1.89181
Epoch 47, Val Loss: 1.89330
Epoch 48, Val Loss: 1.90657
Epoch 49, Val Loss: 1.90648
Epoch 50, Val Loss: 1.90392
Epoch 51, Val Loss: 1.87951
Epoch 52, Val Loss: 1.88655
Epoch 53, Val Loss: 1.90290
Epoch 54, Val Loss: 1.90484
Epoch 55, Val Loss: 1.88304
Epoch 56, Val Loss: 1.89155
Epoch 57, Val Loss: 1.89244
Epoch 58, Val Loss: 1.91696
Epoch 59, Val Loss: 1.88311
Epoch 60, Val Loss: 1.88996
Epoch 61, Val Loss: 1.90146
Epoch 62, Val Loss: 1.88165
Epoch 63, Val Loss: 1.91911
Epoch 64, Val Loss: 1.90678
Epoch 65, Val Loss: 1.92109
Epoch 66, Val Loss: 1.91591
Epoch 67, Val Loss: 1.89631
Epoch 68, Val Loss: 1.87951
Epoch 69, Val Loss: 1.92666
Epoch 70, Val Loss: 1.90941
Epoch 71, Val Loss: 1.90723
Epoch 72, Val Loss: 1.89569
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.1337400000000004, 'Log Loss - std': 0.2426660965194768} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 47 finished with value: 3.1337400000000004 and parameters: {'p_m': 0.7785909353484276, 'alpha': 1.0808919885903148, 'K': 10, 'beta': 6.698183574899565}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}
Fitted encoder
Epoch 0, Val Loss: 2.10579
Epoch 1, Val Loss: 2.11276
Epoch 2, Val Loss: 2.10064
Epoch 3, Val Loss: 2.10204
Epoch 4, Val Loss: 2.09759
Epoch 5, Val Loss: 2.10254
Epoch 6, Val Loss: 2.09438
Epoch 7, Val Loss: 2.11599
Epoch 8, Val Loss: 2.09101
Epoch 9, Val Loss: 2.09599
Epoch 10, Val Loss: 2.11053
Epoch 11, Val Loss: 2.09235
Epoch 12, Val Loss: 2.14312
Epoch 13, Val Loss: 2.11446
Epoch 14, Val Loss: 2.10588
Epoch 15, Val Loss: 2.09785
Epoch 16, Val Loss: 2.08815
Epoch 17, Val Loss: 2.09338
Epoch 18, Val Loss: 2.09792
Epoch 19, Val Loss: 2.09351
Epoch 20, Val Loss: 2.08694
Epoch 21, Val Loss: 2.09047
Epoch 22, Val Loss: 2.08601
Epoch 23, Val Loss: 2.10257
Epoch 24, Val Loss: 2.09077
Epoch 25, Val Loss: 2.09688
Epoch 26, Val Loss: 2.09189
Epoch 27, Val Loss: 2.09737
Epoch 28, Val Loss: 2.09998
Epoch 29, Val Loss: 2.09707
Epoch 30, Val Loss: 2.08849
Epoch 31, Val Loss: 2.09048
Epoch 32, Val Loss: 2.08631
Epoch 33, Val Loss: 2.09177
Epoch 34, Val Loss: 2.08298
Epoch 35, Val Loss: 2.09170
Epoch 36, Val Loss: 2.08572
Epoch 37, Val Loss: 2.09379
Epoch 38, Val Loss: 2.09337
Epoch 39, Val Loss: 2.09174
Epoch 40, Val Loss: 2.08830
Epoch 41, Val Loss: 2.09410
Epoch 42, Val Loss: 2.09462
Epoch 43, Val Loss: 2.08434
Epoch 44, Val Loss: 2.08266
Epoch 45, Val Loss: 2.11139
Epoch 46, Val Loss: 2.08631
Epoch 47, Val Loss: 2.08109
Epoch 48, Val Loss: 2.09058
Epoch 49, Val Loss: 2.11097
Epoch 50, Val Loss: 2.08844
Epoch 51, Val Loss: 2.09352
Epoch 52, Val Loss: 2.08792
Epoch 53, Val Loss: 2.08801
Epoch 54, Val Loss: 2.08890
Epoch 55, Val Loss: 2.08975
Epoch 56, Val Loss: 2.08813
Epoch 57, Val Loss: 2.12047
Epoch 58, Val Loss: 2.08436
Epoch 59, Val Loss: 2.10445
Epoch 60, Val Loss: 2.09142
Epoch 61, Val Loss: 2.08881
Epoch 62, Val Loss: 2.10478
Epoch 63, Val Loss: 2.08674
Epoch 64, Val Loss: 2.09708
Epoch 65, Val Loss: 2.08673
Epoch 66, Val Loss: 2.09642
Epoch 67, Val Loss: 2.08508
Epoch 68, Val Loss: 2.08475
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.2254, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}
Fitted encoder
Epoch 0, Val Loss: 1.97115
Epoch 1, Val Loss: 1.96760
Epoch 2, Val Loss: 1.96433
Epoch 3, Val Loss: 1.98167
Epoch 4, Val Loss: 1.96231
Epoch 5, Val Loss: 1.95092
Epoch 6, Val Loss: 1.97376
Epoch 7, Val Loss: 1.97522
Epoch 8, Val Loss: 1.97695
Epoch 9, Val Loss: 1.94873
Epoch 10, Val Loss: 1.94764
Epoch 11, Val Loss: 1.95965
Epoch 12, Val Loss: 1.94683
Epoch 13, Val Loss: 1.95837
Epoch 14, Val Loss: 1.95242
Epoch 15, Val Loss: 1.94804
Epoch 16, Val Loss: 1.94496
Epoch 17, Val Loss: 1.96308
Epoch 18, Val Loss: 1.94082
Epoch 19, Val Loss: 1.94129
Epoch 20, Val Loss: 1.93841
Epoch 21, Val Loss: 1.94518
Epoch 22, Val Loss: 1.93916
Epoch 23, Val Loss: 1.96145
Epoch 24, Val Loss: 1.94344
Epoch 25, Val Loss: 1.94347
Epoch 26, Val Loss: 1.92211
Epoch 27, Val Loss: 1.93348
Epoch 28, Val Loss: 1.92491
Epoch 29, Val Loss: 1.93499
Epoch 30, Val Loss: 1.93763
Epoch 31, Val Loss: 1.92092
Epoch 32, Val Loss: 1.95847
Epoch 33, Val Loss: 1.92697
Epoch 34, Val Loss: 1.93400
Epoch 35, Val Loss: 1.94319
Epoch 36, Val Loss: 1.92641
Epoch 37, Val Loss: 1.93181
Epoch 38, Val Loss: 1.91838
Epoch 39, Val Loss: 1.93247
Epoch 40, Val Loss: 1.93582
Epoch 41, Val Loss: 1.91336
Epoch 42, Val Loss: 1.91853
Epoch 43, Val Loss: 1.94770
Epoch 44, Val Loss: 1.91998
Epoch 45, Val Loss: 1.95916
Epoch 46, Val Loss: 1.92205
Epoch 47, Val Loss: 1.91629
Epoch 48, Val Loss: 1.92364
Epoch 49, Val Loss: 1.91087
Epoch 50, Val Loss: 1.92511
Epoch 51, Val Loss: 1.92658
Epoch 52, Val Loss: 1.92859
Epoch 53, Val Loss: 1.91070
Epoch 54, Val Loss: 1.91794
Epoch 55, Val Loss: 1.90186
Epoch 56, Val Loss: 1.93728
Epoch 57, Val Loss: 1.91135
Epoch 58, Val Loss: 1.91912
Epoch 59, Val Loss: 1.92527
Epoch 60, Val Loss: 1.93074
Epoch 61, Val Loss: 1.90961
Epoch 62, Val Loss: 1.93752
Epoch 63, Val Loss: 1.92221
Epoch 64, Val Loss: 1.90794
Epoch 65, Val Loss: 1.91468
Epoch 66, Val Loss: 1.91410
Epoch 67, Val Loss: 1.89883
Epoch 68, Val Loss: 1.91658
Epoch 69, Val Loss: 1.90950
Epoch 70, Val Loss: 1.91359
Epoch 71, Val Loss: 1.91892
Epoch 72, Val Loss: 1.90967
Epoch 73, Val Loss: 1.90570
Epoch 74, Val Loss: 1.90699
Epoch 75, Val Loss: 1.92716
Epoch 76, Val Loss: 1.91414
Epoch 77, Val Loss: 1.92297
Epoch 78, Val Loss: 1.91443
Epoch 79, Val Loss: 1.90989
Epoch 80, Val Loss: 1.91135
Epoch 81, Val Loss: 1.90259
Epoch 82, Val Loss: 1.90140
Epoch 83, Val Loss: 1.90838
Epoch 84, Val Loss: 1.90239
Epoch 85, Val Loss: 1.94784
Epoch 86, Val Loss: 1.92339
Epoch 87, Val Loss: 1.93033
Epoch 88, Val Loss: 1.91475
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.7314499999999997, 'Log Loss - std': 0.5060499999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}
Fitted encoder
Epoch 0, Val Loss: 2.14175
Epoch 1, Val Loss: 2.12713
Epoch 2, Val Loss: 2.11989
Epoch 3, Val Loss: 2.11269
Epoch 4, Val Loss: 2.11672
Epoch 5, Val Loss: 2.10909
Epoch 6, Val Loss: 2.11305
Epoch 7, Val Loss: 2.10027
Epoch 8, Val Loss: 2.11512
Epoch 9, Val Loss: 2.09421
Epoch 10, Val Loss: 2.09711
Epoch 11, Val Loss: 2.09828
Epoch 12, Val Loss: 2.08277
Epoch 13, Val Loss: 2.08457
Epoch 14, Val Loss: 2.08649
Epoch 15, Val Loss: 2.11437
Epoch 16, Val Loss: 2.07053
Epoch 17, Val Loss: 2.09378
Epoch 18, Val Loss: 2.09220
Epoch 19, Val Loss: 2.08187
Epoch 20, Val Loss: 2.08802
Epoch 21, Val Loss: 2.07855
Epoch 22, Val Loss: 2.08522
Epoch 23, Val Loss: 2.08340
Epoch 24, Val Loss: 2.08531
Epoch 25, Val Loss: 2.08022
Epoch 26, Val Loss: 2.05784
Epoch 27, Val Loss: 2.11435
Epoch 28, Val Loss: 2.11753
Epoch 29, Val Loss: 2.04518
Epoch 30, Val Loss: 2.06617
Epoch 31, Val Loss: 2.06948
Epoch 32, Val Loss: 2.05561
Epoch 33, Val Loss: 2.06522
Epoch 34, Val Loss: 2.07048
Epoch 35, Val Loss: 2.08375
Epoch 36, Val Loss: 2.03686
Epoch 37, Val Loss: 2.04410
Epoch 38, Val Loss: 2.03705
Epoch 39, Val Loss: 2.03979
Epoch 40, Val Loss: 2.09623
Epoch 41, Val Loss: 2.03843
Epoch 42, Val Loss: 2.11188
Epoch 43, Val Loss: 2.02998
Epoch 44, Val Loss: 2.04116
Epoch 45, Val Loss: 2.04154
Epoch 46, Val Loss: 2.04543
Epoch 47, Val Loss: 2.04126
Epoch 48, Val Loss: 2.03254
Epoch 49, Val Loss: 2.04439
Epoch 50, Val Loss: 2.03743
Epoch 51, Val Loss: 2.05852
Epoch 52, Val Loss: 2.02303
Epoch 53, Val Loss: 2.04370
Epoch 54, Val Loss: 2.03130
Epoch 55, Val Loss: 2.04510
Epoch 56, Val Loss: 2.03067
Epoch 57, Val Loss: 2.03317
Epoch 58, Val Loss: 2.04099
Epoch 59, Val Loss: 2.02724
Epoch 60, Val Loss: 2.02953
Epoch 61, Val Loss: 2.06294
Epoch 62, Val Loss: 2.03287
Epoch 63, Val Loss: 2.02964
Epoch 64, Val Loss: 2.02760
Epoch 65, Val Loss: 2.04875
Epoch 66, Val Loss: 2.01923
Epoch 67, Val Loss: 2.03192
Epoch 68, Val Loss: 2.03040
Epoch 69, Val Loss: 2.04706
Epoch 70, Val Loss: 2.07694
Epoch 71, Val Loss: 2.03006
Epoch 72, Val Loss: 2.04798
Epoch 73, Val Loss: 2.07863
Epoch 74, Val Loss: 2.03983
Epoch 75, Val Loss: 2.02953
Epoch 76, Val Loss: 2.03112
Epoch 77, Val Loss: 2.03605
Epoch 78, Val Loss: 2.04163
Epoch 79, Val Loss: 2.05371
Epoch 80, Val Loss: 2.05687
Epoch 81, Val Loss: 2.04535
Epoch 82, Val Loss: 2.02671
Epoch 83, Val Loss: 2.03563
Epoch 84, Val Loss: 2.06167
Epoch 85, Val Loss: 2.04171
Epoch 86, Val Loss: 2.04512
Epoch 87, Val Loss: 2.04010
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.6918666666666664, 'Log Loss - std': 0.4169629266760082} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}
Fitted encoder
Epoch 0, Val Loss: 2.08069
Epoch 1, Val Loss: 2.08527
Epoch 2, Val Loss: 2.06835
Epoch 3, Val Loss: 2.07313
Epoch 4, Val Loss: 2.06594
Epoch 5, Val Loss: 2.06793
Epoch 6, Val Loss: 2.06478
Epoch 7, Val Loss: 2.05788
Epoch 8, Val Loss: 2.07324
Epoch 9, Val Loss: 2.07353
Epoch 10, Val Loss: 2.06914
Epoch 11, Val Loss: 2.07345
Epoch 12, Val Loss: 2.07930
Epoch 13, Val Loss: 2.06930
Epoch 14, Val Loss: 2.07173
Epoch 15, Val Loss: 2.05731
Epoch 16, Val Loss: 2.05009
Epoch 17, Val Loss: 2.06950
Epoch 18, Val Loss: 2.06867
Epoch 19, Val Loss: 2.07894
Epoch 20, Val Loss: 2.05506
Epoch 21, Val Loss: 2.05568
Epoch 22, Val Loss: 2.06694
Epoch 23, Val Loss: 2.05835
Epoch 24, Val Loss: 2.07683
Epoch 25, Val Loss: 2.05860
Epoch 26, Val Loss: 2.08065
Epoch 27, Val Loss: 2.05053
Epoch 28, Val Loss: 2.05251
Epoch 29, Val Loss: 2.05284
Epoch 30, Val Loss: 2.05705
Epoch 31, Val Loss: 2.04856
Epoch 32, Val Loss: 2.06216
Epoch 33, Val Loss: 2.04822
Epoch 34, Val Loss: 2.04549
Epoch 35, Val Loss: 2.04531
Epoch 36, Val Loss: 2.06813
Epoch 37, Val Loss: 2.08898
Epoch 38, Val Loss: 2.05839
Epoch 39, Val Loss: 2.07019
Epoch 40, Val Loss: 2.05482
Epoch 41, Val Loss: 2.07500
Epoch 42, Val Loss: 2.05331
Epoch 43, Val Loss: 2.07134
Epoch 44, Val Loss: 2.05866
Epoch 45, Val Loss: 2.03429
Epoch 46, Val Loss: 2.03226
Epoch 47, Val Loss: 2.06416
Epoch 48, Val Loss: 2.04710
Epoch 49, Val Loss: 2.05677
Epoch 50, Val Loss: 2.05702
Epoch 51, Val Loss: 2.04582
Epoch 52, Val Loss: 2.04625
Epoch 53, Val Loss: 2.04981
Epoch 54, Val Loss: 2.05153
Epoch 55, Val Loss: 2.04128
Epoch 56, Val Loss: 2.04547
Epoch 57, Val Loss: 2.02278
Epoch 58, Val Loss: 2.03841
Epoch 59, Val Loss: 2.05064
Epoch 60, Val Loss: 2.04914
Epoch 61, Val Loss: 2.03058
Epoch 62, Val Loss: 2.03229
Epoch 63, Val Loss: 2.08946
Epoch 64, Val Loss: 2.06220
Epoch 65, Val Loss: 2.05740
Epoch 66, Val Loss: 2.05898
Epoch 67, Val Loss: 2.04766
Epoch 68, Val Loss: 2.04556
Epoch 69, Val Loss: 2.05281
Epoch 70, Val Loss: 2.03581
Epoch 71, Val Loss: 2.04554
Epoch 72, Val Loss: 2.03764
Epoch 73, Val Loss: 2.03738
Epoch 74, Val Loss: 2.03984
Epoch 75, Val Loss: 2.04292
Epoch 76, Val Loss: 2.03173
Epoch 77, Val Loss: 2.04432
Epoch 78, Val Loss: 2.04540
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.577675, 'Log Loss - std': 0.4117192877131213} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}
Fitted encoder
Epoch 0, Val Loss: 1.97261
Epoch 1, Val Loss: 1.95561
Epoch 2, Val Loss: 1.97081
Epoch 3, Val Loss: 1.95073
Epoch 4, Val Loss: 1.96330
Epoch 5, Val Loss: 2.00670
Epoch 6, Val Loss: 1.96385
Epoch 7, Val Loss: 1.95653
Epoch 8, Val Loss: 1.95188
Epoch 9, Val Loss: 1.95761
Epoch 10, Val Loss: 1.96524
Epoch 11, Val Loss: 1.95357
Epoch 12, Val Loss: 1.94401
Epoch 13, Val Loss: 1.97120
Epoch 14, Val Loss: 1.94554
Epoch 15, Val Loss: 1.94668
Epoch 16, Val Loss: 1.92494
Epoch 17, Val Loss: 1.93841
Epoch 18, Val Loss: 1.95104
Epoch 19, Val Loss: 1.91675
Epoch 20, Val Loss: 1.97310
Epoch 21, Val Loss: 1.94640
Epoch 22, Val Loss: 1.99246
Epoch 23, Val Loss: 1.92753
Epoch 24, Val Loss: 1.92722
Epoch 25, Val Loss: 1.94972
Epoch 26, Val Loss: 1.93974
Epoch 27, Val Loss: 1.92610
Epoch 28, Val Loss: 1.94762
Epoch 29, Val Loss: 1.92712
Epoch 30, Val Loss: 1.98390
Epoch 31, Val Loss: 1.91308
Epoch 32, Val Loss: 1.92582
Epoch 33, Val Loss: 1.91473
Epoch 34, Val Loss: 1.92429
Epoch 35, Val Loss: 1.92071
Epoch 36, Val Loss: 1.92404
Epoch 37, Val Loss: 1.93683
Epoch 38, Val Loss: 1.90434
Epoch 39, Val Loss: 1.92174
Epoch 40, Val Loss: 1.90037
Epoch 41, Val Loss: 1.89032
Epoch 42, Val Loss: 1.89884
Epoch 43, Val Loss: 1.94441
Epoch 44, Val Loss: 1.95306
Epoch 45, Val Loss: 1.90833
Epoch 46, Val Loss: 1.90786
Epoch 47, Val Loss: 1.89724
Epoch 48, Val Loss: 1.90221
Epoch 49, Val Loss: 1.90505
Epoch 50, Val Loss: 1.90839
Epoch 51, Val Loss: 1.92114
Epoch 52, Val Loss: 1.99444
Epoch 53, Val Loss: 1.93514
Epoch 54, Val Loss: 1.90302
Epoch 55, Val Loss: 1.90165
Epoch 56, Val Loss: 1.91683
Epoch 57, Val Loss: 1.91840
Epoch 58, Val Loss: 1.89260
Epoch 59, Val Loss: 1.91263
Epoch 60, Val Loss: 1.90724
Epoch 61, Val Loss: 1.90982
Epoch 62, Val Loss: 1.89299
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.666, 'Log Loss - std': 0.40843045919715626} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 48 finished with value: 2.666 and parameters: {'p_m': 0.6032125839566816, 'alpha': 8.58310158005514, 'K': 3, 'beta': 7.109118986388729}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}
Fitted encoder
Epoch 0, Val Loss: 2.14704
Epoch 1, Val Loss: 2.13067
Epoch 2, Val Loss: 2.13959
Epoch 3, Val Loss: 2.12643
Epoch 4, Val Loss: 2.13475
Epoch 5, Val Loss: 2.11955
Epoch 6, Val Loss: 2.12259
Epoch 7, Val Loss: 2.11804
Epoch 8, Val Loss: 2.11790
Epoch 9, Val Loss: 2.11414
Epoch 10, Val Loss: 2.11395
Epoch 11, Val Loss: 2.10152
Epoch 12, Val Loss: 2.12058
Epoch 13, Val Loss: 2.10216
Epoch 14, Val Loss: 2.10604
Epoch 15, Val Loss: 2.09426
Epoch 16, Val Loss: 2.10283
Epoch 17, Val Loss: 2.09245
Epoch 18, Val Loss: 2.10154
Epoch 19, Val Loss: 2.10785
Epoch 20, Val Loss: 2.11851
Epoch 21, Val Loss: 2.08566
Epoch 22, Val Loss: 2.10024
Epoch 23, Val Loss: 2.08527
Epoch 24, Val Loss: 2.08694
Epoch 25, Val Loss: 2.10385
Epoch 26, Val Loss: 2.09027
Epoch 27, Val Loss: 2.08071
Epoch 28, Val Loss: 2.08394
Epoch 29, Val Loss: 2.09165
Epoch 30, Val Loss: 2.06863
Epoch 31, Val Loss: 2.11302
Epoch 32, Val Loss: 2.09548
Epoch 33, Val Loss: 2.09022
Epoch 34, Val Loss: 2.06525
Epoch 35, Val Loss: 2.07666
Epoch 36, Val Loss: 2.07908
Epoch 37, Val Loss: 2.08030
Epoch 38, Val Loss: 2.08166
Epoch 39, Val Loss: 2.06845
Epoch 40, Val Loss: 2.09283
Epoch 41, Val Loss: 2.06565
Epoch 42, Val Loss: 2.07937
Epoch 43, Val Loss: 2.07445
Epoch 44, Val Loss: 2.07916
Epoch 45, Val Loss: 2.08480
Epoch 46, Val Loss: 2.07412
Epoch 47, Val Loss: 2.07561
Epoch 48, Val Loss: 2.08018
Epoch 49, Val Loss: 2.08519
Epoch 50, Val Loss: 2.07760
Epoch 51, Val Loss: 2.06631
Epoch 52, Val Loss: 2.06268
Epoch 53, Val Loss: 2.07823
Epoch 54, Val Loss: 2.07296
Epoch 55, Val Loss: 2.07634
Epoch 56, Val Loss: 2.08630
Epoch 57, Val Loss: 2.07257
Epoch 58, Val Loss: 2.06667
Epoch 59, Val Loss: 2.10019
Epoch 60, Val Loss: 2.06685
Epoch 61, Val Loss: 2.07164
Epoch 62, Val Loss: 2.07162
Epoch 63, Val Loss: 2.07955
Epoch 64, Val Loss: 2.06983
Epoch 65, Val Loss: 2.07637
Epoch 66, Val Loss: 2.10400
Epoch 67, Val Loss: 2.07502
Epoch 68, Val Loss: 2.07797
Epoch 69, Val Loss: 2.06865
Epoch 70, Val Loss: 2.08371
Epoch 71, Val Loss: 2.09097
Epoch 72, Val Loss: 2.08133
Epoch 73, Val Loss: 2.07220
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.504, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}
Fitted encoder
Epoch 0, Val Loss: 1.95559
Epoch 1, Val Loss: 1.96143
Epoch 2, Val Loss: 1.95032
Epoch 3, Val Loss: 1.94297
Epoch 4, Val Loss: 1.94774
Epoch 5, Val Loss: 1.94727
Epoch 6, Val Loss: 1.94726
Epoch 7, Val Loss: 1.94073
Epoch 8, Val Loss: 1.94002
Epoch 9, Val Loss: 1.93178
Epoch 10, Val Loss: 1.92690
Epoch 11, Val Loss: 1.91929
Epoch 12, Val Loss: 1.93520
Epoch 13, Val Loss: 1.93838
Epoch 14, Val Loss: 1.92144
Epoch 15, Val Loss: 1.94605
Epoch 16, Val Loss: 1.94137
Epoch 17, Val Loss: 1.94113
Epoch 18, Val Loss: 1.92000
Epoch 19, Val Loss: 1.91705
Epoch 20, Val Loss: 1.91594
Epoch 21, Val Loss: 1.90903
Epoch 22, Val Loss: 1.90509
Epoch 23, Val Loss: 1.93264
Epoch 24, Val Loss: 1.90768
Epoch 25, Val Loss: 1.93059
Epoch 26, Val Loss: 1.91005
Epoch 27, Val Loss: 1.93085
Epoch 28, Val Loss: 1.91004
Epoch 29, Val Loss: 1.91046
Epoch 30, Val Loss: 1.90534
Epoch 31, Val Loss: 1.91349
Epoch 32, Val Loss: 1.91265
Epoch 33, Val Loss: 1.92439
Epoch 34, Val Loss: 1.92099
Epoch 35, Val Loss: 1.91805
Epoch 36, Val Loss: 1.92193
Epoch 37, Val Loss: 1.91505
Epoch 38, Val Loss: 1.93490
Epoch 39, Val Loss: 1.90887
Epoch 40, Val Loss: 1.91268
Epoch 41, Val Loss: 1.90401
Epoch 42, Val Loss: 1.90972
Epoch 43, Val Loss: 1.90185
Epoch 44, Val Loss: 1.91514
Epoch 45, Val Loss: 1.91203
Epoch 46, Val Loss: 1.91380
Epoch 47, Val Loss: 1.91536
Epoch 48, Val Loss: 1.91258
Epoch 49, Val Loss: 1.89326
Epoch 50, Val Loss: 1.90773
Epoch 51, Val Loss: 1.90618
Epoch 52, Val Loss: 1.90988
Epoch 53, Val Loss: 1.91026
Epoch 54, Val Loss: 1.91701
Epoch 55, Val Loss: 1.91201
Epoch 56, Val Loss: 1.90223
Epoch 57, Val Loss: 1.89151
Epoch 58, Val Loss: 1.91013
Epoch 59, Val Loss: 1.90417
Epoch 60, Val Loss: 1.91601
Epoch 61, Val Loss: 1.90988
Epoch 62, Val Loss: 1.90537
Epoch 63, Val Loss: 1.90336
Epoch 64, Val Loss: 1.90247
Epoch 65, Val Loss: 1.90783
Epoch 66, Val Loss: 1.90513
Epoch 67, Val Loss: 1.89500
Epoch 68, Val Loss: 1.89913
Epoch 69, Val Loss: 1.90172
Epoch 70, Val Loss: 1.91364
Epoch 71, Val Loss: 1.91555
Epoch 72, Val Loss: 1.90516
Epoch 73, Val Loss: 1.89542
Epoch 74, Val Loss: 1.90042
Epoch 75, Val Loss: 1.91476
Epoch 76, Val Loss: 1.88865
Epoch 77, Val Loss: 1.90015
Epoch 78, Val Loss: 1.89579
Epoch 79, Val Loss: 1.90293
Epoch 80, Val Loss: 1.90124
Epoch 81, Val Loss: 1.90711
Epoch 82, Val Loss: 1.91196
Epoch 83, Val Loss: 1.92474
Epoch 84, Val Loss: 1.89362
Epoch 85, Val Loss: 1.90299
Epoch 86, Val Loss: 1.90038
Epoch 87, Val Loss: 1.89172
Epoch 88, Val Loss: 1.90517
Epoch 89, Val Loss: 1.90629
Epoch 90, Val Loss: 1.90923
Epoch 91, Val Loss: 1.90140
Epoch 92, Val Loss: 1.92439
Epoch 93, Val Loss: 1.90817
Epoch 94, Val Loss: 1.90525
Epoch 95, Val Loss: 1.90182
Epoch 96, Val Loss: 1.90912
Epoch 97, Val Loss: 1.90584
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.2987, 'Log Loss - std': 0.20530000000000004} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}
Fitted encoder
Epoch 0, Val Loss: 2.15050
Epoch 1, Val Loss: 2.13944
Epoch 2, Val Loss: 2.13731
Epoch 3, Val Loss: 2.12523
Epoch 4, Val Loss: 2.12495
Epoch 5, Val Loss: 2.11270
Epoch 6, Val Loss: 2.12077
Epoch 7, Val Loss: 2.11346
Epoch 8, Val Loss: 2.11601
Epoch 9, Val Loss: 2.11064
Epoch 10, Val Loss: 2.11233
Epoch 11, Val Loss: 2.08091
Epoch 12, Val Loss: 2.10697
Epoch 13, Val Loss: 2.07832
Epoch 14, Val Loss: 2.08103
Epoch 15, Val Loss: 2.09038
Epoch 16, Val Loss: 2.08527
Epoch 17, Val Loss: 2.07669
Epoch 18, Val Loss: 2.06904
Epoch 19, Val Loss: 2.08200
Epoch 20, Val Loss: 2.07930
Epoch 21, Val Loss: 2.06383
Epoch 22, Val Loss: 2.06663
Epoch 23, Val Loss: 2.07113
Epoch 24, Val Loss: 2.06499
Epoch 25, Val Loss: 2.07548
Epoch 26, Val Loss: 2.05345
Epoch 27, Val Loss: 2.07329
Epoch 28, Val Loss: 2.05730
Epoch 29, Val Loss: 2.09561
Epoch 30, Val Loss: 2.05147
Epoch 31, Val Loss: 2.05086
Epoch 32, Val Loss: 2.04493
Epoch 33, Val Loss: 2.04371
Epoch 34, Val Loss: 2.05110
Epoch 35, Val Loss: 2.03905
Epoch 36, Val Loss: 2.04652
Epoch 37, Val Loss: 2.04028
Epoch 38, Val Loss: 2.04943
Epoch 39, Val Loss: 2.04674
Epoch 40, Val Loss: 2.03949
Epoch 41, Val Loss: 2.03805
Epoch 42, Val Loss: 2.04256
Epoch 43, Val Loss: 2.04883
Epoch 44, Val Loss: 2.04165
Epoch 45, Val Loss: 2.05565
Epoch 46, Val Loss: 2.03960
Epoch 47, Val Loss: 2.05091
Epoch 48, Val Loss: 2.04945
Epoch 49, Val Loss: 2.03828
Epoch 50, Val Loss: 2.04157
Epoch 51, Val Loss: 2.03485
Epoch 52, Val Loss: 2.04244
Epoch 53, Val Loss: 2.06027
Epoch 54, Val Loss: 2.03535
Epoch 55, Val Loss: 2.03961
Epoch 56, Val Loss: 2.03045
Epoch 57, Val Loss: 2.03686
Epoch 58, Val Loss: 2.03632
Epoch 59, Val Loss: 2.04742
Epoch 60, Val Loss: 2.03467
Epoch 61, Val Loss: 2.02879
Epoch 62, Val Loss: 2.03131
Epoch 63, Val Loss: 2.03684
Epoch 64, Val Loss: 2.05466
Epoch 65, Val Loss: 2.03520
Epoch 66, Val Loss: 2.03115
Epoch 67, Val Loss: 2.05137
Epoch 68, Val Loss: 2.06689
Epoch 69, Val Loss: 2.04078
Epoch 70, Val Loss: 2.03937
Epoch 71, Val Loss: 2.02681
Epoch 72, Val Loss: 2.03581
Epoch 73, Val Loss: 2.02818
Epoch 74, Val Loss: 2.02447
Epoch 75, Val Loss: 2.03548
Epoch 76, Val Loss: 2.04258
Epoch 77, Val Loss: 2.03165
Epoch 78, Val Loss: 2.03655
Epoch 79, Val Loss: 2.03150
Epoch 80, Val Loss: 2.03597
Epoch 81, Val Loss: 2.03422
Epoch 82, Val Loss: 2.04941
Epoch 83, Val Loss: 2.03233
Epoch 84, Val Loss: 2.04513
Epoch 85, Val Loss: 2.04432
Epoch 86, Val Loss: 2.02511
Epoch 87, Val Loss: 2.02693
Epoch 88, Val Loss: 2.02166
Epoch 89, Val Loss: 2.02800
Epoch 90, Val Loss: 2.04145
Epoch 91, Val Loss: 2.03212
Epoch 92, Val Loss: 2.02419
Epoch 93, Val Loss: 2.03838
Epoch 94, Val Loss: 2.03267
Epoch 95, Val Loss: 2.04014
Epoch 96, Val Loss: 2.03486
Epoch 97, Val Loss: 2.04665
Epoch 98, Val Loss: 2.04943
Epoch 99, Val Loss: 2.02965
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.0936, 'Log Loss - std': 0.33500857700462944} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}
Fitted encoder
Epoch 0, Val Loss: 2.07287
Epoch 1, Val Loss: 2.08769
Epoch 2, Val Loss: 2.07769
Epoch 3, Val Loss: 2.05676
Epoch 4, Val Loss: 2.06371
Epoch 5, Val Loss: 2.07348
Epoch 6, Val Loss: 2.05819
Epoch 7, Val Loss: 2.05859
Epoch 8, Val Loss: 2.06327
Epoch 9, Val Loss: 2.05931
Epoch 10, Val Loss: 2.07552
Epoch 11, Val Loss: 2.06549
Epoch 12, Val Loss: 2.06015
Epoch 13, Val Loss: 2.06724
Epoch 14, Val Loss: 2.05819
Epoch 15, Val Loss: 2.06270
Epoch 16, Val Loss: 2.06489
Epoch 17, Val Loss: 2.06564
Epoch 18, Val Loss: 2.06295
Epoch 19, Val Loss: 2.05409
Epoch 20, Val Loss: 2.06711
Epoch 21, Val Loss: 2.05012
Epoch 22, Val Loss: 2.05822
Epoch 23, Val Loss: 2.05820
Epoch 24, Val Loss: 2.05142
Epoch 25, Val Loss: 2.06033
Epoch 26, Val Loss: 2.05697
Epoch 27, Val Loss: 2.05085
Epoch 28, Val Loss: 2.04834
Epoch 29, Val Loss: 2.04529
Epoch 30, Val Loss: 2.04633
Epoch 31, Val Loss: 2.05894
Epoch 32, Val Loss: 2.04901
Epoch 33, Val Loss: 2.04912
Epoch 34, Val Loss: 2.05933
Epoch 35, Val Loss: 2.04597
Epoch 36, Val Loss: 2.04124
Epoch 37, Val Loss: 2.05936
Epoch 38, Val Loss: 2.05282
Epoch 39, Val Loss: 2.03391
Epoch 40, Val Loss: 2.07095
Epoch 41, Val Loss: 2.03378
Epoch 42, Val Loss: 2.03548
Epoch 43, Val Loss: 2.06319
Epoch 44, Val Loss: 2.04040
Epoch 45, Val Loss: 2.05420
Epoch 46, Val Loss: 2.05832
Epoch 47, Val Loss: 2.02318
Epoch 48, Val Loss: 2.03476
Epoch 49, Val Loss: 2.02458
Epoch 50, Val Loss: 2.04846
Epoch 51, Val Loss: 2.04151
Epoch 52, Val Loss: 2.02781
Epoch 53, Val Loss: 2.02964
Epoch 54, Val Loss: 2.02811
Epoch 55, Val Loss: 2.05863
Epoch 56, Val Loss: 2.03407
Epoch 57, Val Loss: 2.02710
Epoch 58, Val Loss: 2.04204
Epoch 59, Val Loss: 2.02652
Epoch 60, Val Loss: 2.04748
Epoch 61, Val Loss: 2.04005
Epoch 62, Val Loss: 2.02831
Epoch 63, Val Loss: 2.02609
Epoch 64, Val Loss: 2.03355
Epoch 65, Val Loss: 2.03646
Epoch 66, Val Loss: 2.02547
Epoch 67, Val Loss: 2.02249
Epoch 68, Val Loss: 2.05990
Epoch 69, Val Loss: 2.01944
Epoch 70, Val Loss: 2.02717
Epoch 71, Val Loss: 2.03266
Epoch 72, Val Loss: 2.02071
Epoch 73, Val Loss: 2.04777
Epoch 74, Val Loss: 2.02494
Epoch 75, Val Loss: 2.03535
Epoch 76, Val Loss: 2.04429
Epoch 77, Val Loss: 2.02959
Epoch 78, Val Loss: 2.03749
Epoch 79, Val Loss: 2.05038
Epoch 80, Val Loss: 2.02401
Epoch 81, Val Loss: 2.03779
Epoch 82, Val Loss: 2.04331
Epoch 83, Val Loss: 2.03701
Epoch 84, Val Loss: 2.01618
Epoch 85, Val Loss: 2.03513
Epoch 86, Val Loss: 2.05522
Epoch 87, Val Loss: 2.01477
Epoch 88, Val Loss: 2.03813
Epoch 89, Val Loss: 2.02493
Epoch 90, Val Loss: 2.04101
Epoch 91, Val Loss: 2.02397
Epoch 92, Val Loss: 2.02612
Epoch 93, Val Loss: 2.04065
Epoch 94, Val Loss: 2.02666
Epoch 95, Val Loss: 2.02437
Epoch 96, Val Loss: 2.03080
Epoch 97, Val Loss: 2.02444
Epoch 98, Val Loss: 2.04341
Epoch 99, Val Loss: 2.02755
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.0279249999999998, 'Log Loss - std': 0.3116290693677341} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}
Fitted encoder
Epoch 0, Val Loss: 1.96142
Epoch 1, Val Loss: 1.95954
Epoch 2, Val Loss: 1.95105
Epoch 3, Val Loss: 1.94709
Epoch 4, Val Loss: 1.94213
Epoch 5, Val Loss: 1.94785
Epoch 6, Val Loss: 1.94936
Epoch 7, Val Loss: 1.93857
Epoch 8, Val Loss: 1.94071
Epoch 9, Val Loss: 1.93300
Epoch 10, Val Loss: 1.93106
Epoch 11, Val Loss: 1.93193
Epoch 12, Val Loss: 1.92510
Epoch 13, Val Loss: 1.93574
Epoch 14, Val Loss: 1.93271
Epoch 15, Val Loss: 1.93808
Epoch 16, Val Loss: 1.94958
Epoch 17, Val Loss: 1.90336
Epoch 18, Val Loss: 1.91728
Epoch 19, Val Loss: 1.91758
Epoch 20, Val Loss: 1.89478
Epoch 21, Val Loss: 1.90584
Epoch 22, Val Loss: 1.89318
Epoch 23, Val Loss: 1.91262
Epoch 24, Val Loss: 1.91780
Epoch 25, Val Loss: 1.90480
Epoch 26, Val Loss: 1.92642
Epoch 27, Val Loss: 1.92355
Epoch 28, Val Loss: 1.90944
Epoch 29, Val Loss: 1.89909
Epoch 30, Val Loss: 1.92030
Epoch 31, Val Loss: 1.91405
Epoch 32, Val Loss: 1.91169
Epoch 33, Val Loss: 1.91226
Epoch 34, Val Loss: 1.88352
Epoch 35, Val Loss: 1.90116
Epoch 36, Val Loss: 1.91247
Epoch 37, Val Loss: 1.90809
Epoch 38, Val Loss: 1.90139
Epoch 39, Val Loss: 1.88835
Epoch 40, Val Loss: 1.90541
Epoch 41, Val Loss: 1.91712
Epoch 42, Val Loss: 1.90708
Epoch 43, Val Loss: 1.89101
Epoch 44, Val Loss: 1.93411
Epoch 45, Val Loss: 1.88606
Epoch 46, Val Loss: 1.89825
Epoch 47, Val Loss: 1.92499
Epoch 48, Val Loss: 1.93573
Epoch 49, Val Loss: 1.92896
Epoch 50, Val Loss: 1.91915
Epoch 51, Val Loss: 1.89885
Epoch 52, Val Loss: 1.88642
Epoch 53, Val Loss: 1.89554
Epoch 54, Val Loss: 1.87863
Epoch 55, Val Loss: 1.88116
Epoch 56, Val Loss: 1.92629
Epoch 57, Val Loss: 1.89305
Epoch 58, Val Loss: 1.89041
Epoch 59, Val Loss: 1.88832
Epoch 60, Val Loss: 1.90023
Epoch 61, Val Loss: 1.88898
Epoch 62, Val Loss: 1.88840
Epoch 63, Val Loss: 1.88465
Epoch 64, Val Loss: 1.88296
Epoch 65, Val Loss: 1.90572
Epoch 66, Val Loss: 1.87751
Epoch 67, Val Loss: 1.87861
Epoch 68, Val Loss: 1.88651
Epoch 69, Val Loss: 1.87820
Epoch 70, Val Loss: 1.88180
Epoch 71, Val Loss: 1.90203
Epoch 72, Val Loss: 1.89862
Epoch 73, Val Loss: 1.89060
Epoch 74, Val Loss: 1.90327
Epoch 75, Val Loss: 1.89162
Epoch 76, Val Loss: 1.89546
Epoch 77, Val Loss: 1.90214
Epoch 78, Val Loss: 1.90315
Epoch 79, Val Loss: 1.88218
Epoch 80, Val Loss: 1.89913
Epoch 81, Val Loss: 1.91618
Epoch 82, Val Loss: 1.89308
Epoch 83, Val Loss: 1.89077
Epoch 84, Val Loss: 1.88197
Epoch 85, Val Loss: 1.88621
Epoch 86, Val Loss: 1.87885
Epoch 87, Val Loss: 1.89060
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.00336, 'Log Loss - std': 0.2830263210374611} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 49 finished with value: 3.00336 and parameters: {'p_m': 0.3643617337911302, 'alpha': 3.9299228638746713, 'K': 2, 'beta': 2.0655896900429704}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}
Fitted encoder
Epoch 0, Val Loss: 2.14475
Epoch 1, Val Loss: 2.13121
Epoch 2, Val Loss: 2.15782
Epoch 3, Val Loss: 2.09989
Epoch 4, Val Loss: 2.08784
Epoch 5, Val Loss: 2.09927
Epoch 6, Val Loss: 2.08177
Epoch 7, Val Loss: 2.09689
Epoch 8, Val Loss: 2.09533
Epoch 9, Val Loss: 2.09528
Epoch 10, Val Loss: 2.09175
Epoch 11, Val Loss: 2.09245
Epoch 12, Val Loss: 2.08407
Epoch 13, Val Loss: 2.08105
Epoch 14, Val Loss: 2.08583
Epoch 15, Val Loss: 2.08933
Epoch 16, Val Loss: 2.08569
Epoch 17, Val Loss: 2.06930
Epoch 18, Val Loss: 2.06661
Epoch 19, Val Loss: 2.05314
Epoch 20, Val Loss: 2.05355
Epoch 21, Val Loss: 2.08279
Epoch 22, Val Loss: 2.08127
Epoch 23, Val Loss: 2.06681
Epoch 24, Val Loss: 2.06115
Epoch 25, Val Loss: 2.06965
Epoch 26, Val Loss: 2.04933
Epoch 27, Val Loss: 2.05996
Epoch 28, Val Loss: 2.06488
Epoch 29, Val Loss: 2.06250
Epoch 30, Val Loss: 2.05408
Epoch 31, Val Loss: 2.05069
Epoch 32, Val Loss: 2.07328
Epoch 33, Val Loss: 2.04161
Epoch 34, Val Loss: 2.04301
Epoch 35, Val Loss: 2.05471
Epoch 36, Val Loss: 2.05592
Epoch 37, Val Loss: 2.04477
Epoch 38, Val Loss: 2.04677
Epoch 39, Val Loss: 2.05232
Epoch 40, Val Loss: 2.03506
Epoch 41, Val Loss: 2.04754
Epoch 42, Val Loss: 2.08771
Epoch 43, Val Loss: 2.03874
Epoch 44, Val Loss: 2.03737
Epoch 45, Val Loss: 2.06632
Epoch 46, Val Loss: 2.04556
Epoch 47, Val Loss: 2.04893
Epoch 48, Val Loss: 2.04269
Epoch 49, Val Loss: 2.04584
Epoch 50, Val Loss: 2.04333
Epoch 51, Val Loss: 2.04259
Epoch 52, Val Loss: 2.04273
Epoch 53, Val Loss: 2.08128
Epoch 54, Val Loss: 2.05885
Epoch 55, Val Loss: 2.04463
Epoch 56, Val Loss: 2.03846
Epoch 57, Val Loss: 2.04312
Epoch 58, Val Loss: 2.04702
Epoch 59, Val Loss: 2.04019
Epoch 60, Val Loss: 2.03475
Epoch 61, Val Loss: 2.04846
Epoch 62, Val Loss: 2.04253
Epoch 63, Val Loss: 2.04611
Epoch 64, Val Loss: 2.04632
Epoch 65, Val Loss: 2.04049
Epoch 66, Val Loss: 2.03367
Epoch 67, Val Loss: 2.03631
Epoch 68, Val Loss: 2.04629
Epoch 69, Val Loss: 2.03659
Epoch 70, Val Loss: 2.05121
Epoch 71, Val Loss: 2.05133
Epoch 72, Val Loss: 2.05269
Epoch 73, Val Loss: 2.05784
Epoch 74, Val Loss: 2.04998
Epoch 75, Val Loss: 2.04555
Epoch 76, Val Loss: 2.03574
Epoch 77, Val Loss: 2.05472
Epoch 78, Val Loss: 2.02791
Epoch 79, Val Loss: 2.03442
Epoch 80, Val Loss: 2.05084
Epoch 81, Val Loss: 2.04313
Epoch 82, Val Loss: 2.03082
Epoch 83, Val Loss: 2.03429
Epoch 84, Val Loss: 2.03269
Epoch 85, Val Loss: 2.03330
Epoch 86, Val Loss: 2.05078
Epoch 87, Val Loss: 2.03319
Epoch 88, Val Loss: 2.02823
Epoch 89, Val Loss: 2.02661
Epoch 90, Val Loss: 2.03759
Epoch 91, Val Loss: 2.03557
Epoch 92, Val Loss: 2.02654
Epoch 93, Val Loss: 2.03620
Epoch 94, Val Loss: 2.05046
Epoch 95, Val Loss: 2.03695
Epoch 96, Val Loss: 2.03687
Epoch 97, Val Loss: 2.05444
Epoch 98, Val Loss: 2.04368
Epoch 99, Val Loss: 2.04625
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.0131, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}
Fitted encoder
Epoch 0, Val Loss: 1.96114
Epoch 1, Val Loss: 1.98111
Epoch 2, Val Loss: 1.94898
Epoch 3, Val Loss: 1.94999
Epoch 4, Val Loss: 1.95511
Epoch 5, Val Loss: 1.92673
Epoch 6, Val Loss: 1.91849
Epoch 7, Val Loss: 1.93408
Epoch 8, Val Loss: 1.94475
Epoch 9, Val Loss: 1.92451
Epoch 10, Val Loss: 1.91926
Epoch 11, Val Loss: 1.90828
Epoch 12, Val Loss: 1.93151
Epoch 13, Val Loss: 1.90759
Epoch 14, Val Loss: 1.91583
Epoch 15, Val Loss: 1.91822
Epoch 16, Val Loss: 1.92472
Epoch 17, Val Loss: 1.93063
Epoch 18, Val Loss: 1.90670
Epoch 19, Val Loss: 1.90921
Epoch 20, Val Loss: 1.90277
Epoch 21, Val Loss: 1.91495
Epoch 22, Val Loss: 1.89756
Epoch 23, Val Loss: 1.90538
Epoch 24, Val Loss: 1.90837
Epoch 25, Val Loss: 1.90001
Epoch 26, Val Loss: 1.89784
Epoch 27, Val Loss: 1.90105
Epoch 28, Val Loss: 1.90009
Epoch 29, Val Loss: 1.92138
Epoch 30, Val Loss: 1.88882
Epoch 31, Val Loss: 1.89902
Epoch 32, Val Loss: 1.91287
Epoch 33, Val Loss: 1.89121
Epoch 34, Val Loss: 1.90616
Epoch 35, Val Loss: 1.89730
Epoch 36, Val Loss: 1.89153
Epoch 37, Val Loss: 1.92773
Epoch 38, Val Loss: 1.89872
Epoch 39, Val Loss: 1.91527
Epoch 40, Val Loss: 1.89270
Epoch 41, Val Loss: 1.89053
Epoch 42, Val Loss: 1.90326
Epoch 43, Val Loss: 1.89373
Epoch 44, Val Loss: 1.89648
Epoch 45, Val Loss: 1.89719
Epoch 46, Val Loss: 1.91553
Epoch 47, Val Loss: 1.90225
Epoch 48, Val Loss: 1.89265
Epoch 49, Val Loss: 1.90278
Epoch 50, Val Loss: 1.90071
Epoch 51, Val Loss: 1.89679
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.9802, 'Log Loss - std': 0.03290000000000015} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}
Fitted encoder
Epoch 0, Val Loss: 2.12825
Epoch 1, Val Loss: 2.12979
Epoch 2, Val Loss: 2.12474
Epoch 3, Val Loss: 2.12585
Epoch 4, Val Loss: 2.12792
Epoch 5, Val Loss: 2.12660
Epoch 6, Val Loss: 2.11413
Epoch 7, Val Loss: 2.12550
Epoch 8, Val Loss: 2.11718
Epoch 9, Val Loss: 2.11239
Epoch 10, Val Loss: 2.12670
Epoch 11, Val Loss: 2.11638
Epoch 12, Val Loss: 2.11928
Epoch 13, Val Loss: 2.11747
Epoch 14, Val Loss: 2.11898
Epoch 15, Val Loss: 2.10776
Epoch 16, Val Loss: 2.11650
Epoch 17, Val Loss: 2.12622
Epoch 18, Val Loss: 2.11010
Epoch 19, Val Loss: 2.11991
Epoch 20, Val Loss: 2.10864
Epoch 21, Val Loss: 2.11224
Epoch 22, Val Loss: 2.10202
Epoch 23, Val Loss: 2.12237
Epoch 24, Val Loss: 2.10503
Epoch 25, Val Loss: 2.11396
Epoch 26, Val Loss: 2.09923
Epoch 27, Val Loss: 2.10287
Epoch 28, Val Loss: 2.10293
Epoch 29, Val Loss: 2.09839
Epoch 30, Val Loss: 2.11832
Epoch 31, Val Loss: 2.10921
Epoch 32, Val Loss: 2.09464
Epoch 33, Val Loss: 2.10117
Epoch 34, Val Loss: 2.09001
Epoch 35, Val Loss: 2.09658
Epoch 36, Val Loss: 2.10986
Epoch 37, Val Loss: 2.10191
Epoch 38, Val Loss: 2.08804
Epoch 39, Val Loss: 2.10525
Epoch 40, Val Loss: 2.09007
Epoch 41, Val Loss: 2.08443
Epoch 42, Val Loss: 2.08483
Epoch 43, Val Loss: 2.07526
Epoch 44, Val Loss: 2.07823
Epoch 45, Val Loss: 2.10012
Epoch 46, Val Loss: 2.08742
Epoch 47, Val Loss: 2.08403
Epoch 48, Val Loss: 2.08324
Epoch 49, Val Loss: 2.08603
Epoch 50, Val Loss: 2.07883
Epoch 51, Val Loss: 2.07897
Epoch 52, Val Loss: 2.07443
Epoch 53, Val Loss: 2.08293
Epoch 54, Val Loss: 2.07823
Epoch 55, Val Loss: 2.08125
Epoch 56, Val Loss: 2.08973
Epoch 57, Val Loss: 2.09633
Epoch 58, Val Loss: 2.11385
Epoch 59, Val Loss: 2.07597
Epoch 60, Val Loss: 2.07807
Epoch 61, Val Loss: 2.07590
Epoch 62, Val Loss: 2.08817
Epoch 63, Val Loss: 2.06617
Epoch 64, Val Loss: 2.08864
Epoch 65, Val Loss: 2.06906
Epoch 66, Val Loss: 2.07377
Epoch 67, Val Loss: 2.09008
Epoch 68, Val Loss: 2.07241
Epoch 69, Val Loss: 2.07867
Epoch 70, Val Loss: 2.07075
Epoch 71, Val Loss: 2.08226
Epoch 72, Val Loss: 2.07113
Epoch 73, Val Loss: 2.07463
Epoch 74, Val Loss: 2.07745
Epoch 75, Val Loss: 2.07836
Epoch 76, Val Loss: 2.06762
Epoch 77, Val Loss: 2.07060
Epoch 78, Val Loss: 2.07553
Epoch 79, Val Loss: 2.07905
Epoch 80, Val Loss: 2.07243
Epoch 81, Val Loss: 2.06618
Epoch 82, Val Loss: 2.08659
Epoch 83, Val Loss: 2.06622
Epoch 84, Val Loss: 2.06289
Epoch 85, Val Loss: 2.11176
Epoch 86, Val Loss: 2.12322
Epoch 87, Val Loss: 2.07672
Epoch 88, Val Loss: 2.08734
Epoch 89, Val Loss: 2.08209
Epoch 90, Val Loss: 2.06297
Epoch 91, Val Loss: 2.06818
Epoch 92, Val Loss: 2.07311
Epoch 93, Val Loss: 2.07303
Epoch 94, Val Loss: 2.07230
Epoch 95, Val Loss: 2.07010
Epoch 96, Val Loss: 2.07995
Epoch 97, Val Loss: 2.06935
Epoch 98, Val Loss: 2.07547
Epoch 99, Val Loss: 2.08534
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.208266666666667, 'Log Loss - std': 0.3236516886338701} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}
Fitted encoder
Epoch 0, Val Loss: 2.09258
Epoch 1, Val Loss: 2.07185
Epoch 2, Val Loss: 2.08352
Epoch 3, Val Loss: 2.08468
Epoch 4, Val Loss: 2.06651
Epoch 5, Val Loss: 2.05772
Epoch 6, Val Loss: 2.05854
Epoch 7, Val Loss: 2.05363
Epoch 8, Val Loss: 2.04579
Epoch 9, Val Loss: 2.05075
Epoch 10, Val Loss: 2.04638
Epoch 11, Val Loss: 2.02543
Epoch 12, Val Loss: 2.04128
Epoch 13, Val Loss: 2.05599
Epoch 14, Val Loss: 2.05364
Epoch 15, Val Loss: 2.05702
Epoch 16, Val Loss: 2.03461
Epoch 17, Val Loss: 2.03172
Epoch 18, Val Loss: 2.03276
Epoch 19, Val Loss: 2.01499
Epoch 20, Val Loss: 2.01960
Epoch 21, Val Loss: 2.02955
Epoch 22, Val Loss: 2.02943
Epoch 23, Val Loss: 2.03815
Epoch 24, Val Loss: 2.03005
Epoch 25, Val Loss: 2.02334
Epoch 26, Val Loss: 2.01683
Epoch 27, Val Loss: 2.03340
Epoch 28, Val Loss: 2.01514
Epoch 29, Val Loss: 2.04343
Epoch 30, Val Loss: 2.02193
Epoch 31, Val Loss: 2.03610
Epoch 32, Val Loss: 2.02574
Epoch 33, Val Loss: 2.01372
Epoch 34, Val Loss: 2.02113
Epoch 35, Val Loss: 2.02965
Epoch 36, Val Loss: 2.01877
Epoch 37, Val Loss: 2.02814
Epoch 38, Val Loss: 2.02056
Epoch 39, Val Loss: 2.01490
Epoch 40, Val Loss: 2.01849
Epoch 41, Val Loss: 2.02012
Epoch 42, Val Loss: 2.03145
Epoch 43, Val Loss: 2.01643
Epoch 44, Val Loss: 2.00721
Epoch 45, Val Loss: 2.01536
Epoch 46, Val Loss: 2.02566
Epoch 47, Val Loss: 2.01935
Epoch 48, Val Loss: 2.01355
Epoch 49, Val Loss: 2.01126
Epoch 50, Val Loss: 2.02371
Epoch 51, Val Loss: 2.01174
Epoch 52, Val Loss: 2.01605
Epoch 53, Val Loss: 2.02428
Epoch 54, Val Loss: 2.04549
Epoch 55, Val Loss: 2.02149
Epoch 56, Val Loss: 2.04922
Epoch 57, Val Loss: 2.01996
Epoch 58, Val Loss: 2.02473
Epoch 59, Val Loss: 2.02198
Epoch 60, Val Loss: 2.02327
Epoch 61, Val Loss: 2.02319
Epoch 62, Val Loss: 2.02497
Epoch 63, Val Loss: 2.02240
Epoch 64, Val Loss: 2.03125
Epoch 65, Val Loss: 2.03271
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.075025, 'Log Loss - std': 0.3630741479023259} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}
Fitted encoder
Epoch 0, Val Loss: 1.96613
Epoch 1, Val Loss: 1.95602
Epoch 2, Val Loss: 1.93907
Epoch 3, Val Loss: 1.94718
Epoch 4, Val Loss: 1.93332
Epoch 5, Val Loss: 1.93365
Epoch 6, Val Loss: 1.91857
Epoch 7, Val Loss: 1.92643
Epoch 8, Val Loss: 1.93047
Epoch 9, Val Loss: 1.91980
Epoch 10, Val Loss: 1.90045
Epoch 11, Val Loss: 1.90442
Epoch 12, Val Loss: 1.91057
Epoch 13, Val Loss: 1.91258
Epoch 14, Val Loss: 1.89966
Epoch 15, Val Loss: 1.90621
Epoch 16, Val Loss: 1.89406
Epoch 17, Val Loss: 1.90484
Epoch 18, Val Loss: 1.89209
Epoch 19, Val Loss: 1.89017
Epoch 20, Val Loss: 1.90103
Epoch 21, Val Loss: 1.89058
Epoch 22, Val Loss: 1.90458
Epoch 23, Val Loss: 1.90024
Epoch 24, Val Loss: 1.90266
Epoch 25, Val Loss: 1.88310
Epoch 26, Val Loss: 1.88813
Epoch 27, Val Loss: 1.89679
Epoch 28, Val Loss: 1.90958
Epoch 29, Val Loss: 1.88057
Epoch 30, Val Loss: 1.89407
Epoch 31, Val Loss: 1.88550
Epoch 32, Val Loss: 1.90240
Epoch 33, Val Loss: 1.90719
Epoch 34, Val Loss: 1.90182
Epoch 35, Val Loss: 1.89502
Epoch 36, Val Loss: 1.88779
Epoch 37, Val Loss: 1.89516
Epoch 38, Val Loss: 1.89129
Epoch 39, Val Loss: 1.88309
Epoch 40, Val Loss: 1.87516
Epoch 41, Val Loss: 1.89626
Epoch 42, Val Loss: 1.88226
Epoch 43, Val Loss: 1.88506
Epoch 44, Val Loss: 1.88370
Epoch 45, Val Loss: 1.90074
Epoch 46, Val Loss: 1.90509
Epoch 47, Val Loss: 1.88790
Epoch 48, Val Loss: 1.89686
Epoch 49, Val Loss: 1.88626
Epoch 50, Val Loss: 1.87738
Epoch 51, Val Loss: 1.88516
Epoch 52, Val Loss: 1.88440
Epoch 53, Val Loss: 1.89400
Epoch 54, Val Loss: 1.89585
Epoch 55, Val Loss: 1.87990
Epoch 56, Val Loss: 1.88642
Epoch 57, Val Loss: 1.87804
Epoch 58, Val Loss: 1.89737
Epoch 59, Val Loss: 1.88552
Epoch 60, Val Loss: 1.88553
Epoch 61, Val Loss: 1.88851
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.0201000000000002, 'Log Loss - std': 0.34281962020864565} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 50 finished with value: 3.0201000000000002 and parameters: {'p_m': 0.30947862072296606, 'alpha': 0.47139969701438306, 'K': 15, 'beta': 3.8765119252605844}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}
Fitted encoder
Epoch 0, Val Loss: 2.13974
Epoch 1, Val Loss: 2.12754
Epoch 2, Val Loss: 2.13074
Epoch 3, Val Loss: 2.11467
Epoch 4, Val Loss: 2.12667
Epoch 5, Val Loss: 2.13010
Epoch 6, Val Loss: 2.10572
Epoch 7, Val Loss: 2.09696
Epoch 8, Val Loss: 2.12102
Epoch 9, Val Loss: 2.11391
Epoch 10, Val Loss: 2.07247
Epoch 11, Val Loss: 2.09731
Epoch 12, Val Loss: 2.10600
Epoch 13, Val Loss: 2.09650
Epoch 14, Val Loss: 2.12919
Epoch 15, Val Loss: 2.10263
Epoch 16, Val Loss: 2.08658
Epoch 17, Val Loss: 2.09176
Epoch 18, Val Loss: 2.07966
Epoch 19, Val Loss: 2.07153
Epoch 20, Val Loss: 2.07252
Epoch 21, Val Loss: 2.08960
Epoch 22, Val Loss: 2.07705
Epoch 23, Val Loss: 2.08783
Epoch 24, Val Loss: 2.07932
Epoch 25, Val Loss: 2.07477
Epoch 26, Val Loss: 2.10939
Epoch 27, Val Loss: 2.07783
Epoch 28, Val Loss: 2.06956
Epoch 29, Val Loss: 2.10180
Epoch 30, Val Loss: 2.11184
Epoch 31, Val Loss: 2.07627
Epoch 32, Val Loss: 2.07134
Epoch 33, Val Loss: 2.08032
Epoch 34, Val Loss: 2.08585
Epoch 35, Val Loss: 2.09184
Epoch 36, Val Loss: 2.09508
Epoch 37, Val Loss: 2.09174
Epoch 38, Val Loss: 2.05626
Epoch 39, Val Loss: 2.07988
Epoch 40, Val Loss: 2.09628
Epoch 41, Val Loss: 2.06929
Epoch 42, Val Loss: 2.08268
Epoch 43, Val Loss: 2.06451
Epoch 44, Val Loss: 2.07066
Epoch 45, Val Loss: 2.08757
Epoch 46, Val Loss: 2.06030
Epoch 47, Val Loss: 2.10658
Epoch 48, Val Loss: 2.06842
Epoch 49, Val Loss: 2.09074
Epoch 50, Val Loss: 2.06317
Epoch 51, Val Loss: 2.09607
Epoch 52, Val Loss: 2.05466
Epoch 53, Val Loss: 2.10735
Epoch 54, Val Loss: 2.07994
Epoch 55, Val Loss: 2.07416
Epoch 56, Val Loss: 2.07353
Epoch 57, Val Loss: 2.07728
Epoch 58, Val Loss: 2.07951
Epoch 59, Val Loss: 2.07949
Epoch 60, Val Loss: 2.07771
Epoch 61, Val Loss: 2.10175
Epoch 62, Val Loss: 2.09130
Epoch 63, Val Loss: 2.08323
Epoch 64, Val Loss: 2.06255
Epoch 65, Val Loss: 2.06432
Epoch 66, Val Loss: 2.06199
Epoch 67, Val Loss: 2.09143
Epoch 68, Val Loss: 2.06717
Epoch 69, Val Loss: 2.08154
Epoch 70, Val Loss: 2.06258
Epoch 71, Val Loss: 2.05501
Epoch 72, Val Loss: 2.08123
Epoch 73, Val Loss: 2.05713
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.1145, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}
Fitted encoder
Epoch 0, Val Loss: 2.07219
Epoch 1, Val Loss: 2.07191
Epoch 2, Val Loss: 2.07212
Epoch 3, Val Loss: 2.06727
Epoch 4, Val Loss: 1.94752
Epoch 5, Val Loss: 1.95481
Epoch 6, Val Loss: 1.95600
Epoch 7, Val Loss: 1.95005
Epoch 8, Val Loss: 1.95431
Epoch 9, Val Loss: 1.93532
Epoch 10, Val Loss: 1.94573
Epoch 11, Val Loss: 1.92980
Epoch 12, Val Loss: 1.93494
Epoch 13, Val Loss: 1.92887
Epoch 14, Val Loss: 1.93262
Epoch 15, Val Loss: 1.95772
Epoch 16, Val Loss: 1.95611
Epoch 17, Val Loss: 1.91615
Epoch 18, Val Loss: 1.92672
Epoch 19, Val Loss: 1.91065
Epoch 20, Val Loss: 1.93017
Epoch 21, Val Loss: 1.91746
Epoch 22, Val Loss: 1.91810
Epoch 23, Val Loss: 1.91800
Epoch 24, Val Loss: 1.90849
Epoch 25, Val Loss: 1.90172
Epoch 26, Val Loss: 1.94516
Epoch 27, Val Loss: 1.94833
Epoch 28, Val Loss: 1.90115
Epoch 29, Val Loss: 1.90536
Epoch 30, Val Loss: 1.90973
Epoch 31, Val Loss: 1.92158
Epoch 32, Val Loss: 1.91413
Epoch 33, Val Loss: 1.91353
Epoch 34, Val Loss: 1.90876
Epoch 35, Val Loss: 1.91744
Epoch 36, Val Loss: 1.91705
Epoch 37, Val Loss: 1.91886
Epoch 38, Val Loss: 1.94000
Epoch 39, Val Loss: 1.90209
Epoch 40, Val Loss: 1.93048
Epoch 41, Val Loss: 1.89752
Epoch 42, Val Loss: 1.91164
Epoch 43, Val Loss: 1.91283
Epoch 44, Val Loss: 1.89755
Epoch 45, Val Loss: 1.91492
Epoch 46, Val Loss: 1.89720
Epoch 47, Val Loss: 1.91082
Epoch 48, Val Loss: 1.89753
Epoch 49, Val Loss: 1.93295
Epoch 50, Val Loss: 1.91608
Epoch 51, Val Loss: 1.90861
Epoch 52, Val Loss: 1.89956
Epoch 53, Val Loss: 1.92271
Epoch 54, Val Loss: 1.90166
Epoch 55, Val Loss: 1.90606
Epoch 56, Val Loss: 1.89861
Epoch 57, Val Loss: 1.91644
Epoch 58, Val Loss: 1.90848
Epoch 59, Val Loss: 1.93299
Epoch 60, Val Loss: 1.91827
Epoch 61, Val Loss: 1.90349
Epoch 62, Val Loss: 1.91404
Epoch 63, Val Loss: 1.92121
Epoch 64, Val Loss: 1.89977
Epoch 65, Val Loss: 1.89740
Epoch 66, Val Loss: 1.89791
Epoch 67, Val Loss: 1.91133
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.9028, 'Log Loss - std': 0.21169999999999978} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}
Fitted encoder
Epoch 0, Val Loss: 2.17480
Epoch 1, Val Loss: 2.16679
Epoch 2, Val Loss: 2.15726
Epoch 3, Val Loss: 2.15319
Epoch 4, Val Loss: 2.15476
Epoch 5, Val Loss: 2.14890
Epoch 6, Val Loss: 2.14572
Epoch 7, Val Loss: 2.13588
Epoch 8, Val Loss: 2.09992
Epoch 9, Val Loss: 2.12304
Epoch 10, Val Loss: 2.11822
Epoch 11, Val Loss: 2.09885
Epoch 12, Val Loss: 2.09926
Epoch 13, Val Loss: 2.09914
Epoch 14, Val Loss: 2.11500
Epoch 15, Val Loss: 2.09506
Epoch 16, Val Loss: 2.08900
Epoch 17, Val Loss: 2.10619
Epoch 18, Val Loss: 2.09126
Epoch 19, Val Loss: 2.08580
Epoch 20, Val Loss: 2.10205
Epoch 21, Val Loss: 2.09583
Epoch 22, Val Loss: 2.07703
Epoch 23, Val Loss: 2.07762
Epoch 24, Val Loss: 2.08298
Epoch 25, Val Loss: 2.08454
Epoch 26, Val Loss: 2.08547
Epoch 27, Val Loss: 2.08051
Epoch 28, Val Loss: 2.10194
Epoch 29, Val Loss: 2.12227
Epoch 30, Val Loss: 2.09467
Epoch 31, Val Loss: 2.07084
Epoch 32, Val Loss: 2.09315
Epoch 33, Val Loss: 2.12575
Epoch 34, Val Loss: 2.10813
Epoch 35, Val Loss: 2.08875
Epoch 36, Val Loss: 2.07928
Epoch 37, Val Loss: 2.09494
Epoch 38, Val Loss: 2.07226
Epoch 39, Val Loss: 2.09154
Epoch 40, Val Loss: 2.10111
Epoch 41, Val Loss: 2.08789
Epoch 42, Val Loss: 2.07872
Epoch 43, Val Loss: 2.07434
Epoch 44, Val Loss: 2.07488
Epoch 45, Val Loss: 2.08187
Epoch 46, Val Loss: 2.06980
Epoch 47, Val Loss: 2.08219
Epoch 48, Val Loss: 2.07848
Epoch 49, Val Loss: 2.06869
Epoch 50, Val Loss: 2.09729
Epoch 51, Val Loss: 2.09117
Epoch 52, Val Loss: 2.07724
Epoch 53, Val Loss: 2.06693
Epoch 54, Val Loss: 2.07166
Epoch 55, Val Loss: 2.07329
Epoch 56, Val Loss: 2.06917
Epoch 57, Val Loss: 2.06255
Epoch 58, Val Loss: 2.07343
Epoch 59, Val Loss: 2.09843
Epoch 60, Val Loss: 2.07513
Epoch 61, Val Loss: 2.07965
Epoch 62, Val Loss: 2.08935
Epoch 63, Val Loss: 2.07891
Epoch 64, Val Loss: 2.06600
Epoch 65, Val Loss: 2.07676
Epoch 66, Val Loss: 2.08447
Epoch 67, Val Loss: 2.07751
Epoch 68, Val Loss: 2.06499
Epoch 69, Val Loss: 2.07826
Epoch 70, Val Loss: 2.10309
Epoch 71, Val Loss: 2.06495
Epoch 72, Val Loss: 2.09758
Epoch 73, Val Loss: 2.13991
Epoch 74, Val Loss: 2.09340
Epoch 75, Val Loss: 2.08953
Epoch 76, Val Loss: 2.06746
Epoch 77, Val Loss: 2.07217
Epoch 78, Val Loss: 2.06808
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.794066666666667, 'Log Loss - std': 0.231352117392995} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}
Fitted encoder
Epoch 0, Val Loss: 2.08475
Epoch 1, Val Loss: 2.07874
Epoch 2, Val Loss: 2.06834
Epoch 3, Val Loss: 2.06745
Epoch 4, Val Loss: 2.06915
Epoch 5, Val Loss: 2.05915
Epoch 6, Val Loss: 2.07361
Epoch 7, Val Loss: 2.06540
Epoch 8, Val Loss: 2.06840
Epoch 9, Val Loss: 2.06396
Epoch 10, Val Loss: 2.06107
Epoch 11, Val Loss: 2.05561
Epoch 12, Val Loss: 2.05759
Epoch 13, Val Loss: 2.06084
Epoch 14, Val Loss: 2.06803
Epoch 15, Val Loss: 2.05846
Epoch 16, Val Loss: 2.05728
Epoch 17, Val Loss: 2.05384
Epoch 18, Val Loss: 2.05957
Epoch 19, Val Loss: 2.05383
Epoch 20, Val Loss: 2.06088
Epoch 21, Val Loss: 2.05518
Epoch 22, Val Loss: 2.05441
Epoch 23, Val Loss: 2.05910
Epoch 24, Val Loss: 2.05827
Epoch 25, Val Loss: 2.05671
Epoch 26, Val Loss: 2.04747
Epoch 27, Val Loss: 2.04732
Epoch 28, Val Loss: 2.05737
Epoch 29, Val Loss: 2.05588
Epoch 30, Val Loss: 2.05001
Epoch 31, Val Loss: 2.05183
Epoch 32, Val Loss: 2.05569
Epoch 33, Val Loss: 2.06412
Epoch 34, Val Loss: 2.06144
Epoch 35, Val Loss: 2.06299
Epoch 36, Val Loss: 2.06271
Epoch 37, Val Loss: 2.05279
Epoch 38, Val Loss: 2.05183
Epoch 39, Val Loss: 2.04986
Epoch 40, Val Loss: 2.04744
Epoch 41, Val Loss: 2.04921
Epoch 42, Val Loss: 2.05323
Epoch 43, Val Loss: 2.05105
Epoch 44, Val Loss: 2.05052
Epoch 45, Val Loss: 2.05387
Epoch 46, Val Loss: 2.05213
Epoch 47, Val Loss: 2.04371
Epoch 48, Val Loss: 2.04458
Epoch 49, Val Loss: 2.04156
Epoch 50, Val Loss: 2.03799
Epoch 51, Val Loss: 2.03224
Epoch 52, Val Loss: 2.02959
Epoch 53, Val Loss: 2.04668
Epoch 54, Val Loss: 2.03635
Epoch 55, Val Loss: 2.05759
Epoch 56, Val Loss: 2.03451
Epoch 57, Val Loss: 2.02423
Epoch 58, Val Loss: 2.02689
Epoch 59, Val Loss: 2.04251
Epoch 60, Val Loss: 2.03463
Epoch 61, Val Loss: 2.04058
Epoch 62, Val Loss: 2.02226
Epoch 63, Val Loss: 2.04125
Epoch 64, Val Loss: 2.02220
Epoch 65, Val Loss: 2.03715
Epoch 66, Val Loss: 2.03940
Epoch 67, Val Loss: 2.03344
Epoch 68, Val Loss: 2.03082
Epoch 69, Val Loss: 2.03846
Epoch 70, Val Loss: 2.06882
Epoch 71, Val Loss: 2.03201
Epoch 72, Val Loss: 2.02700
Epoch 73, Val Loss: 2.05524
Epoch 74, Val Loss: 2.01986
Epoch 75, Val Loss: 2.05026
Epoch 76, Val Loss: 2.02490
Epoch 77, Val Loss: 2.02634
Epoch 78, Val Loss: 2.02564
Epoch 79, Val Loss: 2.02120
Epoch 80, Val Loss: 2.07729
Epoch 81, Val Loss: 2.01967
Epoch 82, Val Loss: 2.02204
Epoch 83, Val Loss: 2.01215
Epoch 84, Val Loss: 2.04910
Epoch 85, Val Loss: 2.03666
Epoch 86, Val Loss: 2.02479
Epoch 87, Val Loss: 2.04950
Epoch 88, Val Loss: 2.04534
Epoch 89, Val Loss: 2.01449
Epoch 90, Val Loss: 2.02606
Epoch 91, Val Loss: 2.02695
Epoch 92, Val Loss: 2.01339
Epoch 93, Val Loss: 2.03824
Epoch 94, Val Loss: 2.02682
Epoch 95, Val Loss: 2.03410
Epoch 96, Val Loss: 2.00791
Epoch 97, Val Loss: 2.01786
Epoch 98, Val Loss: 2.02139
Epoch 99, Val Loss: 2.01128
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.53465, 'Log Loss - std': 0.49196938166922527} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}
Fitted encoder
Epoch 0, Val Loss: 1.96482
Epoch 1, Val Loss: 1.96565
Epoch 2, Val Loss: 1.95896
Epoch 3, Val Loss: 1.94840
Epoch 4, Val Loss: 1.94770
Epoch 5, Val Loss: 1.94210
Epoch 6, Val Loss: 1.94094
Epoch 7, Val Loss: 1.95434
Epoch 8, Val Loss: 1.95764
Epoch 9, Val Loss: 1.94443
Epoch 10, Val Loss: 1.94009
Epoch 11, Val Loss: 1.94051
Epoch 12, Val Loss: 1.94020
Epoch 13, Val Loss: 1.94277
Epoch 14, Val Loss: 1.94021
Epoch 15, Val Loss: 1.96592
Epoch 16, Val Loss: 1.95174
Epoch 17, Val Loss: 1.96597
Epoch 18, Val Loss: 1.96285
Epoch 19, Val Loss: 1.93930
Epoch 20, Val Loss: 1.94734
Epoch 21, Val Loss: 1.93874
Epoch 22, Val Loss: 1.94213
Epoch 23, Val Loss: 1.95088
Epoch 24, Val Loss: 1.94949
Epoch 25, Val Loss: 1.93781
Epoch 26, Val Loss: 1.94357
Epoch 27, Val Loss: 1.93842
Epoch 28, Val Loss: 1.94168
Epoch 29, Val Loss: 1.94267
Epoch 30, Val Loss: 1.94014
Epoch 31, Val Loss: 1.94741
Epoch 32, Val Loss: 1.94334
Epoch 33, Val Loss: 1.94054
Epoch 34, Val Loss: 1.93924
Epoch 35, Val Loss: 1.93823
Epoch 36, Val Loss: 1.94057
Epoch 37, Val Loss: 1.93989
Epoch 38, Val Loss: 1.94280
Epoch 39, Val Loss: 1.93646
Epoch 40, Val Loss: 1.94505
Epoch 41, Val Loss: 1.94714
Epoch 42, Val Loss: 1.93887
Epoch 43, Val Loss: 1.93734
Epoch 44, Val Loss: 1.93729
Epoch 45, Val Loss: 1.93941
Epoch 46, Val Loss: 1.93550
Epoch 47, Val Loss: 1.94569
Epoch 48, Val Loss: 1.94130
Epoch 49, Val Loss: 1.94068
Epoch 50, Val Loss: 1.93529
Epoch 51, Val Loss: 1.93859
Epoch 52, Val Loss: 1.94210
Epoch 53, Val Loss: 1.93946
Epoch 54, Val Loss: 1.93528
Epoch 55, Val Loss: 1.93550
Epoch 56, Val Loss: 1.94508
Epoch 57, Val Loss: 1.94483
Epoch 58, Val Loss: 1.93761
Epoch 59, Val Loss: 1.93553
Epoch 60, Val Loss: 1.93478
Epoch 61, Val Loss: 1.93848
Epoch 62, Val Loss: 1.93358
Epoch 63, Val Loss: 1.93243
Epoch 64, Val Loss: 1.93270
Epoch 65, Val Loss: 1.94247
Epoch 66, Val Loss: 1.94508
Epoch 67, Val Loss: 1.92841
Epoch 68, Val Loss: 1.93146
Epoch 69, Val Loss: 1.93053
Epoch 70, Val Loss: 1.92509
Epoch 71, Val Loss: 1.92272
Epoch 72, Val Loss: 1.92556
Epoch 73, Val Loss: 1.92311
Epoch 74, Val Loss: 1.93099
Epoch 75, Val Loss: 1.92473
Epoch 76, Val Loss: 1.94261
Epoch 77, Val Loss: 1.92802
Epoch 78, Val Loss: 1.92547
Epoch 79, Val Loss: 1.92415
Epoch 80, Val Loss: 1.91430
Epoch 81, Val Loss: 1.91235
Epoch 82, Val Loss: 1.92050
Epoch 83, Val Loss: 1.91409
Epoch 84, Val Loss: 1.91529
Epoch 85, Val Loss: 1.92406
Epoch 86, Val Loss: 1.94357
Epoch 87, Val Loss: 1.91858
Epoch 88, Val Loss: 1.90828
Epoch 89, Val Loss: 1.92477
Epoch 90, Val Loss: 1.90911
Epoch 91, Val Loss: 1.91793
Epoch 92, Val Loss: 1.92141
Epoch 93, Val Loss: 1.92660
Epoch 94, Val Loss: 1.92014
Epoch 95, Val Loss: 1.92493
Epoch 96, Val Loss: 1.91865
Epoch 97, Val Loss: 1.91552
Epoch 98, Val Loss: 1.91778
Epoch 99, Val Loss: 1.91639
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.4459600000000004, 'Log Loss - std': 0.47443731134892825} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 51 finished with value: 3.4459600000000004 and parameters: {'p_m': 0.483989703843692, 'alpha': 1.7036840954156345, 'K': 3, 'beta': 0.6100121972558048}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}
Fitted encoder
Epoch 0, Val Loss: 2.17598
Epoch 1, Val Loss: 2.16084
Epoch 2, Val Loss: 2.13126
Epoch 3, Val Loss: 2.12037
Epoch 4, Val Loss: 2.13426
Epoch 5, Val Loss: 2.14658
Epoch 6, Val Loss: 2.08513
Epoch 7, Val Loss: 2.11530
Epoch 8, Val Loss: 2.12632
Epoch 9, Val Loss: 2.08294
Epoch 10, Val Loss: 2.09213
Epoch 11, Val Loss: 2.12980
Epoch 12, Val Loss: 2.11706
Epoch 13, Val Loss: 2.07342
Epoch 14, Val Loss: 2.09901
Epoch 15, Val Loss: 2.09141
Epoch 16, Val Loss: 2.11554
Epoch 17, Val Loss: 2.11004
Epoch 18, Val Loss: 2.09298
Epoch 19, Val Loss: 2.10338
Epoch 20, Val Loss: 2.09197
Epoch 21, Val Loss: 2.08517
Epoch 22, Val Loss: 2.07859
Epoch 23, Val Loss: 2.09876
Epoch 24, Val Loss: 2.07997
Epoch 25, Val Loss: 2.10091
Epoch 26, Val Loss: 2.09945
Epoch 27, Val Loss: 2.06397
Epoch 28, Val Loss: 2.13856
Epoch 29, Val Loss: 2.08410
Epoch 30, Val Loss: 2.08523
Epoch 31, Val Loss: 2.07847
Epoch 32, Val Loss: 2.09088
Epoch 33, Val Loss: 2.06207
Epoch 34, Val Loss: 2.06337
Epoch 35, Val Loss: 2.10592
Epoch 36, Val Loss: 2.05615
Epoch 37, Val Loss: 2.08352
Epoch 38, Val Loss: 2.07578
Epoch 39, Val Loss: 2.07422
Epoch 40, Val Loss: 2.06803
Epoch 41, Val Loss: 2.07555
Epoch 42, Val Loss: 2.06000
Epoch 43, Val Loss: 2.08546
Epoch 44, Val Loss: 2.06971
Epoch 45, Val Loss: 2.08431
Epoch 46, Val Loss: 2.08350
Epoch 47, Val Loss: 2.08263
Epoch 48, Val Loss: 2.06470
Epoch 49, Val Loss: 2.06942
Epoch 50, Val Loss: 2.06946
Epoch 51, Val Loss: 2.08367
Epoch 52, Val Loss: 2.08370
Epoch 53, Val Loss: 2.06729
Epoch 54, Val Loss: 2.06937
Epoch 55, Val Loss: 2.09223
Epoch 56, Val Loss: 2.05775
Epoch 57, Val Loss: 2.08753
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.3245, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}
Fitted encoder
Epoch 0, Val Loss: 1.96273
Epoch 1, Val Loss: 1.96112
Epoch 2, Val Loss: 1.95815
Epoch 3, Val Loss: 1.95698
Epoch 4, Val Loss: 1.94427
Epoch 5, Val Loss: 1.94539
Epoch 6, Val Loss: 1.95330
Epoch 7, Val Loss: 1.94972
Epoch 8, Val Loss: 1.93979
Epoch 9, Val Loss: 1.94350
Epoch 10, Val Loss: 1.93051
Epoch 11, Val Loss: 1.94788
Epoch 12, Val Loss: 1.92583
Epoch 13, Val Loss: 1.93327
Epoch 14, Val Loss: 1.92736
Epoch 15, Val Loss: 1.93384
Epoch 16, Val Loss: 1.98275
Epoch 17, Val Loss: 1.92849
Epoch 18, Val Loss: 1.92122
Epoch 19, Val Loss: 1.92217
Epoch 20, Val Loss: 1.91731
Epoch 21, Val Loss: 1.92858
Epoch 22, Val Loss: 1.91357
Epoch 23, Val Loss: 1.92100
Epoch 24, Val Loss: 1.94226
Epoch 25, Val Loss: 1.93342
Epoch 26, Val Loss: 1.91235
Epoch 27, Val Loss: 1.91274
Epoch 28, Val Loss: 1.90773
Epoch 29, Val Loss: 1.91446
Epoch 30, Val Loss: 1.97537
Epoch 31, Val Loss: 1.90869
Epoch 32, Val Loss: 1.91409
Epoch 33, Val Loss: 1.92858
Epoch 34, Val Loss: 1.94922
Epoch 35, Val Loss: 1.90926
Epoch 36, Val Loss: 1.91462
Epoch 37, Val Loss: 1.91743
Epoch 38, Val Loss: 1.90603
Epoch 39, Val Loss: 1.89692
Epoch 40, Val Loss: 1.90855
Epoch 41, Val Loss: 1.90725
Epoch 42, Val Loss: 1.90650
Epoch 43, Val Loss: 1.90628
Epoch 44, Val Loss: 1.90739
Epoch 45, Val Loss: 1.92193
Epoch 46, Val Loss: 1.90457
Epoch 47, Val Loss: 1.91006
Epoch 48, Val Loss: 1.94024
Epoch 49, Val Loss: 1.90531
Epoch 50, Val Loss: 1.92265
Epoch 51, Val Loss: 1.90917
Epoch 52, Val Loss: 1.90828
Epoch 53, Val Loss: 1.90443
Epoch 54, Val Loss: 1.91125
Epoch 55, Val Loss: 1.90657
Epoch 56, Val Loss: 1.90445
Epoch 57, Val Loss: 1.91669
Epoch 58, Val Loss: 1.91473
Epoch 59, Val Loss: 1.90790
Epoch 60, Val Loss: 1.89987
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.9773499999999995, 'Log Loss - std': 0.34714999999999985} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}
Fitted encoder
Epoch 0, Val Loss: 2.15063
Epoch 1, Val Loss: 2.14531
Epoch 2, Val Loss: 2.09209
Epoch 3, Val Loss: 2.07872
Epoch 4, Val Loss: 2.08274
Epoch 5, Val Loss: 2.06951
Epoch 6, Val Loss: 2.02800
Epoch 7, Val Loss: 2.10154
Epoch 8, Val Loss: 2.03521
Epoch 9, Val Loss: 2.03710
Epoch 10, Val Loss: 2.02355
Epoch 11, Val Loss: 2.09579
Epoch 12, Val Loss: 2.06561
Epoch 13, Val Loss: 2.09416
Epoch 14, Val Loss: 2.05555
Epoch 15, Val Loss: 2.06085
Epoch 16, Val Loss: 2.05192
Epoch 17, Val Loss: 2.03069
Epoch 18, Val Loss: 2.04989
Epoch 19, Val Loss: 2.05192
Epoch 20, Val Loss: 2.01853
Epoch 21, Val Loss: 2.06452
Epoch 22, Val Loss: 2.02099
Epoch 23, Val Loss: 2.04909
Epoch 24, Val Loss: 2.08397
Epoch 25, Val Loss: 2.05649
Epoch 26, Val Loss: 2.06752
Epoch 27, Val Loss: 2.05011
Epoch 28, Val Loss: 2.04321
Epoch 29, Val Loss: 2.02548
Epoch 30, Val Loss: 2.11220
Epoch 31, Val Loss: 2.09490
Epoch 32, Val Loss: 2.08212
Epoch 33, Val Loss: 2.04517
Epoch 34, Val Loss: 2.04345
Epoch 35, Val Loss: 2.01338
Epoch 36, Val Loss: 2.03481
Epoch 37, Val Loss: 2.02558
Epoch 38, Val Loss: 2.09183
Epoch 39, Val Loss: 2.08566
Epoch 40, Val Loss: 2.05182
Epoch 41, Val Loss: 2.03345
Epoch 42, Val Loss: 2.02696
Epoch 43, Val Loss: 2.03602
Epoch 44, Val Loss: 2.03509
Epoch 45, Val Loss: 2.01926
Epoch 46, Val Loss: 2.02683
Epoch 47, Val Loss: 2.02120
Epoch 48, Val Loss: 2.03043
Epoch 49, Val Loss: 2.04053
Epoch 50, Val Loss: 2.02729
Epoch 51, Val Loss: 2.09064
Epoch 52, Val Loss: 2.03658
Epoch 53, Val Loss: 2.03361
Epoch 54, Val Loss: 2.04354
Epoch 55, Val Loss: 2.03204
Epoch 56, Val Loss: 2.03319
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.5448999999999997, 'Log Loss - std': 0.6740683100893161} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}
Fitted encoder
Epoch 0, Val Loss: 2.08966
Epoch 1, Val Loss: 2.06990
Epoch 2, Val Loss: 2.06336
Epoch 3, Val Loss: 2.07208
Epoch 4, Val Loss: 2.06632
Epoch 5, Val Loss: 2.04711
Epoch 6, Val Loss: 2.04741
Epoch 7, Val Loss: 2.03094
Epoch 8, Val Loss: 2.04437
Epoch 9, Val Loss: 2.04116
Epoch 10, Val Loss: 2.03954
Epoch 11, Val Loss: 2.04058
Epoch 12, Val Loss: 2.04897
Epoch 13, Val Loss: 2.02891
Epoch 14, Val Loss: 2.01886
Epoch 15, Val Loss: 2.03828
Epoch 16, Val Loss: 2.04747
Epoch 17, Val Loss: 2.03410
Epoch 18, Val Loss: 2.03637
Epoch 19, Val Loss: 2.02322
Epoch 20, Val Loss: 2.05544
Epoch 21, Val Loss: 2.03873
Epoch 22, Val Loss: 2.08695
Epoch 23, Val Loss: 2.03112
Epoch 24, Val Loss: 2.04558
Epoch 25, Val Loss: 2.05892
Epoch 26, Val Loss: 2.03061
Epoch 27, Val Loss: 2.02719
Epoch 28, Val Loss: 2.01935
Epoch 29, Val Loss: 2.01910
Epoch 30, Val Loss: 2.01214
Epoch 31, Val Loss: 2.03834
Epoch 32, Val Loss: 2.03364
Epoch 33, Val Loss: 2.02058
Epoch 34, Val Loss: 2.00541
Epoch 35, Val Loss: 2.01817
Epoch 36, Val Loss: 2.02300
Epoch 37, Val Loss: 2.01842
Epoch 38, Val Loss: 2.02487
Epoch 39, Val Loss: 2.02523
Epoch 40, Val Loss: 2.01389
Epoch 41, Val Loss: 2.03153
Epoch 42, Val Loss: 2.02651
Epoch 43, Val Loss: 2.02958
Epoch 44, Val Loss: 2.04170
Epoch 45, Val Loss: 2.05566
Epoch 46, Val Loss: 2.04017
Epoch 47, Val Loss: 2.01752
Epoch 48, Val Loss: 2.01214
Epoch 49, Val Loss: 2.01097
Epoch 50, Val Loss: 2.01769
Epoch 51, Val Loss: 2.01911
Epoch 52, Val Loss: 2.02840
Epoch 53, Val Loss: 2.00823
Epoch 54, Val Loss: 2.03696
Epoch 55, Val Loss: 2.05977
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.5138749999999996, 'Log Loss - std': 0.5862283828637093} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}
Fitted encoder
Epoch 0, Val Loss: 1.94615
Epoch 1, Val Loss: 1.93867
Epoch 2, Val Loss: 1.93039
Epoch 3, Val Loss: 1.97187
Epoch 4, Val Loss: 1.95322
Epoch 5, Val Loss: 1.92726
Epoch 6, Val Loss: 1.92604
Epoch 7, Val Loss: 1.95475
Epoch 8, Val Loss: 1.92691
Epoch 9, Val Loss: 1.91138
Epoch 10, Val Loss: 1.90843
Epoch 11, Val Loss: 1.91831
Epoch 12, Val Loss: 1.94547
Epoch 13, Val Loss: 1.91612
Epoch 14, Val Loss: 1.92073
Epoch 15, Val Loss: 1.91793
Epoch 16, Val Loss: 1.91328
Epoch 17, Val Loss: 1.90638
Epoch 18, Val Loss: 1.94856
Epoch 19, Val Loss: 1.92727
Epoch 20, Val Loss: 2.03546
Epoch 21, Val Loss: 2.01391
Epoch 22, Val Loss: 2.02620
Epoch 23, Val Loss: 2.02652
Epoch 24, Val Loss: 1.99828
Epoch 25, Val Loss: 1.96823
Epoch 26, Val Loss: 1.97008
Epoch 27, Val Loss: 1.93268
Epoch 28, Val Loss: 1.89419
Epoch 29, Val Loss: 1.91935
Epoch 30, Val Loss: 1.93518
Epoch 31, Val Loss: 1.92014
Epoch 32, Val Loss: 1.89845
Epoch 33, Val Loss: 1.91993
Epoch 34, Val Loss: 1.91577
Epoch 35, Val Loss: 1.92682
Epoch 36, Val Loss: 1.95703
Epoch 37, Val Loss: 1.92966
Epoch 38, Val Loss: 1.91848
Epoch 39, Val Loss: 1.91058
Epoch 40, Val Loss: 1.91438
Epoch 41, Val Loss: 1.89739
Epoch 42, Val Loss: 1.93823
Epoch 43, Val Loss: 1.93457
Epoch 44, Val Loss: 1.91353
Epoch 45, Val Loss: 1.93081
Epoch 46, Val Loss: 1.92392
Epoch 47, Val Loss: 1.93341
Epoch 48, Val Loss: 1.92598
Epoch 49, Val Loss: 1.90854
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.5645799999999994, 'Log Loss - std': 0.5340552046371234} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 52 finished with value: 3.5645799999999994 and parameters: {'p_m': 0.8356972311717555, 'alpha': 3.1708776680056565, 'K': 2, 'beta': 2.052196688309851}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}
Fitted encoder
Epoch 0, Val Loss: 2.12872
Epoch 1, Val Loss: 2.12742
Epoch 2, Val Loss: 2.14833
Epoch 3, Val Loss: 2.13061
Epoch 4, Val Loss: 2.13169
Epoch 5, Val Loss: 2.12115
Epoch 6, Val Loss: 2.12265
Epoch 7, Val Loss: 2.09150
Epoch 8, Val Loss: 2.07110
Epoch 9, Val Loss: 2.13750
Epoch 10, Val Loss: 2.10350
Epoch 11, Val Loss: 2.11291
Epoch 12, Val Loss: 2.09651
Epoch 13, Val Loss: 2.12679
Epoch 14, Val Loss: 2.09129
Epoch 15, Val Loss: 2.08459
Epoch 16, Val Loss: 2.09539
Epoch 17, Val Loss: 2.10480
Epoch 18, Val Loss: 2.07665
Epoch 19, Val Loss: 2.08336
Epoch 20, Val Loss: 2.05371
Epoch 21, Val Loss: 2.07426
Epoch 22, Val Loss: 2.10020
Epoch 23, Val Loss: 2.07780
Epoch 24, Val Loss: 2.10572
Epoch 25, Val Loss: 2.09489
Epoch 26, Val Loss: 2.07786
Epoch 27, Val Loss: 2.11649
Epoch 28, Val Loss: 2.09608
Epoch 29, Val Loss: 2.09982
Epoch 30, Val Loss: 2.08466
Epoch 31, Val Loss: 2.07468
Epoch 32, Val Loss: 2.09632
Epoch 33, Val Loss: 2.12242
Epoch 34, Val Loss: 2.07636
Epoch 35, Val Loss: 2.06308
Epoch 36, Val Loss: 2.04264
Epoch 37, Val Loss: 2.05194
Epoch 38, Val Loss: 2.06433
Epoch 39, Val Loss: 2.03835
Epoch 40, Val Loss: 2.06739
Epoch 41, Val Loss: 2.04481
Epoch 42, Val Loss: 2.03865
Epoch 43, Val Loss: 2.05565
Epoch 44, Val Loss: 2.06163
Epoch 45, Val Loss: 2.08992
Epoch 46, Val Loss: 2.05479
Epoch 47, Val Loss: 2.04672
Epoch 48, Val Loss: 2.05644
Epoch 49, Val Loss: 2.05955
Epoch 50, Val Loss: 2.06328
Epoch 51, Val Loss: 2.04581
Epoch 52, Val Loss: 2.04247
Epoch 53, Val Loss: 2.04414
Epoch 54, Val Loss: 2.04341
Epoch 55, Val Loss: 2.04543
Epoch 56, Val Loss: 2.06275
Epoch 57, Val Loss: 2.05806
Epoch 58, Val Loss: 2.04547
Epoch 59, Val Loss: 2.07006
Epoch 60, Val Loss: 2.04288
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.3708, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}
Fitted encoder
Epoch 0, Val Loss: 1.93552
Epoch 1, Val Loss: 1.93899
Epoch 2, Val Loss: 1.94418
Epoch 3, Val Loss: 1.92599
Epoch 4, Val Loss: 1.91859
Epoch 5, Val Loss: 1.92926
Epoch 6, Val Loss: 1.92902
Epoch 7, Val Loss: 1.92718
Epoch 8, Val Loss: 1.91690
Epoch 9, Val Loss: 1.93018
Epoch 10, Val Loss: 1.91603
Epoch 11, Val Loss: 1.94342
Epoch 12, Val Loss: 1.91009
Epoch 13, Val Loss: 1.92445
Epoch 14, Val Loss: 1.92508
Epoch 15, Val Loss: 1.93593
Epoch 16, Val Loss: 1.93595
Epoch 17, Val Loss: 1.89332
Epoch 18, Val Loss: 1.93820
Epoch 19, Val Loss: 1.92416
Epoch 20, Val Loss: 1.93031
Epoch 21, Val Loss: 1.95308
Epoch 22, Val Loss: 1.94223
Epoch 23, Val Loss: 1.89947
Epoch 24, Val Loss: 1.92612
Epoch 25, Val Loss: 1.91634
Epoch 26, Val Loss: 1.91564
Epoch 27, Val Loss: 1.91685
Epoch 28, Val Loss: 1.92462
Epoch 29, Val Loss: 1.93338
Epoch 30, Val Loss: 1.92667
Epoch 31, Val Loss: 1.91270
Epoch 32, Val Loss: 1.95357
Epoch 33, Val Loss: 1.96101
Epoch 34, Val Loss: 1.93130
Epoch 35, Val Loss: 1.90032
Epoch 36, Val Loss: 1.93618
Epoch 37, Val Loss: 1.90786
Epoch 38, Val Loss: 1.91394
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.5147500000000003, 'Log Loss - std': 0.14395000000000002} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}
Fitted encoder
Epoch 0, Val Loss: 2.13288
Epoch 1, Val Loss: 2.13025
Epoch 2, Val Loss: 2.12243
Epoch 3, Val Loss: 2.12854
Epoch 4, Val Loss: 2.11243
Epoch 5, Val Loss: 2.12583
Epoch 6, Val Loss: 2.11497
Epoch 7, Val Loss: 2.11465
Epoch 8, Val Loss: 2.08807
Epoch 9, Val Loss: 2.07009
Epoch 10, Val Loss: 2.11009
Epoch 11, Val Loss: 2.11595
Epoch 12, Val Loss: 2.07200
Epoch 13, Val Loss: 2.10359
Epoch 14, Val Loss: 2.10843
Epoch 15, Val Loss: 2.09450
Epoch 16, Val Loss: 2.08315
Epoch 17, Val Loss: 2.08486
Epoch 18, Val Loss: 2.04999
Epoch 19, Val Loss: 2.14555
Epoch 20, Val Loss: 2.10344
Epoch 21, Val Loss: 2.09923
Epoch 22, Val Loss: 2.11071
Epoch 23, Val Loss: 2.07603
Epoch 24, Val Loss: 2.08452
Epoch 25, Val Loss: 2.10749
Epoch 26, Val Loss: 2.07882
Epoch 27, Val Loss: 2.05938
Epoch 28, Val Loss: 2.10400
Epoch 29, Val Loss: 2.06410
Epoch 30, Val Loss: 2.08131
Epoch 31, Val Loss: 2.07839
Epoch 32, Val Loss: 2.06545
Epoch 33, Val Loss: 2.07587
Epoch 34, Val Loss: 2.07229
Epoch 35, Val Loss: 2.09377
Epoch 36, Val Loss: 2.06884
Epoch 37, Val Loss: 2.07520
Epoch 38, Val Loss: 2.07337
Epoch 39, Val Loss: 2.11069
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.285, 'Log Loss - std': 0.3455206602602321} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}
Fitted encoder
Epoch 0, Val Loss: 2.13558
Epoch 1, Val Loss: 2.07943
Epoch 2, Val Loss: 2.06683
Epoch 3, Val Loss: 2.05893
Epoch 4, Val Loss: 2.05196
Epoch 5, Val Loss: 2.07380
Epoch 6, Val Loss: 2.06654
Epoch 7, Val Loss: 2.05939
Epoch 8, Val Loss: 2.11489
Epoch 9, Val Loss: 2.12651
Epoch 10, Val Loss: 2.13180
Epoch 11, Val Loss: 2.12668
Epoch 12, Val Loss: 2.05769
Epoch 13, Val Loss: 2.07925
Epoch 14, Val Loss: 2.06191
Epoch 15, Val Loss: 2.11975
Epoch 16, Val Loss: 2.07310
Epoch 17, Val Loss: 2.05756
Epoch 18, Val Loss: 2.06966
Epoch 19, Val Loss: 2.09951
Epoch 20, Val Loss: 2.07142
Epoch 21, Val Loss: 2.06603
Epoch 22, Val Loss: 2.04764
Epoch 23, Val Loss: 2.10730
Epoch 24, Val Loss: 2.07838
Epoch 25, Val Loss: 2.05179
Epoch 26, Val Loss: 2.05859
Epoch 27, Val Loss: 2.06553
Epoch 28, Val Loss: 2.05064
Epoch 29, Val Loss: 2.06940
Epoch 30, Val Loss: 2.05089
Epoch 31, Val Loss: 2.07260
Epoch 32, Val Loss: 2.05543
Epoch 33, Val Loss: 2.05624
Epoch 34, Val Loss: 2.03969
Epoch 35, Val Loss: 2.08071
Epoch 36, Val Loss: 2.06359
Epoch 37, Val Loss: 2.05382
Epoch 38, Val Loss: 2.04618
Epoch 39, Val Loss: 2.05234
Epoch 40, Val Loss: 2.04905
Epoch 41, Val Loss: 2.07764
Epoch 42, Val Loss: 2.04178
Epoch 43, Val Loss: 2.06921
Epoch 44, Val Loss: 2.06357
Epoch 45, Val Loss: 2.06676
Epoch 46, Val Loss: 2.05570
Epoch 47, Val Loss: 2.05958
Epoch 48, Val Loss: 2.06132
Epoch 49, Val Loss: 2.05748
Epoch 50, Val Loss: 2.06297
Epoch 51, Val Loss: 2.05863
Epoch 52, Val Loss: 2.08246
Epoch 53, Val Loss: 2.06620
Epoch 54, Val Loss: 2.05414
Epoch 55, Val Loss: 2.06662
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.252675, 'Log Loss - std': 0.3044225876557126} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}
Fitted encoder
Epoch 0, Val Loss: 1.96123
Epoch 1, Val Loss: 1.94856
Epoch 2, Val Loss: 1.93796
Epoch 3, Val Loss: 1.93314
Epoch 4, Val Loss: 1.91950
Epoch 5, Val Loss: 1.94593
Epoch 6, Val Loss: 1.93151
Epoch 7, Val Loss: 1.90721
Epoch 8, Val Loss: 1.91886
Epoch 9, Val Loss: 2.07363
Epoch 10, Val Loss: 1.91849
Epoch 11, Val Loss: 1.89765
Epoch 12, Val Loss: 1.90398
Epoch 13, Val Loss: 1.91589
Epoch 14, Val Loss: 1.92136
Epoch 15, Val Loss: 1.91041
Epoch 16, Val Loss: 1.90097
Epoch 17, Val Loss: 1.91808
Epoch 18, Val Loss: 1.91148
Epoch 19, Val Loss: 1.89600
Epoch 20, Val Loss: 1.92554
Epoch 21, Val Loss: 1.87357
Epoch 22, Val Loss: 1.93191
Epoch 23, Val Loss: 1.90453
Epoch 24, Val Loss: 1.89054
Epoch 25, Val Loss: 1.90056
Epoch 26, Val Loss: 1.88586
Epoch 27, Val Loss: 1.89772
Epoch 28, Val Loss: 1.92324
Epoch 29, Val Loss: 1.88744
Epoch 30, Val Loss: 1.89711
Epoch 31, Val Loss: 1.88653
Epoch 32, Val Loss: 1.91926
Epoch 33, Val Loss: 1.87573
Epoch 34, Val Loss: 1.88719
Epoch 35, Val Loss: 1.88231
Epoch 36, Val Loss: 1.89055
Epoch 37, Val Loss: 1.90090
Epoch 38, Val Loss: 1.92183
Epoch 39, Val Loss: 1.93544
Epoch 40, Val Loss: 1.90068
Epoch 41, Val Loss: 1.92081
Epoch 42, Val Loss: 1.93318
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.27286, 'Log Loss - std': 0.275260288454401} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 53 finished with value: 3.27286 and parameters: {'p_m': 0.8425440903914723, 'alpha': 2.1818632465566434, 'K': 2, 'beta': 0.8931266070393153}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}
Fitted encoder
Epoch 0, Val Loss: 2.14966
Epoch 1, Val Loss: 2.15516
Epoch 2, Val Loss: 2.11579
Epoch 3, Val Loss: 2.17632
Epoch 4, Val Loss: 2.12844
Epoch 5, Val Loss: 2.13917
Epoch 6, Val Loss: 2.14744
Epoch 7, Val Loss: 2.13803
Epoch 8, Val Loss: 2.13453
Epoch 9, Val Loss: 2.14104
Epoch 10, Val Loss: 2.16783
Epoch 11, Val Loss: 2.15567
Epoch 12, Val Loss: 2.15513
Epoch 13, Val Loss: 2.15573
Epoch 14, Val Loss: 2.15386
Epoch 15, Val Loss: 2.15757
Epoch 16, Val Loss: 2.14107
Epoch 17, Val Loss: 2.16020
Epoch 18, Val Loss: 2.15137
Epoch 19, Val Loss: 2.13857
Epoch 20, Val Loss: 2.13464
Epoch 21, Val Loss: 2.13840
Epoch 22, Val Loss: 2.13938
Epoch 23, Val Loss: 2.13143
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.6556, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}
Fitted encoder
Epoch 0, Val Loss: 1.97293
Epoch 1, Val Loss: 1.96731
Epoch 2, Val Loss: 1.96637
Epoch 3, Val Loss: 1.95628
Epoch 4, Val Loss: 1.93786
Epoch 5, Val Loss: 1.92261
Epoch 6, Val Loss: 2.01163
Epoch 7, Val Loss: 1.93401
Epoch 8, Val Loss: 1.89757
Epoch 9, Val Loss: 1.90290
Epoch 10, Val Loss: 1.91085
Epoch 11, Val Loss: 1.92903
Epoch 12, Val Loss: 1.93340
Epoch 13, Val Loss: 1.90331
Epoch 14, Val Loss: 1.90467
Epoch 15, Val Loss: 1.91217
Epoch 16, Val Loss: 1.89124
Epoch 17, Val Loss: 1.91626
Epoch 18, Val Loss: 1.89861
Epoch 19, Val Loss: 1.89224
Epoch 20, Val Loss: 1.90349
Epoch 21, Val Loss: 1.92262
Epoch 22, Val Loss: 1.98874
Epoch 23, Val Loss: 1.91318
Epoch 24, Val Loss: 1.89770
Epoch 25, Val Loss: 1.89757
Epoch 26, Val Loss: 1.93160
Epoch 27, Val Loss: 1.90673
Epoch 28, Val Loss: 1.88017
Epoch 29, Val Loss: 1.92103
Epoch 30, Val Loss: 1.89278
Epoch 31, Val Loss: 1.88931
Epoch 32, Val Loss: 1.90033
Epoch 33, Val Loss: 1.88698
Epoch 34, Val Loss: 1.88854
Epoch 35, Val Loss: 1.88052
Epoch 36, Val Loss: 1.88883
Epoch 37, Val Loss: 1.91653
Epoch 38, Val Loss: 1.89325
Epoch 39, Val Loss: 1.88875
Epoch 40, Val Loss: 1.88157
Epoch 41, Val Loss: 1.89082
Epoch 42, Val Loss: 1.90077
Epoch 43, Val Loss: 1.88504
Epoch 44, Val Loss: 1.88664
Epoch 45, Val Loss: 1.89341
Epoch 46, Val Loss: 1.91393
Epoch 47, Val Loss: 1.88978
Epoch 48, Val Loss: 1.88945
Epoch 49, Val Loss: 1.91359
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 4.0918, 'Log Loss - std': 0.5637999999999999} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}
Fitted encoder
Epoch 0, Val Loss: 2.13055
Epoch 1, Val Loss: 2.12395
Epoch 2, Val Loss: 2.10645
Epoch 3, Val Loss: 2.09196
Epoch 4, Val Loss: 2.10194
Epoch 5, Val Loss: 2.09956
Epoch 6, Val Loss: 2.09461
Epoch 7, Val Loss: 2.10242
Epoch 8, Val Loss: 2.08755
Epoch 9, Val Loss: 2.10251
Epoch 10, Val Loss: 2.07794
Epoch 11, Val Loss: 2.08449
Epoch 12, Val Loss: 2.06641
Epoch 13, Val Loss: 2.07632
Epoch 14, Val Loss: 2.07477
Epoch 15, Val Loss: 2.06756
Epoch 16, Val Loss: 2.08838
Epoch 17, Val Loss: 2.06957
Epoch 18, Val Loss: 2.08058
Epoch 19, Val Loss: 2.07382
Epoch 20, Val Loss: 2.07900
Epoch 21, Val Loss: 2.07797
Epoch 22, Val Loss: 2.07795
Epoch 23, Val Loss: 2.08450
Epoch 24, Val Loss: 2.09869
Epoch 25, Val Loss: 2.07910
Epoch 26, Val Loss: 2.10243
Epoch 27, Val Loss: 2.08709
Epoch 28, Val Loss: 2.09679
Epoch 29, Val Loss: 2.08631
Epoch 30, Val Loss: 2.08495
Epoch 31, Val Loss: 2.07779
Epoch 32, Val Loss: 2.09875
Epoch 33, Val Loss: 2.07232
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.0902, 'Log Loss - std': 0.46034633339113995} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}
Fitted encoder
Epoch 0, Val Loss: 2.14219
Epoch 1, Val Loss: 2.13006
Epoch 2, Val Loss: 2.12326
Epoch 3, Val Loss: 2.22632
Epoch 4, Val Loss: 2.09747
Epoch 5, Val Loss: 2.15421
Epoch 6, Val Loss: 2.08625
Epoch 7, Val Loss: 2.08825
Epoch 8, Val Loss: 2.10701
Epoch 9, Val Loss: 2.12422
Epoch 10, Val Loss: 2.11264
Epoch 11, Val Loss: 2.10564
Epoch 12, Val Loss: 2.10558
Epoch 13, Val Loss: 2.11309
Epoch 14, Val Loss: 2.12531
Epoch 15, Val Loss: 2.08278
Epoch 16, Val Loss: 2.13894
Epoch 17, Val Loss: 2.13356
Epoch 18, Val Loss: 2.13542
Epoch 19, Val Loss: 2.13189
Epoch 20, Val Loss: 2.13634
Epoch 21, Val Loss: 2.14753
Epoch 22, Val Loss: 2.12778
Epoch 23, Val Loss: 2.13489
Epoch 24, Val Loss: 2.11957
Epoch 25, Val Loss: 2.08813
Epoch 26, Val Loss: 2.09875
Epoch 27, Val Loss: 2.11388
Epoch 28, Val Loss: 2.10031
Epoch 29, Val Loss: 2.09994
Epoch 30, Val Loss: 2.09953
Epoch 31, Val Loss: 2.08349
Epoch 32, Val Loss: 2.08125
Epoch 33, Val Loss: 2.02433
Epoch 34, Val Loss: 2.04647
Epoch 35, Val Loss: 2.03606
Epoch 36, Val Loss: 2.02689
Epoch 37, Val Loss: 2.03870
Epoch 38, Val Loss: 2.02146
Epoch 39, Val Loss: 2.04790
Epoch 40, Val Loss: 2.02777
Epoch 41, Val Loss: 2.02111
Epoch 42, Val Loss: 2.02614
Epoch 43, Val Loss: 2.01966
Epoch 44, Val Loss: 2.02489
Epoch 45, Val Loss: 2.06372
Epoch 46, Val Loss: 2.03463
Epoch 47, Val Loss: 2.03978
Epoch 48, Val Loss: 2.01771
Epoch 49, Val Loss: 2.01558
Epoch 50, Val Loss: 2.05534
Epoch 51, Val Loss: 2.01941
Epoch 52, Val Loss: 2.07118
Epoch 53, Val Loss: 2.01300
Epoch 54, Val Loss: 2.04781
Epoch 55, Val Loss: 2.03509
Epoch 56, Val Loss: 2.03723
Epoch 57, Val Loss: 2.02903
Epoch 58, Val Loss: 2.03056
Epoch 59, Val Loss: 2.05665
Epoch 60, Val Loss: 2.02828
Epoch 61, Val Loss: 2.06075
Epoch 62, Val Loss: 2.04471
Epoch 63, Val Loss: 2.04067
Epoch 64, Val Loss: 2.01568
Epoch 65, Val Loss: 2.01385
Epoch 66, Val Loss: 2.03576
Epoch 67, Val Loss: 2.03165
Epoch 68, Val Loss: 2.02279
Epoch 69, Val Loss: 2.06692
Epoch 70, Val Loss: 2.03744
Epoch 71, Val Loss: 2.03190
Epoch 72, Val Loss: 2.04281
Epoch 73, Val Loss: 2.05578
Epoch 74, Val Loss: 2.03649
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.912775, 'Log Loss - std': 0.5033666177598589} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}
Fitted encoder
Epoch 0, Val Loss: 2.08028
Epoch 1, Val Loss: 1.95559
Epoch 2, Val Loss: 1.96211
Epoch 3, Val Loss: 1.96007
Epoch 4, Val Loss: 1.94555
Epoch 5, Val Loss: 1.94303
Epoch 6, Val Loss: 1.95964
Epoch 7, Val Loss: 1.94671
Epoch 8, Val Loss: 1.94675
Epoch 9, Val Loss: 1.93775
Epoch 10, Val Loss: 1.93254
Epoch 11, Val Loss: 1.94472
Epoch 12, Val Loss: 1.94550
Epoch 13, Val Loss: 1.94605
Epoch 14, Val Loss: 1.94357
Epoch 15, Val Loss: 1.93199
Epoch 16, Val Loss: 1.90973
Epoch 17, Val Loss: 1.94898
Epoch 18, Val Loss: 1.91627
Epoch 19, Val Loss: 1.91463
Epoch 20, Val Loss: 1.91130
Epoch 21, Val Loss: 1.90545
Epoch 22, Val Loss: 1.91380
Epoch 23, Val Loss: 1.88967
Epoch 24, Val Loss: 1.89584
Epoch 25, Val Loss: 1.89813
Epoch 26, Val Loss: 1.90620
Epoch 27, Val Loss: 1.88791
Epoch 28, Val Loss: 1.89830
Epoch 29, Val Loss: 1.88998
Epoch 30, Val Loss: 1.91904
Epoch 31, Val Loss: 1.89500
Epoch 32, Val Loss: 1.90301
Epoch 33, Val Loss: 1.88426
Epoch 34, Val Loss: 1.89800
Epoch 35, Val Loss: 1.88915
Epoch 36, Val Loss: 1.88188
Epoch 37, Val Loss: 1.89148
Epoch 38, Val Loss: 1.90254
Epoch 39, Val Loss: 1.89619
Epoch 40, Val Loss: 1.88837
Epoch 41, Val Loss: 1.89107
Epoch 42, Val Loss: 1.88811
Epoch 43, Val Loss: 1.90292
Epoch 44, Val Loss: 1.90553
Epoch 45, Val Loss: 1.90480
Epoch 46, Val Loss: 1.89793
Epoch 47, Val Loss: 1.89218
Epoch 48, Val Loss: 1.89675
Epoch 49, Val Loss: 1.91994
Epoch 50, Val Loss: 1.90817
Epoch 51, Val Loss: 1.89150
Epoch 52, Val Loss: 1.89337
Epoch 53, Val Loss: 1.89202
Epoch 54, Val Loss: 1.89786
Epoch 55, Val Loss: 1.90053
Epoch 56, Val Loss: 1.88549
Epoch 57, Val Loss: 1.88364
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.88254, 'Log Loss - std': 0.45426752294215345} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 54 finished with value: 3.88254 and parameters: {'p_m': 0.7257327723897158, 'alpha': 1.0939859119261683, 'K': 2, 'beta': 0.23287896545935388}. Best is trial 40 with value: 4.2989999999999995.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.14856
Epoch 1, Val Loss: 2.14537
Epoch 2, Val Loss: 2.14540
Epoch 3, Val Loss: 2.11762
Epoch 4, Val Loss: 2.10160
Epoch 5, Val Loss: 2.12246
Epoch 6, Val Loss: 2.11362
Epoch 7, Val Loss: 2.11805
Epoch 8, Val Loss: 2.10142
Epoch 9, Val Loss: 2.09048
Epoch 10, Val Loss: 2.08738
Epoch 11, Val Loss: 2.07965
Epoch 12, Val Loss: 2.06936
Epoch 13, Val Loss: 2.08064
Epoch 14, Val Loss: 2.11538
Epoch 15, Val Loss: 2.08171
Epoch 16, Val Loss: 2.06751
Epoch 17, Val Loss: 2.07911
Epoch 18, Val Loss: 2.07481
Epoch 19, Val Loss: 2.12756
Epoch 20, Val Loss: 2.11260
Epoch 21, Val Loss: 2.08286
Epoch 22, Val Loss: 2.08300
Epoch 23, Val Loss: 2.07218
Epoch 24, Val Loss: 2.09237
Epoch 25, Val Loss: 2.06896
Epoch 26, Val Loss: 2.08251
Epoch 27, Val Loss: 2.11506
Epoch 28, Val Loss: 2.08163
Epoch 29, Val Loss: 2.09072
Epoch 30, Val Loss: 2.09612
Epoch 31, Val Loss: 2.08588
Epoch 32, Val Loss: 2.07219
Epoch 33, Val Loss: 2.07419
Epoch 34, Val Loss: 2.07498
Epoch 35, Val Loss: 2.08392
Epoch 36, Val Loss: 2.07042
Epoch 37, Val Loss: 2.09715
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.1247, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 1.96959
Epoch 1, Val Loss: 1.96602
Epoch 2, Val Loss: 1.96320
Epoch 3, Val Loss: 1.94941
Epoch 4, Val Loss: 1.94843
Epoch 5, Val Loss: 1.93972
Epoch 6, Val Loss: 1.94530
Epoch 7, Val Loss: 1.94017
Epoch 8, Val Loss: 1.93694
Epoch 9, Val Loss: 1.91300
Epoch 10, Val Loss: 1.93563
Epoch 11, Val Loss: 1.94613
Epoch 12, Val Loss: 1.93524
Epoch 13, Val Loss: 1.93689
Epoch 14, Val Loss: 1.93269
Epoch 15, Val Loss: 1.94165
Epoch 16, Val Loss: 1.92198
Epoch 17, Val Loss: 1.96243
Epoch 18, Val Loss: 1.93394
Epoch 19, Val Loss: 1.91870
Epoch 20, Val Loss: 1.92555
Epoch 21, Val Loss: 1.91577
Epoch 22, Val Loss: 1.91393
Epoch 23, Val Loss: 1.91686
Epoch 24, Val Loss: 1.92372
Epoch 25, Val Loss: 1.95928
Epoch 26, Val Loss: 1.94749
Epoch 27, Val Loss: 1.94971
Epoch 28, Val Loss: 1.91002
Epoch 29, Val Loss: 1.91768
Epoch 30, Val Loss: 1.92559
Epoch 31, Val Loss: 1.98716
Epoch 32, Val Loss: 1.92054
Epoch 33, Val Loss: 1.92147
Epoch 34, Val Loss: 1.92230
Epoch 35, Val Loss: 1.90122
Epoch 36, Val Loss: 1.91057
Epoch 37, Val Loss: 1.89815
Epoch 38, Val Loss: 1.91036
Epoch 39, Val Loss: 1.92048
Epoch 40, Val Loss: 1.90495
Epoch 41, Val Loss: 1.91117
Epoch 42, Val Loss: 1.91236
Epoch 43, Val Loss: 1.89872
Epoch 44, Val Loss: 1.91240
Epoch 45, Val Loss: 1.90572
Epoch 46, Val Loss: 1.90320
Epoch 47, Val Loss: 1.89612
Epoch 48, Val Loss: 1.89827
Epoch 49, Val Loss: 1.90007
Epoch 50, Val Loss: 1.90867
Epoch 51, Val Loss: 1.89681
Epoch 52, Val Loss: 1.90353
Epoch 53, Val Loss: 1.90712
Epoch 54, Val Loss: 1.89944
Epoch 55, Val Loss: 1.90300
Epoch 56, Val Loss: 1.90187
Epoch 57, Val Loss: 1.90723
Epoch 58, Val Loss: 1.90212
Epoch 59, Val Loss: 1.90343
Epoch 60, Val Loss: 1.89323
Epoch 61, Val Loss: 1.89871
Epoch 62, Val Loss: 1.89579
Epoch 63, Val Loss: 1.89690
Epoch 64, Val Loss: 1.89903
Epoch 65, Val Loss: 1.91070
Epoch 66, Val Loss: 1.92666
Epoch 67, Val Loss: 1.91660
Epoch 68, Val Loss: 1.90216
Epoch 69, Val Loss: 1.90161
Epoch 70, Val Loss: 1.90436
Epoch 71, Val Loss: 1.90364
Epoch 72, Val Loss: 1.89542
Epoch 73, Val Loss: 1.88921
Epoch 74, Val Loss: 1.90006
Epoch 75, Val Loss: 1.90544
Epoch 76, Val Loss: 1.89935
Epoch 77, Val Loss: 1.90444
Epoch 78, Val Loss: 1.90437
Epoch 79, Val Loss: 1.90033
Epoch 80, Val Loss: 1.90290
Epoch 81, Val Loss: 1.92840
Epoch 82, Val Loss: 1.90036
Epoch 83, Val Loss: 1.90042
Epoch 84, Val Loss: 1.89293
Epoch 85, Val Loss: 1.91866
Epoch 86, Val Loss: 1.90422
Epoch 87, Val Loss: 1.89867
Epoch 88, Val Loss: 1.89635
Epoch 89, Val Loss: 1.90939
Epoch 90, Val Loss: 1.89977
Epoch 91, Val Loss: 1.90611
Epoch 92, Val Loss: 1.91977
Epoch 93, Val Loss: 1.89384
Epoch 94, Val Loss: 1.89757
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.9547499999999998, 'Log Loss - std': 0.16994999999999982} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.19177
Epoch 1, Val Loss: 2.24057
Epoch 2, Val Loss: 2.24247
Epoch 3, Val Loss: 2.24247
Epoch 4, Val Loss: 2.24247
Epoch 5, Val Loss: 2.24247
Epoch 6, Val Loss: 2.24247
Epoch 7, Val Loss: 2.24247
Epoch 8, Val Loss: 2.24247
Epoch 9, Val Loss: 2.24247
Epoch 10, Val Loss: 2.24247
Epoch 11, Val Loss: 2.24247
Epoch 12, Val Loss: 2.24247
Epoch 13, Val Loss: 2.24247
Epoch 14, Val Loss: 2.24247
Epoch 15, Val Loss: 2.24247
Epoch 16, Val Loss: 2.24247
Epoch 17, Val Loss: 2.24247
Epoch 18, Val Loss: 2.24247
Epoch 19, Val Loss: 2.24247
Epoch 20, Val Loss: 2.24247
Epoch 21, Val Loss: 2.24247
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 5.7571666666666665, 'Log Loss - std': 2.552776334807959} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.07465
Epoch 1, Val Loss: 2.14517
Epoch 2, Val Loss: 2.11995
Epoch 3, Val Loss: 2.09704
Epoch 4, Val Loss: 2.07099
Epoch 5, Val Loss: 2.13374
Epoch 6, Val Loss: 2.06414
Epoch 7, Val Loss: 2.08016
Epoch 8, Val Loss: 2.06578
Epoch 9, Val Loss: 2.07251
Epoch 10, Val Loss: 2.04899
Epoch 11, Val Loss: 2.05127
Epoch 12, Val Loss: 2.04415
Epoch 13, Val Loss: 2.07939
Epoch 14, Val Loss: 2.03283
Epoch 15, Val Loss: 2.03184
Epoch 16, Val Loss: 2.03974
Epoch 17, Val Loss: 2.03180
Epoch 18, Val Loss: 2.06311
Epoch 19, Val Loss: 2.06213
Epoch 20, Val Loss: 2.05184
Epoch 21, Val Loss: 2.11790
Epoch 22, Val Loss: 2.04033
Epoch 23, Val Loss: 2.04808
Epoch 24, Val Loss: 2.03834
Epoch 25, Val Loss: 2.03415
Epoch 26, Val Loss: 2.02683
Epoch 27, Val Loss: 2.02494
Epoch 28, Val Loss: 2.03359
Epoch 29, Val Loss: 2.04421
Epoch 30, Val Loss: 2.02226
Epoch 31, Val Loss: 2.09508
Epoch 32, Val Loss: 2.04238
Epoch 33, Val Loss: 2.04489
Epoch 34, Val Loss: 2.02361
Epoch 35, Val Loss: 2.04373
Epoch 36, Val Loss: 2.04711
Epoch 37, Val Loss: 2.02242
Epoch 38, Val Loss: 2.02598
Epoch 39, Val Loss: 2.05119
Epoch 40, Val Loss: 2.02381
Epoch 41, Val Loss: 2.04617
Epoch 42, Val Loss: 2.02901
Epoch 43, Val Loss: 2.01575
Epoch 44, Val Loss: 2.02207
Epoch 45, Val Loss: 2.02247
Epoch 46, Val Loss: 2.04300
Epoch 47, Val Loss: 2.04956
Epoch 48, Val Loss: 2.03327
Epoch 49, Val Loss: 2.04642
Epoch 50, Val Loss: 2.04057
Epoch 51, Val Loss: 2.02639
Epoch 52, Val Loss: 2.02747
Epoch 53, Val Loss: 2.03549
Epoch 54, Val Loss: 2.04861
Epoch 55, Val Loss: 2.05194
Epoch 56, Val Loss: 2.07115
Epoch 57, Val Loss: 2.02645
Epoch 58, Val Loss: 2.05062
Epoch 59, Val Loss: 2.06313
Epoch 60, Val Loss: 2.04970
Epoch 61, Val Loss: 2.03362
Epoch 62, Val Loss: 2.02787
Epoch 63, Val Loss: 2.02185
Epoch 64, Val Loss: 2.02363
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 5.182475, 'Log Loss - std': 2.4245230039896506} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 1.95619
Epoch 1, Val Loss: 1.96818
Epoch 2, Val Loss: 1.95975
Epoch 3, Val Loss: 1.94791
Epoch 4, Val Loss: 1.97156
Epoch 5, Val Loss: 1.94427
Epoch 6, Val Loss: 1.95882
Epoch 7, Val Loss: 2.06887
Epoch 8, Val Loss: 2.02218
Epoch 9, Val Loss: 1.92974
Epoch 10, Val Loss: 1.91476
Epoch 11, Val Loss: 1.93624
Epoch 12, Val Loss: 1.92689
Epoch 13, Val Loss: 1.94371
Epoch 14, Val Loss: 1.92313
Epoch 15, Val Loss: 1.90284
Epoch 16, Val Loss: 1.95438
Epoch 17, Val Loss: 1.94083
Epoch 18, Val Loss: 1.93577
Epoch 19, Val Loss: 1.93893
Epoch 20, Val Loss: 1.93556
Epoch 21, Val Loss: 1.90641
Epoch 22, Val Loss: 1.93258
Epoch 23, Val Loss: 1.91311
Epoch 24, Val Loss: 1.89443
Epoch 25, Val Loss: 1.90013
Epoch 26, Val Loss: 1.91559
Epoch 27, Val Loss: 1.91323
Epoch 28, Val Loss: 1.93084
Epoch 29, Val Loss: 1.90359
Epoch 30, Val Loss: 1.90989
Epoch 31, Val Loss: 1.89254
Epoch 32, Val Loss: 1.90271
Epoch 33, Val Loss: 1.90147
Epoch 34, Val Loss: 1.89716
Epoch 35, Val Loss: 1.99048
Epoch 36, Val Loss: 1.95664
Epoch 37, Val Loss: 1.96222
Epoch 38, Val Loss: 1.92418
Epoch 39, Val Loss: 1.92826
Epoch 40, Val Loss: 1.88937
Epoch 41, Val Loss: 1.90223
Epoch 42, Val Loss: 1.89984
Epoch 43, Val Loss: 1.89923
Epoch 44, Val Loss: 1.90173
Epoch 45, Val Loss: 2.01943
Epoch 46, Val Loss: 2.00526
Epoch 47, Val Loss: 1.97688
Epoch 48, Val Loss: 2.02890
Epoch 49, Val Loss: 1.98661
Epoch 50, Val Loss: 2.00525
Epoch 51, Val Loss: 1.94568
Epoch 52, Val Loss: 1.88274
Epoch 53, Val Loss: 1.90903
Epoch 54, Val Loss: 1.89796
Epoch 55, Val Loss: 1.91121
Epoch 56, Val Loss: 1.96506
Epoch 57, Val Loss: 1.89088
Epoch 58, Val Loss: 1.89279
Epoch 59, Val Loss: 1.90157
Epoch 60, Val Loss: 1.95782
Epoch 61, Val Loss: 1.88276
Epoch 62, Val Loss: 1.88803
Epoch 63, Val Loss: 1.89358
Epoch 64, Val Loss: 1.90386
Epoch 65, Val Loss: 1.88478
Epoch 66, Val Loss: 1.88025
Epoch 67, Val Loss: 1.89039
Epoch 68, Val Loss: 1.88990
Epoch 69, Val Loss: 1.88572
Epoch 70, Val Loss: 1.89679
Epoch 71, Val Loss: 1.88434
Epoch 72, Val Loss: 1.91844
Epoch 73, Val Loss: 1.88634
Epoch 74, Val Loss: 1.88345
Epoch 75, Val Loss: 1.92449
Epoch 76, Val Loss: 1.89752
Epoch 77, Val Loss: 1.88545
Epoch 78, Val Loss: 1.87892
Epoch 79, Val Loss: 1.88644
Epoch 80, Val Loss: 1.91942
Epoch 81, Val Loss: 1.91398
Epoch 82, Val Loss: 1.89295
Epoch 83, Val Loss: 1.91679
Epoch 84, Val Loss: 1.87556
Epoch 85, Val Loss: 1.88153
Epoch 86, Val Loss: 1.88767
Epoch 87, Val Loss: 1.87383
Epoch 88, Val Loss: 1.93648
Epoch 89, Val Loss: 1.88949
Epoch 90, Val Loss: 1.90885
Epoch 91, Val Loss: 1.89902
Epoch 92, Val Loss: 1.96154
Epoch 93, Val Loss: 1.96049
Epoch 94, Val Loss: 1.95690
Epoch 95, Val Loss: 2.00326
Epoch 96, Val Loss: 2.00086
Epoch 97, Val Loss: 2.09433
Epoch 98, Val Loss: 2.00311
Epoch 99, Val Loss: 2.00063
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 4.93648, 'Log Loss - std': 2.2236689496415605} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 55 finished with value: 4.93648 and parameters: {'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}
Fitted encoder
Epoch 0, Val Loss: 2.15219
Epoch 1, Val Loss: 2.14532
Epoch 2, Val Loss: 2.13167
Epoch 3, Val Loss: 2.14387
Epoch 4, Val Loss: 2.11570
Epoch 5, Val Loss: 2.12086
Epoch 6, Val Loss: 2.12544
Epoch 7, Val Loss: 2.13855
Epoch 8, Val Loss: 2.13863
Epoch 9, Val Loss: 2.11241
Epoch 10, Val Loss: 2.13435
Epoch 11, Val Loss: 2.17852
Epoch 12, Val Loss: 2.13467
Epoch 13, Val Loss: 2.12527
Epoch 14, Val Loss: 2.11930
Epoch 15, Val Loss: 2.11899
Epoch 16, Val Loss: 2.10435
Epoch 17, Val Loss: 2.11469
Epoch 18, Val Loss: 2.10153
Epoch 19, Val Loss: 2.11003
Epoch 20, Val Loss: 2.11448
Epoch 21, Val Loss: 2.16056
Epoch 22, Val Loss: 2.09438
Epoch 23, Val Loss: 2.08833
Epoch 24, Val Loss: 2.07950
Epoch 25, Val Loss: 2.09648
Epoch 26, Val Loss: 2.11671
Epoch 27, Val Loss: 2.09081
Epoch 28, Val Loss: 2.08141
Epoch 29, Val Loss: 2.07896
Epoch 30, Val Loss: 2.07914
Epoch 31, Val Loss: 2.12021
Epoch 32, Val Loss: 2.06862
Epoch 33, Val Loss: 2.07815
Epoch 34, Val Loss: 2.11130
Epoch 35, Val Loss: 2.08176
Epoch 36, Val Loss: 2.08131
Epoch 37, Val Loss: 2.07801
Epoch 38, Val Loss: 2.06236
Epoch 39, Val Loss: 2.06071
Epoch 40, Val Loss: 2.11328
Epoch 41, Val Loss: 2.07058
Epoch 42, Val Loss: 2.07302
Epoch 43, Val Loss: 2.06047
Epoch 44, Val Loss: 2.07851
Epoch 45, Val Loss: 2.08557
Epoch 46, Val Loss: 2.06868
Epoch 47, Val Loss: 2.06579
Epoch 48, Val Loss: 2.08202
Epoch 49, Val Loss: 2.07569
Epoch 50, Val Loss: 2.06478
Epoch 51, Val Loss: 2.07400
Epoch 52, Val Loss: 2.06147
Epoch 53, Val Loss: 2.08166
Epoch 54, Val Loss: 2.09530
Epoch 55, Val Loss: 2.07693
Epoch 56, Val Loss: 2.06468
Epoch 57, Val Loss: 2.08591
Epoch 58, Val Loss: 2.05979
Epoch 59, Val Loss: 2.07248
Epoch 60, Val Loss: 2.07290
Epoch 61, Val Loss: 2.06751
Epoch 62, Val Loss: 2.08513
Epoch 63, Val Loss: 2.07550
Epoch 64, Val Loss: 2.06590
Epoch 65, Val Loss: 2.05842
Epoch 66, Val Loss: 2.06032
Epoch 67, Val Loss: 2.06119
Epoch 68, Val Loss: 2.07283
Epoch 69, Val Loss: 2.07794
Epoch 70, Val Loss: 2.08416
Epoch 71, Val Loss: 2.07983
Epoch 72, Val Loss: 2.07291
Epoch 73, Val Loss: 2.06829
Epoch 74, Val Loss: 2.08300
Epoch 75, Val Loss: 2.06660
Epoch 76, Val Loss: 2.07900
Epoch 77, Val Loss: 2.06941
Epoch 78, Val Loss: 2.05967
Epoch 79, Val Loss: 2.06009
Epoch 80, Val Loss: 2.05819
Epoch 81, Val Loss: 2.05841
Epoch 82, Val Loss: 2.08911
Epoch 83, Val Loss: 2.07967
Epoch 84, Val Loss: 2.06911
Epoch 85, Val Loss: 2.06412
Epoch 86, Val Loss: 2.08700
Epoch 87, Val Loss: 2.06559
Epoch 88, Val Loss: 2.05833
Epoch 89, Val Loss: 2.06749
Epoch 90, Val Loss: 2.09061
Epoch 91, Val Loss: 2.06400
Epoch 92, Val Loss: 2.06140
Epoch 93, Val Loss: 2.06673
Epoch 94, Val Loss: 2.06331
Epoch 95, Val Loss: 2.06528
Epoch 96, Val Loss: 2.07030
Epoch 97, Val Loss: 2.06637
Epoch 98, Val Loss: 2.06920
Epoch 99, Val Loss: 2.07933
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.3346, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}
Fitted encoder
Epoch 0, Val Loss: 1.97474
Epoch 1, Val Loss: 1.97352
Epoch 2, Val Loss: 1.98223
Epoch 3, Val Loss: 1.94553
Epoch 4, Val Loss: 2.04919
Epoch 5, Val Loss: 1.93704
Epoch 6, Val Loss: 2.09091
Epoch 7, Val Loss: 1.97672
Epoch 8, Val Loss: 2.06495
Epoch 9, Val Loss: 2.05887
Epoch 10, Val Loss: 2.08053
Epoch 11, Val Loss: 2.04894
Epoch 12, Val Loss: 1.92406
Epoch 13, Val Loss: 1.92665
Epoch 14, Val Loss: 1.92775
Epoch 15, Val Loss: 1.92622
Epoch 16, Val Loss: 1.92666
Epoch 17, Val Loss: 1.92208
Epoch 18, Val Loss: 1.93213
Epoch 19, Val Loss: 1.92952
Epoch 20, Val Loss: 1.92178
Epoch 21, Val Loss: 1.92492
Epoch 22, Val Loss: 1.92771
Epoch 23, Val Loss: 1.93392
Epoch 24, Val Loss: 1.92838
Epoch 25, Val Loss: 1.93200
Epoch 26, Val Loss: 1.93375
Epoch 27, Val Loss: 1.93616
Epoch 28, Val Loss: 1.96148
Epoch 29, Val Loss: 2.06040
Epoch 30, Val Loss: 2.04670
Epoch 31, Val Loss: 2.04838
Epoch 32, Val Loss: 1.93476
Epoch 33, Val Loss: 1.93317
Epoch 34, Val Loss: 1.93190
Epoch 35, Val Loss: 1.92756
Epoch 36, Val Loss: 1.94203
Epoch 37, Val Loss: 2.06869
Epoch 38, Val Loss: 2.06977
Epoch 39, Val Loss: 2.07986
Epoch 40, Val Loss: 2.06859
Epoch 41, Val Loss: 2.06977
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 4.462899999999999, 'Log Loss - std': 0.12829999999999986} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}
Fitted encoder
Epoch 0, Val Loss: 2.11012
Epoch 1, Val Loss: 2.15946
Epoch 2, Val Loss: 2.16430
Epoch 3, Val Loss: 2.14830
Epoch 4, Val Loss: 2.13854
Epoch 5, Val Loss: 2.13642
Epoch 6, Val Loss: 2.09962
Epoch 7, Val Loss: 2.09410
Epoch 8, Val Loss: 2.07553
Epoch 9, Val Loss: 2.11384
Epoch 10, Val Loss: 2.10949
Epoch 11, Val Loss: 2.16921
Epoch 12, Val Loss: 2.11945
Epoch 13, Val Loss: 2.12143
Epoch 14, Val Loss: 2.12523
Epoch 15, Val Loss: 2.11106
Epoch 16, Val Loss: 2.12100
Epoch 17, Val Loss: 2.10578
Epoch 18, Val Loss: 2.07804
Epoch 19, Val Loss: 2.07879
Epoch 20, Val Loss: 2.07255
Epoch 21, Val Loss: 2.08162
Epoch 22, Val Loss: 2.07249
Epoch 23, Val Loss: 2.08890
Epoch 24, Val Loss: 2.06161
Epoch 25, Val Loss: 2.10639
Epoch 26, Val Loss: 2.11677
Epoch 27, Val Loss: 2.11608
Epoch 28, Val Loss: 2.11740
Epoch 29, Val Loss: 2.11981
Epoch 30, Val Loss: 2.10272
Epoch 31, Val Loss: 2.10351
Epoch 32, Val Loss: 2.17501
Epoch 33, Val Loss: 2.18395
Epoch 34, Val Loss: 2.18019
Epoch 35, Val Loss: 2.20357
Epoch 36, Val Loss: 2.19358
Epoch 37, Val Loss: 2.18778
Epoch 38, Val Loss: 2.18655
Epoch 39, Val Loss: 2.15597
Epoch 40, Val Loss: 2.18557
Epoch 41, Val Loss: 2.09551
Epoch 42, Val Loss: 2.10571
Epoch 43, Val Loss: 2.10431
Epoch 44, Val Loss: 2.12108
Epoch 45, Val Loss: 2.12755
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.2844999999999995, 'Log Loss - std': 0.27317951362916393} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}
Fitted encoder
Epoch 0, Val Loss: 2.07899
Epoch 1, Val Loss: 2.06327
Epoch 2, Val Loss: 2.05873
Epoch 3, Val Loss: 2.05080
Epoch 4, Val Loss: 2.07543
Epoch 5, Val Loss: 2.09207
Epoch 6, Val Loss: 2.09120
Epoch 7, Val Loss: 2.09662
Epoch 8, Val Loss: 2.08883
Epoch 9, Val Loss: 2.12072
Epoch 10, Val Loss: 2.07522
Epoch 11, Val Loss: 2.09555
Epoch 12, Val Loss: 2.03677
Epoch 13, Val Loss: 2.08348
Epoch 14, Val Loss: 2.07370
Epoch 15, Val Loss: 2.06786
Epoch 16, Val Loss: 2.07544
Epoch 17, Val Loss: 2.10763
Epoch 18, Val Loss: 2.14931
Epoch 19, Val Loss: 2.08068
Epoch 20, Val Loss: 2.07803
Epoch 21, Val Loss: 2.07939
Epoch 22, Val Loss: 2.09458
Epoch 23, Val Loss: 2.07431
Epoch 24, Val Loss: 2.08794
Epoch 25, Val Loss: 2.09047
Epoch 26, Val Loss: 2.16013
Epoch 27, Val Loss: 2.14136
Epoch 28, Val Loss: 2.13767
Epoch 29, Val Loss: 2.14288
Epoch 30, Val Loss: 2.13365
Epoch 31, Val Loss: 2.10559
Epoch 32, Val Loss: 2.10662
Epoch 33, Val Loss: 2.03896
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.8612499999999996, 'Log Loss - std': 0.7703193964194333} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}
Fitted encoder
Epoch 0, Val Loss: 1.96230
Epoch 1, Val Loss: 1.96043
Epoch 2, Val Loss: 2.05222
Epoch 3, Val Loss: 2.05951
Epoch 4, Val Loss: 2.04548
Epoch 5, Val Loss: 2.04617
Epoch 6, Val Loss: 2.05155
Epoch 7, Val Loss: 2.04103
Epoch 8, Val Loss: 2.05722
Epoch 9, Val Loss: 2.04579
Epoch 10, Val Loss: 1.94655
Epoch 11, Val Loss: 1.98465
Epoch 12, Val Loss: 1.96035
Epoch 13, Val Loss: 1.96133
Epoch 14, Val Loss: 1.95385
Epoch 15, Val Loss: 1.95242
Epoch 16, Val Loss: 1.96888
Epoch 17, Val Loss: 1.93998
Epoch 18, Val Loss: 1.94992
Epoch 19, Val Loss: 1.95733
Epoch 20, Val Loss: 1.95162
Epoch 21, Val Loss: 1.96271
Epoch 22, Val Loss: 2.04466
Epoch 23, Val Loss: 2.03617
Epoch 24, Val Loss: 2.04468
Epoch 25, Val Loss: 2.04147
Epoch 26, Val Loss: 2.04545
Epoch 27, Val Loss: 2.04118
Epoch 28, Val Loss: 2.03610
Epoch 29, Val Loss: 2.04371
Epoch 30, Val Loss: 2.04164
Epoch 31, Val Loss: 2.04413
Epoch 32, Val Loss: 2.03849
Epoch 33, Val Loss: 2.04248
Epoch 34, Val Loss: 2.03819
Epoch 35, Val Loss: 2.03523
Epoch 36, Val Loss: 2.03278
Epoch 37, Val Loss: 2.02049
Epoch 38, Val Loss: 2.02847
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.72966, 'Log Loss - std': 0.737548161410494} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 56 finished with value: 3.72966 and parameters: {'p_m': 0.6728914836321547, 'alpha': 1.1631970121488855, 'K': 2, 'beta': 0.1587759686985105}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}
Fitted encoder
Epoch 0, Val Loss: 2.15856
Epoch 1, Val Loss: 2.14774
Epoch 2, Val Loss: 2.10751
Epoch 3, Val Loss: 2.09368
Epoch 4, Val Loss: 2.10326
Epoch 5, Val Loss: 2.10999
Epoch 6, Val Loss: 2.07248
Epoch 7, Val Loss: 2.10951
Epoch 8, Val Loss: 2.07920
Epoch 9, Val Loss: 2.07242
Epoch 10, Val Loss: 2.06282
Epoch 11, Val Loss: 2.07266
Epoch 12, Val Loss: 2.06202
Epoch 13, Val Loss: 2.04377
Epoch 14, Val Loss: 2.07665
Epoch 15, Val Loss: 2.07183
Epoch 16, Val Loss: 2.06477
Epoch 17, Val Loss: 2.05907
Epoch 18, Val Loss: 2.04212
Epoch 19, Val Loss: 2.08604
Epoch 20, Val Loss: 2.03440
Epoch 21, Val Loss: 2.07380
Epoch 22, Val Loss: 2.06812
Epoch 23, Val Loss: 2.04411
Epoch 24, Val Loss: 2.04055
Epoch 25, Val Loss: 2.06347
Epoch 26, Val Loss: 2.04650
Epoch 27, Val Loss: 2.04150
Epoch 28, Val Loss: 2.06635
Epoch 29, Val Loss: 2.03900
Epoch 30, Val Loss: 2.04827
Epoch 31, Val Loss: 2.05170
Epoch 32, Val Loss: 2.03494
Epoch 33, Val Loss: 2.06856
Epoch 34, Val Loss: 2.08703
Epoch 35, Val Loss: 2.08164
Epoch 36, Val Loss: 2.04353
Epoch 37, Val Loss: 2.06443
Epoch 38, Val Loss: 2.02257
Epoch 39, Val Loss: 2.06468
Epoch 40, Val Loss: 2.05133
Epoch 41, Val Loss: 2.04763
Epoch 42, Val Loss: 2.04036
Epoch 43, Val Loss: 2.04675
Epoch 44, Val Loss: 2.04387
Epoch 45, Val Loss: 2.04715
Epoch 46, Val Loss: 2.05316
Epoch 47, Val Loss: 2.06246
Epoch 48, Val Loss: 2.05508
Epoch 49, Val Loss: 2.04877
Epoch 50, Val Loss: 2.04409
Epoch 51, Val Loss: 2.03532
Epoch 52, Val Loss: 2.04024
Epoch 53, Val Loss: 2.04026
Epoch 54, Val Loss: 2.03355
Epoch 55, Val Loss: 2.07477
Epoch 56, Val Loss: 2.02642
Epoch 57, Val Loss: 2.06430
Epoch 58, Val Loss: 2.04134
Epoch 59, Val Loss: 2.05021
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.2123, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}
Fitted encoder
Epoch 0, Val Loss: 1.97243
Epoch 1, Val Loss: 1.96245
Epoch 2, Val Loss: 1.94123
Epoch 3, Val Loss: 1.93789
Epoch 4, Val Loss: 1.97155
Epoch 5, Val Loss: 1.94553
Epoch 6, Val Loss: 1.94013
Epoch 7, Val Loss: 1.92786
Epoch 8, Val Loss: 1.94220
Epoch 9, Val Loss: 1.93168
Epoch 10, Val Loss: 1.95406
Epoch 11, Val Loss: 1.93221
Epoch 12, Val Loss: 1.93958
Epoch 13, Val Loss: 1.93873
Epoch 14, Val Loss: 1.91597
Epoch 15, Val Loss: 1.93985
Epoch 16, Val Loss: 1.95685
Epoch 17, Val Loss: 1.94656
Epoch 18, Val Loss: 1.92358
Epoch 19, Val Loss: 1.91769
Epoch 20, Val Loss: 1.92726
Epoch 21, Val Loss: 1.91663
Epoch 22, Val Loss: 1.90598
Epoch 23, Val Loss: 1.90606
Epoch 24, Val Loss: 1.90595
Epoch 25, Val Loss: 1.89248
Epoch 26, Val Loss: 1.90090
Epoch 27, Val Loss: 1.91703
Epoch 28, Val Loss: 1.90575
Epoch 29, Val Loss: 1.90309
Epoch 30, Val Loss: 1.92707
Epoch 31, Val Loss: 1.91420
Epoch 32, Val Loss: 1.91569
Epoch 33, Val Loss: 1.90357
Epoch 34, Val Loss: 1.90592
Epoch 35, Val Loss: 1.92692
Epoch 36, Val Loss: 1.90890
Epoch 37, Val Loss: 1.91006
Epoch 38, Val Loss: 1.90202
Epoch 39, Val Loss: 1.91788
Epoch 40, Val Loss: 1.91064
Epoch 41, Val Loss: 1.91788
Epoch 42, Val Loss: 1.90055
Epoch 43, Val Loss: 1.89935
Epoch 44, Val Loss: 1.91594
Epoch 45, Val Loss: 1.88846
Epoch 46, Val Loss: 1.91492
Epoch 47, Val Loss: 1.91842
Epoch 48, Val Loss: 1.89472
Epoch 49, Val Loss: 1.90118
Epoch 50, Val Loss: 1.90662
Epoch 51, Val Loss: 1.92456
Epoch 52, Val Loss: 1.91710
Epoch 53, Val Loss: 1.90524
Epoch 54, Val Loss: 1.89363
Epoch 55, Val Loss: 1.89316
Epoch 56, Val Loss: 1.92308
Epoch 57, Val Loss: 1.92308
Epoch 58, Val Loss: 1.89399
Epoch 59, Val Loss: 1.89281
Epoch 60, Val Loss: 1.89791
Epoch 61, Val Loss: 1.90773
Epoch 62, Val Loss: 1.90181
Epoch 63, Val Loss: 1.90282
Epoch 64, Val Loss: 1.88719
Epoch 65, Val Loss: 1.90214
Epoch 66, Val Loss: 1.89648
Epoch 67, Val Loss: 1.91315
Epoch 68, Val Loss: 1.89965
Epoch 69, Val Loss: 1.89781
Epoch 70, Val Loss: 1.90420
Epoch 71, Val Loss: 1.90238
Epoch 72, Val Loss: 1.91149
Epoch 73, Val Loss: 1.91408
Epoch 74, Val Loss: 1.90332
Epoch 75, Val Loss: 1.91053
Epoch 76, Val Loss: 1.91548
Epoch 77, Val Loss: 1.89238
Epoch 78, Val Loss: 1.89842
Epoch 79, Val Loss: 1.90396
Epoch 80, Val Loss: 1.89922
Epoch 81, Val Loss: 1.89209
Epoch 82, Val Loss: 1.90498
Epoch 83, Val Loss: 1.90384
Epoch 84, Val Loss: 1.89160
Epoch 85, Val Loss: 1.89631
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.31095, 'Log Loss - std': 0.09865000000000013} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}
Fitted encoder
Epoch 0, Val Loss: 2.12834
Epoch 1, Val Loss: 2.14577
Epoch 2, Val Loss: 2.12423
Epoch 3, Val Loss: 2.12945
Epoch 4, Val Loss: 2.12259
Epoch 5, Val Loss: 2.11157
Epoch 6, Val Loss: 2.11586
Epoch 7, Val Loss: 2.10731
Epoch 8, Val Loss: 2.10360
Epoch 9, Val Loss: 2.10652
Epoch 10, Val Loss: 2.10954
Epoch 11, Val Loss: 2.12986
Epoch 12, Val Loss: 2.11037
Epoch 13, Val Loss: 2.09064
Epoch 14, Val Loss: 2.11527
Epoch 15, Val Loss: 2.10127
Epoch 16, Val Loss: 2.08626
Epoch 17, Val Loss: 2.08385
Epoch 18, Val Loss: 2.10284
Epoch 19, Val Loss: 2.12547
Epoch 20, Val Loss: 2.11616
Epoch 21, Val Loss: 2.09765
Epoch 22, Val Loss: 2.12626
Epoch 23, Val Loss: 2.10885
Epoch 24, Val Loss: 2.12155
Epoch 25, Val Loss: 2.10606
Epoch 26, Val Loss: 2.09249
Epoch 27, Val Loss: 2.08070
Epoch 28, Val Loss: 2.09208
Epoch 29, Val Loss: 2.09226
Epoch 30, Val Loss: 2.11424
Epoch 31, Val Loss: 2.11603
Epoch 32, Val Loss: 2.07936
Epoch 33, Val Loss: 2.10256
Epoch 34, Val Loss: 2.09370
Epoch 35, Val Loss: 2.07899
Epoch 36, Val Loss: 2.08660
Epoch 37, Val Loss: 2.06619
Epoch 38, Val Loss: 2.07068
Epoch 39, Val Loss: 2.06548
Epoch 40, Val Loss: 2.07400
Epoch 41, Val Loss: 2.07179
Epoch 42, Val Loss: 2.07008
Epoch 43, Val Loss: 2.08025
Epoch 44, Val Loss: 2.06870
Epoch 45, Val Loss: 2.07731
Epoch 46, Val Loss: 2.10787
Epoch 47, Val Loss: 2.07062
Epoch 48, Val Loss: 2.08606
Epoch 49, Val Loss: 2.09276
Epoch 50, Val Loss: 2.09492
Epoch 51, Val Loss: 2.07814
Epoch 52, Val Loss: 2.07059
Epoch 53, Val Loss: 2.07057
Epoch 54, Val Loss: 2.06408
Epoch 55, Val Loss: 2.07390
Epoch 56, Val Loss: 2.06477
Epoch 57, Val Loss: 2.07476
Epoch 58, Val Loss: 2.07450
Epoch 59, Val Loss: 2.07239
Epoch 60, Val Loss: 2.08116
Epoch 61, Val Loss: 2.07884
Epoch 62, Val Loss: 2.07039
Epoch 63, Val Loss: 2.10076
Epoch 64, Val Loss: 2.07515
Epoch 65, Val Loss: 2.05405
Epoch 66, Val Loss: 2.06887
Epoch 67, Val Loss: 2.06448
Epoch 68, Val Loss: 2.06791
Epoch 69, Val Loss: 2.06698
Epoch 70, Val Loss: 2.07296
Epoch 71, Val Loss: 2.06221
Epoch 72, Val Loss: 2.06168
Epoch 73, Val Loss: 2.08381
Epoch 74, Val Loss: 2.07621
Epoch 75, Val Loss: 2.06111
Epoch 76, Val Loss: 2.08237
Epoch 77, Val Loss: 2.06721
Epoch 78, Val Loss: 2.06230
Epoch 79, Val Loss: 2.07153
Epoch 80, Val Loss: 2.07498
Epoch 81, Val Loss: 2.08691
Epoch 82, Val Loss: 2.08312
Epoch 83, Val Loss: 2.08359
Epoch 84, Val Loss: 2.08100
Epoch 85, Val Loss: 2.07832
Epoch 86, Val Loss: 2.06880
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.4009, 'Log Loss - std': 0.15056522396179894} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}
Fitted encoder
Epoch 0, Val Loss: 2.07807
Epoch 1, Val Loss: 2.07484
Epoch 2, Val Loss: 2.07643
Epoch 3, Val Loss: 2.06616
Epoch 4, Val Loss: 2.03597
Epoch 5, Val Loss: 2.04699
Epoch 6, Val Loss: 2.04425
Epoch 7, Val Loss: 2.09599
Epoch 8, Val Loss: 2.04083
Epoch 9, Val Loss: 2.05151
Epoch 10, Val Loss: 2.00297
Epoch 11, Val Loss: 2.04844
Epoch 12, Val Loss: 2.05322
Epoch 13, Val Loss: 2.00612
Epoch 14, Val Loss: 2.05546
Epoch 15, Val Loss: 2.02817
Epoch 16, Val Loss: 2.03337
Epoch 17, Val Loss: 2.05286
Epoch 18, Val Loss: 2.02760
Epoch 19, Val Loss: 2.06277
Epoch 20, Val Loss: 2.10400
Epoch 21, Val Loss: 2.06785
Epoch 22, Val Loss: 2.09002
Epoch 23, Val Loss: 2.00955
Epoch 24, Val Loss: 2.01591
Epoch 25, Val Loss: 2.03228
Epoch 26, Val Loss: 2.01225
Epoch 27, Val Loss: 2.00121
Epoch 28, Val Loss: 2.04336
Epoch 29, Val Loss: 2.03331
Epoch 30, Val Loss: 2.01961
Epoch 31, Val Loss: 2.01825
Epoch 32, Val Loss: 2.08885
Epoch 33, Val Loss: 2.07257
Epoch 34, Val Loss: 2.04577
Epoch 35, Val Loss: 2.00443
Epoch 36, Val Loss: 2.02343
Epoch 37, Val Loss: 2.01543
Epoch 38, Val Loss: 2.00909
Epoch 39, Val Loss: 2.04143
Epoch 40, Val Loss: 2.00591
Epoch 41, Val Loss: 2.02808
Epoch 42, Val Loss: 2.01598
Epoch 43, Val Loss: 2.02777
Epoch 44, Val Loss: 2.02806
Epoch 45, Val Loss: 2.01624
Epoch 46, Val Loss: 2.02443
Epoch 47, Val Loss: 2.00329
Epoch 48, Val Loss: 2.01326
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.223075, 'Log Loss - std': 0.3344661520617595} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}
Fitted encoder
Epoch 0, Val Loss: 1.94998
Epoch 1, Val Loss: 1.94761
Epoch 2, Val Loss: 1.95352
Epoch 3, Val Loss: 1.95462
Epoch 4, Val Loss: 1.94669
Epoch 5, Val Loss: 1.93707
Epoch 6, Val Loss: 1.94512
Epoch 7, Val Loss: 1.93937
Epoch 8, Val Loss: 1.92932
Epoch 9, Val Loss: 1.93077
Epoch 10, Val Loss: 1.91431
Epoch 11, Val Loss: 1.91811
Epoch 12, Val Loss: 1.91752
Epoch 13, Val Loss: 1.91120
Epoch 14, Val Loss: 1.95975
Epoch 15, Val Loss: 1.91327
Epoch 16, Val Loss: 1.89924
Epoch 17, Val Loss: 1.93524
Epoch 18, Val Loss: 1.93425
Epoch 19, Val Loss: 1.90624
Epoch 20, Val Loss: 1.92029
Epoch 21, Val Loss: 1.90253
Epoch 22, Val Loss: 1.90293
Epoch 23, Val Loss: 1.90509
Epoch 24, Val Loss: 1.88827
Epoch 25, Val Loss: 1.89349
Epoch 26, Val Loss: 1.89607
Epoch 27, Val Loss: 1.91339
Epoch 28, Val Loss: 1.90136
Epoch 29, Val Loss: 1.89432
Epoch 30, Val Loss: 1.91889
Epoch 31, Val Loss: 1.88823
Epoch 32, Val Loss: 1.91429
Epoch 33, Val Loss: 1.89592
Epoch 34, Val Loss: 1.91255
Epoch 35, Val Loss: 1.90823
Epoch 36, Val Loss: 1.93181
Epoch 37, Val Loss: 1.89626
Epoch 38, Val Loss: 1.90970
Epoch 39, Val Loss: 1.88638
Epoch 40, Val Loss: 1.88126
Epoch 41, Val Loss: 1.90031
Epoch 42, Val Loss: 1.89542
Epoch 43, Val Loss: 1.91901
Epoch 44, Val Loss: 1.89033
Epoch 45, Val Loss: 1.88833
Epoch 46, Val Loss: 1.90909
Epoch 47, Val Loss: 1.87619
Epoch 48, Val Loss: 1.89753
Epoch 49, Val Loss: 1.88892
Epoch 50, Val Loss: 1.89632
Epoch 51, Val Loss: 1.97788
Epoch 52, Val Loss: 1.95490
Epoch 53, Val Loss: 1.92163
Epoch 54, Val Loss: 1.90371
Epoch 55, Val Loss: 1.89793
Epoch 56, Val Loss: 1.89632
Epoch 57, Val Loss: 1.88875
Epoch 58, Val Loss: 1.89182
Epoch 59, Val Loss: 1.89373
Epoch 60, Val Loss: 1.89996
Epoch 61, Val Loss: 1.89293
Epoch 62, Val Loss: 1.88266
Epoch 63, Val Loss: 1.88366
Epoch 64, Val Loss: 1.89439
Epoch 65, Val Loss: 1.88181
Epoch 66, Val Loss: 1.87406
Epoch 67, Val Loss: 1.86832
Epoch 68, Val Loss: 1.89331
Epoch 69, Val Loss: 1.89049
Epoch 70, Val Loss: 1.89010
Epoch 71, Val Loss: 1.88219
Epoch 72, Val Loss: 1.88987
Epoch 73, Val Loss: 1.88808
Epoch 74, Val Loss: 1.91687
Epoch 75, Val Loss: 1.89446
Epoch 76, Val Loss: 1.88998
Epoch 77, Val Loss: 1.88442
Epoch 78, Val Loss: 1.89194
Epoch 79, Val Loss: 1.88262
Epoch 80, Val Loss: 1.88155
Epoch 81, Val Loss: 1.89252
Epoch 82, Val Loss: 1.93775
Epoch 83, Val Loss: 1.89947
Epoch 84, Val Loss: 1.89761
Epoch 85, Val Loss: 1.87761
Epoch 86, Val Loss: 1.88071
Epoch 87, Val Loss: 1.91174
Epoch 88, Val Loss: 1.87610
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.28112, 'Log Loss - std': 0.3208909060724533} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 57 finished with value: 3.28112 and parameters: {'p_m': 0.7149215686343362, 'alpha': 0.4571243361138122, 'K': 2, 'beta': 1.6443371199861272}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}
Fitted encoder
Epoch 0, Val Loss: 2.12248
Epoch 1, Val Loss: 2.15808
Epoch 2, Val Loss: 2.14639
Epoch 3, Val Loss: 2.12068
Epoch 4, Val Loss: 2.11082
Epoch 5, Val Loss: 2.10871
Epoch 6, Val Loss: 2.11392
Epoch 7, Val Loss: 2.11284
Epoch 8, Val Loss: 2.10537
Epoch 9, Val Loss: 2.10787
Epoch 10, Val Loss: 2.10915
Epoch 11, Val Loss: 2.07878
Epoch 12, Val Loss: 2.07799
Epoch 13, Val Loss: 2.07979
Epoch 14, Val Loss: 2.10644
Epoch 15, Val Loss: 2.07455
Epoch 16, Val Loss: 2.12156
Epoch 17, Val Loss: 2.08305
Epoch 18, Val Loss: 2.08651
Epoch 19, Val Loss: 2.08501
Epoch 20, Val Loss: 2.08933
Epoch 21, Val Loss: 2.08586
Epoch 22, Val Loss: 2.10838
Epoch 23, Val Loss: 2.10085
Epoch 24, Val Loss: 2.07816
Epoch 25, Val Loss: 2.09565
Epoch 26, Val Loss: 2.07698
Epoch 27, Val Loss: 2.07875
Epoch 28, Val Loss: 2.07917
Epoch 29, Val Loss: 2.08000
Epoch 30, Val Loss: 2.08486
Epoch 31, Val Loss: 2.07859
Epoch 32, Val Loss: 2.07226
Epoch 33, Val Loss: 2.05098
Epoch 34, Val Loss: 2.10221
Epoch 35, Val Loss: 2.09456
Epoch 36, Val Loss: 2.06301
Epoch 37, Val Loss: 2.06734
Epoch 38, Val Loss: 2.10805
Epoch 39, Val Loss: 2.06653
Epoch 40, Val Loss: 2.08400
Epoch 41, Val Loss: 2.05016
Epoch 42, Val Loss: 2.09606
Epoch 43, Val Loss: 2.05059
Epoch 44, Val Loss: 2.04812
Epoch 45, Val Loss: 2.05270
Epoch 46, Val Loss: 2.04879
Epoch 47, Val Loss: 2.05567
Epoch 48, Val Loss: 2.04844
Epoch 49, Val Loss: 2.09283
Epoch 50, Val Loss: 2.05071
Epoch 51, Val Loss: 2.04661
Epoch 52, Val Loss: 2.04035
Epoch 53, Val Loss: 2.05316
Epoch 54, Val Loss: 2.06964
Epoch 55, Val Loss: 2.05670
Epoch 56, Val Loss: 2.04734
Epoch 57, Val Loss: 2.05241
Epoch 58, Val Loss: 2.05649
Epoch 59, Val Loss: 2.04101
Epoch 60, Val Loss: 2.04620
Epoch 61, Val Loss: 2.03011
Epoch 62, Val Loss: 2.03033
Epoch 63, Val Loss: 2.03364
Epoch 64, Val Loss: 2.05252
Epoch 65, Val Loss: 2.03897
Epoch 66, Val Loss: 2.02496
Epoch 67, Val Loss: 2.03015
Epoch 68, Val Loss: 2.03556
Epoch 69, Val Loss: 2.03034
Epoch 70, Val Loss: 2.06442
Epoch 71, Val Loss: 2.03807
Epoch 72, Val Loss: 2.05843
Epoch 73, Val Loss: 2.04911
Epoch 74, Val Loss: 2.03364
Epoch 75, Val Loss: 2.04511
Epoch 76, Val Loss: 2.05913
Epoch 77, Val Loss: 2.04587
Epoch 78, Val Loss: 2.04889
Epoch 79, Val Loss: 2.02308
Epoch 80, Val Loss: 2.03216
Epoch 81, Val Loss: 2.02757
Epoch 82, Val Loss: 2.04668
Epoch 83, Val Loss: 2.04046
Epoch 84, Val Loss: 2.02454
Epoch 85, Val Loss: 2.02544
Epoch 86, Val Loss: 2.02708
Epoch 87, Val Loss: 2.04059
Epoch 88, Val Loss: 2.02823
Epoch 89, Val Loss: 2.02415
Epoch 90, Val Loss: 2.04295
Epoch 91, Val Loss: 2.04392
Epoch 92, Val Loss: 2.07821
Epoch 93, Val Loss: 2.06298
Epoch 94, Val Loss: 2.04998
Epoch 95, Val Loss: 2.04617
Epoch 96, Val Loss: 2.03779
Epoch 97, Val Loss: 2.05601
Epoch 98, Val Loss: 2.02832
Epoch 99, Val Loss: 2.07221
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 2.6632, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}
Fitted encoder
Epoch 0, Val Loss: 1.96182
Epoch 1, Val Loss: 1.95958
Epoch 2, Val Loss: 1.97401
Epoch 3, Val Loss: 1.97091
Epoch 4, Val Loss: 1.96627
Epoch 5, Val Loss: 1.94973
Epoch 6, Val Loss: 1.95390
Epoch 7, Val Loss: 1.96842
Epoch 8, Val Loss: 1.93556
Epoch 9, Val Loss: 1.95163
Epoch 10, Val Loss: 1.93233
Epoch 11, Val Loss: 1.94003
Epoch 12, Val Loss: 1.93802
Epoch 13, Val Loss: 1.91288
Epoch 14, Val Loss: 1.91814
Epoch 15, Val Loss: 1.91129
Epoch 16, Val Loss: 1.92512
Epoch 17, Val Loss: 1.91741
Epoch 18, Val Loss: 1.91441
Epoch 19, Val Loss: 1.90391
Epoch 20, Val Loss: 1.95353
Epoch 21, Val Loss: 1.92004
Epoch 22, Val Loss: 1.92115
Epoch 23, Val Loss: 1.91391
Epoch 24, Val Loss: 1.91983
Epoch 25, Val Loss: 1.92999
Epoch 26, Val Loss: 1.93022
Epoch 27, Val Loss: 1.93103
Epoch 28, Val Loss: 1.91222
Epoch 29, Val Loss: 1.91602
Epoch 30, Val Loss: 1.91819
Epoch 31, Val Loss: 1.90707
Epoch 32, Val Loss: 1.90886
Epoch 33, Val Loss: 1.91689
Epoch 34, Val Loss: 1.90551
Epoch 35, Val Loss: 1.90576
Epoch 36, Val Loss: 1.93018
Epoch 37, Val Loss: 1.91582
Epoch 38, Val Loss: 1.93256
Epoch 39, Val Loss: 1.92187
Epoch 40, Val Loss: 1.91771
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 2.9995, 'Log Loss - std': 0.33630000000000004} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}
Fitted encoder
Epoch 0, Val Loss: 2.15304
Epoch 1, Val Loss: 2.12212
Epoch 2, Val Loss: 2.11443
Epoch 3, Val Loss: 2.13946
Epoch 4, Val Loss: 2.08890
Epoch 5, Val Loss: 2.07276
Epoch 6, Val Loss: 2.08683
Epoch 7, Val Loss: 2.07960
Epoch 8, Val Loss: 2.06537
Epoch 9, Val Loss: 2.07298
Epoch 10, Val Loss: 2.07516
Epoch 11, Val Loss: 2.07038
Epoch 12, Val Loss: 2.08653
Epoch 13, Val Loss: 2.07342
Epoch 14, Val Loss: 2.08045
Epoch 15, Val Loss: 2.07049
Epoch 16, Val Loss: 2.07186
Epoch 17, Val Loss: 2.06984
Epoch 18, Val Loss: 2.07161
Epoch 19, Val Loss: 2.05533
Epoch 20, Val Loss: 2.07465
Epoch 21, Val Loss: 2.06932
Epoch 22, Val Loss: 2.07878
Epoch 23, Val Loss: 2.07575
Epoch 24, Val Loss: 2.07253
Epoch 25, Val Loss: 2.07178
Epoch 26, Val Loss: 2.07105
Epoch 27, Val Loss: 2.06308
Epoch 28, Val Loss: 2.11378
Epoch 29, Val Loss: 2.10266
Epoch 30, Val Loss: 2.06012
Epoch 31, Val Loss: 2.07160
Epoch 32, Val Loss: 2.06842
Epoch 33, Val Loss: 2.07124
Epoch 34, Val Loss: 2.04278
Epoch 35, Val Loss: 2.06547
Epoch 36, Val Loss: 2.04301
Epoch 37, Val Loss: 2.06801
Epoch 38, Val Loss: 2.05388
Epoch 39, Val Loss: 2.05335
Epoch 40, Val Loss: 2.04033
Epoch 41, Val Loss: 2.04804
Epoch 42, Val Loss: 2.06145
Epoch 43, Val Loss: 2.03800
Epoch 44, Val Loss: 2.07541
Epoch 45, Val Loss: 2.04974
Epoch 46, Val Loss: 2.03553
Epoch 47, Val Loss: 2.03002
Epoch 48, Val Loss: 2.08459
Epoch 49, Val Loss: 2.04113
Epoch 50, Val Loss: 2.03688
Epoch 51, Val Loss: 2.03746
Epoch 52, Val Loss: 2.09040
Epoch 53, Val Loss: 2.10616
Epoch 54, Val Loss: 2.10120
Epoch 55, Val Loss: 2.02909
Epoch 56, Val Loss: 2.07091
Epoch 57, Val Loss: 2.06432
Epoch 58, Val Loss: 2.08996
Epoch 59, Val Loss: 2.04070
Epoch 60, Val Loss: 2.04959
Epoch 61, Val Loss: 2.03793
Epoch 62, Val Loss: 2.02883
Epoch 63, Val Loss: 2.02630
Epoch 64, Val Loss: 2.04819
Epoch 65, Val Loss: 2.15539
Epoch 66, Val Loss: 2.10072
Epoch 67, Val Loss: 2.04468
Epoch 68, Val Loss: 2.03746
Epoch 69, Val Loss: 2.06690
Epoch 70, Val Loss: 2.02860
Epoch 71, Val Loss: 2.03146
Epoch 72, Val Loss: 2.04025
Epoch 73, Val Loss: 2.05913
Epoch 74, Val Loss: 2.05195
Epoch 75, Val Loss: 2.07801
Epoch 76, Val Loss: 2.03270
Epoch 77, Val Loss: 2.02447
Epoch 78, Val Loss: 2.05509
Epoch 79, Val Loss: 2.03517
Epoch 80, Val Loss: 2.04803
Epoch 81, Val Loss: 2.04710
Epoch 82, Val Loss: 2.03846
Epoch 83, Val Loss: 2.03444
Epoch 84, Val Loss: 2.04082
Epoch 85, Val Loss: 2.06568
Epoch 86, Val Loss: 2.03320
Epoch 87, Val Loss: 2.03729
Epoch 88, Val Loss: 2.02220
Epoch 89, Val Loss: 2.04225
Epoch 90, Val Loss: 2.05278
Epoch 91, Val Loss: 2.02929
Epoch 92, Val Loss: 2.05182
Epoch 93, Val Loss: 2.02696
Epoch 94, Val Loss: 2.03095
Epoch 95, Val Loss: 2.03067
Epoch 96, Val Loss: 2.04837
Epoch 97, Val Loss: 2.02173
Epoch 98, Val Loss: 2.04013
Epoch 99, Val Loss: 2.03406
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.7886, 'Log Loss - std': 0.4054085346906254} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}
Fitted encoder
Epoch 0, Val Loss: 2.08038
Epoch 1, Val Loss: 2.11150
Epoch 2, Val Loss: 2.07953
Epoch 3, Val Loss: 2.09524
Epoch 4, Val Loss: 2.07156
Epoch 5, Val Loss: 2.09904
Epoch 6, Val Loss: 2.06641
Epoch 7, Val Loss: 2.07711
Epoch 8, Val Loss: 2.06594
Epoch 9, Val Loss: 2.06058
Epoch 10, Val Loss: 2.08396
Epoch 11, Val Loss: 2.06192
Epoch 12, Val Loss: 2.06511
Epoch 13, Val Loss: 2.05668
Epoch 14, Val Loss: 2.05784
Epoch 15, Val Loss: 2.05508
Epoch 16, Val Loss: 2.05620
Epoch 17, Val Loss: 2.04497
Epoch 18, Val Loss: 2.04400
Epoch 19, Val Loss: 2.11726
Epoch 20, Val Loss: 2.03332
Epoch 21, Val Loss: 2.04413
Epoch 22, Val Loss: 2.05793
Epoch 23, Val Loss: 2.02841
Epoch 24, Val Loss: 2.03676
Epoch 25, Val Loss: 2.03131
Epoch 26, Val Loss: 2.09030
Epoch 27, Val Loss: 2.04142
Epoch 28, Val Loss: 2.03593
Epoch 29, Val Loss: 2.05909
Epoch 30, Val Loss: 2.04411
Epoch 31, Val Loss: 2.04080
Epoch 32, Val Loss: 2.03367
Epoch 33, Val Loss: 2.03435
Epoch 34, Val Loss: 2.04158
Epoch 35, Val Loss: 2.05184
Epoch 36, Val Loss: 2.03108
Epoch 37, Val Loss: 2.10896
Epoch 38, Val Loss: 2.04002
Epoch 39, Val Loss: 2.02773
Epoch 40, Val Loss: 2.03718
Epoch 41, Val Loss: 2.05453
Epoch 42, Val Loss: 2.06003
Epoch 43, Val Loss: 2.03315
Epoch 44, Val Loss: 2.09412
Epoch 45, Val Loss: 2.09417
Epoch 46, Val Loss: 2.08458
Epoch 47, Val Loss: 2.03841
Epoch 48, Val Loss: 2.02640
Epoch 49, Val Loss: 2.05765
Epoch 50, Val Loss: 2.02717
Epoch 51, Val Loss: 2.02266
Epoch 52, Val Loss: 2.01836
Epoch 53, Val Loss: 2.03318
Epoch 54, Val Loss: 2.01421
Epoch 55, Val Loss: 2.08019
Epoch 56, Val Loss: 2.01353
Epoch 57, Val Loss: 2.02360
Epoch 58, Val Loss: 2.03068
Epoch 59, Val Loss: 2.03970
Epoch 60, Val Loss: 2.03483
Epoch 61, Val Loss: 2.02665
Epoch 62, Val Loss: 2.03342
Epoch 63, Val Loss: 2.02339
Epoch 64, Val Loss: 2.02149
Epoch 65, Val Loss: 2.05675
Epoch 66, Val Loss: 2.04667
Epoch 67, Val Loss: 2.03918
Epoch 68, Val Loss: 2.01640
Epoch 69, Val Loss: 2.01727
Epoch 70, Val Loss: 2.04054
Epoch 71, Val Loss: 2.02037
Epoch 72, Val Loss: 2.01079
Epoch 73, Val Loss: 2.02065
Epoch 74, Val Loss: 2.01453
Epoch 75, Val Loss: 2.05813
Epoch 76, Val Loss: 2.03208
Epoch 77, Val Loss: 2.03226
Epoch 78, Val Loss: 2.03500
Epoch 79, Val Loss: 2.02656
Epoch 80, Val Loss: 2.02143
Epoch 81, Val Loss: 2.02918
Epoch 82, Val Loss: 2.03555
Epoch 83, Val Loss: 2.01432
Epoch 84, Val Loss: 2.02645
Epoch 85, Val Loss: 2.02962
Epoch 86, Val Loss: 2.02867
Epoch 87, Val Loss: 2.02842
Epoch 88, Val Loss: 2.01596
Epoch 89, Val Loss: 2.02193
Epoch 90, Val Loss: 2.02032
Epoch 91, Val Loss: 2.02515
Epoch 92, Val Loss: 2.08735
Epoch 93, Val Loss: 2.02067
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 2.921475, 'Log Loss - std': 0.41980275948950124} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}
Fitted encoder
Epoch 0, Val Loss: 1.98337
Epoch 1, Val Loss: 1.97897
Epoch 2, Val Loss: 1.96731
Epoch 3, Val Loss: 1.96826
Epoch 4, Val Loss: 1.94922
Epoch 5, Val Loss: 1.96106
Epoch 6, Val Loss: 1.93237
Epoch 7, Val Loss: 1.92551
Epoch 8, Val Loss: 1.90265
Epoch 9, Val Loss: 1.94468
Epoch 10, Val Loss: 1.93202
Epoch 11, Val Loss: 1.91221
Epoch 12, Val Loss: 1.92436
Epoch 13, Val Loss: 1.92764
Epoch 14, Val Loss: 1.90581
Epoch 15, Val Loss: 1.92876
Epoch 16, Val Loss: 1.91814
Epoch 17, Val Loss: 1.91336
Epoch 18, Val Loss: 1.88966
Epoch 19, Val Loss: 1.91448
Epoch 20, Val Loss: 1.91407
Epoch 21, Val Loss: 1.91128
Epoch 22, Val Loss: 1.89677
Epoch 23, Val Loss: 1.88919
Epoch 24, Val Loss: 1.90285
Epoch 25, Val Loss: 1.89375
Epoch 26, Val Loss: 1.91508
Epoch 27, Val Loss: 1.88962
Epoch 28, Val Loss: 1.89550
Epoch 29, Val Loss: 1.90124
Epoch 30, Val Loss: 1.89164
Epoch 31, Val Loss: 1.89147
Epoch 32, Val Loss: 1.90913
Epoch 33, Val Loss: 1.89660
Epoch 34, Val Loss: 1.89751
Epoch 35, Val Loss: 1.89573
Epoch 36, Val Loss: 1.89684
Epoch 37, Val Loss: 1.90125
Epoch 38, Val Loss: 1.90597
Epoch 39, Val Loss: 1.90682
Epoch 40, Val Loss: 1.90493
Epoch 41, Val Loss: 1.90609
Epoch 42, Val Loss: 1.90900
Epoch 43, Val Loss: 1.89062
Epoch 44, Val Loss: 1.89082
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 2.97322, 'Log Loss - std': 0.38948384510785555} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 58 finished with value: 2.97322 and parameters: {'p_m': 0.7563487441094847, 'alpha': 2.6000858570535983, 'K': 2, 'beta': 5.632669903919057}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}
Fitted encoder
Epoch 0, Val Loss: 2.20159
Epoch 1, Val Loss: 2.19778
Epoch 2, Val Loss: 2.19792
Epoch 3, Val Loss: 2.18743
Epoch 4, Val Loss: 2.22640
Epoch 5, Val Loss: 2.22640
Epoch 6, Val Loss: 2.22640
Epoch 7, Val Loss: 2.22640
Epoch 8, Val Loss: 2.22640
Epoch 9, Val Loss: 2.22640
Epoch 10, Val Loss: 2.22640
Epoch 11, Val Loss: 2.22640
Epoch 12, Val Loss: 2.22640
Epoch 13, Val Loss: 2.22640
Epoch 14, Val Loss: 2.22640
Epoch 15, Val Loss: 2.22640
Epoch 16, Val Loss: 2.22640
Epoch 17, Val Loss: 2.22640
Epoch 18, Val Loss: 2.22640
Epoch 19, Val Loss: 2.22640
Epoch 20, Val Loss: 2.22640
Epoch 21, Val Loss: 2.22640
Epoch 22, Val Loss: 2.22640
Epoch 23, Val Loss: 2.22640
Epoch 24, Val Loss: 2.22640
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 8.2022, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}
Fitted encoder
Epoch 0, Val Loss: 1.96948
Epoch 1, Val Loss: 1.96371
Epoch 2, Val Loss: 2.09540
Epoch 3, Val Loss: 1.95593
Epoch 4, Val Loss: 1.96737
Epoch 5, Val Loss: 2.04109
Epoch 6, Val Loss: 2.03333
Epoch 7, Val Loss: 2.07345
Epoch 8, Val Loss: 2.05123
Epoch 9, Val Loss: 2.03193
Epoch 10, Val Loss: 2.03110
Epoch 11, Val Loss: 2.02171
Epoch 12, Val Loss: 2.03019
Epoch 13, Val Loss: 1.92304
Epoch 14, Val Loss: 1.94116
Epoch 15, Val Loss: 1.91619
Epoch 16, Val Loss: 1.92870
Epoch 17, Val Loss: 1.94458
Epoch 18, Val Loss: 1.91916
Epoch 19, Val Loss: 1.93487
Epoch 20, Val Loss: 1.92524
Epoch 21, Val Loss: 1.92183
Epoch 22, Val Loss: 1.91847
Epoch 23, Val Loss: 1.92511
Epoch 24, Val Loss: 1.93447
Epoch 25, Val Loss: 1.93224
Epoch 26, Val Loss: 1.92604
Epoch 27, Val Loss: 1.91760
Epoch 28, Val Loss: 1.91647
Epoch 29, Val Loss: 1.92212
Epoch 30, Val Loss: 1.92531
Epoch 31, Val Loss: 1.92523
Epoch 32, Val Loss: 1.93554
Epoch 33, Val Loss: 1.92053
Epoch 34, Val Loss: 1.92356
Epoch 35, Val Loss: 1.91846
Epoch 36, Val Loss: 1.93200
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 5.7585999999999995, 'Log Loss - std': 2.4436} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}
Fitted encoder
Epoch 0, Val Loss: 2.13264
Epoch 1, Val Loss: 2.11409
Epoch 2, Val Loss: 2.11580
Epoch 3, Val Loss: 2.10075
Epoch 4, Val Loss: 2.08246
Epoch 5, Val Loss: 2.09378
Epoch 6, Val Loss: 2.09951
Epoch 7, Val Loss: 2.09745
Epoch 8, Val Loss: 2.09944
Epoch 9, Val Loss: 2.08118
Epoch 10, Val Loss: 2.09645
Epoch 11, Val Loss: 2.08365
Epoch 12, Val Loss: 2.06016
Epoch 13, Val Loss: 2.09146
Epoch 14, Val Loss: 2.10113
Epoch 15, Val Loss: 2.10912
Epoch 16, Val Loss: 2.06800
Epoch 17, Val Loss: 2.09186
Epoch 18, Val Loss: 2.07539
Epoch 19, Val Loss: 2.09880
Epoch 20, Val Loss: 2.08612
Epoch 21, Val Loss: 2.07275
Epoch 22, Val Loss: 2.08472
Epoch 23, Val Loss: 2.07978
Epoch 24, Val Loss: 2.07739
Epoch 25, Val Loss: 2.08928
Epoch 26, Val Loss: 2.07008
Epoch 27, Val Loss: 2.09985
Epoch 28, Val Loss: 2.06626
Epoch 29, Val Loss: 2.07115
Epoch 30, Val Loss: 2.07265
Epoch 31, Val Loss: 2.06539
Epoch 32, Val Loss: 2.07736
Epoch 33, Val Loss: 2.06812
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.915466666666666, 'Log Loss - std': 2.3243353764511308} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}
Fitted encoder
Epoch 0, Val Loss: 2.12373
Epoch 1, Val Loss: 2.05540
Epoch 2, Val Loss: 2.09310
Epoch 3, Val Loss: 2.04684
Epoch 4, Val Loss: 2.04636
Epoch 5, Val Loss: 2.03383
Epoch 6, Val Loss: 2.04098
Epoch 7, Val Loss: 2.03078
Epoch 8, Val Loss: 2.01704
Epoch 9, Val Loss: 2.11237
Epoch 10, Val Loss: 2.07816
Epoch 11, Val Loss: 2.07297
Epoch 12, Val Loss: 2.07940
Epoch 13, Val Loss: 2.02670
Epoch 14, Val Loss: 2.02963
Epoch 15, Val Loss: 2.02473
Epoch 16, Val Loss: 2.03319
Epoch 17, Val Loss: 2.07101
Epoch 18, Val Loss: 2.06439
Epoch 19, Val Loss: 2.04563
Epoch 20, Val Loss: 2.04469
Epoch 21, Val Loss: 2.02044
Epoch 22, Val Loss: 2.01346
Epoch 23, Val Loss: 2.04451
Epoch 24, Val Loss: 2.02615
Epoch 25, Val Loss: 2.02902
Epoch 26, Val Loss: 2.01431
Epoch 27, Val Loss: 2.01689
Epoch 28, Val Loss: 2.01796
Epoch 29, Val Loss: 2.05914
Epoch 30, Val Loss: 2.02733
Epoch 31, Val Loss: 2.05327
Epoch 32, Val Loss: 2.05480
Epoch 33, Val Loss: 2.09588
Epoch 34, Val Loss: 2.08031
Epoch 35, Val Loss: 2.10894
Epoch 36, Val Loss: 2.07482
Epoch 37, Val Loss: 2.02330
Epoch 38, Val Loss: 2.06791
Epoch 39, Val Loss: 2.13221
Epoch 40, Val Loss: 2.08510
Epoch 41, Val Loss: 2.08235
Epoch 42, Val Loss: 2.07814
Epoch 43, Val Loss: 2.07373
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.285, 'Log Loss - std': 2.290058047299238} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}
Fitted encoder
Epoch 0, Val Loss: 1.96908
Epoch 1, Val Loss: 1.98354
Epoch 2, Val Loss: 1.95211
Epoch 3, Val Loss: 1.95876
Epoch 4, Val Loss: 1.94417
Epoch 5, Val Loss: 1.94617
Epoch 6, Val Loss: 1.94015
Epoch 7, Val Loss: 1.96122
Epoch 8, Val Loss: 1.94987
Epoch 9, Val Loss: 1.94729
Epoch 10, Val Loss: 1.95939
Epoch 11, Val Loss: 1.94165
Epoch 12, Val Loss: 1.94441
Epoch 13, Val Loss: 1.97873
Epoch 14, Val Loss: 1.94553
Epoch 15, Val Loss: 1.93979
Epoch 16, Val Loss: 1.94342
Epoch 17, Val Loss: 1.95857
Epoch 18, Val Loss: 1.96466
Epoch 19, Val Loss: 1.92032
Epoch 20, Val Loss: 1.93657
Epoch 21, Val Loss: 1.93139
Epoch 22, Val Loss: 1.89959
Epoch 23, Val Loss: 1.91972
Epoch 24, Val Loss: 1.91411
Epoch 25, Val Loss: 1.90595
Epoch 26, Val Loss: 1.94972
Epoch 27, Val Loss: 1.91927
Epoch 28, Val Loss: 1.95321
Epoch 29, Val Loss: 1.91871
Epoch 30, Val Loss: 1.93652
Epoch 31, Val Loss: 1.90899
Epoch 32, Val Loss: 1.91263
Epoch 33, Val Loss: 1.95224
Epoch 34, Val Loss: 1.94359
Epoch 35, Val Loss: 1.90512
Epoch 36, Val Loss: 1.91500
Epoch 37, Val Loss: 1.93342
Epoch 38, Val Loss: 1.90461
Epoch 39, Val Loss: 1.92332
Epoch 40, Val Loss: 1.92573
Epoch 41, Val Loss: 1.90978
Epoch 42, Val Loss: 1.91126
Epoch 43, Val Loss: 1.90770
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 4.04624, 'Log Loss - std': 2.1032161178537976} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 59 finished with value: 4.04624 and parameters: {'p_m': 0.6186095088651944, 'alpha': 1.8089596430119623, 'K': 2, 'beta': 0.7638192281565749}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}
Fitted encoder
Epoch 0, Val Loss: 2.16322
Epoch 1, Val Loss: 2.15270
Epoch 2, Val Loss: 2.13115
Epoch 3, Val Loss: 2.12571
Epoch 4, Val Loss: 2.12664
Epoch 5, Val Loss: 2.14026
Epoch 6, Val Loss: 2.12228
Epoch 7, Val Loss: 2.13564
Epoch 8, Val Loss: 2.13841
Epoch 9, Val Loss: 2.12890
Epoch 10, Val Loss: 2.11950
Epoch 11, Val Loss: 2.12273
Epoch 12, Val Loss: 2.12497
Epoch 13, Val Loss: 2.13354
Epoch 14, Val Loss: 2.11973
Epoch 15, Val Loss: 2.12969
Epoch 16, Val Loss: 2.11918
Epoch 17, Val Loss: 2.10561
Epoch 18, Val Loss: 2.12124
Epoch 19, Val Loss: 2.11516
Epoch 20, Val Loss: 2.11061
Epoch 21, Val Loss: 2.13007
Epoch 22, Val Loss: 2.08884
Epoch 23, Val Loss: 2.09387
Epoch 24, Val Loss: 2.10384
Epoch 25, Val Loss: 2.12990
Epoch 26, Val Loss: 2.12588
Epoch 27, Val Loss: 2.10291
Epoch 28, Val Loss: 2.12347
Epoch 29, Val Loss: 2.10663
Epoch 30, Val Loss: 2.11950
Epoch 31, Val Loss: 2.09371
Epoch 32, Val Loss: 2.11567
Epoch 33, Val Loss: 2.09256
Epoch 34, Val Loss: 2.07475
Epoch 35, Val Loss: 2.08302
Epoch 36, Val Loss: 2.09232
Epoch 37, Val Loss: 2.10956
Epoch 38, Val Loss: 2.07609
Epoch 39, Val Loss: 2.07973
Epoch 40, Val Loss: 2.07519
Epoch 41, Val Loss: 2.09665
Epoch 42, Val Loss: 2.09729
Epoch 43, Val Loss: 2.06036
Epoch 44, Val Loss: 2.09690
Epoch 45, Val Loss: 2.08855
Epoch 46, Val Loss: 2.09904
Epoch 47, Val Loss: 2.08018
Epoch 48, Val Loss: 2.11785
Epoch 49, Val Loss: 2.10560
Epoch 50, Val Loss: 2.08912
Epoch 51, Val Loss: 2.07635
Epoch 52, Val Loss: 2.07604
Epoch 53, Val Loss: 2.09705
Epoch 54, Val Loss: 2.08085
Epoch 55, Val Loss: 2.09751
Epoch 56, Val Loss: 2.05373
Epoch 57, Val Loss: 2.07629
Epoch 58, Val Loss: 2.08411
Epoch 59, Val Loss: 2.06568
Epoch 60, Val Loss: 2.08761
Epoch 61, Val Loss: 2.08756
Epoch 62, Val Loss: 2.07455
Epoch 63, Val Loss: 2.06120
Epoch 64, Val Loss: 2.06041
Epoch 65, Val Loss: 2.08591
Epoch 66, Val Loss: 2.07234
Epoch 67, Val Loss: 2.09782
Epoch 68, Val Loss: 2.06806
Epoch 69, Val Loss: 2.07461
Epoch 70, Val Loss: 2.07139
Epoch 71, Val Loss: 2.08928
Epoch 72, Val Loss: 2.06155
Epoch 73, Val Loss: 2.05440
Epoch 74, Val Loss: 2.06242
Epoch 75, Val Loss: 2.09455
Epoch 76, Val Loss: 2.06355
Epoch 77, Val Loss: 2.06218
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.8549, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}
Fitted encoder
Epoch 0, Val Loss: 1.95491
Epoch 1, Val Loss: 1.95496
Epoch 2, Val Loss: 1.97167
Epoch 3, Val Loss: 1.95739
Epoch 4, Val Loss: 1.95081
Epoch 5, Val Loss: 1.94246
Epoch 6, Val Loss: 1.95069
Epoch 7, Val Loss: 1.94305
Epoch 8, Val Loss: 1.94759
Epoch 9, Val Loss: 1.94403
Epoch 10, Val Loss: 1.93592
Epoch 11, Val Loss: 1.95158
Epoch 12, Val Loss: 1.94614
Epoch 13, Val Loss: 1.93918
Epoch 14, Val Loss: 1.94456
Epoch 15, Val Loss: 1.94170
Epoch 16, Val Loss: 1.94084
Epoch 17, Val Loss: 1.94214
Epoch 18, Val Loss: 1.93683
Epoch 19, Val Loss: 1.93703
Epoch 20, Val Loss: 1.93295
Epoch 21, Val Loss: 1.93258
Epoch 22, Val Loss: 1.97677
Epoch 23, Val Loss: 1.92179
Epoch 24, Val Loss: 1.93247
Epoch 25, Val Loss: 1.93112
Epoch 26, Val Loss: 1.93362
Epoch 27, Val Loss: 1.92711
Epoch 28, Val Loss: 1.93543
Epoch 29, Val Loss: 1.92814
Epoch 30, Val Loss: 1.95983
Epoch 31, Val Loss: 1.93495
Epoch 32, Val Loss: 1.91942
Epoch 33, Val Loss: 1.93122
Epoch 34, Val Loss: 1.92508
Epoch 35, Val Loss: 1.93778
Epoch 36, Val Loss: 1.93451
Epoch 37, Val Loss: 1.92773
Epoch 38, Val Loss: 1.91215
Epoch 39, Val Loss: 1.93248
Epoch 40, Val Loss: 1.91927
Epoch 41, Val Loss: 1.92457
Epoch 42, Val Loss: 1.92032
Epoch 43, Val Loss: 1.91489
Epoch 44, Val Loss: 1.93739
Epoch 45, Val Loss: 1.93639
Epoch 46, Val Loss: 1.92808
Epoch 47, Val Loss: 1.92507
Epoch 48, Val Loss: 1.91798
Epoch 49, Val Loss: 1.92740
Epoch 50, Val Loss: 1.96036
Epoch 51, Val Loss: 1.94166
Epoch 52, Val Loss: 1.95863
Epoch 53, Val Loss: 1.95878
Epoch 54, Val Loss: 1.91972
Epoch 55, Val Loss: 1.94655
Epoch 56, Val Loss: 1.92564
Epoch 57, Val Loss: 1.92309
Epoch 58, Val Loss: 1.92692
Epoch 59, Val Loss: 1.93660
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.51675, 'Log Loss - std': 0.3381500000000002} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}
Fitted encoder
Epoch 0, Val Loss: 2.12076
Epoch 1, Val Loss: 2.09935
Epoch 2, Val Loss: 2.10798
Epoch 3, Val Loss: 2.11779
Epoch 4, Val Loss: 2.07771
Epoch 5, Val Loss: 2.08461
Epoch 6, Val Loss: 2.08627
Epoch 7, Val Loss: 2.08539
Epoch 8, Val Loss: 2.10558
Epoch 9, Val Loss: 2.06336
Epoch 10, Val Loss: 2.08283
Epoch 11, Val Loss: 2.07370
Epoch 12, Val Loss: 2.04234
Epoch 13, Val Loss: 2.07571
Epoch 14, Val Loss: 2.06449
Epoch 15, Val Loss: 2.08224
Epoch 16, Val Loss: 2.05729
Epoch 17, Val Loss: 2.03265
Epoch 18, Val Loss: 2.03452
Epoch 19, Val Loss: 2.05233
Epoch 20, Val Loss: 2.03362
Epoch 21, Val Loss: 2.04101
Epoch 22, Val Loss: 2.02939
Epoch 23, Val Loss: 2.02037
Epoch 24, Val Loss: 2.04214
Epoch 25, Val Loss: 2.03361
Epoch 26, Val Loss: 2.02106
Epoch 27, Val Loss: 2.03069
Epoch 28, Val Loss: 2.06364
Epoch 29, Val Loss: 2.07351
Epoch 30, Val Loss: 2.05888
Epoch 31, Val Loss: 2.05795
Epoch 32, Val Loss: 2.03912
Epoch 33, Val Loss: 2.02669
Epoch 34, Val Loss: 2.07134
Epoch 35, Val Loss: 2.03545
Epoch 36, Val Loss: 2.02628
Epoch 37, Val Loss: 2.03322
Epoch 38, Val Loss: 2.01950
Epoch 39, Val Loss: 2.02606
Epoch 40, Val Loss: 2.02235
Epoch 41, Val Loss: 2.06921
Epoch 42, Val Loss: 2.06655
Epoch 43, Val Loss: 2.11473
Epoch 44, Val Loss: 2.07008
Epoch 45, Val Loss: 2.05712
Epoch 46, Val Loss: 2.05571
Epoch 47, Val Loss: 2.01400
Epoch 48, Val Loss: 2.04779
Epoch 49, Val Loss: 2.05615
Epoch 50, Val Loss: 2.05713
Epoch 51, Val Loss: 2.07978
Epoch 52, Val Loss: 2.05565
Epoch 53, Val Loss: 2.02995
Epoch 54, Val Loss: 2.02830
Epoch 55, Val Loss: 2.07863
Epoch 56, Val Loss: 2.03263
Epoch 57, Val Loss: 2.04219
Epoch 58, Val Loss: 2.02926
Epoch 59, Val Loss: 2.03948
Epoch 60, Val Loss: 2.03141
Epoch 61, Val Loss: 2.01950
Epoch 62, Val Loss: 2.03513
Epoch 63, Val Loss: 2.03075
Epoch 64, Val Loss: 2.02527
Epoch 65, Val Loss: 2.02038
Epoch 66, Val Loss: 2.01881
Epoch 67, Val Loss: 2.02832
Epoch 68, Val Loss: 2.02685
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.186666666666667, 'Log Loss - std': 0.5423470250269247} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}
Fitted encoder
Epoch 0, Val Loss: 2.09358
Epoch 1, Val Loss: 2.07767
Epoch 2, Val Loss: 2.05499
Epoch 3, Val Loss: 2.07859
Epoch 4, Val Loss: 2.08499
Epoch 5, Val Loss: 2.04647
Epoch 6, Val Loss: 2.05486
Epoch 7, Val Loss: 2.03362
Epoch 8, Val Loss: 2.08039
Epoch 9, Val Loss: 2.04124
Epoch 10, Val Loss: 2.04078
Epoch 11, Val Loss: 2.06072
Epoch 12, Val Loss: 2.03574
Epoch 13, Val Loss: 2.05552
Epoch 14, Val Loss: 2.02838
Epoch 15, Val Loss: 2.02790
Epoch 16, Val Loss: 2.05303
Epoch 17, Val Loss: 2.02297
Epoch 18, Val Loss: 2.03121
Epoch 19, Val Loss: 2.03085
Epoch 20, Val Loss: 2.03143
Epoch 21, Val Loss: 2.02792
Epoch 22, Val Loss: 2.03871
Epoch 23, Val Loss: 2.02873
Epoch 24, Val Loss: 2.01769
Epoch 25, Val Loss: 2.02580
Epoch 26, Val Loss: 2.04504
Epoch 27, Val Loss: 2.04224
Epoch 28, Val Loss: 2.03852
Epoch 29, Val Loss: 2.03492
Epoch 30, Val Loss: 2.02248
Epoch 31, Val Loss: 2.09352
Epoch 32, Val Loss: 2.02786
Epoch 33, Val Loss: 2.05252
Epoch 34, Val Loss: 2.01960
Epoch 35, Val Loss: 2.02512
Epoch 36, Val Loss: 2.03201
Epoch 37, Val Loss: 2.04269
Epoch 38, Val Loss: 2.03713
Epoch 39, Val Loss: 2.03134
Epoch 40, Val Loss: 2.02172
Epoch 41, Val Loss: 2.05877
Epoch 42, Val Loss: 2.03342
Epoch 43, Val Loss: 2.03141
Epoch 44, Val Loss: 2.03810
Epoch 45, Val Loss: 2.03141
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.02025, 'Log Loss - std': 0.5510796153914606} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}
Fitted encoder
Epoch 0, Val Loss: 2.05802
Epoch 1, Val Loss: 1.95328
Epoch 2, Val Loss: 1.94163
Epoch 3, Val Loss: 1.96858
Epoch 4, Val Loss: 1.95720
Epoch 5, Val Loss: 1.94920
Epoch 6, Val Loss: 1.94059
Epoch 7, Val Loss: 1.96424
Epoch 8, Val Loss: 1.93592
Epoch 9, Val Loss: 1.94210
Epoch 10, Val Loss: 1.92705
Epoch 11, Val Loss: 1.94711
Epoch 12, Val Loss: 1.95349
Epoch 13, Val Loss: 1.92078
Epoch 14, Val Loss: 1.90341
Epoch 15, Val Loss: 1.94286
Epoch 16, Val Loss: 1.94119
Epoch 17, Val Loss: 1.93114
Epoch 18, Val Loss: 1.91985
Epoch 19, Val Loss: 1.93913
Epoch 20, Val Loss: 1.90160
Epoch 21, Val Loss: 1.91111
Epoch 22, Val Loss: 1.92065
Epoch 23, Val Loss: 1.91267
Epoch 24, Val Loss: 1.93851
Epoch 25, Val Loss: 1.89968
Epoch 26, Val Loss: 1.92875
Epoch 27, Val Loss: 1.89946
Epoch 28, Val Loss: 1.91496
Epoch 29, Val Loss: 1.90604
Epoch 30, Val Loss: 1.92540
Epoch 31, Val Loss: 1.92180
Epoch 32, Val Loss: 1.92678
Epoch 33, Val Loss: 1.90030
Epoch 34, Val Loss: 1.91102
Epoch 35, Val Loss: 1.90574
Epoch 36, Val Loss: 1.92782
Epoch 37, Val Loss: 1.89136
Epoch 38, Val Loss: 1.89158
Epoch 39, Val Loss: 1.89164
Epoch 40, Val Loss: 1.89171
Epoch 41, Val Loss: 1.88049
Epoch 42, Val Loss: 1.89627
Epoch 43, Val Loss: 1.90958
Epoch 44, Val Loss: 1.87703
Epoch 45, Val Loss: 1.89519
Epoch 46, Val Loss: 1.93615
Epoch 47, Val Loss: 1.93892
Epoch 48, Val Loss: 1.93256
Epoch 49, Val Loss: 1.89972
Epoch 50, Val Loss: 1.93212
Epoch 51, Val Loss: 1.90505
Epoch 52, Val Loss: 1.88723
Epoch 53, Val Loss: 1.89220
Epoch 54, Val Loss: 1.87260
Epoch 55, Val Loss: 1.91084
Epoch 56, Val Loss: 1.90365
Epoch 57, Val Loss: 1.90005
Epoch 58, Val Loss: 1.88156
Epoch 59, Val Loss: 1.88677
Epoch 60, Val Loss: 1.92484
Epoch 61, Val Loss: 1.90537
Epoch 62, Val Loss: 1.88273
Epoch 63, Val Loss: 1.90054
Epoch 64, Val Loss: 1.91844
Epoch 65, Val Loss: 1.89169
Epoch 66, Val Loss: 1.89838
Epoch 67, Val Loss: 1.90569
Epoch 68, Val Loss: 1.88745
Epoch 69, Val Loss: 1.88358
Epoch 70, Val Loss: 1.87490
Epoch 71, Val Loss: 1.88273
Epoch 72, Val Loss: 1.89259
Epoch 73, Val Loss: 1.88846
Epoch 74, Val Loss: 1.89859
Epoch 75, Val Loss: 1.89622
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.0350200000000003, 'Log Loss - std': 0.49378497911540414} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 60 finished with value: 3.0350200000000003 and parameters: {'p_m': 0.562574429034013, 'alpha': 1.8773671043147373, 'K': 2, 'beta': 0.9200502505012373}. Best is trial 55 with value: 4.93648.
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}
Fitted encoder
Epoch 0, Val Loss: 2.15018
Epoch 1, Val Loss: 2.10216
Epoch 2, Val Loss: 2.09652
Epoch 3, Val Loss: 2.07262
Epoch 4, Val Loss: 2.09543
Epoch 5, Val Loss: 2.09040
Epoch 6, Val Loss: 2.11856
Epoch 7, Val Loss: 2.11821
Epoch 8, Val Loss: 2.10084
Epoch 9, Val Loss: 2.09687
Epoch 10, Val Loss: 2.07791
Epoch 11, Val Loss: 2.09431
Epoch 12, Val Loss: 2.07181
Epoch 13, Val Loss: 2.06403
Epoch 14, Val Loss: 2.07309
Epoch 15, Val Loss: 2.06177
Epoch 16, Val Loss: 2.06924
Epoch 17, Val Loss: 2.10573
Epoch 18, Val Loss: 2.07572
Epoch 19, Val Loss: 2.09580
Epoch 20, Val Loss: 2.12867
Epoch 21, Val Loss: 2.05169
Epoch 22, Val Loss: 2.07963
Epoch 23, Val Loss: 2.07050
Epoch 24, Val Loss: 2.02883
Epoch 25, Val Loss: 2.04616
Epoch 26, Val Loss: 2.06401
Epoch 27, Val Loss: 2.05674
Epoch 28, Val Loss: 2.07116
Epoch 29, Val Loss: 2.05259
Epoch 30, Val Loss: 2.08566
Epoch 31, Val Loss: 2.05965
Epoch 32, Val Loss: 2.03687
Epoch 33, Val Loss: 2.04477
Epoch 34, Val Loss: 2.05038
Epoch 35, Val Loss: 2.04203
Epoch 36, Val Loss: 2.04823
Epoch 37, Val Loss: 2.04483
Epoch 38, Val Loss: 2.03712
Epoch 39, Val Loss: 2.02949
Epoch 40, Val Loss: 2.06212
Epoch 41, Val Loss: 2.04331
Epoch 42, Val Loss: 2.03485
Epoch 43, Val Loss: 2.03231
Epoch 44, Val Loss: 2.06959
Epoch 45, Val Loss: 2.03868
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 3.4356, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}
Fitted encoder
Epoch 0, Val Loss: 1.97264
Epoch 1, Val Loss: 1.94915
Epoch 2, Val Loss: 1.95793
Epoch 3, Val Loss: 1.95132
Epoch 4, Val Loss: 1.94412
Epoch 5, Val Loss: 1.94693
Epoch 6, Val Loss: 1.94944
Epoch 7, Val Loss: 1.93905
Epoch 8, Val Loss: 1.96461
Epoch 9, Val Loss: 1.93829
Epoch 10, Val Loss: 1.94272
Epoch 11, Val Loss: 1.93946
Epoch 12, Val Loss: 1.93915
Epoch 13, Val Loss: 1.93439
Epoch 14, Val Loss: 1.93499
Epoch 15, Val Loss: 1.93972
Epoch 16, Val Loss: 1.93173
Epoch 17, Val Loss: 1.94295
Epoch 18, Val Loss: 1.93621
Epoch 19, Val Loss: 1.94197
Epoch 20, Val Loss: 1.94087
Epoch 21, Val Loss: 1.93038
Epoch 22, Val Loss: 1.93645
Epoch 23, Val Loss: 1.92978
Epoch 24, Val Loss: 1.93717
Epoch 25, Val Loss: 1.93503
Epoch 26, Val Loss: 1.93562
Epoch 27, Val Loss: 1.92449
Epoch 28, Val Loss: 1.96697
Epoch 29, Val Loss: 1.93571
Epoch 30, Val Loss: 1.93916
Epoch 31, Val Loss: 2.05207
Epoch 32, Val Loss: 1.94410
Epoch 33, Val Loss: 1.93385
Epoch 34, Val Loss: 1.93729
Epoch 35, Val Loss: 1.92754
Epoch 36, Val Loss: 1.91426
Epoch 37, Val Loss: 1.94258
Epoch 38, Val Loss: 1.92220
Epoch 39, Val Loss: 1.92414
Epoch 40, Val Loss: 1.90972
Epoch 41, Val Loss: 1.91697
Epoch 42, Val Loss: 1.93071
Epoch 43, Val Loss: 1.92215
Epoch 44, Val Loss: 1.91274
Epoch 45, Val Loss: 1.93813
Epoch 46, Val Loss: 1.91933
Epoch 47, Val Loss: 1.91043
Epoch 48, Val Loss: 1.91382
Epoch 49, Val Loss: 1.91353
Epoch 50, Val Loss: 1.91503
Epoch 51, Val Loss: 1.92462
Epoch 52, Val Loss: 1.90880
Epoch 53, Val Loss: 1.90696
Epoch 54, Val Loss: 1.91534
Epoch 55, Val Loss: 1.91228
Epoch 56, Val Loss: 1.90260
Epoch 57, Val Loss: 1.92114
Epoch 58, Val Loss: 1.92231
Epoch 59, Val Loss: 1.91502
Epoch 60, Val Loss: 1.91422
Epoch 61, Val Loss: 1.94322
Epoch 62, Val Loss: 1.91452
Epoch 63, Val Loss: 1.91247
Epoch 64, Val Loss: 1.90935
Epoch 65, Val Loss: 1.90066
Epoch 66, Val Loss: 1.90393
Epoch 67, Val Loss: 1.92867
Epoch 68, Val Loss: 1.90896
Epoch 69, Val Loss: 1.90643
Epoch 70, Val Loss: 1.92314
Epoch 71, Val Loss: 1.92764
Epoch 72, Val Loss: 1.90288
Epoch 73, Val Loss: 1.91067
Epoch 74, Val Loss: 1.91797
Epoch 75, Val Loss: 1.92167
Epoch 76, Val Loss: 1.90127
Epoch 77, Val Loss: 1.91191
Epoch 78, Val Loss: 1.90882
Epoch 79, Val Loss: 1.91275
Epoch 80, Val Loss: 1.90644
Epoch 81, Val Loss: 1.90445
Epoch 82, Val Loss: 1.91432
Epoch 83, Val Loss: 1.92575
Epoch 84, Val Loss: 1.89914
Epoch 85, Val Loss: 1.90748
Epoch 86, Val Loss: 1.89818
Epoch 87, Val Loss: 1.90872
Epoch 88, Val Loss: 1.92363
Epoch 89, Val Loss: 1.91877
Epoch 90, Val Loss: 1.91951
Epoch 91, Val Loss: 1.90703
Epoch 92, Val Loss: 1.90070
Epoch 93, Val Loss: 1.96667
Epoch 94, Val Loss: 1.90279
Epoch 95, Val Loss: 1.90392
Epoch 96, Val Loss: 1.90203
Epoch 97, Val Loss: 1.90554
Epoch 98, Val Loss: 1.91383
Epoch 99, Val Loss: 1.91962
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 3.4091, 'Log Loss - std': 0.026499999999999968} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}
Fitted encoder
Epoch 0, Val Loss: 2.15780
Epoch 1, Val Loss: 2.15926
Epoch 2, Val Loss: 2.13737
Epoch 3, Val Loss: 2.14778
Epoch 4, Val Loss: 2.14805
Epoch 5, Val Loss: 2.14046
Epoch 6, Val Loss: 2.13981
Epoch 7, Val Loss: 2.14110
Epoch 8, Val Loss: 2.13853
Epoch 9, Val Loss: 2.13239
Epoch 10, Val Loss: 2.10626
Epoch 11, Val Loss: 2.11331
Epoch 12, Val Loss: 2.12190
Epoch 13, Val Loss: 2.10314
Epoch 14, Val Loss: 2.11005
Epoch 15, Val Loss: 2.10886
Epoch 16, Val Loss: 2.10286
Epoch 17, Val Loss: 2.10111
Epoch 18, Val Loss: 2.10928
Epoch 19, Val Loss: 2.10482
Epoch 20, Val Loss: 2.10301
Epoch 21, Val Loss: 2.10234
Epoch 22, Val Loss: 2.10493
Epoch 23, Val Loss: 2.10069
Epoch 24, Val Loss: 2.10950
Epoch 25, Val Loss: 2.10718
Epoch 26, Val Loss: 2.09964
Epoch 27, Val Loss: 2.10004
Epoch 28, Val Loss: 2.12313
Epoch 29, Val Loss: 2.13125
Epoch 30, Val Loss: 2.13750
Epoch 31, Val Loss: 2.12595
Epoch 32, Val Loss: 2.11026
Epoch 33, Val Loss: 2.11624
Epoch 34, Val Loss: 2.12597
Epoch 35, Val Loss: 2.14016
Epoch 36, Val Loss: 2.11843
Epoch 37, Val Loss: 2.08133
Epoch 38, Val Loss: 2.09685
Epoch 39, Val Loss: 2.11017
Epoch 40, Val Loss: 2.10408
Epoch 41, Val Loss: 2.08029
Epoch 42, Val Loss: 2.11493
Epoch 43, Val Loss: 2.09147
Epoch 44, Val Loss: 2.08701
Epoch 45, Val Loss: 2.07767
Epoch 46, Val Loss: 2.13462
Epoch 47, Val Loss: 2.08079
Epoch 48, Val Loss: 2.08230
Epoch 49, Val Loss: 2.09368
Epoch 50, Val Loss: 2.06581
Epoch 51, Val Loss: 2.07400
Epoch 52, Val Loss: 2.06900
Epoch 53, Val Loss: 2.06301
Epoch 54, Val Loss: 2.05418
Epoch 55, Val Loss: 2.08409
Epoch 56, Val Loss: 2.06767
Epoch 57, Val Loss: 2.10433
Epoch 58, Val Loss: 2.07793
Epoch 59, Val Loss: 2.08152
Epoch 60, Val Loss: 2.06980
Epoch 61, Val Loss: 2.06965
Epoch 62, Val Loss: 2.06723
Epoch 63, Val Loss: 2.07781
Epoch 64, Val Loss: 2.05511
Epoch 65, Val Loss: 2.07580
Epoch 66, Val Loss: 2.07552
Epoch 67, Val Loss: 2.07813
Epoch 68, Val Loss: 2.07024
Epoch 69, Val Loss: 2.06130
Epoch 70, Val Loss: 2.06980
Epoch 71, Val Loss: 2.04847
Epoch 72, Val Loss: 2.06638
Epoch 73, Val Loss: 2.06810
Epoch 74, Val Loss: 2.05143
Epoch 75, Val Loss: 2.06436
Epoch 76, Val Loss: 2.06118
Epoch 77, Val Loss: 2.05041
Epoch 78, Val Loss: 2.06391
Epoch 79, Val Loss: 2.05965
Epoch 80, Val Loss: 2.06499
Epoch 81, Val Loss: 2.05208
Epoch 82, Val Loss: 2.05365
Epoch 83, Val Loss: 2.07422
Epoch 84, Val Loss: 2.06189
Epoch 85, Val Loss: 2.08203
Epoch 86, Val Loss: 2.06047
Epoch 87, Val Loss: 2.08460
Epoch 88, Val Loss: 2.05547
Epoch 89, Val Loss: 2.05419
Epoch 90, Val Loss: 2.08520
Epoch 91, Val Loss: 2.05289
Epoch 92, Val Loss: 2.05934
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.3334666666666664, 'Log Loss - std': 0.10912822223828673} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}
Fitted encoder
Epoch 0, Val Loss: 2.06978
Epoch 1, Val Loss: 2.07607
Epoch 2, Val Loss: 2.07329
Epoch 3, Val Loss: 2.06361
Epoch 4, Val Loss: 2.07626
Epoch 5, Val Loss: 2.09134
Epoch 6, Val Loss: 2.05949
Epoch 7, Val Loss: 2.06599
Epoch 8, Val Loss: 2.05590
Epoch 9, Val Loss: 2.08370
Epoch 10, Val Loss: 2.05537
Epoch 11, Val Loss: 2.07063
Epoch 12, Val Loss: 2.05609
Epoch 13, Val Loss: 2.05413
Epoch 14, Val Loss: 2.04905
Epoch 15, Val Loss: 2.04703
Epoch 16, Val Loss: 2.04465
Epoch 17, Val Loss: 2.06161
Epoch 18, Val Loss: 2.04362
Epoch 19, Val Loss: 2.03740
Epoch 20, Val Loss: 2.05004
Epoch 21, Val Loss: 2.05103
Epoch 22, Val Loss: 2.05293
Epoch 23, Val Loss: 2.04366
Epoch 24, Val Loss: 2.04909
Epoch 25, Val Loss: 2.04267
Epoch 26, Val Loss: 2.03908
Epoch 27, Val Loss: 2.05406
Epoch 28, Val Loss: 2.03214
Epoch 29, Val Loss: 2.04095
Epoch 30, Val Loss: 2.04650
Epoch 31, Val Loss: 2.05992
Epoch 32, Val Loss: 2.05966
Epoch 33, Val Loss: 2.04433
Epoch 34, Val Loss: 2.05132
Epoch 35, Val Loss: 2.04699
Epoch 36, Val Loss: 2.03554
Epoch 37, Val Loss: 2.04172
Epoch 38, Val Loss: 2.03850
Epoch 39, Val Loss: 2.03746
Epoch 40, Val Loss: 2.04701
Epoch 41, Val Loss: 2.03128
Epoch 42, Val Loss: 2.03529
Epoch 43, Val Loss: 2.04871
Epoch 44, Val Loss: 2.03537
Epoch 45, Val Loss: 2.03047
Epoch 46, Val Loss: 2.05187
Epoch 47, Val Loss: 2.04335
Epoch 48, Val Loss: 2.03715
Epoch 49, Val Loss: 2.02964
Epoch 50, Val Loss: 2.03765
Epoch 51, Val Loss: 2.03273
Epoch 52, Val Loss: 2.06216
Epoch 53, Val Loss: 2.05801
Epoch 54, Val Loss: 2.05032
Epoch 55, Val Loss: 2.03435
Epoch 56, Val Loss: 2.03403
Epoch 57, Val Loss: 2.04694
Epoch 58, Val Loss: 2.04798
Epoch 59, Val Loss: 2.05312
Epoch 60, Val Loss: 2.03724
Epoch 61, Val Loss: 2.02610
Epoch 62, Val Loss: 2.04775
Epoch 63, Val Loss: 2.04853
Epoch 64, Val Loss: 2.07452
Epoch 65, Val Loss: 2.04207
Epoch 66, Val Loss: 2.04921
Epoch 67, Val Loss: 2.03961
Epoch 68, Val Loss: 2.05035
Epoch 69, Val Loss: 2.07196
Epoch 70, Val Loss: 2.03788
Epoch 71, Val Loss: 2.04605
Epoch 72, Val Loss: 2.04332
Epoch 73, Val Loss: 2.04193
Epoch 74, Val Loss: 2.04928
Epoch 75, Val Loss: 2.02167
Epoch 76, Val Loss: 2.03201
Epoch 77, Val Loss: 2.02432
Epoch 78, Val Loss: 2.02176
Epoch 79, Val Loss: 2.02837
Epoch 80, Val Loss: 2.03811
Epoch 81, Val Loss: 2.02210
Epoch 82, Val Loss: 2.02890
Epoch 83, Val Loss: 2.03832
Epoch 84, Val Loss: 2.03494
Epoch 85, Val Loss: 2.08353
Epoch 86, Val Loss: 2.02358
Epoch 87, Val Loss: 2.12038
Epoch 88, Val Loss: 2.11262
Epoch 89, Val Loss: 2.10602
Epoch 90, Val Loss: 2.10750
Epoch 91, Val Loss: 2.09866
Epoch 92, Val Loss: 2.10657
Epoch 93, Val Loss: 2.08816
Epoch 94, Val Loss: 2.11398
Epoch 95, Val Loss: 2.11109
Epoch 96, Val Loss: 2.10995
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 3.2960749999999996, 'Log Loss - std': 0.11456935399573487} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}
Fitted encoder
Epoch 0, Val Loss: 1.96670
Epoch 1, Val Loss: 1.97985
Epoch 2, Val Loss: 1.94359
Epoch 3, Val Loss: 1.94281
Epoch 4, Val Loss: 1.94453
Epoch 5, Val Loss: 1.94155
Epoch 6, Val Loss: 1.94596
Epoch 7, Val Loss: 1.94941
Epoch 8, Val Loss: 1.95008
Epoch 9, Val Loss: 1.94667
Epoch 10, Val Loss: 1.94241
Epoch 11, Val Loss: 1.95046
Epoch 12, Val Loss: 1.93895
Epoch 13, Val Loss: 1.95052
Epoch 14, Val Loss: 1.94822
Epoch 15, Val Loss: 1.95783
Epoch 16, Val Loss: 1.93450
Epoch 17, Val Loss: 1.94706
Epoch 18, Val Loss: 1.93784
Epoch 19, Val Loss: 1.93605
Epoch 20, Val Loss: 1.93272
Epoch 21, Val Loss: 1.92683
Epoch 22, Val Loss: 1.93389
Epoch 23, Val Loss: 1.93236
Epoch 24, Val Loss: 1.92042
Epoch 25, Val Loss: 1.93740
Epoch 26, Val Loss: 1.94090
Epoch 27, Val Loss: 1.93982
Epoch 28, Val Loss: 1.93270
Epoch 29, Val Loss: 1.91459
Epoch 30, Val Loss: 1.94487
Epoch 31, Val Loss: 1.91918
Epoch 32, Val Loss: 1.94368
Epoch 33, Val Loss: 1.92840
Epoch 34, Val Loss: 1.90589
Epoch 35, Val Loss: 1.91023
Epoch 36, Val Loss: 1.93747
Epoch 37, Val Loss: 1.94280
Epoch 38, Val Loss: 1.94315
Epoch 39, Val Loss: 1.93482
Epoch 40, Val Loss: 1.90163
Epoch 41, Val Loss: 1.89838
Epoch 42, Val Loss: 1.90304
Epoch 43, Val Loss: 1.92629
Epoch 44, Val Loss: 1.88962
Epoch 45, Val Loss: 1.89666
Epoch 46, Val Loss: 1.90576
Epoch 47, Val Loss: 1.88853
Epoch 48, Val Loss: 1.89706
Epoch 49, Val Loss: 1.90776
Epoch 50, Val Loss: 1.94113
Epoch 51, Val Loss: 1.94547
Epoch 52, Val Loss: 1.90191
Epoch 53, Val Loss: 1.89093
Epoch 54, Val Loss: 1.91945
Epoch 55, Val Loss: 1.88795
Epoch 56, Val Loss: 2.00238
Epoch 57, Val Loss: 1.99817
Epoch 58, Val Loss: 1.95569
Epoch 59, Val Loss: 1.96761
Epoch 60, Val Loss: 2.07199
Epoch 61, Val Loss: 1.95299
Epoch 62, Val Loss: 1.92811
Epoch 63, Val Loss: 1.91710
Epoch 64, Val Loss: 1.90593
Epoch 65, Val Loss: 1.89125
Epoch 66, Val Loss: 1.97680
Epoch 67, Val Loss: 1.95389
Epoch 68, Val Loss: 1.89094
Epoch 69, Val Loss: 1.89354
Epoch 70, Val Loss: 1.89889
Epoch 71, Val Loss: 1.89399
Epoch 72, Val Loss: 1.95549
Epoch 73, Val Loss: 1.93135
Epoch 74, Val Loss: 1.91452
Epoch 75, Val Loss: 1.89447
Epoch 76, Val Loss: 1.89177
Early stopping applies.
State of save is False b4 loss saving
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.35982, 'Log Loss - std': 0.1635683636893149} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 61 finished with value: 3.35982 and parameters: {'p_m': 0.6136472228436177, 'alpha': 1.0839340828699082, 'K': 2, 'beta': 0.8114845005868834}. Best is trial 55 with value: 4.93648.
Best parameters After Trials: {'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Parameters saved to YAML file!!!
In get_device
On Device: cuda
Fold 1
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5711722952584546 -0.42686139059459793
  -1.1403358713163287 -0.6396371751892543 -0.6047860626063131
  -0.7242292401724562 -0.6378172121693153]
 [0.0 0.0 1.0 -1.4481230668108207 -1.4372003130391107 -1.268891079376386
  -1.2313829452130387 -1.1708398800472457 -1.207928885291349
  -1.2181336383713948]
 [0.0 0.0 1.0 -0.6964509769087927 -0.42686139059459793
  -0.3690046229559858 -0.6355349514802506 -0.6455419374620602
  -0.6044559947144446 -0.6015474355316853]
 [0.0 1.0 0.0 -1.6151613090112709 -1.538234205283562 -1.5260014954965002
  -1.273430738230327 -1.2161241854425204 -1.2908488244545877
  -1.3269429682842848]
 [0.0 1.0 0.0 -0.8217296585591307 -1.0835816901835313 -1.1403358713163287
  -0.9729428515458055 -0.9829100126568561 -0.9407424146542464
  -0.8554358719950952]
 [1.0 0.0 0.0 0.055221112993235226 0.07830807062765843
  0.27377141734429983 -0.09916920152801632 -0.5481806808622199
  -0.3510895139378818 0.6678947467853636]
 [1.0 0.0 0.0 0.1804997946435733 0.17934196287210982 -0.3690046229559858
  -0.11865476414578383 -0.2900601401091547 -0.27738290134833615
  0.16011787385854406]
 [0.0 0.0 1.0 -0.4041340530580043 -0.3763444444723722 -0.3690046229559858
  -0.6488671785345128 -0.6410135069225328 -0.6182759845749843
  -0.5290078822564254]
 [1.0 0.0 0.0 0.013461552443122539 -0.27531055222792084
  0.016661001224186022 -0.44990932864783295 -0.7429031940619006
  -0.2958095544957226 -0.20257989251775574]
 [0.0 0.0 1.0 -0.27885537140766625 -0.27531055222792084
  -0.11189420683587124 -0.5832315991904535 -0.6364850763830053
  -0.7795091996146154 -0.3476589990682755]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.15461
Epoch 1, Val Loss: 2.13452
Epoch 2, Val Loss: 2.12298
Epoch 3, Val Loss: 2.13332
Epoch 4, Val Loss: 2.09454
Epoch 5, Val Loss: 2.07661
Epoch 6, Val Loss: 2.10737
Epoch 7, Val Loss: 2.12882
Epoch 8, Val Loss: 2.08206
Epoch 9, Val Loss: 2.09726
Epoch 10, Val Loss: 2.08372
Epoch 11, Val Loss: 2.06646
Epoch 12, Val Loss: 2.09789
Epoch 13, Val Loss: 2.06839
Epoch 14, Val Loss: 2.11095
Epoch 15, Val Loss: 2.05926
Epoch 16, Val Loss: 2.08577
Epoch 17, Val Loss: 2.08254
Epoch 18, Val Loss: 2.09269
Epoch 19, Val Loss: 2.07705
Epoch 20, Val Loss: 2.07099
Epoch 21, Val Loss: 2.07526
Epoch 22, Val Loss: 2.09197
Epoch 23, Val Loss: 2.10257
Epoch 24, Val Loss: 2.09579
Epoch 25, Val Loss: 2.05560
Epoch 26, Val Loss: 2.08863
Epoch 27, Val Loss: 2.06689
Epoch 28, Val Loss: 2.08125
Epoch 29, Val Loss: 2.06682
Epoch 30, Val Loss: 2.08018
Epoch 31, Val Loss: 2.10712
Epoch 32, Val Loss: 2.09298
Epoch 33, Val Loss: 2.10450
Epoch 34, Val Loss: 2.09080
Epoch 35, Val Loss: 2.07983
Epoch 36, Val Loss: 2.06763
Epoch 37, Val Loss: 2.09235
Epoch 38, Val Loss: 2.07731
Epoch 39, Val Loss: 2.06990
Epoch 40, Val Loss: 2.08092
Epoch 41, Val Loss: 2.05214
Epoch 42, Val Loss: 2.06901
Epoch 43, Val Loss: 2.07711
Epoch 44, Val Loss: 2.08909
Epoch 45, Val Loss: 2.07060
Epoch 46, Val Loss: 2.06426
Epoch 47, Val Loss: 2.06525
Epoch 48, Val Loss: 2.07063
Epoch 49, Val Loss: 2.06804
Epoch 50, Val Loss: 2.07025
Epoch 51, Val Loss: 2.06642
Epoch 52, Val Loss: 2.05413
Epoch 53, Val Loss: 2.05764
Epoch 54, Val Loss: 2.06932
Epoch 55, Val Loss: 2.07688
Epoch 56, Val Loss: 2.06806
Epoch 57, Val Loss: 2.08160
Epoch 58, Val Loss: 2.10017
Epoch 59, Val Loss: 2.09442
Epoch 60, Val Loss: 2.07089
Epoch 61, Val Loss: 2.06566
Epoch 62, Val Loss: 2.07320
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/VIME/Abalone/logging/loss_0.txt
File name : output/VIME/Abalone/logging/loss_0.txt . The file was saved
Log file exists at: output/VIME/Abalone/logging/val_loss_0.txt
File name : output/VIME/Abalone/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (836,)
Probabilities shape : (836, 9) 

After Evaluation
{'Log Loss - mean': 4.211, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3341, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597]] 
 
 
Val : (3341, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1.0 0.0 0.0 0.051808811977212994 0.1209546838869621
  -0.10725663378676703 -0.30947434175323335 -0.463709340293154
  -0.35856347602228766 -0.20891180319651964]
 [0.0 0.0 1.0 -0.6975125768360658 -0.43337947093655044
  -0.34231364492588795 -0.6402458656513711 -0.6493256004118436
  -0.6110682244346455 -0.6037444215028267]
 [0.0 1.0 0.0 -1.613349829830073 -1.5420477805835755 -1.400070195051931
  -1.2791896167837988 -1.2197560583375726 -1.2951265428608514
  -1.3216219093324761]
 [0.0 1.0 0.0 -0.8223994749716125 -1.0885016539097927 -1.04748467834325
  -0.9782080748516424 -0.9866039267250722 -0.9462108905092297
  -0.855001542243204]
 [1.0 0.0 0.0 0.051808811977212994 0.07056066981209727
  0.24532888292191368 -0.1029989495062593 -0.5519902444959455
  -0.35856347602228766 0.6525411821990598]
 [1.0 0.0 0.0 0.17669571011275956 0.17134869796182692
  -0.34231364492588795 -0.12251652389776423 -0.29393837067240147
  -0.28510754921141984 0.15002694071830516]
 [0.0 0.0 1.0 -0.40610981451979106 -0.3829854568616856
  -0.34231364492588795 -0.6535999954981905 -0.6447983745552902
  -0.6248412107116832 -0.5319566727198618]
 [1.0 0.0 0.0 0.21832467615794174 0.3225307401864214 0.24532888292191368
  0.13737538773648675 -0.20113024061305662 -0.27133456293438213
  0.5807534334160948]
 [0.0 0.0 1.0 -0.7807705089264303 -0.5845615131611449 -0.694899161634569
  -0.8662388322898503 -0.866632441526407 -0.914073922529475
  -0.7473199190687565]
 [0.0 0.0 1.0 -0.2812229163842445 -0.28219742871195597
  -0.10725663378676703 -0.587856587021542 -0.6402711486987368
  -0.7855260506104564 -0.35248730076244944]] 
 
 
Val : (3341, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 1.95954
Epoch 1, Val Loss: 1.94742
Epoch 2, Val Loss: 1.95711
Epoch 3, Val Loss: 1.93985
Epoch 4, Val Loss: 1.93646
Epoch 5, Val Loss: 1.92516
Epoch 6, Val Loss: 1.95076
Epoch 7, Val Loss: 1.91800
Epoch 8, Val Loss: 1.90937
Epoch 9, Val Loss: 1.92505
Epoch 10, Val Loss: 1.90636
Epoch 11, Val Loss: 1.90537
Epoch 12, Val Loss: 1.93833
Epoch 13, Val Loss: 1.91988
Epoch 14, Val Loss: 1.93332
Epoch 15, Val Loss: 2.02822
Epoch 16, Val Loss: 1.96590
Epoch 17, Val Loss: 1.92096
Epoch 18, Val Loss: 1.90405
Epoch 19, Val Loss: 1.90715
Epoch 20, Val Loss: 1.94982
Epoch 21, Val Loss: 1.91271
Epoch 22, Val Loss: 1.91724
Epoch 23, Val Loss: 1.90652
Epoch 24, Val Loss: 1.90461
Epoch 25, Val Loss: 1.91636
Epoch 26, Val Loss: 1.91332
Epoch 27, Val Loss: 1.92333
Epoch 28, Val Loss: 1.90432
Epoch 29, Val Loss: 1.90906
Epoch 30, Val Loss: 1.90856
Epoch 31, Val Loss: 1.89851
Epoch 32, Val Loss: 1.92765
Epoch 33, Val Loss: 1.91216
Epoch 34, Val Loss: 1.90690
Epoch 35, Val Loss: 1.93672
Epoch 36, Val Loss: 1.90331
Epoch 37, Val Loss: 1.90249
Epoch 38, Val Loss: 1.90990
Epoch 39, Val Loss: 1.92814
Epoch 40, Val Loss: 1.91989
Epoch 41, Val Loss: 1.90645
Epoch 42, Val Loss: 1.89774
Epoch 43, Val Loss: 1.90555
Epoch 44, Val Loss: 1.90142
Epoch 45, Val Loss: 1.89588
Epoch 46, Val Loss: 1.90030
Epoch 47, Val Loss: 1.91790
Epoch 48, Val Loss: 1.92100
Epoch 49, Val Loss: 1.90605
Epoch 50, Val Loss: 1.91000
Epoch 51, Val Loss: 1.94252
Epoch 52, Val Loss: 1.90520
Epoch 53, Val Loss: 1.90534
Epoch 54, Val Loss: 1.90634
Epoch 55, Val Loss: 1.89471
Epoch 56, Val Loss: 1.89318
Epoch 57, Val Loss: 1.92231
Epoch 58, Val Loss: 1.90561
Epoch 59, Val Loss: 1.92389
Epoch 60, Val Loss: 1.91620
Epoch 61, Val Loss: 1.91032
Epoch 62, Val Loss: 1.90152
Epoch 63, Val Loss: 1.91000
Epoch 64, Val Loss: 1.92922
Epoch 65, Val Loss: 1.89899
Epoch 66, Val Loss: 1.89971
Epoch 67, Val Loss: 1.91114
Epoch 68, Val Loss: 1.89906
Epoch 69, Val Loss: 1.93827
Epoch 70, Val Loss: 1.90095
Epoch 71, Val Loss: 1.89832
Epoch 72, Val Loss: 1.89285
Epoch 73, Val Loss: 1.90650
Epoch 74, Val Loss: 1.90061
Epoch 75, Val Loss: 1.93366
Epoch 76, Val Loss: 1.89957
Epoch 77, Val Loss: 1.90371
Epoch 78, Val Loss: 1.90488
Epoch 79, Val Loss: 1.89915
Epoch 80, Val Loss: 1.90294
Epoch 81, Val Loss: 1.89408
Epoch 82, Val Loss: 1.90393
Epoch 83, Val Loss: 1.89207
Epoch 84, Val Loss: 1.90956
Epoch 85, Val Loss: 1.90418
Epoch 86, Val Loss: 1.90713
Epoch 87, Val Loss: 1.92953
Epoch 88, Val Loss: 1.90864
Epoch 89, Val Loss: 1.90124
Epoch 90, Val Loss: 1.96011
Epoch 91, Val Loss: 1.92389
Epoch 92, Val Loss: 1.90389
Epoch 93, Val Loss: 1.90554
Epoch 94, Val Loss: 1.89309
Epoch 95, Val Loss: 1.91797
Epoch 96, Val Loss: 1.89173
Epoch 97, Val Loss: 1.91901
Epoch 98, Val Loss: 1.90083
Epoch 99, Val Loss: 1.89367
State of save is True b4 loss saving
Log file exists at: output/VIME/Abalone/logging/loss_1.txt
File name : output/VIME/Abalone/logging/loss_1.txt . The file was saved
Log file exists at: output/VIME/Abalone/logging/val_loss_1.txt
File name : output/VIME/Abalone/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (836,)
Probabilities shape : (836, 8) 

After Evaluation
{'Log Loss - mean': 4.27985, 'Log Loss - std': 0.06884999999999986} 
 

Fold 3
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5698320158539575 -0.4271699725795722 -1.0389280503395208
  -0.6347153561730201 -0.6005026730450418 -0.7223571148557317
  -0.6306854501095174]
 [0.0 0.0 1.0 -1.4435910400327316 -1.4336221198959578 -1.156125699169423
  -1.2182459667920271 -1.160980331721523 -1.1969622573764345
  -1.2017803823001665]
 [1.0 0.0 0.0 0.05428157284516671 0.12637870844443994
  -0.10134685970030412 -0.3050256177643609 -0.4570203924238625
  -0.3562331477683324 -0.2023642509665306]
 [0.0 0.0 1.0 -0.6946547335937824 -0.4271699725795722 -0.3357421573601085
  -0.6306700833091101 -0.6408570644697484 -0.6048358414696529
  -0.5949920168476018]
 [1.0 0.0 0.0 0.05428157284516671 0.07605610107862061 0.25024608678940174
  -0.10175065635288713 -0.5444549071773936 -0.3562331477683324
  0.6542781473194431]
 [0.0 0.0 1.0 -0.4034017255341914 -0.37684736521375284
  -0.3357421573601085 -0.6438172201168175 -0.6363732432003366
  -0.6183959883988158 -0.5236051503237706]
 [1.0 0.0 0.0 0.22071186316493327 0.3276691379077173 0.25024608678940174
  0.13489780618584366 -0.19695875879797511 -0.27035221721696706
  0.5828912807956119]
 [1.0 0.0 0.0 0.012674000265225062 -0.27620215048211416
  0.015850789129598055 -0.44762148621718584 -0.7372592217621032
  -0.3019925600516806 -0.2023642509665306]
 [0.0 0.0 1.0 -0.7778698787536658 -0.5781377946770302 -0.6873351038498147
  -0.8531600908241561 -0.8560804854015173 -0.9031590739112376
  -0.737765749895264]
 [0.0 0.0 1.0 -0.27857900779436645 -0.27620215048211416
  -0.10134685970030412 -0.5790928542942586 -0.6318894219309248
  -0.7765977025723835 -0.3451379840141928]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), 9)
MAX : 8 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Test after shift : [0 1 2 3 4 5 6 7 8], Length : 9
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.13709
Epoch 1, Val Loss: 2.13927
Epoch 2, Val Loss: 2.12466
Epoch 3, Val Loss: 2.09362
Epoch 4, Val Loss: 2.07907
Epoch 5, Val Loss: 2.07558
Epoch 6, Val Loss: 2.07756
Epoch 7, Val Loss: 2.11951
Epoch 8, Val Loss: 2.10484
Epoch 9, Val Loss: 2.07712
Epoch 10, Val Loss: 2.08890
Epoch 11, Val Loss: 2.09408
Epoch 12, Val Loss: 2.08343
Epoch 13, Val Loss: 2.06963
Epoch 14, Val Loss: 2.07093
Epoch 15, Val Loss: 2.07445
Epoch 16, Val Loss: 2.05812
Epoch 17, Val Loss: 2.07100
Epoch 18, Val Loss: 2.09228
Epoch 19, Val Loss: 2.08441
Epoch 20, Val Loss: 2.08946
Epoch 21, Val Loss: 2.07393
Epoch 22, Val Loss: 2.08455
Epoch 23, Val Loss: 2.08082
Epoch 24, Val Loss: 2.05802
Epoch 25, Val Loss: 2.07744
Epoch 26, Val Loss: 2.07638
Epoch 27, Val Loss: 2.06943
Epoch 28, Val Loss: 2.07168
Epoch 29, Val Loss: 2.09139
Epoch 30, Val Loss: 2.07394
Epoch 31, Val Loss: 2.05907
Epoch 32, Val Loss: 2.06757
Epoch 33, Val Loss: 2.07519
Epoch 34, Val Loss: 2.07683
Epoch 35, Val Loss: 2.06098
Epoch 36, Val Loss: 2.05809
Epoch 37, Val Loss: 2.06256
Epoch 38, Val Loss: 2.06192
Epoch 39, Val Loss: 2.07633
Epoch 40, Val Loss: 2.06146
Epoch 41, Val Loss: 2.08458
Epoch 42, Val Loss: 2.07064
Epoch 43, Val Loss: 2.07767
Epoch 44, Val Loss: 2.05995
Epoch 45, Val Loss: 2.07365
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/VIME/Abalone/logging/loss_2.txt
File name : output/VIME/Abalone/logging/loss_2.txt . The file was saved
Log file exists at: output/VIME/Abalone/logging/val_loss_2.txt
File name : output/VIME/Abalone/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 4 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.335633333333333, 'Log Loss - std': 0.09686988982937629} 
 

Fold 4
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5690315405613264 -0.42535969270024443
  -1.0500768981385924 -0.6384214848190454 -0.6042936766305018
  -0.7195875197860123 -0.6349568100929689]
 [0.0 0.0 1.0 -1.4392625570934354 -1.4277233177208453 -1.167955269492567
  -1.225152073368887 -1.1667739623949986 -1.1982585500483505
  -1.2058724559266103]
 [1.0 0.0 0.0 0.05256204267589417 0.12594030106108614
  -0.10704992730679613 -0.30692378660890945 -0.4602987234747907
  -0.35032701072649475 -0.20677007571773787]
 [0.0 1.0 0.0 -1.605020845956694 -1.5279596802229054 -1.403712012200516
  -1.266843501671389 -1.2117723852561584 -1.2803164409504653
  -1.312919139520418]
 [0.0 1.0 0.0 -0.8176689738562148 -1.0768960489636352 -1.0500768981385924
  -0.9689023189242423 -0.9800305075211857 -0.9338497904748684
  -0.8490501772805844]
 [1.0 0.0 0.0 0.05256204267589417 0.07582211981005604 0.24658518675512706
  -0.10253410151615713 -0.5480456480540523 -0.35032701072649475
  0.6496033930327244]
 [1.0 0.0 0.0 0.17688075932333838 0.17605848231211624
  -0.34280667001474535 -0.1218545195099993 -0.2915546377454418
  -0.277386663257948 0.1500522029282881]
 [1.0 0.0 0.0 0.21832033153915312 0.32641302606520656 0.24658518675512706
  0.13541209903958457 -0.1993078708800643 -0.2637103481075954
  0.5782389373035192]
 [1.0 0.0 0.0 0.011122470460079437 -0.2750051489471541
  0.010828444047178483 -0.45030162540531793 -0.741538866357039
  -0.2956217501250846 -0.20677007571773787]
 [0.0 0.0 1.0 -0.7762294016404001 -0.5757142364533347 -0.6964417840766689
  -0.8580641314858839 -0.8607846869391123 -0.9019383884573792
  -0.7420034936867765]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
Unique values in y_test: (array([0., 1., 2., 3., 4., 6., 7., 8., 9.]), 9)
MAX : 9 , Max diff : 1, LEN : 9 , BINS : 10
WE ARE HERE
IN THE SHIIIIIT
Length orig Train: 3342, Length shift : 3342
Length orig Test: 835, Length shift : 835
Warning: Length mismatch in y_train_shift!
Warning: Length mismatch in y_test_shift!
Bin alt after shift : [0, 1, 2, 3, 5, 6, 7, 8] 

Train after shift I : [0 1 2 3 5 6 7 8],  Length : 8
Test after shift I : [0 1 2 3 5 6 7 8], Length : 8 

VERIFY SHIFT
Train after shift : [0 1 2 3 5 6 7 8], Length : 8
Test after shift : [0 1 2 3 5 6 7 8], Length : 8
Number of Classes After Bin Verifier: 9
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 2.06814
Epoch 1, Val Loss: 2.08917
Epoch 2, Val Loss: 2.12275
Epoch 3, Val Loss: 2.11654
Epoch 4, Val Loss: 2.06119
Epoch 5, Val Loss: 2.05514
Epoch 6, Val Loss: 2.09775
Epoch 7, Val Loss: 2.08560
Epoch 8, Val Loss: 2.08072
Epoch 9, Val Loss: 2.12960
Epoch 10, Val Loss: 2.05425
Epoch 11, Val Loss: 2.04415
Epoch 12, Val Loss: 2.05881
Epoch 13, Val Loss: 2.05024
Epoch 14, Val Loss: 2.03538
Epoch 15, Val Loss: 2.03165
Epoch 16, Val Loss: 2.02090
Epoch 17, Val Loss: 2.00530
Epoch 18, Val Loss: 2.06424
Epoch 19, Val Loss: 2.04611
Epoch 20, Val Loss: 2.02703
Epoch 21, Val Loss: 2.05287
Epoch 22, Val Loss: 2.05159
Epoch 23, Val Loss: 2.01867
Epoch 24, Val Loss: 2.04617
Epoch 25, Val Loss: 2.02568
Epoch 26, Val Loss: 2.01550
Epoch 27, Val Loss: 2.02441
Epoch 28, Val Loss: 2.02815
Epoch 29, Val Loss: 2.03078
Epoch 30, Val Loss: 2.02375
Epoch 31, Val Loss: 2.06753
Epoch 32, Val Loss: 2.03357
Epoch 33, Val Loss: 2.01720
Epoch 34, Val Loss: 2.02878
Epoch 35, Val Loss: 2.03887
Epoch 36, Val Loss: 2.01968
Epoch 37, Val Loss: 2.01567
Epoch 38, Val Loss: 2.06583
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/VIME/Abalone/logging/loss_3.txt
File name : output/VIME/Abalone/logging/loss_3.txt . The file was saved
Log file exists at: output/VIME/Abalone/logging/val_loss_3.txt
File name : output/VIME/Abalone/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
B4 Evaluation
Number of classes : 9
Unique y_true : [0 1 2 3 5 6 7 8] 

Prediction shape : (835,)
Probabilities shape : (835, 9) 

After Evaluation
{'Log Loss - mean': 4.14385, 'Log Loss - std': 0.34260819094119743} 
 

Fold 5
num_features : 8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :8
num_classes : 1
cat_idx : [0]
nominal_idx : [0]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (3342, 8)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [1, 2, 3, 4, 5, 6, 7]
Cat Dims V1 : []
Cat Idx V1 : [0] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044]] 
 
 
Val : (3342, 10) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [1, 2, 3, 4, 5, 6, 7] 


OHE Idx : [0, 1, 2]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 1.0 -0.5902805359689328 -0.4481428509674965 -1.0550394761935622
  -0.652531118203336 -0.6203614871572382 -0.7346462314941438
  -0.6481967718014128]
 [0.0 0.0 1.0 -1.4674337379289928 -1.4602346254866023 -1.172782811845699
  -1.2399035204261921 -1.1817207861619912 -1.2109175474628806
  -1.2256252900914224]
 [1.0 0.0 0.0 0.036257465431109887 0.10850762501801176
  -0.11309279097646885 -0.32067080082959054 -0.4766535066120213
  -0.3672369306039755 -0.21512538308390547]
 [0.0 0.0 1.0 -0.7155881362489415 -0.4481428509674965 -0.3485794622807424
  -0.6484592124686889 -0.6607793566855803 -0.6167123818256947
  -0.6121074894082871]
 [0.0 1.0 0.0 -1.634510538302337 -1.561443802938513 -1.4082694831499722
  -1.2816405542063258 -1.2266295300823715 -1.292564058771807
  -1.3338931372707994]
 [0.0 1.0 0.0 -0.8408957365289501 -1.1060025044049155 -1.0550394761935622
  -0.9833734591434197 -0.9953494988924132 -0.9478343443563404
  -0.8647324661601664]
 [1.0 0.0 0.0 0.1615650657111185 0.15911221374396708 -0.3485794622807424
  -0.13539908990314378 -0.30824571691059555 -0.29466225388492984
  0.14576744084735074]
 [0.0 0.0 1.0 -0.42320373559558844 -0.39753826224154115
  -0.3485794622807424 -0.6616929061062923 -0.6562884822935423
  -0.6303201337105158 -0.5399289246220358]
 [1.0 0.0 0.0 0.20333426580445474 0.31092597992183313 0.24013721597994078
  0.12214894781329044 -0.21618279187381598 -0.28105450200010873
  0.578838829564858]
 [1.0 0.0 0.0 -0.0055117346622263206 -0.29632908478963044
  0.0046505446756679135 -0.4642054779759037 -0.7573331561143978
  -0.31280592306469124 -0.21512538308390547]] 
 
 
Val : (3342, 10) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
num_features :10
num_classes : 1
cat_idx : None
nominal_idx : [0, 1, 2]
ordinal_idx : None
num_idx : [3, 4, 5, 6, 7, 8, 9]
cat_dims : []
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Number of Classes B4 Bin Verifier: 10
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
MAX : 7 , Max diff : 1, LEN : 8 , BINS : 10
WE ARE HERE
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
On Device: cuda
{'p_m': 0.7192123464423629, 'alpha': 1.1041260180067325, 'K': 2, 'beta': 0.18806809637682864}
Fitted encoder
Epoch 0, Val Loss: 1.95259
Epoch 1, Val Loss: 1.95168
Epoch 2, Val Loss: 1.96290
Epoch 3, Val Loss: 1.93221
Epoch 4, Val Loss: 1.91556
Epoch 5, Val Loss: 1.88436
Epoch 6, Val Loss: 1.90725
Epoch 7, Val Loss: 1.89759
Epoch 8, Val Loss: 1.88255
Epoch 9, Val Loss: 1.95843
Epoch 10, Val Loss: 1.91670
Epoch 11, Val Loss: 1.89322
Epoch 12, Val Loss: 1.92936
Epoch 13, Val Loss: 1.89788
Epoch 14, Val Loss: 1.89618
Epoch 15, Val Loss: 1.91401
Epoch 16, Val Loss: 1.88254
Epoch 17, Val Loss: 1.88003
Epoch 18, Val Loss: 1.88643
Epoch 19, Val Loss: 1.91158
Epoch 20, Val Loss: 1.88557
Epoch 21, Val Loss: 1.89118
Epoch 22, Val Loss: 1.89147
Epoch 23, Val Loss: 1.93909
Epoch 24, Val Loss: 1.90790
Epoch 25, Val Loss: 1.89221
Epoch 26, Val Loss: 1.88061
Epoch 27, Val Loss: 1.91855
Epoch 28, Val Loss: 1.89471
Epoch 29, Val Loss: 1.88342
Epoch 30, Val Loss: 1.90795
Epoch 31, Val Loss: 1.88456
Epoch 32, Val Loss: 1.89042
Epoch 33, Val Loss: 1.90396
Epoch 34, Val Loss: 1.90306
Epoch 35, Val Loss: 1.92656
Epoch 36, Val Loss: 1.87596
Epoch 37, Val Loss: 1.88116
Epoch 38, Val Loss: 1.88682
Epoch 39, Val Loss: 1.88736
Epoch 40, Val Loss: 1.88312
Epoch 41, Val Loss: 1.90085
Epoch 42, Val Loss: 1.89627
Epoch 43, Val Loss: 1.89571
Epoch 44, Val Loss: 1.90547
Epoch 45, Val Loss: 1.88731
Epoch 46, Val Loss: 1.88514
Epoch 47, Val Loss: 1.87730
Epoch 48, Val Loss: 1.88015
Epoch 49, Val Loss: 1.88848
Epoch 50, Val Loss: 1.87221
Epoch 51, Val Loss: 1.89519
Epoch 52, Val Loss: 1.88583
Epoch 53, Val Loss: 1.87708
Epoch 54, Val Loss: 1.89931
Epoch 55, Val Loss: 1.87202
Epoch 56, Val Loss: 1.87573
Epoch 57, Val Loss: 1.93385
Epoch 58, Val Loss: 1.88617
Epoch 59, Val Loss: 1.89631
Epoch 60, Val Loss: 1.87397
Epoch 61, Val Loss: 1.91689
Epoch 62, Val Loss: 1.88093
Epoch 63, Val Loss: 1.87178
Epoch 64, Val Loss: 1.89523
Epoch 65, Val Loss: 1.86528
Epoch 66, Val Loss: 1.88501
Epoch 67, Val Loss: 1.90340
Epoch 68, Val Loss: 1.91609
Epoch 69, Val Loss: 1.90646
Epoch 70, Val Loss: 1.92102
Epoch 71, Val Loss: 1.88434
Epoch 72, Val Loss: 1.89188
Epoch 73, Val Loss: 1.89994
Epoch 74, Val Loss: 1.88710
Epoch 75, Val Loss: 1.87216
Epoch 76, Val Loss: 1.87019
Epoch 77, Val Loss: 1.87837
Epoch 78, Val Loss: 1.87830
Epoch 79, Val Loss: 1.86568
Epoch 80, Val Loss: 1.87006
Epoch 81, Val Loss: 1.98679
Epoch 82, Val Loss: 1.99695
Epoch 83, Val Loss: 2.00258
Epoch 84, Val Loss: 1.86880
Epoch 85, Val Loss: 1.88326
Epoch 86, Val Loss: 1.87511
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/VIME/Abalone/logging/loss_4.txt
File name : output/VIME/Abalone/logging/loss_4.txt . The file was saved
Log file exists at: output/VIME/Abalone/logging/val_loss_4.txt
File name : output/VIME/Abalone/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
B4 Evaluation
Number of classes : 8
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (835,)
Probabilities shape : (835, 8) 

After Evaluation
{'Log Loss - mean': 3.9981199999999992, 'Log Loss - std': 0.42291042739568385} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 3.9981199999999992, 'Log Loss - std': 0.42291042739568385}
Train time: 33.67729517679982
Inference time: 0.04822168399987277
Finished cross validation
Loss path :output/VIME/Abalone/logging/
Plots saved successfully!
