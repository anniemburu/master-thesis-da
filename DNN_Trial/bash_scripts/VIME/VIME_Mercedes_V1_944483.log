 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/mercedes_benz.yml', data_parallel=False, dataset='Mercedes_Benz', direction='minimize', dropna_idx=[0], early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='VIME', n_trials=100, nominal_idx=[1, 2, 3, 4, 5, 6, 7, 8], num_classes=1, num_features=377, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Mercedes_Benz...
Dataset loaded! 

X b4 encoding : ['k' 'v' 'at' 'a' 'd' 'u' 'j' 'o' 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0
 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0
 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0
 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0] 

(4209, 376)
Data Type of X: <class 'numpy.ndarray'>
Nominal Idx: [0, 1, 2, 3, 4, 5, 6, 7]
Ordinal Idx: None
Cat Dims: None 
 

Normonal Idx: [0, 1, 2, 3, 4, 5, 6, 7]
Cat Idx Part II: [0, 1, 2, 3, 4, 5, 6, 7] 
ENDE 
 

Scaling the data...
One Hot Encoding...
args.num_features: 563
args.cat_idx: None
New Shape: (4209, 563)
Using an existing study with name 'VIME_Mercedes_Benz' instead of creating a new one.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1111.90430
Epoch 1, Val Loss: 475.22812
Epoch 2, Val Loss: 218.78311
Epoch 3, Val Loss: 170.20122
Epoch 4, Val Loss: 182.65265
Epoch 5, Val Loss: 156.91467
Epoch 6, Val Loss: 153.72275
Epoch 7, Val Loss: 123.88205
Epoch 8, Val Loss: 140.42802
Epoch 9, Val Loss: 127.57412
Epoch 10, Val Loss: 118.07228
Epoch 11, Val Loss: 113.10826
Epoch 12, Val Loss: 125.07883
Epoch 13, Val Loss: 108.52636
Epoch 14, Val Loss: 116.80860
Epoch 15, Val Loss: 103.93239
Epoch 16, Val Loss: 111.93045
Epoch 17, Val Loss: 114.03068
Epoch 18, Val Loss: 115.06450
Epoch 19, Val Loss: 110.68829
Epoch 20, Val Loss: 112.19942
Epoch 21, Val Loss: 108.79478
Epoch 22, Val Loss: 118.18530
Epoch 23, Val Loss: 113.66415
Epoch 24, Val Loss: 104.78454
Epoch 25, Val Loss: 105.41991
Epoch 26, Val Loss: 104.15307
Epoch 27, Val Loss: 107.15181
Epoch 28, Val Loss: 100.89402
Epoch 29, Val Loss: 105.55127
Epoch 30, Val Loss: 110.76952
Epoch 31, Val Loss: 98.69279
Epoch 32, Val Loss: 107.08035
Epoch 33, Val Loss: 95.27908
Epoch 34, Val Loss: 94.86938
Epoch 35, Val Loss: 103.03296
Epoch 36, Val Loss: 97.35727
Epoch 37, Val Loss: 99.05161
Epoch 38, Val Loss: 94.80795
Epoch 39, Val Loss: 92.76291
Epoch 40, Val Loss: 98.40775
Epoch 41, Val Loss: 95.26490
Epoch 42, Val Loss: 95.74465
Epoch 43, Val Loss: 100.79115
Epoch 44, Val Loss: 95.22702
Epoch 45, Val Loss: 89.30185
Epoch 46, Val Loss: 91.70837
Epoch 47, Val Loss: 91.89896
Epoch 48, Val Loss: 91.68443
Epoch 49, Val Loss: 92.98800
Epoch 50, Val Loss: 91.63969
Epoch 51, Val Loss: 91.30323
Epoch 52, Val Loss: 93.71320
Epoch 53, Val Loss: 116.43304
Epoch 54, Val Loss: 89.64190
Epoch 55, Val Loss: 90.43902
Epoch 56, Val Loss: 89.27230
Epoch 57, Val Loss: 89.34315
Epoch 58, Val Loss: 89.79850
Epoch 59, Val Loss: 87.96917
Epoch 60, Val Loss: 87.10754
Epoch 61, Val Loss: 99.53742
Epoch 62, Val Loss: 95.03838
Epoch 63, Val Loss: 90.73212
Epoch 64, Val Loss: 93.68048
Epoch 65, Val Loss: 92.82448
Epoch 66, Val Loss: 88.31702
Epoch 67, Val Loss: 85.84476
Epoch 68, Val Loss: 94.12161
Epoch 69, Val Loss: 86.23709
Epoch 70, Val Loss: 86.03590
Epoch 71, Val Loss: 90.53296
Epoch 72, Val Loss: 95.20821
Epoch 73, Val Loss: 83.99474
Epoch 74, Val Loss: 86.77223
Epoch 75, Val Loss: 89.82504
Epoch 76, Val Loss: 91.32643
Epoch 77, Val Loss: 91.66559
Epoch 78, Val Loss: 91.13621
Epoch 79, Val Loss: 85.13917
Epoch 80, Val Loss: 84.76006
Epoch 81, Val Loss: 86.39893
Epoch 82, Val Loss: 89.50319
Epoch 83, Val Loss: 111.14394
Epoch 84, Val Loss: 92.34817
Epoch 85, Val Loss: 87.10650
Epoch 86, Val Loss: 86.32338
Epoch 87, Val Loss: 90.76671
Epoch 88, Val Loss: 85.89281
Epoch 89, Val Loss: 88.19685
Epoch 90, Val Loss: 86.97037
Epoch 91, Val Loss: 91.87628
Epoch 92, Val Loss: 86.12653
Epoch 93, Val Loss: 86.33803
Epoch 94, Val Loss: 86.56863
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.20265713850365, 'MSE - std': 0.0, 'R2 - mean': 0.4918411074813378, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 996.74481
Epoch 1, Val Loss: 367.44888
Epoch 2, Val Loss: 146.40439
Epoch 3, Val Loss: 140.77403
Epoch 4, Val Loss: 130.94444
Epoch 5, Val Loss: 114.67707
Epoch 6, Val Loss: 102.32770
Epoch 7, Val Loss: 104.83511
Epoch 8, Val Loss: 100.75769
Epoch 9, Val Loss: 105.30197
Epoch 10, Val Loss: 94.99378
Epoch 11, Val Loss: 91.08733
Epoch 12, Val Loss: 100.13462
Epoch 13, Val Loss: 83.92223
Epoch 14, Val Loss: 94.17794
Epoch 15, Val Loss: 88.99065
Epoch 16, Val Loss: 91.50829
Epoch 17, Val Loss: 88.82776
Epoch 18, Val Loss: 90.54370
Epoch 19, Val Loss: 100.32217
Epoch 20, Val Loss: 89.19624
Epoch 21, Val Loss: 86.73759
Epoch 22, Val Loss: 89.29405
Epoch 23, Val Loss: 85.72344
Epoch 24, Val Loss: 89.81139
Epoch 25, Val Loss: 83.78710
Epoch 26, Val Loss: 80.76647
Epoch 27, Val Loss: 79.57272
Epoch 28, Val Loss: 76.93086
Epoch 29, Val Loss: 79.98941
Epoch 30, Val Loss: 82.47929
Epoch 31, Val Loss: 80.79144
Epoch 32, Val Loss: 74.66281
Epoch 33, Val Loss: 79.89274
Epoch 34, Val Loss: 77.12998
Epoch 35, Val Loss: 75.28316
Epoch 36, Val Loss: 76.57835
Epoch 37, Val Loss: 89.54973
Epoch 38, Val Loss: 84.50595
Epoch 39, Val Loss: 78.98225
Epoch 40, Val Loss: 72.02055
Epoch 41, Val Loss: 74.26282
Epoch 42, Val Loss: 79.91399
Epoch 43, Val Loss: 75.25130
Epoch 44, Val Loss: 75.00568
Epoch 45, Val Loss: 89.43633
Epoch 46, Val Loss: 79.59401
Epoch 47, Val Loss: 74.69901
Epoch 48, Val Loss: 77.50374
Epoch 49, Val Loss: 72.34326
Epoch 50, Val Loss: 77.18681
Epoch 51, Val Loss: 72.94780
Epoch 52, Val Loss: 76.68508
Epoch 53, Val Loss: 76.00536
Epoch 54, Val Loss: 70.83118
Epoch 55, Val Loss: 80.63163
Epoch 56, Val Loss: 74.92051
Epoch 57, Val Loss: 87.07675
Epoch 58, Val Loss: 80.62802
Epoch 59, Val Loss: 70.72032
Epoch 60, Val Loss: 87.41874
Epoch 61, Val Loss: 71.54879
Epoch 62, Val Loss: 78.96871
Epoch 63, Val Loss: 77.48005
Epoch 64, Val Loss: 72.10226
Epoch 65, Val Loss: 76.54758
Epoch 66, Val Loss: 72.52361
Epoch 67, Val Loss: 77.27032
Epoch 68, Val Loss: 69.87834
Epoch 69, Val Loss: 81.00359
Epoch 70, Val Loss: 73.01244
Epoch 71, Val Loss: 71.70040
Epoch 72, Val Loss: 82.34364
Epoch 73, Val Loss: 72.96340
Epoch 74, Val Loss: 73.82616
Epoch 75, Val Loss: 78.97033
Epoch 76, Val Loss: 74.90762
Epoch 77, Val Loss: 71.72456
Epoch 78, Val Loss: 74.20398
Epoch 79, Val Loss: 69.89395
Epoch 80, Val Loss: 72.07216
Epoch 81, Val Loss: 82.15797
Epoch 82, Val Loss: 83.22335
Epoch 83, Val Loss: 69.31219
Epoch 84, Val Loss: 71.47241
Epoch 85, Val Loss: 72.39950
Epoch 86, Val Loss: 74.65575
Epoch 87, Val Loss: 77.61835
Epoch 88, Val Loss: 74.97333
Epoch 89, Val Loss: 68.15958
Epoch 90, Val Loss: 74.64513
Epoch 91, Val Loss: 81.36901
Epoch 92, Val Loss: 75.37022
Epoch 93, Val Loss: 90.75640
Epoch 94, Val Loss: 80.18307
Epoch 95, Val Loss: 71.22017
Epoch 96, Val Loss: 68.49342
Epoch 97, Val Loss: 71.43578
Epoch 98, Val Loss: 83.92867
Epoch 99, Val Loss: 73.13899
DID NOT SAVE RESULTS
{'MSE - mean': 80.82381486879187, 'MSE - std': 6.378842269711782, 'R2 - mean': 0.5084418140261291, 'R2 - std': 0.01660070654479129} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1031.35303
Epoch 1, Val Loss: 397.03076
Epoch 2, Val Loss: 159.01248
Epoch 3, Val Loss: 140.68695
Epoch 4, Val Loss: 114.87032
Epoch 5, Val Loss: 125.66293
Epoch 6, Val Loss: 91.44810
Epoch 7, Val Loss: 91.44461
Epoch 8, Val Loss: 89.51796
Epoch 9, Val Loss: 86.75116
Epoch 10, Val Loss: 80.49841
Epoch 11, Val Loss: 86.35045
Epoch 12, Val Loss: 79.95653
Epoch 13, Val Loss: 84.85976
Epoch 14, Val Loss: 79.35559
Epoch 15, Val Loss: 79.39882
Epoch 16, Val Loss: 88.60704
Epoch 17, Val Loss: 81.22640
Epoch 18, Val Loss: 80.01003
Epoch 19, Val Loss: 80.10164
Epoch 20, Val Loss: 84.00916
Epoch 21, Val Loss: 81.12740
Epoch 22, Val Loss: 78.17693
Epoch 23, Val Loss: 86.97722
Epoch 24, Val Loss: 79.35857
Epoch 25, Val Loss: 73.94772
Epoch 26, Val Loss: 93.42140
Epoch 27, Val Loss: 79.99657
Epoch 28, Val Loss: 77.44996
Epoch 29, Val Loss: 86.90576
Epoch 30, Val Loss: 78.19724
Epoch 31, Val Loss: 77.34021
Epoch 32, Val Loss: 75.31906
Epoch 33, Val Loss: 80.29727
Epoch 34, Val Loss: 82.23032
Epoch 35, Val Loss: 75.01111
Epoch 36, Val Loss: 77.06380
Epoch 37, Val Loss: 72.60834
Epoch 38, Val Loss: 80.66980
Epoch 39, Val Loss: 81.04562
Epoch 40, Val Loss: 76.22593
Epoch 41, Val Loss: 79.82324
Epoch 42, Val Loss: 72.28365
Epoch 43, Val Loss: 73.78883
Epoch 44, Val Loss: 71.50470
Epoch 45, Val Loss: 71.53986
Epoch 46, Val Loss: 72.36513
Epoch 47, Val Loss: 80.38436
Epoch 48, Val Loss: 72.41633
Epoch 49, Val Loss: 86.31076
Epoch 50, Val Loss: 69.63566
Epoch 51, Val Loss: 74.63123
Epoch 52, Val Loss: 68.28941
Epoch 53, Val Loss: 90.99895
Epoch 54, Val Loss: 74.72404
Epoch 55, Val Loss: 74.44895
Epoch 56, Val Loss: 71.44443
Epoch 57, Val Loss: 80.69820
Epoch 58, Val Loss: 71.39814
Epoch 59, Val Loss: 70.20627
Epoch 60, Val Loss: 68.75146
Epoch 61, Val Loss: 72.54832
Epoch 62, Val Loss: 82.34609
Epoch 63, Val Loss: 70.08563
Epoch 64, Val Loss: 71.58781
Epoch 65, Val Loss: 69.10647
Epoch 66, Val Loss: 77.75403
Epoch 67, Val Loss: 73.15681
Epoch 68, Val Loss: 73.31884
Epoch 69, Val Loss: 68.25904
Epoch 70, Val Loss: 68.86494
Epoch 71, Val Loss: 67.32030
Epoch 72, Val Loss: 71.34984
Epoch 73, Val Loss: 71.79195
Epoch 74, Val Loss: 68.88419
Epoch 75, Val Loss: 70.79836
Epoch 76, Val Loss: 69.76772
Epoch 77, Val Loss: 66.63764
Epoch 78, Val Loss: 72.19926
Epoch 79, Val Loss: 67.88811
Epoch 80, Val Loss: 70.42973
Epoch 81, Val Loss: 71.07185
Epoch 82, Val Loss: 68.89402
Epoch 83, Val Loss: 72.58652
Epoch 84, Val Loss: 75.67369
Epoch 85, Val Loss: 69.88182
Epoch 86, Val Loss: 68.01605
Epoch 87, Val Loss: 69.22143
Epoch 88, Val Loss: 69.97550
Epoch 89, Val Loss: 69.69706
Epoch 90, Val Loss: 68.94728
Epoch 91, Val Loss: 69.34991
Epoch 92, Val Loss: 70.45551
Epoch 93, Val Loss: 71.79824
Epoch 94, Val Loss: 67.51491
Epoch 95, Val Loss: 69.31718
Epoch 96, Val Loss: 71.21590
Epoch 97, Val Loss: 71.02225
Epoch 98, Val Loss: 79.36478
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.3614946088898, 'MSE - std': 8.182360499173797, 'R2 - mean': 0.5212108560153463, 'R2 - std': 0.022579175623472995} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 454.58655
Epoch 1, Val Loss: 287.50580
Epoch 2, Val Loss: 195.42758
Epoch 3, Val Loss: 160.67422
Epoch 4, Val Loss: 136.10942
Epoch 5, Val Loss: 131.02820
Epoch 6, Val Loss: 107.74216
Epoch 7, Val Loss: 108.41607
Epoch 8, Val Loss: 107.26917
Epoch 9, Val Loss: 104.03766
Epoch 10, Val Loss: 95.17793
Epoch 11, Val Loss: 98.32718
Epoch 12, Val Loss: 104.27672
Epoch 13, Val Loss: 101.18402
Epoch 14, Val Loss: 100.09088
Epoch 15, Val Loss: 98.19810
Epoch 16, Val Loss: 94.50953
Epoch 17, Val Loss: 98.34376
Epoch 18, Val Loss: 97.92723
Epoch 19, Val Loss: 107.16393
Epoch 20, Val Loss: 118.92966
Epoch 21, Val Loss: 96.62848
Epoch 22, Val Loss: 91.48708
Epoch 23, Val Loss: 91.12817
Epoch 24, Val Loss: 91.25597
Epoch 25, Val Loss: 86.81985
Epoch 26, Val Loss: 88.89753
Epoch 27, Val Loss: 108.88993
Epoch 28, Val Loss: 89.34258
Epoch 29, Val Loss: 89.70671
Epoch 30, Val Loss: 83.73804
Epoch 31, Val Loss: 90.71538
Epoch 32, Val Loss: 94.40282
Epoch 33, Val Loss: 85.42921
Epoch 34, Val Loss: 91.64452
Epoch 35, Val Loss: 87.51810
Epoch 36, Val Loss: 93.97150
Epoch 37, Val Loss: 96.89598
Epoch 38, Val Loss: 84.41733
Epoch 39, Val Loss: 91.43730
Epoch 40, Val Loss: 86.44302
Epoch 41, Val Loss: 84.53944
Epoch 42, Val Loss: 83.93182
Epoch 43, Val Loss: 85.25217
Epoch 44, Val Loss: 85.98598
Epoch 45, Val Loss: 88.52733
Epoch 46, Val Loss: 99.04665
Epoch 47, Val Loss: 87.40746
Epoch 48, Val Loss: 86.32085
Epoch 49, Val Loss: 87.69080
Epoch 50, Val Loss: 84.63167
Epoch 51, Val Loss: 82.17310
Epoch 52, Val Loss: 93.17427
Epoch 53, Val Loss: 84.24223
Epoch 54, Val Loss: 89.16276
Epoch 55, Val Loss: 81.65238
Epoch 56, Val Loss: 82.87300
Epoch 57, Val Loss: 83.97704
Epoch 58, Val Loss: 82.50423
Epoch 59, Val Loss: 82.74285
Epoch 60, Val Loss: 88.02514
Epoch 61, Val Loss: 81.42303
Epoch 62, Val Loss: 82.61691
Epoch 63, Val Loss: 83.54498
Epoch 64, Val Loss: 82.38114
Epoch 65, Val Loss: 84.08167
Epoch 66, Val Loss: 81.61247
Epoch 67, Val Loss: 87.05322
Epoch 68, Val Loss: 85.63657
Epoch 69, Val Loss: 87.96290
Epoch 70, Val Loss: 82.17246
Epoch 71, Val Loss: 85.64151
Epoch 72, Val Loss: 83.76097
Epoch 73, Val Loss: 88.12299
Epoch 74, Val Loss: 85.74121
Epoch 75, Val Loss: 97.51071
Epoch 76, Val Loss: 85.37717
Epoch 77, Val Loss: 87.46368
Epoch 78, Val Loss: 86.77203
Epoch 79, Val Loss: 87.98971
Epoch 80, Val Loss: 81.49059
Epoch 81, Val Loss: 83.60712
Epoch 82, Val Loss: 83.46385
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.32078660757986, 'MSE - std': 9.861097651707098, 'R2 - mean': 0.5027787026991529, 'R2 - std': 0.03743791135322198} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1038.53613
Epoch 1, Val Loss: 448.53873
Epoch 2, Val Loss: 174.96138
Epoch 3, Val Loss: 154.49310
Epoch 4, Val Loss: 147.16324
Epoch 5, Val Loss: 133.71010
Epoch 6, Val Loss: 130.31281
Epoch 7, Val Loss: 127.47060
Epoch 8, Val Loss: 116.54594
Epoch 9, Val Loss: 108.86713
Epoch 10, Val Loss: 96.48248
Epoch 11, Val Loss: 101.86352
Epoch 12, Val Loss: 97.31109
Epoch 13, Val Loss: 93.38592
Epoch 14, Val Loss: 88.81021
Epoch 15, Val Loss: 108.68561
Epoch 16, Val Loss: 91.40582
Epoch 17, Val Loss: 109.51945
Epoch 18, Val Loss: 98.52559
Epoch 19, Val Loss: 95.38139
Epoch 20, Val Loss: 106.66474
Epoch 21, Val Loss: 96.20677
Epoch 22, Val Loss: 95.90913
Epoch 23, Val Loss: 96.33853
Epoch 24, Val Loss: 105.54327
Epoch 25, Val Loss: 102.76689
Epoch 26, Val Loss: 97.22379
Epoch 27, Val Loss: 96.06293
Epoch 28, Val Loss: 91.33617
Epoch 29, Val Loss: 87.02861
Epoch 30, Val Loss: 104.50565
Epoch 31, Val Loss: 92.07497
Epoch 32, Val Loss: 90.81875
Epoch 33, Val Loss: 95.19126
Epoch 34, Val Loss: 102.01296
Epoch 35, Val Loss: 92.20314
Epoch 36, Val Loss: 87.64243
Epoch 37, Val Loss: 85.77675
Epoch 38, Val Loss: 84.58080
Epoch 39, Val Loss: 86.64697
Epoch 40, Val Loss: 92.04124
Epoch 41, Val Loss: 87.99606
Epoch 42, Val Loss: 94.67563
Epoch 43, Val Loss: 87.21090
Epoch 44, Val Loss: 89.92395
Epoch 45, Val Loss: 80.85100
Epoch 46, Val Loss: 87.47248
Epoch 47, Val Loss: 85.55932
Epoch 48, Val Loss: 79.03073
Epoch 49, Val Loss: 95.38981
Epoch 50, Val Loss: 84.97944
Epoch 51, Val Loss: 94.82772
Epoch 52, Val Loss: 81.44490
Epoch 53, Val Loss: 78.97615
Epoch 54, Val Loss: 80.30536
Epoch 55, Val Loss: 82.07531
Epoch 56, Val Loss: 80.79029
Epoch 57, Val Loss: 93.04031
Epoch 58, Val Loss: 80.58203
Epoch 59, Val Loss: 82.81686
Epoch 60, Val Loss: 77.08901
Epoch 61, Val Loss: 80.24750
Epoch 62, Val Loss: 81.96124
Epoch 63, Val Loss: 76.70281
Epoch 64, Val Loss: 79.79466
Epoch 65, Val Loss: 83.68066
Epoch 66, Val Loss: 79.64114
Epoch 67, Val Loss: 92.95164
Epoch 68, Val Loss: 75.85223
Epoch 69, Val Loss: 80.76873
Epoch 70, Val Loss: 76.63360
Epoch 71, Val Loss: 76.37178
Epoch 72, Val Loss: 77.58202
Epoch 73, Val Loss: 80.13049
Epoch 74, Val Loss: 79.90539
Epoch 75, Val Loss: 79.63766
Epoch 76, Val Loss: 81.78273
Epoch 77, Val Loss: 79.48514
Epoch 78, Val Loss: 86.02899
Epoch 79, Val Loss: 78.32958
Epoch 80, Val Loss: 77.56541
Epoch 81, Val Loss: 77.15313
Epoch 82, Val Loss: 81.82030
Epoch 83, Val Loss: 77.91528
Epoch 84, Val Loss: 90.80318
Epoch 85, Val Loss: 76.78531
Epoch 86, Val Loss: 76.37115
Epoch 87, Val Loss: 94.48638
Epoch 88, Val Loss: 77.14008
Epoch 89, Val Loss: 81.04047
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.56802138974692, 'MSE - std': 8.94760411562329, 'R2 - mean': 0.5061972565167653, 'R2 - std': 0.03417636326482112} 
 

Results After CV: {'MSE - mean': 79.56802138974692, 'MSE - std': 8.94760411562329, 'R2 - mean': 0.5061972565167653, 'R2 - std': 0.03417636326482112}
Train time: 1682.3703840326002
Inference time: 0.17523259219997273
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 20 finished with value: 79.56802138974692 and parameters: {'p_m': 0.22112915445319242, 'alpha': 1.0588259794895105, 'K': 10, 'beta': 8.388098720163253}. Best is trial 3 with value: 78.3667380652227.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1170.40149
Epoch 1, Val Loss: 578.21997
Epoch 2, Val Loss: 272.70135
Epoch 3, Val Loss: 235.65112
Epoch 4, Val Loss: 262.54556
Epoch 5, Val Loss: 218.06374
Epoch 6, Val Loss: 169.85843
Epoch 7, Val Loss: 163.51158
Epoch 8, Val Loss: 158.26817
Epoch 9, Val Loss: 141.74818
Epoch 10, Val Loss: 144.31543
Epoch 11, Val Loss: 141.86876
Epoch 12, Val Loss: 119.63067
Epoch 13, Val Loss: 112.33115
Epoch 14, Val Loss: 107.72009
Epoch 15, Val Loss: 110.29279
Epoch 16, Val Loss: 110.20766
Epoch 17, Val Loss: 103.77439
Epoch 18, Val Loss: 106.16388
Epoch 19, Val Loss: 95.83623
Epoch 20, Val Loss: 94.46327
Epoch 21, Val Loss: 94.55179
Epoch 22, Val Loss: 87.85146
Epoch 23, Val Loss: 93.99712
Epoch 24, Val Loss: 95.21446
Epoch 25, Val Loss: 93.43633
Epoch 26, Val Loss: 88.20479
Epoch 27, Val Loss: 84.15025
Epoch 28, Val Loss: 83.51833
Epoch 29, Val Loss: 85.21824
Epoch 30, Val Loss: 87.42518
Epoch 31, Val Loss: 84.09774
Epoch 32, Val Loss: 82.56644
Epoch 33, Val Loss: 85.39323
Epoch 34, Val Loss: 91.30779
Epoch 35, Val Loss: 89.21313
Epoch 36, Val Loss: 89.71749
Epoch 37, Val Loss: 86.53373
Epoch 38, Val Loss: 93.58855
Epoch 39, Val Loss: 98.30931
Epoch 40, Val Loss: 88.29317
Epoch 41, Val Loss: 82.29978
Epoch 42, Val Loss: 84.82237
Epoch 43, Val Loss: 86.91299
Epoch 44, Val Loss: 87.89146
Epoch 45, Val Loss: 84.80144
Epoch 46, Val Loss: 81.95354
Epoch 47, Val Loss: 83.28329
Epoch 48, Val Loss: 84.04092
Epoch 49, Val Loss: 84.43958
Epoch 50, Val Loss: 86.39136
Epoch 51, Val Loss: 86.85555
Epoch 52, Val Loss: 83.76630
Epoch 53, Val Loss: 84.31681
Epoch 54, Val Loss: 86.40751
Epoch 55, Val Loss: 86.16486
Epoch 56, Val Loss: 88.86609
Epoch 57, Val Loss: 91.84671
Epoch 58, Val Loss: 85.99629
Epoch 59, Val Loss: 88.12038
Epoch 60, Val Loss: 89.42847
Epoch 61, Val Loss: 85.38435
Epoch 62, Val Loss: 87.35193
Epoch 63, Val Loss: 84.17509
Epoch 64, Val Loss: 82.94165
Epoch 65, Val Loss: 90.53877
Epoch 66, Val Loss: 84.97546
Epoch 67, Val Loss: 85.24876
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.95311328498387, 'MSE - std': 0.0, 'R2 - mean': 0.49912261519674594, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 604.86646
Epoch 1, Val Loss: 460.77893
Epoch 2, Val Loss: 305.15564
Epoch 3, Val Loss: 230.74396
Epoch 4, Val Loss: 215.26202
Epoch 5, Val Loss: 175.53011
Epoch 6, Val Loss: 190.96957
Epoch 7, Val Loss: 141.20221
Epoch 8, Val Loss: 184.41867
Epoch 9, Val Loss: 146.03673
Epoch 10, Val Loss: 121.15027
Epoch 11, Val Loss: 107.35143
Epoch 12, Val Loss: 120.76175
Epoch 13, Val Loss: 105.52332
Epoch 14, Val Loss: 119.74133
Epoch 15, Val Loss: 111.73230
Epoch 16, Val Loss: 88.55988
Epoch 17, Val Loss: 92.52625
Epoch 18, Val Loss: 87.60075
Epoch 19, Val Loss: 89.84537
Epoch 20, Val Loss: 82.28278
Epoch 21, Val Loss: 84.21655
Epoch 22, Val Loss: 74.68962
Epoch 23, Val Loss: 74.91312
Epoch 24, Val Loss: 78.36938
Epoch 25, Val Loss: 71.89266
Epoch 26, Val Loss: 72.71645
Epoch 27, Val Loss: 74.73443
Epoch 28, Val Loss: 69.92153
Epoch 29, Val Loss: 72.32475
Epoch 30, Val Loss: 72.78850
Epoch 31, Val Loss: 70.19558
Epoch 32, Val Loss: 69.98611
Epoch 33, Val Loss: 74.30213
Epoch 34, Val Loss: 72.38739
Epoch 35, Val Loss: 79.31640
Epoch 36, Val Loss: 72.23508
Epoch 37, Val Loss: 72.52779
Epoch 38, Val Loss: 70.83743
Epoch 39, Val Loss: 74.28339
Epoch 40, Val Loss: 76.46600
Epoch 41, Val Loss: 72.07275
Epoch 42, Val Loss: 71.78596
Epoch 43, Val Loss: 76.03572
Epoch 44, Val Loss: 74.31248
Epoch 45, Val Loss: 74.18556
Epoch 46, Val Loss: 75.68132
Epoch 47, Val Loss: 73.02994
Epoch 48, Val Loss: 72.74820
Epoch 49, Val Loss: 75.91378
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.74201840666157, 'MSE - std': 3.2110948783222995, 'R2 - mean': 0.4958584338051622, 'R2 - std': 0.0032641813915837425} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 789.88031
Epoch 1, Val Loss: 625.33789
Epoch 2, Val Loss: 302.50351
Epoch 3, Val Loss: 229.63904
Epoch 4, Val Loss: 237.60733
Epoch 5, Val Loss: 190.16934
Epoch 6, Val Loss: 178.31509
Epoch 7, Val Loss: 148.08812
Epoch 8, Val Loss: 149.64905
Epoch 9, Val Loss: 142.74741
Epoch 10, Val Loss: 126.85684
Epoch 11, Val Loss: 117.41060
Epoch 12, Val Loss: 124.43415
Epoch 13, Val Loss: 96.24692
Epoch 14, Val Loss: 99.52047
Epoch 15, Val Loss: 105.39104
Epoch 16, Val Loss: 90.94912
Epoch 17, Val Loss: 90.64711
Epoch 18, Val Loss: 79.69246
Epoch 19, Val Loss: 85.90839
Epoch 20, Val Loss: 80.93193
Epoch 21, Val Loss: 80.76019
Epoch 22, Val Loss: 77.12622
Epoch 23, Val Loss: 82.16209
Epoch 24, Val Loss: 81.63903
Epoch 25, Val Loss: 80.42456
Epoch 26, Val Loss: 77.78239
Epoch 27, Val Loss: 76.09850
Epoch 28, Val Loss: 81.56819
Epoch 29, Val Loss: 73.32522
Epoch 30, Val Loss: 78.93192
Epoch 31, Val Loss: 74.66109
Epoch 32, Val Loss: 71.51225
Epoch 33, Val Loss: 69.10554
Epoch 34, Val Loss: 75.30335
Epoch 35, Val Loss: 78.47737
Epoch 36, Val Loss: 77.26535
Epoch 37, Val Loss: 77.94435
Epoch 38, Val Loss: 74.56289
Epoch 39, Val Loss: 75.11945
Epoch 40, Val Loss: 77.05795
Epoch 41, Val Loss: 81.13042
Epoch 42, Val Loss: 78.03433
Epoch 43, Val Loss: 77.64950
Epoch 44, Val Loss: 72.29953
Epoch 45, Val Loss: 73.12794
Epoch 46, Val Loss: 76.66695
Epoch 47, Val Loss: 75.21788
Epoch 48, Val Loss: 79.19104
Epoch 49, Val Loss: 78.67305
Epoch 50, Val Loss: 74.81590
Epoch 51, Val Loss: 76.32187
Epoch 52, Val Loss: 69.97727
Epoch 53, Val Loss: 70.62401
Epoch 54, Val Loss: 76.24078
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.4899787752726, 'MSE - std': 6.560012875916994, 'R2 - mean': 0.5071111240981687, 'R2 - std': 0.016135344158051054} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 552.88733
Epoch 1, Val Loss: 548.14978
Epoch 2, Val Loss: 320.32822
Epoch 3, Val Loss: 232.60327
Epoch 4, Val Loss: 209.61322
Epoch 5, Val Loss: 199.89211
Epoch 6, Val Loss: 159.91058
Epoch 7, Val Loss: 201.20729
Epoch 8, Val Loss: 133.32866
Epoch 9, Val Loss: 130.79573
Epoch 10, Val Loss: 130.42450
Epoch 11, Val Loss: 116.84439
Epoch 12, Val Loss: 130.45518
Epoch 13, Val Loss: 107.37696
Epoch 14, Val Loss: 114.15945
Epoch 15, Val Loss: 108.81511
Epoch 16, Val Loss: 106.70382
Epoch 17, Val Loss: 102.69239
Epoch 18, Val Loss: 92.45877
Epoch 19, Val Loss: 93.07107
Epoch 20, Val Loss: 88.70390
Epoch 21, Val Loss: 90.75692
Epoch 22, Val Loss: 86.08643
Epoch 23, Val Loss: 84.66695
Epoch 24, Val Loss: 84.18915
Epoch 25, Val Loss: 88.36774
Epoch 26, Val Loss: 84.19296
Epoch 27, Val Loss: 81.22166
Epoch 28, Val Loss: 79.98993
Epoch 29, Val Loss: 81.89140
Epoch 30, Val Loss: 87.13770
Epoch 31, Val Loss: 90.80305
Epoch 32, Val Loss: 80.05250
Epoch 33, Val Loss: 78.14580
Epoch 34, Val Loss: 94.58350
Epoch 35, Val Loss: 81.02173
Epoch 36, Val Loss: 81.18623
Epoch 37, Val Loss: 82.83549
Epoch 38, Val Loss: 84.42044
Epoch 39, Val Loss: 83.50377
Epoch 40, Val Loss: 81.96016
Epoch 41, Val Loss: 79.21091
Epoch 42, Val Loss: 78.65053
Epoch 43, Val Loss: 85.78885
Epoch 44, Val Loss: 79.78899
Epoch 45, Val Loss: 80.45764
Epoch 46, Val Loss: 78.78816
Epoch 47, Val Loss: 79.50461
Epoch 48, Val Loss: 82.76749
Epoch 49, Val Loss: 79.66992
Epoch 50, Val Loss: 86.23090
Epoch 51, Val Loss: 81.04603
Epoch 52, Val Loss: 83.75259
Epoch 53, Val Loss: 83.68313
Epoch 54, Val Loss: 80.11143
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.21004254418517, 'MSE - std': 7.380485581586089, 'R2 - mean': 0.49644137604900423, 'R2 - std': 0.023168784357881438} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 808.01233
Epoch 1, Val Loss: 738.04956
Epoch 2, Val Loss: 318.69254
Epoch 3, Val Loss: 244.69853
Epoch 4, Val Loss: 211.79956
Epoch 5, Val Loss: 253.27637
Epoch 6, Val Loss: 148.44168
Epoch 7, Val Loss: 159.37927
Epoch 8, Val Loss: 185.23088
Epoch 9, Val Loss: 143.06343
Epoch 10, Val Loss: 157.48074
Epoch 11, Val Loss: 115.16119
Epoch 12, Val Loss: 114.11239
Epoch 13, Val Loss: 150.67581
Epoch 14, Val Loss: 103.47804
Epoch 15, Val Loss: 96.19909
Epoch 16, Val Loss: 104.03190
Epoch 17, Val Loss: 98.07137
Epoch 18, Val Loss: 90.13356
Epoch 19, Val Loss: 98.67245
Epoch 20, Val Loss: 91.63751
Epoch 21, Val Loss: 87.27122
Epoch 22, Val Loss: 97.08371
Epoch 23, Val Loss: 87.05066
Epoch 24, Val Loss: 81.34210
Epoch 25, Val Loss: 89.10089
Epoch 26, Val Loss: 79.88664
Epoch 27, Val Loss: 78.04889
Epoch 28, Val Loss: 83.13346
Epoch 29, Val Loss: 77.47692
Epoch 30, Val Loss: 79.34662
Epoch 31, Val Loss: 82.05758
Epoch 32, Val Loss: 79.45055
Epoch 33, Val Loss: 76.40100
Epoch 34, Val Loss: 80.72145
Epoch 35, Val Loss: 79.47360
Epoch 36, Val Loss: 81.22529
Epoch 37, Val Loss: 74.44379
Epoch 38, Val Loss: 78.89397
Epoch 39, Val Loss: 81.84093
Epoch 40, Val Loss: 79.69355
Epoch 41, Val Loss: 83.50850
Epoch 42, Val Loss: 80.89326
Epoch 43, Val Loss: 76.19209
Epoch 44, Val Loss: 79.82149
Epoch 45, Val Loss: 86.46635
Epoch 46, Val Loss: 85.24120
Epoch 47, Val Loss: 81.26118
Epoch 48, Val Loss: 80.09392
Epoch 49, Val Loss: 83.96425
Epoch 50, Val Loss: 78.63989
Epoch 51, Val Loss: 76.86398
Epoch 52, Val Loss: 81.33675
Epoch 53, Val Loss: 81.31123
Epoch 54, Val Loss: 83.51619
Epoch 55, Val Loss: 77.37591
Epoch 56, Val Loss: 77.08314
Epoch 57, Val Loss: 74.95974
Epoch 58, Val Loss: 77.88569
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.90720381822585, 'MSE - std': 7.096957722815976, 'R2 - mean': 0.5034617950192886, 'R2 - std': 0.025031563773981778} 
 

Results After CV: {'MSE - mean': 79.90720381822585, 'MSE - std': 7.096957722815976, 'R2 - mean': 0.5034617950192886, 'R2 - std': 0.025031563773981778}
Train time: 342.87657399120036
Inference time: 0.181152695000128
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 21 finished with value: 79.90720381822585 and parameters: {'p_m': 0.6508188393675085, 'alpha': 4.932834241566746, 'K': 3, 'beta': 9.28108020661008}. Best is trial 3 with value: 78.3667380652227.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 623.28735
Epoch 1, Val Loss: 364.12476
Epoch 2, Val Loss: 243.78644
Epoch 3, Val Loss: 196.88828
Epoch 4, Val Loss: 183.39136
Epoch 5, Val Loss: 174.04057
Epoch 6, Val Loss: 163.13756
Epoch 7, Val Loss: 146.02536
Epoch 8, Val Loss: 138.12775
Epoch 9, Val Loss: 165.83939
Epoch 10, Val Loss: 137.58961
Epoch 11, Val Loss: 147.41670
Epoch 12, Val Loss: 151.22626
Epoch 13, Val Loss: 120.08788
Epoch 14, Val Loss: 127.10480
Epoch 15, Val Loss: 128.38350
Epoch 16, Val Loss: 113.06161
Epoch 17, Val Loss: 117.08465
Epoch 18, Val Loss: 114.90359
Epoch 19, Val Loss: 101.98110
Epoch 20, Val Loss: 111.79333
Epoch 21, Val Loss: 109.75056
Epoch 22, Val Loss: 100.36293
Epoch 23, Val Loss: 117.39644
Epoch 24, Val Loss: 115.94213
Epoch 25, Val Loss: 92.91588
Epoch 26, Val Loss: 94.46941
Epoch 27, Val Loss: 102.28801
Epoch 28, Val Loss: 93.21650
Epoch 29, Val Loss: 98.53771
Epoch 30, Val Loss: 94.88792
Epoch 31, Val Loss: 106.84612
Epoch 32, Val Loss: 101.94147
Epoch 33, Val Loss: 86.36665
Epoch 34, Val Loss: 93.32790
Epoch 35, Val Loss: 86.19031
Epoch 36, Val Loss: 87.73373
Epoch 37, Val Loss: 84.69699
Epoch 38, Val Loss: 85.34552
Epoch 39, Val Loss: 90.49347
Epoch 40, Val Loss: 89.29610
Epoch 41, Val Loss: 87.44054
Epoch 42, Val Loss: 86.63132
Epoch 43, Val Loss: 83.39314
Epoch 44, Val Loss: 89.07978
Epoch 45, Val Loss: 83.38730
Epoch 46, Val Loss: 94.58151
Epoch 47, Val Loss: 87.37874
Epoch 48, Val Loss: 86.84863
Epoch 49, Val Loss: 84.02358
Epoch 50, Val Loss: 87.85529
Epoch 51, Val Loss: 93.17729
Epoch 52, Val Loss: 86.83598
Epoch 53, Val Loss: 89.31712
Epoch 54, Val Loss: 88.88753
Epoch 55, Val Loss: 94.27710
Epoch 56, Val Loss: 90.59138
Epoch 57, Val Loss: 89.37253
Epoch 58, Val Loss: 98.24222
Epoch 59, Val Loss: 91.05000
Epoch 60, Val Loss: 88.26756
Epoch 61, Val Loss: 91.40048
Epoch 62, Val Loss: 86.24873
Epoch 63, Val Loss: 90.43873
Epoch 64, Val Loss: 89.36220
Epoch 65, Val Loss: 88.33499
Epoch 66, Val Loss: 91.79115
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.77070963907387, 'MSE - std': 0.0, 'R2 - mean': 0.49435820925482865, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 530.97498
Epoch 1, Val Loss: 488.90500
Epoch 2, Val Loss: 230.17783
Epoch 3, Val Loss: 177.47041
Epoch 4, Val Loss: 186.13757
Epoch 5, Val Loss: 180.11717
Epoch 6, Val Loss: 171.69492
Epoch 7, Val Loss: 129.91537
Epoch 8, Val Loss: 130.46040
Epoch 9, Val Loss: 134.34854
Epoch 10, Val Loss: 130.04065
Epoch 11, Val Loss: 107.07675
Epoch 12, Val Loss: 98.03501
Epoch 13, Val Loss: 98.29967
Epoch 14, Val Loss: 101.17186
Epoch 15, Val Loss: 105.33260
Epoch 16, Val Loss: 98.17276
Epoch 17, Val Loss: 106.79039
Epoch 18, Val Loss: 107.90864
Epoch 19, Val Loss: 89.77850
Epoch 20, Val Loss: 84.91675
Epoch 21, Val Loss: 96.02543
Epoch 22, Val Loss: 89.73997
Epoch 23, Val Loss: 85.74651
Epoch 24, Val Loss: 84.78032
Epoch 25, Val Loss: 86.51410
Epoch 26, Val Loss: 80.68792
Epoch 27, Val Loss: 78.27548
Epoch 28, Val Loss: 76.85664
Epoch 29, Val Loss: 76.29114
Epoch 30, Val Loss: 78.99913
Epoch 31, Val Loss: 76.73355
Epoch 32, Val Loss: 79.07006
Epoch 33, Val Loss: 91.63916
Epoch 34, Val Loss: 74.41348
Epoch 35, Val Loss: 75.08875
Epoch 36, Val Loss: 73.94210
Epoch 37, Val Loss: 71.95071
Epoch 38, Val Loss: 74.48791
Epoch 39, Val Loss: 71.75834
Epoch 40, Val Loss: 73.34241
Epoch 41, Val Loss: 75.29240
Epoch 42, Val Loss: 73.24739
Epoch 43, Val Loss: 73.64302
Epoch 44, Val Loss: 76.03048
Epoch 45, Val Loss: 75.93219
Epoch 46, Val Loss: 78.76437
Epoch 47, Val Loss: 73.96403
Epoch 48, Val Loss: 78.36190
Epoch 49, Val Loss: 75.58533
Epoch 50, Val Loss: 74.75919
Epoch 51, Val Loss: 77.67867
Epoch 52, Val Loss: 80.34142
Epoch 53, Val Loss: 73.66231
Epoch 54, Val Loss: 77.06241
Epoch 55, Val Loss: 83.16321
Epoch 56, Val Loss: 73.17755
Epoch 57, Val Loss: 76.83545
Epoch 58, Val Loss: 74.41658
Epoch 59, Val Loss: 76.86823
Epoch 60, Val Loss: 79.90721
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.17165198005614, 'MSE - std': 3.5990576590177383, 'R2 - mean': 0.4933433014101256, 'R2 - std': 0.001014907844703039} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 945.84131
Epoch 1, Val Loss: 536.62622
Epoch 2, Val Loss: 223.78290
Epoch 3, Val Loss: 177.41696
Epoch 4, Val Loss: 149.65823
Epoch 5, Val Loss: 143.44713
Epoch 6, Val Loss: 154.48483
Epoch 7, Val Loss: 106.61555
Epoch 8, Val Loss: 146.67427
Epoch 9, Val Loss: 101.08527
Epoch 10, Val Loss: 96.32217
Epoch 11, Val Loss: 97.74842
Epoch 12, Val Loss: 97.13282
Epoch 13, Val Loss: 84.68812
Epoch 14, Val Loss: 87.50019
Epoch 15, Val Loss: 86.07003
Epoch 16, Val Loss: 85.40425
Epoch 17, Val Loss: 86.80878
Epoch 18, Val Loss: 102.58493
Epoch 19, Val Loss: 85.71705
Epoch 20, Val Loss: 81.63137
Epoch 21, Val Loss: 81.16534
Epoch 22, Val Loss: 77.51506
Epoch 23, Val Loss: 78.09567
Epoch 24, Val Loss: 86.36807
Epoch 25, Val Loss: 81.30149
Epoch 26, Val Loss: 75.35562
Epoch 27, Val Loss: 69.49329
Epoch 28, Val Loss: 77.58523
Epoch 29, Val Loss: 78.08513
Epoch 30, Val Loss: 84.19749
Epoch 31, Val Loss: 73.51399
Epoch 32, Val Loss: 69.23744
Epoch 33, Val Loss: 71.12284
Epoch 34, Val Loss: 67.37021
Epoch 35, Val Loss: 69.34620
Epoch 36, Val Loss: 69.54136
Epoch 37, Val Loss: 72.28283
Epoch 38, Val Loss: 68.22377
Epoch 39, Val Loss: 67.69502
Epoch 40, Val Loss: 69.78997
Epoch 41, Val Loss: 66.47057
Epoch 42, Val Loss: 70.10406
Epoch 43, Val Loss: 69.52771
Epoch 44, Val Loss: 72.15126
Epoch 45, Val Loss: 71.55148
Epoch 46, Val Loss: 74.10238
Epoch 47, Val Loss: 66.99466
Epoch 48, Val Loss: 69.59547
Epoch 49, Val Loss: 70.27571
Epoch 50, Val Loss: 67.45725
Epoch 51, Val Loss: 68.23972
Epoch 52, Val Loss: 69.43867
Epoch 53, Val Loss: 73.37222
Epoch 54, Val Loss: 77.52393
Epoch 55, Val Loss: 74.87389
Epoch 56, Val Loss: 70.12939
Epoch 57, Val Loss: 68.32494
Epoch 58, Val Loss: 68.62585
Epoch 59, Val Loss: 68.77905
Epoch 60, Val Loss: 89.97427
Epoch 61, Val Loss: 71.84079
Epoch 62, Val Loss: 72.81409
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.69049922451681, 'MSE - std': 8.289846103179617, 'R2 - mean': 0.5127328442950149, 'R2 - std': 0.027433472957782964} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 834.93433
Epoch 1, Val Loss: 394.76810
Epoch 2, Val Loss: 211.43907
Epoch 3, Val Loss: 222.40984
Epoch 4, Val Loss: 214.77019
Epoch 5, Val Loss: 189.37930
Epoch 6, Val Loss: 152.01511
Epoch 7, Val Loss: 144.63934
Epoch 8, Val Loss: 158.45891
Epoch 9, Val Loss: 114.13538
Epoch 10, Val Loss: 134.62660
Epoch 11, Val Loss: 139.95010
Epoch 12, Val Loss: 121.38091
Epoch 13, Val Loss: 106.79512
Epoch 14, Val Loss: 126.06596
Epoch 15, Val Loss: 112.44496
Epoch 16, Val Loss: 98.29824
Epoch 17, Val Loss: 96.64268
Epoch 18, Val Loss: 107.28398
Epoch 19, Val Loss: 103.05675
Epoch 20, Val Loss: 93.63155
Epoch 21, Val Loss: 94.28041
Epoch 22, Val Loss: 93.69286
Epoch 23, Val Loss: 113.97971
Epoch 24, Val Loss: 91.69528
Epoch 25, Val Loss: 93.97085
Epoch 26, Val Loss: 97.50513
Epoch 27, Val Loss: 85.17700
Epoch 28, Val Loss: 86.62997
Epoch 29, Val Loss: 89.43136
Epoch 30, Val Loss: 83.29302
Epoch 31, Val Loss: 81.24240
Epoch 32, Val Loss: 81.13380
Epoch 33, Val Loss: 84.96708
Epoch 34, Val Loss: 83.69946
Epoch 35, Val Loss: 86.45377
Epoch 36, Val Loss: 82.95851
Epoch 37, Val Loss: 92.08235
Epoch 38, Val Loss: 83.63739
Epoch 39, Val Loss: 79.71127
Epoch 40, Val Loss: 84.28941
Epoch 41, Val Loss: 86.42362
Epoch 42, Val Loss: 78.99249
Epoch 43, Val Loss: 85.05026
Epoch 44, Val Loss: 87.49100
Epoch 45, Val Loss: 86.43861
Epoch 46, Val Loss: 80.24393
Epoch 47, Val Loss: 82.09714
Epoch 48, Val Loss: 90.91351
Epoch 49, Val Loss: 82.48816
Epoch 50, Val Loss: 80.59646
Epoch 51, Val Loss: 90.11794
Epoch 52, Val Loss: 80.65874
Epoch 53, Val Loss: 81.20660
Epoch 54, Val Loss: 85.84410
Epoch 55, Val Loss: 83.18761
Epoch 56, Val Loss: 83.31243
Epoch 57, Val Loss: 80.62900
Epoch 58, Val Loss: 84.65292
Epoch 59, Val Loss: 82.27017
Epoch 60, Val Loss: 79.98113
Epoch 61, Val Loss: 81.35815
Epoch 62, Val Loss: 82.49817
Epoch 63, Val Loss: 89.41371
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.46411322245108, 'MSE - std': 8.638284849402252, 'R2 - mean': 0.5015345141612982, 'R2 - std': 0.030670089211562036} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 803.66321
Epoch 1, Val Loss: 503.23718
Epoch 2, Val Loss: 215.18166
Epoch 3, Val Loss: 168.67191
Epoch 4, Val Loss: 193.10863
Epoch 5, Val Loss: 159.27269
Epoch 6, Val Loss: 146.53568
Epoch 7, Val Loss: 126.38191
Epoch 8, Val Loss: 137.31845
Epoch 9, Val Loss: 131.69901
Epoch 10, Val Loss: 127.56958
Epoch 11, Val Loss: 118.44824
Epoch 12, Val Loss: 100.89227
Epoch 13, Val Loss: 106.36116
Epoch 14, Val Loss: 100.22904
Epoch 15, Val Loss: 100.76999
Epoch 16, Val Loss: 93.86485
Epoch 17, Val Loss: 101.60983
Epoch 18, Val Loss: 103.33144
Epoch 19, Val Loss: 95.86198
Epoch 20, Val Loss: 90.60663
Epoch 21, Val Loss: 128.91318
Epoch 22, Val Loss: 95.75400
Epoch 23, Val Loss: 84.72314
Epoch 24, Val Loss: 96.21750
Epoch 25, Val Loss: 105.58100
Epoch 26, Val Loss: 84.70257
Epoch 27, Val Loss: 83.12375
Epoch 28, Val Loss: 86.82738
Epoch 29, Val Loss: 88.24220
Epoch 30, Val Loss: 80.25148
Epoch 31, Val Loss: 78.68316
Epoch 32, Val Loss: 80.91832
Epoch 33, Val Loss: 80.52895
Epoch 34, Val Loss: 76.45491
Epoch 35, Val Loss: 79.65871
Epoch 36, Val Loss: 73.23976
Epoch 37, Val Loss: 73.39700
Epoch 38, Val Loss: 74.35873
Epoch 39, Val Loss: 75.92741
Epoch 40, Val Loss: 75.29224
Epoch 41, Val Loss: 83.67724
Epoch 42, Val Loss: 76.23827
Epoch 43, Val Loss: 78.11034
Epoch 44, Val Loss: 78.91812
Epoch 45, Val Loss: 76.95409
Epoch 46, Val Loss: 74.85613
Epoch 47, Val Loss: 79.96461
Epoch 48, Val Loss: 77.29649
Epoch 49, Val Loss: 74.25954
Epoch 50, Val Loss: 74.38554
Epoch 51, Val Loss: 79.66599
Epoch 52, Val Loss: 75.89482
Epoch 53, Val Loss: 76.90450
Epoch 54, Val Loss: 78.24692
Epoch 55, Val Loss: 85.79839
Epoch 56, Val Loss: 85.33326
Epoch 57, Val Loss: 72.75849
Epoch 58, Val Loss: 80.03230
Epoch 59, Val Loss: 78.66454
Epoch 60, Val Loss: 80.85507
Epoch 61, Val Loss: 80.54350
Epoch 62, Val Loss: 79.66248
Epoch 63, Val Loss: 73.39442
Epoch 64, Val Loss: 78.63362
Epoch 65, Val Loss: 77.34545
Epoch 66, Val Loss: 73.62193
Epoch 67, Val Loss: 76.88118
Epoch 68, Val Loss: 86.07064
Epoch 69, Val Loss: 75.99987
Epoch 70, Val Loss: 87.73015
Epoch 71, Val Loss: 74.00556
Epoch 72, Val Loss: 82.49544
Epoch 73, Val Loss: 81.36740
Epoch 74, Val Loss: 78.49384
Epoch 75, Val Loss: 78.97148
Epoch 76, Val Loss: 82.48759
Epoch 77, Val Loss: 79.96142
Epoch 78, Val Loss: 85.20799
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.294834009037, 'MSE - std': 8.072473451626767, 'R2 - mean': 0.5076343064908897, 'R2 - std': 0.030022547587650012} 
 

Results After CV: {'MSE - mean': 79.294834009037, 'MSE - std': 8.072473451626767, 'R2 - mean': 0.5076343064908897, 'R2 - std': 0.030022547587650012}
Train time: 399.46772615760017
Inference time: 0.17736315200018
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 22 finished with value: 79.294834009037 and parameters: {'p_m': 0.42458362582753983, 'alpha': 3.9736631822612676, 'K': 3, 'beta': 9.131186649480128}. Best is trial 3 with value: 78.3667380652227.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 856.08350
Epoch 1, Val Loss: 474.38556
Epoch 2, Val Loss: 238.74937
Epoch 3, Val Loss: 206.44881
Epoch 4, Val Loss: 190.11292
Epoch 5, Val Loss: 194.50784
Epoch 6, Val Loss: 155.92352
Epoch 7, Val Loss: 138.54237
Epoch 8, Val Loss: 144.86057
Epoch 9, Val Loss: 136.90666
Epoch 10, Val Loss: 116.67348
Epoch 11, Val Loss: 147.65085
Epoch 12, Val Loss: 139.60754
Epoch 13, Val Loss: 132.78450
Epoch 14, Val Loss: 118.66498
Epoch 15, Val Loss: 150.14526
Epoch 16, Val Loss: 118.49683
Epoch 17, Val Loss: 116.03104
Epoch 18, Val Loss: 112.13004
Epoch 19, Val Loss: 106.61684
Epoch 20, Val Loss: 108.84415
Epoch 21, Val Loss: 102.21589
Epoch 22, Val Loss: 108.93019
Epoch 23, Val Loss: 98.26041
Epoch 24, Val Loss: 93.66644
Epoch 25, Val Loss: 92.91318
Epoch 26, Val Loss: 88.41176
Epoch 27, Val Loss: 94.71693
Epoch 28, Val Loss: 90.72763
Epoch 29, Val Loss: 93.62012
Epoch 30, Val Loss: 92.82948
Epoch 31, Val Loss: 102.22631
Epoch 32, Val Loss: 90.32115
Epoch 33, Val Loss: 88.72940
Epoch 34, Val Loss: 90.48930
Epoch 35, Val Loss: 84.78137
Epoch 36, Val Loss: 92.53728
Epoch 37, Val Loss: 85.32767
Epoch 38, Val Loss: 84.20398
Epoch 39, Val Loss: 85.15421
Epoch 40, Val Loss: 85.34370
Epoch 41, Val Loss: 87.51514
Epoch 42, Val Loss: 86.76823
Epoch 43, Val Loss: 88.23657
Epoch 44, Val Loss: 82.90779
Epoch 45, Val Loss: 87.50229
Epoch 46, Val Loss: 87.54071
Epoch 47, Val Loss: 82.70733
Epoch 48, Val Loss: 86.71905
Epoch 49, Val Loss: 89.81712
Epoch 50, Val Loss: 88.45809
Epoch 51, Val Loss: 85.81427
Epoch 52, Val Loss: 89.39803
Epoch 53, Val Loss: 85.90128
Epoch 54, Val Loss: 92.66792
Epoch 55, Val Loss: 91.88066
Epoch 56, Val Loss: 86.24066
Epoch 57, Val Loss: 93.29703
Epoch 58, Val Loss: 88.47548
Epoch 59, Val Loss: 96.09185
Epoch 60, Val Loss: 101.00320
Epoch 61, Val Loss: 88.68476
Epoch 62, Val Loss: 85.40105
Epoch 63, Val Loss: 102.82017
Epoch 64, Val Loss: 84.96027
Epoch 65, Val Loss: 84.43456
Epoch 66, Val Loss: 93.53275
Epoch 67, Val Loss: 96.90174
Epoch 68, Val Loss: 85.63709
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.74130064745947, 'MSE - std': 0.0, 'R2 - mean': 0.5003569178984963, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 620.22284
Epoch 1, Val Loss: 478.04181
Epoch 2, Val Loss: 196.73370
Epoch 3, Val Loss: 173.19702
Epoch 4, Val Loss: 151.21677
Epoch 5, Val Loss: 150.23801
Epoch 6, Val Loss: 120.36601
Epoch 7, Val Loss: 129.21347
Epoch 8, Val Loss: 114.89384
Epoch 9, Val Loss: 128.66803
Epoch 10, Val Loss: 137.62357
Epoch 11, Val Loss: 107.82163
Epoch 12, Val Loss: 102.81075
Epoch 13, Val Loss: 108.73571
Epoch 14, Val Loss: 97.65810
Epoch 15, Val Loss: 89.29178
Epoch 16, Val Loss: 99.54285
Epoch 17, Val Loss: 97.03899
Epoch 18, Val Loss: 101.91166
Epoch 19, Val Loss: 92.47812
Epoch 20, Val Loss: 90.44611
Epoch 21, Val Loss: 91.73938
Epoch 22, Val Loss: 78.97132
Epoch 23, Val Loss: 110.85754
Epoch 24, Val Loss: 84.98169
Epoch 25, Val Loss: 82.22965
Epoch 26, Val Loss: 86.15549
Epoch 27, Val Loss: 74.40932
Epoch 28, Val Loss: 77.24934
Epoch 29, Val Loss: 97.06759
Epoch 30, Val Loss: 80.04672
Epoch 31, Val Loss: 79.49178
Epoch 32, Val Loss: 81.31253
Epoch 33, Val Loss: 76.41901
Epoch 34, Val Loss: 75.64330
Epoch 35, Val Loss: 78.81487
Epoch 36, Val Loss: 77.49294
Epoch 37, Val Loss: 79.70704
Epoch 38, Val Loss: 78.12215
Epoch 39, Val Loss: 74.99193
Epoch 40, Val Loss: 78.55871
Epoch 41, Val Loss: 74.73353
Epoch 42, Val Loss: 80.72795
Epoch 43, Val Loss: 77.57664
Epoch 44, Val Loss: 74.80698
Epoch 45, Val Loss: 74.53154
Epoch 46, Val Loss: 77.02850
Epoch 47, Val Loss: 79.12302
Epoch 48, Val Loss: 82.18259
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.19913229258326, 'MSE - std': 1.5421683548762104, 'R2 - mean': 0.48650354660467177, 'R2 - std': 0.013853371293824579} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 588.16095
Epoch 1, Val Loss: 516.27734
Epoch 2, Val Loss: 194.69177
Epoch 3, Val Loss: 152.76956
Epoch 4, Val Loss: 143.06557
Epoch 5, Val Loss: 157.10297
Epoch 6, Val Loss: 112.01114
Epoch 7, Val Loss: 104.75591
Epoch 8, Val Loss: 112.73090
Epoch 9, Val Loss: 103.56134
Epoch 10, Val Loss: 110.88008
Epoch 11, Val Loss: 109.34290
Epoch 12, Val Loss: 89.78542
Epoch 13, Val Loss: 98.16656
Epoch 14, Val Loss: 106.61203
Epoch 15, Val Loss: 96.29939
Epoch 16, Val Loss: 88.35670
Epoch 17, Val Loss: 85.33643
Epoch 18, Val Loss: 88.40444
Epoch 19, Val Loss: 89.71450
Epoch 20, Val Loss: 74.09878
Epoch 21, Val Loss: 85.36809
Epoch 22, Val Loss: 83.86020
Epoch 23, Val Loss: 89.02361
Epoch 24, Val Loss: 75.24899
Epoch 25, Val Loss: 74.50494
Epoch 26, Val Loss: 75.11557
Epoch 27, Val Loss: 74.51648
Epoch 28, Val Loss: 73.83833
Epoch 29, Val Loss: 73.02231
Epoch 30, Val Loss: 73.53448
Epoch 31, Val Loss: 77.61068
Epoch 32, Val Loss: 71.74846
Epoch 33, Val Loss: 79.37957
Epoch 34, Val Loss: 68.88020
Epoch 35, Val Loss: 69.62794
Epoch 36, Val Loss: 71.61362
Epoch 37, Val Loss: 69.21703
Epoch 38, Val Loss: 71.69510
Epoch 39, Val Loss: 68.69156
Epoch 40, Val Loss: 68.05736
Epoch 41, Val Loss: 73.23386
Epoch 42, Val Loss: 71.09988
Epoch 43, Val Loss: 77.02248
Epoch 44, Val Loss: 71.50920
Epoch 45, Val Loss: 72.84688
Epoch 46, Val Loss: 70.11587
Epoch 47, Val Loss: 75.08678
Epoch 48, Val Loss: 72.43128
Epoch 49, Val Loss: 72.07732
Epoch 50, Val Loss: 69.27974
Epoch 51, Val Loss: 73.01257
Epoch 52, Val Loss: 68.54308
Epoch 53, Val Loss: 73.18681
Epoch 54, Val Loss: 84.58508
Epoch 55, Val Loss: 81.94670
Epoch 56, Val Loss: 75.89966
Epoch 57, Val Loss: 71.72727
Epoch 58, Val Loss: 69.75765
Epoch 59, Val Loss: 71.48185
Epoch 60, Val Loss: 70.95090
Epoch 61, Val Loss: 68.79687
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.94376559023196, 'MSE - std': 7.538121815736765, 'R2 - mean': 0.5043535341924789, 'R2 - std': 0.02766203254594235} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 619.12012
Epoch 1, Val Loss: 443.87457
Epoch 2, Val Loss: 201.95236
Epoch 3, Val Loss: 199.94102
Epoch 4, Val Loss: 178.32294
Epoch 5, Val Loss: 168.24342
Epoch 6, Val Loss: 159.87845
Epoch 7, Val Loss: 129.59143
Epoch 8, Val Loss: 126.88140
Epoch 9, Val Loss: 121.72506
Epoch 10, Val Loss: 108.59917
Epoch 11, Val Loss: 105.51449
Epoch 12, Val Loss: 104.75301
Epoch 13, Val Loss: 109.49728
Epoch 14, Val Loss: 111.92754
Epoch 15, Val Loss: 122.90596
Epoch 16, Val Loss: 99.87691
Epoch 17, Val Loss: 100.95806
Epoch 18, Val Loss: 95.59588
Epoch 19, Val Loss: 96.60860
Epoch 20, Val Loss: 87.75114
Epoch 21, Val Loss: 89.77750
Epoch 22, Val Loss: 90.39637
Epoch 23, Val Loss: 88.31241
Epoch 24, Val Loss: 86.47907
Epoch 25, Val Loss: 82.79157
Epoch 26, Val Loss: 85.57170
Epoch 27, Val Loss: 87.45325
Epoch 28, Val Loss: 90.38493
Epoch 29, Val Loss: 85.43290
Epoch 30, Val Loss: 83.06509
Epoch 31, Val Loss: 83.26958
Epoch 32, Val Loss: 87.85509
Epoch 33, Val Loss: 85.37724
Epoch 34, Val Loss: 85.63818
Epoch 35, Val Loss: 80.80495
Epoch 36, Val Loss: 88.18294
Epoch 37, Val Loss: 82.43927
Epoch 38, Val Loss: 100.54268
Epoch 39, Val Loss: 81.71559
Epoch 40, Val Loss: 79.32539
Epoch 41, Val Loss: 78.83247
Epoch 42, Val Loss: 80.04340
Epoch 43, Val Loss: 83.55955
Epoch 44, Val Loss: 84.64674
Epoch 45, Val Loss: 87.33773
Epoch 46, Val Loss: 77.62769
Epoch 47, Val Loss: 83.19893
Epoch 48, Val Loss: 81.87674
Epoch 49, Val Loss: 80.47023
Epoch 50, Val Loss: 81.21617
Epoch 51, Val Loss: 78.97766
Epoch 52, Val Loss: 100.56871
Epoch 53, Val Loss: 88.03093
Epoch 54, Val Loss: 113.23779
Epoch 55, Val Loss: 82.10400
Epoch 56, Val Loss: 80.69328
Epoch 57, Val Loss: 81.80424
Epoch 58, Val Loss: 85.42046
Epoch 59, Val Loss: 77.65947
Epoch 60, Val Loss: 78.66373
Epoch 61, Val Loss: 79.01219
Epoch 62, Val Loss: 88.45875
Epoch 63, Val Loss: 82.64203
Epoch 64, Val Loss: 81.63560
Epoch 65, Val Loss: 81.39652
Epoch 66, Val Loss: 80.21158
Epoch 67, Val Loss: 89.98405
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.47741890012279, 'MSE - std': 7.86610816514921, 'R2 - mean': 0.494810432591581, 'R2 - std': 0.029105040764870197} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 979.30280
Epoch 1, Val Loss: 537.30518
Epoch 2, Val Loss: 203.48851
Epoch 3, Val Loss: 196.83737
Epoch 4, Val Loss: 185.77692
Epoch 5, Val Loss: 149.20937
Epoch 6, Val Loss: 155.02756
Epoch 7, Val Loss: 119.24523
Epoch 8, Val Loss: 132.77814
Epoch 9, Val Loss: 115.36447
Epoch 10, Val Loss: 121.66689
Epoch 11, Val Loss: 114.79694
Epoch 12, Val Loss: 107.08263
Epoch 13, Val Loss: 109.52762
Epoch 14, Val Loss: 101.37586
Epoch 15, Val Loss: 99.51757
Epoch 16, Val Loss: 104.67475
Epoch 17, Val Loss: 101.35187
Epoch 18, Val Loss: 92.29406
Epoch 19, Val Loss: 103.56573
Epoch 20, Val Loss: 86.51900
Epoch 21, Val Loss: 106.89938
Epoch 22, Val Loss: 96.50190
Epoch 23, Val Loss: 86.41734
Epoch 24, Val Loss: 95.46644
Epoch 25, Val Loss: 89.03745
Epoch 26, Val Loss: 91.08224
Epoch 27, Val Loss: 82.81090
Epoch 28, Val Loss: 81.97150
Epoch 29, Val Loss: 80.65710
Epoch 30, Val Loss: 84.61855
Epoch 31, Val Loss: 91.80092
Epoch 32, Val Loss: 86.90318
Epoch 33, Val Loss: 79.14648
Epoch 34, Val Loss: 88.43678
Epoch 35, Val Loss: 80.18356
Epoch 36, Val Loss: 78.27501
Epoch 37, Val Loss: 76.33255
Epoch 38, Val Loss: 78.34382
Epoch 39, Val Loss: 86.53109
Epoch 40, Val Loss: 78.86365
Epoch 41, Val Loss: 78.38802
Epoch 42, Val Loss: 87.25063
Epoch 43, Val Loss: 77.33440
Epoch 44, Val Loss: 76.62173
Epoch 45, Val Loss: 82.06494
Epoch 46, Val Loss: 74.88365
Epoch 47, Val Loss: 76.60963
Epoch 48, Val Loss: 78.00848
Epoch 49, Val Loss: 76.34045
Epoch 50, Val Loss: 82.47131
Epoch 51, Val Loss: 78.08406
Epoch 52, Val Loss: 80.41641
Epoch 53, Val Loss: 84.85822
Epoch 54, Val Loss: 82.40747
Epoch 55, Val Loss: 80.31631
Epoch 56, Val Loss: 84.96786
Epoch 57, Val Loss: 79.00710
Epoch 58, Val Loss: 81.75290
Epoch 59, Val Loss: 78.82407
Epoch 60, Val Loss: 90.09523
Epoch 61, Val Loss: 80.46217
Epoch 62, Val Loss: 83.05376
Epoch 63, Val Loss: 80.51725
Epoch 64, Val Loss: 80.75856
Epoch 65, Val Loss: 79.06193
Epoch 66, Val Loss: 80.54684
Epoch 67, Val Loss: 89.64610
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.49150375141565, 'MSE - std': 7.306753099322739, 'R2 - mean': 0.499834076374575, 'R2 - std': 0.027903955020273787} 
 

Results After CV: {'MSE - mean': 80.49150375141565, 'MSE - std': 7.306753099322739, 'R2 - mean': 0.499834076374575, 'R2 - std': 0.027903955020273787}
Train time: 375.5324795552002
Inference time: 0.17021094359988637
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 23 finished with value: 80.49150375141565 and parameters: {'p_m': 0.3959412916042278, 'alpha': 3.381724860181893, 'K': 3, 'beta': 8.808809024573081}. Best is trial 3 with value: 78.3667380652227.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 888.12769
Epoch 1, Val Loss: 448.77243
Epoch 2, Val Loss: 205.64716
Epoch 3, Val Loss: 189.66354
Epoch 4, Val Loss: 172.23260
Epoch 5, Val Loss: 147.19383
Epoch 6, Val Loss: 138.32138
Epoch 7, Val Loss: 136.92224
Epoch 8, Val Loss: 130.45615
Epoch 9, Val Loss: 124.78876
Epoch 10, Val Loss: 129.15125
Epoch 11, Val Loss: 123.34548
Epoch 12, Val Loss: 135.26686
Epoch 13, Val Loss: 109.22385
Epoch 14, Val Loss: 99.22655
Epoch 15, Val Loss: 119.25690
Epoch 16, Val Loss: 112.80473
Epoch 17, Val Loss: 108.86752
Epoch 18, Val Loss: 113.85007
Epoch 19, Val Loss: 106.25951
Epoch 20, Val Loss: 96.58981
Epoch 21, Val Loss: 94.86828
Epoch 22, Val Loss: 95.47573
Epoch 23, Val Loss: 91.59942
Epoch 24, Val Loss: 93.47336
Epoch 25, Val Loss: 90.55733
Epoch 26, Val Loss: 98.97463
Epoch 27, Val Loss: 92.41075
Epoch 28, Val Loss: 91.49496
Epoch 29, Val Loss: 91.66623
Epoch 30, Val Loss: 89.29334
Epoch 31, Val Loss: 90.51424
Epoch 32, Val Loss: 96.39826
Epoch 33, Val Loss: 86.91723
Epoch 34, Val Loss: 85.30924
Epoch 35, Val Loss: 87.90883
Epoch 36, Val Loss: 85.25407
Epoch 37, Val Loss: 89.74535
Epoch 38, Val Loss: 83.81243
Epoch 39, Val Loss: 88.82366
Epoch 40, Val Loss: 86.52782
Epoch 41, Val Loss: 86.04068
Epoch 42, Val Loss: 88.90158
Epoch 43, Val Loss: 85.80499
Epoch 44, Val Loss: 90.60362
Epoch 45, Val Loss: 84.15381
Epoch 46, Val Loss: 89.80110
Epoch 47, Val Loss: 86.63528
Epoch 48, Val Loss: 84.32369
Epoch 49, Val Loss: 83.74690
Epoch 50, Val Loss: 86.48041
Epoch 51, Val Loss: 90.45186
Epoch 52, Val Loss: 89.84526
Epoch 53, Val Loss: 88.12623
Epoch 54, Val Loss: 85.60193
Epoch 55, Val Loss: 85.61657
Epoch 56, Val Loss: 85.12410
Epoch 57, Val Loss: 91.89982
Epoch 58, Val Loss: 84.87488
Epoch 59, Val Loss: 84.94928
Epoch 60, Val Loss: 87.89438
Epoch 61, Val Loss: 91.06957
Epoch 62, Val Loss: 84.13625
Epoch 63, Val Loss: 93.39844
Epoch 64, Val Loss: 84.97718
Epoch 65, Val Loss: 92.87958
Epoch 66, Val Loss: 87.14011
Epoch 67, Val Loss: 89.24188
Epoch 68, Val Loss: 86.48657
Epoch 69, Val Loss: 91.81587
Epoch 70, Val Loss: 89.79239
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.99093648310591, 'MSE - std': 0.0, 'R2 - mean': 0.49890220683879094, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 933.13733
Epoch 1, Val Loss: 430.66681
Epoch 2, Val Loss: 193.89963
Epoch 3, Val Loss: 160.46535
Epoch 4, Val Loss: 157.28265
Epoch 5, Val Loss: 144.36195
Epoch 6, Val Loss: 131.18571
Epoch 7, Val Loss: 126.83420
Epoch 8, Val Loss: 113.42249
Epoch 9, Val Loss: 116.49725
Epoch 10, Val Loss: 97.65034
Epoch 11, Val Loss: 92.44615
Epoch 12, Val Loss: 104.31895
Epoch 13, Val Loss: 104.70805
Epoch 14, Val Loss: 106.43977
Epoch 15, Val Loss: 96.66570
Epoch 16, Val Loss: 96.99817
Epoch 17, Val Loss: 88.36983
Epoch 18, Val Loss: 97.04589
Epoch 19, Val Loss: 90.10415
Epoch 20, Val Loss: 83.82351
Epoch 21, Val Loss: 80.43223
Epoch 22, Val Loss: 88.92917
Epoch 23, Val Loss: 86.49152
Epoch 24, Val Loss: 85.53036
Epoch 25, Val Loss: 78.71165
Epoch 26, Val Loss: 77.56603
Epoch 27, Val Loss: 77.01285
Epoch 28, Val Loss: 85.47107
Epoch 29, Val Loss: 74.38883
Epoch 30, Val Loss: 71.54726
Epoch 31, Val Loss: 78.95196
Epoch 32, Val Loss: 72.93275
Epoch 33, Val Loss: 74.27686
Epoch 34, Val Loss: 75.95728
Epoch 35, Val Loss: 77.53393
Epoch 36, Val Loss: 76.02282
Epoch 37, Val Loss: 74.51502
Epoch 38, Val Loss: 71.99226
Epoch 39, Val Loss: 84.56770
Epoch 40, Val Loss: 79.43279
Epoch 41, Val Loss: 70.40297
Epoch 42, Val Loss: 76.26991
Epoch 43, Val Loss: 87.85178
Epoch 44, Val Loss: 76.50655
Epoch 45, Val Loss: 71.93712
Epoch 46, Val Loss: 74.71703
Epoch 47, Val Loss: 70.99075
Epoch 48, Val Loss: 76.01956
Epoch 49, Val Loss: 72.47253
Epoch 50, Val Loss: 73.72539
Epoch 51, Val Loss: 74.25156
Epoch 52, Val Loss: 72.95411
Epoch 53, Val Loss: 72.40921
Epoch 54, Val Loss: 77.56519
Epoch 55, Val Loss: 74.77793
Epoch 56, Val Loss: 71.57691
Epoch 57, Val Loss: 80.56859
Epoch 58, Val Loss: 77.12426
Epoch 59, Val Loss: 71.57365
Epoch 60, Val Loss: 73.90711
Epoch 61, Val Loss: 70.23157
Epoch 62, Val Loss: 71.14314
Epoch 63, Val Loss: 89.45043
Epoch 64, Val Loss: 71.61069
Epoch 65, Val Loss: 78.38390
Epoch 66, Val Loss: 71.20430
Epoch 67, Val Loss: 74.25149
Epoch 68, Val Loss: 74.83765
Epoch 69, Val Loss: 70.89207
Epoch 70, Val Loss: 73.79523
Epoch 71, Val Loss: 72.23101
Epoch 72, Val Loss: 72.85051
Epoch 73, Val Loss: 73.70256
Epoch 74, Val Loss: 81.44827
Epoch 75, Val Loss: 84.61589
Epoch 76, Val Loss: 74.04285
Epoch 77, Val Loss: 77.73179
Epoch 78, Val Loss: 74.00764
Epoch 79, Val Loss: 80.94748
Epoch 80, Val Loss: 72.49329
Epoch 81, Val Loss: 80.75840
Epoch 82, Val Loss: 72.05960
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.98385183355586, 'MSE - std': 4.007084649550059, 'R2 - mean': 0.5007059732734197, 'R2 - std': 0.0018037664346287618} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 791.52258
Epoch 1, Val Loss: 514.76495
Epoch 2, Val Loss: 189.05099
Epoch 3, Val Loss: 180.30632
Epoch 4, Val Loss: 183.20891
Epoch 5, Val Loss: 135.05005
Epoch 6, Val Loss: 117.30760
Epoch 7, Val Loss: 119.64899
Epoch 8, Val Loss: 101.06586
Epoch 9, Val Loss: 105.19729
Epoch 10, Val Loss: 116.14771
Epoch 11, Val Loss: 103.56601
Epoch 12, Val Loss: 103.49738
Epoch 13, Val Loss: 90.40306
Epoch 14, Val Loss: 93.69392
Epoch 15, Val Loss: 97.33452
Epoch 16, Val Loss: 88.64686
Epoch 17, Val Loss: 92.61811
Epoch 18, Val Loss: 80.02550
Epoch 19, Val Loss: 80.28817
Epoch 20, Val Loss: 81.37486
Epoch 21, Val Loss: 82.40717
Epoch 22, Val Loss: 82.57418
Epoch 23, Val Loss: 80.78239
Epoch 24, Val Loss: 74.87703
Epoch 25, Val Loss: 83.91573
Epoch 26, Val Loss: 70.05270
Epoch 27, Val Loss: 78.21634
Epoch 28, Val Loss: 82.32874
Epoch 29, Val Loss: 67.91273
Epoch 30, Val Loss: 74.38481
Epoch 31, Val Loss: 72.51999
Epoch 32, Val Loss: 76.33014
Epoch 33, Val Loss: 69.90102
Epoch 34, Val Loss: 70.24702
Epoch 35, Val Loss: 70.68391
Epoch 36, Val Loss: 69.36002
Epoch 37, Val Loss: 76.01962
Epoch 38, Val Loss: 68.42172
Epoch 39, Val Loss: 77.00644
Epoch 40, Val Loss: 69.78508
Epoch 41, Val Loss: 68.72975
Epoch 42, Val Loss: 69.93546
Epoch 43, Val Loss: 72.42097
Epoch 44, Val Loss: 69.02993
Epoch 45, Val Loss: 77.34441
Epoch 46, Val Loss: 77.32227
Epoch 47, Val Loss: 67.77625
Epoch 48, Val Loss: 66.17094
Epoch 49, Val Loss: 70.48878
Epoch 50, Val Loss: 72.21094
Epoch 51, Val Loss: 75.40989
Epoch 52, Val Loss: 72.01107
Epoch 53, Val Loss: 80.19838
Epoch 54, Val Loss: 71.40569
Epoch 55, Val Loss: 76.36842
Epoch 56, Val Loss: 79.59016
Epoch 57, Val Loss: 71.61528
Epoch 58, Val Loss: 68.08401
Epoch 59, Val Loss: 73.79591
Epoch 60, Val Loss: 72.32421
Epoch 61, Val Loss: 81.57010
Epoch 62, Val Loss: 70.08260
Epoch 63, Val Loss: 76.61559
Epoch 64, Val Loss: 79.43705
Epoch 65, Val Loss: 72.47115
Epoch 66, Val Loss: 69.35079
Epoch 67, Val Loss: 82.52468
Epoch 68, Val Loss: 69.43865
Epoch 69, Val Loss: 68.81070
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.19919933614868, 'MSE - std': 7.516001860541451, 'R2 - mean': 0.5156211467363249, 'R2 - std': 0.02114459381869435} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 865.12451
Epoch 1, Val Loss: 409.29956
Epoch 2, Val Loss: 188.56012
Epoch 3, Val Loss: 182.57031
Epoch 4, Val Loss: 164.18282
Epoch 5, Val Loss: 145.19678
Epoch 6, Val Loss: 125.33094
Epoch 7, Val Loss: 131.60570
Epoch 8, Val Loss: 121.42258
Epoch 9, Val Loss: 121.54904
Epoch 10, Val Loss: 122.02967
Epoch 11, Val Loss: 109.41276
Epoch 12, Val Loss: 106.92227
Epoch 13, Val Loss: 115.56998
Epoch 14, Val Loss: 127.71141
Epoch 15, Val Loss: 113.04980
Epoch 16, Val Loss: 106.29022
Epoch 17, Val Loss: 100.90547
Epoch 18, Val Loss: 94.94353
Epoch 19, Val Loss: 93.18610
Epoch 20, Val Loss: 96.28575
Epoch 21, Val Loss: 95.98969
Epoch 22, Val Loss: 88.84007
Epoch 23, Val Loss: 92.33914
Epoch 24, Val Loss: 86.82531
Epoch 25, Val Loss: 95.07878
Epoch 26, Val Loss: 91.14582
Epoch 27, Val Loss: 86.28130
Epoch 28, Val Loss: 82.38630
Epoch 29, Val Loss: 89.64532
Epoch 30, Val Loss: 79.20306
Epoch 31, Val Loss: 78.89526
Epoch 32, Val Loss: 83.28078
Epoch 33, Val Loss: 81.95504
Epoch 34, Val Loss: 82.00959
Epoch 35, Val Loss: 81.51154
Epoch 36, Val Loss: 81.41153
Epoch 37, Val Loss: 82.12455
Epoch 38, Val Loss: 90.51833
Epoch 39, Val Loss: 81.72955
Epoch 40, Val Loss: 81.48428
Epoch 41, Val Loss: 87.61364
Epoch 42, Val Loss: 83.12624
Epoch 43, Val Loss: 81.03611
Epoch 44, Val Loss: 83.05049
Epoch 45, Val Loss: 81.34245
Epoch 46, Val Loss: 81.94796
Epoch 47, Val Loss: 85.85778
Epoch 48, Val Loss: 80.73479
Epoch 49, Val Loss: 81.63772
Epoch 50, Val Loss: 85.40080
Epoch 51, Val Loss: 84.23622
Epoch 52, Val Loss: 85.94983
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.5829721937177, 'MSE - std': 8.758850908116257, 'R2 - mean': 0.5007803013788099, 'R2 - std': 0.03156061562446464} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1170.80054
Epoch 1, Val Loss: 510.69797
Epoch 2, Val Loss: 194.24251
Epoch 3, Val Loss: 160.73943
Epoch 4, Val Loss: 170.22591
Epoch 5, Val Loss: 142.49445
Epoch 6, Val Loss: 161.40744
Epoch 7, Val Loss: 114.07501
Epoch 8, Val Loss: 134.51184
Epoch 9, Val Loss: 111.47228
Epoch 10, Val Loss: 114.22293
Epoch 11, Val Loss: 109.77120
Epoch 12, Val Loss: 132.76999
Epoch 13, Val Loss: 118.44362
Epoch 14, Val Loss: 95.82775
Epoch 15, Val Loss: 102.67506
Epoch 16, Val Loss: 126.11961
Epoch 17, Val Loss: 99.56778
Epoch 18, Val Loss: 97.96759
Epoch 19, Val Loss: 106.41270
Epoch 20, Val Loss: 95.18007
Epoch 21, Val Loss: 85.00296
Epoch 22, Val Loss: 100.47644
Epoch 23, Val Loss: 87.73956
Epoch 24, Val Loss: 91.43382
Epoch 25, Val Loss: 83.30274
Epoch 26, Val Loss: 103.97648
Epoch 27, Val Loss: 87.54095
Epoch 28, Val Loss: 90.01584
Epoch 29, Val Loss: 78.87755
Epoch 30, Val Loss: 86.76668
Epoch 31, Val Loss: 83.38234
Epoch 32, Val Loss: 100.20947
Epoch 33, Val Loss: 75.97746
Epoch 34, Val Loss: 76.46130
Epoch 35, Val Loss: 82.81362
Epoch 36, Val Loss: 87.60139
Epoch 37, Val Loss: 82.27640
Epoch 38, Val Loss: 76.86046
Epoch 39, Val Loss: 74.66559
Epoch 40, Val Loss: 77.63947
Epoch 41, Val Loss: 79.12917
Epoch 42, Val Loss: 76.57913
Epoch 43, Val Loss: 81.24758
Epoch 44, Val Loss: 76.47076
Epoch 45, Val Loss: 75.65119
Epoch 46, Val Loss: 77.95644
Epoch 47, Val Loss: 79.73189
Epoch 48, Val Loss: 75.72790
Epoch 49, Val Loss: 78.13901
Epoch 50, Val Loss: 73.50014
Epoch 51, Val Loss: 79.98984
Epoch 52, Val Loss: 77.58482
Epoch 53, Val Loss: 71.80533
Epoch 54, Val Loss: 78.79311
Epoch 55, Val Loss: 74.55618
Epoch 56, Val Loss: 77.58743
Epoch 57, Val Loss: 76.70181
Epoch 58, Val Loss: 75.00887
Epoch 59, Val Loss: 75.86613
Epoch 60, Val Loss: 76.38403
Epoch 61, Val Loss: 76.25961
Epoch 62, Val Loss: 83.16533
Epoch 63, Val Loss: 74.92005
Epoch 64, Val Loss: 78.61195
Epoch 65, Val Loss: 77.00203
Epoch 66, Val Loss: 83.39667
Epoch 67, Val Loss: 79.07389
Epoch 68, Val Loss: 74.08722
Epoch 69, Val Loss: 82.59335
Epoch 70, Val Loss: 78.31711
Epoch 71, Val Loss: 78.21805
Epoch 72, Val Loss: 75.70309
Epoch 73, Val Loss: 83.13869
Epoch 74, Val Loss: 78.11622
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.27088697213892, 'MSE - std': 8.261975907688718, 'R2 - mean': 0.507777461747954, 'R2 - std': 0.03150712585753015} 
 

Results After CV: {'MSE - mean': 79.27088697213892, 'MSE - std': 8.261975907688718, 'R2 - mean': 0.507777461747954, 'R2 - std': 0.03150712585753015}
Train time: 418.0316305598
Inference time: 0.18120661040011327
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 24 finished with value: 79.27088697213892 and parameters: {'p_m': 0.43744213850737423, 'alpha': 3.947606454814653, 'K': 3, 'beta': 6.835459451589694}. Best is trial 3 with value: 78.3667380652227.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 450.31876
Epoch 1, Val Loss: 303.64651
Epoch 2, Val Loss: 198.63367
Epoch 3, Val Loss: 166.03886
Epoch 4, Val Loss: 150.19647
Epoch 5, Val Loss: 121.23946
Epoch 6, Val Loss: 119.88806
Epoch 7, Val Loss: 113.89247
Epoch 8, Val Loss: 109.20213
Epoch 9, Val Loss: 109.88866
Epoch 10, Val Loss: 107.37321
Epoch 11, Val Loss: 107.72260
Epoch 12, Val Loss: 111.55800
Epoch 13, Val Loss: 104.04749
Epoch 14, Val Loss: 103.69382
Epoch 15, Val Loss: 105.23064
Epoch 16, Val Loss: 112.70433
Epoch 17, Val Loss: 110.82175
Epoch 18, Val Loss: 103.10859
Epoch 19, Val Loss: 105.85367
Epoch 20, Val Loss: 105.72620
Epoch 21, Val Loss: 108.50185
Epoch 22, Val Loss: 105.69744
Epoch 23, Val Loss: 111.18368
Epoch 24, Val Loss: 120.64941
Epoch 25, Val Loss: 104.54478
Epoch 26, Val Loss: 100.80692
Epoch 27, Val Loss: 111.07833
Epoch 28, Val Loss: 95.42381
Epoch 29, Val Loss: 102.12115
Epoch 30, Val Loss: 105.95255
Epoch 31, Val Loss: 108.64945
Epoch 32, Val Loss: 100.81996
Epoch 33, Val Loss: 103.42742
Epoch 34, Val Loss: 99.28025
Epoch 35, Val Loss: 97.10379
Epoch 36, Val Loss: 100.20470
Epoch 37, Val Loss: 91.29661
Epoch 38, Val Loss: 96.57066
Epoch 39, Val Loss: 102.34082
Epoch 40, Val Loss: 103.15379
Epoch 41, Val Loss: 93.85605
Epoch 42, Val Loss: 93.80222
Epoch 43, Val Loss: 99.66837
Epoch 44, Val Loss: 95.17851
Epoch 45, Val Loss: 101.07768
Epoch 46, Val Loss: 90.05389
Epoch 47, Val Loss: 96.91544
Epoch 48, Val Loss: 103.61543
Epoch 49, Val Loss: 89.94561
Epoch 50, Val Loss: 93.81085
Epoch 51, Val Loss: 88.24268
Epoch 52, Val Loss: 91.35251
Epoch 53, Val Loss: 96.85197
Epoch 54, Val Loss: 92.42400
Epoch 55, Val Loss: 93.69732
Epoch 56, Val Loss: 85.73027
Epoch 57, Val Loss: 101.41798
Epoch 58, Val Loss: 109.74760
Epoch 59, Val Loss: 89.17657
Epoch 60, Val Loss: 89.38319
Epoch 61, Val Loss: 96.17925
Epoch 62, Val Loss: 86.68175
Epoch 63, Val Loss: 90.35734
Epoch 64, Val Loss: 83.54775
Epoch 65, Val Loss: 85.98572
Epoch 66, Val Loss: 88.62512
Epoch 67, Val Loss: 85.16844
Epoch 68, Val Loss: 89.08939
Epoch 69, Val Loss: 85.81531
Epoch 70, Val Loss: 85.23812
Epoch 71, Val Loss: 92.77006
Epoch 72, Val Loss: 83.73948
Epoch 73, Val Loss: 87.91302
Epoch 74, Val Loss: 87.25752
Epoch 75, Val Loss: 84.44806
Epoch 76, Val Loss: 92.89423
Epoch 77, Val Loss: 88.62160
Epoch 78, Val Loss: 81.75626
Epoch 79, Val Loss: 81.54977
Epoch 80, Val Loss: 92.30184
Epoch 81, Val Loss: 83.90295
Epoch 82, Val Loss: 85.48027
Epoch 83, Val Loss: 84.01599
Epoch 84, Val Loss: 86.25872
Epoch 85, Val Loss: 94.56293
Epoch 86, Val Loss: 85.68976
Epoch 87, Val Loss: 87.26961
Epoch 88, Val Loss: 87.74995
Epoch 89, Val Loss: 90.54873
Epoch 90, Val Loss: 83.05939
Epoch 91, Val Loss: 85.45926
Epoch 92, Val Loss: 90.27919
Epoch 93, Val Loss: 84.90918
Epoch 94, Val Loss: 82.82739
Epoch 95, Val Loss: 87.11268
Epoch 96, Val Loss: 88.16045
Epoch 97, Val Loss: 82.98355
Epoch 98, Val Loss: 88.04475
Epoch 99, Val Loss: 83.81879
DID NOT SAVE RESULTS
{'MSE - mean': 86.09627986121427, 'MSE - std': 0.0, 'R2 - mean': 0.49828833593037714, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 599.80194
Epoch 1, Val Loss: 453.04395
Epoch 2, Val Loss: 149.01160
Epoch 3, Val Loss: 129.87599
Epoch 4, Val Loss: 112.13099
Epoch 5, Val Loss: 107.22240
Epoch 6, Val Loss: 93.35469
Epoch 7, Val Loss: 102.91503
Epoch 8, Val Loss: 111.99990
Epoch 9, Val Loss: 88.53076
Epoch 10, Val Loss: 87.88297
Epoch 11, Val Loss: 91.87483
Epoch 12, Val Loss: 99.29114
Epoch 13, Val Loss: 95.38557
Epoch 14, Val Loss: 85.00286
Epoch 15, Val Loss: 80.29131
Epoch 16, Val Loss: 80.60844
Epoch 17, Val Loss: 80.83281
Epoch 18, Val Loss: 85.08609
Epoch 19, Val Loss: 92.36340
Epoch 20, Val Loss: 85.56132
Epoch 21, Val Loss: 88.94975
Epoch 22, Val Loss: 80.69407
Epoch 23, Val Loss: 76.71740
Epoch 24, Val Loss: 96.57017
Epoch 25, Val Loss: 79.93280
Epoch 26, Val Loss: 85.81501
Epoch 27, Val Loss: 77.21598
Epoch 28, Val Loss: 75.61735
Epoch 29, Val Loss: 82.61728
Epoch 30, Val Loss: 96.31079
Epoch 31, Val Loss: 81.94546
Epoch 32, Val Loss: 80.79327
Epoch 33, Val Loss: 83.73553
Epoch 34, Val Loss: 78.55911
Epoch 35, Val Loss: 82.79502
Epoch 36, Val Loss: 91.01492
Epoch 37, Val Loss: 83.07281
Epoch 38, Val Loss: 76.07301
Epoch 39, Val Loss: 83.96309
Epoch 40, Val Loss: 73.24197
Epoch 41, Val Loss: 87.67986
Epoch 42, Val Loss: 96.79330
Epoch 43, Val Loss: 74.95089
Epoch 44, Val Loss: 78.69165
Epoch 45, Val Loss: 73.81605
Epoch 46, Val Loss: 79.08128
Epoch 47, Val Loss: 78.50499
Epoch 48, Val Loss: 79.05187
Epoch 49, Val Loss: 74.24155
Epoch 50, Val Loss: 85.13306
Epoch 51, Val Loss: 76.80354
Epoch 52, Val Loss: 74.11826
Epoch 53, Val Loss: 78.51462
Epoch 54, Val Loss: 75.57864
Epoch 55, Val Loss: 84.40495
Epoch 56, Val Loss: 83.59161
Epoch 57, Val Loss: 74.01942
Epoch 58, Val Loss: 73.01384
Epoch 59, Val Loss: 74.34120
Epoch 60, Val Loss: 72.15765
Epoch 61, Val Loss: 74.19940
Epoch 62, Val Loss: 82.95268
Epoch 63, Val Loss: 75.48126
Epoch 64, Val Loss: 75.70950
Epoch 65, Val Loss: 80.46977
Epoch 66, Val Loss: 75.58696
Epoch 67, Val Loss: 76.54797
Epoch 68, Val Loss: 92.49699
Epoch 69, Val Loss: 70.81219
Epoch 70, Val Loss: 78.51319
Epoch 71, Val Loss: 72.86870
Epoch 72, Val Loss: 73.99066
Epoch 73, Val Loss: 69.74201
Epoch 74, Val Loss: 77.79455
Epoch 75, Val Loss: 77.56735
Epoch 76, Val Loss: 68.97264
Epoch 77, Val Loss: 74.80714
Epoch 78, Val Loss: 70.75356
Epoch 79, Val Loss: 71.38734
Epoch 80, Val Loss: 74.35092
Epoch 81, Val Loss: 79.25613
Epoch 82, Val Loss: 71.22971
Epoch 83, Val Loss: 76.07764
Epoch 84, Val Loss: 70.74476
Epoch 85, Val Loss: 69.54280
Epoch 86, Val Loss: 75.85330
Epoch 87, Val Loss: 73.76916
Epoch 88, Val Loss: 76.43225
Epoch 89, Val Loss: 72.80045
Epoch 90, Val Loss: 73.84513
Epoch 91, Val Loss: 73.66441
Epoch 92, Val Loss: 68.64841
Epoch 93, Val Loss: 72.50392
Epoch 94, Val Loss: 73.18109
Epoch 95, Val Loss: 75.46833
Epoch 96, Val Loss: 82.42534
Epoch 97, Val Loss: 78.40927
Epoch 98, Val Loss: 82.19554
Epoch 99, Val Loss: 74.35470
DID NOT SAVE RESULTS
{'MSE - mean': 80.96770526587795, 'MSE - std': 5.12857459533631, 'R2 - mean': 0.5072180775402579, 'R2 - std': 0.008929741609880804} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1162.41479
Epoch 1, Val Loss: 401.80789
Epoch 2, Val Loss: 148.64606
Epoch 3, Val Loss: 115.91631
Epoch 4, Val Loss: 107.96945
Epoch 5, Val Loss: 108.39312
Epoch 6, Val Loss: 90.87727
Epoch 7, Val Loss: 90.52364
Epoch 8, Val Loss: 84.72838
Epoch 9, Val Loss: 82.04900
Epoch 10, Val Loss: 87.96080
Epoch 11, Val Loss: 91.28599
Epoch 12, Val Loss: 81.34434
Epoch 13, Val Loss: 81.34128
Epoch 14, Val Loss: 87.23692
Epoch 15, Val Loss: 86.01942
Epoch 16, Val Loss: 81.44083
Epoch 17, Val Loss: 81.40747
Epoch 18, Val Loss: 83.73508
Epoch 19, Val Loss: 80.71613
Epoch 20, Val Loss: 78.39643
Epoch 21, Val Loss: 87.64100
Epoch 22, Val Loss: 81.10683
Epoch 23, Val Loss: 78.69930
Epoch 24, Val Loss: 81.20612
Epoch 25, Val Loss: 91.67237
Epoch 26, Val Loss: 84.11781
Epoch 27, Val Loss: 90.51642
Epoch 28, Val Loss: 85.99068
Epoch 29, Val Loss: 91.11029
Epoch 30, Val Loss: 80.61254
Epoch 31, Val Loss: 76.22598
Epoch 32, Val Loss: 82.17582
Epoch 33, Val Loss: 81.65382
Epoch 34, Val Loss: 87.89783
Epoch 35, Val Loss: 90.98987
Epoch 36, Val Loss: 82.25582
Epoch 37, Val Loss: 83.59715
Epoch 38, Val Loss: 80.65637
Epoch 39, Val Loss: 85.29658
Epoch 40, Val Loss: 82.26895
Epoch 41, Val Loss: 73.87822
Epoch 42, Val Loss: 83.45148
Epoch 43, Val Loss: 79.67853
Epoch 44, Val Loss: 78.13804
Epoch 45, Val Loss: 79.96185
Epoch 46, Val Loss: 79.35098
Epoch 47, Val Loss: 79.37752
Epoch 48, Val Loss: 81.53545
Epoch 49, Val Loss: 87.80135
Epoch 50, Val Loss: 73.27560
Epoch 51, Val Loss: 77.65742
Epoch 52, Val Loss: 76.07154
Epoch 53, Val Loss: 76.32477
Epoch 54, Val Loss: 73.01484
Epoch 55, Val Loss: 72.10227
Epoch 56, Val Loss: 72.82308
Epoch 57, Val Loss: 69.12570
Epoch 58, Val Loss: 73.14458
Epoch 59, Val Loss: 73.41673
Epoch 60, Val Loss: 77.82593
Epoch 61, Val Loss: 67.77330
Epoch 62, Val Loss: 69.73752
Epoch 63, Val Loss: 69.34702
Epoch 64, Val Loss: 72.67984
Epoch 65, Val Loss: 75.36968
Epoch 66, Val Loss: 69.30441
Epoch 67, Val Loss: 73.69685
Epoch 68, Val Loss: 74.62161
Epoch 69, Val Loss: 77.44546
Epoch 70, Val Loss: 69.13625
Epoch 71, Val Loss: 69.45389
Epoch 72, Val Loss: 73.07871
Epoch 73, Val Loss: 71.63622
Epoch 74, Val Loss: 69.41671
Epoch 75, Val Loss: 71.60733
Epoch 76, Val Loss: 69.42278
Epoch 77, Val Loss: 71.08928
Epoch 78, Val Loss: 76.17986
Epoch 79, Val Loss: 71.79221
Epoch 80, Val Loss: 72.60521
Epoch 81, Val Loss: 72.36517
Epoch 82, Val Loss: 70.10824
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.58893661226692, 'MSE - std': 7.475431855773453, 'R2 - mean': 0.5195111033618888, 'R2 - std': 0.018851980210278195} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 876.93237
Epoch 1, Val Loss: 410.67856
Epoch 2, Val Loss: 153.51820
Epoch 3, Val Loss: 146.04204
Epoch 4, Val Loss: 121.95583
Epoch 5, Val Loss: 119.21667
Epoch 6, Val Loss: 108.02581
Epoch 7, Val Loss: 101.12949
Epoch 8, Val Loss: 97.95472
Epoch 9, Val Loss: 102.38741
Epoch 10, Val Loss: 105.35603
Epoch 11, Val Loss: 97.20865
Epoch 12, Val Loss: 99.39044
Epoch 13, Val Loss: 94.91487
Epoch 14, Val Loss: 96.10000
Epoch 15, Val Loss: 96.69553
Epoch 16, Val Loss: 96.68008
Epoch 17, Val Loss: 99.78991
Epoch 18, Val Loss: 93.31940
Epoch 19, Val Loss: 90.69043
Epoch 20, Val Loss: 95.02467
Epoch 21, Val Loss: 85.40675
Epoch 22, Val Loss: 99.62909
Epoch 23, Val Loss: 97.44750
Epoch 24, Val Loss: 103.43166
Epoch 25, Val Loss: 97.10031
Epoch 26, Val Loss: 93.14825
Epoch 27, Val Loss: 88.89106
Epoch 28, Val Loss: 91.46927
Epoch 29, Val Loss: 94.69331
Epoch 30, Val Loss: 86.92816
Epoch 31, Val Loss: 89.40745
Epoch 32, Val Loss: 89.94856
Epoch 33, Val Loss: 90.75935
Epoch 34, Val Loss: 91.94599
Epoch 35, Val Loss: 92.54481
Epoch 36, Val Loss: 83.86676
Epoch 37, Val Loss: 92.66245
Epoch 38, Val Loss: 85.37749
Epoch 39, Val Loss: 91.09380
Epoch 40, Val Loss: 82.60827
Epoch 41, Val Loss: 81.17964
Epoch 42, Val Loss: 86.14753
Epoch 43, Val Loss: 92.78979
Epoch 44, Val Loss: 86.98589
Epoch 45, Val Loss: 97.45197
Epoch 46, Val Loss: 86.65659
Epoch 47, Val Loss: 81.59154
Epoch 48, Val Loss: 84.08469
Epoch 49, Val Loss: 86.84879
Epoch 50, Val Loss: 97.98489
Epoch 51, Val Loss: 86.66416
Epoch 52, Val Loss: 81.95406
Epoch 53, Val Loss: 82.20133
Epoch 54, Val Loss: 79.16788
Epoch 55, Val Loss: 83.16676
Epoch 56, Val Loss: 82.11303
Epoch 57, Val Loss: 79.25737
Epoch 58, Val Loss: 83.50905
Epoch 59, Val Loss: 80.41962
Epoch 60, Val Loss: 79.69801
Epoch 61, Val Loss: 77.28896
Epoch 62, Val Loss: 80.98625
Epoch 63, Val Loss: 78.64192
Epoch 64, Val Loss: 91.65866
Epoch 65, Val Loss: 79.02978
Epoch 66, Val Loss: 83.64085
Epoch 67, Val Loss: 86.38142
Epoch 68, Val Loss: 78.46291
Epoch 69, Val Loss: 85.31859
Epoch 70, Val Loss: 80.17980
Epoch 71, Val Loss: 81.36405
Epoch 72, Val Loss: 79.87605
Epoch 73, Val Loss: 80.71085
Epoch 74, Val Loss: 78.52707
Epoch 75, Val Loss: 77.13374
Epoch 76, Val Loss: 77.64794
Epoch 77, Val Loss: 86.88097
Epoch 78, Val Loss: 79.89942
Epoch 79, Val Loss: 95.52240
Epoch 80, Val Loss: 83.49955
Epoch 81, Val Loss: 76.30341
Epoch 82, Val Loss: 78.99709
Epoch 83, Val Loss: 78.44099
Epoch 84, Val Loss: 76.34788
Epoch 85, Val Loss: 92.83755
Epoch 86, Val Loss: 78.32143
Epoch 87, Val Loss: 80.00822
Epoch 88, Val Loss: 76.63618
Epoch 89, Val Loss: 82.68132
Epoch 90, Val Loss: 77.87210
Epoch 91, Val Loss: 78.42550
Epoch 92, Val Loss: 79.80028
Epoch 93, Val Loss: 82.73486
Epoch 94, Val Loss: 87.48773
Epoch 95, Val Loss: 78.83243
Epoch 96, Val Loss: 81.41281
Epoch 97, Val Loss: 77.22029
Epoch 98, Val Loss: 83.06400
Epoch 99, Val Loss: 80.47131
DID NOT SAVE RESULTS
{'MSE - mean': 78.96217428784152, 'MSE - std': 7.668659091851364, 'R2 - mean': 0.5106678686532566, 'R2 - std': 0.022386519799254406} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1197.20190
Epoch 1, Val Loss: 395.09598
Epoch 2, Val Loss: 163.91283
Epoch 3, Val Loss: 134.49878
Epoch 4, Val Loss: 119.79263
Epoch 5, Val Loss: 110.25029
Epoch 6, Val Loss: 115.83862
Epoch 7, Val Loss: 112.10238
Epoch 8, Val Loss: 106.97929
Epoch 9, Val Loss: 101.88857
Epoch 10, Val Loss: 99.96575
Epoch 11, Val Loss: 102.23273
Epoch 12, Val Loss: 105.48659
Epoch 13, Val Loss: 111.10822
Epoch 14, Val Loss: 102.74748
Epoch 15, Val Loss: 95.56830
Epoch 16, Val Loss: 89.01073
Epoch 17, Val Loss: 89.33382
Epoch 18, Val Loss: 86.71350
Epoch 19, Val Loss: 100.73781
Epoch 20, Val Loss: 88.32027
Epoch 21, Val Loss: 92.25836
Epoch 22, Val Loss: 105.40697
Epoch 23, Val Loss: 116.96143
Epoch 24, Val Loss: 95.39324
Epoch 25, Val Loss: 94.11464
Epoch 26, Val Loss: 102.09880
Epoch 27, Val Loss: 84.13945
Epoch 28, Val Loss: 87.61993
Epoch 29, Val Loss: 96.30859
Epoch 30, Val Loss: 86.09153
Epoch 31, Val Loss: 94.27569
Epoch 32, Val Loss: 100.46178
Epoch 33, Val Loss: 97.98441
Epoch 34, Val Loss: 92.87109
Epoch 35, Val Loss: 88.46831
Epoch 36, Val Loss: 100.73582
Epoch 37, Val Loss: 87.50380
Epoch 38, Val Loss: 99.75828
Epoch 39, Val Loss: 97.25423
Epoch 40, Val Loss: 95.08028
Epoch 41, Val Loss: 93.46008
Epoch 42, Val Loss: 88.26183
Epoch 43, Val Loss: 96.54566
Epoch 44, Val Loss: 84.76334
Epoch 45, Val Loss: 83.81480
Epoch 46, Val Loss: 91.02003
Epoch 47, Val Loss: 90.91216
Epoch 48, Val Loss: 86.75153
Epoch 49, Val Loss: 85.66415
Epoch 50, Val Loss: 90.74022
Epoch 51, Val Loss: 82.75243
Epoch 52, Val Loss: 83.39816
Epoch 53, Val Loss: 84.07477
Epoch 54, Val Loss: 82.50508
Epoch 55, Val Loss: 89.38762
Epoch 56, Val Loss: 85.35432
Epoch 57, Val Loss: 80.41563
Epoch 58, Val Loss: 79.17674
Epoch 59, Val Loss: 80.01801
Epoch 60, Val Loss: 79.37290
Epoch 61, Val Loss: 90.05278
Epoch 62, Val Loss: 95.91545
Epoch 63, Val Loss: 79.46764
Epoch 64, Val Loss: 77.32672
Epoch 65, Val Loss: 82.98911
Epoch 66, Val Loss: 81.24490
Epoch 67, Val Loss: 92.69336
Epoch 68, Val Loss: 80.39977
Epoch 69, Val Loss: 75.56255
Epoch 70, Val Loss: 74.31220
Epoch 71, Val Loss: 78.77568
Epoch 72, Val Loss: 78.82014
Epoch 73, Val Loss: 77.56947
Epoch 74, Val Loss: 78.07341
Epoch 75, Val Loss: 76.97240
Epoch 76, Val Loss: 74.08256
Epoch 77, Val Loss: 76.83218
Epoch 78, Val Loss: 81.49254
Epoch 79, Val Loss: 78.43739
Epoch 80, Val Loss: 78.14881
Epoch 81, Val Loss: 77.52767
Epoch 82, Val Loss: 76.39613
Epoch 83, Val Loss: 81.51889
Epoch 84, Val Loss: 81.43713
Epoch 85, Val Loss: 75.83224
Epoch 86, Val Loss: 75.66111
Epoch 87, Val Loss: 73.23913
Epoch 88, Val Loss: 77.37267
Epoch 89, Val Loss: 74.87615
Epoch 90, Val Loss: 87.06411
Epoch 91, Val Loss: 76.07162
Epoch 92, Val Loss: 77.59929
Epoch 93, Val Loss: 76.27052
Epoch 94, Val Loss: 72.93201
Epoch 95, Val Loss: 73.11515
Epoch 96, Val Loss: 91.92949
Epoch 97, Val Loss: 76.52296
Epoch 98, Val Loss: 76.36726
Epoch 99, Val Loss: 77.08973
DID NOT SAVE RESULTS
{'MSE - mean': 77.85177176700307, 'MSE - std': 7.209621408005081, 'R2 - mean': 0.5164556318033847, 'R2 - std': 0.02312829055736392} 
 

Results After CV: {'MSE - mean': 77.85177176700307, 'MSE - std': 7.209621408005081, 'R2 - mean': 0.5164556318033847, 'R2 - std': 0.02312829055736392}
Train time: 930.702071536001
Inference time: 0.16583930720007628
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 25 finished with value: 77.85177176700307 and parameters: {'p_m': 0.20004938218927543, 'alpha': 5.617200231768984, 'K': 5, 'beta': 6.046971185928288}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 932.67566
Epoch 1, Val Loss: 404.79651
Epoch 2, Val Loss: 167.46057
Epoch 3, Val Loss: 155.79932
Epoch 4, Val Loss: 137.52103
Epoch 5, Val Loss: 124.81317
Epoch 6, Val Loss: 128.79416
Epoch 7, Val Loss: 110.11562
Epoch 8, Val Loss: 115.98702
Epoch 9, Val Loss: 105.81279
Epoch 10, Val Loss: 106.21042
Epoch 11, Val Loss: 94.97648
Epoch 12, Val Loss: 97.41415
Epoch 13, Val Loss: 103.61012
Epoch 14, Val Loss: 99.77904
Epoch 15, Val Loss: 101.12794
Epoch 16, Val Loss: 96.10114
Epoch 17, Val Loss: 98.73244
Epoch 18, Val Loss: 103.82391
Epoch 19, Val Loss: 106.97395
Epoch 20, Val Loss: 100.86642
Epoch 21, Val Loss: 101.31586
Epoch 22, Val Loss: 100.45705
Epoch 23, Val Loss: 96.78560
Epoch 24, Val Loss: 106.35940
Epoch 25, Val Loss: 93.77994
Epoch 26, Val Loss: 102.95460
Epoch 27, Val Loss: 97.88939
Epoch 28, Val Loss: 103.62064
Epoch 29, Val Loss: 103.57566
Epoch 30, Val Loss: 100.36589
Epoch 31, Val Loss: 97.57783
Epoch 32, Val Loss: 107.88132
Epoch 33, Val Loss: 95.93212
Epoch 34, Val Loss: 99.89546
Epoch 35, Val Loss: 96.54856
Epoch 36, Val Loss: 99.60542
Epoch 37, Val Loss: 98.65038
Epoch 38, Val Loss: 96.94603
Epoch 39, Val Loss: 96.22546
Epoch 40, Val Loss: 103.25645
Epoch 41, Val Loss: 103.12397
Epoch 42, Val Loss: 96.17564
Epoch 43, Val Loss: 94.31083
Epoch 44, Val Loss: 91.48181
Epoch 45, Val Loss: 89.99579
Epoch 46, Val Loss: 94.00034
Epoch 47, Val Loss: 89.12632
Epoch 48, Val Loss: 88.48579
Epoch 49, Val Loss: 86.84921
Epoch 50, Val Loss: 86.68443
Epoch 51, Val Loss: 87.05412
Epoch 52, Val Loss: 90.34123
Epoch 53, Val Loss: 84.27762
Epoch 54, Val Loss: 86.31590
Epoch 55, Val Loss: 85.72415
Epoch 56, Val Loss: 96.12801
Epoch 57, Val Loss: 87.60995
Epoch 58, Val Loss: 87.53909
Epoch 59, Val Loss: 92.64474
Epoch 60, Val Loss: 91.72595
Epoch 61, Val Loss: 100.14859
Epoch 62, Val Loss: 84.22025
Epoch 63, Val Loss: 83.20824
Epoch 64, Val Loss: 86.47273
Epoch 65, Val Loss: 88.44162
Epoch 66, Val Loss: 86.01770
Epoch 67, Val Loss: 83.16666
Epoch 68, Val Loss: 83.25892
Epoch 69, Val Loss: 86.47961
Epoch 70, Val Loss: 89.74022
Epoch 71, Val Loss: 88.36316
Epoch 72, Val Loss: 90.25716
Epoch 73, Val Loss: 84.37349
Epoch 74, Val Loss: 85.90119
Epoch 75, Val Loss: 83.14319
Epoch 76, Val Loss: 89.91631
Epoch 77, Val Loss: 87.03893
Epoch 78, Val Loss: 88.44231
Epoch 79, Val Loss: 86.25336
Epoch 80, Val Loss: 86.64444
Epoch 81, Val Loss: 94.59042
Epoch 82, Val Loss: 85.55495
Epoch 83, Val Loss: 84.22639
Epoch 84, Val Loss: 91.89948
Epoch 85, Val Loss: 86.31284
Epoch 86, Val Loss: 85.82487
Epoch 87, Val Loss: 85.91835
Epoch 88, Val Loss: 84.39050
Epoch 89, Val Loss: 87.65131
Epoch 90, Val Loss: 85.69930
Epoch 91, Val Loss: 87.00535
Epoch 92, Val Loss: 85.59937
Epoch 93, Val Loss: 83.93242
Epoch 94, Val Loss: 85.06976
Epoch 95, Val Loss: 99.05544
Epoch 96, Val Loss: 83.80516
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.29900598867958, 'MSE - std': 0.0, 'R2 - mean': 0.4912796506793611, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1178.41138
Epoch 1, Val Loss: 452.12299
Epoch 2, Val Loss: 149.27957
Epoch 3, Val Loss: 131.36235
Epoch 4, Val Loss: 131.92244
Epoch 5, Val Loss: 112.56081
Epoch 6, Val Loss: 103.78588
Epoch 7, Val Loss: 100.88775
Epoch 8, Val Loss: 109.97414
Epoch 9, Val Loss: 102.16953
Epoch 10, Val Loss: 92.41159
Epoch 11, Val Loss: 86.68732
Epoch 12, Val Loss: 87.07714
Epoch 13, Val Loss: 103.86188
Epoch 14, Val Loss: 91.14215
Epoch 15, Val Loss: 84.02122
Epoch 16, Val Loss: 82.73181
Epoch 17, Val Loss: 86.56580
Epoch 18, Val Loss: 98.57529
Epoch 19, Val Loss: 83.28639
Epoch 20, Val Loss: 108.65617
Epoch 21, Val Loss: 75.95085
Epoch 22, Val Loss: 104.07769
Epoch 23, Val Loss: 83.98017
Epoch 24, Val Loss: 82.55280
Epoch 25, Val Loss: 87.91900
Epoch 26, Val Loss: 85.64595
Epoch 27, Val Loss: 82.92137
Epoch 28, Val Loss: 85.92716
Epoch 29, Val Loss: 79.23247
Epoch 30, Val Loss: 82.53494
Epoch 31, Val Loss: 85.79900
Epoch 32, Val Loss: 94.93260
Epoch 33, Val Loss: 79.96583
Epoch 34, Val Loss: 86.45670
Epoch 35, Val Loss: 75.97076
Epoch 36, Val Loss: 85.28902
Epoch 37, Val Loss: 84.76765
Epoch 38, Val Loss: 93.34910
Epoch 39, Val Loss: 76.59570
Epoch 40, Val Loss: 77.50396
Epoch 41, Val Loss: 79.61223
Epoch 42, Val Loss: 74.72457
Epoch 43, Val Loss: 96.07335
Epoch 44, Val Loss: 72.36541
Epoch 45, Val Loss: 81.68011
Epoch 46, Val Loss: 79.47036
Epoch 47, Val Loss: 79.16947
Epoch 48, Val Loss: 75.59733
Epoch 49, Val Loss: 71.77560
Epoch 50, Val Loss: 84.35773
Epoch 51, Val Loss: 99.37585
Epoch 52, Val Loss: 73.53185
Epoch 53, Val Loss: 73.88854
Epoch 54, Val Loss: 72.82764
Epoch 55, Val Loss: 72.73255
Epoch 56, Val Loss: 77.55941
Epoch 57, Val Loss: 74.74712
Epoch 58, Val Loss: 69.63410
Epoch 59, Val Loss: 72.29245
Epoch 60, Val Loss: 72.14741
Epoch 61, Val Loss: 73.92380
Epoch 62, Val Loss: 78.86746
Epoch 63, Val Loss: 70.39182
Epoch 64, Val Loss: 75.38090
Epoch 65, Val Loss: 70.07860
Epoch 66, Val Loss: 70.55298
Epoch 67, Val Loss: 76.58398
Epoch 68, Val Loss: 71.35287
Epoch 69, Val Loss: 71.37781
Epoch 70, Val Loss: 71.35429
Epoch 71, Val Loss: 72.05407
Epoch 72, Val Loss: 68.86332
Epoch 73, Val Loss: 73.17081
Epoch 74, Val Loss: 72.77506
Epoch 75, Val Loss: 81.87471
Epoch 76, Val Loss: 72.03407
Epoch 77, Val Loss: 79.98531
Epoch 78, Val Loss: 75.33918
Epoch 79, Val Loss: 72.28981
Epoch 80, Val Loss: 75.76936
Epoch 81, Val Loss: 81.09674
Epoch 82, Val Loss: 68.36029
Epoch 83, Val Loss: 75.43610
Epoch 84, Val Loss: 74.52554
Epoch 85, Val Loss: 73.93577
Epoch 86, Val Loss: 72.94083
Epoch 87, Val Loss: 70.23959
Epoch 88, Val Loss: 71.20057
Epoch 89, Val Loss: 75.79004
Epoch 90, Val Loss: 70.17484
Epoch 91, Val Loss: 72.80179
Epoch 92, Val Loss: 77.85515
Epoch 93, Val Loss: 69.42651
Epoch 94, Val Loss: 71.95763
Epoch 95, Val Loss: 70.65012
Epoch 96, Val Loss: 87.59385
Epoch 97, Val Loss: 75.55830
Epoch 98, Val Loss: 74.43157
Epoch 99, Val Loss: 74.25326
DID NOT SAVE RESULTS
{'MSE - mean': 81.88589873223852, 'MSE - std': 5.413107256441066, 'R2 - mean': 0.5016923630989651, 'R2 - std': 0.01041271241960412} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1447.77222
Epoch 1, Val Loss: 419.44049
Epoch 2, Val Loss: 153.57256
Epoch 3, Val Loss: 133.57239
Epoch 4, Val Loss: 135.94466
Epoch 5, Val Loss: 124.52737
Epoch 6, Val Loss: 106.74419
Epoch 7, Val Loss: 104.71539
Epoch 8, Val Loss: 95.51344
Epoch 9, Val Loss: 101.46205
Epoch 10, Val Loss: 104.23734
Epoch 11, Val Loss: 122.07045
Epoch 12, Val Loss: 109.01795
Epoch 13, Val Loss: 97.27527
Epoch 14, Val Loss: 93.01267
Epoch 15, Val Loss: 89.76715
Epoch 16, Val Loss: 86.62309
Epoch 17, Val Loss: 100.90608
Epoch 18, Val Loss: 87.61993
Epoch 19, Val Loss: 88.21758
Epoch 20, Val Loss: 89.00478
Epoch 21, Val Loss: 84.63682
Epoch 22, Val Loss: 99.61012
Epoch 23, Val Loss: 83.56779
Epoch 24, Val Loss: 85.08008
Epoch 25, Val Loss: 89.55506
Epoch 26, Val Loss: 86.85896
Epoch 27, Val Loss: 89.25767
Epoch 28, Val Loss: 84.32853
Epoch 29, Val Loss: 95.92828
Epoch 30, Val Loss: 91.60421
Epoch 31, Val Loss: 83.73618
Epoch 32, Val Loss: 92.13610
Epoch 33, Val Loss: 93.40769
Epoch 34, Val Loss: 94.95918
Epoch 35, Val Loss: 80.97931
Epoch 36, Val Loss: 81.64771
Epoch 37, Val Loss: 90.06646
Epoch 38, Val Loss: 82.80101
Epoch 39, Val Loss: 88.42447
Epoch 40, Val Loss: 88.92534
Epoch 41, Val Loss: 83.91543
Epoch 42, Val Loss: 92.72272
Epoch 43, Val Loss: 75.87061
Epoch 44, Val Loss: 89.55309
Epoch 45, Val Loss: 79.46788
Epoch 46, Val Loss: 78.12807
Epoch 47, Val Loss: 81.50378
Epoch 48, Val Loss: 81.78691
Epoch 49, Val Loss: 76.42867
Epoch 50, Val Loss: 78.29446
Epoch 51, Val Loss: 74.89243
Epoch 52, Val Loss: 80.14317
Epoch 53, Val Loss: 74.18570
Epoch 54, Val Loss: 84.46445
Epoch 55, Val Loss: 83.98163
Epoch 56, Val Loss: 78.05655
Epoch 57, Val Loss: 71.87943
Epoch 58, Val Loss: 81.22598
Epoch 59, Val Loss: 72.34167
Epoch 60, Val Loss: 73.48004
Epoch 61, Val Loss: 71.35022
Epoch 62, Val Loss: 72.63480
Epoch 63, Val Loss: 72.98344
Epoch 64, Val Loss: 75.85075
Epoch 65, Val Loss: 70.37673
Epoch 66, Val Loss: 73.24554
Epoch 67, Val Loss: 72.69173
Epoch 68, Val Loss: 72.17027
Epoch 69, Val Loss: 90.19010
Epoch 70, Val Loss: 71.41573
Epoch 71, Val Loss: 69.10055
Epoch 72, Val Loss: 72.31494
Epoch 73, Val Loss: 70.55482
Epoch 74, Val Loss: 72.81668
Epoch 75, Val Loss: 78.72200
Epoch 76, Val Loss: 68.84073
Epoch 77, Val Loss: 71.66261
Epoch 78, Val Loss: 73.30713
Epoch 79, Val Loss: 70.11535
Epoch 80, Val Loss: 78.40243
Epoch 81, Val Loss: 72.76311
Epoch 82, Val Loss: 72.53139
Epoch 83, Val Loss: 73.90516
Epoch 84, Val Loss: 76.02733
Epoch 85, Val Loss: 73.92916
Epoch 86, Val Loss: 80.02713
Epoch 87, Val Loss: 72.14657
Epoch 88, Val Loss: 72.23225
Epoch 89, Val Loss: 75.74258
Epoch 90, Val Loss: 71.13689
Epoch 91, Val Loss: 71.38562
Epoch 92, Val Loss: 86.53541
Epoch 93, Val Loss: 72.10446
Epoch 94, Val Loss: 70.03281
Epoch 95, Val Loss: 71.26481
Epoch 96, Val Loss: 73.11227
Epoch 97, Val Loss: 74.87549
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.57062908928158, 'MSE - std': 7.53509064064093, 'R2 - mean': 0.5133434138125604, 'R2 - std': 0.01854122484493558} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 742.31458
Epoch 1, Val Loss: 355.39066
Epoch 2, Val Loss: 188.81358
Epoch 3, Val Loss: 167.85300
Epoch 4, Val Loss: 152.73784
Epoch 5, Val Loss: 146.88220
Epoch 6, Val Loss: 119.01853
Epoch 7, Val Loss: 124.07703
Epoch 8, Val Loss: 105.23180
Epoch 9, Val Loss: 100.80931
Epoch 10, Val Loss: 131.89230
Epoch 11, Val Loss: 118.60007
Epoch 12, Val Loss: 96.81758
Epoch 13, Val Loss: 106.59232
Epoch 14, Val Loss: 93.41134
Epoch 15, Val Loss: 94.99417
Epoch 16, Val Loss: 95.30161
Epoch 17, Val Loss: 95.21145
Epoch 18, Val Loss: 95.70966
Epoch 19, Val Loss: 99.67266
Epoch 20, Val Loss: 93.81634
Epoch 21, Val Loss: 108.20531
Epoch 22, Val Loss: 94.67686
Epoch 23, Val Loss: 88.56542
Epoch 24, Val Loss: 105.51780
Epoch 25, Val Loss: 90.54500
Epoch 26, Val Loss: 103.70734
Epoch 27, Val Loss: 85.27411
Epoch 28, Val Loss: 93.08293
Epoch 29, Val Loss: 99.11765
Epoch 30, Val Loss: 86.14158
Epoch 31, Val Loss: 87.11277
Epoch 32, Val Loss: 86.80622
Epoch 33, Val Loss: 90.81096
Epoch 34, Val Loss: 93.47159
Epoch 35, Val Loss: 113.40646
Epoch 36, Val Loss: 82.28692
Epoch 37, Val Loss: 79.33431
Epoch 38, Val Loss: 80.08896
Epoch 39, Val Loss: 81.90723
Epoch 40, Val Loss: 90.35685
Epoch 41, Val Loss: 84.92417
Epoch 42, Val Loss: 83.10317
Epoch 43, Val Loss: 84.90807
Epoch 44, Val Loss: 81.56716
Epoch 45, Val Loss: 83.98306
Epoch 46, Val Loss: 82.56012
Epoch 47, Val Loss: 79.71011
Epoch 48, Val Loss: 85.87939
Epoch 49, Val Loss: 87.11359
Epoch 50, Val Loss: 82.93905
Epoch 51, Val Loss: 78.64835
Epoch 52, Val Loss: 78.67795
Epoch 53, Val Loss: 82.05861
Epoch 54, Val Loss: 80.63815
Epoch 55, Val Loss: 89.43069
Epoch 56, Val Loss: 78.62721
Epoch 57, Val Loss: 79.17393
Epoch 58, Val Loss: 91.48950
Epoch 59, Val Loss: 84.42240
Epoch 60, Val Loss: 84.31283
Epoch 61, Val Loss: 81.30444
Epoch 62, Val Loss: 79.85435
Epoch 63, Val Loss: 79.81778
Epoch 64, Val Loss: 85.11569
Epoch 65, Val Loss: 87.26831
Epoch 66, Val Loss: 90.56322
Epoch 67, Val Loss: 81.55000
Epoch 68, Val Loss: 87.24081
Epoch 69, Val Loss: 80.88805
Epoch 70, Val Loss: 83.51736
Epoch 71, Val Loss: 79.52654
Epoch 72, Val Loss: 85.89154
Epoch 73, Val Loss: 78.48667
Epoch 74, Val Loss: 80.84444
Epoch 75, Val Loss: 80.79710
Epoch 76, Val Loss: 79.40388
Epoch 77, Val Loss: 81.55579
Epoch 78, Val Loss: 84.91323
Epoch 79, Val Loss: 84.87570
Epoch 80, Val Loss: 78.60952
Epoch 81, Val Loss: 77.80981
Epoch 82, Val Loss: 83.65131
Epoch 83, Val Loss: 99.42933
Epoch 84, Val Loss: 78.47416
Epoch 85, Val Loss: 81.31198
Epoch 86, Val Loss: 78.23374
Epoch 87, Val Loss: 80.94148
Epoch 88, Val Loss: 94.20895
Epoch 89, Val Loss: 81.54738
Epoch 90, Val Loss: 86.20883
Epoch 91, Val Loss: 78.69563
Epoch 92, Val Loss: 83.56384
Epoch 93, Val Loss: 79.87160
Epoch 94, Val Loss: 77.33421
Epoch 95, Val Loss: 78.11063
Epoch 96, Val Loss: 80.30555
Epoch 97, Val Loss: 76.72428
Epoch 98, Val Loss: 78.12376
Epoch 99, Val Loss: 77.56690
DID NOT SAVE RESULTS
{'MSE - mean': 80.09456977364543, 'MSE - std': 7.854554281215903, 'R2 - mean': 0.5036682414625628, 'R2 - std': 0.023209042291083778} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 607.12488
Epoch 1, Val Loss: 402.79510
Epoch 2, Val Loss: 148.64557
Epoch 3, Val Loss: 133.73706
Epoch 4, Val Loss: 134.96153
Epoch 5, Val Loss: 131.27319
Epoch 6, Val Loss: 128.81673
Epoch 7, Val Loss: 114.80829
Epoch 8, Val Loss: 109.76830
Epoch 9, Val Loss: 104.28513
Epoch 10, Val Loss: 101.46736
Epoch 11, Val Loss: 104.02992
Epoch 12, Val Loss: 101.52842
Epoch 13, Val Loss: 103.41986
Epoch 14, Val Loss: 95.71371
Epoch 15, Val Loss: 93.10225
Epoch 16, Val Loss: 106.79027
Epoch 17, Val Loss: 110.43640
Epoch 18, Val Loss: 93.46483
Epoch 19, Val Loss: 97.01434
Epoch 20, Val Loss: 99.47581
Epoch 21, Val Loss: 97.32198
Epoch 22, Val Loss: 96.04849
Epoch 23, Val Loss: 101.42412
Epoch 24, Val Loss: 91.60286
Epoch 25, Val Loss: 103.93953
Epoch 26, Val Loss: 89.47116
Epoch 27, Val Loss: 92.49259
Epoch 28, Val Loss: 92.90430
Epoch 29, Val Loss: 94.13087
Epoch 30, Val Loss: 90.19974
Epoch 31, Val Loss: 95.79785
Epoch 32, Val Loss: 108.52960
Epoch 33, Val Loss: 85.53389
Epoch 34, Val Loss: 83.74953
Epoch 35, Val Loss: 96.98897
Epoch 36, Val Loss: 82.77425
Epoch 37, Val Loss: 84.95428
Epoch 38, Val Loss: 80.03331
Epoch 39, Val Loss: 95.28326
Epoch 40, Val Loss: 85.42597
Epoch 41, Val Loss: 83.49777
Epoch 42, Val Loss: 82.93382
Epoch 43, Val Loss: 80.52920
Epoch 44, Val Loss: 77.31147
Epoch 45, Val Loss: 83.03307
Epoch 46, Val Loss: 81.68784
Epoch 47, Val Loss: 75.84119
Epoch 48, Val Loss: 82.92255
Epoch 49, Val Loss: 80.50343
Epoch 50, Val Loss: 76.22974
Epoch 51, Val Loss: 87.04155
Epoch 52, Val Loss: 82.67079
Epoch 53, Val Loss: 77.30902
Epoch 54, Val Loss: 81.80976
Epoch 55, Val Loss: 75.69859
Epoch 56, Val Loss: 82.26694
Epoch 57, Val Loss: 76.42119
Epoch 58, Val Loss: 83.44290
Epoch 59, Val Loss: 73.69057
Epoch 60, Val Loss: 83.14523
Epoch 61, Val Loss: 84.56866
Epoch 62, Val Loss: 75.22722
Epoch 63, Val Loss: 104.08313
Epoch 64, Val Loss: 86.41575
Epoch 65, Val Loss: 76.30882
Epoch 66, Val Loss: 81.40480
Epoch 67, Val Loss: 79.61559
Epoch 68, Val Loss: 75.84830
Epoch 69, Val Loss: 82.07719
Epoch 70, Val Loss: 75.62814
Epoch 71, Val Loss: 86.52054
Epoch 72, Val Loss: 76.70004
Epoch 73, Val Loss: 81.31276
Epoch 74, Val Loss: 80.27919
Epoch 75, Val Loss: 75.21230
Epoch 76, Val Loss: 80.35495
Epoch 77, Val Loss: 82.40573
Epoch 78, Val Loss: 80.37197
Epoch 79, Val Loss: 76.44146
Epoch 80, Val Loss: 80.50516
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.97839467862983, 'MSE - std': 7.371472426604208, 'R2 - mean': 0.5094717646225065, 'R2 - std': 0.023783423629231065} 
 

Results After CV: {'MSE - mean': 78.97839467862983, 'MSE - std': 7.371472426604208, 'R2 - mean': 0.5094717646225065, 'R2 - std': 0.023783423629231065}
Train time: 922.4554381961992
Inference time: 0.18927622500050348
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 26 finished with value: 78.97839467862983 and parameters: {'p_m': 0.23627783144870085, 'alpha': 5.5595392636046865, 'K': 5, 'beta': 5.93772790627427}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 973.45856
Epoch 1, Val Loss: 369.75296
Epoch 2, Val Loss: 158.69958
Epoch 3, Val Loss: 139.04480
Epoch 4, Val Loss: 125.70821
Epoch 5, Val Loss: 120.81210
Epoch 6, Val Loss: 116.77049
Epoch 7, Val Loss: 105.40108
Epoch 8, Val Loss: 100.49818
Epoch 9, Val Loss: 97.91832
Epoch 10, Val Loss: 103.68301
Epoch 11, Val Loss: 96.08580
Epoch 12, Val Loss: 106.93779
Epoch 13, Val Loss: 114.74744
Epoch 14, Val Loss: 111.33955
Epoch 15, Val Loss: 105.09151
Epoch 16, Val Loss: 106.26411
Epoch 17, Val Loss: 95.52054
Epoch 18, Val Loss: 97.82413
Epoch 19, Val Loss: 96.36965
Epoch 20, Val Loss: 95.71272
Epoch 21, Val Loss: 95.22961
Epoch 22, Val Loss: 95.32845
Epoch 23, Val Loss: 93.98692
Epoch 24, Val Loss: 96.59146
Epoch 25, Val Loss: 99.81696
Epoch 26, Val Loss: 96.46400
Epoch 27, Val Loss: 91.15274
Epoch 28, Val Loss: 91.89000
Epoch 29, Val Loss: 93.05324
Epoch 30, Val Loss: 101.95961
Epoch 31, Val Loss: 109.06925
Epoch 32, Val Loss: 94.83321
Epoch 33, Val Loss: 96.39481
Epoch 34, Val Loss: 92.86427
Epoch 35, Val Loss: 103.78407
Epoch 36, Val Loss: 95.81330
Epoch 37, Val Loss: 89.55254
Epoch 38, Val Loss: 98.21308
Epoch 39, Val Loss: 89.38883
Epoch 40, Val Loss: 97.19832
Epoch 41, Val Loss: 87.84081
Epoch 42, Val Loss: 94.56878
Epoch 43, Val Loss: 94.36031
Epoch 44, Val Loss: 94.58332
Epoch 45, Val Loss: 90.89948
Epoch 46, Val Loss: 104.69499
Epoch 47, Val Loss: 100.93349
Epoch 48, Val Loss: 92.62501
Epoch 49, Val Loss: 102.65816
Epoch 50, Val Loss: 94.59819
Epoch 51, Val Loss: 87.85688
Epoch 52, Val Loss: 97.11610
Epoch 53, Val Loss: 90.28648
Epoch 54, Val Loss: 96.05418
Epoch 55, Val Loss: 95.49229
Epoch 56, Val Loss: 92.01346
Epoch 57, Val Loss: 91.82387
Epoch 58, Val Loss: 104.74646
Epoch 59, Val Loss: 97.11862
Epoch 60, Val Loss: 101.04227
Epoch 61, Val Loss: 91.91801
Epoch 62, Val Loss: 94.47074
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 94.2955606491248, 'MSE - std': 0.0, 'R2 - mean': 0.45050839915601415, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1578.82739
Epoch 1, Val Loss: 368.50842
Epoch 2, Val Loss: 148.68741
Epoch 3, Val Loss: 128.98457
Epoch 4, Val Loss: 123.08039
Epoch 5, Val Loss: 111.98833
Epoch 6, Val Loss: 105.24263
Epoch 7, Val Loss: 101.37714
Epoch 8, Val Loss: 102.62480
Epoch 9, Val Loss: 96.26661
Epoch 10, Val Loss: 91.77131
Epoch 11, Val Loss: 94.31852
Epoch 12, Val Loss: 86.62316
Epoch 13, Val Loss: 95.31795
Epoch 14, Val Loss: 80.14346
Epoch 15, Val Loss: 82.82301
Epoch 16, Val Loss: 81.35884
Epoch 17, Val Loss: 94.32408
Epoch 18, Val Loss: 84.80683
Epoch 19, Val Loss: 82.60662
Epoch 20, Val Loss: 77.58879
Epoch 21, Val Loss: 80.79577
Epoch 22, Val Loss: 91.34792
Epoch 23, Val Loss: 84.06327
Epoch 24, Val Loss: 95.32488
Epoch 25, Val Loss: 77.53261
Epoch 26, Val Loss: 87.97848
Epoch 27, Val Loss: 89.18735
Epoch 28, Val Loss: 89.56076
Epoch 29, Val Loss: 80.19360
Epoch 30, Val Loss: 81.26861
Epoch 31, Val Loss: 82.45118
Epoch 32, Val Loss: 82.12169
Epoch 33, Val Loss: 80.91415
Epoch 34, Val Loss: 83.53126
Epoch 35, Val Loss: 81.60225
Epoch 36, Val Loss: 77.72709
Epoch 37, Val Loss: 78.18625
Epoch 38, Val Loss: 82.65287
Epoch 39, Val Loss: 84.43089
Epoch 40, Val Loss: 84.78008
Epoch 41, Val Loss: 76.41685
Epoch 42, Val Loss: 78.41111
Epoch 43, Val Loss: 88.36083
Epoch 44, Val Loss: 86.38055
Epoch 45, Val Loss: 75.52663
Epoch 46, Val Loss: 84.74178
Epoch 47, Val Loss: 81.79929
Epoch 48, Val Loss: 80.59617
Epoch 49, Val Loss: 75.87656
Epoch 50, Val Loss: 81.36055
Epoch 51, Val Loss: 99.69797
Epoch 52, Val Loss: 75.54416
Epoch 53, Val Loss: 84.71449
Epoch 54, Val Loss: 99.48115
Epoch 55, Val Loss: 91.71824
Epoch 56, Val Loss: 76.63029
Epoch 57, Val Loss: 77.68212
Epoch 58, Val Loss: 77.27006
Epoch 59, Val Loss: 84.40753
Epoch 60, Val Loss: 75.94773
Epoch 61, Val Loss: 74.62626
Epoch 62, Val Loss: 74.34805
Epoch 63, Val Loss: 73.67583
Epoch 64, Val Loss: 81.97390
Epoch 65, Val Loss: 75.54682
Epoch 66, Val Loss: 77.94052
Epoch 67, Val Loss: 71.28680
Epoch 68, Val Loss: 73.79279
Epoch 69, Val Loss: 74.58607
Epoch 70, Val Loss: 77.85262
Epoch 71, Val Loss: 72.23200
Epoch 72, Val Loss: 70.58671
Epoch 73, Val Loss: 75.31055
Epoch 74, Val Loss: 76.25369
Epoch 75, Val Loss: 75.18589
Epoch 76, Val Loss: 72.34811
Epoch 77, Val Loss: 73.81028
Epoch 78, Val Loss: 80.44359
Epoch 79, Val Loss: 74.22760
Epoch 80, Val Loss: 72.83015
Epoch 81, Val Loss: 73.20070
Epoch 82, Val Loss: 75.63566
Epoch 83, Val Loss: 73.67569
Epoch 84, Val Loss: 70.71060
Epoch 85, Val Loss: 76.11743
Epoch 86, Val Loss: 76.77165
Epoch 87, Val Loss: 71.53564
Epoch 88, Val Loss: 70.28844
Epoch 89, Val Loss: 82.00820
Epoch 90, Val Loss: 74.02140
Epoch 91, Val Loss: 71.84142
Epoch 92, Val Loss: 76.75047
Epoch 93, Val Loss: 71.44765
Epoch 94, Val Loss: 74.26176
Epoch 95, Val Loss: 72.33534
Epoch 96, Val Loss: 71.44017
Epoch 97, Val Loss: 72.13090
Epoch 98, Val Loss: 76.64938
Epoch 99, Val Loss: 70.75283
DID NOT SAVE RESULTS
{'MSE - mean': 85.57962860055875, 'MSE - std': 8.715932048566039, 'R2 - mean': 0.48005975394000033, 'R2 - std': 0.029551354783986183} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1343.35706
Epoch 1, Val Loss: 383.09796
Epoch 2, Val Loss: 150.91557
Epoch 3, Val Loss: 118.04424
Epoch 4, Val Loss: 105.28711
Epoch 5, Val Loss: 102.15347
Epoch 6, Val Loss: 95.30400
Epoch 7, Val Loss: 89.93721
Epoch 8, Val Loss: 89.51569
Epoch 9, Val Loss: 94.53913
Epoch 10, Val Loss: 84.28946
Epoch 11, Val Loss: 87.57920
Epoch 12, Val Loss: 80.97144
Epoch 13, Val Loss: 79.84923
Epoch 14, Val Loss: 74.16732
Epoch 15, Val Loss: 95.32362
Epoch 16, Val Loss: 84.82831
Epoch 17, Val Loss: 80.08144
Epoch 18, Val Loss: 74.41229
Epoch 19, Val Loss: 78.27349
Epoch 20, Val Loss: 85.91890
Epoch 21, Val Loss: 72.39429
Epoch 22, Val Loss: 82.41116
Epoch 23, Val Loss: 80.37553
Epoch 24, Val Loss: 77.04409
Epoch 25, Val Loss: 77.64886
Epoch 26, Val Loss: 79.97841
Epoch 27, Val Loss: 78.75391
Epoch 28, Val Loss: 79.31759
Epoch 29, Val Loss: 79.64704
Epoch 30, Val Loss: 80.48351
Epoch 31, Val Loss: 76.26181
Epoch 32, Val Loss: 78.43926
Epoch 33, Val Loss: 79.73979
Epoch 34, Val Loss: 76.06068
Epoch 35, Val Loss: 76.76878
Epoch 36, Val Loss: 77.89670
Epoch 37, Val Loss: 102.73339
Epoch 38, Val Loss: 92.46239
Epoch 39, Val Loss: 86.13989
Epoch 40, Val Loss: 79.66460
Epoch 41, Val Loss: 84.89314
Epoch 42, Val Loss: 75.35825
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.06747635888637, 'MSE - std': 8.67844500592411, 'R2 - mean': 0.4852484959315659, 'R2 - std': 0.02521972376182485} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1679.47888
Epoch 1, Val Loss: 415.44891
Epoch 2, Val Loss: 160.06689
Epoch 3, Val Loss: 141.17009
Epoch 4, Val Loss: 123.88760
Epoch 5, Val Loss: 124.34988
Epoch 6, Val Loss: 111.75389
Epoch 7, Val Loss: 105.96037
Epoch 8, Val Loss: 105.60712
Epoch 9, Val Loss: 96.53751
Epoch 10, Val Loss: 95.56371
Epoch 11, Val Loss: 91.40103
Epoch 12, Val Loss: 95.33515
Epoch 13, Val Loss: 90.59722
Epoch 14, Val Loss: 97.00517
Epoch 15, Val Loss: 91.24535
Epoch 16, Val Loss: 85.56002
Epoch 17, Val Loss: 92.26173
Epoch 18, Val Loss: 89.48113
Epoch 19, Val Loss: 86.02797
Epoch 20, Val Loss: 84.67473
Epoch 21, Val Loss: 91.59459
Epoch 22, Val Loss: 89.70173
Epoch 23, Val Loss: 86.32077
Epoch 24, Val Loss: 92.10393
Epoch 25, Val Loss: 96.84820
Epoch 26, Val Loss: 87.41813
Epoch 27, Val Loss: 93.55156
Epoch 28, Val Loss: 89.26493
Epoch 29, Val Loss: 88.00606
Epoch 30, Val Loss: 90.68239
Epoch 31, Val Loss: 90.24699
Epoch 32, Val Loss: 88.21533
Epoch 33, Val Loss: 83.32983
Epoch 34, Val Loss: 82.42065
Epoch 35, Val Loss: 83.30431
Epoch 36, Val Loss: 89.40122
Epoch 37, Val Loss: 89.36444
Epoch 38, Val Loss: 102.71697
Epoch 39, Val Loss: 84.61617
Epoch 40, Val Loss: 83.64187
Epoch 41, Val Loss: 89.29764
Epoch 42, Val Loss: 87.31997
Epoch 43, Val Loss: 87.03525
Epoch 44, Val Loss: 91.50005
Epoch 45, Val Loss: 88.81013
Epoch 46, Val Loss: 100.08681
Epoch 47, Val Loss: 100.75246
Epoch 48, Val Loss: 94.14853
Epoch 49, Val Loss: 89.04071
Epoch 50, Val Loss: 103.36690
Epoch 51, Val Loss: 88.18900
Epoch 52, Val Loss: 90.17613
Epoch 53, Val Loss: 81.34520
Epoch 54, Val Loss: 97.08398
Epoch 55, Val Loss: 89.44666
Epoch 56, Val Loss: 81.04290
Epoch 57, Val Loss: 84.15238
Epoch 58, Val Loss: 90.70804
Epoch 59, Val Loss: 83.92725
Epoch 60, Val Loss: 84.03319
Epoch 61, Val Loss: 95.01855
Epoch 62, Val Loss: 81.90335
Epoch 63, Val Loss: 82.18826
Epoch 64, Val Loss: 85.00043
Epoch 65, Val Loss: 81.52658
Epoch 66, Val Loss: 83.05570
Epoch 67, Val Loss: 81.61052
Epoch 68, Val Loss: 82.81393
Epoch 69, Val Loss: 82.62646
Epoch 70, Val Loss: 81.63987
Epoch 71, Val Loss: 81.95652
Epoch 72, Val Loss: 85.19458
Epoch 73, Val Loss: 81.06051
Epoch 74, Val Loss: 109.51746
Epoch 75, Val Loss: 82.63058
Epoch 76, Val Loss: 86.35851
Epoch 77, Val Loss: 86.24375
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.3439765707067, 'MSE - std': 8.487279625056019, 'R2 - mean': 0.4773428365219759, 'R2 - std': 0.025778366939516933} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 684.75366
Epoch 1, Val Loss: 373.80417
Epoch 2, Val Loss: 155.49191
Epoch 3, Val Loss: 135.08966
Epoch 4, Val Loss: 109.20772
Epoch 5, Val Loss: 106.80394
Epoch 6, Val Loss: 95.01819
Epoch 7, Val Loss: 92.96674
Epoch 8, Val Loss: 97.65733
Epoch 9, Val Loss: 95.19653
Epoch 10, Val Loss: 90.03038
Epoch 11, Val Loss: 90.56834
Epoch 12, Val Loss: 90.84076
Epoch 13, Val Loss: 86.81012
Epoch 14, Val Loss: 88.61741
Epoch 15, Val Loss: 97.17849
Epoch 16, Val Loss: 89.19365
Epoch 17, Val Loss: 93.83058
Epoch 18, Val Loss: 87.41805
Epoch 19, Val Loss: 87.97118
Epoch 20, Val Loss: 82.52333
Epoch 21, Val Loss: 93.83611
Epoch 22, Val Loss: 87.28263
Epoch 23, Val Loss: 80.96736
Epoch 24, Val Loss: 85.62695
Epoch 25, Val Loss: 87.80096
Epoch 26, Val Loss: 98.65697
Epoch 27, Val Loss: 91.65744
Epoch 28, Val Loss: 83.65685
Epoch 29, Val Loss: 93.29892
Epoch 30, Val Loss: 88.52913
Epoch 31, Val Loss: 89.11874
Epoch 32, Val Loss: 87.15135
Epoch 33, Val Loss: 86.90457
Epoch 34, Val Loss: 101.79492
Epoch 35, Val Loss: 102.40823
Epoch 36, Val Loss: 94.42062
Epoch 37, Val Loss: 102.61868
Epoch 38, Val Loss: 94.67378
Epoch 39, Val Loss: 84.75781
Epoch 40, Val Loss: 86.69625
Epoch 41, Val Loss: 92.59390
Epoch 42, Val Loss: 82.38026
Epoch 43, Val Loss: 82.11752
Epoch 44, Val Loss: 84.23495
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.50997752834567, 'MSE - std': 7.772345203202779, 'R2 - mean': 0.48131171968546005, 'R2 - std': 0.024384985050564488} 
 

Results After CV: {'MSE - mean': 83.50997752834567, 'MSE - std': 7.772345203202779, 'R2 - mean': 0.48131171968546005, 'R2 - std': 0.024384985050564488}
Train time: 646.8394837177991
Inference time: 0.1750198818015633
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 27 finished with value: 83.50997752834567 and parameters: {'p_m': 0.1787048574863213, 'alpha': 6.947755658587189, 'K': 5, 'beta': 3.686407038681347}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1208.84961
Epoch 1, Val Loss: 433.46548
Epoch 2, Val Loss: 178.28539
Epoch 3, Val Loss: 154.87473
Epoch 4, Val Loss: 139.69514
Epoch 5, Val Loss: 131.52849
Epoch 6, Val Loss: 128.27985
Epoch 7, Val Loss: 122.42746
Epoch 8, Val Loss: 112.97362
Epoch 9, Val Loss: 114.82564
Epoch 10, Val Loss: 108.35096
Epoch 11, Val Loss: 105.95617
Epoch 12, Val Loss: 106.96848
Epoch 13, Val Loss: 108.45853
Epoch 14, Val Loss: 131.85965
Epoch 15, Val Loss: 101.23134
Epoch 16, Val Loss: 108.33645
Epoch 17, Val Loss: 100.44034
Epoch 18, Val Loss: 104.52788
Epoch 19, Val Loss: 100.53257
Epoch 20, Val Loss: 117.28334
Epoch 21, Val Loss: 97.78749
Epoch 22, Val Loss: 97.23552
Epoch 23, Val Loss: 102.54612
Epoch 24, Val Loss: 100.33328
Epoch 25, Val Loss: 106.80532
Epoch 26, Val Loss: 100.68099
Epoch 27, Val Loss: 97.49471
Epoch 28, Val Loss: 100.16982
Epoch 29, Val Loss: 93.56852
Epoch 30, Val Loss: 106.18914
Epoch 31, Val Loss: 109.21400
Epoch 32, Val Loss: 98.61914
Epoch 33, Val Loss: 96.08499
Epoch 34, Val Loss: 101.76692
Epoch 35, Val Loss: 100.08276
Epoch 36, Val Loss: 96.33006
Epoch 37, Val Loss: 96.95120
Epoch 38, Val Loss: 108.91830
Epoch 39, Val Loss: 112.15747
Epoch 40, Val Loss: 111.15739
Epoch 41, Val Loss: 95.61772
Epoch 42, Val Loss: 95.29385
Epoch 43, Val Loss: 97.40381
Epoch 44, Val Loss: 104.74581
Epoch 45, Val Loss: 104.53365
Epoch 46, Val Loss: 92.67834
Epoch 47, Val Loss: 95.77829
Epoch 48, Val Loss: 90.14568
Epoch 49, Val Loss: 89.17965
Epoch 50, Val Loss: 99.06049
Epoch 51, Val Loss: 92.46805
Epoch 52, Val Loss: 89.17787
Epoch 53, Val Loss: 93.79079
Epoch 54, Val Loss: 87.29662
Epoch 55, Val Loss: 98.47395
Epoch 56, Val Loss: 91.14404
Epoch 57, Val Loss: 94.16106
Epoch 58, Val Loss: 92.39827
Epoch 59, Val Loss: 91.02945
Epoch 60, Val Loss: 90.23833
Epoch 61, Val Loss: 90.63924
Epoch 62, Val Loss: 89.09007
Epoch 63, Val Loss: 92.65069
Epoch 64, Val Loss: 94.65806
Epoch 65, Val Loss: 97.06924
Epoch 66, Val Loss: 91.65582
Epoch 67, Val Loss: 91.07743
Epoch 68, Val Loss: 86.78432
Epoch 69, Val Loss: 93.54549
Epoch 70, Val Loss: 87.11779
Epoch 71, Val Loss: 84.73470
Epoch 72, Val Loss: 90.12210
Epoch 73, Val Loss: 82.72791
Epoch 74, Val Loss: 98.55815
Epoch 75, Val Loss: 88.50884
Epoch 76, Val Loss: 88.01148
Epoch 77, Val Loss: 85.08270
Epoch 78, Val Loss: 96.39353
Epoch 79, Val Loss: 82.16016
Epoch 80, Val Loss: 88.01239
Epoch 81, Val Loss: 89.11656
Epoch 82, Val Loss: 84.03801
Epoch 83, Val Loss: 86.87482
Epoch 84, Val Loss: 85.21832
Epoch 85, Val Loss: 84.02928
Epoch 86, Val Loss: 86.83726
Epoch 87, Val Loss: 85.91205
Epoch 88, Val Loss: 87.72355
Epoch 89, Val Loss: 84.73196
Epoch 90, Val Loss: 88.94708
Epoch 91, Val Loss: 86.68964
Epoch 92, Val Loss: 83.01608
Epoch 93, Val Loss: 95.61936
Epoch 94, Val Loss: 86.71524
Epoch 95, Val Loss: 85.82156
Epoch 96, Val Loss: 84.82240
Epoch 97, Val Loss: 82.79128
Epoch 98, Val Loss: 88.42118
Epoch 99, Val Loss: 87.44483
DID NOT SAVE RESULTS
{'MSE - mean': 85.41811207986116, 'MSE - std': 0.0, 'R2 - mean': 0.5022402451957896, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 894.21759
Epoch 1, Val Loss: 374.94846
Epoch 2, Val Loss: 136.44054
Epoch 3, Val Loss: 118.16016
Epoch 4, Val Loss: 104.40583
Epoch 5, Val Loss: 108.63718
Epoch 6, Val Loss: 92.74998
Epoch 7, Val Loss: 106.79616
Epoch 8, Val Loss: 99.59938
Epoch 9, Val Loss: 99.91760
Epoch 10, Val Loss: 90.56960
Epoch 11, Val Loss: 85.28534
Epoch 12, Val Loss: 86.83541
Epoch 13, Val Loss: 86.26344
Epoch 14, Val Loss: 83.49721
Epoch 15, Val Loss: 85.68820
Epoch 16, Val Loss: 74.64214
Epoch 17, Val Loss: 87.62971
Epoch 18, Val Loss: 82.19563
Epoch 19, Val Loss: 84.61816
Epoch 20, Val Loss: 76.38145
Epoch 21, Val Loss: 86.13528
Epoch 22, Val Loss: 89.43613
Epoch 23, Val Loss: 80.53529
Epoch 24, Val Loss: 88.32549
Epoch 25, Val Loss: 81.45119
Epoch 26, Val Loss: 85.95627
Epoch 27, Val Loss: 86.62017
Epoch 28, Val Loss: 80.79726
Epoch 29, Val Loss: 85.45956
Epoch 30, Val Loss: 82.65300
Epoch 31, Val Loss: 88.70750
Epoch 32, Val Loss: 91.27794
Epoch 33, Val Loss: 94.34151
Epoch 34, Val Loss: 83.96407
Epoch 35, Val Loss: 84.04276
Epoch 36, Val Loss: 85.37021
Epoch 37, Val Loss: 81.90696
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.6480474762796, 'MSE - std': 1.7700646035815666, 'R2 - mean': 0.4899301522866253, 'R2 - std': 0.012310092909164294} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1265.11914
Epoch 1, Val Loss: 499.93265
Epoch 2, Val Loss: 156.32756
Epoch 3, Val Loss: 123.64543
Epoch 4, Val Loss: 110.23653
Epoch 5, Val Loss: 108.37421
Epoch 6, Val Loss: 105.93312
Epoch 7, Val Loss: 92.66237
Epoch 8, Val Loss: 91.46297
Epoch 9, Val Loss: 87.32885
Epoch 10, Val Loss: 96.82759
Epoch 11, Val Loss: 80.72102
Epoch 12, Val Loss: 78.94272
Epoch 13, Val Loss: 89.17481
Epoch 14, Val Loss: 91.39204
Epoch 15, Val Loss: 78.41093
Epoch 16, Val Loss: 83.43007
Epoch 17, Val Loss: 80.23493
Epoch 18, Val Loss: 78.91199
Epoch 19, Val Loss: 83.19260
Epoch 20, Val Loss: 80.60902
Epoch 21, Val Loss: 76.87131
Epoch 22, Val Loss: 80.34506
Epoch 23, Val Loss: 87.58916
Epoch 24, Val Loss: 85.99812
Epoch 25, Val Loss: 79.89470
Epoch 26, Val Loss: 79.15630
Epoch 27, Val Loss: 82.04053
Epoch 28, Val Loss: 88.50887
Epoch 29, Val Loss: 77.82153
Epoch 30, Val Loss: 76.67146
Epoch 31, Val Loss: 88.65528
Epoch 32, Val Loss: 75.85696
Epoch 33, Val Loss: 77.29974
Epoch 34, Val Loss: 90.71206
Epoch 35, Val Loss: 88.48967
Epoch 36, Val Loss: 75.83533
Epoch 37, Val Loss: 79.44953
Epoch 38, Val Loss: 79.23448
Epoch 39, Val Loss: 79.84535
Epoch 40, Val Loss: 79.89807
Epoch 41, Val Loss: 82.59676
Epoch 42, Val Loss: 78.97096
Epoch 43, Val Loss: 78.19995
Epoch 44, Val Loss: 80.53481
Epoch 45, Val Loss: 76.60112
Epoch 46, Val Loss: 74.67368
Epoch 47, Val Loss: 83.51312
Epoch 48, Val Loss: 73.20401
Epoch 49, Val Loss: 76.87517
Epoch 50, Val Loss: 77.40372
Epoch 51, Val Loss: 82.03884
Epoch 52, Val Loss: 73.15272
Epoch 53, Val Loss: 85.44942
Epoch 54, Val Loss: 78.83472
Epoch 55, Val Loss: 71.32301
Epoch 56, Val Loss: 73.77380
Epoch 57, Val Loss: 76.35651
Epoch 58, Val Loss: 92.63765
Epoch 59, Val Loss: 75.81499
Epoch 60, Val Loss: 72.67036
Epoch 61, Val Loss: 72.45064
Epoch 62, Val Loss: 75.13343
Epoch 63, Val Loss: 72.21090
Epoch 64, Val Loss: 73.31826
Epoch 65, Val Loss: 71.02218
Epoch 66, Val Loss: 71.10220
Epoch 67, Val Loss: 68.56581
Epoch 68, Val Loss: 69.90818
Epoch 69, Val Loss: 70.71373
Epoch 70, Val Loss: 70.38940
Epoch 71, Val Loss: 80.54108
Epoch 72, Val Loss: 73.44921
Epoch 73, Val Loss: 70.39360
Epoch 74, Val Loss: 70.75436
Epoch 75, Val Loss: 68.81370
Epoch 76, Val Loss: 70.83411
Epoch 77, Val Loss: 78.88142
Epoch 78, Val Loss: 72.96657
Epoch 79, Val Loss: 71.84967
Epoch 80, Val Loss: 67.39760
Epoch 81, Val Loss: 66.46955
Epoch 82, Val Loss: 73.98092
Epoch 83, Val Loss: 69.01241
Epoch 84, Val Loss: 71.47037
Epoch 85, Val Loss: 68.27892
Epoch 86, Val Loss: 68.45840
Epoch 87, Val Loss: 69.03429
Epoch 88, Val Loss: 75.25233
Epoch 89, Val Loss: 83.61287
Epoch 90, Val Loss: 69.84307
Epoch 91, Val Loss: 71.55672
Epoch 92, Val Loss: 66.29025
Epoch 93, Val Loss: 75.50640
Epoch 94, Val Loss: 66.45921
Epoch 95, Val Loss: 75.56614
Epoch 96, Val Loss: 67.72003
Epoch 97, Val Loss: 71.84427
Epoch 98, Val Loss: 70.20816
Epoch 99, Val Loss: 66.46862
DID NOT SAVE RESULTS
{'MSE - mean': 77.9371901027071, 'MSE - std': 8.204665523335466, 'R2 - mean': 0.5109339799471381, 'R2 - std': 0.031358366418015975} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1226.82483
Epoch 1, Val Loss: 423.48141
Epoch 2, Val Loss: 152.54428
Epoch 3, Val Loss: 138.21059
Epoch 4, Val Loss: 127.93405
Epoch 5, Val Loss: 119.48716
Epoch 6, Val Loss: 113.16412
Epoch 7, Val Loss: 112.30130
Epoch 8, Val Loss: 112.21870
Epoch 9, Val Loss: 112.32808
Epoch 10, Val Loss: 104.30726
Epoch 11, Val Loss: 98.53506
Epoch 12, Val Loss: 95.57079
Epoch 13, Val Loss: 116.33883
Epoch 14, Val Loss: 96.79633
Epoch 15, Val Loss: 96.60991
Epoch 16, Val Loss: 105.92941
Epoch 17, Val Loss: 98.91354
Epoch 18, Val Loss: 96.55820
Epoch 19, Val Loss: 105.50404
Epoch 20, Val Loss: 92.02368
Epoch 21, Val Loss: 95.44785
Epoch 22, Val Loss: 94.77026
Epoch 23, Val Loss: 102.18246
Epoch 24, Val Loss: 93.67163
Epoch 25, Val Loss: 91.87865
Epoch 26, Val Loss: 92.55843
Epoch 27, Val Loss: 90.15159
Epoch 28, Val Loss: 93.08543
Epoch 29, Val Loss: 88.90597
Epoch 30, Val Loss: 93.90734
Epoch 31, Val Loss: 92.49455
Epoch 32, Val Loss: 90.85538
Epoch 33, Val Loss: 96.37885
Epoch 34, Val Loss: 97.06468
Epoch 35, Val Loss: 93.83740
Epoch 36, Val Loss: 95.08483
Epoch 37, Val Loss: 91.43776
Epoch 38, Val Loss: 95.94824
Epoch 39, Val Loss: 93.54030
Epoch 40, Val Loss: 91.06625
Epoch 41, Val Loss: 92.06699
Epoch 42, Val Loss: 84.43337
Epoch 43, Val Loss: 89.39960
Epoch 44, Val Loss: 86.04016
Epoch 45, Val Loss: 87.24486
Epoch 46, Val Loss: 106.57602
Epoch 47, Val Loss: 83.98167
Epoch 48, Val Loss: 83.26881
Epoch 49, Val Loss: 88.01833
Epoch 50, Val Loss: 79.48287
Epoch 51, Val Loss: 88.27554
Epoch 52, Val Loss: 80.82048
Epoch 53, Val Loss: 83.84384
Epoch 54, Val Loss: 80.50948
Epoch 55, Val Loss: 85.04933
Epoch 56, Val Loss: 85.96060
Epoch 57, Val Loss: 83.24621
Epoch 58, Val Loss: 79.08295
Epoch 59, Val Loss: 83.87660
Epoch 60, Val Loss: 85.92607
Epoch 61, Val Loss: 84.32062
Epoch 62, Val Loss: 79.90054
Epoch 63, Val Loss: 80.39966
Epoch 64, Val Loss: 80.72688
Epoch 65, Val Loss: 84.85013
Epoch 66, Val Loss: 86.40977
Epoch 67, Val Loss: 90.34243
Epoch 68, Val Loss: 79.83107
Epoch 69, Val Loss: 80.00837
Epoch 70, Val Loss: 79.23021
Epoch 71, Val Loss: 78.96801
Epoch 72, Val Loss: 84.40509
Epoch 73, Val Loss: 83.80518
Epoch 74, Val Loss: 76.46100
Epoch 75, Val Loss: 81.02668
Epoch 76, Val Loss: 79.14539
Epoch 77, Val Loss: 78.43425
Epoch 78, Val Loss: 79.73053
Epoch 79, Val Loss: 82.32908
Epoch 80, Val Loss: 77.94326
Epoch 81, Val Loss: 77.66866
Epoch 82, Val Loss: 80.45981
Epoch 83, Val Loss: 80.40997
Epoch 84, Val Loss: 78.50764
Epoch 85, Val Loss: 79.43087
Epoch 86, Val Loss: 78.03748
Epoch 87, Val Loss: 76.92576
Epoch 88, Val Loss: 79.93179
Epoch 89, Val Loss: 79.92873
Epoch 90, Val Loss: 77.20762
Epoch 91, Val Loss: 77.73401
Epoch 92, Val Loss: 81.65140
Epoch 93, Val Loss: 79.63496
Epoch 94, Val Loss: 80.14476
Epoch 95, Val Loss: 89.72727
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.97576685717036, 'MSE - std': 7.934405322005614, 'R2 - mean': 0.5042206289515359, 'R2 - std': 0.029541794174954474} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 675.57556
Epoch 1, Val Loss: 330.60648
Epoch 2, Val Loss: 181.24359
Epoch 3, Val Loss: 153.92169
Epoch 4, Val Loss: 124.73492
Epoch 5, Val Loss: 123.84167
Epoch 6, Val Loss: 107.55219
Epoch 7, Val Loss: 100.59902
Epoch 8, Val Loss: 108.15984
Epoch 9, Val Loss: 114.15843
Epoch 10, Val Loss: 105.94135
Epoch 11, Val Loss: 116.27720
Epoch 12, Val Loss: 100.91878
Epoch 13, Val Loss: 104.15009
Epoch 14, Val Loss: 101.87518
Epoch 15, Val Loss: 93.48775
Epoch 16, Val Loss: 115.96242
Epoch 17, Val Loss: 98.89374
Epoch 18, Val Loss: 96.14310
Epoch 19, Val Loss: 104.72362
Epoch 20, Val Loss: 141.55698
Epoch 21, Val Loss: 96.15326
Epoch 22, Val Loss: 101.45058
Epoch 23, Val Loss: 102.00999
Epoch 24, Val Loss: 109.12846
Epoch 25, Val Loss: 96.99238
Epoch 26, Val Loss: 93.86246
Epoch 27, Val Loss: 94.38814
Epoch 28, Val Loss: 88.04647
Epoch 29, Val Loss: 101.96207
Epoch 30, Val Loss: 95.72258
Epoch 31, Val Loss: 88.66333
Epoch 32, Val Loss: 89.60148
Epoch 33, Val Loss: 87.27255
Epoch 34, Val Loss: 89.00754
Epoch 35, Val Loss: 88.57310
Epoch 36, Val Loss: 85.98975
Epoch 37, Val Loss: 84.29317
Epoch 38, Val Loss: 78.32637
Epoch 39, Val Loss: 100.05036
Epoch 40, Val Loss: 83.11597
Epoch 41, Val Loss: 93.68653
Epoch 42, Val Loss: 86.33121
Epoch 43, Val Loss: 79.51833
Epoch 44, Val Loss: 82.71533
Epoch 45, Val Loss: 86.02453
Epoch 46, Val Loss: 78.52419
Epoch 47, Val Loss: 90.54373
Epoch 48, Val Loss: 86.05771
Epoch 49, Val Loss: 82.23257
Epoch 50, Val Loss: 81.55568
Epoch 51, Val Loss: 81.64977
Epoch 52, Val Loss: 78.28481
Epoch 53, Val Loss: 74.84076
Epoch 54, Val Loss: 79.33473
Epoch 55, Val Loss: 75.17112
Epoch 56, Val Loss: 85.87323
Epoch 57, Val Loss: 73.81759
Epoch 58, Val Loss: 76.96537
Epoch 59, Val Loss: 72.59381
Epoch 60, Val Loss: 73.60448
Epoch 61, Val Loss: 85.13040
Epoch 62, Val Loss: 82.67368
Epoch 63, Val Loss: 75.90874
Epoch 64, Val Loss: 71.29712
Epoch 65, Val Loss: 82.73424
Epoch 66, Val Loss: 76.87694
Epoch 67, Val Loss: 69.87285
Epoch 68, Val Loss: 78.98224
Epoch 69, Val Loss: 72.36040
Epoch 70, Val Loss: 74.44662
Epoch 71, Val Loss: 71.32697
Epoch 72, Val Loss: 80.23949
Epoch 73, Val Loss: 73.14545
Epoch 74, Val Loss: 72.98796
Epoch 75, Val Loss: 108.28111
Epoch 76, Val Loss: 77.67769
Epoch 77, Val Loss: 74.20963
Epoch 78, Val Loss: 77.68037
Epoch 79, Val Loss: 72.93123
Epoch 80, Val Loss: 68.77678
Epoch 81, Val Loss: 73.22437
Epoch 82, Val Loss: 81.23528
Epoch 83, Val Loss: 79.37860
Epoch 84, Val Loss: 76.12561
Epoch 85, Val Loss: 74.99462
Epoch 86, Val Loss: 72.36247
Epoch 87, Val Loss: 71.88054
Epoch 88, Val Loss: 72.96114
Epoch 89, Val Loss: 74.20867
Epoch 90, Val Loss: 71.23396
Epoch 91, Val Loss: 77.17960
Epoch 92, Val Loss: 71.11836
Epoch 93, Val Loss: 73.66054
Epoch 94, Val Loss: 80.76259
Epoch 95, Val Loss: 72.63271
Epoch 96, Val Loss: 72.63100
Epoch 97, Val Loss: 74.78780
Epoch 98, Val Loss: 70.17621
Epoch 99, Val Loss: 73.26890
DID NOT SAVE RESULTS
{'MSE - mean': 77.96536595606167, 'MSE - std': 8.156633949357484, 'R2 - mean': 0.5156708448444735, 'R2 - std': 0.03496575265084139} 
 

Results After CV: {'MSE - mean': 77.96536595606167, 'MSE - std': 8.156633949357484, 'R2 - mean': 0.5156708448444735, 'R2 - std': 0.03496575265084139}
Train time: 829.9452788476003
Inference time: 0.19336303579984815
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 28 finished with value: 77.96536595606167 and parameters: {'p_m': 0.17359612027575835, 'alpha': 8.489660725068093, 'K': 5, 'beta': 5.694448667582565}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1600.60034
Epoch 1, Val Loss: 414.21820
Epoch 2, Val Loss: 182.12000
Epoch 3, Val Loss: 150.40765
Epoch 4, Val Loss: 144.03160
Epoch 5, Val Loss: 129.09007
Epoch 6, Val Loss: 120.11663
Epoch 7, Val Loss: 123.48100
Epoch 8, Val Loss: 110.73744
Epoch 9, Val Loss: 101.81400
Epoch 10, Val Loss: 105.50908
Epoch 11, Val Loss: 108.30649
Epoch 12, Val Loss: 109.43712
Epoch 13, Val Loss: 98.86441
Epoch 14, Val Loss: 100.44028
Epoch 15, Val Loss: 95.52277
Epoch 16, Val Loss: 98.48848
Epoch 17, Val Loss: 98.98393
Epoch 18, Val Loss: 101.34232
Epoch 19, Val Loss: 99.94617
Epoch 20, Val Loss: 104.04230
Epoch 21, Val Loss: 112.30697
Epoch 22, Val Loss: 96.00314
Epoch 23, Val Loss: 94.43262
Epoch 24, Val Loss: 94.29601
Epoch 25, Val Loss: 94.94641
Epoch 26, Val Loss: 105.20115
Epoch 27, Val Loss: 101.55270
Epoch 28, Val Loss: 95.87094
Epoch 29, Val Loss: 91.82914
Epoch 30, Val Loss: 99.50293
Epoch 31, Val Loss: 93.02362
Epoch 32, Val Loss: 97.74352
Epoch 33, Val Loss: 102.22244
Epoch 34, Val Loss: 100.66595
Epoch 35, Val Loss: 96.56712
Epoch 36, Val Loss: 97.54664
Epoch 37, Val Loss: 96.16545
Epoch 38, Val Loss: 100.44733
Epoch 39, Val Loss: 93.42142
Epoch 40, Val Loss: 101.77242
Epoch 41, Val Loss: 90.78212
Epoch 42, Val Loss: 97.89716
Epoch 43, Val Loss: 91.47557
Epoch 44, Val Loss: 97.65033
Epoch 45, Val Loss: 94.63919
Epoch 46, Val Loss: 95.33515
Epoch 47, Val Loss: 93.60233
Epoch 48, Val Loss: 95.30186
Epoch 49, Val Loss: 97.05999
Epoch 50, Val Loss: 99.53497
Epoch 51, Val Loss: 95.16134
Epoch 52, Val Loss: 117.71585
Epoch 53, Val Loss: 94.85672
Epoch 54, Val Loss: 93.41334
Epoch 55, Val Loss: 98.49403
Epoch 56, Val Loss: 94.13049
Epoch 57, Val Loss: 116.85942
Epoch 58, Val Loss: 93.84322
Epoch 59, Val Loss: 89.87202
Epoch 60, Val Loss: 107.64539
Epoch 61, Val Loss: 90.37608
Epoch 62, Val Loss: 93.08561
Epoch 63, Val Loss: 87.51044
Epoch 64, Val Loss: 87.60705
Epoch 65, Val Loss: 97.45972
Epoch 66, Val Loss: 94.80925
Epoch 67, Val Loss: 96.91789
Epoch 68, Val Loss: 94.07336
Epoch 69, Val Loss: 87.32755
Epoch 70, Val Loss: 97.83656
Epoch 71, Val Loss: 85.19057
Epoch 72, Val Loss: 105.28508
Epoch 73, Val Loss: 84.89996
Epoch 74, Val Loss: 88.68022
Epoch 75, Val Loss: 90.24169
Epoch 76, Val Loss: 85.95296
Epoch 77, Val Loss: 94.42337
Epoch 78, Val Loss: 88.43205
Epoch 79, Val Loss: 101.02547
Epoch 80, Val Loss: 87.62621
Epoch 81, Val Loss: 91.04397
Epoch 82, Val Loss: 86.26528
Epoch 83, Val Loss: 90.01018
Epoch 84, Val Loss: 88.36829
Epoch 85, Val Loss: 93.60210
Epoch 86, Val Loss: 87.29157
Epoch 87, Val Loss: 93.98164
Epoch 88, Val Loss: 85.16360
Epoch 89, Val Loss: 92.41177
Epoch 90, Val Loss: 92.60571
Epoch 91, Val Loss: 93.37090
Epoch 92, Val Loss: 88.76863
Epoch 93, Val Loss: 90.03638
Epoch 94, Val Loss: 90.29956
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.3010991805542, 'MSE - std': 0.0, 'R2 - mean': 0.48544012028781924, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 483.08612
Epoch 1, Val Loss: 273.08044
Epoch 2, Val Loss: 164.36967
Epoch 3, Val Loss: 126.62401
Epoch 4, Val Loss: 112.51283
Epoch 5, Val Loss: 116.18385
Epoch 6, Val Loss: 108.55534
Epoch 7, Val Loss: 95.98466
Epoch 8, Val Loss: 97.92311
Epoch 9, Val Loss: 99.07135
Epoch 10, Val Loss: 92.20406
Epoch 11, Val Loss: 93.46713
Epoch 12, Val Loss: 88.10631
Epoch 13, Val Loss: 90.01659
Epoch 14, Val Loss: 99.98775
Epoch 15, Val Loss: 92.25337
Epoch 16, Val Loss: 86.65171
Epoch 17, Val Loss: 84.98708
Epoch 18, Val Loss: 82.96831
Epoch 19, Val Loss: 87.46329
Epoch 20, Val Loss: 100.11473
Epoch 21, Val Loss: 99.25526
Epoch 22, Val Loss: 89.97661
Epoch 23, Val Loss: 87.94664
Epoch 24, Val Loss: 86.56844
Epoch 25, Val Loss: 82.28955
Epoch 26, Val Loss: 83.43510
Epoch 27, Val Loss: 83.32648
Epoch 28, Val Loss: 78.79200
Epoch 29, Val Loss: 105.50592
Epoch 30, Val Loss: 82.32880
Epoch 31, Val Loss: 82.54257
Epoch 32, Val Loss: 89.97639
Epoch 33, Val Loss: 90.86126
Epoch 34, Val Loss: 77.64839
Epoch 35, Val Loss: 86.92204
Epoch 36, Val Loss: 76.76659
Epoch 37, Val Loss: 85.34290
Epoch 38, Val Loss: 91.85797
Epoch 39, Val Loss: 82.09252
Epoch 40, Val Loss: 82.46965
Epoch 41, Val Loss: 75.95595
Epoch 42, Val Loss: 94.57971
Epoch 43, Val Loss: 78.76729
Epoch 44, Val Loss: 84.08405
Epoch 45, Val Loss: 83.84118
Epoch 46, Val Loss: 82.13493
Epoch 47, Val Loss: 74.97578
Epoch 48, Val Loss: 73.68755
Epoch 49, Val Loss: 77.55826
Epoch 50, Val Loss: 93.27736
Epoch 51, Val Loss: 75.70315
Epoch 52, Val Loss: 75.48005
Epoch 53, Val Loss: 75.24286
Epoch 54, Val Loss: 91.12223
Epoch 55, Val Loss: 80.72583
Epoch 56, Val Loss: 72.66413
Epoch 57, Val Loss: 73.48724
Epoch 58, Val Loss: 80.94838
Epoch 59, Val Loss: 72.81133
Epoch 60, Val Loss: 83.14169
Epoch 61, Val Loss: 70.72097
Epoch 62, Val Loss: 69.57946
Epoch 63, Val Loss: 73.31778
Epoch 64, Val Loss: 72.18430
Epoch 65, Val Loss: 72.42207
Epoch 66, Val Loss: 76.69263
Epoch 67, Val Loss: 71.15298
Epoch 68, Val Loss: 80.75462
Epoch 69, Val Loss: 72.07385
Epoch 70, Val Loss: 79.36447
Epoch 71, Val Loss: 75.65152
Epoch 72, Val Loss: 78.44361
Epoch 73, Val Loss: 69.60126
Epoch 74, Val Loss: 72.65202
Epoch 75, Val Loss: 74.88483
Epoch 76, Val Loss: 69.64721
Epoch 77, Val Loss: 71.84644
Epoch 78, Val Loss: 69.30759
Epoch 79, Val Loss: 74.51044
Epoch 80, Val Loss: 71.53827
Epoch 81, Val Loss: 71.88540
Epoch 82, Val Loss: 70.50698
Epoch 83, Val Loss: 73.55621
Epoch 84, Val Loss: 69.63095
Epoch 85, Val Loss: 73.87466
Epoch 86, Val Loss: 77.74242
Epoch 87, Val Loss: 76.83234
Epoch 88, Val Loss: 69.72950
Epoch 89, Val Loss: 85.57614
Epoch 90, Val Loss: 68.44794
Epoch 91, Val Loss: 69.16431
Epoch 92, Val Loss: 72.35827
Epoch 93, Val Loss: 72.08872
Epoch 94, Val Loss: 69.75272
Epoch 95, Val Loss: 73.01988
Epoch 96, Val Loss: 72.96212
Epoch 97, Val Loss: 69.44507
Epoch 98, Val Loss: 65.68977
Epoch 99, Val Loss: 71.45132
DID NOT SAVE RESULTS
{'MSE - mean': 81.15068936907383, 'MSE - std': 7.1504098114803725, 'R2 - mean': 0.506659886913648, 'R2 - std': 0.021219766625828862} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1879.89941
Epoch 1, Val Loss: 419.28433
Epoch 2, Val Loss: 147.60938
Epoch 3, Val Loss: 120.81509
Epoch 4, Val Loss: 117.37830
Epoch 5, Val Loss: 106.50198
Epoch 6, Val Loss: 90.15675
Epoch 7, Val Loss: 84.84734
Epoch 8, Val Loss: 87.64557
Epoch 9, Val Loss: 83.32498
Epoch 10, Val Loss: 82.08869
Epoch 11, Val Loss: 82.00145
Epoch 12, Val Loss: 83.80840
Epoch 13, Val Loss: 75.35483
Epoch 14, Val Loss: 74.49862
Epoch 15, Val Loss: 79.04680
Epoch 16, Val Loss: 85.20337
Epoch 17, Val Loss: 81.16232
Epoch 18, Val Loss: 78.53679
Epoch 19, Val Loss: 75.51350
Epoch 20, Val Loss: 79.79239
Epoch 21, Val Loss: 75.04478
Epoch 22, Val Loss: 84.75007
Epoch 23, Val Loss: 86.99114
Epoch 24, Val Loss: 93.58546
Epoch 25, Val Loss: 81.56320
Epoch 26, Val Loss: 103.40410
Epoch 27, Val Loss: 82.43583
Epoch 28, Val Loss: 77.02104
Epoch 29, Val Loss: 78.53525
Epoch 30, Val Loss: 79.98119
Epoch 31, Val Loss: 76.57318
Epoch 32, Val Loss: 71.80749
Epoch 33, Val Loss: 109.24713
Epoch 34, Val Loss: 79.11745
Epoch 35, Val Loss: 82.49998
Epoch 36, Val Loss: 81.72446
Epoch 37, Val Loss: 78.33319
Epoch 38, Val Loss: 78.48679
Epoch 39, Val Loss: 75.97328
Epoch 40, Val Loss: 81.00563
Epoch 41, Val Loss: 100.32277
Epoch 42, Val Loss: 84.99882
Epoch 43, Val Loss: 85.20741
Epoch 44, Val Loss: 88.80415
Epoch 45, Val Loss: 75.42567
Epoch 46, Val Loss: 74.89101
Epoch 47, Val Loss: 74.59619
Epoch 48, Val Loss: 75.29780
Epoch 49, Val Loss: 80.02347
Epoch 50, Val Loss: 76.21143
Epoch 51, Val Loss: 75.08663
Epoch 52, Val Loss: 77.86761
Epoch 53, Val Loss: 75.89447
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.2018135042356, 'MSE - std': 7.174769082035142, 'R2 - mean': 0.5091185453981524, 'R2 - std': 0.01767132329104447} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1309.89185
Epoch 1, Val Loss: 433.21014
Epoch 2, Val Loss: 153.06104
Epoch 3, Val Loss: 139.84084
Epoch 4, Val Loss: 118.39276
Epoch 5, Val Loss: 139.72089
Epoch 6, Val Loss: 110.71096
Epoch 7, Val Loss: 112.38735
Epoch 8, Val Loss: 108.21107
Epoch 9, Val Loss: 99.89045
Epoch 10, Val Loss: 96.56126
Epoch 11, Val Loss: 96.02146
Epoch 12, Val Loss: 100.62693
Epoch 13, Val Loss: 95.39167
Epoch 14, Val Loss: 96.92196
Epoch 15, Val Loss: 89.77395
Epoch 16, Val Loss: 108.95560
Epoch 17, Val Loss: 89.47485
Epoch 18, Val Loss: 103.35588
Epoch 19, Val Loss: 94.62845
Epoch 20, Val Loss: 86.45418
Epoch 21, Val Loss: 88.63300
Epoch 22, Val Loss: 92.79610
Epoch 23, Val Loss: 89.89961
Epoch 24, Val Loss: 94.64119
Epoch 25, Val Loss: 106.46931
Epoch 26, Val Loss: 96.11913
Epoch 27, Val Loss: 87.50617
Epoch 28, Val Loss: 97.16055
Epoch 29, Val Loss: 90.58887
Epoch 30, Val Loss: 87.12571
Epoch 31, Val Loss: 87.41789
Epoch 32, Val Loss: 90.36597
Epoch 33, Val Loss: 88.31648
Epoch 34, Val Loss: 84.30577
Epoch 35, Val Loss: 84.86805
Epoch 36, Val Loss: 96.89375
Epoch 37, Val Loss: 91.16559
Epoch 38, Val Loss: 98.55659
Epoch 39, Val Loss: 84.55817
Epoch 40, Val Loss: 80.76500
Epoch 41, Val Loss: 85.87158
Epoch 42, Val Loss: 81.43016
Epoch 43, Val Loss: 86.03442
Epoch 44, Val Loss: 85.18326
Epoch 45, Val Loss: 81.69684
Epoch 46, Val Loss: 93.34248
Epoch 47, Val Loss: 90.90698
Epoch 48, Val Loss: 85.34159
Epoch 49, Val Loss: 81.33769
Epoch 50, Val Loss: 88.25844
Epoch 51, Val Loss: 89.66447
Epoch 52, Val Loss: 86.35757
Epoch 53, Val Loss: 82.74457
Epoch 54, Val Loss: 84.05283
Epoch 55, Val Loss: 81.95354
Epoch 56, Val Loss: 80.64793
Epoch 57, Val Loss: 85.66005
Epoch 58, Val Loss: 81.12743
Epoch 59, Val Loss: 79.50040
Epoch 60, Val Loss: 81.14535
Epoch 61, Val Loss: 82.34265
Epoch 62, Val Loss: 86.73396
Epoch 63, Val Loss: 81.78014
Epoch 64, Val Loss: 78.15966
Epoch 65, Val Loss: 80.32429
Epoch 66, Val Loss: 92.64666
Epoch 67, Val Loss: 82.30643
Epoch 68, Val Loss: 80.31126
Epoch 69, Val Loss: 81.79543
Epoch 70, Val Loss: 79.69867
Epoch 71, Val Loss: 81.06960
Epoch 72, Val Loss: 95.71013
Epoch 73, Val Loss: 83.88495
Epoch 74, Val Loss: 85.72938
Epoch 75, Val Loss: 84.22533
Epoch 76, Val Loss: 93.52422
Epoch 77, Val Loss: 79.52903
Epoch 78, Val Loss: 80.77367
Epoch 79, Val Loss: 79.96870
Epoch 80, Val Loss: 81.91056
Epoch 81, Val Loss: 80.18424
Epoch 82, Val Loss: 82.15811
Epoch 83, Val Loss: 80.38869
Epoch 84, Val Loss: 82.31085
Epoch 85, Val Loss: 86.71936
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.49504390257658, 'MSE - std': 7.374598329063147, 'R2 - mean': 0.5009365420481267, 'R2 - std': 0.020857667333667798} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1603.76147
Epoch 1, Val Loss: 389.29404
Epoch 2, Val Loss: 163.01654
Epoch 3, Val Loss: 128.35410
Epoch 4, Val Loss: 119.81009
Epoch 5, Val Loss: 121.38723
Epoch 6, Val Loss: 112.81367
Epoch 7, Val Loss: 99.35877
Epoch 8, Val Loss: 103.10571
Epoch 9, Val Loss: 102.31585
Epoch 10, Val Loss: 103.15170
Epoch 11, Val Loss: 98.98875
Epoch 12, Val Loss: 99.82959
Epoch 13, Val Loss: 100.38597
Epoch 14, Val Loss: 97.08834
Epoch 15, Val Loss: 103.92783
Epoch 16, Val Loss: 99.31841
Epoch 17, Val Loss: 106.70492
Epoch 18, Val Loss: 100.33634
Epoch 19, Val Loss: 102.68887
Epoch 20, Val Loss: 98.27005
Epoch 21, Val Loss: 105.86578
Epoch 22, Val Loss: 101.20334
Epoch 23, Val Loss: 94.91669
Epoch 24, Val Loss: 96.55344
Epoch 25, Val Loss: 98.18584
Epoch 26, Val Loss: 92.13889
Epoch 27, Val Loss: 109.49449
Epoch 28, Val Loss: 97.84369
Epoch 29, Val Loss: 94.59008
Epoch 30, Val Loss: 95.55219
Epoch 31, Val Loss: 99.23752
Epoch 32, Val Loss: 97.07069
Epoch 33, Val Loss: 88.66452
Epoch 34, Val Loss: 94.40429
Epoch 35, Val Loss: 95.66236
Epoch 36, Val Loss: 94.82523
Epoch 37, Val Loss: 94.66734
Epoch 38, Val Loss: 86.19831
Epoch 39, Val Loss: 95.81997
Epoch 40, Val Loss: 104.53061
Epoch 41, Val Loss: 101.34000
Epoch 42, Val Loss: 94.55203
Epoch 43, Val Loss: 92.59899
Epoch 44, Val Loss: 101.82838
Epoch 45, Val Loss: 91.52542
Epoch 46, Val Loss: 84.47539
Epoch 47, Val Loss: 86.40544
Epoch 48, Val Loss: 91.93779
Epoch 49, Val Loss: 98.30312
Epoch 50, Val Loss: 87.81487
Epoch 51, Val Loss: 93.91302
Epoch 52, Val Loss: 85.48987
Epoch 53, Val Loss: 94.07895
Epoch 54, Val Loss: 88.29648
Epoch 55, Val Loss: 86.05635
Epoch 56, Val Loss: 89.05406
Epoch 57, Val Loss: 91.93696
Epoch 58, Val Loss: 84.64652
Epoch 59, Val Loss: 79.18339
Epoch 60, Val Loss: 88.18748
Epoch 61, Val Loss: 84.40462
Epoch 62, Val Loss: 79.75023
Epoch 63, Val Loss: 85.83316
Epoch 64, Val Loss: 88.12680
Epoch 65, Val Loss: 81.12377
Epoch 66, Val Loss: 88.61387
Epoch 67, Val Loss: 80.00066
Epoch 68, Val Loss: 84.92506
Epoch 69, Val Loss: 83.22781
Epoch 70, Val Loss: 84.38982
Epoch 71, Val Loss: 78.38641
Epoch 72, Val Loss: 79.32719
Epoch 73, Val Loss: 76.82835
Epoch 74, Val Loss: 78.84599
Epoch 75, Val Loss: 80.57876
Epoch 76, Val Loss: 79.86652
Epoch 77, Val Loss: 83.08549
Epoch 78, Val Loss: 85.78645
Epoch 79, Val Loss: 81.79739
Epoch 80, Val Loss: 78.36185
Epoch 81, Val Loss: 77.20183
Epoch 82, Val Loss: 80.61883
Epoch 83, Val Loss: 75.70985
Epoch 84, Val Loss: 74.77066
Epoch 85, Val Loss: 75.93501
Epoch 86, Val Loss: 79.71579
Epoch 87, Val Loss: 75.59174
Epoch 88, Val Loss: 86.35332
Epoch 89, Val Loss: 79.71147
Epoch 90, Val Loss: 73.51006
Epoch 91, Val Loss: 86.43723
Epoch 92, Val Loss: 72.86044
Epoch 93, Val Loss: 77.95354
Epoch 94, Val Loss: 78.27550
Epoch 95, Val Loss: 71.03516
Epoch 96, Val Loss: 86.23250
Epoch 97, Val Loss: 83.72155
Epoch 98, Val Loss: 73.15514
Epoch 99, Val Loss: 73.68633
DID NOT SAVE RESULTS
{'MSE - mean': 78.80537275966837, 'MSE - std': 7.41132341061457, 'R2 - mean': 0.5103807808470501, 'R2 - std': 0.026548228099930276} 
 

Results After CV: {'MSE - mean': 78.80537275966837, 'MSE - std': 7.41132341061457, 'R2 - mean': 0.5103807808470501, 'R2 - std': 0.026548228099930276}
Train time: 833.6027348910029
Inference time: 0.18595600859844125
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 29 finished with value: 78.80537275966837 and parameters: {'p_m': 0.16287152449343195, 'alpha': 9.956647302810504, 'K': 5, 'beta': 5.3849613482486}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1127.39417
Epoch 1, Val Loss: 390.97629
Epoch 2, Val Loss: 188.22597
Epoch 3, Val Loss: 164.08748
Epoch 4, Val Loss: 150.12405
Epoch 5, Val Loss: 146.14514
Epoch 6, Val Loss: 123.53407
Epoch 7, Val Loss: 124.21024
Epoch 8, Val Loss: 122.58215
Epoch 9, Val Loss: 112.49415
Epoch 10, Val Loss: 109.60149
Epoch 11, Val Loss: 122.69322
Epoch 12, Val Loss: 111.85437
Epoch 13, Val Loss: 105.25864
Epoch 14, Val Loss: 109.49107
Epoch 15, Val Loss: 107.73769
Epoch 16, Val Loss: 100.21963
Epoch 17, Val Loss: 98.71469
Epoch 18, Val Loss: 108.46355
Epoch 19, Val Loss: 98.03271
Epoch 20, Val Loss: 104.66949
Epoch 21, Val Loss: 97.99525
Epoch 22, Val Loss: 95.14114
Epoch 23, Val Loss: 106.25287
Epoch 24, Val Loss: 106.32719
Epoch 25, Val Loss: 93.83304
Epoch 26, Val Loss: 103.33795
Epoch 27, Val Loss: 92.55965
Epoch 28, Val Loss: 97.25894
Epoch 29, Val Loss: 99.08733
Epoch 30, Val Loss: 95.83829
Epoch 31, Val Loss: 98.13222
Epoch 32, Val Loss: 106.24611
Epoch 33, Val Loss: 102.73245
Epoch 34, Val Loss: 95.60477
Epoch 35, Val Loss: 98.67587
Epoch 36, Val Loss: 96.71074
Epoch 37, Val Loss: 98.17583
Epoch 38, Val Loss: 96.69686
Epoch 39, Val Loss: 94.23014
Epoch 40, Val Loss: 101.92926
Epoch 41, Val Loss: 101.16326
Epoch 42, Val Loss: 94.84838
Epoch 43, Val Loss: 100.43915
Epoch 44, Val Loss: 91.54833
Epoch 45, Val Loss: 91.81187
Epoch 46, Val Loss: 91.90358
Epoch 47, Val Loss: 88.64175
Epoch 48, Val Loss: 94.46792
Epoch 49, Val Loss: 88.52100
Epoch 50, Val Loss: 97.30270
Epoch 51, Val Loss: 92.22013
Epoch 52, Val Loss: 91.11662
Epoch 53, Val Loss: 91.37500
Epoch 54, Val Loss: 95.04756
Epoch 55, Val Loss: 87.36951
Epoch 56, Val Loss: 89.87260
Epoch 57, Val Loss: 87.40263
Epoch 58, Val Loss: 87.71467
Epoch 59, Val Loss: 86.60076
Epoch 60, Val Loss: 85.37624
Epoch 61, Val Loss: 92.17307
Epoch 62, Val Loss: 88.54207
Epoch 63, Val Loss: 88.64392
Epoch 64, Val Loss: 94.81029
Epoch 65, Val Loss: 84.63867
Epoch 66, Val Loss: 89.83047
Epoch 67, Val Loss: 89.13598
Epoch 68, Val Loss: 91.39706
Epoch 69, Val Loss: 89.51173
Epoch 70, Val Loss: 98.25989
Epoch 71, Val Loss: 88.18179
Epoch 72, Val Loss: 88.06710
Epoch 73, Val Loss: 90.11052
Epoch 74, Val Loss: 87.59244
Epoch 75, Val Loss: 84.71751
Epoch 76, Val Loss: 82.36395
Epoch 77, Val Loss: 85.99341
Epoch 78, Val Loss: 85.83324
Epoch 79, Val Loss: 84.96560
Epoch 80, Val Loss: 85.69523
Epoch 81, Val Loss: 88.23910
Epoch 82, Val Loss: 84.86510
Epoch 83, Val Loss: 95.68407
Epoch 84, Val Loss: 84.95412
Epoch 85, Val Loss: 89.42406
Epoch 86, Val Loss: 91.82784
Epoch 87, Val Loss: 85.96447
Epoch 88, Val Loss: 87.21505
Epoch 89, Val Loss: 84.47714
Epoch 90, Val Loss: 82.82687
Epoch 91, Val Loss: 94.47212
Epoch 92, Val Loss: 86.72254
Epoch 93, Val Loss: 89.24551
Epoch 94, Val Loss: 84.67075
Epoch 95, Val Loss: 92.88327
Epoch 96, Val Loss: 88.84903
Epoch 97, Val Loss: 83.45105
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.04670824917939, 'MSE - std': 0.0, 'R2 - mean': 0.4869225408721932, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1526.14185
Epoch 1, Val Loss: 360.40952
Epoch 2, Val Loss: 169.98747
Epoch 3, Val Loss: 137.49411
Epoch 4, Val Loss: 125.15442
Epoch 5, Val Loss: 121.47276
Epoch 6, Val Loss: 119.50614
Epoch 7, Val Loss: 106.52624
Epoch 8, Val Loss: 103.48436
Epoch 9, Val Loss: 104.24004
Epoch 10, Val Loss: 108.93141
Epoch 11, Val Loss: 101.02061
Epoch 12, Val Loss: 100.91367
Epoch 13, Val Loss: 92.19339
Epoch 14, Val Loss: 93.39635
Epoch 15, Val Loss: 81.15343
Epoch 16, Val Loss: 90.84235
Epoch 17, Val Loss: 85.26882
Epoch 18, Val Loss: 92.66414
Epoch 19, Val Loss: 93.05505
Epoch 20, Val Loss: 84.97610
Epoch 21, Val Loss: 89.39046
Epoch 22, Val Loss: 87.52973
Epoch 23, Val Loss: 86.79321
Epoch 24, Val Loss: 86.71994
Epoch 25, Val Loss: 93.87788
Epoch 26, Val Loss: 85.89470
Epoch 27, Val Loss: 96.45421
Epoch 28, Val Loss: 91.85510
Epoch 29, Val Loss: 91.54641
Epoch 30, Val Loss: 96.12720
Epoch 31, Val Loss: 83.17083
Epoch 32, Val Loss: 84.75916
Epoch 33, Val Loss: 80.25385
Epoch 34, Val Loss: 83.85444
Epoch 35, Val Loss: 81.92006
Epoch 36, Val Loss: 77.80508
Epoch 37, Val Loss: 87.85776
Epoch 38, Val Loss: 82.00178
Epoch 39, Val Loss: 78.85368
Epoch 40, Val Loss: 87.91713
Epoch 41, Val Loss: 80.24989
Epoch 42, Val Loss: 82.03175
Epoch 43, Val Loss: 78.24375
Epoch 44, Val Loss: 77.97754
Epoch 45, Val Loss: 85.09514
Epoch 46, Val Loss: 76.56520
Epoch 47, Val Loss: 86.94930
Epoch 48, Val Loss: 72.08799
Epoch 49, Val Loss: 77.18750
Epoch 50, Val Loss: 73.65060
Epoch 51, Val Loss: 87.66994
Epoch 52, Val Loss: 79.62580
Epoch 53, Val Loss: 83.12077
Epoch 54, Val Loss: 79.49514
Epoch 55, Val Loss: 80.52225
Epoch 56, Val Loss: 78.11163
Epoch 57, Val Loss: 77.40209
Epoch 58, Val Loss: 74.46500
Epoch 59, Val Loss: 73.42085
Epoch 60, Val Loss: 75.25200
Epoch 61, Val Loss: 77.51495
Epoch 62, Val Loss: 80.10294
Epoch 63, Val Loss: 81.44162
Epoch 64, Val Loss: 73.60215
Epoch 65, Val Loss: 80.43096
Epoch 66, Val Loss: 75.29137
Epoch 67, Val Loss: 76.01304
Epoch 68, Val Loss: 72.83628
Epoch 69, Val Loss: 77.29250
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.7044317776884, 'MSE - std': 4.342276471490997, 'R2 - mean': 0.49029676563274305, 'R2 - std': 0.0033742247605498266} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1026.38440
Epoch 1, Val Loss: 352.07840
Epoch 2, Val Loss: 155.71085
Epoch 3, Val Loss: 119.68668
Epoch 4, Val Loss: 123.55115
Epoch 5, Val Loss: 101.48296
Epoch 6, Val Loss: 97.27165
Epoch 7, Val Loss: 93.17788
Epoch 8, Val Loss: 91.82832
Epoch 9, Val Loss: 90.92208
Epoch 10, Val Loss: 95.17159
Epoch 11, Val Loss: 81.04494
Epoch 12, Val Loss: 83.93205
Epoch 13, Val Loss: 88.02001
Epoch 14, Val Loss: 84.53382
Epoch 15, Val Loss: 83.79158
Epoch 16, Val Loss: 89.87825
Epoch 17, Val Loss: 86.49196
Epoch 18, Val Loss: 82.55270
Epoch 19, Val Loss: 81.19784
Epoch 20, Val Loss: 84.51553
Epoch 21, Val Loss: 95.84361
Epoch 22, Val Loss: 84.33252
Epoch 23, Val Loss: 92.04453
Epoch 24, Val Loss: 85.80737
Epoch 25, Val Loss: 85.26546
Epoch 26, Val Loss: 82.04594
Epoch 27, Val Loss: 82.54819
Epoch 28, Val Loss: 82.88905
Epoch 29, Val Loss: 84.06693
Epoch 30, Val Loss: 83.27745
Epoch 31, Val Loss: 106.41475
Epoch 32, Val Loss: 90.10384
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.79551129907729, 'MSE - std': 3.5477928718677654, 'R2 - mean': 0.47205656396861, 'R2 - std': 0.025942246921182938} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1015.80646
Epoch 1, Val Loss: 313.09402
Epoch 2, Val Loss: 183.20703
Epoch 3, Val Loss: 144.61694
Epoch 4, Val Loss: 137.00159
Epoch 5, Val Loss: 124.28780
Epoch 6, Val Loss: 116.13229
Epoch 7, Val Loss: 110.42195
Epoch 8, Val Loss: 109.95856
Epoch 9, Val Loss: 123.70357
Epoch 10, Val Loss: 103.23356
Epoch 11, Val Loss: 96.65836
Epoch 12, Val Loss: 94.15552
Epoch 13, Val Loss: 104.76492
Epoch 14, Val Loss: 99.99209
Epoch 15, Val Loss: 97.67901
Epoch 16, Val Loss: 103.85813
Epoch 17, Val Loss: 103.29811
Epoch 18, Val Loss: 95.21416
Epoch 19, Val Loss: 96.51586
Epoch 20, Val Loss: 89.89998
Epoch 21, Val Loss: 104.89463
Epoch 22, Val Loss: 93.57299
Epoch 23, Val Loss: 93.40836
Epoch 24, Val Loss: 93.52390
Epoch 25, Val Loss: 97.00390
Epoch 26, Val Loss: 90.01628
Epoch 27, Val Loss: 92.09975
Epoch 28, Val Loss: 85.72663
Epoch 29, Val Loss: 91.63719
Epoch 30, Val Loss: 90.74461
Epoch 31, Val Loss: 93.94160
Epoch 32, Val Loss: 92.96744
Epoch 33, Val Loss: 87.49395
Epoch 34, Val Loss: 87.52119
Epoch 35, Val Loss: 79.88029
Epoch 36, Val Loss: 84.13920
Epoch 37, Val Loss: 86.18094
Epoch 38, Val Loss: 102.60819
Epoch 39, Val Loss: 84.75699
Epoch 40, Val Loss: 88.04610
Epoch 41, Val Loss: 86.07129
Epoch 42, Val Loss: 89.82357
Epoch 43, Val Loss: 82.90853
Epoch 44, Val Loss: 81.81567
Epoch 45, Val Loss: 83.86145
Epoch 46, Val Loss: 92.18857
Epoch 47, Val Loss: 82.46043
Epoch 48, Val Loss: 83.90310
Epoch 49, Val Loss: 85.12683
Epoch 50, Val Loss: 83.36295
Epoch 51, Val Loss: 81.15217
Epoch 52, Val Loss: 80.93778
Epoch 53, Val Loss: 79.38883
Epoch 54, Val Loss: 80.66965
Epoch 55, Val Loss: 87.98026
Epoch 56, Val Loss: 79.43362
Epoch 57, Val Loss: 96.07418
Epoch 58, Val Loss: 78.70303
Epoch 59, Val Loss: 83.51134
Epoch 60, Val Loss: 80.77076
Epoch 61, Val Loss: 78.10059
Epoch 62, Val Loss: 83.82177
Epoch 63, Val Loss: 81.83679
Epoch 64, Val Loss: 78.86226
Epoch 65, Val Loss: 82.47714
Epoch 66, Val Loss: 82.78105
Epoch 67, Val Loss: 78.12546
Epoch 68, Val Loss: 81.55139
Epoch 69, Val Loss: 85.97427
Epoch 70, Val Loss: 99.09911
Epoch 71, Val Loss: 79.09634
Epoch 72, Val Loss: 77.06910
Epoch 73, Val Loss: 80.91251
Epoch 74, Val Loss: 80.14270
Epoch 75, Val Loss: 78.76614
Epoch 76, Val Loss: 79.43386
Epoch 77, Val Loss: 80.40988
Epoch 78, Val Loss: 79.32340
Epoch 79, Val Loss: 85.12660
Epoch 80, Val Loss: 79.52699
Epoch 81, Val Loss: 81.76038
Epoch 82, Val Loss: 82.57114
Epoch 83, Val Loss: 117.68198
Epoch 84, Val Loss: 81.04321
Epoch 85, Val Loss: 80.26741
Epoch 86, Val Loss: 85.05515
Epoch 87, Val Loss: 81.42017
Epoch 88, Val Loss: 80.32852
Epoch 89, Val Loss: 81.76057
Epoch 90, Val Loss: 84.44161
Epoch 91, Val Loss: 85.57488
Epoch 92, Val Loss: 80.13611
Epoch 93, Val Loss: 84.17572
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.98556041541642, 'MSE - std': 3.6998346441639094, 'R2 - mean': 0.47137075599149725, 'R2 - std': 0.022498025007411958} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 936.73157
Epoch 1, Val Loss: 321.68594
Epoch 2, Val Loss: 163.80794
Epoch 3, Val Loss: 138.98232
Epoch 4, Val Loss: 134.64168
Epoch 5, Val Loss: 111.49612
Epoch 6, Val Loss: 109.94592
Epoch 7, Val Loss: 106.22014
Epoch 8, Val Loss: 98.65665
Epoch 9, Val Loss: 105.78622
Epoch 10, Val Loss: 101.50626
Epoch 11, Val Loss: 107.36668
Epoch 12, Val Loss: 97.96585
Epoch 13, Val Loss: 90.87076
Epoch 14, Val Loss: 88.20644
Epoch 15, Val Loss: 92.15176
Epoch 16, Val Loss: 96.97975
Epoch 17, Val Loss: 103.78228
Epoch 18, Val Loss: 97.68144
Epoch 19, Val Loss: 83.35268
Epoch 20, Val Loss: 92.82845
Epoch 21, Val Loss: 101.00168
Epoch 22, Val Loss: 104.85377
Epoch 23, Val Loss: 80.92336
Epoch 24, Val Loss: 92.50623
Epoch 25, Val Loss: 97.53214
Epoch 26, Val Loss: 81.86178
Epoch 27, Val Loss: 87.56113
Epoch 28, Val Loss: 89.51725
Epoch 29, Val Loss: 87.30753
Epoch 30, Val Loss: 86.41260
Epoch 31, Val Loss: 81.47365
Epoch 32, Val Loss: 88.53454
Epoch 33, Val Loss: 86.05776
Epoch 34, Val Loss: 81.15524
Epoch 35, Val Loss: 85.48533
Epoch 36, Val Loss: 82.62067
Epoch 37, Val Loss: 92.73307
Epoch 38, Val Loss: 92.98732
Epoch 39, Val Loss: 86.20113
Epoch 40, Val Loss: 74.35958
Epoch 41, Val Loss: 89.16838
Epoch 42, Val Loss: 92.84926
Epoch 43, Val Loss: 80.76299
Epoch 44, Val Loss: 84.44438
Epoch 45, Val Loss: 80.06209
Epoch 46, Val Loss: 84.85978
Epoch 47, Val Loss: 80.37075
Epoch 48, Val Loss: 84.48888
Epoch 49, Val Loss: 77.68184
Epoch 50, Val Loss: 84.17542
Epoch 51, Val Loss: 88.26865
Epoch 52, Val Loss: 78.50542
Epoch 53, Val Loss: 76.36739
Epoch 54, Val Loss: 74.58753
Epoch 55, Val Loss: 90.95747
Epoch 56, Val Loss: 75.65897
Epoch 57, Val Loss: 83.28615
Epoch 58, Val Loss: 76.33450
Epoch 59, Val Loss: 85.45111
Epoch 60, Val Loss: 82.24973
Epoch 61, Val Loss: 80.78358
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.06514246842978, 'MSE - std': 5.0698167106669585, 'R2 - mean': 0.4825428122071248, 'R2 - std': 0.03006972337298561} 
 

Results After CV: {'MSE - mean': 83.06514246842978, 'MSE - std': 5.0698167106669585, 'R2 - mean': 0.4825428122071248, 'R2 - std': 0.03006972337298561}
Train time: 686.4761402706005
Inference time: 0.17791783860011492
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 30 finished with value: 83.06514246842978 and parameters: {'p_m': 0.2609394016987665, 'alpha': 8.822877253577817, 'K': 5, 'beta': 4.721631514003219}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 673.10748
Epoch 1, Val Loss: 397.49472
Epoch 2, Val Loss: 190.99356
Epoch 3, Val Loss: 172.70609
Epoch 4, Val Loss: 161.78403
Epoch 5, Val Loss: 138.74188
Epoch 6, Val Loss: 132.86000
Epoch 7, Val Loss: 148.48369
Epoch 8, Val Loss: 118.16754
Epoch 9, Val Loss: 127.51759
Epoch 10, Val Loss: 120.44411
Epoch 11, Val Loss: 117.48804
Epoch 12, Val Loss: 113.88297
Epoch 13, Val Loss: 114.06486
Epoch 14, Val Loss: 130.39490
Epoch 15, Val Loss: 111.69150
Epoch 16, Val Loss: 110.15173
Epoch 17, Val Loss: 114.45433
Epoch 18, Val Loss: 105.85544
Epoch 19, Val Loss: 114.36426
Epoch 20, Val Loss: 116.78914
Epoch 21, Val Loss: 105.30952
Epoch 22, Val Loss: 121.98415
Epoch 23, Val Loss: 99.26996
Epoch 24, Val Loss: 92.43469
Epoch 25, Val Loss: 104.12111
Epoch 26, Val Loss: 99.21712
Epoch 27, Val Loss: 97.60997
Epoch 28, Val Loss: 101.82866
Epoch 29, Val Loss: 99.22945
Epoch 30, Val Loss: 94.10648
Epoch 31, Val Loss: 102.31748
Epoch 32, Val Loss: 92.57631
Epoch 33, Val Loss: 95.28579
Epoch 34, Val Loss: 93.55630
Epoch 35, Val Loss: 91.51785
Epoch 36, Val Loss: 86.85236
Epoch 37, Val Loss: 102.04311
Epoch 38, Val Loss: 88.39434
Epoch 39, Val Loss: 91.51620
Epoch 40, Val Loss: 94.76257
Epoch 41, Val Loss: 85.08403
Epoch 42, Val Loss: 87.20137
Epoch 43, Val Loss: 91.02657
Epoch 44, Val Loss: 87.40185
Epoch 45, Val Loss: 85.50553
Epoch 46, Val Loss: 94.92610
Epoch 47, Val Loss: 88.48936
Epoch 48, Val Loss: 88.11977
Epoch 49, Val Loss: 97.23050
Epoch 50, Val Loss: 83.10089
Epoch 51, Val Loss: 81.61355
Epoch 52, Val Loss: 92.55541
Epoch 53, Val Loss: 108.17714
Epoch 54, Val Loss: 85.78053
Epoch 55, Val Loss: 86.40588
Epoch 56, Val Loss: 89.61573
Epoch 57, Val Loss: 89.56041
Epoch 58, Val Loss: 88.93874
Epoch 59, Val Loss: 89.79021
Epoch 60, Val Loss: 87.97757
Epoch 61, Val Loss: 87.31503
Epoch 62, Val Loss: 82.96768
Epoch 63, Val Loss: 83.07497
Epoch 64, Val Loss: 87.39359
Epoch 65, Val Loss: 86.32356
Epoch 66, Val Loss: 90.85413
Epoch 67, Val Loss: 91.18510
Epoch 68, Val Loss: 86.24954
Epoch 69, Val Loss: 86.78805
Epoch 70, Val Loss: 86.89424
Epoch 71, Val Loss: 88.16808
Epoch 72, Val Loss: 88.24810
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.00764278159835, 'MSE - std': 0.0, 'R2 - mean': 0.4988048536798555, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1213.21436
Epoch 1, Val Loss: 390.40399
Epoch 2, Val Loss: 175.53867
Epoch 3, Val Loss: 159.42282
Epoch 4, Val Loss: 156.25699
Epoch 5, Val Loss: 121.28917
Epoch 6, Val Loss: 132.28827
Epoch 7, Val Loss: 110.12183
Epoch 8, Val Loss: 112.20615
Epoch 9, Val Loss: 98.15799
Epoch 10, Val Loss: 101.50244
Epoch 11, Val Loss: 87.12719
Epoch 12, Val Loss: 106.16174
Epoch 13, Val Loss: 104.69611
Epoch 14, Val Loss: 90.97540
Epoch 15, Val Loss: 91.17609
Epoch 16, Val Loss: 96.19449
Epoch 17, Val Loss: 98.63896
Epoch 18, Val Loss: 88.74892
Epoch 19, Val Loss: 88.58200
Epoch 20, Val Loss: 90.27048
Epoch 21, Val Loss: 84.38079
Epoch 22, Val Loss: 116.54945
Epoch 23, Val Loss: 83.67635
Epoch 24, Val Loss: 92.34288
Epoch 25, Val Loss: 87.29085
Epoch 26, Val Loss: 82.57592
Epoch 27, Val Loss: 78.68326
Epoch 28, Val Loss: 80.03517
Epoch 29, Val Loss: 86.11296
Epoch 30, Val Loss: 83.72936
Epoch 31, Val Loss: 89.52369
Epoch 32, Val Loss: 84.34703
Epoch 33, Val Loss: 86.08043
Epoch 34, Val Loss: 78.13641
Epoch 35, Val Loss: 79.49031
Epoch 36, Val Loss: 72.54449
Epoch 37, Val Loss: 75.08159
Epoch 38, Val Loss: 82.11781
Epoch 39, Val Loss: 90.55045
Epoch 40, Val Loss: 76.53945
Epoch 41, Val Loss: 75.78626
Epoch 42, Val Loss: 75.78941
Epoch 43, Val Loss: 69.23077
Epoch 44, Val Loss: 74.59727
Epoch 45, Val Loss: 71.32327
Epoch 46, Val Loss: 81.14129
Epoch 47, Val Loss: 74.34739
Epoch 48, Val Loss: 85.49403
Epoch 49, Val Loss: 68.83602
Epoch 50, Val Loss: 74.34001
Epoch 51, Val Loss: 80.59543
Epoch 52, Val Loss: 78.91730
Epoch 53, Val Loss: 71.45017
Epoch 54, Val Loss: 73.46247
Epoch 55, Val Loss: 76.62064
Epoch 56, Val Loss: 87.72295
Epoch 57, Val Loss: 87.41199
Epoch 58, Val Loss: 71.36861
Epoch 59, Val Loss: 75.12421
Epoch 60, Val Loss: 70.53364
Epoch 61, Val Loss: 72.64101
Epoch 62, Val Loss: 74.43830
Epoch 63, Val Loss: 75.69712
Epoch 64, Val Loss: 76.63908
Epoch 65, Val Loss: 76.13040
Epoch 66, Val Loss: 78.04426
Epoch 67, Val Loss: 73.08945
Epoch 68, Val Loss: 68.88514
Epoch 69, Val Loss: 72.63329
Epoch 70, Val Loss: 76.00330
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.4432898546392, 'MSE - std': 4.5643529269591525, 'R2 - mean': 0.5041593645514657, 'R2 - std': 0.0053545108716102074} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 601.94934
Epoch 1, Val Loss: 410.19910
Epoch 2, Val Loss: 159.97433
Epoch 3, Val Loss: 133.20621
Epoch 4, Val Loss: 116.26832
Epoch 5, Val Loss: 123.11909
Epoch 6, Val Loss: 112.90405
Epoch 7, Val Loss: 94.65172
Epoch 8, Val Loss: 113.88068
Epoch 9, Val Loss: 97.92822
Epoch 10, Val Loss: 85.70316
Epoch 11, Val Loss: 89.03037
Epoch 12, Val Loss: 79.30693
Epoch 13, Val Loss: 85.85986
Epoch 14, Val Loss: 84.69614
Epoch 15, Val Loss: 79.09112
Epoch 16, Val Loss: 81.83009
Epoch 17, Val Loss: 93.89877
Epoch 18, Val Loss: 117.06544
Epoch 19, Val Loss: 83.23047
Epoch 20, Val Loss: 83.60982
Epoch 21, Val Loss: 79.94174
Epoch 22, Val Loss: 99.01113
Epoch 23, Val Loss: 80.10408
Epoch 24, Val Loss: 83.13283
Epoch 25, Val Loss: 84.69207
Epoch 26, Val Loss: 83.40082
Epoch 27, Val Loss: 84.05422
Epoch 28, Val Loss: 85.31547
Epoch 29, Val Loss: 79.01978
Epoch 30, Val Loss: 87.71947
Epoch 31, Val Loss: 83.85764
Epoch 32, Val Loss: 79.88478
Epoch 33, Val Loss: 78.53913
Epoch 34, Val Loss: 78.19453
Epoch 35, Val Loss: 80.08260
Epoch 36, Val Loss: 96.96371
Epoch 37, Val Loss: 78.16401
Epoch 38, Val Loss: 70.82667
Epoch 39, Val Loss: 75.66858
Epoch 40, Val Loss: 74.64281
Epoch 41, Val Loss: 78.49720
Epoch 42, Val Loss: 72.21517
Epoch 43, Val Loss: 79.89580
Epoch 44, Val Loss: 71.72791
Epoch 45, Val Loss: 71.06416
Epoch 46, Val Loss: 70.17296
Epoch 47, Val Loss: 71.02346
Epoch 48, Val Loss: 71.67393
Epoch 49, Val Loss: 75.79037
Epoch 50, Val Loss: 76.36476
Epoch 51, Val Loss: 67.65413
Epoch 52, Val Loss: 66.33328
Epoch 53, Val Loss: 73.12570
Epoch 54, Val Loss: 71.46552
Epoch 55, Val Loss: 75.12006
Epoch 56, Val Loss: 68.86477
Epoch 57, Val Loss: 67.98833
Epoch 58, Val Loss: 69.18465
Epoch 59, Val Loss: 68.18074
Epoch 60, Val Loss: 71.12962
Epoch 61, Val Loss: 72.13605
Epoch 62, Val Loss: 68.95689
Epoch 63, Val Loss: 74.59945
Epoch 64, Val Loss: 70.09940
Epoch 65, Val Loss: 67.85410
Epoch 66, Val Loss: 70.06818
Epoch 67, Val Loss: 70.27321
Epoch 68, Val Loss: 68.66361
Epoch 69, Val Loss: 67.71496
Epoch 70, Val Loss: 71.20930
Epoch 71, Val Loss: 70.98596
Epoch 72, Val Loss: 87.95012
Epoch 73, Val Loss: 73.31638
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.70897935288055, 'MSE - std': 7.662654258285329, 'R2 - mean': 0.5187961133892433, 'R2 - std': 0.0211561501900312} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 514.68011
Epoch 1, Val Loss: 379.73346
Epoch 2, Val Loss: 172.03236
Epoch 3, Val Loss: 171.18811
Epoch 4, Val Loss: 156.70119
Epoch 5, Val Loss: 126.85435
Epoch 6, Val Loss: 122.15640
Epoch 7, Val Loss: 110.02663
Epoch 8, Val Loss: 121.30373
Epoch 9, Val Loss: 101.72177
Epoch 10, Val Loss: 101.65736
Epoch 11, Val Loss: 101.50092
Epoch 12, Val Loss: 98.59644
Epoch 13, Val Loss: 106.20541
Epoch 14, Val Loss: 101.61757
Epoch 15, Val Loss: 117.67375
Epoch 16, Val Loss: 115.84746
Epoch 17, Val Loss: 91.09012
Epoch 18, Val Loss: 89.16821
Epoch 19, Val Loss: 89.16595
Epoch 20, Val Loss: 96.96909
Epoch 21, Val Loss: 88.13565
Epoch 22, Val Loss: 92.65914
Epoch 23, Val Loss: 87.59453
Epoch 24, Val Loss: 90.22135
Epoch 25, Val Loss: 85.04991
Epoch 26, Val Loss: 99.16222
Epoch 27, Val Loss: 89.23392
Epoch 28, Val Loss: 97.08607
Epoch 29, Val Loss: 83.12659
Epoch 30, Val Loss: 84.28076
Epoch 31, Val Loss: 82.44842
Epoch 32, Val Loss: 85.40683
Epoch 33, Val Loss: 81.86237
Epoch 34, Val Loss: 88.20374
Epoch 35, Val Loss: 85.65047
Epoch 36, Val Loss: 88.59533
Epoch 37, Val Loss: 82.26763
Epoch 38, Val Loss: 84.70778
Epoch 39, Val Loss: 82.78962
Epoch 40, Val Loss: 86.60693
Epoch 41, Val Loss: 92.85861
Epoch 42, Val Loss: 82.62772
Epoch 43, Val Loss: 80.37582
Epoch 44, Val Loss: 86.47149
Epoch 45, Val Loss: 85.84132
Epoch 46, Val Loss: 82.76301
Epoch 47, Val Loss: 88.83409
Epoch 48, Val Loss: 84.72775
Epoch 49, Val Loss: 82.66060
Epoch 50, Val Loss: 89.99016
Epoch 51, Val Loss: 84.84102
Epoch 52, Val Loss: 87.91965
Epoch 53, Val Loss: 84.22887
Epoch 54, Val Loss: 80.25647
Epoch 55, Val Loss: 81.89488
Epoch 56, Val Loss: 82.96989
Epoch 57, Val Loss: 80.27071
Epoch 58, Val Loss: 82.49190
Epoch 59, Val Loss: 80.58648
Epoch 60, Val Loss: 81.15803
Epoch 61, Val Loss: 86.49503
Epoch 62, Val Loss: 80.25209
Epoch 63, Val Loss: 81.39908
Epoch 64, Val Loss: 84.54137
Epoch 65, Val Loss: 83.91580
Epoch 66, Val Loss: 83.98830
Epoch 67, Val Loss: 86.64348
Epoch 68, Val Loss: 81.14068
Epoch 69, Val Loss: 80.77060
Epoch 70, Val Loss: 80.56133
Epoch 71, Val Loss: 84.37981
Epoch 72, Val Loss: 91.87704
Epoch 73, Val Loss: 80.86356
Epoch 74, Val Loss: 83.15291
Epoch 75, Val Loss: 80.50708
Epoch 76, Val Loss: 81.95186
Epoch 77, Val Loss: 86.80885
Epoch 78, Val Loss: 81.36294
Epoch 79, Val Loss: 84.93022
Epoch 80, Val Loss: 81.39304
Epoch 81, Val Loss: 83.65581
Epoch 82, Val Loss: 80.70798
Epoch 83, Val Loss: 84.23685
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.7099207042307, 'MSE - std': 9.59477971619695, 'R2 - mean': 0.5001974623258862, 'R2 - std': 0.037059634135766815} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1096.62317
Epoch 1, Val Loss: 409.64813
Epoch 2, Val Loss: 172.30786
Epoch 3, Val Loss: 147.02260
Epoch 4, Val Loss: 127.27905
Epoch 5, Val Loss: 150.49808
Epoch 6, Val Loss: 123.37305
Epoch 7, Val Loss: 131.35506
Epoch 8, Val Loss: 103.49457
Epoch 9, Val Loss: 102.09573
Epoch 10, Val Loss: 120.54735
Epoch 11, Val Loss: 109.15016
Epoch 12, Val Loss: 109.88145
Epoch 13, Val Loss: 107.09444
Epoch 14, Val Loss: 97.56575
Epoch 15, Val Loss: 106.05786
Epoch 16, Val Loss: 97.14349
Epoch 17, Val Loss: 96.04058
Epoch 18, Val Loss: 102.44145
Epoch 19, Val Loss: 96.01366
Epoch 20, Val Loss: 102.14098
Epoch 21, Val Loss: 98.60301
Epoch 22, Val Loss: 108.63266
Epoch 23, Val Loss: 113.42724
Epoch 24, Val Loss: 95.20186
Epoch 25, Val Loss: 91.49423
Epoch 26, Val Loss: 93.74316
Epoch 27, Val Loss: 88.43929
Epoch 28, Val Loss: 94.06688
Epoch 29, Val Loss: 81.98872
Epoch 30, Val Loss: 84.71248
Epoch 31, Val Loss: 100.90161
Epoch 32, Val Loss: 80.39923
Epoch 33, Val Loss: 83.95638
Epoch 34, Val Loss: 88.19362
Epoch 35, Val Loss: 87.67892
Epoch 36, Val Loss: 83.16357
Epoch 37, Val Loss: 76.29730
Epoch 38, Val Loss: 81.21326
Epoch 39, Val Loss: 83.11465
Epoch 40, Val Loss: 77.28206
Epoch 41, Val Loss: 82.04254
Epoch 42, Val Loss: 81.66721
Epoch 43, Val Loss: 82.45739
Epoch 44, Val Loss: 80.08051
Epoch 45, Val Loss: 86.90208
Epoch 46, Val Loss: 79.34348
Epoch 47, Val Loss: 83.65807
Epoch 48, Val Loss: 83.64318
Epoch 49, Val Loss: 85.47000
Epoch 50, Val Loss: 76.66187
Epoch 51, Val Loss: 73.98209
Epoch 52, Val Loss: 79.26327
Epoch 53, Val Loss: 78.79817
Epoch 54, Val Loss: 81.31023
Epoch 55, Val Loss: 73.97394
Epoch 56, Val Loss: 76.91671
Epoch 57, Val Loss: 74.65186
Epoch 58, Val Loss: 71.13233
Epoch 59, Val Loss: 79.27197
Epoch 60, Val Loss: 83.14137
Epoch 61, Val Loss: 71.25529
Epoch 62, Val Loss: 86.99956
Epoch 63, Val Loss: 75.75401
Epoch 64, Val Loss: 80.28688
Epoch 65, Val Loss: 77.76524
Epoch 66, Val Loss: 73.16066
Epoch 67, Val Loss: 72.12367
Epoch 68, Val Loss: 75.48055
Epoch 69, Val Loss: 75.59642
Epoch 70, Val Loss: 78.60123
Epoch 71, Val Loss: 79.07518
Epoch 72, Val Loss: 77.63960
Epoch 73, Val Loss: 77.56030
Epoch 74, Val Loss: 79.77962
Epoch 75, Val Loss: 78.16687
Epoch 76, Val Loss: 73.78815
Epoch 77, Val Loss: 76.52750
Epoch 78, Val Loss: 87.85965
Epoch 79, Val Loss: 90.36590
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.21534671771153, 'MSE - std': 9.08751032167748, 'R2 - mean': 0.5082964404595467, 'R2 - std': 0.03689318328715425} 
 

Results After CV: {'MSE - mean': 79.21534671771153, 'MSE - std': 9.08751032167748, 'R2 - mean': 0.5082964404595467, 'R2 - std': 0.03689318328715425}
Train time: 743.9655541423999
Inference time: 0.19746850699884816
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 31 finished with value: 79.21534671771153 and parameters: {'p_m': 0.35945856940329457, 'alpha': 7.5666995261033225, 'K': 5, 'beta': 6.107115369515753}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1463.24878
Epoch 1, Val Loss: 447.54120
Epoch 2, Val Loss: 153.58572
Epoch 3, Val Loss: 136.57880
Epoch 4, Val Loss: 122.90633
Epoch 5, Val Loss: 112.51038
Epoch 6, Val Loss: 115.76041
Epoch 7, Val Loss: 112.50325
Epoch 8, Val Loss: 109.50108
Epoch 9, Val Loss: 102.81101
Epoch 10, Val Loss: 115.21997
Epoch 11, Val Loss: 101.58861
Epoch 12, Val Loss: 102.81094
Epoch 13, Val Loss: 100.42424
Epoch 14, Val Loss: 106.77247
Epoch 15, Val Loss: 99.79073
Epoch 16, Val Loss: 96.03725
Epoch 17, Val Loss: 97.08273
Epoch 18, Val Loss: 106.16381
Epoch 19, Val Loss: 103.38973
Epoch 20, Val Loss: 96.40260
Epoch 21, Val Loss: 97.77406
Epoch 22, Val Loss: 102.65208
Epoch 23, Val Loss: 106.76073
Epoch 24, Val Loss: 104.12058
Epoch 25, Val Loss: 106.14550
Epoch 26, Val Loss: 95.59761
Epoch 27, Val Loss: 103.52786
Epoch 28, Val Loss: 93.52898
Epoch 29, Val Loss: 102.19843
Epoch 30, Val Loss: 96.97738
Epoch 31, Val Loss: 106.46262
Epoch 32, Val Loss: 108.29053
Epoch 33, Val Loss: 103.08942
Epoch 34, Val Loss: 97.13290
Epoch 35, Val Loss: 97.34024
Epoch 36, Val Loss: 99.28667
Epoch 37, Val Loss: 100.14401
Epoch 38, Val Loss: 103.72437
Epoch 39, Val Loss: 104.17418
Epoch 40, Val Loss: 96.97641
Epoch 41, Val Loss: 102.97517
Epoch 42, Val Loss: 111.29987
Epoch 43, Val Loss: 101.91802
Epoch 44, Val Loss: 108.12434
Epoch 45, Val Loss: 96.17993
Epoch 46, Val Loss: 98.87994
Epoch 47, Val Loss: 117.26007
Epoch 48, Val Loss: 107.63290
Epoch 49, Val Loss: 111.11554
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 98.93597603605926, 'MSE - std': 0.0, 'R2 - mean': 0.42346715498720555, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 455.32028
Epoch 1, Val Loss: 229.03271
Epoch 2, Val Loss: 143.22076
Epoch 3, Val Loss: 122.23749
Epoch 4, Val Loss: 116.92087
Epoch 5, Val Loss: 111.19173
Epoch 6, Val Loss: 100.82063
Epoch 7, Val Loss: 96.14723
Epoch 8, Val Loss: 95.34785
Epoch 9, Val Loss: 88.20274
Epoch 10, Val Loss: 86.66756
Epoch 11, Val Loss: 85.08781
Epoch 12, Val Loss: 85.85007
Epoch 13, Val Loss: 85.50853
Epoch 14, Val Loss: 89.34467
Epoch 15, Val Loss: 84.89027
Epoch 16, Val Loss: 95.38654
Epoch 17, Val Loss: 86.76669
Epoch 18, Val Loss: 83.39469
Epoch 19, Val Loss: 84.42196
Epoch 20, Val Loss: 80.61935
Epoch 21, Val Loss: 82.91928
Epoch 22, Val Loss: 80.56734
Epoch 23, Val Loss: 81.25887
Epoch 24, Val Loss: 83.91386
Epoch 25, Val Loss: 85.22715
Epoch 26, Val Loss: 77.92581
Epoch 27, Val Loss: 83.78252
Epoch 28, Val Loss: 82.57195
Epoch 29, Val Loss: 95.43886
Epoch 30, Val Loss: 80.11597
Epoch 31, Val Loss: 80.01637
Epoch 32, Val Loss: 82.98867
Epoch 33, Val Loss: 77.92126
Epoch 34, Val Loss: 80.48512
Epoch 35, Val Loss: 79.30803
Epoch 36, Val Loss: 80.39038
Epoch 37, Val Loss: 80.50374
Epoch 38, Val Loss: 80.70935
Epoch 39, Val Loss: 96.05676
Epoch 40, Val Loss: 82.43957
Epoch 41, Val Loss: 93.02229
Epoch 42, Val Loss: 89.64857
Epoch 43, Val Loss: 78.32773
Epoch 44, Val Loss: 80.25160
Epoch 45, Val Loss: 82.65597
Epoch 46, Val Loss: 88.64252
Epoch 47, Val Loss: 78.74796
Epoch 48, Val Loss: 83.22842
Epoch 49, Val Loss: 81.22608
Epoch 50, Val Loss: 82.37244
Epoch 51, Val Loss: 84.65837
Epoch 52, Val Loss: 78.67872
Epoch 53, Val Loss: 100.14514
Epoch 54, Val Loss: 88.70694
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 92.80987408504751, 'MSE - std': 6.126101951011741, 'R2 - mean': 0.43521318610390225, 'R2 - std': 0.011746031116696698} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1368.80542
Epoch 1, Val Loss: 370.54950
Epoch 2, Val Loss: 145.24068
Epoch 3, Val Loss: 126.61962
Epoch 4, Val Loss: 108.70584
Epoch 5, Val Loss: 105.54126
Epoch 6, Val Loss: 100.48176
Epoch 7, Val Loss: 101.54173
Epoch 8, Val Loss: 91.33315
Epoch 9, Val Loss: 88.46291
Epoch 10, Val Loss: 85.88891
Epoch 11, Val Loss: 81.10519
Epoch 12, Val Loss: 83.44901
Epoch 13, Val Loss: 79.65945
Epoch 14, Val Loss: 76.98067
Epoch 15, Val Loss: 79.94807
Epoch 16, Val Loss: 78.35772
Epoch 17, Val Loss: 83.79533
Epoch 18, Val Loss: 85.89750
Epoch 19, Val Loss: 83.34152
Epoch 20, Val Loss: 81.27432
Epoch 21, Val Loss: 83.01308
Epoch 22, Val Loss: 81.80243
Epoch 23, Val Loss: 84.37765
Epoch 24, Val Loss: 82.62111
Epoch 25, Val Loss: 78.18566
Epoch 26, Val Loss: 85.71908
Epoch 27, Val Loss: 80.45131
Epoch 28, Val Loss: 86.92802
Epoch 29, Val Loss: 89.36896
Epoch 30, Val Loss: 79.61215
Epoch 31, Val Loss: 84.56524
Epoch 32, Val Loss: 80.83878
Epoch 33, Val Loss: 81.35928
Epoch 34, Val Loss: 78.53712
Epoch 35, Val Loss: 79.58295
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.27057292377935, 'MSE - std': 8.13817711826022, 'R2 - mean': 0.44605592865067134, 'R2 - std': 0.018086172338759327} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1447.70728
Epoch 1, Val Loss: 367.32004
Epoch 2, Val Loss: 146.32234
Epoch 3, Val Loss: 132.83855
Epoch 4, Val Loss: 119.84155
Epoch 5, Val Loss: 115.34624
Epoch 6, Val Loss: 105.55453
Epoch 7, Val Loss: 105.02014
Epoch 8, Val Loss: 107.48419
Epoch 9, Val Loss: 102.51524
Epoch 10, Val Loss: 107.20092
Epoch 11, Val Loss: 100.05609
Epoch 12, Val Loss: 104.35536
Epoch 13, Val Loss: 94.57666
Epoch 14, Val Loss: 93.70689
Epoch 15, Val Loss: 99.23615
Epoch 16, Val Loss: 96.80305
Epoch 17, Val Loss: 94.52087
Epoch 18, Val Loss: 94.49142
Epoch 19, Val Loss: 93.08881
Epoch 20, Val Loss: 100.63640
Epoch 21, Val Loss: 101.89319
Epoch 22, Val Loss: 92.76114
Epoch 23, Val Loss: 89.59317
Epoch 24, Val Loss: 93.94406
Epoch 25, Val Loss: 95.75632
Epoch 26, Val Loss: 98.57080
Epoch 27, Val Loss: 105.17601
Epoch 28, Val Loss: 93.19538
Epoch 29, Val Loss: 92.49646
Epoch 30, Val Loss: 86.40200
Epoch 31, Val Loss: 89.24644
Epoch 32, Val Loss: 88.74264
Epoch 33, Val Loss: 86.60821
Epoch 34, Val Loss: 85.05754
Epoch 35, Val Loss: 97.16332
Epoch 36, Val Loss: 93.27174
Epoch 37, Val Loss: 87.27487
Epoch 38, Val Loss: 91.09116
Epoch 39, Val Loss: 85.82849
Epoch 40, Val Loss: 89.99683
Epoch 41, Val Loss: 91.17123
Epoch 42, Val Loss: 91.42451
Epoch 43, Val Loss: 91.91394
Epoch 44, Val Loss: 92.13389
Epoch 45, Val Loss: 92.45162
Epoch 46, Val Loss: 99.31958
Epoch 47, Val Loss: 86.52633
Epoch 48, Val Loss: 93.58406
Epoch 49, Val Loss: 88.67662
Epoch 50, Val Loss: 84.52416
Epoch 51, Val Loss: 82.17302
Epoch 52, Val Loss: 89.86925
Epoch 53, Val Loss: 86.69211
Epoch 54, Val Loss: 88.09968
Epoch 55, Val Loss: 84.99855
Epoch 56, Val Loss: 82.26418
Epoch 57, Val Loss: 83.90489
Epoch 58, Val Loss: 82.26173
Epoch 59, Val Loss: 81.69757
Epoch 60, Val Loss: 87.16893
Epoch 61, Val Loss: 89.95013
Epoch 62, Val Loss: 82.34583
Epoch 63, Val Loss: 89.78912
Epoch 64, Val Loss: 82.27556
Epoch 65, Val Loss: 86.32452
Epoch 66, Val Loss: 82.28826
Epoch 67, Val Loss: 94.24898
Epoch 68, Val Loss: 82.85008
Epoch 69, Val Loss: 91.95087
Epoch 70, Val Loss: 82.68835
Epoch 71, Val Loss: 79.51041
Epoch 72, Val Loss: 84.14285
Epoch 73, Val Loss: 81.19440
Epoch 74, Val Loss: 83.44530
Epoch 75, Val Loss: 83.73747
Epoch 76, Val Loss: 83.95709
Epoch 77, Val Loss: 82.86275
Epoch 78, Val Loss: 90.56702
Epoch 79, Val Loss: 81.62908
Epoch 80, Val Loss: 81.69165
Epoch 81, Val Loss: 81.25719
Epoch 82, Val Loss: 87.80369
Epoch 83, Val Loss: 81.52419
Epoch 84, Val Loss: 78.76601
Epoch 85, Val Loss: 83.23973
Epoch 86, Val Loss: 81.61575
Epoch 87, Val Loss: 81.20258
Epoch 88, Val Loss: 80.80177
Epoch 89, Val Loss: 81.10360
Epoch 90, Val Loss: 81.11540
Epoch 91, Val Loss: 78.97878
Epoch 92, Val Loss: 80.85275
Epoch 93, Val Loss: 81.22505
Epoch 94, Val Loss: 78.08938
Epoch 95, Val Loss: 79.59535
Epoch 96, Val Loss: 78.54290
Epoch 97, Val Loss: 78.28869
Epoch 98, Val Loss: 79.33006
Epoch 99, Val Loss: 82.22824
DID NOT SAVE RESULTS
{'MSE - mean': 88.21752865300164, 'MSE - std': 7.048466938995862, 'R2 - mean': 0.45261533821922395, 'R2 - std': 0.019349671420066477} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 507.06595
Epoch 1, Val Loss: 326.38925
Epoch 2, Val Loss: 162.75728
Epoch 3, Val Loss: 137.64468
Epoch 4, Val Loss: 123.13631
Epoch 5, Val Loss: 106.11020
Epoch 6, Val Loss: 101.68375
Epoch 7, Val Loss: 107.99884
Epoch 8, Val Loss: 95.59848
Epoch 9, Val Loss: 104.92577
Epoch 10, Val Loss: 100.29572
Epoch 11, Val Loss: 87.59510
Epoch 12, Val Loss: 92.99387
Epoch 13, Val Loss: 92.16061
Epoch 14, Val Loss: 89.07970
Epoch 15, Val Loss: 98.11278
Epoch 16, Val Loss: 96.77153
Epoch 17, Val Loss: 92.11319
Epoch 18, Val Loss: 93.85352
Epoch 19, Val Loss: 88.59201
Epoch 20, Val Loss: 89.56310
Epoch 21, Val Loss: 93.68095
Epoch 22, Val Loss: 93.70285
Epoch 23, Val Loss: 91.44531
Epoch 24, Val Loss: 102.33802
Epoch 25, Val Loss: 98.07938
Epoch 26, Val Loss: 93.08788
Epoch 27, Val Loss: 88.28484
Epoch 28, Val Loss: 102.20995
Epoch 29, Val Loss: 96.60143
Epoch 30, Val Loss: 95.66647
Epoch 31, Val Loss: 93.75927
Epoch 32, Val Loss: 95.86125
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.64248284082677, 'MSE - std': 6.361371958869773, 'R2 - mean': 0.44877555830048976, 'R2 - std': 0.018934187771037003} 
 

Results After CV: {'MSE - mean': 88.64248284082677, 'MSE - std': 6.361371958869773, 'R2 - mean': 0.44877555830048976, 'R2 - std': 0.018934187771037003}
Train time: 225.66208310999937
Inference time: 0.1895174679986667
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 32 finished with value: 88.64248284082677 and parameters: {'p_m': 0.17333808681271043, 'alpha': 9.166747217091103, 'K': 2, 'beta': 3.219822769243886}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 588.82690
Epoch 1, Val Loss: 478.60736
Epoch 2, Val Loss: 227.03731
Epoch 3, Val Loss: 177.02985
Epoch 4, Val Loss: 174.32469
Epoch 5, Val Loss: 159.16570
Epoch 6, Val Loss: 132.04103
Epoch 7, Val Loss: 122.50036
Epoch 8, Val Loss: 114.70319
Epoch 9, Val Loss: 118.48967
Epoch 10, Val Loss: 106.40608
Epoch 11, Val Loss: 103.01877
Epoch 12, Val Loss: 103.33953
Epoch 13, Val Loss: 95.32158
Epoch 14, Val Loss: 106.18565
Epoch 15, Val Loss: 95.92125
Epoch 16, Val Loss: 93.09344
Epoch 17, Val Loss: 90.77094
Epoch 18, Val Loss: 93.88867
Epoch 19, Val Loss: 85.64892
Epoch 20, Val Loss: 88.14554
Epoch 21, Val Loss: 83.42201
Epoch 22, Val Loss: 86.55456
Epoch 23, Val Loss: 83.77283
Epoch 24, Val Loss: 85.77313
Epoch 25, Val Loss: 84.59863
Epoch 26, Val Loss: 85.17940
Epoch 27, Val Loss: 89.58229
Epoch 28, Val Loss: 82.87782
Epoch 29, Val Loss: 87.81696
Epoch 30, Val Loss: 83.09143
Epoch 31, Val Loss: 85.02341
Epoch 32, Val Loss: 85.72663
Epoch 33, Val Loss: 84.60785
Epoch 34, Val Loss: 86.29401
Epoch 35, Val Loss: 90.03941
Epoch 36, Val Loss: 87.40656
Epoch 37, Val Loss: 84.42241
Epoch 38, Val Loss: 85.87983
Epoch 39, Val Loss: 90.59889
Epoch 40, Val Loss: 84.75697
Epoch 41, Val Loss: 84.79047
Epoch 42, Val Loss: 89.11654
Epoch 43, Val Loss: 86.04342
Epoch 44, Val Loss: 83.76614
Epoch 45, Val Loss: 88.89905
Epoch 46, Val Loss: 96.56731
Epoch 47, Val Loss: 84.95535
Epoch 48, Val Loss: 80.79799
Epoch 49, Val Loss: 89.26675
Epoch 50, Val Loss: 88.13238
Epoch 51, Val Loss: 85.27153
Epoch 52, Val Loss: 86.85483
Epoch 53, Val Loss: 88.20795
Epoch 54, Val Loss: 84.19724
Epoch 55, Val Loss: 92.17546
Epoch 56, Val Loss: 87.76841
Epoch 57, Val Loss: 88.59822
Epoch 58, Val Loss: 86.42281
Epoch 59, Val Loss: 87.26037
Epoch 60, Val Loss: 88.04656
Epoch 61, Val Loss: 89.30883
Epoch 62, Val Loss: 89.80555
Epoch 63, Val Loss: 87.83737
Epoch 64, Val Loss: 88.18008
Epoch 65, Val Loss: 83.20059
Epoch 66, Val Loss: 90.02025
Epoch 67, Val Loss: 86.15840
Epoch 68, Val Loss: 85.55702
Epoch 69, Val Loss: 84.05238
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.10922642364771, 'MSE - std': 0.0, 'R2 - mean': 0.509867557336503, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 853.86584
Epoch 1, Val Loss: 454.71783
Epoch 2, Val Loss: 202.78792
Epoch 3, Val Loss: 200.62949
Epoch 4, Val Loss: 181.62096
Epoch 5, Val Loss: 132.98930
Epoch 6, Val Loss: 136.06454
Epoch 7, Val Loss: 108.55566
Epoch 8, Val Loss: 98.12085
Epoch 9, Val Loss: 113.78903
Epoch 10, Val Loss: 101.46352
Epoch 11, Val Loss: 91.16492
Epoch 12, Val Loss: 96.52760
Epoch 13, Val Loss: 91.54994
Epoch 14, Val Loss: 96.54179
Epoch 15, Val Loss: 102.29583
Epoch 16, Val Loss: 82.71678
Epoch 17, Val Loss: 82.15623
Epoch 18, Val Loss: 77.66785
Epoch 19, Val Loss: 82.66609
Epoch 20, Val Loss: 74.87196
Epoch 21, Val Loss: 79.72028
Epoch 22, Val Loss: 74.74425
Epoch 23, Val Loss: 76.29646
Epoch 24, Val Loss: 76.77678
Epoch 25, Val Loss: 79.02502
Epoch 26, Val Loss: 75.81315
Epoch 27, Val Loss: 72.48463
Epoch 28, Val Loss: 76.82689
Epoch 29, Val Loss: 78.58791
Epoch 30, Val Loss: 71.97987
Epoch 31, Val Loss: 76.84744
Epoch 32, Val Loss: 75.03505
Epoch 33, Val Loss: 73.89038
Epoch 34, Val Loss: 73.97365
Epoch 35, Val Loss: 84.30424
Epoch 36, Val Loss: 73.46223
Epoch 37, Val Loss: 80.15725
Epoch 38, Val Loss: 74.23499
Epoch 39, Val Loss: 72.19762
Epoch 40, Val Loss: 74.89275
Epoch 41, Val Loss: 71.28909
Epoch 42, Val Loss: 72.49236
Epoch 43, Val Loss: 81.64153
Epoch 44, Val Loss: 74.74059
Epoch 45, Val Loss: 80.35556
Epoch 46, Val Loss: 77.20883
Epoch 47, Val Loss: 84.45751
Epoch 48, Val Loss: 79.22353
Epoch 49, Val Loss: 72.95292
Epoch 50, Val Loss: 80.02552
Epoch 51, Val Loss: 78.76693
Epoch 52, Val Loss: 74.07352
Epoch 53, Val Loss: 71.29617
Epoch 54, Val Loss: 72.49196
Epoch 55, Val Loss: 88.90750
Epoch 56, Val Loss: 73.54945
Epoch 57, Val Loss: 78.48139
Epoch 58, Val Loss: 75.36974
Epoch 59, Val Loss: 73.87156
Epoch 60, Val Loss: 71.81380
Epoch 61, Val Loss: 74.93489
Epoch 62, Val Loss: 82.26270
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.6529583036652, 'MSE - std': 2.456268119982518, 'R2 - mean': 0.5022971059990183, 'R2 - std': 0.007570451337484685} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1241.08350
Epoch 1, Val Loss: 451.63757
Epoch 2, Val Loss: 210.09607
Epoch 3, Val Loss: 182.74472
Epoch 4, Val Loss: 167.92401
Epoch 5, Val Loss: 145.22617
Epoch 6, Val Loss: 117.85556
Epoch 7, Val Loss: 112.80278
Epoch 8, Val Loss: 103.65253
Epoch 9, Val Loss: 98.66734
Epoch 10, Val Loss: 96.60971
Epoch 11, Val Loss: 91.31480
Epoch 12, Val Loss: 88.94951
Epoch 13, Val Loss: 82.06081
Epoch 14, Val Loss: 81.98779
Epoch 15, Val Loss: 89.58904
Epoch 16, Val Loss: 98.14419
Epoch 17, Val Loss: 74.77877
Epoch 18, Val Loss: 77.97427
Epoch 19, Val Loss: 83.33932
Epoch 20, Val Loss: 77.16583
Epoch 21, Val Loss: 73.84335
Epoch 22, Val Loss: 80.05502
Epoch 23, Val Loss: 74.47083
Epoch 24, Val Loss: 74.98469
Epoch 25, Val Loss: 84.29586
Epoch 26, Val Loss: 91.51701
Epoch 27, Val Loss: 76.50640
Epoch 28, Val Loss: 88.22742
Epoch 29, Val Loss: 71.12061
Epoch 30, Val Loss: 73.56831
Epoch 31, Val Loss: 72.51785
Epoch 32, Val Loss: 72.72730
Epoch 33, Val Loss: 70.77480
Epoch 34, Val Loss: 73.80144
Epoch 35, Val Loss: 74.58543
Epoch 36, Val Loss: 74.78339
Epoch 37, Val Loss: 89.69857
Epoch 38, Val Loss: 73.68747
Epoch 39, Val Loss: 76.88368
Epoch 40, Val Loss: 86.12241
Epoch 41, Val Loss: 81.77444
Epoch 42, Val Loss: 77.00753
Epoch 43, Val Loss: 75.63587
Epoch 44, Val Loss: 68.04067
Epoch 45, Val Loss: 94.78905
Epoch 46, Val Loss: 70.73795
Epoch 47, Val Loss: 72.37012
Epoch 48, Val Loss: 76.83049
Epoch 49, Val Loss: 74.06614
Epoch 50, Val Loss: 71.50125
Epoch 51, Val Loss: 69.76003
Epoch 52, Val Loss: 81.10661
Epoch 53, Val Loss: 72.54327
Epoch 54, Val Loss: 75.04791
Epoch 55, Val Loss: 71.22477
Epoch 56, Val Loss: 70.90535
Epoch 57, Val Loss: 70.61264
Epoch 58, Val Loss: 80.81976
Epoch 59, Val Loss: 75.14613
Epoch 60, Val Loss: 69.73924
Epoch 61, Val Loss: 70.24142
Epoch 62, Val Loss: 72.86131
Epoch 63, Val Loss: 77.80180
Epoch 64, Val Loss: 71.15935
Epoch 65, Val Loss: 73.65014
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.73051372537346, 'MSE - std': 5.898585564158775, 'R2 - mean': 0.5116282254734693, 'R2 - std': 0.0145721447836311} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 900.00897
Epoch 1, Val Loss: 496.37854
Epoch 2, Val Loss: 221.53148
Epoch 3, Val Loss: 203.72643
Epoch 4, Val Loss: 183.64246
Epoch 5, Val Loss: 143.02173
Epoch 6, Val Loss: 157.50354
Epoch 7, Val Loss: 111.81113
Epoch 8, Val Loss: 126.05476
Epoch 9, Val Loss: 128.46344
Epoch 10, Val Loss: 99.71104
Epoch 11, Val Loss: 101.01160
Epoch 12, Val Loss: 96.61755
Epoch 13, Val Loss: 110.28367
Epoch 14, Val Loss: 90.60847
Epoch 15, Val Loss: 97.78194
Epoch 16, Val Loss: 100.48806
Epoch 17, Val Loss: 84.99807
Epoch 18, Val Loss: 84.06252
Epoch 19, Val Loss: 91.31509
Epoch 20, Val Loss: 87.89261
Epoch 21, Val Loss: 87.93643
Epoch 22, Val Loss: 84.67003
Epoch 23, Val Loss: 81.08762
Epoch 24, Val Loss: 81.94408
Epoch 25, Val Loss: 89.47395
Epoch 26, Val Loss: 84.04867
Epoch 27, Val Loss: 81.97968
Epoch 28, Val Loss: 78.69557
Epoch 29, Val Loss: 80.28946
Epoch 30, Val Loss: 85.98083
Epoch 31, Val Loss: 79.56351
Epoch 32, Val Loss: 93.10503
Epoch 33, Val Loss: 81.66518
Epoch 34, Val Loss: 80.09914
Epoch 35, Val Loss: 80.68128
Epoch 36, Val Loss: 82.17712
Epoch 37, Val Loss: 80.03862
Epoch 38, Val Loss: 83.22270
Epoch 39, Val Loss: 79.71531
Epoch 40, Val Loss: 83.60169
Epoch 41, Val Loss: 79.19329
Epoch 42, Val Loss: 83.01077
Epoch 43, Val Loss: 79.78494
Epoch 44, Val Loss: 81.57639
Epoch 45, Val Loss: 85.65024
Epoch 46, Val Loss: 82.31640
Epoch 47, Val Loss: 94.77482
Epoch 48, Val Loss: 81.40051
Epoch 49, Val Loss: 85.95395
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.96291522595874, 'MSE - std': 7.578934102249137, 'R2 - mean': 0.4978967313926552, 'R2 - std': 0.026924381919937} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1188.40430
Epoch 1, Val Loss: 488.62610
Epoch 2, Val Loss: 192.37946
Epoch 3, Val Loss: 203.77756
Epoch 4, Val Loss: 169.27826
Epoch 5, Val Loss: 163.13712
Epoch 6, Val Loss: 151.98050
Epoch 7, Val Loss: 138.00900
Epoch 8, Val Loss: 121.48991
Epoch 9, Val Loss: 110.91901
Epoch 10, Val Loss: 133.28862
Epoch 11, Val Loss: 109.35545
Epoch 12, Val Loss: 96.42712
Epoch 13, Val Loss: 97.47627
Epoch 14, Val Loss: 108.54981
Epoch 15, Val Loss: 93.46960
Epoch 16, Val Loss: 89.98793
Epoch 17, Val Loss: 101.33629
Epoch 18, Val Loss: 105.39700
Epoch 19, Val Loss: 94.29800
Epoch 20, Val Loss: 87.26781
Epoch 21, Val Loss: 87.62912
Epoch 22, Val Loss: 87.84623
Epoch 23, Val Loss: 92.90930
Epoch 24, Val Loss: 87.07330
Epoch 25, Val Loss: 81.72184
Epoch 26, Val Loss: 79.20044
Epoch 27, Val Loss: 83.96152
Epoch 28, Val Loss: 83.98176
Epoch 29, Val Loss: 79.08018
Epoch 30, Val Loss: 80.62915
Epoch 31, Val Loss: 77.81642
Epoch 32, Val Loss: 78.61079
Epoch 33, Val Loss: 88.20534
Epoch 34, Val Loss: 76.99903
Epoch 35, Val Loss: 81.50121
Epoch 36, Val Loss: 84.97739
Epoch 37, Val Loss: 78.35228
Epoch 38, Val Loss: 78.65742
Epoch 39, Val Loss: 78.43008
Epoch 40, Val Loss: 83.14659
Epoch 41, Val Loss: 81.42442
Epoch 42, Val Loss: 84.08913
Epoch 43, Val Loss: 80.11820
Epoch 44, Val Loss: 77.96489
Epoch 45, Val Loss: 84.08816
Epoch 46, Val Loss: 80.55869
Epoch 47, Val Loss: 78.12895
Epoch 48, Val Loss: 78.32391
Epoch 49, Val Loss: 77.13538
Epoch 50, Val Loss: 78.50058
Epoch 51, Val Loss: 81.51424
Epoch 52, Val Loss: 81.72784
Epoch 53, Val Loss: 79.75805
Epoch 54, Val Loss: 83.65102
Epoch 55, Val Loss: 86.10664
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.74672904474355, 'MSE - std': 6.792579742688457, 'R2 - mean': 0.4981210886506656, 'R2 - std': 0.024086079343334236} 
 

Results After CV: {'MSE - mean': 80.74672904474355, 'MSE - std': 6.792579742688457, 'R2 - mean': 0.4981210886506656, 'R2 - std': 0.024086079343334236}
Train time: 2267.2999253912
Inference time: 0.16783540000033098
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 33 finished with value: 80.74672904474355 and parameters: {'p_m': 0.5745517084699082, 'alpha': 8.044178796945134, 'K': 20, 'beta': 7.492671497921921}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1320.14099
Epoch 1, Val Loss: 416.61322
Epoch 2, Val Loss: 150.48212
Epoch 3, Val Loss: 139.99069
Epoch 4, Val Loss: 111.95187
Epoch 5, Val Loss: 114.23017
Epoch 6, Val Loss: 102.30042
Epoch 7, Val Loss: 96.52791
Epoch 8, Val Loss: 100.17493
Epoch 9, Val Loss: 93.15076
Epoch 10, Val Loss: 90.64920
Epoch 11, Val Loss: 100.60217
Epoch 12, Val Loss: 94.80677
Epoch 13, Val Loss: 95.79988
Epoch 14, Val Loss: 92.74094
Epoch 15, Val Loss: 101.64946
Epoch 16, Val Loss: 96.43919
Epoch 17, Val Loss: 104.71545
Epoch 18, Val Loss: 98.53384
Epoch 19, Val Loss: 101.00778
Epoch 20, Val Loss: 91.50536
Epoch 21, Val Loss: 93.46680
Epoch 22, Val Loss: 92.90544
Epoch 23, Val Loss: 95.17886
Epoch 24, Val Loss: 95.03034
Epoch 25, Val Loss: 99.05103
Epoch 26, Val Loss: 91.44986
Epoch 27, Val Loss: 89.65070
Epoch 28, Val Loss: 104.71956
Epoch 29, Val Loss: 98.03148
Epoch 30, Val Loss: 96.44178
Epoch 31, Val Loss: 90.42736
Epoch 32, Val Loss: 89.66077
Epoch 33, Val Loss: 96.31283
Epoch 34, Val Loss: 89.68176
Epoch 35, Val Loss: 106.70676
Epoch 36, Val Loss: 90.71372
Epoch 37, Val Loss: 92.71701
Epoch 38, Val Loss: 98.25715
Epoch 39, Val Loss: 104.98972
Epoch 40, Val Loss: 104.49172
Epoch 41, Val Loss: 93.60400
Epoch 42, Val Loss: 92.54963
Epoch 43, Val Loss: 95.02087
Epoch 44, Val Loss: 101.44701
Epoch 45, Val Loss: 126.23847
Epoch 46, Val Loss: 95.01604
Epoch 47, Val Loss: 105.07800
Epoch 48, Val Loss: 94.44915
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 94.11288073717701, 'MSE - std': 0.0, 'R2 - mean': 0.45157293577435775, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 994.15399
Epoch 1, Val Loss: 326.99554
Epoch 2, Val Loss: 133.55470
Epoch 3, Val Loss: 115.02273
Epoch 4, Val Loss: 113.57449
Epoch 5, Val Loss: 95.95621
Epoch 6, Val Loss: 94.35985
Epoch 7, Val Loss: 89.13020
Epoch 8, Val Loss: 87.85940
Epoch 9, Val Loss: 95.49942
Epoch 10, Val Loss: 85.64858
Epoch 11, Val Loss: 84.54971
Epoch 12, Val Loss: 86.24008
Epoch 13, Val Loss: 86.44975
Epoch 14, Val Loss: 92.00032
Epoch 15, Val Loss: 88.18037
Epoch 16, Val Loss: 80.73181
Epoch 17, Val Loss: 80.30944
Epoch 18, Val Loss: 92.48931
Epoch 19, Val Loss: 89.67132
Epoch 20, Val Loss: 81.36825
Epoch 21, Val Loss: 85.04830
Epoch 22, Val Loss: 83.81702
Epoch 23, Val Loss: 83.10848
Epoch 24, Val Loss: 86.98213
Epoch 25, Val Loss: 78.72857
Epoch 26, Val Loss: 81.75958
Epoch 27, Val Loss: 80.05254
Epoch 28, Val Loss: 76.99226
Epoch 29, Val Loss: 78.21943
Epoch 30, Val Loss: 78.54826
Epoch 31, Val Loss: 87.38837
Epoch 32, Val Loss: 86.28082
Epoch 33, Val Loss: 78.55506
Epoch 34, Val Loss: 86.74715
Epoch 35, Val Loss: 104.69131
Epoch 36, Val Loss: 87.76067
Epoch 37, Val Loss: 81.90498
Epoch 38, Val Loss: 88.61962
Epoch 39, Val Loss: 94.60666
Epoch 40, Val Loss: 85.52726
Epoch 41, Val Loss: 77.01860
Epoch 42, Val Loss: 88.11401
Epoch 43, Val Loss: 94.01077
Epoch 44, Val Loss: 74.06075
Epoch 45, Val Loss: 78.41811
Epoch 46, Val Loss: 76.11514
Epoch 47, Val Loss: 80.38488
Epoch 48, Val Loss: 77.54291
Epoch 49, Val Loss: 78.03539
Epoch 50, Val Loss: 83.85332
Epoch 51, Val Loss: 77.43787
Epoch 52, Val Loss: 81.16908
Epoch 53, Val Loss: 79.39177
Epoch 54, Val Loss: 81.36925
Epoch 55, Val Loss: 79.41631
Epoch 56, Val Loss: 74.67653
Epoch 57, Val Loss: 82.09927
Epoch 58, Val Loss: 80.93423
Epoch 59, Val Loss: 72.50514
Epoch 60, Val Loss: 81.68280
Epoch 61, Val Loss: 76.39682
Epoch 62, Val Loss: 78.74673
Epoch 63, Val Loss: 75.60997
Epoch 64, Val Loss: 76.62185
Epoch 65, Val Loss: 74.75619
Epoch 66, Val Loss: 75.59810
Epoch 67, Val Loss: 75.62694
Epoch 68, Val Loss: 78.70958
Epoch 69, Val Loss: 69.91153
Epoch 70, Val Loss: 73.18012
Epoch 71, Val Loss: 73.71928
Epoch 72, Val Loss: 75.09303
Epoch 73, Val Loss: 72.79463
Epoch 74, Val Loss: 78.80914
Epoch 75, Val Loss: 81.45110
Epoch 76, Val Loss: 78.41584
Epoch 77, Val Loss: 77.85975
Epoch 78, Val Loss: 85.36823
Epoch 79, Val Loss: 82.83324
Epoch 80, Val Loss: 82.61684
Epoch 81, Val Loss: 68.94518
Epoch 82, Val Loss: 71.02058
Epoch 83, Val Loss: 70.53870
Epoch 84, Val Loss: 74.92902
Epoch 85, Val Loss: 82.88035
Epoch 86, Val Loss: 80.24718
Epoch 87, Val Loss: 74.35685
Epoch 88, Val Loss: 72.46337
Epoch 89, Val Loss: 69.54549
Epoch 90, Val Loss: 71.50546
Epoch 91, Val Loss: 67.99922
Epoch 92, Val Loss: 72.95209
Epoch 93, Val Loss: 67.86945
Epoch 94, Val Loss: 72.10960
Epoch 95, Val Loss: 67.77220
Epoch 96, Val Loss: 70.13077
Epoch 97, Val Loss: 68.81270
Epoch 98, Val Loss: 74.03653
Epoch 99, Val Loss: 74.21143
DID NOT SAVE RESULTS
{'MSE - mean': 84.87530889757693, 'MSE - std': 9.237571839600086, 'R2 - mean': 0.4845028211307552, 'R2 - std': 0.03292988535639746} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1491.66016
Epoch 1, Val Loss: 372.15439
Epoch 2, Val Loss: 147.55884
Epoch 3, Val Loss: 117.15775
Epoch 4, Val Loss: 108.01273
Epoch 5, Val Loss: 102.94064
Epoch 6, Val Loss: 88.43828
Epoch 7, Val Loss: 88.68999
Epoch 8, Val Loss: 81.95714
Epoch 9, Val Loss: 81.28999
Epoch 10, Val Loss: 77.57243
Epoch 11, Val Loss: 78.56366
Epoch 12, Val Loss: 79.74922
Epoch 13, Val Loss: 76.37022
Epoch 14, Val Loss: 79.01965
Epoch 15, Val Loss: 97.23992
Epoch 16, Val Loss: 79.51865
Epoch 17, Val Loss: 74.83940
Epoch 18, Val Loss: 85.19289
Epoch 19, Val Loss: 82.31037
Epoch 20, Val Loss: 102.69016
Epoch 21, Val Loss: 77.02328
Epoch 22, Val Loss: 81.08375
Epoch 23, Val Loss: 85.04912
Epoch 24, Val Loss: 75.93927
Epoch 25, Val Loss: 77.79878
Epoch 26, Val Loss: 76.14223
Epoch 27, Val Loss: 75.38478
Epoch 28, Val Loss: 80.31054
Epoch 29, Val Loss: 97.22443
Epoch 30, Val Loss: 85.44173
Epoch 31, Val Loss: 87.16291
Epoch 32, Val Loss: 87.32065
Epoch 33, Val Loss: 84.26949
Epoch 34, Val Loss: 78.96456
Epoch 35, Val Loss: 81.97292
Epoch 36, Val Loss: 106.91163
Epoch 37, Val Loss: 76.62604
Epoch 38, Val Loss: 84.22856
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.03871561962812, 'MSE - std': 8.542892475240677, 'R2 - mean': 0.4852479677853812, 'R2 - std': 0.02690778177648219} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 714.20569
Epoch 1, Val Loss: 348.86118
Epoch 2, Val Loss: 148.00667
Epoch 3, Val Loss: 131.47668
Epoch 4, Val Loss: 112.74495
Epoch 5, Val Loss: 109.64098
Epoch 6, Val Loss: 110.43195
Epoch 7, Val Loss: 102.52725
Epoch 8, Val Loss: 110.52961
Epoch 9, Val Loss: 106.79019
Epoch 10, Val Loss: 100.09456
Epoch 11, Val Loss: 101.48185
Epoch 12, Val Loss: 99.39006
Epoch 13, Val Loss: 94.74127
Epoch 14, Val Loss: 93.53065
Epoch 15, Val Loss: 101.19780
Epoch 16, Val Loss: 101.15118
Epoch 17, Val Loss: 100.28942
Epoch 18, Val Loss: 94.71336
Epoch 19, Val Loss: 93.65166
Epoch 20, Val Loss: 92.02456
Epoch 21, Val Loss: 94.29385
Epoch 22, Val Loss: 91.51080
Epoch 23, Val Loss: 94.23006
Epoch 24, Val Loss: 92.08935
Epoch 25, Val Loss: 87.29429
Epoch 26, Val Loss: 91.68107
Epoch 27, Val Loss: 93.68751
Epoch 28, Val Loss: 91.95024
Epoch 29, Val Loss: 88.92198
Epoch 30, Val Loss: 92.47721
Epoch 31, Val Loss: 96.96476
Epoch 32, Val Loss: 92.41817
Epoch 33, Val Loss: 90.41624
Epoch 34, Val Loss: 97.17116
Epoch 35, Val Loss: 87.52322
Epoch 36, Val Loss: 91.36758
Epoch 37, Val Loss: 85.82248
Epoch 38, Val Loss: 88.38450
Epoch 39, Val Loss: 88.68629
Epoch 40, Val Loss: 86.68717
Epoch 41, Val Loss: 92.49019
Epoch 42, Val Loss: 84.02047
Epoch 43, Val Loss: 92.92429
Epoch 44, Val Loss: 93.22691
Epoch 45, Val Loss: 89.60273
Epoch 46, Val Loss: 82.43153
Epoch 47, Val Loss: 90.18602
Epoch 48, Val Loss: 91.49960
Epoch 49, Val Loss: 86.35918
Epoch 50, Val Loss: 85.71354
Epoch 51, Val Loss: 97.88534
Epoch 52, Val Loss: 86.22733
Epoch 53, Val Loss: 89.67295
Epoch 54, Val Loss: 89.80135
Epoch 55, Val Loss: 80.70867
Epoch 56, Val Loss: 82.51684
Epoch 57, Val Loss: 86.06851
Epoch 58, Val Loss: 84.47726
Epoch 59, Val Loss: 81.76778
Epoch 60, Val Loss: 83.03149
Epoch 61, Val Loss: 86.64194
Epoch 62, Val Loss: 83.70444
Epoch 63, Val Loss: 86.76440
Epoch 64, Val Loss: 87.25178
Epoch 65, Val Loss: 81.23879
Epoch 66, Val Loss: 79.17699
Epoch 67, Val Loss: 85.35951
Epoch 68, Val Loss: 79.24201
Epoch 69, Val Loss: 77.60091
Epoch 70, Val Loss: 80.90726
Epoch 71, Val Loss: 81.48420
Epoch 72, Val Loss: 84.00487
Epoch 73, Val Loss: 81.74146
Epoch 74, Val Loss: 89.94194
Epoch 75, Val Loss: 77.46506
Epoch 76, Val Loss: 79.10057
Epoch 77, Val Loss: 80.50103
Epoch 78, Val Loss: 81.01708
Epoch 79, Val Loss: 79.06466
Epoch 80, Val Loss: 81.68269
Epoch 81, Val Loss: 78.81499
Epoch 82, Val Loss: 91.24123
Epoch 83, Val Loss: 76.38218
Epoch 84, Val Loss: 88.49284
Epoch 85, Val Loss: 78.47090
Epoch 86, Val Loss: 78.67046
Epoch 87, Val Loss: 77.48220
Epoch 88, Val Loss: 83.04842
Epoch 89, Val Loss: 80.41183
Epoch 90, Val Loss: 76.97178
Epoch 91, Val Loss: 80.34503
Epoch 92, Val Loss: 78.40557
Epoch 93, Val Loss: 83.59021
Epoch 94, Val Loss: 76.58346
Epoch 95, Val Loss: 77.96062
Epoch 96, Val Loss: 81.43340
Epoch 97, Val Loss: 80.78568
Epoch 98, Val Loss: 78.97490
Epoch 99, Val Loss: 80.06535
DID NOT SAVE RESULTS
{'MSE - mean': 83.03791153280946, 'MSE - std': 7.598087673974135, 'R2 - mean': 0.48504001422908527, 'R2 - std': 0.023305606066841917} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 729.80994
Epoch 1, Val Loss: 365.13538
Epoch 2, Val Loss: 148.74046
Epoch 3, Val Loss: 116.87504
Epoch 4, Val Loss: 107.82317
Epoch 5, Val Loss: 99.53143
Epoch 6, Val Loss: 102.10371
Epoch 7, Val Loss: 110.21545
Epoch 8, Val Loss: 92.67988
Epoch 9, Val Loss: 91.81167
Epoch 10, Val Loss: 101.28480
Epoch 11, Val Loss: 91.28056
Epoch 12, Val Loss: 83.02525
Epoch 13, Val Loss: 84.34731
Epoch 14, Val Loss: 87.85892
Epoch 15, Val Loss: 88.88889
Epoch 16, Val Loss: 87.96184
Epoch 17, Val Loss: 89.06392
Epoch 18, Val Loss: 85.30267
Epoch 19, Val Loss: 101.38123
Epoch 20, Val Loss: 98.20734
Epoch 21, Val Loss: 85.44238
Epoch 22, Val Loss: 94.75563
Epoch 23, Val Loss: 87.33742
Epoch 24, Val Loss: 97.92321
Epoch 25, Val Loss: 90.35644
Epoch 26, Val Loss: 87.93253
Epoch 27, Val Loss: 84.48212
Epoch 28, Val Loss: 85.74257
Epoch 29, Val Loss: 85.93011
Epoch 30, Val Loss: 86.81342
Epoch 31, Val Loss: 84.68526
Epoch 32, Val Loss: 77.04475
Epoch 33, Val Loss: 83.69959
Epoch 34, Val Loss: 97.56061
Epoch 35, Val Loss: 85.60912
Epoch 36, Val Loss: 102.99767
Epoch 37, Val Loss: 91.38860
Epoch 38, Val Loss: 91.23121
Epoch 39, Val Loss: 83.58907
Epoch 40, Val Loss: 84.18921
Epoch 41, Val Loss: 87.16000
Epoch 42, Val Loss: 81.15772
Epoch 43, Val Loss: 88.98469
Epoch 44, Val Loss: 82.42279
Epoch 45, Val Loss: 83.85085
Epoch 46, Val Loss: 79.33407
Epoch 47, Val Loss: 77.99513
Epoch 48, Val Loss: 84.09435
Epoch 49, Val Loss: 87.51595
Epoch 50, Val Loss: 83.36133
Epoch 51, Val Loss: 77.97896
Epoch 52, Val Loss: 77.57965
Epoch 53, Val Loss: 75.63176
Epoch 54, Val Loss: 100.87962
Epoch 55, Val Loss: 82.37505
Epoch 56, Val Loss: 78.86358
Epoch 57, Val Loss: 75.21349
Epoch 58, Val Loss: 79.91631
Epoch 59, Val Loss: 73.24160
Epoch 60, Val Loss: 76.93993
Epoch 61, Val Loss: 79.00768
Epoch 62, Val Loss: 75.02032
Epoch 63, Val Loss: 83.47308
Epoch 64, Val Loss: 92.84010
Epoch 65, Val Loss: 76.24817
Epoch 66, Val Loss: 75.06769
Epoch 67, Val Loss: 75.12960
Epoch 68, Val Loss: 94.25589
Epoch 69, Val Loss: 74.75165
Epoch 70, Val Loss: 73.52316
Epoch 71, Val Loss: 72.26488
Epoch 72, Val Loss: 76.40610
Epoch 73, Val Loss: 77.12645
Epoch 74, Val Loss: 78.37746
Epoch 75, Val Loss: 80.92556
Epoch 76, Val Loss: 82.29881
Epoch 77, Val Loss: 75.70724
Epoch 78, Val Loss: 72.03781
Epoch 79, Val Loss: 74.11960
Epoch 80, Val Loss: 82.12502
Epoch 81, Val Loss: 83.51869
Epoch 82, Val Loss: 82.19621
Epoch 83, Val Loss: 75.57641
Epoch 84, Val Loss: 75.85585
Epoch 85, Val Loss: 73.93404
Epoch 86, Val Loss: 87.19939
Epoch 87, Val Loss: 73.30298
Epoch 88, Val Loss: 78.66759
Epoch 89, Val Loss: 78.27782
Epoch 90, Val Loss: 72.93419
Epoch 91, Val Loss: 71.76829
Epoch 92, Val Loss: 73.92621
Epoch 93, Val Loss: 76.76073
Epoch 94, Val Loss: 71.15465
Epoch 95, Val Loss: 73.27498
Epoch 96, Val Loss: 89.10226
Epoch 97, Val Loss: 73.19745
Epoch 98, Val Loss: 75.18261
Epoch 99, Val Loss: 72.62076
DID NOT SAVE RESULTS
{'MSE - mean': 80.84845406651286, 'MSE - std': 8.08453121881572, 'R2 - mean': 0.49760844947240057, 'R2 - std': 0.0326555244510924} 
 

Results After CV: {'MSE - mean': 80.84845406651286, 'MSE - std': 8.08453121881572, 'R2 - mean': 0.49760844947240057, 'R2 - std': 0.0326555244510924}
Train time: 2182.9881839053996
Inference time: 0.1870365361988661
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 34 finished with value: 80.84845406651286 and parameters: {'p_m': 0.15299515476264244, 'alpha': 6.574303058022894, 'K': 15, 'beta': 4.353130316616094}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 824.17365
Epoch 1, Val Loss: 457.14117
Epoch 2, Val Loss: 250.76146
Epoch 3, Val Loss: 231.52133
Epoch 4, Val Loss: 195.71303
Epoch 5, Val Loss: 186.84937
Epoch 6, Val Loss: 154.31470
Epoch 7, Val Loss: 140.74867
Epoch 8, Val Loss: 136.50995
Epoch 9, Val Loss: 120.83924
Epoch 10, Val Loss: 118.36810
Epoch 11, Val Loss: 132.66570
Epoch 12, Val Loss: 105.69009
Epoch 13, Val Loss: 108.71771
Epoch 14, Val Loss: 108.23538
Epoch 15, Val Loss: 101.79827
Epoch 16, Val Loss: 99.78391
Epoch 17, Val Loss: 105.56158
Epoch 18, Val Loss: 105.76981
Epoch 19, Val Loss: 95.47909
Epoch 20, Val Loss: 93.77436
Epoch 21, Val Loss: 96.91299
Epoch 22, Val Loss: 94.84226
Epoch 23, Val Loss: 98.62560
Epoch 24, Val Loss: 99.74811
Epoch 25, Val Loss: 93.99646
Epoch 26, Val Loss: 99.36738
Epoch 27, Val Loss: 89.37433
Epoch 28, Val Loss: 94.71391
Epoch 29, Val Loss: 89.28371
Epoch 30, Val Loss: 88.54885
Epoch 31, Val Loss: 97.08765
Epoch 32, Val Loss: 90.64719
Epoch 33, Val Loss: 89.59309
Epoch 34, Val Loss: 96.05401
Epoch 35, Val Loss: 96.08186
Epoch 36, Val Loss: 88.90695
Epoch 37, Val Loss: 97.34709
Epoch 38, Val Loss: 92.57097
Epoch 39, Val Loss: 100.39460
Epoch 40, Val Loss: 90.80266
Epoch 41, Val Loss: 96.48834
Epoch 42, Val Loss: 95.35941
Epoch 43, Val Loss: 89.38091
Epoch 44, Val Loss: 91.62708
Epoch 45, Val Loss: 90.14684
Epoch 46, Val Loss: 105.14435
Epoch 47, Val Loss: 103.49847
Epoch 48, Val Loss: 93.73376
Epoch 49, Val Loss: 87.05582
Epoch 50, Val Loss: 93.62240
Epoch 51, Val Loss: 103.12767
Epoch 52, Val Loss: 91.02724
Epoch 53, Val Loss: 106.11603
Epoch 54, Val Loss: 88.47363
Epoch 55, Val Loss: 89.71352
Epoch 56, Val Loss: 90.15827
Epoch 57, Val Loss: 104.86975
Epoch 58, Val Loss: 88.51634
Epoch 59, Val Loss: 93.59197
Epoch 60, Val Loss: 92.83765
Epoch 61, Val Loss: 99.19221
Epoch 62, Val Loss: 93.35793
Epoch 63, Val Loss: 96.84960
Epoch 64, Val Loss: 91.85170
Epoch 65, Val Loss: 87.08160
Epoch 66, Val Loss: 95.10113
Epoch 67, Val Loss: 94.56619
Epoch 68, Val Loss: 91.03253
Epoch 69, Val Loss: 99.58069
Epoch 70, Val Loss: 91.96355
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 91.3317331515589, 'MSE - std': 0.0, 'R2 - mean': 0.4677796079494265, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1105.69250
Epoch 1, Val Loss: 583.95984
Epoch 2, Val Loss: 245.31375
Epoch 3, Val Loss: 217.11690
Epoch 4, Val Loss: 188.94093
Epoch 5, Val Loss: 179.88210
Epoch 6, Val Loss: 143.30061
Epoch 7, Val Loss: 138.98552
Epoch 8, Val Loss: 124.31760
Epoch 9, Val Loss: 131.10576
Epoch 10, Val Loss: 105.16793
Epoch 11, Val Loss: 124.60541
Epoch 12, Val Loss: 97.03834
Epoch 13, Val Loss: 93.53660
Epoch 14, Val Loss: 98.01337
Epoch 15, Val Loss: 85.55493
Epoch 16, Val Loss: 93.15387
Epoch 17, Val Loss: 84.24081
Epoch 18, Val Loss: 87.10059
Epoch 19, Val Loss: 82.32198
Epoch 20, Val Loss: 77.24088
Epoch 21, Val Loss: 84.36782
Epoch 22, Val Loss: 79.99397
Epoch 23, Val Loss: 80.09075
Epoch 24, Val Loss: 80.89103
Epoch 25, Val Loss: 75.98732
Epoch 26, Val Loss: 79.75113
Epoch 27, Val Loss: 85.13689
Epoch 28, Val Loss: 78.61950
Epoch 29, Val Loss: 83.42332
Epoch 30, Val Loss: 80.66560
Epoch 31, Val Loss: 81.58631
Epoch 32, Val Loss: 76.65002
Epoch 33, Val Loss: 77.12341
Epoch 34, Val Loss: 76.38103
Epoch 35, Val Loss: 74.54498
Epoch 36, Val Loss: 83.05820
Epoch 37, Val Loss: 70.56036
Epoch 38, Val Loss: 75.53590
Epoch 39, Val Loss: 75.46960
Epoch 40, Val Loss: 76.65984
Epoch 41, Val Loss: 75.21622
Epoch 42, Val Loss: 80.45571
Epoch 43, Val Loss: 77.04355
Epoch 44, Val Loss: 79.52339
Epoch 45, Val Loss: 80.09417
Epoch 46, Val Loss: 77.08661
Epoch 47, Val Loss: 72.36629
Epoch 48, Val Loss: 71.80820
Epoch 49, Val Loss: 74.86026
Epoch 50, Val Loss: 86.94405
Epoch 51, Val Loss: 74.62603
Epoch 52, Val Loss: 81.10938
Epoch 53, Val Loss: 74.07365
Epoch 54, Val Loss: 73.11063
Epoch 55, Val Loss: 73.35960
Epoch 56, Val Loss: 73.97498
Epoch 57, Val Loss: 76.23126
Epoch 58, Val Loss: 72.30117
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.25954088720886, 'MSE - std': 6.072192264350029, 'R2 - mean': 0.48128293079379963, 'R2 - std': 0.013503322844373111} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1322.35669
Epoch 1, Val Loss: 554.96991
Epoch 2, Val Loss: 246.64005
Epoch 3, Val Loss: 196.72910
Epoch 4, Val Loss: 222.01035
Epoch 5, Val Loss: 158.40225
Epoch 6, Val Loss: 149.08365
Epoch 7, Val Loss: 118.75330
Epoch 8, Val Loss: 106.66946
Epoch 9, Val Loss: 108.76718
Epoch 10, Val Loss: 107.16613
Epoch 11, Val Loss: 96.83853
Epoch 12, Val Loss: 92.00343
Epoch 13, Val Loss: 98.96723
Epoch 14, Val Loss: 90.47344
Epoch 15, Val Loss: 85.94106
Epoch 16, Val Loss: 79.67715
Epoch 17, Val Loss: 81.23773
Epoch 18, Val Loss: 79.44694
Epoch 19, Val Loss: 82.06905
Epoch 20, Val Loss: 78.69814
Epoch 21, Val Loss: 75.86591
Epoch 22, Val Loss: 76.47356
Epoch 23, Val Loss: 75.23657
Epoch 24, Val Loss: 74.26864
Epoch 25, Val Loss: 75.87613
Epoch 26, Val Loss: 75.16070
Epoch 27, Val Loss: 76.84120
Epoch 28, Val Loss: 73.17894
Epoch 29, Val Loss: 96.16367
Epoch 30, Val Loss: 72.80772
Epoch 31, Val Loss: 78.16373
Epoch 32, Val Loss: 81.85935
Epoch 33, Val Loss: 74.29027
Epoch 34, Val Loss: 71.61570
Epoch 35, Val Loss: 72.39081
Epoch 36, Val Loss: 80.38680
Epoch 37, Val Loss: 82.48924
Epoch 38, Val Loss: 72.18228
Epoch 39, Val Loss: 77.84592
Epoch 40, Val Loss: 82.26614
Epoch 41, Val Loss: 71.10087
Epoch 42, Val Loss: 81.39515
Epoch 43, Val Loss: 74.76729
Epoch 44, Val Loss: 74.75237
Epoch 45, Val Loss: 71.58707
Epoch 46, Val Loss: 72.49180
Epoch 47, Val Loss: 73.10287
Epoch 48, Val Loss: 74.71887
Epoch 49, Val Loss: 77.60452
Epoch 50, Val Loss: 78.36747
Epoch 51, Val Loss: 81.47901
Epoch 52, Val Loss: 74.57897
Epoch 53, Val Loss: 82.96188
Epoch 54, Val Loss: 69.71622
Epoch 55, Val Loss: 72.53249
Epoch 56, Val Loss: 74.42685
Epoch 57, Val Loss: 72.76269
Epoch 58, Val Loss: 73.79488
Epoch 59, Val Loss: 78.22642
Epoch 60, Val Loss: 74.90209
Epoch 61, Val Loss: 76.87032
Epoch 62, Val Loss: 71.22896
Epoch 63, Val Loss: 72.14691
Epoch 64, Val Loss: 70.67909
Epoch 65, Val Loss: 74.56454
Epoch 66, Val Loss: 78.48282
Epoch 67, Val Loss: 78.90591
Epoch 68, Val Loss: 76.55062
Epoch 69, Val Loss: 69.85345
Epoch 70, Val Loss: 80.89716
Epoch 71, Val Loss: 74.34340
Epoch 72, Val Loss: 79.37634
Epoch 73, Val Loss: 84.35524
Epoch 74, Val Loss: 73.81646
Epoch 75, Val Loss: 70.40890
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.93209329306637, 'MSE - std': 9.019113500421795, 'R2 - mean': 0.4989818773747176, 'R2 - std': 0.027350781318052943} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1019.29358
Epoch 1, Val Loss: 522.76569
Epoch 2, Val Loss: 269.55511
Epoch 3, Val Loss: 210.14560
Epoch 4, Val Loss: 191.03415
Epoch 5, Val Loss: 174.99048
Epoch 6, Val Loss: 149.84839
Epoch 7, Val Loss: 142.35561
Epoch 8, Val Loss: 138.03856
Epoch 9, Val Loss: 131.19084
Epoch 10, Val Loss: 128.17886
Epoch 11, Val Loss: 122.07854
Epoch 12, Val Loss: 108.46833
Epoch 13, Val Loss: 108.07147
Epoch 14, Val Loss: 101.35903
Epoch 15, Val Loss: 94.47525
Epoch 16, Val Loss: 95.14070
Epoch 17, Val Loss: 90.19049
Epoch 18, Val Loss: 99.10954
Epoch 19, Val Loss: 96.59928
Epoch 20, Val Loss: 91.33654
Epoch 21, Val Loss: 88.01318
Epoch 22, Val Loss: 86.20029
Epoch 23, Val Loss: 86.70473
Epoch 24, Val Loss: 85.89464
Epoch 25, Val Loss: 84.84988
Epoch 26, Val Loss: 83.92961
Epoch 27, Val Loss: 85.84860
Epoch 28, Val Loss: 87.26421
Epoch 29, Val Loss: 99.34602
Epoch 30, Val Loss: 84.59165
Epoch 31, Val Loss: 82.92451
Epoch 32, Val Loss: 85.12342
Epoch 33, Val Loss: 83.03309
Epoch 34, Val Loss: 92.55650
Epoch 35, Val Loss: 80.45641
Epoch 36, Val Loss: 81.12955
Epoch 37, Val Loss: 81.31615
Epoch 38, Val Loss: 84.51555
Epoch 39, Val Loss: 83.19930
Epoch 40, Val Loss: 79.67560
Epoch 41, Val Loss: 83.70354
Epoch 42, Val Loss: 80.05708
Epoch 43, Val Loss: 83.15751
Epoch 44, Val Loss: 86.64510
Epoch 45, Val Loss: 79.41457
Epoch 46, Val Loss: 81.07623
Epoch 47, Val Loss: 79.94805
Epoch 48, Val Loss: 86.28981
Epoch 49, Val Loss: 92.61961
Epoch 50, Val Loss: 83.71832
Epoch 51, Val Loss: 88.55905
Epoch 52, Val Loss: 81.71864
Epoch 53, Val Loss: 82.30663
Epoch 54, Val Loss: 89.65652
Epoch 55, Val Loss: 81.89739
Epoch 56, Val Loss: 82.23090
Epoch 57, Val Loss: 83.20350
Epoch 58, Val Loss: 86.28891
Epoch 59, Val Loss: 83.79596
Epoch 60, Val Loss: 88.83071
Epoch 61, Val Loss: 85.48374
Epoch 62, Val Loss: 79.09957
Epoch 63, Val Loss: 81.68224
Epoch 64, Val Loss: 88.99611
Epoch 65, Val Loss: 82.92295
Epoch 66, Val Loss: 83.49516
Epoch 67, Val Loss: 81.39684
Epoch 68, Val Loss: 85.09779
Epoch 69, Val Loss: 84.20346
Epoch 70, Val Loss: 84.62357
Epoch 71, Val Loss: 81.09601
Epoch 72, Val Loss: 80.76849
Epoch 73, Val Loss: 89.07349
Epoch 74, Val Loss: 87.33964
Epoch 75, Val Loss: 81.38132
Epoch 76, Val Loss: 98.45050
Epoch 77, Val Loss: 85.41772
Epoch 78, Val Loss: 81.93806
Epoch 79, Val Loss: 82.92930
Epoch 80, Val Loss: 88.96557
Epoch 81, Val Loss: 82.92031
Epoch 82, Val Loss: 81.90193
Epoch 83, Val Loss: 82.74132
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.54556624952033, 'MSE - std': 9.02768126001725, 'R2 - mean': 0.4888226710678736, 'R2 - std': 0.029507242287039003} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1451.94946
Epoch 1, Val Loss: 519.85559
Epoch 2, Val Loss: 259.18839
Epoch 3, Val Loss: 213.50597
Epoch 4, Val Loss: 184.08688
Epoch 5, Val Loss: 166.25909
Epoch 6, Val Loss: 156.13887
Epoch 7, Val Loss: 146.64592
Epoch 8, Val Loss: 129.97876
Epoch 9, Val Loss: 143.90167
Epoch 10, Val Loss: 125.24393
Epoch 11, Val Loss: 116.31601
Epoch 12, Val Loss: 106.73640
Epoch 13, Val Loss: 101.55695
Epoch 14, Val Loss: 102.40482
Epoch 15, Val Loss: 97.25383
Epoch 16, Val Loss: 91.99924
Epoch 17, Val Loss: 96.86783
Epoch 18, Val Loss: 91.58311
Epoch 19, Val Loss: 90.07001
Epoch 20, Val Loss: 85.33406
Epoch 21, Val Loss: 88.92912
Epoch 22, Val Loss: 82.06323
Epoch 23, Val Loss: 90.70375
Epoch 24, Val Loss: 83.60528
Epoch 25, Val Loss: 85.01848
Epoch 26, Val Loss: 81.92593
Epoch 27, Val Loss: 84.44340
Epoch 28, Val Loss: 83.72633
Epoch 29, Val Loss: 89.33956
Epoch 30, Val Loss: 79.52469
Epoch 31, Val Loss: 86.44142
Epoch 32, Val Loss: 84.41695
Epoch 33, Val Loss: 91.20643
Epoch 34, Val Loss: 84.50931
Epoch 35, Val Loss: 94.68385
Epoch 36, Val Loss: 82.26688
Epoch 37, Val Loss: 85.90743
Epoch 38, Val Loss: 78.63120
Epoch 39, Val Loss: 82.06865
Epoch 40, Val Loss: 86.78207
Epoch 41, Val Loss: 81.83726
Epoch 42, Val Loss: 77.45359
Epoch 43, Val Loss: 80.46609
Epoch 44, Val Loss: 80.62257
Epoch 45, Val Loss: 88.20750
Epoch 46, Val Loss: 104.15788
Epoch 47, Val Loss: 84.42340
Epoch 48, Val Loss: 91.48166
Epoch 49, Val Loss: 81.44603
Epoch 50, Val Loss: 78.57392
Epoch 51, Val Loss: 81.21371
Epoch 52, Val Loss: 80.53044
Epoch 53, Val Loss: 74.70137
Epoch 54, Val Loss: 78.43849
Epoch 55, Val Loss: 78.86488
Epoch 56, Val Loss: 92.41734
Epoch 57, Val Loss: 87.90247
Epoch 58, Val Loss: 93.12764
Epoch 59, Val Loss: 77.68251
Epoch 60, Val Loss: 79.25762
Epoch 61, Val Loss: 81.70232
Epoch 62, Val Loss: 80.00353
Epoch 63, Val Loss: 79.80587
Epoch 64, Val Loss: 80.04385
Epoch 65, Val Loss: 82.41341
Epoch 66, Val Loss: 79.30115
Epoch 67, Val Loss: 81.16145
Epoch 68, Val Loss: 79.11169
Epoch 69, Val Loss: 85.50581
Epoch 70, Val Loss: 79.84038
Epoch 71, Val Loss: 89.21808
Epoch 72, Val Loss: 82.19740
Epoch 73, Val Loss: 84.27382
Epoch 74, Val Loss: 77.97794
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.46840662227723, 'MSE - std': 8.357051788533036, 'R2 - mean': 0.4942763272040331, 'R2 - std': 0.02855715915343645} 
 

Results After CV: {'MSE - mean': 81.46840662227723, 'MSE - std': 8.357051788533036, 'R2 - mean': 0.4942763272040331, 'R2 - std': 0.02855715915343645}
Train time: 728.5169213186048
Inference time: 0.18827367320191116
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 35 finished with value: 81.46840662227723 and parameters: {'p_m': 0.709082103821515, 'alpha': 5.272384775117592, 'K': 5, 'beta': 6.4711962163768835}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 651.88074
Epoch 1, Val Loss: 421.82477
Epoch 2, Val Loss: 184.71318
Epoch 3, Val Loss: 148.20288
Epoch 4, Val Loss: 139.40448
Epoch 5, Val Loss: 127.43046
Epoch 6, Val Loss: 115.23090
Epoch 7, Val Loss: 113.14478
Epoch 8, Val Loss: 113.46201
Epoch 9, Val Loss: 101.68691
Epoch 10, Val Loss: 108.33511
Epoch 11, Val Loss: 123.92946
Epoch 12, Val Loss: 116.32012
Epoch 13, Val Loss: 102.36873
Epoch 14, Val Loss: 106.09906
Epoch 15, Val Loss: 103.16156
Epoch 16, Val Loss: 96.35077
Epoch 17, Val Loss: 98.19876
Epoch 18, Val Loss: 111.52225
Epoch 19, Val Loss: 111.29218
Epoch 20, Val Loss: 95.75373
Epoch 21, Val Loss: 96.10404
Epoch 22, Val Loss: 99.66268
Epoch 23, Val Loss: 94.68818
Epoch 24, Val Loss: 106.13576
Epoch 25, Val Loss: 97.55883
Epoch 26, Val Loss: 101.49216
Epoch 27, Val Loss: 89.49863
Epoch 28, Val Loss: 87.15546
Epoch 29, Val Loss: 94.31915
Epoch 30, Val Loss: 92.08216
Epoch 31, Val Loss: 86.39194
Epoch 32, Val Loss: 99.63068
Epoch 33, Val Loss: 85.65576
Epoch 34, Val Loss: 96.17071
Epoch 35, Val Loss: 86.38058
Epoch 36, Val Loss: 86.16989
Epoch 37, Val Loss: 92.53546
Epoch 38, Val Loss: 91.12661
Epoch 39, Val Loss: 86.84039
Epoch 40, Val Loss: 84.96349
Epoch 41, Val Loss: 104.27630
Epoch 42, Val Loss: 89.50214
Epoch 43, Val Loss: 98.94275
Epoch 44, Val Loss: 89.68047
Epoch 45, Val Loss: 87.03895
Epoch 46, Val Loss: 84.31792
Epoch 47, Val Loss: 92.52282
Epoch 48, Val Loss: 90.07318
Epoch 49, Val Loss: 86.06583
Epoch 50, Val Loss: 85.63744
Epoch 51, Val Loss: 90.40205
Epoch 52, Val Loss: 89.05719
Epoch 53, Val Loss: 84.28361
Epoch 54, Val Loss: 83.08946
Epoch 55, Val Loss: 86.09962
Epoch 56, Val Loss: 85.45542
Epoch 57, Val Loss: 83.90875
Epoch 58, Val Loss: 93.28995
Epoch 59, Val Loss: 86.33598
Epoch 60, Val Loss: 90.41285
Epoch 61, Val Loss: 98.36536
Epoch 62, Val Loss: 90.98611
Epoch 63, Val Loss: 83.69032
Epoch 64, Val Loss: 95.86808
Epoch 65, Val Loss: 89.11192
Epoch 66, Val Loss: 89.68428
Epoch 67, Val Loss: 84.38976
Epoch 68, Val Loss: 86.34961
Epoch 69, Val Loss: 83.78603
Epoch 70, Val Loss: 86.79335
Epoch 71, Val Loss: 83.42674
Epoch 72, Val Loss: 84.08527
Epoch 73, Val Loss: 88.13136
Epoch 74, Val Loss: 85.45924
Epoch 75, Val Loss: 86.20471
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.43165296790653, 'MSE - std': 0.0, 'R2 - mean': 0.4905066726042453, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1087.88513
Epoch 1, Val Loss: 447.81137
Epoch 2, Val Loss: 184.78088
Epoch 3, Val Loss: 158.23022
Epoch 4, Val Loss: 160.92169
Epoch 5, Val Loss: 128.21881
Epoch 6, Val Loss: 133.58253
Epoch 7, Val Loss: 110.23226
Epoch 8, Val Loss: 105.07576
Epoch 9, Val Loss: 103.64246
Epoch 10, Val Loss: 104.06795
Epoch 11, Val Loss: 102.11830
Epoch 12, Val Loss: 118.24984
Epoch 13, Val Loss: 98.98329
Epoch 14, Val Loss: 82.34859
Epoch 15, Val Loss: 80.76331
Epoch 16, Val Loss: 81.17993
Epoch 17, Val Loss: 86.19476
Epoch 18, Val Loss: 93.84690
Epoch 19, Val Loss: 79.89166
Epoch 20, Val Loss: 89.58992
Epoch 21, Val Loss: 87.39429
Epoch 22, Val Loss: 80.53519
Epoch 23, Val Loss: 77.90780
Epoch 24, Val Loss: 77.28763
Epoch 25, Val Loss: 79.81551
Epoch 26, Val Loss: 92.42944
Epoch 27, Val Loss: 90.37342
Epoch 28, Val Loss: 85.04919
Epoch 29, Val Loss: 86.68410
Epoch 30, Val Loss: 77.54846
Epoch 31, Val Loss: 84.34031
Epoch 32, Val Loss: 81.28422
Epoch 33, Val Loss: 89.26873
Epoch 34, Val Loss: 75.06477
Epoch 35, Val Loss: 70.99034
Epoch 36, Val Loss: 75.81129
Epoch 37, Val Loss: 78.89844
Epoch 38, Val Loss: 82.41926
Epoch 39, Val Loss: 96.07360
Epoch 40, Val Loss: 73.40150
Epoch 41, Val Loss: 77.70383
Epoch 42, Val Loss: 80.02145
Epoch 43, Val Loss: 73.63002
Epoch 44, Val Loss: 79.24732
Epoch 45, Val Loss: 73.30463
Epoch 46, Val Loss: 75.51829
Epoch 47, Val Loss: 74.54167
Epoch 48, Val Loss: 89.99541
Epoch 49, Val Loss: 78.41390
Epoch 50, Val Loss: 71.34824
Epoch 51, Val Loss: 74.07890
Epoch 52, Val Loss: 71.85763
Epoch 53, Val Loss: 74.42226
Epoch 54, Val Loss: 74.62675
Epoch 55, Val Loss: 74.80894
Epoch 56, Val Loss: 80.43551
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.16348789594161, 'MSE - std': 4.2681650719649085, 'R2 - mean': 0.49357802258401035, 'R2 - std': 0.003071349979765048} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 674.28229
Epoch 1, Val Loss: 404.06281
Epoch 2, Val Loss: 153.75801
Epoch 3, Val Loss: 122.51761
Epoch 4, Val Loss: 111.92646
Epoch 5, Val Loss: 98.98343
Epoch 6, Val Loss: 92.18331
Epoch 7, Val Loss: 95.75555
Epoch 8, Val Loss: 85.62253
Epoch 9, Val Loss: 89.60741
Epoch 10, Val Loss: 87.03982
Epoch 11, Val Loss: 89.44957
Epoch 12, Val Loss: 86.40842
Epoch 13, Val Loss: 82.34372
Epoch 14, Val Loss: 129.22719
Epoch 15, Val Loss: 88.25987
Epoch 16, Val Loss: 90.26524
Epoch 17, Val Loss: 77.01779
Epoch 18, Val Loss: 84.38657
Epoch 19, Val Loss: 84.03615
Epoch 20, Val Loss: 82.62147
Epoch 21, Val Loss: 84.75344
Epoch 22, Val Loss: 86.38032
Epoch 23, Val Loss: 80.03596
Epoch 24, Val Loss: 85.28630
Epoch 25, Val Loss: 74.26504
Epoch 26, Val Loss: 79.13075
Epoch 27, Val Loss: 86.39828
Epoch 28, Val Loss: 74.50454
Epoch 29, Val Loss: 78.28207
Epoch 30, Val Loss: 85.93980
Epoch 31, Val Loss: 73.78384
Epoch 32, Val Loss: 70.67472
Epoch 33, Val Loss: 75.03585
Epoch 34, Val Loss: 74.93484
Epoch 35, Val Loss: 75.91374
Epoch 36, Val Loss: 71.67992
Epoch 37, Val Loss: 81.33929
Epoch 38, Val Loss: 69.94752
Epoch 39, Val Loss: 79.88934
Epoch 40, Val Loss: 85.32747
Epoch 41, Val Loss: 71.31642
Epoch 42, Val Loss: 71.99544
Epoch 43, Val Loss: 74.12538
Epoch 44, Val Loss: 70.61461
Epoch 45, Val Loss: 73.11899
Epoch 46, Val Loss: 69.64836
Epoch 47, Val Loss: 70.56245
Epoch 48, Val Loss: 69.77684
Epoch 49, Val Loss: 73.33107
Epoch 50, Val Loss: 74.75549
Epoch 51, Val Loss: 74.99641
Epoch 52, Val Loss: 70.45386
Epoch 53, Val Loss: 68.68475
Epoch 54, Val Loss: 68.39599
Epoch 55, Val Loss: 73.86688
Epoch 56, Val Loss: 70.75884
Epoch 57, Val Loss: 72.20833
Epoch 58, Val Loss: 68.03777
Epoch 59, Val Loss: 70.18851
Epoch 60, Val Loss: 66.87511
Epoch 61, Val Loss: 76.60871
Epoch 62, Val Loss: 73.44271
Epoch 63, Val Loss: 71.06920
Epoch 64, Val Loss: 72.99161
Epoch 65, Val Loss: 72.52417
Epoch 66, Val Loss: 68.15389
Epoch 67, Val Loss: 75.46519
Epoch 68, Val Loss: 67.89731
Epoch 69, Val Loss: 69.17355
Epoch 70, Val Loss: 68.99048
Epoch 71, Val Loss: 74.29111
Epoch 72, Val Loss: 70.82190
Epoch 73, Val Loss: 69.74138
Epoch 74, Val Loss: 70.88182
Epoch 75, Val Loss: 69.52604
Epoch 76, Val Loss: 85.60133
Epoch 77, Val Loss: 75.79490
Epoch 78, Val Loss: 78.55517
Epoch 79, Val Loss: 70.31076
Epoch 80, Val Loss: 71.79739
Epoch 81, Val Loss: 69.83110
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.96400130420551, 'MSE - std': 8.137207364301833, 'R2 - mean': 0.5110145041196402, 'R2 - std': 0.024786096313932342} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 493.64825
Epoch 1, Val Loss: 408.10199
Epoch 2, Val Loss: 174.72000
Epoch 3, Val Loss: 142.89012
Epoch 4, Val Loss: 147.02673
Epoch 5, Val Loss: 123.03535
Epoch 6, Val Loss: 120.05116
Epoch 7, Val Loss: 109.09145
Epoch 8, Val Loss: 124.62145
Epoch 9, Val Loss: 128.33582
Epoch 10, Val Loss: 105.90898
Epoch 11, Val Loss: 98.26500
Epoch 12, Val Loss: 99.40755
Epoch 13, Val Loss: 101.93811
Epoch 14, Val Loss: 100.77766
Epoch 15, Val Loss: 92.75267
Epoch 16, Val Loss: 90.95732
Epoch 17, Val Loss: 101.33944
Epoch 18, Val Loss: 118.60643
Epoch 19, Val Loss: 96.12878
Epoch 20, Val Loss: 90.72638
Epoch 21, Val Loss: 96.65249
Epoch 22, Val Loss: 104.52361
Epoch 23, Val Loss: 93.47926
Epoch 24, Val Loss: 97.15929
Epoch 25, Val Loss: 93.64487
Epoch 26, Val Loss: 87.10733
Epoch 27, Val Loss: 98.05032
Epoch 28, Val Loss: 86.50911
Epoch 29, Val Loss: 91.25429
Epoch 30, Val Loss: 94.18426
Epoch 31, Val Loss: 91.58083
Epoch 32, Val Loss: 94.49832
Epoch 33, Val Loss: 83.52130
Epoch 34, Val Loss: 101.49184
Epoch 35, Val Loss: 89.67144
Epoch 36, Val Loss: 90.22769
Epoch 37, Val Loss: 85.81213
Epoch 38, Val Loss: 93.86487
Epoch 39, Val Loss: 87.87682
Epoch 40, Val Loss: 84.28915
Epoch 41, Val Loss: 88.61562
Epoch 42, Val Loss: 86.11479
Epoch 43, Val Loss: 84.96596
Epoch 44, Val Loss: 85.14907
Epoch 45, Val Loss: 85.38807
Epoch 46, Val Loss: 96.69517
Epoch 47, Val Loss: 84.09824
Epoch 48, Val Loss: 85.25132
Epoch 49, Val Loss: 83.35758
Epoch 50, Val Loss: 83.81707
Epoch 51, Val Loss: 91.80494
Epoch 52, Val Loss: 82.93923
Epoch 53, Val Loss: 88.14490
Epoch 54, Val Loss: 80.35508
Epoch 55, Val Loss: 83.78036
Epoch 56, Val Loss: 83.16245
Epoch 57, Val Loss: 82.36996
Epoch 58, Val Loss: 84.80305
Epoch 59, Val Loss: 83.29263
Epoch 60, Val Loss: 83.66993
Epoch 61, Val Loss: 82.15374
Epoch 62, Val Loss: 100.52982
Epoch 63, Val Loss: 89.10870
Epoch 64, Val Loss: 81.01683
Epoch 65, Val Loss: 81.53600
Epoch 66, Val Loss: 83.56967
Epoch 67, Val Loss: 83.29641
Epoch 68, Val Loss: 94.18439
Epoch 69, Val Loss: 84.77628
Epoch 70, Val Loss: 82.87893
Epoch 71, Val Loss: 86.21291
Epoch 72, Val Loss: 83.87235
Epoch 73, Val Loss: 84.35070
Epoch 74, Val Loss: 89.58189
Epoch 75, Val Loss: 83.29934
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.17060086568755, 'MSE - std': 8.972594385701743, 'R2 - mean': 0.49724125881698444, 'R2 - std': 0.03209158435422031} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1003.87030
Epoch 1, Val Loss: 433.56824
Epoch 2, Val Loss: 164.90698
Epoch 3, Val Loss: 140.90550
Epoch 4, Val Loss: 147.37202
Epoch 5, Val Loss: 125.18857
Epoch 6, Val Loss: 123.80272
Epoch 7, Val Loss: 116.73459
Epoch 8, Val Loss: 110.91435
Epoch 9, Val Loss: 105.61933
Epoch 10, Val Loss: 98.56712
Epoch 11, Val Loss: 109.48361
Epoch 12, Val Loss: 122.43422
Epoch 13, Val Loss: 107.71044
Epoch 14, Val Loss: 91.74017
Epoch 15, Val Loss: 95.67108
Epoch 16, Val Loss: 100.55970
Epoch 17, Val Loss: 88.21033
Epoch 18, Val Loss: 96.81749
Epoch 19, Val Loss: 91.63909
Epoch 20, Val Loss: 88.44215
Epoch 21, Val Loss: 94.70874
Epoch 22, Val Loss: 86.38953
Epoch 23, Val Loss: 90.68397
Epoch 24, Val Loss: 99.04385
Epoch 25, Val Loss: 94.93167
Epoch 26, Val Loss: 104.47273
Epoch 27, Val Loss: 89.12899
Epoch 28, Val Loss: 103.76212
Epoch 29, Val Loss: 92.11798
Epoch 30, Val Loss: 91.07120
Epoch 31, Val Loss: 85.83812
Epoch 32, Val Loss: 87.95947
Epoch 33, Val Loss: 87.43977
Epoch 34, Val Loss: 88.79453
Epoch 35, Val Loss: 85.57072
Epoch 36, Val Loss: 93.56153
Epoch 37, Val Loss: 79.78510
Epoch 38, Val Loss: 89.85306
Epoch 39, Val Loss: 80.97276
Epoch 40, Val Loss: 82.75261
Epoch 41, Val Loss: 91.58575
Epoch 42, Val Loss: 80.53802
Epoch 43, Val Loss: 89.92052
Epoch 44, Val Loss: 85.30467
Epoch 45, Val Loss: 92.93378
Epoch 46, Val Loss: 80.49788
Epoch 47, Val Loss: 79.05670
Epoch 48, Val Loss: 91.79890
Epoch 49, Val Loss: 78.60308
Epoch 50, Val Loss: 86.03017
Epoch 51, Val Loss: 80.50449
Epoch 52, Val Loss: 87.56081
Epoch 53, Val Loss: 82.17012
Epoch 54, Val Loss: 84.31345
Epoch 55, Val Loss: 79.18272
Epoch 56, Val Loss: 83.62453
Epoch 57, Val Loss: 80.30070
Epoch 58, Val Loss: 78.49603
Epoch 59, Val Loss: 78.54490
Epoch 60, Val Loss: 77.23277
Epoch 61, Val Loss: 81.04827
Epoch 62, Val Loss: 78.07794
Epoch 63, Val Loss: 80.32402
Epoch 64, Val Loss: 88.87408
Epoch 65, Val Loss: 76.70227
Epoch 66, Val Loss: 81.31515
Epoch 67, Val Loss: 77.41499
Epoch 68, Val Loss: 80.44078
Epoch 69, Val Loss: 86.53182
Epoch 70, Val Loss: 77.64894
Epoch 71, Val Loss: 79.99556
Epoch 72, Val Loss: 86.59927
Epoch 73, Val Loss: 81.80289
Epoch 74, Val Loss: 86.50072
Epoch 75, Val Loss: 77.37318
Epoch 76, Val Loss: 81.27843
Epoch 77, Val Loss: 75.43556
Epoch 78, Val Loss: 77.79979
Epoch 79, Val Loss: 78.31438
Epoch 80, Val Loss: 78.21789
Epoch 81, Val Loss: 88.79302
Epoch 82, Val Loss: 80.54282
Epoch 83, Val Loss: 82.60194
Epoch 84, Val Loss: 80.53415
Epoch 85, Val Loss: 80.35854
Epoch 86, Val Loss: 76.02641
Epoch 87, Val Loss: 79.49732
Epoch 88, Val Loss: 82.57048
Epoch 89, Val Loss: 81.47886
Epoch 90, Val Loss: 80.58645
Epoch 91, Val Loss: 76.80461
Epoch 92, Val Loss: 108.06935
Epoch 93, Val Loss: 79.78973
Epoch 94, Val Loss: 80.32751
Epoch 95, Val Loss: 79.45461
Epoch 96, Val Loss: 86.49020
Epoch 97, Val Loss: 89.79411
Epoch 98, Val Loss: 81.62895
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.15872991271422, 'MSE - std': 8.276562771473783, 'R2 - mean': 0.5023263628102127, 'R2 - std': 0.03045207644117246} 
 

Results After CV: {'MSE - mean': 80.15872991271422, 'MSE - std': 8.276562771473783, 'R2 - mean': 0.5023263628102127, 'R2 - std': 0.03045207644117246}
Train time: 2864.665277109001
Inference time: 0.18673455100215505
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 36 finished with value: 80.15872991271422 and parameters: {'p_m': 0.28543727629290533, 'alpha': 4.67487596518575, 'K': 20, 'beta': 7.678717125038141}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 812.04059
Epoch 1, Val Loss: 449.78391
Epoch 2, Val Loss: 187.19749
Epoch 3, Val Loss: 159.27100
Epoch 4, Val Loss: 129.74283
Epoch 5, Val Loss: 124.38844
Epoch 6, Val Loss: 133.39282
Epoch 7, Val Loss: 125.69293
Epoch 8, Val Loss: 111.89880
Epoch 9, Val Loss: 111.57863
Epoch 10, Val Loss: 103.85689
Epoch 11, Val Loss: 109.71671
Epoch 12, Val Loss: 106.60806
Epoch 13, Val Loss: 102.11388
Epoch 14, Val Loss: 111.60301
Epoch 15, Val Loss: 102.99113
Epoch 16, Val Loss: 97.97079
Epoch 17, Val Loss: 99.30182
Epoch 18, Val Loss: 100.14729
Epoch 19, Val Loss: 96.45712
Epoch 20, Val Loss: 109.60532
Epoch 21, Val Loss: 108.10623
Epoch 22, Val Loss: 97.67345
Epoch 23, Val Loss: 96.74873
Epoch 24, Val Loss: 112.48250
Epoch 25, Val Loss: 95.10838
Epoch 26, Val Loss: 100.56168
Epoch 27, Val Loss: 97.77934
Epoch 28, Val Loss: 97.78206
Epoch 29, Val Loss: 104.03731
Epoch 30, Val Loss: 102.41905
Epoch 31, Val Loss: 107.55382
Epoch 32, Val Loss: 96.48447
Epoch 33, Val Loss: 96.18188
Epoch 34, Val Loss: 104.69148
Epoch 35, Val Loss: 104.28792
Epoch 36, Val Loss: 98.41592
Epoch 37, Val Loss: 101.08785
Epoch 38, Val Loss: 98.34822
Epoch 39, Val Loss: 102.05041
Epoch 40, Val Loss: 97.58706
Epoch 41, Val Loss: 93.22848
Epoch 42, Val Loss: 102.53185
Epoch 43, Val Loss: 95.20345
Epoch 44, Val Loss: 100.36311
Epoch 45, Val Loss: 95.94852
Epoch 46, Val Loss: 98.57647
Epoch 47, Val Loss: 112.53986
Epoch 48, Val Loss: 112.45856
Epoch 49, Val Loss: 101.02274
Epoch 50, Val Loss: 92.42685
Epoch 51, Val Loss: 94.71580
Epoch 52, Val Loss: 120.15179
Epoch 53, Val Loss: 101.76488
Epoch 54, Val Loss: 100.23150
Epoch 55, Val Loss: 97.90172
Epoch 56, Val Loss: 106.75690
Epoch 57, Val Loss: 123.38574
Epoch 58, Val Loss: 99.86212
Epoch 59, Val Loss: 91.73793
Epoch 60, Val Loss: 91.57066
Epoch 61, Val Loss: 96.79276
Epoch 62, Val Loss: 96.94887
Epoch 63, Val Loss: 107.09180
Epoch 64, Val Loss: 94.13828
Epoch 65, Val Loss: 97.89191
Epoch 66, Val Loss: 92.89652
Epoch 67, Val Loss: 86.21697
Epoch 68, Val Loss: 101.62650
Epoch 69, Val Loss: 89.68450
Epoch 70, Val Loss: 98.08801
Epoch 71, Val Loss: 93.84481
Epoch 72, Val Loss: 91.07159
Epoch 73, Val Loss: 87.02587
Epoch 74, Val Loss: 90.12584
Epoch 75, Val Loss: 90.43398
Epoch 76, Val Loss: 105.99222
Epoch 77, Val Loss: 89.19299
Epoch 78, Val Loss: 87.04888
Epoch 79, Val Loss: 86.42061
Epoch 80, Val Loss: 93.45473
Epoch 81, Val Loss: 86.88291
Epoch 82, Val Loss: 88.98657
Epoch 83, Val Loss: 91.83066
Epoch 84, Val Loss: 86.22066
Epoch 85, Val Loss: 89.60963
Epoch 86, Val Loss: 88.04116
Epoch 87, Val Loss: 86.46847
Epoch 88, Val Loss: 88.62747
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 89.97194432576224, 'MSE - std': 0.0, 'R2 - mean': 0.47570354979306306, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 569.33356
Epoch 1, Val Loss: 425.81708
Epoch 2, Val Loss: 148.51074
Epoch 3, Val Loss: 138.87672
Epoch 4, Val Loss: 126.45187
Epoch 5, Val Loss: 109.20126
Epoch 6, Val Loss: 124.60664
Epoch 7, Val Loss: 101.76538
Epoch 8, Val Loss: 95.99754
Epoch 9, Val Loss: 97.19581
Epoch 10, Val Loss: 93.74825
Epoch 11, Val Loss: 96.67632
Epoch 12, Val Loss: 89.61152
Epoch 13, Val Loss: 95.98131
Epoch 14, Val Loss: 94.64538
Epoch 15, Val Loss: 84.89613
Epoch 16, Val Loss: 83.67223
Epoch 17, Val Loss: 81.39665
Epoch 18, Val Loss: 107.03179
Epoch 19, Val Loss: 98.22215
Epoch 20, Val Loss: 96.64125
Epoch 21, Val Loss: 90.62820
Epoch 22, Val Loss: 89.10546
Epoch 23, Val Loss: 86.25579
Epoch 24, Val Loss: 94.35644
Epoch 25, Val Loss: 82.14600
Epoch 26, Val Loss: 103.90190
Epoch 27, Val Loss: 84.52870
Epoch 28, Val Loss: 82.13568
Epoch 29, Val Loss: 101.47945
Epoch 30, Val Loss: 96.41992
Epoch 31, Val Loss: 93.72723
Epoch 32, Val Loss: 79.21152
Epoch 33, Val Loss: 83.07394
Epoch 34, Val Loss: 84.68456
Epoch 35, Val Loss: 85.85092
Epoch 36, Val Loss: 83.84718
Epoch 37, Val Loss: 81.01070
Epoch 38, Val Loss: 82.77658
Epoch 39, Val Loss: 91.93442
Epoch 40, Val Loss: 80.48222
Epoch 41, Val Loss: 84.59962
Epoch 42, Val Loss: 80.28746
Epoch 43, Val Loss: 87.68310
Epoch 44, Val Loss: 83.95411
Epoch 45, Val Loss: 81.58949
Epoch 46, Val Loss: 82.08424
Epoch 47, Val Loss: 71.68647
Epoch 48, Val Loss: 89.28496
Epoch 49, Val Loss: 82.22501
Epoch 50, Val Loss: 82.50462
Epoch 51, Val Loss: 76.13010
Epoch 52, Val Loss: 78.77346
Epoch 53, Val Loss: 77.70089
Epoch 54, Val Loss: 75.94940
Epoch 55, Val Loss: 78.98679
Epoch 56, Val Loss: 76.51819
Epoch 57, Val Loss: 74.95147
Epoch 58, Val Loss: 77.03788
Epoch 59, Val Loss: 77.30432
Epoch 60, Val Loss: 93.46581
Epoch 61, Val Loss: 79.06387
Epoch 62, Val Loss: 80.58818
Epoch 63, Val Loss: 76.74313
Epoch 64, Val Loss: 81.36154
Epoch 65, Val Loss: 76.86823
Epoch 66, Val Loss: 79.42039
Epoch 67, Val Loss: 72.70583
Epoch 68, Val Loss: 77.83264
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.3862824279208, 'MSE - std': 4.58566189784144, 'R2 - mean': 0.48009857999679795, 'R2 - std': 0.004395030203734884} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1459.13550
Epoch 1, Val Loss: 387.43597
Epoch 2, Val Loss: 144.96405
Epoch 3, Val Loss: 125.20558
Epoch 4, Val Loss: 116.94083
Epoch 5, Val Loss: 113.46564
Epoch 6, Val Loss: 95.92491
Epoch 7, Val Loss: 98.67116
Epoch 8, Val Loss: 88.28469
Epoch 9, Val Loss: 99.69112
Epoch 10, Val Loss: 91.90306
Epoch 11, Val Loss: 87.81122
Epoch 12, Val Loss: 90.59605
Epoch 13, Val Loss: 81.85359
Epoch 14, Val Loss: 97.96566
Epoch 15, Val Loss: 86.74809
Epoch 16, Val Loss: 81.01911
Epoch 17, Val Loss: 85.31547
Epoch 18, Val Loss: 75.07480
Epoch 19, Val Loss: 78.04684
Epoch 20, Val Loss: 78.56059
Epoch 21, Val Loss: 78.22855
Epoch 22, Val Loss: 80.05341
Epoch 23, Val Loss: 81.31062
Epoch 24, Val Loss: 76.66706
Epoch 25, Val Loss: 83.65787
Epoch 26, Val Loss: 74.49895
Epoch 27, Val Loss: 78.55608
Epoch 28, Val Loss: 74.88994
Epoch 29, Val Loss: 90.28787
Epoch 30, Val Loss: 77.04756
Epoch 31, Val Loss: 80.53673
Epoch 32, Val Loss: 72.69220
Epoch 33, Val Loss: 86.52522
Epoch 34, Val Loss: 97.21196
Epoch 35, Val Loss: 76.00034
Epoch 36, Val Loss: 79.84074
Epoch 37, Val Loss: 93.99931
Epoch 38, Val Loss: 83.69820
Epoch 39, Val Loss: 83.70811
Epoch 40, Val Loss: 76.36084
Epoch 41, Val Loss: 80.08272
Epoch 42, Val Loss: 79.35498
Epoch 43, Val Loss: 76.58118
Epoch 44, Val Loss: 77.95477
Epoch 45, Val Loss: 80.96021
Epoch 46, Val Loss: 79.87693
Epoch 47, Val Loss: 72.01299
Epoch 48, Val Loss: 76.96582
Epoch 49, Val Loss: 80.64245
Epoch 50, Val Loss: 83.49049
Epoch 51, Val Loss: 77.27325
Epoch 52, Val Loss: 82.63673
Epoch 53, Val Loss: 80.28536
Epoch 54, Val Loss: 78.97827
Epoch 55, Val Loss: 76.36352
Epoch 56, Val Loss: 90.73153
Epoch 57, Val Loss: 77.56073
Epoch 58, Val Loss: 74.78519
Epoch 59, Val Loss: 72.35271
Epoch 60, Val Loss: 72.53297
Epoch 61, Val Loss: 74.67628
Epoch 62, Val Loss: 82.26175
Epoch 63, Val Loss: 72.98091
Epoch 64, Val Loss: 79.79616
Epoch 65, Val Loss: 71.43803
Epoch 66, Val Loss: 102.73251
Epoch 67, Val Loss: 86.44171
Epoch 68, Val Loss: 73.30896
Epoch 69, Val Loss: 72.17860
Epoch 70, Val Loss: 78.26406
Epoch 71, Val Loss: 72.83363
Epoch 72, Val Loss: 70.41590
Epoch 73, Val Loss: 74.49373
Epoch 74, Val Loss: 75.08559
Epoch 75, Val Loss: 71.80281
Epoch 76, Val Loss: 77.61552
Epoch 77, Val Loss: 69.69085
Epoch 78, Val Loss: 74.04739
Epoch 79, Val Loss: 78.40334
Epoch 80, Val Loss: 72.24263
Epoch 81, Val Loss: 78.72269
Epoch 82, Val Loss: 72.16419
Epoch 83, Val Loss: 71.35036
Epoch 84, Val Loss: 71.29253
Epoch 85, Val Loss: 72.40639
Epoch 86, Val Loss: 67.57242
Epoch 87, Val Loss: 79.98816
Epoch 88, Val Loss: 71.61681
Epoch 89, Val Loss: 68.11576
Epoch 90, Val Loss: 70.63240
Epoch 91, Val Loss: 72.36259
Epoch 92, Val Loss: 72.76643
Epoch 93, Val Loss: 71.18219
Epoch 94, Val Loss: 73.59527
Epoch 95, Val Loss: 76.33507
Epoch 96, Val Loss: 72.25185
Epoch 97, Val Loss: 74.11600
Epoch 98, Val Loss: 76.02258
Epoch 99, Val Loss: 70.43472
DID NOT SAVE RESULTS
{'MSE - mean': 79.58271724435104, 'MSE - std': 9.021175147438527, 'R2 - mean': 0.5011084044329951, 'R2 - std': 0.029928297189685628} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 628.78064
Epoch 1, Val Loss: 295.36359
Epoch 2, Val Loss: 171.48422
Epoch 3, Val Loss: 130.35625
Epoch 4, Val Loss: 119.85413
Epoch 5, Val Loss: 114.11600
Epoch 6, Val Loss: 108.82026
Epoch 7, Val Loss: 111.28295
Epoch 8, Val Loss: 107.02815
Epoch 9, Val Loss: 112.10410
Epoch 10, Val Loss: 98.26522
Epoch 11, Val Loss: 94.73413
Epoch 12, Val Loss: 107.95842
Epoch 13, Val Loss: 108.47896
Epoch 14, Val Loss: 99.10802
Epoch 15, Val Loss: 98.84227
Epoch 16, Val Loss: 109.32482
Epoch 17, Val Loss: 92.51389
Epoch 18, Val Loss: 87.78571
Epoch 19, Val Loss: 91.99456
Epoch 20, Val Loss: 94.79650
Epoch 21, Val Loss: 92.57482
Epoch 22, Val Loss: 98.27888
Epoch 23, Val Loss: 101.26789
Epoch 24, Val Loss: 96.81602
Epoch 25, Val Loss: 89.37797
Epoch 26, Val Loss: 90.93832
Epoch 27, Val Loss: 86.97174
Epoch 28, Val Loss: 87.05828
Epoch 29, Val Loss: 94.70141
Epoch 30, Val Loss: 86.78847
Epoch 31, Val Loss: 89.01300
Epoch 32, Val Loss: 95.53523
Epoch 33, Val Loss: 92.83494
Epoch 34, Val Loss: 85.76283
Epoch 35, Val Loss: 86.97753
Epoch 36, Val Loss: 83.01972
Epoch 37, Val Loss: 90.11690
Epoch 38, Val Loss: 90.07142
Epoch 39, Val Loss: 87.41302
Epoch 40, Val Loss: 87.45937
Epoch 41, Val Loss: 91.56289
Epoch 42, Val Loss: 91.63053
Epoch 43, Val Loss: 86.45918
Epoch 44, Val Loss: 90.11083
Epoch 45, Val Loss: 93.33033
Epoch 46, Val Loss: 91.75729
Epoch 47, Val Loss: 109.00433
Epoch 48, Val Loss: 83.01535
Epoch 49, Val Loss: 82.86318
Epoch 50, Val Loss: 82.42780
Epoch 51, Val Loss: 89.87744
Epoch 52, Val Loss: 81.84476
Epoch 53, Val Loss: 88.33265
Epoch 54, Val Loss: 81.30391
Epoch 55, Val Loss: 79.23989
Epoch 56, Val Loss: 81.70209
Epoch 57, Val Loss: 80.32271
Epoch 58, Val Loss: 80.52319
Epoch 59, Val Loss: 87.45030
Epoch 60, Val Loss: 77.50968
Epoch 61, Val Loss: 84.81828
Epoch 62, Val Loss: 80.80951
Epoch 63, Val Loss: 86.82193
Epoch 64, Val Loss: 80.53658
Epoch 65, Val Loss: 80.24577
Epoch 66, Val Loss: 80.43504
Epoch 67, Val Loss: 79.78076
Epoch 68, Val Loss: 100.91425
Epoch 69, Val Loss: 78.82440
Epoch 70, Val Loss: 79.09079
Epoch 71, Val Loss: 77.92479
Epoch 72, Val Loss: 84.98363
Epoch 73, Val Loss: 81.86758
Epoch 74, Val Loss: 77.77489
Epoch 75, Val Loss: 78.35042
Epoch 76, Val Loss: 81.54074
Epoch 77, Val Loss: 84.25640
Epoch 78, Val Loss: 79.60054
Epoch 79, Val Loss: 78.47645
Epoch 80, Val Loss: 82.63039
Epoch 81, Val Loss: 80.07485
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.97048522557155, 'MSE - std': 8.839712018895044, 'R2 - mean': 0.49229357106218996, 'R2 - std': 0.030081241523095208} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 754.04144
Epoch 1, Val Loss: 374.65845
Epoch 2, Val Loss: 175.59666
Epoch 3, Val Loss: 141.33942
Epoch 4, Val Loss: 118.05095
Epoch 5, Val Loss: 117.20145
Epoch 6, Val Loss: 105.52858
Epoch 7, Val Loss: 126.55699
Epoch 8, Val Loss: 97.66688
Epoch 9, Val Loss: 102.11729
Epoch 10, Val Loss: 117.58488
Epoch 11, Val Loss: 102.37428
Epoch 12, Val Loss: 95.29832
Epoch 13, Val Loss: 92.71989
Epoch 14, Val Loss: 93.16075
Epoch 15, Val Loss: 104.41894
Epoch 16, Val Loss: 97.57533
Epoch 17, Val Loss: 93.28024
Epoch 18, Val Loss: 87.89825
Epoch 19, Val Loss: 81.45926
Epoch 20, Val Loss: 103.86788
Epoch 21, Val Loss: 97.77084
Epoch 22, Val Loss: 95.52183
Epoch 23, Val Loss: 87.82301
Epoch 24, Val Loss: 93.28262
Epoch 25, Val Loss: 82.82204
Epoch 26, Val Loss: 88.48867
Epoch 27, Val Loss: 97.67593
Epoch 28, Val Loss: 94.19222
Epoch 29, Val Loss: 90.49588
Epoch 30, Val Loss: 90.32787
Epoch 31, Val Loss: 88.12361
Epoch 32, Val Loss: 90.89479
Epoch 33, Val Loss: 85.44649
Epoch 34, Val Loss: 88.81168
Epoch 35, Val Loss: 101.55109
Epoch 36, Val Loss: 88.02267
Epoch 37, Val Loss: 93.77479
Epoch 38, Val Loss: 83.46840
Epoch 39, Val Loss: 105.90102
Epoch 40, Val Loss: 89.16601
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.59706438734769, 'MSE - std': 7.941673586296357, 'R2 - mean': 0.4933608615905273, 'R2 - std': 0.026990022407255326} 
 

Results After CV: {'MSE - mean': 81.59706438734769, 'MSE - std': 7.941673586296357, 'R2 - mean': 0.4933608615905273, 'R2 - std': 0.026990022407255326}
Train time: 315.11342335579974
Inference time: 0.1962956774048507
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 37 finished with value: 81.59706438734769 and parameters: {'p_m': 0.13118872369474557, 'alpha': 6.207362231057187, 'K': 2, 'beta': 5.643342511163838}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1502.15588
Epoch 1, Val Loss: 313.37415
Epoch 2, Val Loss: 191.10863
Epoch 3, Val Loss: 172.71024
Epoch 4, Val Loss: 160.18532
Epoch 5, Val Loss: 137.27357
Epoch 6, Val Loss: 126.76749
Epoch 7, Val Loss: 127.82248
Epoch 8, Val Loss: 119.57835
Epoch 9, Val Loss: 116.23125
Epoch 10, Val Loss: 115.63288
Epoch 11, Val Loss: 107.40237
Epoch 12, Val Loss: 105.00890
Epoch 13, Val Loss: 107.39065
Epoch 14, Val Loss: 108.20803
Epoch 15, Val Loss: 115.25520
Epoch 16, Val Loss: 102.98497
Epoch 17, Val Loss: 101.25520
Epoch 18, Val Loss: 116.21693
Epoch 19, Val Loss: 106.61877
Epoch 20, Val Loss: 100.10097
Epoch 21, Val Loss: 100.98720
Epoch 22, Val Loss: 99.55914
Epoch 23, Val Loss: 97.35325
Epoch 24, Val Loss: 100.74181
Epoch 25, Val Loss: 105.11145
Epoch 26, Val Loss: 104.57700
Epoch 27, Val Loss: 102.88416
Epoch 28, Val Loss: 94.47063
Epoch 29, Val Loss: 104.94757
Epoch 30, Val Loss: 94.74887
Epoch 31, Val Loss: 100.61949
Epoch 32, Val Loss: 95.06184
Epoch 33, Val Loss: 100.40823
Epoch 34, Val Loss: 99.56860
Epoch 35, Val Loss: 103.97849
Epoch 36, Val Loss: 93.71313
Epoch 37, Val Loss: 99.76812
Epoch 38, Val Loss: 102.10455
Epoch 39, Val Loss: 94.21268
Epoch 40, Val Loss: 95.09318
Epoch 41, Val Loss: 98.45054
Epoch 42, Val Loss: 93.77077
Epoch 43, Val Loss: 97.90885
Epoch 44, Val Loss: 98.99602
Epoch 45, Val Loss: 102.99031
Epoch 46, Val Loss: 91.98696
Epoch 47, Val Loss: 93.69144
Epoch 48, Val Loss: 98.80762
Epoch 49, Val Loss: 89.20512
Epoch 50, Val Loss: 94.33456
Epoch 51, Val Loss: 91.26498
Epoch 52, Val Loss: 91.09206
Epoch 53, Val Loss: 93.97228
Epoch 54, Val Loss: 97.76638
Epoch 55, Val Loss: 92.20101
Epoch 56, Val Loss: 88.93579
Epoch 57, Val Loss: 94.47947
Epoch 58, Val Loss: 98.28101
Epoch 59, Val Loss: 103.16100
Epoch 60, Val Loss: 95.33028
Epoch 61, Val Loss: 95.06001
Epoch 62, Val Loss: 93.18564
Epoch 63, Val Loss: 97.64756
Epoch 64, Val Loss: 99.25902
Epoch 65, Val Loss: 93.78983
Epoch 66, Val Loss: 95.89513
Epoch 67, Val Loss: 93.49249
Epoch 68, Val Loss: 93.07948
Epoch 69, Val Loss: 89.88201
Epoch 70, Val Loss: 91.84263
Epoch 71, Val Loss: 91.67111
Epoch 72, Val Loss: 90.74140
Epoch 73, Val Loss: 97.05293
Epoch 74, Val Loss: 88.31087
Epoch 75, Val Loss: 93.71365
Epoch 76, Val Loss: 99.01845
Epoch 77, Val Loss: 91.71385
Epoch 78, Val Loss: 90.21320
Epoch 79, Val Loss: 92.67006
Epoch 80, Val Loss: 95.56425
Epoch 81, Val Loss: 92.73631
Epoch 82, Val Loss: 93.53665
Epoch 83, Val Loss: 92.80275
Epoch 84, Val Loss: 97.21092
Epoch 85, Val Loss: 97.37843
Epoch 86, Val Loss: 90.79983
Epoch 87, Val Loss: 102.84599
Epoch 88, Val Loss: 108.46070
Epoch 89, Val Loss: 101.02353
Epoch 90, Val Loss: 99.08707
Epoch 91, Val Loss: 89.46231
Epoch 92, Val Loss: 96.46609
Epoch 93, Val Loss: 91.31488
Epoch 94, Val Loss: 102.77510
Epoch 95, Val Loss: 91.14220
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 92.76225414031124, 'MSE - std': 0.0, 'R2 - mean': 0.45944348626205045, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1227.23560
Epoch 1, Val Loss: 283.99094
Epoch 2, Val Loss: 174.24503
Epoch 3, Val Loss: 157.74234
Epoch 4, Val Loss: 136.53909
Epoch 5, Val Loss: 126.45528
Epoch 6, Val Loss: 119.79662
Epoch 7, Val Loss: 114.93597
Epoch 8, Val Loss: 101.66682
Epoch 9, Val Loss: 100.74581
Epoch 10, Val Loss: 102.08980
Epoch 11, Val Loss: 100.98833
Epoch 12, Val Loss: 106.20513
Epoch 13, Val Loss: 94.36549
Epoch 14, Val Loss: 100.24849
Epoch 15, Val Loss: 91.61972
Epoch 16, Val Loss: 82.80652
Epoch 17, Val Loss: 83.58203
Epoch 18, Val Loss: 83.81083
Epoch 19, Val Loss: 83.50511
Epoch 20, Val Loss: 84.05047
Epoch 21, Val Loss: 85.03327
Epoch 22, Val Loss: 82.62923
Epoch 23, Val Loss: 81.46194
Epoch 24, Val Loss: 80.42117
Epoch 25, Val Loss: 80.77074
Epoch 26, Val Loss: 81.18910
Epoch 27, Val Loss: 79.95022
Epoch 28, Val Loss: 80.58441
Epoch 29, Val Loss: 79.31752
Epoch 30, Val Loss: 79.03651
Epoch 31, Val Loss: 78.72869
Epoch 32, Val Loss: 80.93407
Epoch 33, Val Loss: 74.81455
Epoch 34, Val Loss: 87.38978
Epoch 35, Val Loss: 78.05370
Epoch 36, Val Loss: 79.57498
Epoch 37, Val Loss: 72.44798
Epoch 38, Val Loss: 84.80585
Epoch 39, Val Loss: 78.33572
Epoch 40, Val Loss: 81.67772
Epoch 41, Val Loss: 80.08194
Epoch 42, Val Loss: 77.26011
Epoch 43, Val Loss: 78.72321
Epoch 44, Val Loss: 76.95548
Epoch 45, Val Loss: 82.72826
Epoch 46, Val Loss: 78.26007
Epoch 47, Val Loss: 78.26028
Epoch 48, Val Loss: 75.99512
Epoch 49, Val Loss: 90.80111
Epoch 50, Val Loss: 73.31851
Epoch 51, Val Loss: 76.33261
Epoch 52, Val Loss: 86.82703
Epoch 53, Val Loss: 71.68888
Epoch 54, Val Loss: 80.40509
Epoch 55, Val Loss: 76.97236
Epoch 56, Val Loss: 72.88675
Epoch 57, Val Loss: 71.22012
Epoch 58, Val Loss: 73.45698
Epoch 59, Val Loss: 80.98145
Epoch 60, Val Loss: 75.29848
Epoch 61, Val Loss: 72.74487
Epoch 62, Val Loss: 78.86563
Epoch 63, Val Loss: 79.26736
Epoch 64, Val Loss: 72.24825
Epoch 65, Val Loss: 81.21966
Epoch 66, Val Loss: 73.16112
Epoch 67, Val Loss: 74.71024
Epoch 68, Val Loss: 73.96789
Epoch 69, Val Loss: 74.44398
Epoch 70, Val Loss: 79.22552
Epoch 71, Val Loss: 74.19250
Epoch 72, Val Loss: 73.36340
Epoch 73, Val Loss: 78.46945
Epoch 74, Val Loss: 69.93343
Epoch 75, Val Loss: 83.62709
Epoch 76, Val Loss: 88.37574
Epoch 77, Val Loss: 81.87637
Epoch 78, Val Loss: 74.16631
Epoch 79, Val Loss: 75.89806
Epoch 80, Val Loss: 72.34683
Epoch 81, Val Loss: 72.82517
Epoch 82, Val Loss: 77.63410
Epoch 83, Val Loss: 73.42601
Epoch 84, Val Loss: 72.64511
Epoch 85, Val Loss: 82.50117
Epoch 86, Val Loss: 72.74832
Epoch 87, Val Loss: 79.99284
Epoch 88, Val Loss: 80.42928
Epoch 89, Val Loss: 73.53848
Epoch 90, Val Loss: 75.55603
Epoch 91, Val Loss: 82.63162
Epoch 92, Val Loss: 75.91142
Epoch 93, Val Loss: 79.51031
Epoch 94, Val Loss: 72.07684
Epoch 95, Val Loss: 72.68449
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.57709541652225, 'MSE - std': 7.185158723788987, 'R2 - mean': 0.47965222628359305, 'R2 - std': 0.020208740021542604} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1820.12280
Epoch 1, Val Loss: 412.90045
Epoch 2, Val Loss: 167.48915
Epoch 3, Val Loss: 151.69125
Epoch 4, Val Loss: 129.45415
Epoch 5, Val Loss: 113.07520
Epoch 6, Val Loss: 106.75517
Epoch 7, Val Loss: 114.57243
Epoch 8, Val Loss: 93.50734
Epoch 9, Val Loss: 97.31590
Epoch 10, Val Loss: 95.45979
Epoch 11, Val Loss: 94.56950
Epoch 12, Val Loss: 91.16040
Epoch 13, Val Loss: 86.31084
Epoch 14, Val Loss: 96.77625
Epoch 15, Val Loss: 88.67038
Epoch 16, Val Loss: 90.37544
Epoch 17, Val Loss: 92.15491
Epoch 18, Val Loss: 87.41891
Epoch 19, Val Loss: 80.39584
Epoch 20, Val Loss: 88.38416
Epoch 21, Val Loss: 90.30172
Epoch 22, Val Loss: 90.57922
Epoch 23, Val Loss: 83.78546
Epoch 24, Val Loss: 80.32162
Epoch 25, Val Loss: 85.41001
Epoch 26, Val Loss: 88.00026
Epoch 27, Val Loss: 80.20498
Epoch 28, Val Loss: 78.65406
Epoch 29, Val Loss: 78.37813
Epoch 30, Val Loss: 81.69803
Epoch 31, Val Loss: 76.74770
Epoch 32, Val Loss: 81.32361
Epoch 33, Val Loss: 77.05465
Epoch 34, Val Loss: 83.27615
Epoch 35, Val Loss: 78.40075
Epoch 36, Val Loss: 75.90999
Epoch 37, Val Loss: 87.27123
Epoch 38, Val Loss: 78.39330
Epoch 39, Val Loss: 72.17709
Epoch 40, Val Loss: 74.14242
Epoch 41, Val Loss: 73.62904
Epoch 42, Val Loss: 91.13164
Epoch 43, Val Loss: 74.65321
Epoch 44, Val Loss: 75.41607
Epoch 45, Val Loss: 74.90123
Epoch 46, Val Loss: 76.78066
Epoch 47, Val Loss: 81.92709
Epoch 48, Val Loss: 74.58225
Epoch 49, Val Loss: 78.45152
Epoch 50, Val Loss: 74.65369
Epoch 51, Val Loss: 96.44418
Epoch 52, Val Loss: 80.77242
Epoch 53, Val Loss: 75.08182
Epoch 54, Val Loss: 73.87835
Epoch 55, Val Loss: 78.47639
Epoch 56, Val Loss: 76.31364
Epoch 57, Val Loss: 74.67587
Epoch 58, Val Loss: 85.12230
Epoch 59, Val Loss: 75.52003
Epoch 60, Val Loss: 74.25183
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.31621155961194, 'MSE - std': 8.409990075787944, 'R2 - mean': 0.4900147997079914, 'R2 - std': 0.022068710235481046} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1548.96094
Epoch 1, Val Loss: 373.91583
Epoch 2, Val Loss: 174.24254
Epoch 3, Val Loss: 155.87543
Epoch 4, Val Loss: 141.06320
Epoch 5, Val Loss: 126.52550
Epoch 6, Val Loss: 130.64848
Epoch 7, Val Loss: 127.55125
Epoch 8, Val Loss: 113.31239
Epoch 9, Val Loss: 110.54338
Epoch 10, Val Loss: 102.60361
Epoch 11, Val Loss: 104.11899
Epoch 12, Val Loss: 115.82011
Epoch 13, Val Loss: 109.44777
Epoch 14, Val Loss: 95.12592
Epoch 15, Val Loss: 101.66064
Epoch 16, Val Loss: 98.84381
Epoch 17, Val Loss: 98.59556
Epoch 18, Val Loss: 94.08002
Epoch 19, Val Loss: 92.75025
Epoch 20, Val Loss: 91.79935
Epoch 21, Val Loss: 96.42241
Epoch 22, Val Loss: 92.53136
Epoch 23, Val Loss: 91.41629
Epoch 24, Val Loss: 90.65378
Epoch 25, Val Loss: 90.73602
Epoch 26, Val Loss: 92.14895
Epoch 27, Val Loss: 96.55714
Epoch 28, Val Loss: 88.85139
Epoch 29, Val Loss: 86.29043
Epoch 30, Val Loss: 83.50698
Epoch 31, Val Loss: 88.23891
Epoch 32, Val Loss: 83.51837
Epoch 33, Val Loss: 87.79527
Epoch 34, Val Loss: 87.57852
Epoch 35, Val Loss: 86.22432
Epoch 36, Val Loss: 88.59310
Epoch 37, Val Loss: 86.53319
Epoch 38, Val Loss: 80.92097
Epoch 39, Val Loss: 89.49648
Epoch 40, Val Loss: 86.16994
Epoch 41, Val Loss: 93.84912
Epoch 42, Val Loss: 86.51762
Epoch 43, Val Loss: 83.31506
Epoch 44, Val Loss: 83.17030
Epoch 45, Val Loss: 85.13216
Epoch 46, Val Loss: 83.84283
Epoch 47, Val Loss: 87.53002
Epoch 48, Val Loss: 83.15654
Epoch 49, Val Loss: 88.73613
Epoch 50, Val Loss: 85.21016
Epoch 51, Val Loss: 80.62263
Epoch 52, Val Loss: 83.08838
Epoch 53, Val Loss: 84.53510
Epoch 54, Val Loss: 84.92661
Epoch 55, Val Loss: 81.39050
Epoch 56, Val Loss: 83.65728
Epoch 57, Val Loss: 83.30291
Epoch 58, Val Loss: 84.93214
Epoch 59, Val Loss: 84.65656
Epoch 60, Val Loss: 81.07042
Epoch 61, Val Loss: 84.17539
Epoch 62, Val Loss: 90.27138
Epoch 63, Val Loss: 83.11032
Epoch 64, Val Loss: 87.96450
Epoch 65, Val Loss: 87.68899
Epoch 66, Val Loss: 86.47681
Epoch 67, Val Loss: 87.31143
Epoch 68, Val Loss: 81.88659
Epoch 69, Val Loss: 82.08054
Epoch 70, Val Loss: 82.28458
Epoch 71, Val Loss: 83.24825
Epoch 72, Val Loss: 88.79662
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.08354530155282, 'MSE - std': 8.718965415919028, 'R2 - mean': 0.47910167623815336, 'R2 - std': 0.02688047191172446} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1837.42053
Epoch 1, Val Loss: 387.50974
Epoch 2, Val Loss: 183.08888
Epoch 3, Val Loss: 153.32555
Epoch 4, Val Loss: 137.17786
Epoch 5, Val Loss: 129.62834
Epoch 6, Val Loss: 122.33996
Epoch 7, Val Loss: 115.85950
Epoch 8, Val Loss: 109.01453
Epoch 9, Val Loss: 127.38708
Epoch 10, Val Loss: 103.99852
Epoch 11, Val Loss: 104.17317
Epoch 12, Val Loss: 110.12552
Epoch 13, Val Loss: 110.72115
Epoch 14, Val Loss: 103.13345
Epoch 15, Val Loss: 94.97398
Epoch 16, Val Loss: 97.47343
Epoch 17, Val Loss: 97.04178
Epoch 18, Val Loss: 89.42856
Epoch 19, Val Loss: 85.92579
Epoch 20, Val Loss: 89.26769
Epoch 21, Val Loss: 92.81925
Epoch 22, Val Loss: 90.34465
Epoch 23, Val Loss: 86.46090
Epoch 24, Val Loss: 94.12389
Epoch 25, Val Loss: 96.94778
Epoch 26, Val Loss: 91.21767
Epoch 27, Val Loss: 99.48026
Epoch 28, Val Loss: 83.03720
Epoch 29, Val Loss: 87.79279
Epoch 30, Val Loss: 87.43120
Epoch 31, Val Loss: 89.18938
Epoch 32, Val Loss: 83.78358
Epoch 33, Val Loss: 81.42842
Epoch 34, Val Loss: 83.80357
Epoch 35, Val Loss: 88.25354
Epoch 36, Val Loss: 76.43801
Epoch 37, Val Loss: 84.80211
Epoch 38, Val Loss: 98.11354
Epoch 39, Val Loss: 83.77893
Epoch 40, Val Loss: 80.36023
Epoch 41, Val Loss: 80.28194
Epoch 42, Val Loss: 79.72042
Epoch 43, Val Loss: 84.77760
Epoch 44, Val Loss: 77.13017
Epoch 45, Val Loss: 82.50851
Epoch 46, Val Loss: 88.37848
Epoch 47, Val Loss: 87.41681
Epoch 48, Val Loss: 80.24905
Epoch 49, Val Loss: 90.28960
Epoch 50, Val Loss: 79.30157
Epoch 51, Val Loss: 80.72713
Epoch 52, Val Loss: 79.01003
Epoch 53, Val Loss: 86.60231
Epoch 54, Val Loss: 83.99153
Epoch 55, Val Loss: 82.74664
Epoch 56, Val Loss: 91.69539
Epoch 57, Val Loss: 78.51917
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.9089229947449, 'MSE - std': 8.144644657306829, 'R2 - mean': 0.4851816771548692, 'R2 - std': 0.02694278123629161} 
 

Results After CV: {'MSE - mean': 82.9089229947449, 'MSE - std': 8.144644657306829, 'R2 - mean': 0.4851816771548692, 'R2 - std': 0.02694278123629161}
Train time: 777.0198335892055
Inference time: 0.20055962960177567
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 38 finished with value: 82.9089229947449 and parameters: {'p_m': 0.548187985874851, 'alpha': 7.161166386005423, 'K': 5, 'beta': 2.6951501198109273}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 735.62415
Epoch 1, Val Loss: 353.75214
Epoch 2, Val Loss: 170.64594
Epoch 3, Val Loss: 142.86258
Epoch 4, Val Loss: 122.90155
Epoch 5, Val Loss: 122.76394
Epoch 6, Val Loss: 113.07714
Epoch 7, Val Loss: 106.62523
Epoch 8, Val Loss: 106.24409
Epoch 9, Val Loss: 100.81237
Epoch 10, Val Loss: 103.49117
Epoch 11, Val Loss: 101.35736
Epoch 12, Val Loss: 108.13409
Epoch 13, Val Loss: 100.12308
Epoch 14, Val Loss: 103.88891
Epoch 15, Val Loss: 104.31786
Epoch 16, Val Loss: 99.50768
Epoch 17, Val Loss: 107.02166
Epoch 18, Val Loss: 99.75030
Epoch 19, Val Loss: 102.52696
Epoch 20, Val Loss: 106.43401
Epoch 21, Val Loss: 104.49991
Epoch 22, Val Loss: 105.79080
Epoch 23, Val Loss: 105.12034
Epoch 24, Val Loss: 107.50240
Epoch 25, Val Loss: 105.29768
Epoch 26, Val Loss: 135.07312
Epoch 27, Val Loss: 106.41135
Epoch 28, Val Loss: 106.72505
Epoch 29, Val Loss: 102.52741
Epoch 30, Val Loss: 103.84116
Epoch 31, Val Loss: 105.44138
Epoch 32, Val Loss: 105.63284
Epoch 33, Val Loss: 109.71892
Epoch 34, Val Loss: 102.13755
Epoch 35, Val Loss: 105.88560
Epoch 36, Val Loss: 100.55392
Epoch 37, Val Loss: 100.66270
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 105.89776420015014, 'MSE - std': 0.0, 'R2 - mean': 0.382898499403752, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1310.04749
Epoch 1, Val Loss: 375.87131
Epoch 2, Val Loss: 147.95007
Epoch 3, Val Loss: 130.07520
Epoch 4, Val Loss: 119.55271
Epoch 5, Val Loss: 113.50292
Epoch 6, Val Loss: 103.37495
Epoch 7, Val Loss: 101.23602
Epoch 8, Val Loss: 91.82929
Epoch 9, Val Loss: 90.40701
Epoch 10, Val Loss: 88.29382
Epoch 11, Val Loss: 82.97108
Epoch 12, Val Loss: 87.02085
Epoch 13, Val Loss: 84.86449
Epoch 14, Val Loss: 86.10468
Epoch 15, Val Loss: 85.55576
Epoch 16, Val Loss: 81.16058
Epoch 17, Val Loss: 83.22401
Epoch 18, Val Loss: 80.15038
Epoch 19, Val Loss: 83.72570
Epoch 20, Val Loss: 82.38869
Epoch 21, Val Loss: 77.61886
Epoch 22, Val Loss: 79.90290
Epoch 23, Val Loss: 84.78295
Epoch 24, Val Loss: 77.59220
Epoch 25, Val Loss: 84.40751
Epoch 26, Val Loss: 93.89302
Epoch 27, Val Loss: 81.31705
Epoch 28, Val Loss: 78.54976
Epoch 29, Val Loss: 82.40357
Epoch 30, Val Loss: 75.44877
Epoch 31, Val Loss: 77.56590
Epoch 32, Val Loss: 77.77257
Epoch 33, Val Loss: 85.21199
Epoch 34, Val Loss: 89.87767
Epoch 35, Val Loss: 82.96330
Epoch 36, Val Loss: 95.66826
Epoch 37, Val Loss: 78.50109
Epoch 38, Val Loss: 75.22542
Epoch 39, Val Loss: 89.85482
Epoch 40, Val Loss: 87.37665
Epoch 41, Val Loss: 94.76379
Epoch 42, Val Loss: 82.53087
Epoch 43, Val Loss: 74.81869
Epoch 44, Val Loss: 105.69659
Epoch 45, Val Loss: 81.02319
Epoch 46, Val Loss: 75.41583
Epoch 47, Val Loss: 80.65620
Epoch 48, Val Loss: 79.02184
Epoch 49, Val Loss: 71.39481
Epoch 50, Val Loss: 84.24924
Epoch 51, Val Loss: 76.33717
Epoch 52, Val Loss: 76.88084
Epoch 53, Val Loss: 79.97272
Epoch 54, Val Loss: 80.11035
Epoch 55, Val Loss: 77.80273
Epoch 56, Val Loss: 81.68993
Epoch 57, Val Loss: 74.17752
Epoch 58, Val Loss: 88.99033
Epoch 59, Val Loss: 83.20618
Epoch 60, Val Loss: 82.11893
Epoch 61, Val Loss: 89.25754
Epoch 62, Val Loss: 71.20410
Epoch 63, Val Loss: 88.31524
Epoch 64, Val Loss: 85.24465
Epoch 65, Val Loss: 78.63436
Epoch 66, Val Loss: 79.49528
Epoch 67, Val Loss: 72.07787
Epoch 68, Val Loss: 72.31572
Epoch 69, Val Loss: 75.47654
Epoch 70, Val Loss: 76.89494
Epoch 71, Val Loss: 72.73537
Epoch 72, Val Loss: 71.04821
Epoch 73, Val Loss: 89.10918
Epoch 74, Val Loss: 68.01043
Epoch 75, Val Loss: 73.88877
Epoch 76, Val Loss: 74.52084
Epoch 77, Val Loss: 68.51196
Epoch 78, Val Loss: 67.49332
Epoch 79, Val Loss: 75.35682
Epoch 80, Val Loss: 73.11481
Epoch 81, Val Loss: 69.41748
Epoch 82, Val Loss: 75.11007
Epoch 83, Val Loss: 69.73713
Epoch 84, Val Loss: 73.01775
Epoch 85, Val Loss: 71.48142
Epoch 86, Val Loss: 74.68027
Epoch 87, Val Loss: 87.28526
Epoch 88, Val Loss: 72.21336
Epoch 89, Val Loss: 75.82919
Epoch 90, Val Loss: 71.45301
Epoch 91, Val Loss: 98.03912
Epoch 92, Val Loss: 75.33607
Epoch 93, Val Loss: 69.08849
Epoch 94, Val Loss: 76.05119
Epoch 95, Val Loss: 70.99154
Epoch 96, Val Loss: 74.21393
Epoch 97, Val Loss: 71.47383
Epoch 98, Val Loss: 74.97418
Epoch 99, Val Loss: 75.18867
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 89.96493640350434, 'MSE - std': 15.932827796645803, 'R2 - mean': 0.4552875421135258, 'R2 - std': 0.07238904270977381} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1222.84937
Epoch 1, Val Loss: 447.36588
Epoch 2, Val Loss: 139.12015
Epoch 3, Val Loss: 136.06364
Epoch 4, Val Loss: 122.31960
Epoch 5, Val Loss: 110.24293
Epoch 6, Val Loss: 85.36224
Epoch 7, Val Loss: 86.61034
Epoch 8, Val Loss: 83.39947
Epoch 9, Val Loss: 78.38816
Epoch 10, Val Loss: 80.83448
Epoch 11, Val Loss: 77.02477
Epoch 12, Val Loss: 78.07292
Epoch 13, Val Loss: 86.32572
Epoch 14, Val Loss: 92.34865
Epoch 15, Val Loss: 81.69349
Epoch 16, Val Loss: 76.16106
Epoch 17, Val Loss: 80.80251
Epoch 18, Val Loss: 81.72630
Epoch 19, Val Loss: 78.78349
Epoch 20, Val Loss: 86.63117
Epoch 21, Val Loss: 76.97863
Epoch 22, Val Loss: 93.97357
Epoch 23, Val Loss: 87.51677
Epoch 24, Val Loss: 90.08121
Epoch 25, Val Loss: 82.79764
Epoch 26, Val Loss: 84.88344
Epoch 27, Val Loss: 83.94862
Epoch 28, Val Loss: 90.09323
Epoch 29, Val Loss: 87.85734
Epoch 30, Val Loss: 87.23048
Epoch 31, Val Loss: 86.48292
Epoch 32, Val Loss: 85.23782
Epoch 33, Val Loss: 101.84643
Epoch 34, Val Loss: 86.79890
Epoch 35, Val Loss: 82.67075
Epoch 36, Val Loss: 95.07555
Epoch 37, Val Loss: 85.18638
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.20532131731107, 'MSE - std': 14.053685599314393, 'R2 - mean': 0.460572191178966, 'R2 - std': 0.059576035739616146} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 491.94696
Epoch 1, Val Loss: 381.43515
Epoch 2, Val Loss: 153.10080
Epoch 3, Val Loss: 140.18744
Epoch 4, Val Loss: 123.60660
Epoch 5, Val Loss: 117.08490
Epoch 6, Val Loss: 115.11818
Epoch 7, Val Loss: 109.77723
Epoch 8, Val Loss: 99.45517
Epoch 9, Val Loss: 100.08414
Epoch 10, Val Loss: 109.90186
Epoch 11, Val Loss: 94.05170
Epoch 12, Val Loss: 107.52149
Epoch 13, Val Loss: 99.11674
Epoch 14, Val Loss: 90.27079
Epoch 15, Val Loss: 93.14214
Epoch 16, Val Loss: 95.59097
Epoch 17, Val Loss: 95.41237
Epoch 18, Val Loss: 97.42923
Epoch 19, Val Loss: 93.20828
Epoch 20, Val Loss: 94.90928
Epoch 21, Val Loss: 91.44376
Epoch 22, Val Loss: 92.29402
Epoch 23, Val Loss: 92.70065
Epoch 24, Val Loss: 86.18809
Epoch 25, Val Loss: 91.27341
Epoch 26, Val Loss: 89.85025
Epoch 27, Val Loss: 93.39235
Epoch 28, Val Loss: 93.31762
Epoch 29, Val Loss: 98.06928
Epoch 30, Val Loss: 89.02849
Epoch 31, Val Loss: 95.39668
Epoch 32, Val Loss: 89.63620
Epoch 33, Val Loss: 84.21540
Epoch 34, Val Loss: 89.00243
Epoch 35, Val Loss: 94.25129
Epoch 36, Val Loss: 88.34591
Epoch 37, Val Loss: 86.45978
Epoch 38, Val Loss: 86.96693
Epoch 39, Val Loss: 96.75699
Epoch 40, Val Loss: 88.89671
Epoch 41, Val Loss: 84.34980
Epoch 42, Val Loss: 94.47152
Epoch 43, Val Loss: 82.99068
Epoch 44, Val Loss: 98.67450
Epoch 45, Val Loss: 81.94078
Epoch 46, Val Loss: 83.34023
Epoch 47, Val Loss: 107.54795
Epoch 48, Val Loss: 83.31766
Epoch 49, Val Loss: 84.02753
Epoch 50, Val Loss: 83.36145
Epoch 51, Val Loss: 83.29341
Epoch 52, Val Loss: 80.98179
Epoch 53, Val Loss: 79.83180
Epoch 54, Val Loss: 91.62959
Epoch 55, Val Loss: 81.13401
Epoch 56, Val Loss: 83.46114
Epoch 57, Val Loss: 80.21880
Epoch 58, Val Loss: 97.96758
Epoch 59, Val Loss: 90.60021
Epoch 60, Val Loss: 84.33459
Epoch 61, Val Loss: 81.20676
Epoch 62, Val Loss: 78.65907
Epoch 63, Val Loss: 81.84707
Epoch 64, Val Loss: 79.88319
Epoch 65, Val Loss: 76.73673
Epoch 66, Val Loss: 82.97262
Epoch 67, Val Loss: 78.45758
Epoch 68, Val Loss: 80.05394
Epoch 69, Val Loss: 79.92024
Epoch 70, Val Loss: 90.42191
Epoch 71, Val Loss: 80.72816
Epoch 72, Val Loss: 87.96305
Epoch 73, Val Loss: 81.57561
Epoch 74, Val Loss: 80.37379
Epoch 75, Val Loss: 78.14925
Epoch 76, Val Loss: 82.57447
Epoch 77, Val Loss: 81.15893
Epoch 78, Val Loss: 82.14729
Epoch 79, Val Loss: 75.26833
Epoch 80, Val Loss: 78.57673
Epoch 81, Val Loss: 81.65672
Epoch 82, Val Loss: 80.57590
Epoch 83, Val Loss: 81.19118
Epoch 84, Val Loss: 76.65036
Epoch 85, Val Loss: 78.57271
Epoch 86, Val Loss: 95.14507
Epoch 87, Val Loss: 80.01359
Epoch 88, Val Loss: 78.41390
Epoch 89, Val Loss: 81.99461
Epoch 90, Val Loss: 78.84298
Epoch 91, Val Loss: 77.63725
Epoch 92, Val Loss: 77.89462
Epoch 93, Val Loss: 79.14651
Epoch 94, Val Loss: 85.90263
Epoch 95, Val Loss: 77.20514
Epoch 96, Val Loss: 79.88605
Epoch 97, Val Loss: 76.85226
Epoch 98, Val Loss: 83.30900
Epoch 99, Val Loss: 78.59868
DID NOT SAVE RESULTS
{'MSE - mean': 85.98676457078736, 'MSE - std': 12.176734387660577, 'R2 - mean': 0.46758850141580066, 'R2 - std': 0.05300626240223461} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 631.54352
Epoch 1, Val Loss: 351.80634
Epoch 2, Val Loss: 156.70575
Epoch 3, Val Loss: 130.39316
Epoch 4, Val Loss: 133.50104
Epoch 5, Val Loss: 114.21805
Epoch 6, Val Loss: 111.23213
Epoch 7, Val Loss: 102.36581
Epoch 8, Val Loss: 111.47154
Epoch 9, Val Loss: 112.31015
Epoch 10, Val Loss: 104.11087
Epoch 11, Val Loss: 89.18388
Epoch 12, Val Loss: 97.85899
Epoch 13, Val Loss: 102.40806
Epoch 14, Val Loss: 92.65563
Epoch 15, Val Loss: 102.24011
Epoch 16, Val Loss: 100.21784
Epoch 17, Val Loss: 109.46161
Epoch 18, Val Loss: 92.92153
Epoch 19, Val Loss: 88.73084
Epoch 20, Val Loss: 106.49716
Epoch 21, Val Loss: 92.41286
Epoch 22, Val Loss: 91.81437
Epoch 23, Val Loss: 105.03822
Epoch 24, Val Loss: 94.12702
Epoch 25, Val Loss: 89.95863
Epoch 26, Val Loss: 96.24117
Epoch 27, Val Loss: 89.55362
Epoch 28, Val Loss: 97.63230
Epoch 29, Val Loss: 94.14305
Epoch 30, Val Loss: 93.77706
Epoch 31, Val Loss: 102.34934
Epoch 32, Val Loss: 96.38835
Epoch 33, Val Loss: 90.38591
Epoch 34, Val Loss: 87.21236
Epoch 35, Val Loss: 91.69780
Epoch 36, Val Loss: 104.29275
Epoch 37, Val Loss: 82.85017
Epoch 38, Val Loss: 82.89750
Epoch 39, Val Loss: 81.13384
Epoch 40, Val Loss: 93.59850
Epoch 41, Val Loss: 98.34586
Epoch 42, Val Loss: 104.93290
Epoch 43, Val Loss: 98.40865
Epoch 44, Val Loss: 87.47507
Epoch 45, Val Loss: 91.67916
Epoch 46, Val Loss: 85.56837
Epoch 47, Val Loss: 86.74825
Epoch 48, Val Loss: 87.58520
Epoch 49, Val Loss: 87.66365
Epoch 50, Val Loss: 91.34712
Epoch 51, Val Loss: 76.27437
Epoch 52, Val Loss: 80.40083
Epoch 53, Val Loss: 84.01908
Epoch 54, Val Loss: 86.57393
Epoch 55, Val Loss: 80.63605
Epoch 56, Val Loss: 86.16318
Epoch 57, Val Loss: 93.82604
Epoch 58, Val Loss: 80.32035
Epoch 59, Val Loss: 83.43345
Epoch 60, Val Loss: 94.16559
Epoch 61, Val Loss: 79.93557
Epoch 62, Val Loss: 83.54372
Epoch 63, Val Loss: 75.80532
Epoch 64, Val Loss: 77.47260
Epoch 65, Val Loss: 79.59393
Epoch 66, Val Loss: 82.06979
Epoch 67, Val Loss: 82.67934
Epoch 68, Val Loss: 80.19055
Epoch 69, Val Loss: 76.93411
Epoch 70, Val Loss: 76.32836
Epoch 71, Val Loss: 80.47379
Epoch 72, Val Loss: 82.74698
Epoch 73, Val Loss: 84.78975
Epoch 74, Val Loss: 81.56728
Epoch 75, Val Loss: 79.20853
Epoch 76, Val Loss: 85.32899
Epoch 77, Val Loss: 76.64862
Epoch 78, Val Loss: 77.50980
Epoch 79, Val Loss: 75.97784
Epoch 80, Val Loss: 79.87707
Epoch 81, Val Loss: 78.49490
Epoch 82, Val Loss: 79.00278
Epoch 83, Val Loss: 81.65209
Epoch 84, Val Loss: 85.18668
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.1968302093529, 'MSE - std': 11.46445586807693, 'R2 - mean': 0.4774428636703396, 'R2 - std': 0.051343596532171056} 
 

Results After CV: {'MSE - mean': 84.1968302093529, 'MSE - std': 11.46445586807693, 'R2 - mean': 0.4774428636703396, 'R2 - std': 0.051343596532171056}
Train time: 1995.0780445207988
Inference time: 0.18610303800087422
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 39 finished with value: 84.1968302093529 and parameters: {'p_m': 0.21273976404130723, 'alpha': 4.543506468710788, 'K': 15, 'beta': 5.029584470484685}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 659.63269
Epoch 1, Val Loss: 417.36221
Epoch 2, Val Loss: 258.61368
Epoch 3, Val Loss: 174.66016
Epoch 4, Val Loss: 178.51830
Epoch 5, Val Loss: 189.01254
Epoch 6, Val Loss: 137.87868
Epoch 7, Val Loss: 126.89788
Epoch 8, Val Loss: 120.30317
Epoch 9, Val Loss: 121.89146
Epoch 10, Val Loss: 126.03381
Epoch 11, Val Loss: 121.96526
Epoch 12, Val Loss: 106.50192
Epoch 13, Val Loss: 122.09721
Epoch 14, Val Loss: 110.84946
Epoch 15, Val Loss: 115.89374
Epoch 16, Val Loss: 102.17284
Epoch 17, Val Loss: 116.87680
Epoch 18, Val Loss: 103.89233
Epoch 19, Val Loss: 100.42778
Epoch 20, Val Loss: 97.32404
Epoch 21, Val Loss: 103.21573
Epoch 22, Val Loss: 94.44365
Epoch 23, Val Loss: 103.88994
Epoch 24, Val Loss: 97.47855
Epoch 25, Val Loss: 109.88253
Epoch 26, Val Loss: 92.80064
Epoch 27, Val Loss: 92.94671
Epoch 28, Val Loss: 93.12133
Epoch 29, Val Loss: 93.81782
Epoch 30, Val Loss: 93.22809
Epoch 31, Val Loss: 89.07758
Epoch 32, Val Loss: 89.42261
Epoch 33, Val Loss: 86.61932
Epoch 34, Val Loss: 89.05649
Epoch 35, Val Loss: 88.27521
Epoch 36, Val Loss: 90.72987
Epoch 37, Val Loss: 92.24400
Epoch 38, Val Loss: 111.21643
Epoch 39, Val Loss: 96.31067
Epoch 40, Val Loss: 91.02998
Epoch 41, Val Loss: 91.25706
Epoch 42, Val Loss: 92.45828
Epoch 43, Val Loss: 90.50069
Epoch 44, Val Loss: 90.14027
Epoch 45, Val Loss: 90.08778
Epoch 46, Val Loss: 90.20477
Epoch 47, Val Loss: 86.73924
Epoch 48, Val Loss: 89.96482
Epoch 49, Val Loss: 88.62751
Epoch 50, Val Loss: 88.73183
Epoch 51, Val Loss: 83.61581
Epoch 52, Val Loss: 86.93383
Epoch 53, Val Loss: 83.95710
Epoch 54, Val Loss: 94.51299
Epoch 55, Val Loss: 84.51573
Epoch 56, Val Loss: 87.52685
Epoch 57, Val Loss: 90.01422
Epoch 58, Val Loss: 87.84631
Epoch 59, Val Loss: 112.65418
Epoch 60, Val Loss: 100.13206
Epoch 61, Val Loss: 86.38036
Epoch 62, Val Loss: 101.45016
Epoch 63, Val Loss: 87.20393
Epoch 64, Val Loss: 90.62155
Epoch 65, Val Loss: 99.16666
Epoch 66, Val Loss: 88.26213
Epoch 67, Val Loss: 85.85468
Epoch 68, Val Loss: 86.80288
Epoch 69, Val Loss: 89.17093
Epoch 70, Val Loss: 89.12132
Epoch 71, Val Loss: 82.88065
Epoch 72, Val Loss: 92.00638
Epoch 73, Val Loss: 90.69389
Epoch 74, Val Loss: 87.70258
Epoch 75, Val Loss: 93.93761
Epoch 76, Val Loss: 92.98138
Epoch 77, Val Loss: 93.07021
Epoch 78, Val Loss: 87.72235
Epoch 79, Val Loss: 87.81696
Epoch 80, Val Loss: 89.25454
Epoch 81, Val Loss: 87.84933
Epoch 82, Val Loss: 88.00165
Epoch 83, Val Loss: 89.70884
Epoch 84, Val Loss: 95.85684
Epoch 85, Val Loss: 91.79591
Epoch 86, Val Loss: 87.22478
Epoch 87, Val Loss: 93.30865
Epoch 88, Val Loss: 87.16295
Epoch 89, Val Loss: 89.19748
Epoch 90, Val Loss: 89.14848
Epoch 91, Val Loss: 88.34125
Epoch 92, Val Loss: 90.85332
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.12240204542606, 'MSE - std': 0.0, 'R2 - mean': 0.4864814479406997, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 395.00000
Epoch 1, Val Loss: 374.09000
Epoch 2, Val Loss: 197.57535
Epoch 3, Val Loss: 171.57118
Epoch 4, Val Loss: 138.99406
Epoch 5, Val Loss: 131.81897
Epoch 6, Val Loss: 129.99326
Epoch 7, Val Loss: 106.32465
Epoch 8, Val Loss: 107.05624
Epoch 9, Val Loss: 109.40971
Epoch 10, Val Loss: 94.48823
Epoch 11, Val Loss: 90.80785
Epoch 12, Val Loss: 91.56743
Epoch 13, Val Loss: 96.25117
Epoch 14, Val Loss: 92.48702
Epoch 15, Val Loss: 104.53214
Epoch 16, Val Loss: 91.08631
Epoch 17, Val Loss: 82.74300
Epoch 18, Val Loss: 81.21655
Epoch 19, Val Loss: 80.11375
Epoch 20, Val Loss: 82.76915
Epoch 21, Val Loss: 80.58234
Epoch 22, Val Loss: 78.55462
Epoch 23, Val Loss: 80.43177
Epoch 24, Val Loss: 78.14577
Epoch 25, Val Loss: 80.94833
Epoch 26, Val Loss: 82.77268
Epoch 27, Val Loss: 91.23748
Epoch 28, Val Loss: 86.98257
Epoch 29, Val Loss: 75.79771
Epoch 30, Val Loss: 78.21281
Epoch 31, Val Loss: 76.44816
Epoch 32, Val Loss: 71.04574
Epoch 33, Val Loss: 83.23438
Epoch 34, Val Loss: 74.76041
Epoch 35, Val Loss: 77.13017
Epoch 36, Val Loss: 76.24106
Epoch 37, Val Loss: 77.30801
Epoch 38, Val Loss: 78.42732
Epoch 39, Val Loss: 74.41351
Epoch 40, Val Loss: 75.67152
Epoch 41, Val Loss: 75.31084
Epoch 42, Val Loss: 73.08164
Epoch 43, Val Loss: 80.08583
Epoch 44, Val Loss: 73.28513
Epoch 45, Val Loss: 75.38625
Epoch 46, Val Loss: 77.32728
Epoch 47, Val Loss: 76.46400
Epoch 48, Val Loss: 76.96142
Epoch 49, Val Loss: 78.31710
Epoch 50, Val Loss: 73.31274
Epoch 51, Val Loss: 75.72865
Epoch 52, Val Loss: 86.70848
Epoch 53, Val Loss: 74.07952
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.97149667522777, 'MSE - std': 4.150905370198281, 'R2 - mean': 0.488613812782233, 'R2 - std': 0.002132364841533285} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1293.97046
Epoch 1, Val Loss: 481.69983
Epoch 2, Val Loss: 176.17465
Epoch 3, Val Loss: 146.23631
Epoch 4, Val Loss: 132.50620
Epoch 5, Val Loss: 119.28355
Epoch 6, Val Loss: 110.46143
Epoch 7, Val Loss: 102.70433
Epoch 8, Val Loss: 109.36564
Epoch 9, Val Loss: 120.09843
Epoch 10, Val Loss: 91.25050
Epoch 11, Val Loss: 102.04300
Epoch 12, Val Loss: 96.09998
Epoch 13, Val Loss: 105.71419
Epoch 14, Val Loss: 87.40499
Epoch 15, Val Loss: 81.62469
Epoch 16, Val Loss: 92.10919
Epoch 17, Val Loss: 87.89482
Epoch 18, Val Loss: 84.87221
Epoch 19, Val Loss: 81.40980
Epoch 20, Val Loss: 82.18180
Epoch 21, Val Loss: 81.60250
Epoch 22, Val Loss: 93.78760
Epoch 23, Val Loss: 80.08742
Epoch 24, Val Loss: 82.83665
Epoch 25, Val Loss: 76.09408
Epoch 26, Val Loss: 77.41506
Epoch 27, Val Loss: 75.29707
Epoch 28, Val Loss: 76.10609
Epoch 29, Val Loss: 87.24189
Epoch 30, Val Loss: 75.06445
Epoch 31, Val Loss: 92.39621
Epoch 32, Val Loss: 75.81299
Epoch 33, Val Loss: 75.17826
Epoch 34, Val Loss: 80.94781
Epoch 35, Val Loss: 75.07062
Epoch 36, Val Loss: 75.05778
Epoch 37, Val Loss: 73.76997
Epoch 38, Val Loss: 75.40257
Epoch 39, Val Loss: 73.65274
Epoch 40, Val Loss: 73.79237
Epoch 41, Val Loss: 75.30957
Epoch 42, Val Loss: 73.48355
Epoch 43, Val Loss: 74.27016
Epoch 44, Val Loss: 71.58666
Epoch 45, Val Loss: 77.08272
Epoch 46, Val Loss: 73.71059
Epoch 47, Val Loss: 69.80307
Epoch 48, Val Loss: 72.39104
Epoch 49, Val Loss: 73.15826
Epoch 50, Val Loss: 70.89309
Epoch 51, Val Loss: 80.28869
Epoch 52, Val Loss: 73.77260
Epoch 53, Val Loss: 72.29994
Epoch 54, Val Loss: 69.45068
Epoch 55, Val Loss: 77.49817
Epoch 56, Val Loss: 77.04436
Epoch 57, Val Loss: 73.84043
Epoch 58, Val Loss: 101.03573
Epoch 59, Val Loss: 71.92468
Epoch 60, Val Loss: 74.25787
Epoch 61, Val Loss: 72.67030
Epoch 62, Val Loss: 73.09275
Epoch 63, Val Loss: 74.20242
Epoch 64, Val Loss: 70.97662
Epoch 65, Val Loss: 74.32555
Epoch 66, Val Loss: 70.89344
Epoch 67, Val Loss: 77.37053
Epoch 68, Val Loss: 72.08849
Epoch 69, Val Loss: 69.31302
Epoch 70, Val Loss: 71.60048
Epoch 71, Val Loss: 74.13485
Epoch 72, Val Loss: 74.38024
Epoch 73, Val Loss: 75.99277
Epoch 74, Val Loss: 71.96981
Epoch 75, Val Loss: 72.13963
Epoch 76, Val Loss: 72.18298
Epoch 77, Val Loss: 74.05349
Epoch 78, Val Loss: 75.59222
Epoch 79, Val Loss: 74.60612
Epoch 80, Val Loss: 77.52489
Epoch 81, Val Loss: 72.32485
Epoch 82, Val Loss: 71.10573
Epoch 83, Val Loss: 78.72141
Epoch 84, Val Loss: 75.86295
Epoch 85, Val Loss: 78.40311
Epoch 86, Val Loss: 78.30219
Epoch 87, Val Loss: 75.35358
Epoch 88, Val Loss: 75.15628
Epoch 89, Val Loss: 72.86615
Epoch 90, Val Loss: 85.64126
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.40763087260547, 'MSE - std': 7.290021883157682, 'R2 - mean': 0.5016227077258398, 'R2 - std': 0.018479556682611937} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 930.24310
Epoch 1, Val Loss: 417.89639
Epoch 2, Val Loss: 208.49683
Epoch 3, Val Loss: 169.93999
Epoch 4, Val Loss: 164.29155
Epoch 5, Val Loss: 142.40384
Epoch 6, Val Loss: 123.06509
Epoch 7, Val Loss: 124.34124
Epoch 8, Val Loss: 121.48571
Epoch 9, Val Loss: 110.52728
Epoch 10, Val Loss: 99.03545
Epoch 11, Val Loss: 99.22122
Epoch 12, Val Loss: 102.30274
Epoch 13, Val Loss: 93.80270
Epoch 14, Val Loss: 96.63214
Epoch 15, Val Loss: 100.40179
Epoch 16, Val Loss: 97.30672
Epoch 17, Val Loss: 90.83599
Epoch 18, Val Loss: 90.15948
Epoch 19, Val Loss: 92.44543
Epoch 20, Val Loss: 97.32201
Epoch 21, Val Loss: 84.49333
Epoch 22, Val Loss: 87.60131
Epoch 23, Val Loss: 85.14144
Epoch 24, Val Loss: 82.14608
Epoch 25, Val Loss: 87.43665
Epoch 26, Val Loss: 83.48686
Epoch 27, Val Loss: 91.11918
Epoch 28, Val Loss: 88.46189
Epoch 29, Val Loss: 80.39689
Epoch 30, Val Loss: 97.31553
Epoch 31, Val Loss: 83.98125
Epoch 32, Val Loss: 86.77936
Epoch 33, Val Loss: 84.07635
Epoch 34, Val Loss: 80.45545
Epoch 35, Val Loss: 85.14056
Epoch 36, Val Loss: 80.26292
Epoch 37, Val Loss: 81.19982
Epoch 38, Val Loss: 79.80103
Epoch 39, Val Loss: 84.87090
Epoch 40, Val Loss: 85.15279
Epoch 41, Val Loss: 82.57344
Epoch 42, Val Loss: 85.09967
Epoch 43, Val Loss: 82.46509
Epoch 44, Val Loss: 83.94186
Epoch 45, Val Loss: 79.88732
Epoch 46, Val Loss: 83.81355
Epoch 47, Val Loss: 81.82484
Epoch 48, Val Loss: 86.37517
Epoch 49, Val Loss: 82.68719
Epoch 50, Val Loss: 82.52576
Epoch 51, Val Loss: 81.48175
Epoch 52, Val Loss: 80.61459
Epoch 53, Val Loss: 80.89477
Epoch 54, Val Loss: 80.74585
Epoch 55, Val Loss: 84.91322
Epoch 56, Val Loss: 88.45395
Epoch 57, Val Loss: 80.83154
Epoch 58, Val Loss: 80.20446
Epoch 59, Val Loss: 78.10656
Epoch 60, Val Loss: 90.97456
Epoch 61, Val Loss: 85.98573
Epoch 62, Val Loss: 81.35461
Epoch 63, Val Loss: 79.46378
Epoch 64, Val Loss: 80.66327
Epoch 65, Val Loss: 79.85121
Epoch 66, Val Loss: 83.12222
Epoch 67, Val Loss: 107.36373
Epoch 68, Val Loss: 84.99141
Epoch 69, Val Loss: 82.72188
Epoch 70, Val Loss: 86.89269
Epoch 71, Val Loss: 90.18069
Epoch 72, Val Loss: 79.07401
Epoch 73, Val Loss: 80.73725
Epoch 74, Val Loss: 81.73107
Epoch 75, Val Loss: 80.65357
Epoch 76, Val Loss: 82.55868
Epoch 77, Val Loss: 81.63255
Epoch 78, Val Loss: 99.93895
Epoch 79, Val Loss: 81.27674
Epoch 80, Val Loss: 81.05058
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.82466976410602, 'MSE - std': 7.575258761373574, 'R2 - mean': 0.49276619658905796, 'R2 - std': 0.022168308007992486} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1318.17590
Epoch 1, Val Loss: 449.45233
Epoch 2, Val Loss: 186.76251
Epoch 3, Val Loss: 177.20016
Epoch 4, Val Loss: 171.60051
Epoch 5, Val Loss: 158.89371
Epoch 6, Val Loss: 151.18509
Epoch 7, Val Loss: 133.12030
Epoch 8, Val Loss: 162.80519
Epoch 9, Val Loss: 119.82220
Epoch 10, Val Loss: 128.03027
Epoch 11, Val Loss: 116.07784
Epoch 12, Val Loss: 108.09421
Epoch 13, Val Loss: 112.15221
Epoch 14, Val Loss: 109.35251
Epoch 15, Val Loss: 116.83241
Epoch 16, Val Loss: 104.35313
Epoch 17, Val Loss: 95.99825
Epoch 18, Val Loss: 112.17278
Epoch 19, Val Loss: 100.05896
Epoch 20, Val Loss: 97.06944
Epoch 21, Val Loss: 81.90381
Epoch 22, Val Loss: 91.42013
Epoch 23, Val Loss: 88.54914
Epoch 24, Val Loss: 99.20887
Epoch 25, Val Loss: 84.81345
Epoch 26, Val Loss: 87.03307
Epoch 27, Val Loss: 94.96623
Epoch 28, Val Loss: 84.60718
Epoch 29, Val Loss: 100.10391
Epoch 30, Val Loss: 85.99525
Epoch 31, Val Loss: 84.49167
Epoch 32, Val Loss: 83.31834
Epoch 33, Val Loss: 84.28986
Epoch 34, Val Loss: 81.96717
Epoch 35, Val Loss: 80.53178
Epoch 36, Val Loss: 91.92556
Epoch 37, Val Loss: 83.89624
Epoch 38, Val Loss: 81.89392
Epoch 39, Val Loss: 82.48112
Epoch 40, Val Loss: 86.64426
Epoch 41, Val Loss: 82.05321
Epoch 42, Val Loss: 74.88667
Epoch 43, Val Loss: 79.63972
Epoch 44, Val Loss: 83.77600
Epoch 45, Val Loss: 85.94992
Epoch 46, Val Loss: 85.43154
Epoch 47, Val Loss: 81.73341
Epoch 48, Val Loss: 89.82689
Epoch 49, Val Loss: 85.94482
Epoch 50, Val Loss: 84.42419
Epoch 51, Val Loss: 80.22552
Epoch 52, Val Loss: 79.50816
Epoch 53, Val Loss: 84.15536
Epoch 54, Val Loss: 78.66142
Epoch 55, Val Loss: 81.86699
Epoch 56, Val Loss: 79.14557
Epoch 57, Val Loss: 78.06772
Epoch 58, Val Loss: 86.35437
Epoch 59, Val Loss: 80.86906
Epoch 60, Val Loss: 80.51501
Epoch 61, Val Loss: 89.51894
Epoch 62, Val Loss: 82.47952
Epoch 63, Val Loss: 81.42493
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.80451769619476, 'MSE - std': 7.076049548163733, 'R2 - mean': 0.49797784693956293, 'R2 - std': 0.022400721002982356} 
 

Results After CV: {'MSE - mean': 80.80451769619476, 'MSE - std': 7.076049548163733, 'R2 - mean': 0.49797784693956293, 'R2 - std': 0.022400721002982356}
Train time: 2833.1658417170024
Inference time: 0.18490311679488514
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 40 finished with value: 80.80451769619476 and parameters: {'p_m': 0.4751289663532814, 'alpha': 7.938438948498697, 'K': 20, 'beta': 6.342768141720459}. Best is trial 25 with value: 77.85177176700307.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1174.80591
Epoch 1, Val Loss: 422.47797
Epoch 2, Val Loss: 171.80676
Epoch 3, Val Loss: 150.00980
Epoch 4, Val Loss: 136.45007
Epoch 5, Val Loss: 119.59669
Epoch 6, Val Loss: 118.98228
Epoch 7, Val Loss: 121.69865
Epoch 8, Val Loss: 110.17375
Epoch 9, Val Loss: 105.62321
Epoch 10, Val Loss: 106.52357
Epoch 11, Val Loss: 109.31313
Epoch 12, Val Loss: 127.98996
Epoch 13, Val Loss: 104.05573
Epoch 14, Val Loss: 101.56795
Epoch 15, Val Loss: 103.79198
Epoch 16, Val Loss: 122.42513
Epoch 17, Val Loss: 101.88744
Epoch 18, Val Loss: 117.16805
Epoch 19, Val Loss: 113.23567
Epoch 20, Val Loss: 95.32409
Epoch 21, Val Loss: 105.38530
Epoch 22, Val Loss: 103.14561
Epoch 23, Val Loss: 113.82397
Epoch 24, Val Loss: 107.30353
Epoch 25, Val Loss: 99.31633
Epoch 26, Val Loss: 110.64140
Epoch 27, Val Loss: 108.32719
Epoch 28, Val Loss: 103.19101
Epoch 29, Val Loss: 115.39681
Epoch 30, Val Loss: 99.63026
Epoch 31, Val Loss: 97.39563
Epoch 32, Val Loss: 98.61119
Epoch 33, Val Loss: 107.95283
Epoch 34, Val Loss: 103.58109
Epoch 35, Val Loss: 95.10984
Epoch 36, Val Loss: 101.17136
Epoch 37, Val Loss: 123.71216
Epoch 38, Val Loss: 105.63719
Epoch 39, Val Loss: 95.39537
Epoch 40, Val Loss: 96.54173
Epoch 41, Val Loss: 98.47697
Epoch 42, Val Loss: 112.30771
Epoch 43, Val Loss: 95.70049
Epoch 44, Val Loss: 92.88731
Epoch 45, Val Loss: 106.59737
Epoch 46, Val Loss: 93.14407
Epoch 47, Val Loss: 94.84676
Epoch 48, Val Loss: 88.16470
Epoch 49, Val Loss: 93.04855
Epoch 50, Val Loss: 97.02642
Epoch 51, Val Loss: 92.37018
Epoch 52, Val Loss: 91.78935
Epoch 53, Val Loss: 92.03938
Epoch 54, Val Loss: 91.67043
Epoch 55, Val Loss: 94.05717
Epoch 56, Val Loss: 94.46087
Epoch 57, Val Loss: 90.25781
Epoch 58, Val Loss: 86.72822
Epoch 59, Val Loss: 82.79772
Epoch 60, Val Loss: 84.10613
Epoch 61, Val Loss: 86.63148
Epoch 62, Val Loss: 97.35003
Epoch 63, Val Loss: 88.11965
Epoch 64, Val Loss: 88.93454
Epoch 65, Val Loss: 85.51494
Epoch 66, Val Loss: 87.41852
Epoch 67, Val Loss: 86.21590
Epoch 68, Val Loss: 95.93847
Epoch 69, Val Loss: 88.03375
Epoch 70, Val Loss: 83.19398
Epoch 71, Val Loss: 88.35497
Epoch 72, Val Loss: 81.12791
Epoch 73, Val Loss: 108.74084
Epoch 74, Val Loss: 83.14799
Epoch 75, Val Loss: 86.00543
Epoch 76, Val Loss: 89.66222
Epoch 77, Val Loss: 81.47965
Epoch 78, Val Loss: 95.63026
Epoch 79, Val Loss: 88.64373
Epoch 80, Val Loss: 83.49649
Epoch 81, Val Loss: 88.71410
Epoch 82, Val Loss: 97.50305
Epoch 83, Val Loss: 83.10220
Epoch 84, Val Loss: 88.25732
Epoch 85, Val Loss: 84.32277
Epoch 86, Val Loss: 94.82652
Epoch 87, Val Loss: 82.16792
Epoch 88, Val Loss: 83.24786
Epoch 89, Val Loss: 79.73933
Epoch 90, Val Loss: 85.80264
Epoch 91, Val Loss: 88.20265
Epoch 92, Val Loss: 85.02103
Epoch 93, Val Loss: 82.11665
Epoch 94, Val Loss: 85.00372
Epoch 95, Val Loss: 78.31435
Epoch 96, Val Loss: 90.15299
Epoch 97, Val Loss: 81.25172
Epoch 98, Val Loss: 83.91991
Epoch 99, Val Loss: 85.00224
DID NOT SAVE RESULTS
{'MSE - mean': 82.7351354095907, 'MSE - std': 0.0, 'R2 - mean': 0.5178748427889867, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 627.30322
Epoch 1, Val Loss: 353.22571
Epoch 2, Val Loss: 150.87477
Epoch 3, Val Loss: 127.19323
Epoch 4, Val Loss: 109.14559
Epoch 5, Val Loss: 123.04387
Epoch 6, Val Loss: 104.48546
Epoch 7, Val Loss: 94.76508
Epoch 8, Val Loss: 88.39336
Epoch 9, Val Loss: 89.60497
Epoch 10, Val Loss: 89.60636
Epoch 11, Val Loss: 82.09314
Epoch 12, Val Loss: 85.44341
Epoch 13, Val Loss: 89.98098
Epoch 14, Val Loss: 97.11684
Epoch 15, Val Loss: 93.10085
Epoch 16, Val Loss: 83.60599
Epoch 17, Val Loss: 83.11008
Epoch 18, Val Loss: 88.86931
Epoch 19, Val Loss: 82.40099
Epoch 20, Val Loss: 100.48360
Epoch 21, Val Loss: 77.65411
Epoch 22, Val Loss: 83.92356
Epoch 23, Val Loss: 88.51750
Epoch 24, Val Loss: 84.56184
Epoch 25, Val Loss: 82.09741
Epoch 26, Val Loss: 94.02357
Epoch 27, Val Loss: 76.71523
Epoch 28, Val Loss: 77.14543
Epoch 29, Val Loss: 88.83635
Epoch 30, Val Loss: 85.68427
Epoch 31, Val Loss: 81.96985
Epoch 32, Val Loss: 79.43877
Epoch 33, Val Loss: 79.85234
Epoch 34, Val Loss: 78.48058
Epoch 35, Val Loss: 84.37977
Epoch 36, Val Loss: 81.31984
Epoch 37, Val Loss: 76.03955
Epoch 38, Val Loss: 81.03759
Epoch 39, Val Loss: 82.23769
Epoch 40, Val Loss: 78.15225
Epoch 41, Val Loss: 74.26702
Epoch 42, Val Loss: 84.37115
Epoch 43, Val Loss: 79.43298
Epoch 44, Val Loss: 86.78446
Epoch 45, Val Loss: 72.77534
Epoch 46, Val Loss: 89.40359
Epoch 47, Val Loss: 76.49006
Epoch 48, Val Loss: 80.69759
Epoch 49, Val Loss: 87.13188
Epoch 50, Val Loss: 74.20552
Epoch 51, Val Loss: 80.84389
Epoch 52, Val Loss: 83.28478
Epoch 53, Val Loss: 75.68349
Epoch 54, Val Loss: 88.22426
Epoch 55, Val Loss: 74.90392
Epoch 56, Val Loss: 69.64086
Epoch 57, Val Loss: 81.33725
Epoch 58, Val Loss: 72.77793
Epoch 59, Val Loss: 71.19951
Epoch 60, Val Loss: 76.22588
Epoch 61, Val Loss: 104.16574
Epoch 62, Val Loss: 73.46468
Epoch 63, Val Loss: 75.92591
Epoch 64, Val Loss: 70.58605
Epoch 65, Val Loss: 79.22727
Epoch 66, Val Loss: 72.26452
Epoch 67, Val Loss: 74.51478
Epoch 68, Val Loss: 75.47056
Epoch 69, Val Loss: 74.82923
Epoch 70, Val Loss: 91.93160
Epoch 71, Val Loss: 73.02099
Epoch 72, Val Loss: 72.38763
Epoch 73, Val Loss: 73.55898
Epoch 74, Val Loss: 72.85974
Epoch 75, Val Loss: 75.78181
Epoch 76, Val Loss: 73.46998
Epoch 77, Val Loss: 71.64717
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.64432764722264, 'MSE - std': 2.0908077623680654, 'R2 - mean': 0.5083524557332013, 'R2 - std': 0.009522387055785286} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 782.19586
Epoch 1, Val Loss: 406.14191
Epoch 2, Val Loss: 156.76447
Epoch 3, Val Loss: 108.63006
Epoch 4, Val Loss: 99.18981
Epoch 5, Val Loss: 109.03097
Epoch 6, Val Loss: 99.18788
Epoch 7, Val Loss: 87.69693
Epoch 8, Val Loss: 93.01869
Epoch 9, Val Loss: 81.94303
Epoch 10, Val Loss: 78.88824
Epoch 11, Val Loss: 82.45123
Epoch 12, Val Loss: 78.95176
Epoch 13, Val Loss: 81.62979
Epoch 14, Val Loss: 79.56850
Epoch 15, Val Loss: 89.86211
Epoch 16, Val Loss: 80.16781
Epoch 17, Val Loss: 81.52676
Epoch 18, Val Loss: 80.93037
Epoch 19, Val Loss: 79.23896
Epoch 20, Val Loss: 79.49511
Epoch 21, Val Loss: 81.75462
Epoch 22, Val Loss: 79.53876
Epoch 23, Val Loss: 80.19287
Epoch 24, Val Loss: 82.21263
Epoch 25, Val Loss: 92.42619
Epoch 26, Val Loss: 81.85476
Epoch 27, Val Loss: 77.81580
Epoch 28, Val Loss: 86.56976
Epoch 29, Val Loss: 87.09680
Epoch 30, Val Loss: 76.74252
Epoch 31, Val Loss: 73.58382
Epoch 32, Val Loss: 76.06878
Epoch 33, Val Loss: 84.13319
Epoch 34, Val Loss: 79.25079
Epoch 35, Val Loss: 74.98680
Epoch 36, Val Loss: 77.15002
Epoch 37, Val Loss: 85.05980
Epoch 38, Val Loss: 102.01843
Epoch 39, Val Loss: 77.41568
Epoch 40, Val Loss: 75.17176
Epoch 41, Val Loss: 76.21996
Epoch 42, Val Loss: 83.56836
Epoch 43, Val Loss: 81.68179
Epoch 44, Val Loss: 77.88383
Epoch 45, Val Loss: 77.05059
Epoch 46, Val Loss: 74.75511
Epoch 47, Val Loss: 72.99783
Epoch 48, Val Loss: 75.42577
Epoch 49, Val Loss: 72.42206
Epoch 50, Val Loss: 70.68134
Epoch 51, Val Loss: 73.04116
Epoch 52, Val Loss: 84.29011
Epoch 53, Val Loss: 71.70806
Epoch 54, Val Loss: 69.63442
Epoch 55, Val Loss: 70.29057
Epoch 56, Val Loss: 78.53708
Epoch 57, Val Loss: 71.90135
Epoch 58, Val Loss: 72.50607
Epoch 59, Val Loss: 69.02347
Epoch 60, Val Loss: 72.61897
Epoch 61, Val Loss: 73.83774
Epoch 62, Val Loss: 73.50195
Epoch 63, Val Loss: 68.09813
Epoch 64, Val Loss: 72.37117
Epoch 65, Val Loss: 72.17789
Epoch 66, Val Loss: 75.51559
Epoch 67, Val Loss: 76.31090
Epoch 68, Val Loss: 75.53264
Epoch 69, Val Loss: 67.22324
Epoch 70, Val Loss: 71.40465
Epoch 71, Val Loss: 67.47314
Epoch 72, Val Loss: 68.24100
Epoch 73, Val Loss: 69.18423
Epoch 74, Val Loss: 67.65649
Epoch 75, Val Loss: 66.23921
Epoch 76, Val Loss: 72.16557
Epoch 77, Val Loss: 74.78084
Epoch 78, Val Loss: 67.62757
Epoch 79, Val Loss: 69.73866
Epoch 80, Val Loss: 67.37916
Epoch 81, Val Loss: 91.17821
Epoch 82, Val Loss: 70.49165
Epoch 83, Val Loss: 65.92095
Epoch 84, Val Loss: 68.65833
Epoch 85, Val Loss: 70.63069
Epoch 86, Val Loss: 66.87086
Epoch 87, Val Loss: 68.46416
Epoch 88, Val Loss: 64.97916
Epoch 89, Val Loss: 69.74824
Epoch 90, Val Loss: 67.60255
Epoch 91, Val Loss: 73.22662
Epoch 92, Val Loss: 76.14569
Epoch 93, Val Loss: 67.38837
Epoch 94, Val Loss: 75.13919
Epoch 95, Val Loss: 70.94987
Epoch 96, Val Loss: 69.44673
Epoch 97, Val Loss: 68.78088
Epoch 98, Val Loss: 73.95802
Epoch 99, Val Loss: 69.47027
DID NOT SAVE RESULTS
{'MSE - mean': 75.56741371871381, 'MSE - std': 7.380001906577871, 'R2 - mean': 0.5256841587152915, 'R2 - std': 0.025714323375871942} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 476.62122
Epoch 1, Val Loss: 359.67303
Epoch 2, Val Loss: 150.73848
Epoch 3, Val Loss: 129.09479
Epoch 4, Val Loss: 122.95261
Epoch 5, Val Loss: 120.15891
Epoch 6, Val Loss: 112.31155
Epoch 7, Val Loss: 123.35590
Epoch 8, Val Loss: 111.36372
Epoch 9, Val Loss: 102.04586
Epoch 10, Val Loss: 99.66708
Epoch 11, Val Loss: 94.16172
Epoch 12, Val Loss: 94.62672
Epoch 13, Val Loss: 93.90463
Epoch 14, Val Loss: 95.85021
Epoch 15, Val Loss: 94.86786
Epoch 16, Val Loss: 89.93183
Epoch 17, Val Loss: 88.41835
Epoch 18, Val Loss: 95.16852
Epoch 19, Val Loss: 95.23863
Epoch 20, Val Loss: 88.09002
Epoch 21, Val Loss: 92.95146
Epoch 22, Val Loss: 89.69290
Epoch 23, Val Loss: 95.58185
Epoch 24, Val Loss: 112.27374
Epoch 25, Val Loss: 91.02916
Epoch 26, Val Loss: 88.37668
Epoch 27, Val Loss: 84.53120
Epoch 28, Val Loss: 95.55324
Epoch 29, Val Loss: 91.46404
Epoch 30, Val Loss: 100.43552
Epoch 31, Val Loss: 89.72002
Epoch 32, Val Loss: 90.27454
Epoch 33, Val Loss: 93.02339
Epoch 34, Val Loss: 95.34686
Epoch 35, Val Loss: 86.27730
Epoch 36, Val Loss: 111.22359
Epoch 37, Val Loss: 84.01518
Epoch 38, Val Loss: 88.50927
Epoch 39, Val Loss: 83.07649
Epoch 40, Val Loss: 86.64296
Epoch 41, Val Loss: 85.92043
Epoch 42, Val Loss: 101.46252
Epoch 43, Val Loss: 81.04543
Epoch 44, Val Loss: 86.14736
Epoch 45, Val Loss: 85.84088
Epoch 46, Val Loss: 80.75682
Epoch 47, Val Loss: 80.47641
Epoch 48, Val Loss: 84.32261
Epoch 49, Val Loss: 80.01840
Epoch 50, Val Loss: 80.47646
Epoch 51, Val Loss: 83.71526
Epoch 52, Val Loss: 78.67719
Epoch 53, Val Loss: 83.50519
Epoch 54, Val Loss: 80.20077
Epoch 55, Val Loss: 86.98206
Epoch 56, Val Loss: 82.10041
Epoch 57, Val Loss: 88.45927
Epoch 58, Val Loss: 82.61986
Epoch 59, Val Loss: 83.84485
Epoch 60, Val Loss: 82.52221
Epoch 61, Val Loss: 84.41088
Epoch 62, Val Loss: 115.00772
Epoch 63, Val Loss: 85.18198
Epoch 64, Val Loss: 79.34538
Epoch 65, Val Loss: 85.54513
Epoch 66, Val Loss: 81.77500
Epoch 67, Val Loss: 79.10676
Epoch 68, Val Loss: 80.29660
Epoch 69, Val Loss: 79.91294
Epoch 70, Val Loss: 77.47656
Epoch 71, Val Loss: 80.12662
Epoch 72, Val Loss: 79.40864
Epoch 73, Val Loss: 82.97129
Epoch 74, Val Loss: 81.69609
Epoch 75, Val Loss: 78.03606
Epoch 76, Val Loss: 77.76503
Epoch 77, Val Loss: 84.85069
Epoch 78, Val Loss: 78.08473
Epoch 79, Val Loss: 79.03210
Epoch 80, Val Loss: 80.23521
Epoch 81, Val Loss: 77.67556
Epoch 82, Val Loss: 79.00333
Epoch 83, Val Loss: 78.77565
Epoch 84, Val Loss: 81.09152
Epoch 85, Val Loss: 88.06876
Epoch 86, Val Loss: 94.24765
Epoch 87, Val Loss: 80.24703
Epoch 88, Val Loss: 81.48084
Epoch 89, Val Loss: 77.57349
Epoch 90, Val Loss: 79.66348
Epoch 91, Val Loss: 76.38093
Epoch 92, Val Loss: 78.98618
Epoch 93, Val Loss: 82.85295
Epoch 94, Val Loss: 78.58447
Epoch 95, Val Loss: 77.76367
Epoch 96, Val Loss: 84.57976
Epoch 97, Val Loss: 78.31028
Epoch 98, Val Loss: 77.12355
Epoch 99, Val Loss: 94.50687
DID NOT SAVE RESULTS
{'MSE - mean': 78.28894611478673, 'MSE - std': 7.9415701756291925, 'R2 - mean': 0.5147408556350259, 'R2 - std': 0.029243588475576} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 775.11688
Epoch 1, Val Loss: 473.06891
Epoch 2, Val Loss: 167.28757
Epoch 3, Val Loss: 131.86224
Epoch 4, Val Loss: 117.32626
Epoch 5, Val Loss: 109.24016
Epoch 6, Val Loss: 118.03081
Epoch 7, Val Loss: 104.73834
Epoch 8, Val Loss: 120.93384
Epoch 9, Val Loss: 101.18562
Epoch 10, Val Loss: 104.21427
Epoch 11, Val Loss: 104.12835
Epoch 12, Val Loss: 101.35750
Epoch 13, Val Loss: 100.23086
Epoch 14, Val Loss: 101.32671
Epoch 15, Val Loss: 96.03589
Epoch 16, Val Loss: 96.73828
Epoch 17, Val Loss: 97.10130
Epoch 18, Val Loss: 89.76624
Epoch 19, Val Loss: 98.87921
Epoch 20, Val Loss: 96.99526
Epoch 21, Val Loss: 95.09830
Epoch 22, Val Loss: 87.66881
Epoch 23, Val Loss: 90.41792
Epoch 24, Val Loss: 104.22870
Epoch 25, Val Loss: 85.81759
Epoch 26, Val Loss: 88.28114
Epoch 27, Val Loss: 96.44957
Epoch 28, Val Loss: 118.51491
Epoch 29, Val Loss: 91.12398
Epoch 30, Val Loss: 99.96525
Epoch 31, Val Loss: 81.90898
Epoch 32, Val Loss: 101.02903
Epoch 33, Val Loss: 87.98354
Epoch 34, Val Loss: 83.75342
Epoch 35, Val Loss: 83.44061
Epoch 36, Val Loss: 92.78758
Epoch 37, Val Loss: 87.36190
Epoch 38, Val Loss: 86.26458
Epoch 39, Val Loss: 83.22601
Epoch 40, Val Loss: 87.33010
Epoch 41, Val Loss: 90.21042
Epoch 42, Val Loss: 83.69981
Epoch 43, Val Loss: 96.51614
Epoch 44, Val Loss: 87.13262
Epoch 45, Val Loss: 87.15845
Epoch 46, Val Loss: 86.25466
Epoch 47, Val Loss: 82.22900
Epoch 48, Val Loss: 78.71119
Epoch 49, Val Loss: 81.92850
Epoch 50, Val Loss: 83.75305
Epoch 51, Val Loss: 76.91914
Epoch 52, Val Loss: 82.69086
Epoch 53, Val Loss: 82.79060
Epoch 54, Val Loss: 80.85155
Epoch 55, Val Loss: 82.22213
Epoch 56, Val Loss: 78.86636
Epoch 57, Val Loss: 82.71526
Epoch 58, Val Loss: 84.45518
Epoch 59, Val Loss: 87.86790
Epoch 60, Val Loss: 81.09292
Epoch 61, Val Loss: 80.95676
Epoch 62, Val Loss: 76.66721
Epoch 63, Val Loss: 84.01611
Epoch 64, Val Loss: 88.24847
Epoch 65, Val Loss: 80.26619
Epoch 66, Val Loss: 76.09467
Epoch 67, Val Loss: 74.56031
Epoch 68, Val Loss: 76.39277
Epoch 69, Val Loss: 88.55769
Epoch 70, Val Loss: 78.24287
Epoch 71, Val Loss: 80.91472
Epoch 72, Val Loss: 78.95801
Epoch 73, Val Loss: 84.56802
Epoch 74, Val Loss: 81.26929
Epoch 75, Val Loss: 75.80349
Epoch 76, Val Loss: 75.45728
Epoch 77, Val Loss: 78.75945
Epoch 78, Val Loss: 76.61761
Epoch 79, Val Loss: 79.61152
Epoch 80, Val Loss: 78.48669
Epoch 81, Val Loss: 79.16644
Epoch 82, Val Loss: 79.04166
Epoch 83, Val Loss: 82.06668
Epoch 84, Val Loss: 82.18929
Epoch 85, Val Loss: 78.11051
Epoch 86, Val Loss: 80.59618
Epoch 87, Val Loss: 81.07618
Epoch 88, Val Loss: 75.68220
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.75526758879647, 'MSE - std': 7.182901959512392, 'R2 - mean': 0.5169415180002367, 'R2 - std': 0.0265239822222398} 
 

Results After CV: {'MSE - mean': 77.75526758879647, 'MSE - std': 7.182901959512392, 'R2 - mean': 0.5169415180002367, 'R2 - std': 0.0265239822222398}
Train time: 894.338781580003
Inference time: 0.17725188519689256
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 41 finished with value: 77.75526758879647 and parameters: {'p_m': 0.1818013619907834, 'alpha': 9.92483907611208, 'K': 5, 'beta': 5.319913971632655}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1574.53613
Epoch 1, Val Loss: 410.28174
Epoch 2, Val Loss: 163.48668
Epoch 3, Val Loss: 142.54828
Epoch 4, Val Loss: 131.56003
Epoch 5, Val Loss: 152.12306
Epoch 6, Val Loss: 126.93970
Epoch 7, Val Loss: 115.73364
Epoch 8, Val Loss: 109.47240
Epoch 9, Val Loss: 112.77468
Epoch 10, Val Loss: 112.43924
Epoch 11, Val Loss: 105.89057
Epoch 12, Val Loss: 100.40938
Epoch 13, Val Loss: 104.05131
Epoch 14, Val Loss: 100.22398
Epoch 15, Val Loss: 105.26078
Epoch 16, Val Loss: 101.82292
Epoch 17, Val Loss: 104.43683
Epoch 18, Val Loss: 99.90790
Epoch 19, Val Loss: 106.16451
Epoch 20, Val Loss: 103.22750
Epoch 21, Val Loss: 107.37314
Epoch 22, Val Loss: 115.46928
Epoch 23, Val Loss: 99.70944
Epoch 24, Val Loss: 106.09581
Epoch 25, Val Loss: 103.90179
Epoch 26, Val Loss: 107.82745
Epoch 27, Val Loss: 101.03189
Epoch 28, Val Loss: 96.88611
Epoch 29, Val Loss: 95.62755
Epoch 30, Val Loss: 100.63149
Epoch 31, Val Loss: 106.58160
Epoch 32, Val Loss: 96.57966
Epoch 33, Val Loss: 108.16933
Epoch 34, Val Loss: 104.94757
Epoch 35, Val Loss: 96.22402
Epoch 36, Val Loss: 104.16755
Epoch 37, Val Loss: 101.70332
Epoch 38, Val Loss: 99.98782
Epoch 39, Val Loss: 103.85411
Epoch 40, Val Loss: 102.47456
Epoch 41, Val Loss: 95.69228
Epoch 42, Val Loss: 107.96266
Epoch 43, Val Loss: 98.04815
Epoch 44, Val Loss: 94.02238
Epoch 45, Val Loss: 94.84833
Epoch 46, Val Loss: 95.40364
Epoch 47, Val Loss: 95.90022
Epoch 48, Val Loss: 96.19724
Epoch 49, Val Loss: 96.21002
Epoch 50, Val Loss: 101.57584
Epoch 51, Val Loss: 94.40428
Epoch 52, Val Loss: 96.26227
Epoch 53, Val Loss: 90.04512
Epoch 54, Val Loss: 92.95833
Epoch 55, Val Loss: 92.31297
Epoch 56, Val Loss: 94.23482
Epoch 57, Val Loss: 102.69263
Epoch 58, Val Loss: 97.84642
Epoch 59, Val Loss: 93.56387
Epoch 60, Val Loss: 100.38925
Epoch 61, Val Loss: 86.12908
Epoch 62, Val Loss: 94.37309
Epoch 63, Val Loss: 84.92468
Epoch 64, Val Loss: 86.58768
Epoch 65, Val Loss: 89.44237
Epoch 66, Val Loss: 87.82040
Epoch 67, Val Loss: 83.65504
Epoch 68, Val Loss: 89.88942
Epoch 69, Val Loss: 96.65866
Epoch 70, Val Loss: 88.06882
Epoch 71, Val Loss: 93.17598
Epoch 72, Val Loss: 91.01927
Epoch 73, Val Loss: 94.43746
Epoch 74, Val Loss: 87.62704
Epoch 75, Val Loss: 91.88175
Epoch 76, Val Loss: 87.39584
Epoch 77, Val Loss: 84.86297
Epoch 78, Val Loss: 84.17427
Epoch 79, Val Loss: 86.61060
Epoch 80, Val Loss: 93.13464
Epoch 81, Val Loss: 91.04417
Epoch 82, Val Loss: 87.54468
Epoch 83, Val Loss: 106.80984
Epoch 84, Val Loss: 87.89915
Epoch 85, Val Loss: 93.28306
Epoch 86, Val Loss: 84.14883
Epoch 87, Val Loss: 86.35423
Epoch 88, Val Loss: 85.38448
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 89.17345959751843, 'MSE - std': 0.0, 'R2 - mean': 0.4803565859333836, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 658.60706
Epoch 1, Val Loss: 290.85510
Epoch 2, Val Loss: 148.48573
Epoch 3, Val Loss: 120.49011
Epoch 4, Val Loss: 117.23839
Epoch 5, Val Loss: 109.33258
Epoch 6, Val Loss: 109.27695
Epoch 7, Val Loss: 101.36478
Epoch 8, Val Loss: 108.29129
Epoch 9, Val Loss: 100.01102
Epoch 10, Val Loss: 88.87167
Epoch 11, Val Loss: 89.50029
Epoch 12, Val Loss: 85.65881
Epoch 13, Val Loss: 83.44225
Epoch 14, Val Loss: 105.17770
Epoch 15, Val Loss: 81.48325
Epoch 16, Val Loss: 82.68728
Epoch 17, Val Loss: 77.14328
Epoch 18, Val Loss: 79.61565
Epoch 19, Val Loss: 85.19601
Epoch 20, Val Loss: 81.97662
Epoch 21, Val Loss: 79.97974
Epoch 22, Val Loss: 86.11099
Epoch 23, Val Loss: 82.13649
Epoch 24, Val Loss: 84.80650
Epoch 25, Val Loss: 77.50614
Epoch 26, Val Loss: 95.27708
Epoch 27, Val Loss: 82.45495
Epoch 28, Val Loss: 81.14352
Epoch 29, Val Loss: 80.11850
Epoch 30, Val Loss: 80.50810
Epoch 31, Val Loss: 86.08650
Epoch 32, Val Loss: 87.59628
Epoch 33, Val Loss: 82.79572
Epoch 34, Val Loss: 77.17236
Epoch 35, Val Loss: 82.51048
Epoch 36, Val Loss: 78.49674
Epoch 37, Val Loss: 93.06521
Epoch 38, Val Loss: 76.99120
Epoch 39, Val Loss: 72.35442
Epoch 40, Val Loss: 74.93009
Epoch 41, Val Loss: 75.06880
Epoch 42, Val Loss: 73.60112
Epoch 43, Val Loss: 71.76926
Epoch 44, Val Loss: 79.42085
Epoch 45, Val Loss: 76.59108
Epoch 46, Val Loss: 72.15074
Epoch 47, Val Loss: 80.66909
Epoch 48, Val Loss: 72.55580
Epoch 49, Val Loss: 73.91198
Epoch 50, Val Loss: 75.88162
Epoch 51, Val Loss: 75.50378
Epoch 52, Val Loss: 75.47504
Epoch 53, Val Loss: 74.01196
Epoch 54, Val Loss: 70.92731
Epoch 55, Val Loss: 74.75563
Epoch 56, Val Loss: 76.24921
Epoch 57, Val Loss: 72.34958
Epoch 58, Val Loss: 69.07043
Epoch 59, Val Loss: 69.68407
Epoch 60, Val Loss: 74.53769
Epoch 61, Val Loss: 70.12368
Epoch 62, Val Loss: 68.78696
Epoch 63, Val Loss: 85.23874
Epoch 64, Val Loss: 71.32378
Epoch 65, Val Loss: 72.38205
Epoch 66, Val Loss: 80.69011
Epoch 67, Val Loss: 70.03414
Epoch 68, Val Loss: 74.43829
Epoch 69, Val Loss: 71.44402
Epoch 70, Val Loss: 77.38471
Epoch 71, Val Loss: 73.45977
Epoch 72, Val Loss: 76.20159
Epoch 73, Val Loss: 72.88053
Epoch 74, Val Loss: 74.81752
Epoch 75, Val Loss: 70.48645
Epoch 76, Val Loss: 70.39009
Epoch 77, Val Loss: 71.82629
Epoch 78, Val Loss: 70.84803
Epoch 79, Val Loss: 69.14652
Epoch 80, Val Loss: 70.11032
Epoch 81, Val Loss: 69.75783
Epoch 82, Val Loss: 69.24040
Epoch 83, Val Loss: 72.33649
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.0561526278835, 'MSE - std': 7.1173069696349245, 'R2 - mean': 0.501124102989017, 'R2 - std': 0.0207675170556334} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1725.34631
Epoch 1, Val Loss: 410.97424
Epoch 2, Val Loss: 161.99100
Epoch 3, Val Loss: 129.78946
Epoch 4, Val Loss: 112.05099
Epoch 5, Val Loss: 102.95941
Epoch 6, Val Loss: 104.75220
Epoch 7, Val Loss: 94.58123
Epoch 8, Val Loss: 93.09377
Epoch 9, Val Loss: 94.60213
Epoch 10, Val Loss: 91.62957
Epoch 11, Val Loss: 80.70445
Epoch 12, Val Loss: 86.68168
Epoch 13, Val Loss: 87.98283
Epoch 14, Val Loss: 105.90865
Epoch 15, Val Loss: 93.64487
Epoch 16, Val Loss: 78.15506
Epoch 17, Val Loss: 82.08678
Epoch 18, Val Loss: 81.14986
Epoch 19, Val Loss: 89.85737
Epoch 20, Val Loss: 85.88387
Epoch 21, Val Loss: 83.96236
Epoch 22, Val Loss: 80.12290
Epoch 23, Val Loss: 87.05211
Epoch 24, Val Loss: 78.28030
Epoch 25, Val Loss: 85.86771
Epoch 26, Val Loss: 88.82891
Epoch 27, Val Loss: 86.57301
Epoch 28, Val Loss: 80.32695
Epoch 29, Val Loss: 78.58953
Epoch 30, Val Loss: 85.60452
Epoch 31, Val Loss: 90.52974
Epoch 32, Val Loss: 78.62429
Epoch 33, Val Loss: 87.70891
Epoch 34, Val Loss: 77.24374
Epoch 35, Val Loss: 81.96581
Epoch 36, Val Loss: 86.06494
Epoch 37, Val Loss: 74.14460
Epoch 38, Val Loss: 82.66773
Epoch 39, Val Loss: 77.32045
Epoch 40, Val Loss: 95.85385
Epoch 41, Val Loss: 85.09557
Epoch 42, Val Loss: 79.31575
Epoch 43, Val Loss: 81.85612
Epoch 44, Val Loss: 76.06335
Epoch 45, Val Loss: 75.62391
Epoch 46, Val Loss: 77.68871
Epoch 47, Val Loss: 82.26830
Epoch 48, Val Loss: 75.56364
Epoch 49, Val Loss: 70.27106
Epoch 50, Val Loss: 75.80863
Epoch 51, Val Loss: 73.30384
Epoch 52, Val Loss: 76.58478
Epoch 53, Val Loss: 74.28246
Epoch 54, Val Loss: 100.71085
Epoch 55, Val Loss: 74.52616
Epoch 56, Val Loss: 77.47181
Epoch 57, Val Loss: 70.51528
Epoch 58, Val Loss: 74.16063
Epoch 59, Val Loss: 73.08308
Epoch 60, Val Loss: 76.66833
Epoch 61, Val Loss: 82.26633
Epoch 62, Val Loss: 70.56580
Epoch 63, Val Loss: 71.90271
Epoch 64, Val Loss: 71.03439
Epoch 65, Val Loss: 72.70805
Epoch 66, Val Loss: 73.80071
Epoch 67, Val Loss: 76.76550
Epoch 68, Val Loss: 71.38594
Epoch 69, Val Loss: 81.76974
Epoch 70, Val Loss: 71.51219
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.46813288512817, 'MSE - std': 7.714821904326769, 'R2 - mean': 0.5076952090991181, 'R2 - std': 0.01933611596963307} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 739.68915
Epoch 1, Val Loss: 339.46509
Epoch 2, Val Loss: 146.62366
Epoch 3, Val Loss: 135.44206
Epoch 4, Val Loss: 122.76955
Epoch 5, Val Loss: 122.48203
Epoch 6, Val Loss: 121.17907
Epoch 7, Val Loss: 103.56586
Epoch 8, Val Loss: 100.98530
Epoch 9, Val Loss: 97.84295
Epoch 10, Val Loss: 97.29038
Epoch 11, Val Loss: 102.37642
Epoch 12, Val Loss: 99.95166
Epoch 13, Val Loss: 92.55846
Epoch 14, Val Loss: 91.12656
Epoch 15, Val Loss: 92.59205
Epoch 16, Val Loss: 93.47682
Epoch 17, Val Loss: 95.11769
Epoch 18, Val Loss: 96.48631
Epoch 19, Val Loss: 100.18764
Epoch 20, Val Loss: 93.80936
Epoch 21, Val Loss: 87.51281
Epoch 22, Val Loss: 87.22272
Epoch 23, Val Loss: 101.74181
Epoch 24, Val Loss: 90.38667
Epoch 25, Val Loss: 89.87936
Epoch 26, Val Loss: 91.72427
Epoch 27, Val Loss: 92.75962
Epoch 28, Val Loss: 94.82954
Epoch 29, Val Loss: 93.06763
Epoch 30, Val Loss: 88.60126
Epoch 31, Val Loss: 89.24858
Epoch 32, Val Loss: 86.19645
Epoch 33, Val Loss: 89.54915
Epoch 34, Val Loss: 91.56279
Epoch 35, Val Loss: 86.83225
Epoch 36, Val Loss: 102.14475
Epoch 37, Val Loss: 90.14527
Epoch 38, Val Loss: 87.00179
Epoch 39, Val Loss: 85.23820
Epoch 40, Val Loss: 89.52859
Epoch 41, Val Loss: 90.70876
Epoch 42, Val Loss: 85.06489
Epoch 43, Val Loss: 90.32154
Epoch 44, Val Loss: 87.47568
Epoch 45, Val Loss: 85.96376
Epoch 46, Val Loss: 89.87669
Epoch 47, Val Loss: 95.84404
Epoch 48, Val Loss: 86.80424
Epoch 49, Val Loss: 87.85358
Epoch 50, Val Loss: 87.43633
Epoch 51, Val Loss: 81.45621
Epoch 52, Val Loss: 85.46522
Epoch 53, Val Loss: 80.62834
Epoch 54, Val Loss: 80.84941
Epoch 55, Val Loss: 82.87886
Epoch 56, Val Loss: 79.68343
Epoch 57, Val Loss: 81.34196
Epoch 58, Val Loss: 78.99155
Epoch 59, Val Loss: 83.08802
Epoch 60, Val Loss: 85.60859
Epoch 61, Val Loss: 82.04155
Epoch 62, Val Loss: 112.98787
Epoch 63, Val Loss: 84.50118
Epoch 64, Val Loss: 83.12376
Epoch 65, Val Loss: 82.92739
Epoch 66, Val Loss: 79.83181
Epoch 67, Val Loss: 84.48785
Epoch 68, Val Loss: 90.19839
Epoch 69, Val Loss: 88.98862
Epoch 70, Val Loss: 87.01482
Epoch 71, Val Loss: 80.34779
Epoch 72, Val Loss: 80.33880
Epoch 73, Val Loss: 84.96723
Epoch 74, Val Loss: 83.10665
Epoch 75, Val Loss: 82.70086
Epoch 76, Val Loss: 82.94547
Epoch 77, Val Loss: 81.45111
Epoch 78, Val Loss: 82.34099
Epoch 79, Val Loss: 80.29408
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.46886622521465, 'MSE - std': 8.46475395369114, 'R2 - mean': 0.4952302037138317, 'R2 - std': 0.027322941154988817} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 626.92450
Epoch 1, Val Loss: 263.98608
Epoch 2, Val Loss: 146.48650
Epoch 3, Val Loss: 119.68018
Epoch 4, Val Loss: 114.86147
Epoch 5, Val Loss: 109.14249
Epoch 6, Val Loss: 105.63700
Epoch 7, Val Loss: 99.36297
Epoch 8, Val Loss: 97.32697
Epoch 9, Val Loss: 93.04512
Epoch 10, Val Loss: 95.68887
Epoch 11, Val Loss: 103.78858
Epoch 12, Val Loss: 91.29257
Epoch 13, Val Loss: 95.00529
Epoch 14, Val Loss: 105.26982
Epoch 15, Val Loss: 88.53238
Epoch 16, Val Loss: 84.12369
Epoch 17, Val Loss: 98.63707
Epoch 18, Val Loss: 89.34529
Epoch 19, Val Loss: 91.12240
Epoch 20, Val Loss: 86.96581
Epoch 21, Val Loss: 91.47009
Epoch 22, Val Loss: 84.89849
Epoch 23, Val Loss: 115.08001
Epoch 24, Val Loss: 86.97604
Epoch 25, Val Loss: 88.74860
Epoch 26, Val Loss: 88.01031
Epoch 27, Val Loss: 86.37732
Epoch 28, Val Loss: 95.28203
Epoch 29, Val Loss: 91.27956
Epoch 30, Val Loss: 87.86732
Epoch 31, Val Loss: 95.81226
Epoch 32, Val Loss: 88.16079
Epoch 33, Val Loss: 99.41895
Epoch 34, Val Loss: 99.94524
Epoch 35, Val Loss: 91.06230
Epoch 36, Val Loss: 84.65686
Epoch 37, Val Loss: 90.90268
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.16814059931421, 'MSE - std': 7.699193866783269, 'R2 - mean': 0.48961192070883364, 'R2 - std': 0.026897860628387983} 
 

Results After CV: {'MSE - mean': 82.16814059931421, 'MSE - std': 7.699193866783269, 'R2 - mean': 0.48961192070883364, 'R2 - std': 0.026897860628387983}
Train time: 690.9621472495986
Inference time: 0.1783319690031931
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 42 finished with value: 82.16814059931421 and parameters: {'p_m': 0.2652339789328307, 'alpha': 9.30404028588296, 'K': 5, 'beta': 4.411753671629898}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1167.86548
Epoch 1, Val Loss: 476.94986
Epoch 2, Val Loss: 200.61699
Epoch 3, Val Loss: 160.45230
Epoch 4, Val Loss: 127.89096
Epoch 5, Val Loss: 130.38293
Epoch 6, Val Loss: 112.41176
Epoch 7, Val Loss: 121.07687
Epoch 8, Val Loss: 104.08823
Epoch 9, Val Loss: 99.95838
Epoch 10, Val Loss: 94.88965
Epoch 11, Val Loss: 99.49929
Epoch 12, Val Loss: 98.51959
Epoch 13, Val Loss: 117.10715
Epoch 14, Val Loss: 94.72841
Epoch 15, Val Loss: 101.04329
Epoch 16, Val Loss: 103.99429
Epoch 17, Val Loss: 104.46845
Epoch 18, Val Loss: 92.19869
Epoch 19, Val Loss: 102.20602
Epoch 20, Val Loss: 95.78223
Epoch 21, Val Loss: 95.54138
Epoch 22, Val Loss: 95.36528
Epoch 23, Val Loss: 95.37352
Epoch 24, Val Loss: 109.48724
Epoch 25, Val Loss: 103.92585
Epoch 26, Val Loss: 97.35455
Epoch 27, Val Loss: 89.18582
Epoch 28, Val Loss: 95.36115
Epoch 29, Val Loss: 93.16164
Epoch 30, Val Loss: 100.87679
Epoch 31, Val Loss: 93.32968
Epoch 32, Val Loss: 94.12944
Epoch 33, Val Loss: 108.11126
Epoch 34, Val Loss: 95.69003
Epoch 35, Val Loss: 101.29195
Epoch 36, Val Loss: 102.08155
Epoch 37, Val Loss: 92.52181
Epoch 38, Val Loss: 95.15242
Epoch 39, Val Loss: 90.00260
Epoch 40, Val Loss: 96.52334
Epoch 41, Val Loss: 99.07448
Epoch 42, Val Loss: 96.19503
Epoch 43, Val Loss: 89.64353
Epoch 44, Val Loss: 89.05650
Epoch 45, Val Loss: 92.39335
Epoch 46, Val Loss: 97.45382
Epoch 47, Val Loss: 94.16048
Epoch 48, Val Loss: 90.65320
Epoch 49, Val Loss: 90.36778
Epoch 50, Val Loss: 91.41284
Epoch 51, Val Loss: 99.48285
Epoch 52, Val Loss: 87.64386
Epoch 53, Val Loss: 89.96576
Epoch 54, Val Loss: 94.86710
Epoch 55, Val Loss: 95.90274
Epoch 56, Val Loss: 86.38204
Epoch 57, Val Loss: 93.20565
Epoch 58, Val Loss: 99.42107
Epoch 59, Val Loss: 91.59931
Epoch 60, Val Loss: 87.22131
Epoch 61, Val Loss: 85.36540
Epoch 62, Val Loss: 85.73470
Epoch 63, Val Loss: 88.24112
Epoch 64, Val Loss: 88.54936
Epoch 65, Val Loss: 88.72672
Epoch 66, Val Loss: 87.82739
Epoch 67, Val Loss: 99.45492
Epoch 68, Val Loss: 86.16222
Epoch 69, Val Loss: 96.63441
Epoch 70, Val Loss: 87.19894
Epoch 71, Val Loss: 85.41035
Epoch 72, Val Loss: 94.75822
Epoch 73, Val Loss: 109.98663
Epoch 74, Val Loss: 95.88036
Epoch 75, Val Loss: 91.20050
Epoch 76, Val Loss: 90.61048
Epoch 77, Val Loss: 84.45880
Epoch 78, Val Loss: 86.95670
Epoch 79, Val Loss: 84.05925
Epoch 80, Val Loss: 85.52745
Epoch 81, Val Loss: 84.12256
Epoch 82, Val Loss: 82.08310
Epoch 83, Val Loss: 85.10403
Epoch 84, Val Loss: 89.78069
Epoch 85, Val Loss: 85.86822
Epoch 86, Val Loss: 88.11118
Epoch 87, Val Loss: 87.79063
Epoch 88, Val Loss: 86.86846
Epoch 89, Val Loss: 86.04107
Epoch 90, Val Loss: 82.26199
Epoch 91, Val Loss: 83.51910
Epoch 92, Val Loss: 85.28168
Epoch 93, Val Loss: 83.86381
Epoch 94, Val Loss: 91.30374
Epoch 95, Val Loss: 85.12025
Epoch 96, Val Loss: 84.81844
Epoch 97, Val Loss: 86.86107
Epoch 98, Val Loss: 96.19226
Epoch 99, Val Loss: 81.49220
DID NOT SAVE RESULTS
{'MSE - mean': 85.4328301065541, 'MSE - std': 0.0, 'R2 - mean': 0.5021544783580604, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 540.05603
Epoch 1, Val Loss: 480.55270
Epoch 2, Val Loss: 152.51381
Epoch 3, Val Loss: 136.41061
Epoch 4, Val Loss: 133.43518
Epoch 5, Val Loss: 125.60155
Epoch 6, Val Loss: 99.86679
Epoch 7, Val Loss: 101.00009
Epoch 8, Val Loss: 104.74442
Epoch 9, Val Loss: 101.52480
Epoch 10, Val Loss: 112.72678
Epoch 11, Val Loss: 94.53877
Epoch 12, Val Loss: 92.25741
Epoch 13, Val Loss: 94.88148
Epoch 14, Val Loss: 89.66810
Epoch 15, Val Loss: 84.87192
Epoch 16, Val Loss: 87.95863
Epoch 17, Val Loss: 80.75293
Epoch 18, Val Loss: 98.69340
Epoch 19, Val Loss: 87.88991
Epoch 20, Val Loss: 93.64391
Epoch 21, Val Loss: 80.83354
Epoch 22, Val Loss: 82.02585
Epoch 23, Val Loss: 88.70286
Epoch 24, Val Loss: 85.63043
Epoch 25, Val Loss: 81.14168
Epoch 26, Val Loss: 80.01186
Epoch 27, Val Loss: 77.46927
Epoch 28, Val Loss: 86.28313
Epoch 29, Val Loss: 83.40097
Epoch 30, Val Loss: 91.73718
Epoch 31, Val Loss: 81.71480
Epoch 32, Val Loss: 92.48089
Epoch 33, Val Loss: 89.19733
Epoch 34, Val Loss: 79.64186
Epoch 35, Val Loss: 92.18696
Epoch 36, Val Loss: 75.56940
Epoch 37, Val Loss: 77.61855
Epoch 38, Val Loss: 94.62061
Epoch 39, Val Loss: 81.10055
Epoch 40, Val Loss: 78.34584
Epoch 41, Val Loss: 84.89929
Epoch 42, Val Loss: 77.20996
Epoch 43, Val Loss: 80.85130
Epoch 44, Val Loss: 100.26708
Epoch 45, Val Loss: 80.70238
Epoch 46, Val Loss: 78.44035
Epoch 47, Val Loss: 80.38944
Epoch 48, Val Loss: 75.30660
Epoch 49, Val Loss: 83.32828
Epoch 50, Val Loss: 79.58141
Epoch 51, Val Loss: 76.41299
Epoch 52, Val Loss: 77.06146
Epoch 53, Val Loss: 73.23934
Epoch 54, Val Loss: 73.94925
Epoch 55, Val Loss: 78.25785
Epoch 56, Val Loss: 79.20623
Epoch 57, Val Loss: 72.76161
Epoch 58, Val Loss: 74.21570
Epoch 59, Val Loss: 84.87276
Epoch 60, Val Loss: 73.82535
Epoch 61, Val Loss: 80.02871
Epoch 62, Val Loss: 70.57754
Epoch 63, Val Loss: 72.11280
Epoch 64, Val Loss: 72.84623
Epoch 65, Val Loss: 77.57153
Epoch 66, Val Loss: 74.46889
Epoch 67, Val Loss: 76.89475
Epoch 68, Val Loss: 70.67232
Epoch 69, Val Loss: 72.09492
Epoch 70, Val Loss: 79.37000
Epoch 71, Val Loss: 78.98667
Epoch 72, Val Loss: 73.44068
Epoch 73, Val Loss: 69.93543
Epoch 74, Val Loss: 76.47363
Epoch 75, Val Loss: 71.64195
Epoch 76, Val Loss: 70.30901
Epoch 77, Val Loss: 72.23030
Epoch 78, Val Loss: 73.85364
Epoch 79, Val Loss: 72.95724
Epoch 80, Val Loss: 70.36613
Epoch 81, Val Loss: 75.53060
Epoch 82, Val Loss: 72.53189
Epoch 83, Val Loss: 74.54459
Epoch 84, Val Loss: 70.79050
Epoch 85, Val Loss: 75.00529
Epoch 86, Val Loss: 72.75915
Epoch 87, Val Loss: 70.91940
Epoch 88, Val Loss: 82.41990
Epoch 89, Val Loss: 76.88200
Epoch 90, Val Loss: 71.11378
Epoch 91, Val Loss: 78.35238
Epoch 92, Val Loss: 70.67050
Epoch 93, Val Loss: 69.05263
Epoch 94, Val Loss: 72.56413
Epoch 95, Val Loss: 68.56089
Epoch 96, Val Loss: 79.39953
Epoch 97, Val Loss: 72.01680
Epoch 98, Val Loss: 70.92080
Epoch 99, Val Loss: 77.61768
DID NOT SAVE RESULTS
{'MSE - mean': 80.55384387086272, 'MSE - std': 4.878986235691379, 'R2 - mean': 0.5096751781418047, 'R2 - std': 0.007520699783744311} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1073.61780
Epoch 1, Val Loss: 464.69693
Epoch 2, Val Loss: 156.81204
Epoch 3, Val Loss: 120.30865
Epoch 4, Val Loss: 113.40684
Epoch 5, Val Loss: 98.70880
Epoch 6, Val Loss: 87.19783
Epoch 7, Val Loss: 91.45634
Epoch 8, Val Loss: 93.83208
Epoch 9, Val Loss: 89.47437
Epoch 10, Val Loss: 81.95220
Epoch 11, Val Loss: 78.09518
Epoch 12, Val Loss: 82.56973
Epoch 13, Val Loss: 80.46516
Epoch 14, Val Loss: 78.76319
Epoch 15, Val Loss: 75.29478
Epoch 16, Val Loss: 78.18370
Epoch 17, Val Loss: 78.93796
Epoch 18, Val Loss: 78.10027
Epoch 19, Val Loss: 80.16197
Epoch 20, Val Loss: 87.88545
Epoch 21, Val Loss: 75.15228
Epoch 22, Val Loss: 85.00111
Epoch 23, Val Loss: 75.82112
Epoch 24, Val Loss: 76.94478
Epoch 25, Val Loss: 82.16470
Epoch 26, Val Loss: 79.22037
Epoch 27, Val Loss: 88.18884
Epoch 28, Val Loss: 80.07745
Epoch 29, Val Loss: 88.66618
Epoch 30, Val Loss: 86.33244
Epoch 31, Val Loss: 78.41511
Epoch 32, Val Loss: 100.15644
Epoch 33, Val Loss: 79.96690
Epoch 34, Val Loss: 80.27959
Epoch 35, Val Loss: 79.06351
Epoch 36, Val Loss: 84.88819
Epoch 37, Val Loss: 77.13954
Epoch 38, Val Loss: 77.71770
Epoch 39, Val Loss: 82.56615
Epoch 40, Val Loss: 75.81133
Epoch 41, Val Loss: 77.79050
Epoch 42, Val Loss: 75.61584
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.11792965225963, 'MSE - std': 4.471394683065937, 'R2 - mean': 0.5022971020175113, 'R2 - std': 0.012106993767373148} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1165.26147
Epoch 1, Val Loss: 428.62183
Epoch 2, Val Loss: 208.04446
Epoch 3, Val Loss: 142.98932
Epoch 4, Val Loss: 125.14443
Epoch 5, Val Loss: 127.68643
Epoch 6, Val Loss: 119.62378
Epoch 7, Val Loss: 111.53194
Epoch 8, Val Loss: 108.59547
Epoch 9, Val Loss: 108.19393
Epoch 10, Val Loss: 103.36069
Epoch 11, Val Loss: 105.60110
Epoch 12, Val Loss: 100.23483
Epoch 13, Val Loss: 97.33177
Epoch 14, Val Loss: 103.37292
Epoch 15, Val Loss: 94.12518
Epoch 16, Val Loss: 92.18098
Epoch 17, Val Loss: 100.40972
Epoch 18, Val Loss: 92.15967
Epoch 19, Val Loss: 94.31061
Epoch 20, Val Loss: 91.46559
Epoch 21, Val Loss: 100.10332
Epoch 22, Val Loss: 87.69700
Epoch 23, Val Loss: 91.62861
Epoch 24, Val Loss: 91.61980
Epoch 25, Val Loss: 92.90255
Epoch 26, Val Loss: 95.86897
Epoch 27, Val Loss: 89.83531
Epoch 28, Val Loss: 86.11632
Epoch 29, Val Loss: 85.58910
Epoch 30, Val Loss: 97.92002
Epoch 31, Val Loss: 94.29137
Epoch 32, Val Loss: 102.96890
Epoch 33, Val Loss: 93.68995
Epoch 34, Val Loss: 89.05066
Epoch 35, Val Loss: 85.23502
Epoch 36, Val Loss: 92.93614
Epoch 37, Val Loss: 114.85629
Epoch 38, Val Loss: 91.24744
Epoch 39, Val Loss: 97.30241
Epoch 40, Val Loss: 93.58832
Epoch 41, Val Loss: 92.77348
Epoch 42, Val Loss: 86.95585
Epoch 43, Val Loss: 89.42017
Epoch 44, Val Loss: 87.77790
Epoch 45, Val Loss: 86.11022
Epoch 46, Val Loss: 87.31523
Epoch 47, Val Loss: 85.81485
Epoch 48, Val Loss: 83.55194
Epoch 49, Val Loss: 87.24634
Epoch 50, Val Loss: 92.88771
Epoch 51, Val Loss: 87.54165
Epoch 52, Val Loss: 84.04797
Epoch 53, Val Loss: 91.93323
Epoch 54, Val Loss: 88.61401
Epoch 55, Val Loss: 82.81089
Epoch 56, Val Loss: 86.73505
Epoch 57, Val Loss: 105.06032
Epoch 58, Val Loss: 91.48373
Epoch 59, Val Loss: 85.24667
Epoch 60, Val Loss: 82.45387
Epoch 61, Val Loss: 81.16409
Epoch 62, Val Loss: 82.69489
Epoch 63, Val Loss: 86.14037
Epoch 64, Val Loss: 103.03474
Epoch 65, Val Loss: 82.62958
Epoch 66, Val Loss: 84.11512
Epoch 67, Val Loss: 83.51667
Epoch 68, Val Loss: 81.31514
Epoch 69, Val Loss: 84.51271
Epoch 70, Val Loss: 88.36063
Epoch 71, Val Loss: 83.01604
Epoch 72, Val Loss: 79.78539
Epoch 73, Val Loss: 80.59692
Epoch 74, Val Loss: 82.98555
Epoch 75, Val Loss: 87.54467
Epoch 76, Val Loss: 83.59159
Epoch 77, Val Loss: 79.71599
Epoch 78, Val Loss: 82.74149
Epoch 79, Val Loss: 77.06284
Epoch 80, Val Loss: 82.13436
Epoch 81, Val Loss: 84.40719
Epoch 82, Val Loss: 83.46783
Epoch 83, Val Loss: 84.74996
Epoch 84, Val Loss: 78.08506
Epoch 85, Val Loss: 78.07069
Epoch 86, Val Loss: 78.32162
Epoch 87, Val Loss: 79.89289
Epoch 88, Val Loss: 77.79714
Epoch 89, Val Loss: 80.58466
Epoch 90, Val Loss: 80.85608
Epoch 91, Val Loss: 86.14110
Epoch 92, Val Loss: 86.43579
Epoch 93, Val Loss: 79.35428
Epoch 94, Val Loss: 82.34474
Epoch 95, Val Loss: 82.53011
Epoch 96, Val Loss: 84.24921
Epoch 97, Val Loss: 86.14346
Epoch 98, Val Loss: 82.39590
Epoch 99, Val Loss: 78.40320
DID NOT SAVE RESULTS
{'MSE - mean': 81.34001621169443, 'MSE - std': 5.459673418957876, 'R2 - mean': 0.49487430288636153, 'R2 - std': 0.016590006461318897} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 906.89160
Epoch 1, Val Loss: 491.55444
Epoch 2, Val Loss: 173.32574
Epoch 3, Val Loss: 145.51758
Epoch 4, Val Loss: 113.36200
Epoch 5, Val Loss: 115.92894
Epoch 6, Val Loss: 108.87193
Epoch 7, Val Loss: 104.91135
Epoch 8, Val Loss: 111.95441
Epoch 9, Val Loss: 113.61736
Epoch 10, Val Loss: 101.32739
Epoch 11, Val Loss: 99.20334
Epoch 12, Val Loss: 89.86625
Epoch 13, Val Loss: 92.82574
Epoch 14, Val Loss: 99.83006
Epoch 15, Val Loss: 91.23951
Epoch 16, Val Loss: 105.87001
Epoch 17, Val Loss: 97.04530
Epoch 18, Val Loss: 97.30049
Epoch 19, Val Loss: 97.67418
Epoch 20, Val Loss: 95.58685
Epoch 21, Val Loss: 95.45892
Epoch 22, Val Loss: 84.59148
Epoch 23, Val Loss: 99.16380
Epoch 24, Val Loss: 93.08289
Epoch 25, Val Loss: 92.75727
Epoch 26, Val Loss: 98.73521
Epoch 27, Val Loss: 90.04027
Epoch 28, Val Loss: 97.19560
Epoch 29, Val Loss: 89.78522
Epoch 30, Val Loss: 82.59915
Epoch 31, Val Loss: 88.28951
Epoch 32, Val Loss: 110.53743
Epoch 33, Val Loss: 84.07577
Epoch 34, Val Loss: 86.83420
Epoch 35, Val Loss: 86.16409
Epoch 36, Val Loss: 90.22495
Epoch 37, Val Loss: 84.34135
Epoch 38, Val Loss: 85.48937
Epoch 39, Val Loss: 95.00933
Epoch 40, Val Loss: 89.05755
Epoch 41, Val Loss: 78.29774
Epoch 42, Val Loss: 82.01695
Epoch 43, Val Loss: 89.45786
Epoch 44, Val Loss: 85.70105
Epoch 45, Val Loss: 79.95320
Epoch 46, Val Loss: 82.59169
Epoch 47, Val Loss: 88.32973
Epoch 48, Val Loss: 78.40924
Epoch 49, Val Loss: 80.87438
Epoch 50, Val Loss: 79.75640
Epoch 51, Val Loss: 83.85390
Epoch 52, Val Loss: 98.92990
Epoch 53, Val Loss: 89.69695
Epoch 54, Val Loss: 77.73349
Epoch 55, Val Loss: 84.13270
Epoch 56, Val Loss: 81.85363
Epoch 57, Val Loss: 78.88966
Epoch 58, Val Loss: 77.34749
Epoch 59, Val Loss: 95.34016
Epoch 60, Val Loss: 77.00139
Epoch 61, Val Loss: 90.67313
Epoch 62, Val Loss: 84.15469
Epoch 63, Val Loss: 79.15506
Epoch 64, Val Loss: 77.80445
Epoch 65, Val Loss: 75.59126
Epoch 66, Val Loss: 95.40468
Epoch 67, Val Loss: 74.44011
Epoch 68, Val Loss: 78.38618
Epoch 69, Val Loss: 78.00098
Epoch 70, Val Loss: 75.64860
Epoch 71, Val Loss: 81.42584
Epoch 72, Val Loss: 70.93266
Epoch 73, Val Loss: 74.26637
Epoch 74, Val Loss: 73.41549
Epoch 75, Val Loss: 78.75833
Epoch 76, Val Loss: 74.76990
Epoch 77, Val Loss: 74.51022
Epoch 78, Val Loss: 73.07832
Epoch 79, Val Loss: 80.36964
Epoch 80, Val Loss: 76.56669
Epoch 81, Val Loss: 77.09937
Epoch 82, Val Loss: 83.07959
Epoch 83, Val Loss: 81.83321
Epoch 84, Val Loss: 73.40526
Epoch 85, Val Loss: 75.51095
Epoch 86, Val Loss: 73.28595
Epoch 87, Val Loss: 71.30539
Epoch 88, Val Loss: 72.86657
Epoch 89, Val Loss: 73.81393
Epoch 90, Val Loss: 70.54504
Epoch 91, Val Loss: 75.03184
Epoch 92, Val Loss: 75.93831
Epoch 93, Val Loss: 72.40981
Epoch 94, Val Loss: 70.87334
Epoch 95, Val Loss: 76.75323
Epoch 96, Val Loss: 69.86946
Epoch 97, Val Loss: 71.28532
Epoch 98, Val Loss: 77.78282
Epoch 99, Val Loss: 91.81503
DID NOT SAVE RESULTS
{'MSE - mean': 79.38204139263624, 'MSE - std': 6.259479901845219, 'R2 - mean': 0.5061538092663538, 'R2 - std': 0.02700169824685898} 
 

Results After CV: {'MSE - mean': 79.38204139263624, 'MSE - std': 6.259479901845219, 'R2 - mean': 0.5061538092663538, 'R2 - std': 0.02700169824685898}
Train time: 844.7412628393998
Inference time: 0.1763838921993738
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 43 finished with value: 79.38204139263624 and parameters: {'p_m': 0.1351227121344321, 'alpha': 9.476685717219281, 'K': 5, 'beta': 7.038146879669628}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1289.29211
Epoch 1, Val Loss: 417.43756
Epoch 2, Val Loss: 196.04155
Epoch 3, Val Loss: 150.10193
Epoch 4, Val Loss: 140.89301
Epoch 5, Val Loss: 126.35942
Epoch 6, Val Loss: 124.83295
Epoch 7, Val Loss: 111.14294
Epoch 8, Val Loss: 112.73199
Epoch 9, Val Loss: 109.37012
Epoch 10, Val Loss: 110.13358
Epoch 11, Val Loss: 103.37411
Epoch 12, Val Loss: 104.87267
Epoch 13, Val Loss: 107.04163
Epoch 14, Val Loss: 111.10494
Epoch 15, Val Loss: 103.98013
Epoch 16, Val Loss: 107.41998
Epoch 17, Val Loss: 99.04978
Epoch 18, Val Loss: 103.69853
Epoch 19, Val Loss: 111.54745
Epoch 20, Val Loss: 97.62329
Epoch 21, Val Loss: 101.92824
Epoch 22, Val Loss: 102.61764
Epoch 23, Val Loss: 100.52039
Epoch 24, Val Loss: 97.00337
Epoch 25, Val Loss: 103.52324
Epoch 26, Val Loss: 136.86794
Epoch 27, Val Loss: 105.33984
Epoch 28, Val Loss: 100.71914
Epoch 29, Val Loss: 103.68347
Epoch 30, Val Loss: 99.79399
Epoch 31, Val Loss: 101.38265
Epoch 32, Val Loss: 99.42882
Epoch 33, Val Loss: 106.03156
Epoch 34, Val Loss: 104.39009
Epoch 35, Val Loss: 110.45251
Epoch 36, Val Loss: 98.84933
Epoch 37, Val Loss: 95.60899
Epoch 38, Val Loss: 108.56175
Epoch 39, Val Loss: 109.16761
Epoch 40, Val Loss: 99.96664
Epoch 41, Val Loss: 96.73909
Epoch 42, Val Loss: 102.49765
Epoch 43, Val Loss: 99.87758
Epoch 44, Val Loss: 102.58610
Epoch 45, Val Loss: 95.68900
Epoch 46, Val Loss: 106.84753
Epoch 47, Val Loss: 110.21222
Epoch 48, Val Loss: 93.32407
Epoch 49, Val Loss: 91.95269
Epoch 50, Val Loss: 95.01643
Epoch 51, Val Loss: 105.28239
Epoch 52, Val Loss: 94.28716
Epoch 53, Val Loss: 88.26530
Epoch 54, Val Loss: 96.19666
Epoch 55, Val Loss: 101.05624
Epoch 56, Val Loss: 111.99541
Epoch 57, Val Loss: 87.05867
Epoch 58, Val Loss: 89.42957
Epoch 59, Val Loss: 89.85580
Epoch 60, Val Loss: 91.47456
Epoch 61, Val Loss: 91.00319
Epoch 62, Val Loss: 92.46851
Epoch 63, Val Loss: 91.58599
Epoch 64, Val Loss: 115.05437
Epoch 65, Val Loss: 95.96545
Epoch 66, Val Loss: 96.56134
Epoch 67, Val Loss: 94.06866
Epoch 68, Val Loss: 96.48466
Epoch 69, Val Loss: 90.64248
Epoch 70, Val Loss: 90.40503
Epoch 71, Val Loss: 90.73975
Epoch 72, Val Loss: 86.86340
Epoch 73, Val Loss: 84.72465
Epoch 74, Val Loss: 92.11414
Epoch 75, Val Loss: 91.50612
Epoch 76, Val Loss: 92.51413
Epoch 77, Val Loss: 96.71439
Epoch 78, Val Loss: 87.46615
Epoch 79, Val Loss: 90.90413
Epoch 80, Val Loss: 85.73560
Epoch 81, Val Loss: 84.69286
Epoch 82, Val Loss: 87.61179
Epoch 83, Val Loss: 89.78735
Epoch 84, Val Loss: 87.79512
Epoch 85, Val Loss: 86.31516
Epoch 86, Val Loss: 88.35283
Epoch 87, Val Loss: 89.10993
Epoch 88, Val Loss: 87.98035
Epoch 89, Val Loss: 92.71565
Epoch 90, Val Loss: 99.71567
Epoch 91, Val Loss: 84.65524
Epoch 92, Val Loss: 90.40955
Epoch 93, Val Loss: 85.21684
Epoch 94, Val Loss: 86.88180
Epoch 95, Val Loss: 90.92642
Epoch 96, Val Loss: 83.78621
Epoch 97, Val Loss: 85.74825
Epoch 98, Val Loss: 83.37029
Epoch 99, Val Loss: 88.82692
DID NOT SAVE RESULTS
{'MSE - mean': 87.78725850715298, 'MSE - std': 0.0, 'R2 - mean': 0.4884344408291289, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1109.40930
Epoch 1, Val Loss: 406.26724
Epoch 2, Val Loss: 179.11084
Epoch 3, Val Loss: 144.08015
Epoch 4, Val Loss: 123.99141
Epoch 5, Val Loss: 125.31315
Epoch 6, Val Loss: 106.13198
Epoch 7, Val Loss: 114.56107
Epoch 8, Val Loss: 109.98962
Epoch 9, Val Loss: 120.05635
Epoch 10, Val Loss: 93.05116
Epoch 11, Val Loss: 90.86975
Epoch 12, Val Loss: 96.89198
Epoch 13, Val Loss: 90.97559
Epoch 14, Val Loss: 90.70445
Epoch 15, Val Loss: 81.00228
Epoch 16, Val Loss: 87.06121
Epoch 17, Val Loss: 87.71619
Epoch 18, Val Loss: 82.13036
Epoch 19, Val Loss: 84.52256
Epoch 20, Val Loss: 87.13496
Epoch 21, Val Loss: 89.49889
Epoch 22, Val Loss: 83.66588
Epoch 23, Val Loss: 87.91423
Epoch 24, Val Loss: 93.11665
Epoch 25, Val Loss: 89.62595
Epoch 26, Val Loss: 95.33661
Epoch 27, Val Loss: 86.70896
Epoch 28, Val Loss: 90.89007
Epoch 29, Val Loss: 81.15454
Epoch 30, Val Loss: 83.69923
Epoch 31, Val Loss: 79.36169
Epoch 32, Val Loss: 93.96624
Epoch 33, Val Loss: 88.80403
Epoch 34, Val Loss: 85.05692
Epoch 35, Val Loss: 82.10979
Epoch 36, Val Loss: 80.84094
Epoch 37, Val Loss: 90.74643
Epoch 38, Val Loss: 80.08286
Epoch 39, Val Loss: 88.21905
Epoch 40, Val Loss: 95.47369
Epoch 41, Val Loss: 79.94339
Epoch 42, Val Loss: 78.74059
Epoch 43, Val Loss: 79.86308
Epoch 44, Val Loss: 83.77948
Epoch 45, Val Loss: 77.33724
Epoch 46, Val Loss: 87.50002
Epoch 47, Val Loss: 77.17328
Epoch 48, Val Loss: 79.88261
Epoch 49, Val Loss: 93.79034
Epoch 50, Val Loss: 80.35105
Epoch 51, Val Loss: 77.78255
Epoch 52, Val Loss: 83.83495
Epoch 53, Val Loss: 89.69637
Epoch 54, Val Loss: 77.10936
Epoch 55, Val Loss: 74.19207
Epoch 56, Val Loss: 75.77627
Epoch 57, Val Loss: 73.43169
Epoch 58, Val Loss: 76.46396
Epoch 59, Val Loss: 72.16506
Epoch 60, Val Loss: 88.82733
Epoch 61, Val Loss: 75.69241
Epoch 62, Val Loss: 70.64409
Epoch 63, Val Loss: 73.07888
Epoch 64, Val Loss: 76.76823
Epoch 65, Val Loss: 76.48994
Epoch 66, Val Loss: 110.23800
Epoch 67, Val Loss: 94.68888
Epoch 68, Val Loss: 74.66970
Epoch 69, Val Loss: 89.04163
Epoch 70, Val Loss: 71.76067
Epoch 71, Val Loss: 83.44685
Epoch 72, Val Loss: 80.03970
Epoch 73, Val Loss: 74.13064
Epoch 74, Val Loss: 82.51991
Epoch 75, Val Loss: 73.31509
Epoch 76, Val Loss: 70.90923
Epoch 77, Val Loss: 69.69364
Epoch 78, Val Loss: 81.32269
Epoch 79, Val Loss: 98.63613
Epoch 80, Val Loss: 70.12910
Epoch 81, Val Loss: 74.63509
Epoch 82, Val Loss: 67.70804
Epoch 83, Val Loss: 70.87281
Epoch 84, Val Loss: 69.99685
Epoch 85, Val Loss: 77.65144
Epoch 86, Val Loss: 79.05199
Epoch 87, Val Loss: 73.37909
Epoch 88, Val Loss: 76.99953
Epoch 89, Val Loss: 71.69098
Epoch 90, Val Loss: 71.41522
Epoch 91, Val Loss: 76.87308
Epoch 92, Val Loss: 74.38298
Epoch 93, Val Loss: 76.64698
Epoch 94, Val Loss: 72.21400
Epoch 95, Val Loss: 71.19814
Epoch 96, Val Loss: 74.16490
Epoch 97, Val Loss: 70.85145
Epoch 98, Val Loss: 67.91938
Epoch 99, Val Loss: 71.20156
DID NOT SAVE RESULTS
{'MSE - mean': 81.36919644825886, 'MSE - std': 6.418062058894122, 'R2 - mean': 0.5051238295039553, 'R2 - std': 0.016689388674826444} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 731.13257
Epoch 1, Val Loss: 365.52155
Epoch 2, Val Loss: 139.94150
Epoch 3, Val Loss: 120.52022
Epoch 4, Val Loss: 107.70100
Epoch 5, Val Loss: 101.86268
Epoch 6, Val Loss: 94.72519
Epoch 7, Val Loss: 91.94117
Epoch 8, Val Loss: 101.91453
Epoch 9, Val Loss: 87.86259
Epoch 10, Val Loss: 87.87367
Epoch 11, Val Loss: 85.37064
Epoch 12, Val Loss: 81.25740
Epoch 13, Val Loss: 84.80083
Epoch 14, Val Loss: 82.71541
Epoch 15, Val Loss: 98.35956
Epoch 16, Val Loss: 89.33779
Epoch 17, Val Loss: 85.30367
Epoch 18, Val Loss: 83.37190
Epoch 19, Val Loss: 89.97908
Epoch 20, Val Loss: 102.40866
Epoch 21, Val Loss: 85.87904
Epoch 22, Val Loss: 87.47632
Epoch 23, Val Loss: 87.77624
Epoch 24, Val Loss: 87.06181
Epoch 25, Val Loss: 84.62375
Epoch 26, Val Loss: 83.28275
Epoch 27, Val Loss: 80.92244
Epoch 28, Val Loss: 88.09000
Epoch 29, Val Loss: 78.36892
Epoch 30, Val Loss: 81.35757
Epoch 31, Val Loss: 89.47628
Epoch 32, Val Loss: 78.78936
Epoch 33, Val Loss: 82.19131
Epoch 34, Val Loss: 78.43962
Epoch 35, Val Loss: 86.76305
Epoch 36, Val Loss: 82.03622
Epoch 37, Val Loss: 80.58754
Epoch 38, Val Loss: 83.62861
Epoch 39, Val Loss: 76.86710
Epoch 40, Val Loss: 83.63817
Epoch 41, Val Loss: 76.74328
Epoch 42, Val Loss: 76.10416
Epoch 43, Val Loss: 75.27389
Epoch 44, Val Loss: 75.11229
Epoch 45, Val Loss: 78.71642
Epoch 46, Val Loss: 76.94208
Epoch 47, Val Loss: 83.40014
Epoch 48, Val Loss: 76.35796
Epoch 49, Val Loss: 73.59780
Epoch 50, Val Loss: 74.67394
Epoch 51, Val Loss: 78.43832
Epoch 52, Val Loss: 81.33818
Epoch 53, Val Loss: 74.87241
Epoch 54, Val Loss: 81.13733
Epoch 55, Val Loss: 72.88400
Epoch 56, Val Loss: 81.60410
Epoch 57, Val Loss: 76.91292
Epoch 58, Val Loss: 73.56507
Epoch 59, Val Loss: 76.29884
Epoch 60, Val Loss: 85.37610
Epoch 61, Val Loss: 71.39110
Epoch 62, Val Loss: 78.85702
Epoch 63, Val Loss: 71.24429
Epoch 64, Val Loss: 74.55323
Epoch 65, Val Loss: 93.46448
Epoch 66, Val Loss: 79.03901
Epoch 67, Val Loss: 73.22993
Epoch 68, Val Loss: 80.51801
Epoch 69, Val Loss: 70.50484
Epoch 70, Val Loss: 73.78891
Epoch 71, Val Loss: 73.62613
Epoch 72, Val Loss: 82.91422
Epoch 73, Val Loss: 70.62145
Epoch 74, Val Loss: 70.63762
Epoch 75, Val Loss: 92.62681
Epoch 76, Val Loss: 75.04264
Epoch 77, Val Loss: 72.39478
Epoch 78, Val Loss: 83.57361
Epoch 79, Val Loss: 72.08609
Epoch 80, Val Loss: 71.75858
Epoch 81, Val Loss: 72.55379
Epoch 82, Val Loss: 72.08147
Epoch 83, Val Loss: 76.30865
Epoch 84, Val Loss: 75.95442
Epoch 85, Val Loss: 71.25427
Epoch 86, Val Loss: 71.92922
Epoch 87, Val Loss: 70.42348
Epoch 88, Val Loss: 70.63104
Epoch 89, Val Loss: 72.18809
Epoch 90, Val Loss: 67.60578
Epoch 91, Val Loss: 72.64149
Epoch 92, Val Loss: 69.59956
Epoch 93, Val Loss: 74.02898
Epoch 94, Val Loss: 70.39203
Epoch 95, Val Loss: 74.08350
Epoch 96, Val Loss: 74.33054
Epoch 97, Val Loss: 71.63817
Epoch 98, Val Loss: 75.39694
Epoch 99, Val Loss: 77.41278
DID NOT SAVE RESULTS
{'MSE - mean': 76.92522526212022, 'MSE - std': 8.182834077160459, 'R2 - mean': 0.5176536820422238, 'R2 - std': 0.022353632191535605} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 818.51282
Epoch 1, Val Loss: 429.51013
Epoch 2, Val Loss: 162.66681
Epoch 3, Val Loss: 136.57353
Epoch 4, Val Loss: 137.92186
Epoch 5, Val Loss: 126.63971
Epoch 6, Val Loss: 112.43584
Epoch 7, Val Loss: 108.76444
Epoch 8, Val Loss: 103.26593
Epoch 9, Val Loss: 100.75746
Epoch 10, Val Loss: 104.50484
Epoch 11, Val Loss: 96.60458
Epoch 12, Val Loss: 97.58142
Epoch 13, Val Loss: 100.73904
Epoch 14, Val Loss: 90.88360
Epoch 15, Val Loss: 102.38707
Epoch 16, Val Loss: 97.57608
Epoch 17, Val Loss: 90.96622
Epoch 18, Val Loss: 104.24461
Epoch 19, Val Loss: 89.41175
Epoch 20, Val Loss: 92.08791
Epoch 21, Val Loss: 92.20507
Epoch 22, Val Loss: 100.78881
Epoch 23, Val Loss: 89.63808
Epoch 24, Val Loss: 90.35498
Epoch 25, Val Loss: 94.55363
Epoch 26, Val Loss: 91.32449
Epoch 27, Val Loss: 91.20619
Epoch 28, Val Loss: 94.45425
Epoch 29, Val Loss: 102.95930
Epoch 30, Val Loss: 93.86824
Epoch 31, Val Loss: 103.77261
Epoch 32, Val Loss: 109.32925
Epoch 33, Val Loss: 94.66504
Epoch 34, Val Loss: 88.23654
Epoch 35, Val Loss: 92.13081
Epoch 36, Val Loss: 88.18742
Epoch 37, Val Loss: 86.51881
Epoch 38, Val Loss: 91.42668
Epoch 39, Val Loss: 96.46762
Epoch 40, Val Loss: 89.93929
Epoch 41, Val Loss: 90.40808
Epoch 42, Val Loss: 90.27159
Epoch 43, Val Loss: 92.27587
Epoch 44, Val Loss: 88.62199
Epoch 45, Val Loss: 94.14433
Epoch 46, Val Loss: 85.61628
Epoch 47, Val Loss: 107.03674
Epoch 48, Val Loss: 83.68491
Epoch 49, Val Loss: 84.62540
Epoch 50, Val Loss: 92.37326
Epoch 51, Val Loss: 86.56907
Epoch 52, Val Loss: 92.91666
Epoch 53, Val Loss: 90.87649
Epoch 54, Val Loss: 82.01759
Epoch 55, Val Loss: 84.16589
Epoch 56, Val Loss: 84.08193
Epoch 57, Val Loss: 88.88635
Epoch 58, Val Loss: 78.83620
Epoch 59, Val Loss: 81.41362
Epoch 60, Val Loss: 81.04027
Epoch 61, Val Loss: 85.63001
Epoch 62, Val Loss: 83.38146
Epoch 63, Val Loss: 80.06490
Epoch 64, Val Loss: 80.76759
Epoch 65, Val Loss: 81.03903
Epoch 66, Val Loss: 84.05154
Epoch 67, Val Loss: 84.85567
Epoch 68, Val Loss: 81.67467
Epoch 69, Val Loss: 80.92970
Epoch 70, Val Loss: 80.37457
Epoch 71, Val Loss: 88.36702
Epoch 72, Val Loss: 88.92941
Epoch 73, Val Loss: 80.23695
Epoch 74, Val Loss: 84.37968
Epoch 75, Val Loss: 86.23692
Epoch 76, Val Loss: 80.66541
Epoch 77, Val Loss: 79.88888
Epoch 78, Val Loss: 80.84148
Epoch 79, Val Loss: 80.77465
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.91288538773426, 'MSE - std': 8.774817333101932, 'R2 - mean': 0.5050889428489258, 'R2 - std': 0.02912699207097506} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1193.19556
Epoch 1, Val Loss: 439.99756
Epoch 2, Val Loss: 152.02817
Epoch 3, Val Loss: 138.90405
Epoch 4, Val Loss: 112.47502
Epoch 5, Val Loss: 106.22304
Epoch 6, Val Loss: 108.27762
Epoch 7, Val Loss: 104.35445
Epoch 8, Val Loss: 105.56307
Epoch 9, Val Loss: 89.31546
Epoch 10, Val Loss: 96.59346
Epoch 11, Val Loss: 89.90720
Epoch 12, Val Loss: 102.19971
Epoch 13, Val Loss: 90.98367
Epoch 14, Val Loss: 97.55579
Epoch 15, Val Loss: 95.83000
Epoch 16, Val Loss: 92.23467
Epoch 17, Val Loss: 82.60091
Epoch 18, Val Loss: 94.60284
Epoch 19, Val Loss: 82.74693
Epoch 20, Val Loss: 81.13508
Epoch 21, Val Loss: 84.67372
Epoch 22, Val Loss: 84.34272
Epoch 23, Val Loss: 88.23531
Epoch 24, Val Loss: 86.35076
Epoch 25, Val Loss: 86.09466
Epoch 26, Val Loss: 84.38496
Epoch 27, Val Loss: 97.30002
Epoch 28, Val Loss: 87.16998
Epoch 29, Val Loss: 81.93446
Epoch 30, Val Loss: 89.64233
Epoch 31, Val Loss: 94.82986
Epoch 32, Val Loss: 93.98693
Epoch 33, Val Loss: 91.29506
Epoch 34, Val Loss: 84.75258
Epoch 35, Val Loss: 87.59505
Epoch 36, Val Loss: 81.05203
Epoch 37, Val Loss: 98.90922
Epoch 38, Val Loss: 82.95580
Epoch 39, Val Loss: 92.00883
Epoch 40, Val Loss: 100.22390
Epoch 41, Val Loss: 85.02646
Epoch 42, Val Loss: 81.15909
Epoch 43, Val Loss: 82.88930
Epoch 44, Val Loss: 82.31546
Epoch 45, Val Loss: 97.94338
Epoch 46, Val Loss: 89.13488
Epoch 47, Val Loss: 80.71291
Epoch 48, Val Loss: 84.94138
Epoch 49, Val Loss: 79.47968
Epoch 50, Val Loss: 76.05399
Epoch 51, Val Loss: 97.60302
Epoch 52, Val Loss: 77.27925
Epoch 53, Val Loss: 76.69070
Epoch 54, Val Loss: 79.88234
Epoch 55, Val Loss: 85.53674
Epoch 56, Val Loss: 78.26921
Epoch 57, Val Loss: 84.21173
Epoch 58, Val Loss: 80.26876
Epoch 59, Val Loss: 82.20066
Epoch 60, Val Loss: 80.21164
Epoch 61, Val Loss: 79.41775
Epoch 62, Val Loss: 77.59830
Epoch 63, Val Loss: 90.45490
Epoch 64, Val Loss: 83.32071
Epoch 65, Val Loss: 80.82690
Epoch 66, Val Loss: 89.95902
Epoch 67, Val Loss: 73.82171
Epoch 68, Val Loss: 79.25367
Epoch 69, Val Loss: 83.63998
Epoch 70, Val Loss: 79.04817
Epoch 71, Val Loss: 78.69202
Epoch 72, Val Loss: 75.86732
Epoch 73, Val Loss: 81.62104
Epoch 74, Val Loss: 80.92778
Epoch 75, Val Loss: 84.14742
Epoch 76, Val Loss: 85.28713
Epoch 77, Val Loss: 79.93624
Epoch 78, Val Loss: 77.94017
Epoch 79, Val Loss: 79.91919
Epoch 80, Val Loss: 79.60307
Epoch 81, Val Loss: 72.00247
Epoch 82, Val Loss: 74.24837
Epoch 83, Val Loss: 77.56078
Epoch 84, Val Loss: 72.55167
Epoch 85, Val Loss: 77.12492
Epoch 86, Val Loss: 74.76620
Epoch 87, Val Loss: 75.85577
Epoch 88, Val Loss: 72.27779
Epoch 89, Val Loss: 75.14676
Epoch 90, Val Loss: 74.05787
Epoch 91, Val Loss: 75.24496
Epoch 92, Val Loss: 74.64769
Epoch 93, Val Loss: 75.61993
Epoch 94, Val Loss: 72.60355
Epoch 95, Val Loss: 71.76523
Epoch 96, Val Loss: 75.88132
Epoch 97, Val Loss: 78.84073
Epoch 98, Val Loss: 73.29842
Epoch 99, Val Loss: 72.49705
DID NOT SAVE RESULTS
{'MSE - mean': 78.5257921896197, 'MSE - std': 8.324304508153684, 'R2 - mean': 0.5125352815625168, 'R2 - std': 0.030008285099822184} 
 

Results After CV: {'MSE - mean': 78.5257921896197, 'MSE - std': 8.324304508153684, 'R2 - mean': 0.5125352815625168, 'R2 - std': 0.030008285099822184}
Train time: 916.0574181371951
Inference time: 0.17927210919442588
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 44 finished with value: 78.5257921896197 and parameters: {'p_m': 0.18640301674422807, 'alpha': 8.814152206382783, 'K': 5, 'beta': 5.390662532328541}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1550.97534
Epoch 1, Val Loss: 415.49655
Epoch 2, Val Loss: 162.75226
Epoch 3, Val Loss: 144.88831
Epoch 4, Val Loss: 150.45639
Epoch 5, Val Loss: 153.85793
Epoch 6, Val Loss: 115.12775
Epoch 7, Val Loss: 116.54924
Epoch 8, Val Loss: 112.83239
Epoch 9, Val Loss: 105.68762
Epoch 10, Val Loss: 104.13850
Epoch 11, Val Loss: 108.00655
Epoch 12, Val Loss: 96.19016
Epoch 13, Val Loss: 100.80743
Epoch 14, Val Loss: 98.28654
Epoch 15, Val Loss: 103.82896
Epoch 16, Val Loss: 100.75774
Epoch 17, Val Loss: 97.26253
Epoch 18, Val Loss: 93.88882
Epoch 19, Val Loss: 104.04490
Epoch 20, Val Loss: 99.39874
Epoch 21, Val Loss: 113.42645
Epoch 22, Val Loss: 101.47442
Epoch 23, Val Loss: 94.09517
Epoch 24, Val Loss: 92.65633
Epoch 25, Val Loss: 103.38199
Epoch 26, Val Loss: 106.79984
Epoch 27, Val Loss: 98.24710
Epoch 28, Val Loss: 97.43182
Epoch 29, Val Loss: 125.58485
Epoch 30, Val Loss: 111.11269
Epoch 31, Val Loss: 94.93471
Epoch 32, Val Loss: 100.37820
Epoch 33, Val Loss: 96.34599
Epoch 34, Val Loss: 93.43044
Epoch 35, Val Loss: 96.38924
Epoch 36, Val Loss: 96.25903
Epoch 37, Val Loss: 93.56732
Epoch 38, Val Loss: 91.71297
Epoch 39, Val Loss: 104.30843
Epoch 40, Val Loss: 100.31297
Epoch 41, Val Loss: 99.79996
Epoch 42, Val Loss: 94.61951
Epoch 43, Val Loss: 103.57919
Epoch 44, Val Loss: 102.90511
Epoch 45, Val Loss: 97.70967
Epoch 46, Val Loss: 93.81868
Epoch 47, Val Loss: 95.59061
Epoch 48, Val Loss: 90.92056
Epoch 49, Val Loss: 98.42223
Epoch 50, Val Loss: 94.61671
Epoch 51, Val Loss: 95.29601
Epoch 52, Val Loss: 107.10031
Epoch 53, Val Loss: 97.71114
Epoch 54, Val Loss: 96.78954
Epoch 55, Val Loss: 90.56038
Epoch 56, Val Loss: 90.30132
Epoch 57, Val Loss: 95.22309
Epoch 58, Val Loss: 94.36548
Epoch 59, Val Loss: 103.12561
Epoch 60, Val Loss: 100.64875
Epoch 61, Val Loss: 91.32170
Epoch 62, Val Loss: 88.39184
Epoch 63, Val Loss: 94.19698
Epoch 64, Val Loss: 91.55908
Epoch 65, Val Loss: 90.68916
Epoch 66, Val Loss: 98.87145
Epoch 67, Val Loss: 89.60056
Epoch 68, Val Loss: 89.84424
Epoch 69, Val Loss: 90.04721
Epoch 70, Val Loss: 88.51455
Epoch 71, Val Loss: 101.80985
Epoch 72, Val Loss: 84.39494
Epoch 73, Val Loss: 88.47425
Epoch 74, Val Loss: 88.07296
Epoch 75, Val Loss: 92.61523
Epoch 76, Val Loss: 82.23700
Epoch 77, Val Loss: 90.10648
Epoch 78, Val Loss: 88.58145
Epoch 79, Val Loss: 89.50670
Epoch 80, Val Loss: 87.65450
Epoch 81, Val Loss: 89.50771
Epoch 82, Val Loss: 102.77882
Epoch 83, Val Loss: 87.17970
Epoch 84, Val Loss: 85.81108
Epoch 85, Val Loss: 86.27860
Epoch 86, Val Loss: 88.90386
Epoch 87, Val Loss: 90.51770
Epoch 88, Val Loss: 92.39048
Epoch 89, Val Loss: 87.02747
Epoch 90, Val Loss: 86.81258
Epoch 91, Val Loss: 86.80981
Epoch 92, Val Loss: 81.29701
Epoch 93, Val Loss: 87.11394
Epoch 94, Val Loss: 91.66143
Epoch 95, Val Loss: 87.66293
Epoch 96, Val Loss: 82.45870
Epoch 97, Val Loss: 81.99562
Epoch 98, Val Loss: 88.05023
Epoch 99, Val Loss: 82.80619
DID NOT SAVE RESULTS
{'MSE - mean': 84.21893168069334, 'MSE - std': 0.0, 'R2 - mean': 0.5092282683084722, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1066.05115
Epoch 1, Val Loss: 401.13324
Epoch 2, Val Loss: 145.49603
Epoch 3, Val Loss: 127.77396
Epoch 4, Val Loss: 114.35047
Epoch 5, Val Loss: 104.04144
Epoch 6, Val Loss: 97.13730
Epoch 7, Val Loss: 91.07955
Epoch 8, Val Loss: 92.72820
Epoch 9, Val Loss: 90.62945
Epoch 10, Val Loss: 83.74939
Epoch 11, Val Loss: 87.92702
Epoch 12, Val Loss: 94.09445
Epoch 13, Val Loss: 83.73955
Epoch 14, Val Loss: 85.72821
Epoch 15, Val Loss: 87.26543
Epoch 16, Val Loss: 99.38333
Epoch 17, Val Loss: 103.59460
Epoch 18, Val Loss: 83.17548
Epoch 19, Val Loss: 83.34681
Epoch 20, Val Loss: 89.58012
Epoch 21, Val Loss: 89.60995
Epoch 22, Val Loss: 79.63378
Epoch 23, Val Loss: 83.55247
Epoch 24, Val Loss: 76.88791
Epoch 25, Val Loss: 95.35873
Epoch 26, Val Loss: 89.31057
Epoch 27, Val Loss: 94.56786
Epoch 28, Val Loss: 82.05873
Epoch 29, Val Loss: 77.92542
Epoch 30, Val Loss: 81.52762
Epoch 31, Val Loss: 83.47946
Epoch 32, Val Loss: 82.56843
Epoch 33, Val Loss: 80.96900
Epoch 34, Val Loss: 84.29306
Epoch 35, Val Loss: 91.46066
Epoch 36, Val Loss: 76.86961
Epoch 37, Val Loss: 91.87881
Epoch 38, Val Loss: 73.85244
Epoch 39, Val Loss: 79.94337
Epoch 40, Val Loss: 86.33820
Epoch 41, Val Loss: 82.35736
Epoch 42, Val Loss: 76.23769
Epoch 43, Val Loss: 81.93601
Epoch 44, Val Loss: 90.90536
Epoch 45, Val Loss: 79.63861
Epoch 46, Val Loss: 71.04780
Epoch 47, Val Loss: 78.31019
Epoch 48, Val Loss: 75.07775
Epoch 49, Val Loss: 72.66008
Epoch 50, Val Loss: 75.21793
Epoch 51, Val Loss: 90.03008
Epoch 52, Val Loss: 75.99450
Epoch 53, Val Loss: 83.84323
Epoch 54, Val Loss: 71.63251
Epoch 55, Val Loss: 86.61829
Epoch 56, Val Loss: 75.56694
Epoch 57, Val Loss: 70.63807
Epoch 58, Val Loss: 74.60086
Epoch 59, Val Loss: 69.86907
Epoch 60, Val Loss: 77.58484
Epoch 61, Val Loss: 76.43904
Epoch 62, Val Loss: 94.85177
Epoch 63, Val Loss: 82.42546
Epoch 64, Val Loss: 69.81123
Epoch 65, Val Loss: 71.15872
Epoch 66, Val Loss: 71.67793
Epoch 67, Val Loss: 69.66422
Epoch 68, Val Loss: 70.83942
Epoch 69, Val Loss: 73.21566
Epoch 70, Val Loss: 82.83319
Epoch 71, Val Loss: 75.68317
Epoch 72, Val Loss: 77.20378
Epoch 73, Val Loss: 69.73395
Epoch 74, Val Loss: 71.64639
Epoch 75, Val Loss: 69.13820
Epoch 76, Val Loss: 68.25453
Epoch 77, Val Loss: 70.53669
Epoch 78, Val Loss: 69.16195
Epoch 79, Val Loss: 87.61874
Epoch 80, Val Loss: 69.22703
Epoch 81, Val Loss: 67.35506
Epoch 82, Val Loss: 71.16695
Epoch 83, Val Loss: 81.45128
Epoch 84, Val Loss: 69.67509
Epoch 85, Val Loss: 70.85478
Epoch 86, Val Loss: 73.73684
Epoch 87, Val Loss: 68.14610
Epoch 88, Val Loss: 69.61448
Epoch 89, Val Loss: 69.04095
Epoch 90, Val Loss: 71.60522
Epoch 91, Val Loss: 74.67965
Epoch 92, Val Loss: 69.64600
Epoch 93, Val Loss: 67.01891
Epoch 94, Val Loss: 82.79214
Epoch 95, Val Loss: 66.88143
Epoch 96, Val Loss: 71.62105
Epoch 97, Val Loss: 68.02469
Epoch 98, Val Loss: 66.78928
Epoch 99, Val Loss: 80.35200
DID NOT SAVE RESULTS
{'MSE - mean': 79.99745491412008, 'MSE - std': 4.221476766573261, 'R2 - mean': 0.5128894996644345, 'R2 - std': 0.003661231355962302} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 786.45294
Epoch 1, Val Loss: 410.85321
Epoch 2, Val Loss: 159.57095
Epoch 3, Val Loss: 134.63133
Epoch 4, Val Loss: 109.94668
Epoch 5, Val Loss: 105.41156
Epoch 6, Val Loss: 97.93629
Epoch 7, Val Loss: 90.62204
Epoch 8, Val Loss: 92.45938
Epoch 9, Val Loss: 87.40562
Epoch 10, Val Loss: 81.56747
Epoch 11, Val Loss: 83.26057
Epoch 12, Val Loss: 79.88414
Epoch 13, Val Loss: 76.64500
Epoch 14, Val Loss: 79.00118
Epoch 15, Val Loss: 90.02530
Epoch 16, Val Loss: 75.32407
Epoch 17, Val Loss: 78.13455
Epoch 18, Val Loss: 91.78589
Epoch 19, Val Loss: 74.85442
Epoch 20, Val Loss: 84.94835
Epoch 21, Val Loss: 74.66298
Epoch 22, Val Loss: 85.37701
Epoch 23, Val Loss: 78.34582
Epoch 24, Val Loss: 76.73162
Epoch 25, Val Loss: 82.92586
Epoch 26, Val Loss: 86.71580
Epoch 27, Val Loss: 74.77743
Epoch 28, Val Loss: 73.60287
Epoch 29, Val Loss: 91.09737
Epoch 30, Val Loss: 79.93063
Epoch 31, Val Loss: 80.85193
Epoch 32, Val Loss: 73.96435
Epoch 33, Val Loss: 78.46946
Epoch 34, Val Loss: 89.31976
Epoch 35, Val Loss: 82.83306
Epoch 36, Val Loss: 81.03416
Epoch 37, Val Loss: 84.54167
Epoch 38, Val Loss: 95.50237
Epoch 39, Val Loss: 80.23605
Epoch 40, Val Loss: 79.37360
Epoch 41, Val Loss: 96.67025
Epoch 42, Val Loss: 73.66953
Epoch 43, Val Loss: 80.78082
Epoch 44, Val Loss: 81.75669
Epoch 45, Val Loss: 84.23803
Epoch 46, Val Loss: 89.98172
Epoch 47, Val Loss: 85.98962
Epoch 48, Val Loss: 70.57147
Epoch 49, Val Loss: 80.16159
Epoch 50, Val Loss: 72.03796
Epoch 51, Val Loss: 71.11646
Epoch 52, Val Loss: 72.96072
Epoch 53, Val Loss: 71.19166
Epoch 54, Val Loss: 73.16244
Epoch 55, Val Loss: 78.22684
Epoch 56, Val Loss: 71.96712
Epoch 57, Val Loss: 77.99107
Epoch 58, Val Loss: 90.54057
Epoch 59, Val Loss: 77.34016
Epoch 60, Val Loss: 74.77795
Epoch 61, Val Loss: 76.15646
Epoch 62, Val Loss: 71.19622
Epoch 63, Val Loss: 80.86357
Epoch 64, Val Loss: 74.92630
Epoch 65, Val Loss: 72.45512
Epoch 66, Val Loss: 76.97557
Epoch 67, Val Loss: 69.69392
Epoch 68, Val Loss: 77.36570
Epoch 69, Val Loss: 73.26905
Epoch 70, Val Loss: 74.41321
Epoch 71, Val Loss: 68.40491
Epoch 72, Val Loss: 71.86665
Epoch 73, Val Loss: 72.31244
Epoch 74, Val Loss: 71.74210
Epoch 75, Val Loss: 74.04416
Epoch 76, Val Loss: 76.05109
Epoch 77, Val Loss: 73.83314
Epoch 78, Val Loss: 85.42375
Epoch 79, Val Loss: 71.88519
Epoch 80, Val Loss: 68.82068
Epoch 81, Val Loss: 69.81528
Epoch 82, Val Loss: 72.43112
Epoch 83, Val Loss: 91.02240
Epoch 84, Val Loss: 70.14716
Epoch 85, Val Loss: 68.27039
Epoch 86, Val Loss: 69.00253
Epoch 87, Val Loss: 76.49886
Epoch 88, Val Loss: 72.49869
Epoch 89, Val Loss: 69.16488
Epoch 90, Val Loss: 68.63515
Epoch 91, Val Loss: 75.91914
Epoch 92, Val Loss: 68.68462
Epoch 93, Val Loss: 74.31555
Epoch 94, Val Loss: 71.23848
Epoch 95, Val Loss: 73.61131
Epoch 96, Val Loss: 71.77512
Epoch 97, Val Loss: 70.37273
Epoch 98, Val Loss: 68.75270
Epoch 99, Val Loss: 73.52161
DID NOT SAVE RESULTS
{'MSE - mean': 76.23302659137634, 'MSE - std': 6.342114677925846, 'R2 - mean': 0.5213367199302351, 'R2 - std': 0.012314522746165353} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1044.22485
Epoch 1, Val Loss: 486.35391
Epoch 2, Val Loss: 149.01779
Epoch 3, Val Loss: 143.46072
Epoch 4, Val Loss: 135.10852
Epoch 5, Val Loss: 120.69395
Epoch 6, Val Loss: 113.00988
Epoch 7, Val Loss: 103.00526
Epoch 8, Val Loss: 102.07040
Epoch 9, Val Loss: 101.41513
Epoch 10, Val Loss: 102.36867
Epoch 11, Val Loss: 100.41484
Epoch 12, Val Loss: 99.03316
Epoch 13, Val Loss: 95.92295
Epoch 14, Val Loss: 91.23885
Epoch 15, Val Loss: 89.08900
Epoch 16, Val Loss: 88.96749
Epoch 17, Val Loss: 91.73978
Epoch 18, Val Loss: 104.17064
Epoch 19, Val Loss: 92.57468
Epoch 20, Val Loss: 101.13589
Epoch 21, Val Loss: 96.10242
Epoch 22, Val Loss: 89.26741
Epoch 23, Val Loss: 85.20782
Epoch 24, Val Loss: 86.22928
Epoch 25, Val Loss: 93.18172
Epoch 26, Val Loss: 87.15885
Epoch 27, Val Loss: 85.22423
Epoch 28, Val Loss: 102.32803
Epoch 29, Val Loss: 87.53246
Epoch 30, Val Loss: 93.51355
Epoch 31, Val Loss: 93.76444
Epoch 32, Val Loss: 87.95522
Epoch 33, Val Loss: 86.94061
Epoch 34, Val Loss: 87.77776
Epoch 35, Val Loss: 89.29219
Epoch 36, Val Loss: 88.15060
Epoch 37, Val Loss: 87.54456
Epoch 38, Val Loss: 91.60169
Epoch 39, Val Loss: 84.51975
Epoch 40, Val Loss: 84.83250
Epoch 41, Val Loss: 83.19725
Epoch 42, Val Loss: 85.67312
Epoch 43, Val Loss: 97.69452
Epoch 44, Val Loss: 98.15128
Epoch 45, Val Loss: 87.91934
Epoch 46, Val Loss: 102.74628
Epoch 47, Val Loss: 93.32065
Epoch 48, Val Loss: 82.71362
Epoch 49, Val Loss: 89.78002
Epoch 50, Val Loss: 88.83389
Epoch 51, Val Loss: 83.13768
Epoch 52, Val Loss: 82.26974
Epoch 53, Val Loss: 87.92863
Epoch 54, Val Loss: 79.83508
Epoch 55, Val Loss: 87.57731
Epoch 56, Val Loss: 84.44908
Epoch 57, Val Loss: 81.29110
Epoch 58, Val Loss: 81.60543
Epoch 59, Val Loss: 86.71879
Epoch 60, Val Loss: 83.22173
Epoch 61, Val Loss: 85.07693
Epoch 62, Val Loss: 83.07841
Epoch 63, Val Loss: 84.58935
Epoch 64, Val Loss: 77.08707
Epoch 65, Val Loss: 82.63537
Epoch 66, Val Loss: 83.13675
Epoch 67, Val Loss: 79.13190
Epoch 68, Val Loss: 81.52320
Epoch 69, Val Loss: 81.87053
Epoch 70, Val Loss: 78.33733
Epoch 71, Val Loss: 82.78598
Epoch 72, Val Loss: 81.14886
Epoch 73, Val Loss: 91.36607
Epoch 74, Val Loss: 81.23458
Epoch 75, Val Loss: 79.07803
Epoch 76, Val Loss: 77.68074
Epoch 77, Val Loss: 86.00959
Epoch 78, Val Loss: 84.17426
Epoch 79, Val Loss: 81.53945
Epoch 80, Val Loss: 77.43332
Epoch 81, Val Loss: 84.82561
Epoch 82, Val Loss: 85.86420
Epoch 83, Val Loss: 77.94300
Epoch 84, Val Loss: 78.15293
Epoch 85, Val Loss: 78.10735
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.15028167896949, 'MSE - std': 7.463105632324676, 'R2 - mean': 0.5093101691953096, 'R2 - std': 0.023401909550047} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 814.04895
Epoch 1, Val Loss: 385.16803
Epoch 2, Val Loss: 224.26950
Epoch 3, Val Loss: 151.19859
Epoch 4, Val Loss: 129.14636
Epoch 5, Val Loss: 106.23814
Epoch 6, Val Loss: 95.02904
Epoch 7, Val Loss: 106.61899
Epoch 8, Val Loss: 108.63539
Epoch 9, Val Loss: 85.50961
Epoch 10, Val Loss: 87.03757
Epoch 11, Val Loss: 100.55526
Epoch 12, Val Loss: 89.01556
Epoch 13, Val Loss: 95.93509
Epoch 14, Val Loss: 98.93658
Epoch 15, Val Loss: 91.53844
Epoch 16, Val Loss: 101.36258
Epoch 17, Val Loss: 86.32586
Epoch 18, Val Loss: 97.47586
Epoch 19, Val Loss: 100.03757
Epoch 20, Val Loss: 95.03858
Epoch 21, Val Loss: 112.06461
Epoch 22, Val Loss: 107.86286
Epoch 23, Val Loss: 95.90919
Epoch 24, Val Loss: 95.68800
Epoch 25, Val Loss: 99.11278
Epoch 26, Val Loss: 89.93911
Epoch 27, Val Loss: 93.70638
Epoch 28, Val Loss: 91.94292
Epoch 29, Val Loss: 94.51926
Epoch 30, Val Loss: 94.29726
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.52719183459615, 'MSE - std': 7.2209336550103025, 'R2 - mean': 0.4995342965545464, 'R2 - std': 0.028642455202453485} 
 

Results After CV: {'MSE - mean': 80.52719183459615, 'MSE - std': 7.2209336550103025, 'R2 - mean': 0.4995342965545464, 'R2 - std': 0.028642455202453485}
Train time: 880.7216008075978
Inference time: 0.18341772779240273
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 45 finished with value: 80.52719183459615 and parameters: {'p_m': 0.12072849266114483, 'alpha': 5.298572246507653, 'K': 5, 'beta': 7.62883505686391}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1121.68250
Epoch 1, Val Loss: 401.51602
Epoch 2, Val Loss: 152.62517
Epoch 3, Val Loss: 147.83536
Epoch 4, Val Loss: 129.55386
Epoch 5, Val Loss: 126.29756
Epoch 6, Val Loss: 116.34601
Epoch 7, Val Loss: 107.65347
Epoch 8, Val Loss: 117.74426
Epoch 9, Val Loss: 109.96712
Epoch 10, Val Loss: 100.33736
Epoch 11, Val Loss: 104.46973
Epoch 12, Val Loss: 104.15364
Epoch 13, Val Loss: 98.77541
Epoch 14, Val Loss: 110.14305
Epoch 15, Val Loss: 96.10310
Epoch 16, Val Loss: 105.07831
Epoch 17, Val Loss: 99.87335
Epoch 18, Val Loss: 101.15517
Epoch 19, Val Loss: 102.41952
Epoch 20, Val Loss: 101.48358
Epoch 21, Val Loss: 102.38554
Epoch 22, Val Loss: 102.93359
Epoch 23, Val Loss: 108.89127
Epoch 24, Val Loss: 109.08559
Epoch 25, Val Loss: 104.11298
Epoch 26, Val Loss: 99.18073
Epoch 27, Val Loss: 103.35696
Epoch 28, Val Loss: 101.90751
Epoch 29, Val Loss: 101.13863
Epoch 30, Val Loss: 108.86062
Epoch 31, Val Loss: 102.31023
Epoch 32, Val Loss: 102.70370
Epoch 33, Val Loss: 130.25890
Epoch 34, Val Loss: 98.88153
Epoch 35, Val Loss: 107.10414
Epoch 36, Val Loss: 91.48493
Epoch 37, Val Loss: 94.21907
Epoch 38, Val Loss: 100.27954
Epoch 39, Val Loss: 99.63870
Epoch 40, Val Loss: 92.69958
Epoch 41, Val Loss: 94.90958
Epoch 42, Val Loss: 96.37095
Epoch 43, Val Loss: 86.80545
Epoch 44, Val Loss: 90.47723
Epoch 45, Val Loss: 98.20625
Epoch 46, Val Loss: 94.53223
Epoch 47, Val Loss: 92.38759
Epoch 48, Val Loss: 89.62345
Epoch 49, Val Loss: 89.05511
Epoch 50, Val Loss: 87.85414
Epoch 51, Val Loss: 90.80952
Epoch 52, Val Loss: 89.45586
Epoch 53, Val Loss: 90.91769
Epoch 54, Val Loss: 95.68675
Epoch 55, Val Loss: 97.90360
Epoch 56, Val Loss: 91.35270
Epoch 57, Val Loss: 95.95448
Epoch 58, Val Loss: 100.72110
Epoch 59, Val Loss: 93.89736
Epoch 60, Val Loss: 92.05908
Epoch 61, Val Loss: 100.02248
Epoch 62, Val Loss: 88.54317
Epoch 63, Val Loss: 93.44876
Epoch 64, Val Loss: 88.44744
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 90.74858000763368, 'MSE - std': 0.0, 'R2 - mean': 0.4711778353143925, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 506.70557
Epoch 1, Val Loss: 274.44226
Epoch 2, Val Loss: 141.94830
Epoch 3, Val Loss: 120.80519
Epoch 4, Val Loss: 109.06338
Epoch 5, Val Loss: 107.63435
Epoch 6, Val Loss: 100.94076
Epoch 7, Val Loss: 108.58715
Epoch 8, Val Loss: 91.57629
Epoch 9, Val Loss: 91.34960
Epoch 10, Val Loss: 94.43835
Epoch 11, Val Loss: 84.45740
Epoch 12, Val Loss: 89.08808
Epoch 13, Val Loss: 83.97826
Epoch 14, Val Loss: 90.42551
Epoch 15, Val Loss: 89.38084
Epoch 16, Val Loss: 89.54822
Epoch 17, Val Loss: 91.73323
Epoch 18, Val Loss: 83.73814
Epoch 19, Val Loss: 87.17194
Epoch 20, Val Loss: 81.82175
Epoch 21, Val Loss: 80.25056
Epoch 22, Val Loss: 86.10117
Epoch 23, Val Loss: 84.35203
Epoch 24, Val Loss: 92.14308
Epoch 25, Val Loss: 86.40804
Epoch 26, Val Loss: 91.67303
Epoch 27, Val Loss: 90.85078
Epoch 28, Val Loss: 76.40726
Epoch 29, Val Loss: 76.77197
Epoch 30, Val Loss: 87.91977
Epoch 31, Val Loss: 81.61987
Epoch 32, Val Loss: 80.95260
Epoch 33, Val Loss: 77.64027
Epoch 34, Val Loss: 84.73961
Epoch 35, Val Loss: 96.38818
Epoch 36, Val Loss: 89.53542
Epoch 37, Val Loss: 80.54740
Epoch 38, Val Loss: 79.44248
Epoch 39, Val Loss: 82.82911
Epoch 40, Val Loss: 75.59593
Epoch 41, Val Loss: 86.89217
Epoch 42, Val Loss: 80.58751
Epoch 43, Val Loss: 74.94104
Epoch 44, Val Loss: 78.44755
Epoch 45, Val Loss: 80.35036
Epoch 46, Val Loss: 101.03615
Epoch 47, Val Loss: 79.81143
Epoch 48, Val Loss: 79.30408
Epoch 49, Val Loss: 74.10098
Epoch 50, Val Loss: 87.25026
Epoch 51, Val Loss: 76.81163
Epoch 52, Val Loss: 73.61757
Epoch 53, Val Loss: 74.25836
Epoch 54, Val Loss: 78.65376
Epoch 55, Val Loss: 73.12576
Epoch 56, Val Loss: 74.75408
Epoch 57, Val Loss: 106.05650
Epoch 58, Val Loss: 75.39145
Epoch 59, Val Loss: 73.07536
Epoch 60, Val Loss: 80.86382
Epoch 61, Val Loss: 83.91476
Epoch 62, Val Loss: 72.01704
Epoch 63, Val Loss: 77.79459
Epoch 64, Val Loss: 72.43097
Epoch 65, Val Loss: 77.35359
Epoch 66, Val Loss: 73.26984
Epoch 67, Val Loss: 72.89094
Epoch 68, Val Loss: 74.77885
Epoch 69, Val Loss: 78.39225
Epoch 70, Val Loss: 72.66497
Epoch 71, Val Loss: 73.39472
Epoch 72, Val Loss: 88.60107
Epoch 73, Val Loss: 79.67328
Epoch 74, Val Loss: 75.14172
Epoch 75, Val Loss: 70.69906
Epoch 76, Val Loss: 72.71373
Epoch 77, Val Loss: 72.23406
Epoch 78, Val Loss: 74.69731
Epoch 79, Val Loss: 76.19998
Epoch 80, Val Loss: 72.37126
Epoch 81, Val Loss: 75.39796
Epoch 82, Val Loss: 71.25632
Epoch 83, Val Loss: 75.77734
Epoch 84, Val Loss: 72.06485
Epoch 85, Val Loss: 67.62165
Epoch 86, Val Loss: 73.35529
Epoch 87, Val Loss: 73.95852
Epoch 88, Val Loss: 77.64604
Epoch 89, Val Loss: 78.27895
Epoch 90, Val Loss: 78.56908
Epoch 91, Val Loss: 73.81342
Epoch 92, Val Loss: 77.92336
Epoch 93, Val Loss: 71.55979
Epoch 94, Val Loss: 79.35976
Epoch 95, Val Loss: 71.02813
Epoch 96, Val Loss: 70.96646
Epoch 97, Val Loss: 75.74023
Epoch 98, Val Loss: 72.64955
Epoch 99, Val Loss: 80.20592
DID NOT SAVE RESULTS
{'MSE - mean': 83.24981606239024, 'MSE - std': 7.4987639452434465, 'R2 - mean': 0.4939437969623338, 'R2 - std': 0.022765961647941313} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 390.15222
Epoch 1, Val Loss: 243.50940
Epoch 2, Val Loss: 146.01569
Epoch 3, Val Loss: 120.01112
Epoch 4, Val Loss: 105.14557
Epoch 5, Val Loss: 101.48016
Epoch 6, Val Loss: 91.94147
Epoch 7, Val Loss: 89.99893
Epoch 8, Val Loss: 86.57613
Epoch 9, Val Loss: 84.82717
Epoch 10, Val Loss: 81.59870
Epoch 11, Val Loss: 77.96112
Epoch 12, Val Loss: 89.57391
Epoch 13, Val Loss: 95.10667
Epoch 14, Val Loss: 85.61393
Epoch 15, Val Loss: 84.11884
Epoch 16, Val Loss: 79.94044
Epoch 17, Val Loss: 82.38069
Epoch 18, Val Loss: 82.69925
Epoch 19, Val Loss: 78.38110
Epoch 20, Val Loss: 82.19540
Epoch 21, Val Loss: 91.43723
Epoch 22, Val Loss: 80.71206
Epoch 23, Val Loss: 83.00211
Epoch 24, Val Loss: 86.20113
Epoch 25, Val Loss: 81.39245
Epoch 26, Val Loss: 84.13577
Epoch 27, Val Loss: 85.21033
Epoch 28, Val Loss: 88.44381
Epoch 29, Val Loss: 90.40904
Epoch 30, Val Loss: 109.01555
Epoch 31, Val Loss: 101.24482
Epoch 32, Val Loss: 80.18703
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.32200658933613, 'MSE - std': 6.261733091370679, 'R2 - mean': 0.48235450007758063, 'R2 - std': 0.02478204210854286} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1449.65417
Epoch 1, Val Loss: 344.55298
Epoch 2, Val Loss: 146.92197
Epoch 3, Val Loss: 149.05194
Epoch 4, Val Loss: 117.44223
Epoch 5, Val Loss: 124.23717
Epoch 6, Val Loss: 110.98531
Epoch 7, Val Loss: 109.67614
Epoch 8, Val Loss: 105.20659
Epoch 9, Val Loss: 101.29758
Epoch 10, Val Loss: 97.52242
Epoch 11, Val Loss: 98.79417
Epoch 12, Val Loss: 105.63152
Epoch 13, Val Loss: 94.09962
Epoch 14, Val Loss: 105.46396
Epoch 15, Val Loss: 99.56779
Epoch 16, Val Loss: 96.78904
Epoch 17, Val Loss: 96.33132
Epoch 18, Val Loss: 89.14018
Epoch 19, Val Loss: 95.33629
Epoch 20, Val Loss: 94.12566
Epoch 21, Val Loss: 86.31094
Epoch 22, Val Loss: 90.90208
Epoch 23, Val Loss: 87.36418
Epoch 24, Val Loss: 97.86249
Epoch 25, Val Loss: 94.49345
Epoch 26, Val Loss: 98.09077
Epoch 27, Val Loss: 93.19836
Epoch 28, Val Loss: 93.98381
Epoch 29, Val Loss: 95.92438
Epoch 30, Val Loss: 89.28117
Epoch 31, Val Loss: 91.20599
Epoch 32, Val Loss: 91.37495
Epoch 33, Val Loss: 94.99681
Epoch 34, Val Loss: 81.97871
Epoch 35, Val Loss: 91.96381
Epoch 36, Val Loss: 85.79432
Epoch 37, Val Loss: 86.52644
Epoch 38, Val Loss: 99.66882
Epoch 39, Val Loss: 93.76415
Epoch 40, Val Loss: 84.74252
Epoch 41, Val Loss: 86.05525
Epoch 42, Val Loss: 88.13496
Epoch 43, Val Loss: 83.58363
Epoch 44, Val Loss: 82.90772
Epoch 45, Val Loss: 81.83912
Epoch 46, Val Loss: 88.86222
Epoch 47, Val Loss: 79.83418
Epoch 48, Val Loss: 92.81483
Epoch 49, Val Loss: 93.25569
Epoch 50, Val Loss: 87.11958
Epoch 51, Val Loss: 79.40182
Epoch 52, Val Loss: 93.75234
Epoch 53, Val Loss: 81.29271
Epoch 54, Val Loss: 80.49287
Epoch 55, Val Loss: 85.18423
Epoch 56, Val Loss: 82.25797
Epoch 57, Val Loss: 85.13258
Epoch 58, Val Loss: 79.91529
Epoch 59, Val Loss: 80.25890
Epoch 60, Val Loss: 83.83362
Epoch 61, Val Loss: 79.67225
Epoch 62, Val Loss: 78.27708
Epoch 63, Val Loss: 81.82357
Epoch 64, Val Loss: 84.14175
Epoch 65, Val Loss: 82.70525
Epoch 66, Val Loss: 77.72012
Epoch 67, Val Loss: 83.07473
Epoch 68, Val Loss: 79.69431
Epoch 69, Val Loss: 78.35743
Epoch 70, Val Loss: 84.59319
Epoch 71, Val Loss: 84.62925
Epoch 72, Val Loss: 78.75265
Epoch 73, Val Loss: 81.06976
Epoch 74, Val Loss: 83.76565
Epoch 75, Val Loss: 82.71384
Epoch 76, Val Loss: 81.62750
Epoch 77, Val Loss: 80.38895
Epoch 78, Val Loss: 81.16676
Epoch 79, Val Loss: 80.68694
Epoch 80, Val Loss: 79.32967
Epoch 81, Val Loss: 81.76577
Epoch 82, Val Loss: 83.60983
Epoch 83, Val Loss: 78.80495
Epoch 84, Val Loss: 79.53300
Epoch 85, Val Loss: 78.72337
Epoch 86, Val Loss: 89.90359
Epoch 87, Val Loss: 79.87685
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.92380610829122, 'MSE - std': 6.091326709137285, 'R2 - mean': 0.4788342799035263, 'R2 - std': 0.022311164436748947} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1281.42920
Epoch 1, Val Loss: 325.06976
Epoch 2, Val Loss: 148.82033
Epoch 3, Val Loss: 132.86685
Epoch 4, Val Loss: 120.08469
Epoch 5, Val Loss: 114.54960
Epoch 6, Val Loss: 102.71031
Epoch 7, Val Loss: 104.03396
Epoch 8, Val Loss: 104.98565
Epoch 9, Val Loss: 101.11803
Epoch 10, Val Loss: 97.83229
Epoch 11, Val Loss: 96.67541
Epoch 12, Val Loss: 101.35658
Epoch 13, Val Loss: 110.58214
Epoch 14, Val Loss: 105.62729
Epoch 15, Val Loss: 98.87083
Epoch 16, Val Loss: 108.62358
Epoch 17, Val Loss: 102.46745
Epoch 18, Val Loss: 92.36723
Epoch 19, Val Loss: 93.67770
Epoch 20, Val Loss: 96.03168
Epoch 21, Val Loss: 95.55766
Epoch 22, Val Loss: 90.78545
Epoch 23, Val Loss: 91.13681
Epoch 24, Val Loss: 101.79877
Epoch 25, Val Loss: 94.18700
Epoch 26, Val Loss: 89.83102
Epoch 27, Val Loss: 93.79246
Epoch 28, Val Loss: 98.89313
Epoch 29, Val Loss: 93.74354
Epoch 30, Val Loss: 93.69685
Epoch 31, Val Loss: 100.40520
Epoch 32, Val Loss: 98.36078
Epoch 33, Val Loss: 94.32680
Epoch 34, Val Loss: 105.16013
Epoch 35, Val Loss: 88.96413
Epoch 36, Val Loss: 86.39517
Epoch 37, Val Loss: 86.30675
Epoch 38, Val Loss: 93.00528
Epoch 39, Val Loss: 94.32758
Epoch 40, Val Loss: 94.47212
Epoch 41, Val Loss: 89.30138
Epoch 42, Val Loss: 86.04073
Epoch 43, Val Loss: 91.92521
Epoch 44, Val Loss: 94.80612
Epoch 45, Val Loss: 88.60982
Epoch 46, Val Loss: 88.03412
Epoch 47, Val Loss: 85.31342
Epoch 48, Val Loss: 84.77402
Epoch 49, Val Loss: 91.45638
Epoch 50, Val Loss: 84.80650
Epoch 51, Val Loss: 86.65304
Epoch 52, Val Loss: 101.03036
Epoch 53, Val Loss: 86.32887
Epoch 54, Val Loss: 81.58064
Epoch 55, Val Loss: 87.96739
Epoch 56, Val Loss: 81.96470
Epoch 57, Val Loss: 83.57334
Epoch 58, Val Loss: 84.08875
Epoch 59, Val Loss: 83.53073
Epoch 60, Val Loss: 83.52261
Epoch 61, Val Loss: 93.99873
Epoch 62, Val Loss: 86.73042
Epoch 63, Val Loss: 81.90701
Epoch 64, Val Loss: 87.27236
Epoch 65, Val Loss: 78.69168
Epoch 66, Val Loss: 87.46263
Epoch 67, Val Loss: 87.72247
Epoch 68, Val Loss: 85.92752
Epoch 69, Val Loss: 82.56660
Epoch 70, Val Loss: 82.22706
Epoch 71, Val Loss: 85.73080
Epoch 72, Val Loss: 80.82384
Epoch 73, Val Loss: 83.40630
Epoch 74, Val Loss: 83.19994
Epoch 75, Val Loss: 81.32353
Epoch 76, Val Loss: 86.77875
Epoch 77, Val Loss: 80.03407
Epoch 78, Val Loss: 81.16124
Epoch 79, Val Loss: 76.38525
Epoch 80, Val Loss: 78.82967
Epoch 81, Val Loss: 81.75664
Epoch 82, Val Loss: 94.81467
Epoch 83, Val Loss: 80.27138
Epoch 84, Val Loss: 85.87319
Epoch 85, Val Loss: 93.69730
Epoch 86, Val Loss: 81.33620
Epoch 87, Val Loss: 84.36462
Epoch 88, Val Loss: 79.16024
Epoch 89, Val Loss: 87.96482
Epoch 90, Val Loss: 79.39693
Epoch 91, Val Loss: 83.70078
Epoch 92, Val Loss: 76.85444
Epoch 93, Val Loss: 80.09271
Epoch 94, Val Loss: 86.06152
Epoch 95, Val Loss: 76.92430
Epoch 96, Val Loss: 78.24472
Epoch 97, Val Loss: 92.01021
Epoch 98, Val Loss: 81.39463
Epoch 99, Val Loss: 78.20744
DID NOT SAVE RESULTS
{'MSE - mean': 82.7675076743443, 'MSE - std': 5.9187425299088465, 'R2 - mean': 0.48505320306452077, 'R2 - std': 0.02351447358433386} 
 

Results After CV: {'MSE - mean': 82.7675076743443, 'MSE - std': 5.9187425299088465, 'R2 - mean': 0.48505320306452077, 'R2 - std': 0.02351447358433386}
Train time: 1656.5972728505963
Inference time: 0.17584338059532456
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 46 finished with value: 82.7675076743443 and parameters: {'p_m': 0.24995428638587935, 'alpha': 7.964978810093395, 'K': 10, 'beta': 4.713805472326191}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 911.31299
Epoch 1, Val Loss: 401.86246
Epoch 2, Val Loss: 194.90959
Epoch 3, Val Loss: 193.66066
Epoch 4, Val Loss: 182.44014
Epoch 5, Val Loss: 147.16187
Epoch 6, Val Loss: 134.13974
Epoch 7, Val Loss: 132.23819
Epoch 8, Val Loss: 116.04899
Epoch 9, Val Loss: 112.01547
Epoch 10, Val Loss: 114.55298
Epoch 11, Val Loss: 120.68551
Epoch 12, Val Loss: 104.47054
Epoch 13, Val Loss: 113.36673
Epoch 14, Val Loss: 115.50737
Epoch 15, Val Loss: 104.79808
Epoch 16, Val Loss: 117.74030
Epoch 17, Val Loss: 126.68965
Epoch 18, Val Loss: 116.50980
Epoch 19, Val Loss: 97.25690
Epoch 20, Val Loss: 102.14111
Epoch 21, Val Loss: 101.11877
Epoch 22, Val Loss: 102.65931
Epoch 23, Val Loss: 97.22763
Epoch 24, Val Loss: 97.09158
Epoch 25, Val Loss: 101.80836
Epoch 26, Val Loss: 92.21492
Epoch 27, Val Loss: 96.77856
Epoch 28, Val Loss: 93.38663
Epoch 29, Val Loss: 87.46409
Epoch 30, Val Loss: 93.55484
Epoch 31, Val Loss: 93.77185
Epoch 32, Val Loss: 86.64173
Epoch 33, Val Loss: 90.45910
Epoch 34, Val Loss: 85.93352
Epoch 35, Val Loss: 86.87712
Epoch 36, Val Loss: 89.80355
Epoch 37, Val Loss: 90.62637
Epoch 38, Val Loss: 87.78323
Epoch 39, Val Loss: 87.46523
Epoch 40, Val Loss: 89.94921
Epoch 41, Val Loss: 89.34097
Epoch 42, Val Loss: 82.04817
Epoch 43, Val Loss: 86.38094
Epoch 44, Val Loss: 86.52282
Epoch 45, Val Loss: 87.72607
Epoch 46, Val Loss: 88.87798
Epoch 47, Val Loss: 84.26868
Epoch 48, Val Loss: 83.26286
Epoch 49, Val Loss: 82.76685
Epoch 50, Val Loss: 89.89902
Epoch 51, Val Loss: 83.01471
Epoch 52, Val Loss: 83.87445
Epoch 53, Val Loss: 88.03334
Epoch 54, Val Loss: 88.01392
Epoch 55, Val Loss: 87.97384
Epoch 56, Val Loss: 92.83104
Epoch 57, Val Loss: 84.05801
Epoch 58, Val Loss: 84.33216
Epoch 59, Val Loss: 90.27837
Epoch 60, Val Loss: 89.98837
Epoch 61, Val Loss: 89.05598
Epoch 62, Val Loss: 88.91311
Epoch 63, Val Loss: 85.10185
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.46417783557065, 'MSE - std': 0.0, 'R2 - mean': 0.5019718047127525, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 931.33960
Epoch 1, Val Loss: 412.48370
Epoch 2, Val Loss: 158.07774
Epoch 3, Val Loss: 144.96967
Epoch 4, Val Loss: 154.01880
Epoch 5, Val Loss: 123.36707
Epoch 6, Val Loss: 118.62021
Epoch 7, Val Loss: 120.63532
Epoch 8, Val Loss: 109.26022
Epoch 9, Val Loss: 100.53589
Epoch 10, Val Loss: 94.34229
Epoch 11, Val Loss: 93.38213
Epoch 12, Val Loss: 94.86057
Epoch 13, Val Loss: 95.96751
Epoch 14, Val Loss: 88.43533
Epoch 15, Val Loss: 82.16502
Epoch 16, Val Loss: 86.46616
Epoch 17, Val Loss: 94.66236
Epoch 18, Val Loss: 83.15453
Epoch 19, Val Loss: 85.98972
Epoch 20, Val Loss: 86.41304
Epoch 21, Val Loss: 78.99134
Epoch 22, Val Loss: 87.49129
Epoch 23, Val Loss: 92.80888
Epoch 24, Val Loss: 79.16972
Epoch 25, Val Loss: 75.17011
Epoch 26, Val Loss: 78.48517
Epoch 27, Val Loss: 75.50355
Epoch 28, Val Loss: 78.17099
Epoch 29, Val Loss: 75.29711
Epoch 30, Val Loss: 75.64787
Epoch 31, Val Loss: 79.91016
Epoch 32, Val Loss: 74.24151
Epoch 33, Val Loss: 73.02435
Epoch 34, Val Loss: 79.48682
Epoch 35, Val Loss: 75.10030
Epoch 36, Val Loss: 92.91340
Epoch 37, Val Loss: 72.80499
Epoch 38, Val Loss: 74.19588
Epoch 39, Val Loss: 77.86729
Epoch 40, Val Loss: 87.21015
Epoch 41, Val Loss: 78.60721
Epoch 42, Val Loss: 78.73531
Epoch 43, Val Loss: 71.68797
Epoch 44, Val Loss: 77.37206
Epoch 45, Val Loss: 75.68789
Epoch 46, Val Loss: 76.07979
Epoch 47, Val Loss: 72.08311
Epoch 48, Val Loss: 72.66083
Epoch 49, Val Loss: 75.88754
Epoch 50, Val Loss: 75.20478
Epoch 51, Val Loss: 70.61008
Epoch 52, Val Loss: 71.78206
Epoch 53, Val Loss: 70.70172
Epoch 54, Val Loss: 79.68427
Epoch 55, Val Loss: 73.66384
Epoch 56, Val Loss: 75.92931
Epoch 57, Val Loss: 74.66676
Epoch 58, Val Loss: 82.95625
Epoch 59, Val Loss: 82.95174
Epoch 60, Val Loss: 69.97234
Epoch 61, Val Loss: 74.27998
Epoch 62, Val Loss: 71.17578
Epoch 63, Val Loss: 70.95084
Epoch 64, Val Loss: 70.55998
Epoch 65, Val Loss: 85.22821
Epoch 66, Val Loss: 71.09138
Epoch 67, Val Loss: 73.12676
Epoch 68, Val Loss: 83.92161
Epoch 69, Val Loss: 73.32812
Epoch 70, Val Loss: 80.31582
Epoch 71, Val Loss: 76.05518
Epoch 72, Val Loss: 90.44279
Epoch 73, Val Loss: 74.68330
Epoch 74, Val Loss: 77.35435
Epoch 75, Val Loss: 75.38966
Epoch 76, Val Loss: 74.17593
Epoch 77, Val Loss: 74.60608
Epoch 78, Val Loss: 74.34259
Epoch 79, Val Loss: 73.67918
Epoch 80, Val Loss: 75.12178
Epoch 81, Val Loss: 76.77202
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.9805464518802, 'MSE - std': 3.483631383690458, 'R2 - mean': 0.5005815055106002, 'R2 - std': 0.0013902992021522231} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1059.63916
Epoch 1, Val Loss: 329.56049
Epoch 2, Val Loss: 164.40521
Epoch 3, Val Loss: 136.82620
Epoch 4, Val Loss: 130.58800
Epoch 5, Val Loss: 122.70510
Epoch 6, Val Loss: 101.35245
Epoch 7, Val Loss: 96.38338
Epoch 8, Val Loss: 101.63625
Epoch 9, Val Loss: 100.07007
Epoch 10, Val Loss: 89.95680
Epoch 11, Val Loss: 85.63689
Epoch 12, Val Loss: 82.31630
Epoch 13, Val Loss: 82.09849
Epoch 14, Val Loss: 91.15753
Epoch 15, Val Loss: 89.79663
Epoch 16, Val Loss: 84.88029
Epoch 17, Val Loss: 89.54230
Epoch 18, Val Loss: 102.96434
Epoch 19, Val Loss: 83.71707
Epoch 20, Val Loss: 81.02672
Epoch 21, Val Loss: 82.70489
Epoch 22, Val Loss: 79.97662
Epoch 23, Val Loss: 74.91128
Epoch 24, Val Loss: 107.02642
Epoch 25, Val Loss: 81.24088
Epoch 26, Val Loss: 80.10231
Epoch 27, Val Loss: 84.14323
Epoch 28, Val Loss: 76.04678
Epoch 29, Val Loss: 75.31918
Epoch 30, Val Loss: 77.85246
Epoch 31, Val Loss: 76.99639
Epoch 32, Val Loss: 76.71220
Epoch 33, Val Loss: 75.04607
Epoch 34, Val Loss: 73.03500
Epoch 35, Val Loss: 72.69191
Epoch 36, Val Loss: 73.96217
Epoch 37, Val Loss: 74.79405
Epoch 38, Val Loss: 76.85764
Epoch 39, Val Loss: 73.24406
Epoch 40, Val Loss: 80.01557
Epoch 41, Val Loss: 75.88972
Epoch 42, Val Loss: 92.95332
Epoch 43, Val Loss: 70.96513
Epoch 44, Val Loss: 71.93808
Epoch 45, Val Loss: 70.10143
Epoch 46, Val Loss: 75.18684
Epoch 47, Val Loss: 69.10424
Epoch 48, Val Loss: 68.03036
Epoch 49, Val Loss: 71.60278
Epoch 50, Val Loss: 71.75744
Epoch 51, Val Loss: 72.15955
Epoch 52, Val Loss: 69.58681
Epoch 53, Val Loss: 69.00713
Epoch 54, Val Loss: 67.74268
Epoch 55, Val Loss: 75.42489
Epoch 56, Val Loss: 73.77612
Epoch 57, Val Loss: 71.14279
Epoch 58, Val Loss: 69.62526
Epoch 59, Val Loss: 70.00028
Epoch 60, Val Loss: 70.61256
Epoch 61, Val Loss: 67.22765
Epoch 62, Val Loss: 69.97524
Epoch 63, Val Loss: 74.39340
Epoch 64, Val Loss: 75.22733
Epoch 65, Val Loss: 69.88221
Epoch 66, Val Loss: 70.95993
Epoch 67, Val Loss: 85.54809
Epoch 68, Val Loss: 69.05105
Epoch 69, Val Loss: 75.79379
Epoch 70, Val Loss: 72.00719
Epoch 71, Val Loss: 70.67403
Epoch 72, Val Loss: 72.38096
Epoch 73, Val Loss: 78.30762
Epoch 74, Val Loss: 74.80025
Epoch 75, Val Loss: 70.11809
Epoch 76, Val Loss: 75.61369
Epoch 77, Val Loss: 69.27628
Epoch 78, Val Loss: 72.57240
Epoch 79, Val Loss: 71.35938
Epoch 80, Val Loss: 70.93854
Epoch 81, Val Loss: 72.50811
Epoch 82, Val Loss: 70.89812
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.23384804645444, 'MSE - std': 7.290593248547401, 'R2 - mean': 0.5152904795804008, 'R2 - std': 0.02083258163598065} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 974.44482
Epoch 1, Val Loss: 421.92911
Epoch 2, Val Loss: 183.35994
Epoch 3, Val Loss: 175.45490
Epoch 4, Val Loss: 144.60289
Epoch 5, Val Loss: 143.38138
Epoch 6, Val Loss: 126.76050
Epoch 7, Val Loss: 125.68147
Epoch 8, Val Loss: 104.86124
Epoch 9, Val Loss: 117.94819
Epoch 10, Val Loss: 110.57442
Epoch 11, Val Loss: 115.89114
Epoch 12, Val Loss: 98.98595
Epoch 13, Val Loss: 104.06498
Epoch 14, Val Loss: 98.11961
Epoch 15, Val Loss: 101.67187
Epoch 16, Val Loss: 102.71428
Epoch 17, Val Loss: 93.60706
Epoch 18, Val Loss: 91.82896
Epoch 19, Val Loss: 96.82433
Epoch 20, Val Loss: 89.10438
Epoch 21, Val Loss: 94.07146
Epoch 22, Val Loss: 99.66716
Epoch 23, Val Loss: 100.31035
Epoch 24, Val Loss: 90.00023
Epoch 25, Val Loss: 98.04901
Epoch 26, Val Loss: 107.36023
Epoch 27, Val Loss: 89.13797
Epoch 28, Val Loss: 89.37502
Epoch 29, Val Loss: 88.65272
Epoch 30, Val Loss: 91.44855
Epoch 31, Val Loss: 88.63313
Epoch 32, Val Loss: 87.00940
Epoch 33, Val Loss: 100.70197
Epoch 34, Val Loss: 86.33589
Epoch 35, Val Loss: 104.44559
Epoch 36, Val Loss: 82.21083
Epoch 37, Val Loss: 86.75536
Epoch 38, Val Loss: 87.21143
Epoch 39, Val Loss: 86.36237
Epoch 40, Val Loss: 81.10884
Epoch 41, Val Loss: 85.26002
Epoch 42, Val Loss: 87.72905
Epoch 43, Val Loss: 86.04361
Epoch 44, Val Loss: 82.45731
Epoch 45, Val Loss: 85.78612
Epoch 46, Val Loss: 81.62273
Epoch 47, Val Loss: 80.00514
Epoch 48, Val Loss: 81.75893
Epoch 49, Val Loss: 79.49425
Epoch 50, Val Loss: 80.25433
Epoch 51, Val Loss: 89.66309
Epoch 52, Val Loss: 84.13769
Epoch 53, Val Loss: 84.39335
Epoch 54, Val Loss: 81.62335
Epoch 55, Val Loss: 89.15508
Epoch 56, Val Loss: 80.86767
Epoch 57, Val Loss: 83.34846
Epoch 58, Val Loss: 81.55401
Epoch 59, Val Loss: 79.20393
Epoch 60, Val Loss: 84.41025
Epoch 61, Val Loss: 82.74738
Epoch 62, Val Loss: 84.35476
Epoch 63, Val Loss: 81.33155
Epoch 64, Val Loss: 82.46629
Epoch 65, Val Loss: 84.27618
Epoch 66, Val Loss: 95.27836
Epoch 67, Val Loss: 98.85272
Epoch 68, Val Loss: 83.98294
Epoch 69, Val Loss: 84.78082
Epoch 70, Val Loss: 83.55872
Epoch 71, Val Loss: 87.85101
Epoch 72, Val Loss: 82.13766
Epoch 73, Val Loss: 79.12491
Epoch 74, Val Loss: 81.30984
Epoch 75, Val Loss: 88.67062
Epoch 76, Val Loss: 82.64811
Epoch 77, Val Loss: 91.01270
Epoch 78, Val Loss: 83.09830
Epoch 79, Val Loss: 82.48238
Epoch 80, Val Loss: 85.10101
Epoch 81, Val Loss: 80.77413
Epoch 82, Val Loss: 89.66833
Epoch 83, Val Loss: 81.80485
Epoch 84, Val Loss: 86.54940
Epoch 85, Val Loss: 81.08041
Epoch 86, Val Loss: 83.33599
Epoch 87, Val Loss: 83.53123
Epoch 88, Val Loss: 85.24426
Epoch 89, Val Loss: 84.79669
Epoch 90, Val Loss: 81.14510
Epoch 91, Val Loss: 80.96361
Epoch 92, Val Loss: 85.34276
Epoch 93, Val Loss: 84.17422
Epoch 94, Val Loss: 82.40665
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.33360079044655, 'MSE - std': 8.28794085756431, 'R2 - mean': 0.5021824350262161, 'R2 - std': 0.028999307566187266} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1303.95813
Epoch 1, Val Loss: 454.44867
Epoch 2, Val Loss: 166.50192
Epoch 3, Val Loss: 145.76195
Epoch 4, Val Loss: 154.44742
Epoch 5, Val Loss: 137.26382
Epoch 6, Val Loss: 136.45245
Epoch 7, Val Loss: 117.14346
Epoch 8, Val Loss: 116.85313
Epoch 9, Val Loss: 99.73210
Epoch 10, Val Loss: 98.64987
Epoch 11, Val Loss: 96.87882
Epoch 12, Val Loss: 103.73477
Epoch 13, Val Loss: 129.22678
Epoch 14, Val Loss: 98.38499
Epoch 15, Val Loss: 108.16163
Epoch 16, Val Loss: 99.52951
Epoch 17, Val Loss: 107.70338
Epoch 18, Val Loss: 96.52923
Epoch 19, Val Loss: 92.71384
Epoch 20, Val Loss: 100.92799
Epoch 21, Val Loss: 99.28099
Epoch 22, Val Loss: 84.61948
Epoch 23, Val Loss: 93.57673
Epoch 24, Val Loss: 89.08859
Epoch 25, Val Loss: 90.12212
Epoch 26, Val Loss: 90.19527
Epoch 27, Val Loss: 87.58981
Epoch 28, Val Loss: 98.47554
Epoch 29, Val Loss: 90.37519
Epoch 30, Val Loss: 87.46426
Epoch 31, Val Loss: 87.71072
Epoch 32, Val Loss: 82.18121
Epoch 33, Val Loss: 88.52887
Epoch 34, Val Loss: 80.73608
Epoch 35, Val Loss: 85.07301
Epoch 36, Val Loss: 88.32472
Epoch 37, Val Loss: 97.92056
Epoch 38, Val Loss: 82.65784
Epoch 39, Val Loss: 80.36080
Epoch 40, Val Loss: 81.11934
Epoch 41, Val Loss: 81.65584
Epoch 42, Val Loss: 82.83806
Epoch 43, Val Loss: 82.96654
Epoch 44, Val Loss: 81.31940
Epoch 45, Val Loss: 75.97102
Epoch 46, Val Loss: 89.85609
Epoch 47, Val Loss: 89.43991
Epoch 48, Val Loss: 78.15919
Epoch 49, Val Loss: 78.50908
Epoch 50, Val Loss: 84.07458
Epoch 51, Val Loss: 83.95462
Epoch 52, Val Loss: 75.36124
Epoch 53, Val Loss: 86.45387
Epoch 54, Val Loss: 78.56216
Epoch 55, Val Loss: 87.55402
Epoch 56, Val Loss: 79.87846
Epoch 57, Val Loss: 94.70692
Epoch 58, Val Loss: 77.09367
Epoch 59, Val Loss: 80.25844
Epoch 60, Val Loss: 77.74612
Epoch 61, Val Loss: 77.85439
Epoch 62, Val Loss: 80.45711
Epoch 63, Val Loss: 78.36053
Epoch 64, Val Loss: 78.32687
Epoch 65, Val Loss: 76.32916
Epoch 66, Val Loss: 74.93289
Epoch 67, Val Loss: 80.34198
Epoch 68, Val Loss: 82.33832
Epoch 69, Val Loss: 74.73972
Epoch 70, Val Loss: 79.56835
Epoch 71, Val Loss: 82.28226
Epoch 72, Val Loss: 76.62663
Epoch 73, Val Loss: 82.33616
Epoch 74, Val Loss: 80.05688
Epoch 75, Val Loss: 82.13757
Epoch 76, Val Loss: 78.70840
Epoch 77, Val Loss: 77.13099
Epoch 78, Val Loss: 78.38887
Epoch 79, Val Loss: 77.33503
Epoch 80, Val Loss: 87.78851
Epoch 81, Val Loss: 95.95552
Epoch 82, Val Loss: 81.37609
Epoch 83, Val Loss: 79.00394
Epoch 84, Val Loss: 80.70171
Epoch 85, Val Loss: 78.67459
Epoch 86, Val Loss: 91.67339
Epoch 87, Val Loss: 81.50791
Epoch 88, Val Loss: 87.68434
Epoch 89, Val Loss: 80.59004
Epoch 90, Val Loss: 80.64582
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.47350599988289, 'MSE - std': 7.609929245519044, 'R2 - mean': 0.5063772890858123, 'R2 - std': 0.027260870745079} 
 

Results After CV: {'MSE - mean': 79.47350599988289, 'MSE - std': 7.609929245519044, 'R2 - mean': 0.5063772890858123, 'R2 - std': 0.027260870745079}
Train time: 933.7057595553982
Inference time: 0.1869720945949666
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 47 finished with value: 79.47350599988289 and parameters: {'p_m': 0.3536265856224089, 'alpha': 5.9565633276736385, 'K': 5, 'beta': 6.543663522455264}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 999.34045
Epoch 1, Val Loss: 372.79471
Epoch 2, Val Loss: 176.27245
Epoch 3, Val Loss: 149.46887
Epoch 4, Val Loss: 151.26804
Epoch 5, Val Loss: 133.70540
Epoch 6, Val Loss: 125.21453
Epoch 7, Val Loss: 129.36797
Epoch 8, Val Loss: 111.65908
Epoch 9, Val Loss: 124.96190
Epoch 10, Val Loss: 107.75205
Epoch 11, Val Loss: 113.77553
Epoch 12, Val Loss: 132.52731
Epoch 13, Val Loss: 114.28699
Epoch 14, Val Loss: 104.79337
Epoch 15, Val Loss: 130.19434
Epoch 16, Val Loss: 106.27135
Epoch 17, Val Loss: 111.42368
Epoch 18, Val Loss: 100.65373
Epoch 19, Val Loss: 104.76017
Epoch 20, Val Loss: 115.51379
Epoch 21, Val Loss: 102.10364
Epoch 22, Val Loss: 99.86197
Epoch 23, Val Loss: 136.20555
Epoch 24, Val Loss: 107.15067
Epoch 25, Val Loss: 122.04158
Epoch 26, Val Loss: 100.18587
Epoch 27, Val Loss: 103.47912
Epoch 28, Val Loss: 111.96674
Epoch 29, Val Loss: 102.16662
Epoch 30, Val Loss: 97.64453
Epoch 31, Val Loss: 111.21915
Epoch 32, Val Loss: 101.27019
Epoch 33, Val Loss: 103.79033
Epoch 34, Val Loss: 95.34123
Epoch 35, Val Loss: 91.33236
Epoch 36, Val Loss: 92.66916
Epoch 37, Val Loss: 95.47031
Epoch 38, Val Loss: 96.81271
Epoch 39, Val Loss: 89.45084
Epoch 40, Val Loss: 92.57043
Epoch 41, Val Loss: 88.67347
Epoch 42, Val Loss: 101.53764
Epoch 43, Val Loss: 92.48271
Epoch 44, Val Loss: 83.68539
Epoch 45, Val Loss: 87.04721
Epoch 46, Val Loss: 87.01627
Epoch 47, Val Loss: 99.90002
Epoch 48, Val Loss: 84.79700
Epoch 49, Val Loss: 90.59236
Epoch 50, Val Loss: 85.68486
Epoch 51, Val Loss: 87.28728
Epoch 52, Val Loss: 86.73460
Epoch 53, Val Loss: 85.57117
Epoch 54, Val Loss: 80.57848
Epoch 55, Val Loss: 86.84208
Epoch 56, Val Loss: 86.87998
Epoch 57, Val Loss: 87.11224
Epoch 58, Val Loss: 84.38404
Epoch 59, Val Loss: 87.77613
Epoch 60, Val Loss: 89.04024
Epoch 61, Val Loss: 87.84043
Epoch 62, Val Loss: 88.51686
Epoch 63, Val Loss: 92.97204
Epoch 64, Val Loss: 89.52451
Epoch 65, Val Loss: 88.75208
Epoch 66, Val Loss: 86.34509
Epoch 67, Val Loss: 85.23093
Epoch 68, Val Loss: 91.20836
Epoch 69, Val Loss: 91.02953
Epoch 70, Val Loss: 89.42238
Epoch 71, Val Loss: 84.86408
Epoch 72, Val Loss: 87.61595
Epoch 73, Val Loss: 94.50430
Epoch 74, Val Loss: 112.73341
Epoch 75, Val Loss: 90.33885
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.29837626734812, 'MSE - std': 0.0, 'R2 - mean': 0.5087653182735097, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 933.79987
Epoch 1, Val Loss: 363.35406
Epoch 2, Val Loss: 158.20734
Epoch 3, Val Loss: 167.82497
Epoch 4, Val Loss: 143.90067
Epoch 5, Val Loss: 117.71934
Epoch 6, Val Loss: 131.80753
Epoch 7, Val Loss: 104.57033
Epoch 8, Val Loss: 98.80392
Epoch 9, Val Loss: 111.77397
Epoch 10, Val Loss: 94.24736
Epoch 11, Val Loss: 93.64511
Epoch 12, Val Loss: 98.04709
Epoch 13, Val Loss: 109.22338
Epoch 14, Val Loss: 105.02965
Epoch 15, Val Loss: 93.77393
Epoch 16, Val Loss: 85.26785
Epoch 17, Val Loss: 91.48614
Epoch 18, Val Loss: 88.65359
Epoch 19, Val Loss: 89.79504
Epoch 20, Val Loss: 90.58183
Epoch 21, Val Loss: 83.38118
Epoch 22, Val Loss: 88.78482
Epoch 23, Val Loss: 90.87390
Epoch 24, Val Loss: 79.43967
Epoch 25, Val Loss: 91.28291
Epoch 26, Val Loss: 80.53612
Epoch 27, Val Loss: 93.51974
Epoch 28, Val Loss: 84.24496
Epoch 29, Val Loss: 92.15866
Epoch 30, Val Loss: 76.82622
Epoch 31, Val Loss: 75.12492
Epoch 32, Val Loss: 77.93568
Epoch 33, Val Loss: 78.20409
Epoch 34, Val Loss: 86.47780
Epoch 35, Val Loss: 80.79980
Epoch 36, Val Loss: 95.63139
Epoch 37, Val Loss: 76.89733
Epoch 38, Val Loss: 79.61104
Epoch 39, Val Loss: 75.99818
Epoch 40, Val Loss: 78.88201
Epoch 41, Val Loss: 95.43819
Epoch 42, Val Loss: 72.62421
Epoch 43, Val Loss: 71.20934
Epoch 44, Val Loss: 83.02751
Epoch 45, Val Loss: 83.60954
Epoch 46, Val Loss: 77.01283
Epoch 47, Val Loss: 71.71609
Epoch 48, Val Loss: 80.30186
Epoch 49, Val Loss: 68.36520
Epoch 50, Val Loss: 70.34975
Epoch 51, Val Loss: 73.60992
Epoch 52, Val Loss: 78.65245
Epoch 53, Val Loss: 71.39226
Epoch 54, Val Loss: 69.52106
Epoch 55, Val Loss: 71.63364
Epoch 56, Val Loss: 70.25925
Epoch 57, Val Loss: 71.54520
Epoch 58, Val Loss: 70.67613
Epoch 59, Val Loss: 69.96866
Epoch 60, Val Loss: 71.66169
Epoch 61, Val Loss: 70.59724
Epoch 62, Val Loss: 70.20404
Epoch 63, Val Loss: 71.90875
Epoch 64, Val Loss: 86.50478
Epoch 65, Val Loss: 72.50937
Epoch 66, Val Loss: 72.29704
Epoch 67, Val Loss: 68.32521
Epoch 68, Val Loss: 72.05850
Epoch 69, Val Loss: 68.00046
Epoch 70, Val Loss: 71.64735
Epoch 71, Val Loss: 72.51628
Epoch 72, Val Loss: 73.49073
Epoch 73, Val Loss: 71.77230
Epoch 74, Val Loss: 74.02531
Epoch 75, Val Loss: 75.34012
Epoch 76, Val Loss: 75.62960
Epoch 77, Val Loss: 73.96214
Epoch 78, Val Loss: 73.34483
Epoch 79, Val Loss: 70.57103
Epoch 80, Val Loss: 74.17181
Epoch 81, Val Loss: 69.60598
Epoch 82, Val Loss: 75.93977
Epoch 83, Val Loss: 73.51517
Epoch 84, Val Loss: 74.35377
Epoch 85, Val Loss: 73.74187
Epoch 86, Val Loss: 72.60341
Epoch 87, Val Loss: 73.68145
Epoch 88, Val Loss: 75.24352
Epoch 89, Val Loss: 68.81376
Epoch 90, Val Loss: 73.11908
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.63314523781958, 'MSE - std': 3.6652310295285417, 'R2 - mean': 0.508855760187132, 'R2 - std': 9.044191362234111e-05} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1312.59644
Epoch 1, Val Loss: 485.91830
Epoch 2, Val Loss: 147.10909
Epoch 3, Val Loss: 147.12549
Epoch 4, Val Loss: 125.74239
Epoch 5, Val Loss: 103.30783
Epoch 6, Val Loss: 99.11880
Epoch 7, Val Loss: 113.54149
Epoch 8, Val Loss: 87.05616
Epoch 9, Val Loss: 98.97312
Epoch 10, Val Loss: 91.10245
Epoch 11, Val Loss: 92.54231
Epoch 12, Val Loss: 88.68879
Epoch 13, Val Loss: 98.21610
Epoch 14, Val Loss: 81.66021
Epoch 15, Val Loss: 88.11108
Epoch 16, Val Loss: 94.37903
Epoch 17, Val Loss: 78.84045
Epoch 18, Val Loss: 80.50771
Epoch 19, Val Loss: 79.03792
Epoch 20, Val Loss: 78.39805
Epoch 21, Val Loss: 84.09523
Epoch 22, Val Loss: 95.25130
Epoch 23, Val Loss: 79.15233
Epoch 24, Val Loss: 89.47058
Epoch 25, Val Loss: 102.05315
Epoch 26, Val Loss: 90.79654
Epoch 27, Val Loss: 89.93834
Epoch 28, Val Loss: 85.04215
Epoch 29, Val Loss: 79.39377
Epoch 30, Val Loss: 83.74921
Epoch 31, Val Loss: 88.13483
Epoch 32, Val Loss: 76.43366
Epoch 33, Val Loss: 87.32536
Epoch 34, Val Loss: 81.15874
Epoch 35, Val Loss: 74.85717
Epoch 36, Val Loss: 84.58372
Epoch 37, Val Loss: 76.34833
Epoch 38, Val Loss: 71.00603
Epoch 39, Val Loss: 70.16528
Epoch 40, Val Loss: 72.85768
Epoch 41, Val Loss: 71.89370
Epoch 42, Val Loss: 69.48947
Epoch 43, Val Loss: 83.09410
Epoch 44, Val Loss: 69.55724
Epoch 45, Val Loss: 83.04967
Epoch 46, Val Loss: 73.69426
Epoch 47, Val Loss: 69.89520
Epoch 48, Val Loss: 69.78168
Epoch 49, Val Loss: 79.27033
Epoch 50, Val Loss: 69.13553
Epoch 51, Val Loss: 86.23367
Epoch 52, Val Loss: 69.36889
Epoch 53, Val Loss: 72.06300
Epoch 54, Val Loss: 71.73633
Epoch 55, Val Loss: 77.23550
Epoch 56, Val Loss: 70.73120
Epoch 57, Val Loss: 74.02724
Epoch 58, Val Loss: 73.27347
Epoch 59, Val Loss: 68.80312
Epoch 60, Val Loss: 71.32572
Epoch 61, Val Loss: 67.67576
Epoch 62, Val Loss: 69.91982
Epoch 63, Val Loss: 70.46349
Epoch 64, Val Loss: 66.81712
Epoch 65, Val Loss: 66.18518
Epoch 66, Val Loss: 70.61572
Epoch 67, Val Loss: 72.32099
Epoch 68, Val Loss: 75.13773
Epoch 69, Val Loss: 67.60802
Epoch 70, Val Loss: 72.04385
Epoch 71, Val Loss: 70.44499
Epoch 72, Val Loss: 71.77824
Epoch 73, Val Loss: 69.44308
Epoch 74, Val Loss: 64.96196
Epoch 75, Val Loss: 71.93893
Epoch 76, Val Loss: 69.56525
Epoch 77, Val Loss: 73.52870
Epoch 78, Val Loss: 71.27002
Epoch 79, Val Loss: 67.84998
Epoch 80, Val Loss: 70.69414
Epoch 81, Val Loss: 84.91369
Epoch 82, Val Loss: 78.01258
Epoch 83, Val Loss: 70.72946
Epoch 84, Val Loss: 66.88243
Epoch 85, Val Loss: 68.09294
Epoch 86, Val Loss: 69.43645
Epoch 87, Val Loss: 67.62506
Epoch 88, Val Loss: 77.57639
Epoch 89, Val Loss: 70.87660
Epoch 90, Val Loss: 79.53061
Epoch 91, Val Loss: 68.43625
Epoch 92, Val Loss: 74.33907
Epoch 93, Val Loss: 71.95258
Epoch 94, Val Loss: 67.84635
Epoch 95, Val Loss: 68.20049
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 75.88776568069453, 'MSE - std': 7.348006528910167, 'R2 - mean': 0.523816466121388, 'R2 - std': 0.021157762104305648} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1196.76465
Epoch 1, Val Loss: 394.07257
Epoch 2, Val Loss: 179.46320
Epoch 3, Val Loss: 160.92157
Epoch 4, Val Loss: 141.22308
Epoch 5, Val Loss: 150.11948
Epoch 6, Val Loss: 144.18375
Epoch 7, Val Loss: 140.77094
Epoch 8, Val Loss: 118.43709
Epoch 9, Val Loss: 118.83153
Epoch 10, Val Loss: 118.82980
Epoch 11, Val Loss: 111.38997
Epoch 12, Val Loss: 106.14818
Epoch 13, Val Loss: 111.37404
Epoch 14, Val Loss: 109.71891
Epoch 15, Val Loss: 107.27473
Epoch 16, Val Loss: 106.27402
Epoch 17, Val Loss: 101.28172
Epoch 18, Val Loss: 102.11088
Epoch 19, Val Loss: 99.22679
Epoch 20, Val Loss: 100.52547
Epoch 21, Val Loss: 97.47251
Epoch 22, Val Loss: 128.31055
Epoch 23, Val Loss: 100.30432
Epoch 24, Val Loss: 98.02353
Epoch 25, Val Loss: 93.72794
Epoch 26, Val Loss: 96.49080
Epoch 27, Val Loss: 92.75214
Epoch 28, Val Loss: 99.81065
Epoch 29, Val Loss: 93.95107
Epoch 30, Val Loss: 93.77866
Epoch 31, Val Loss: 99.79611
Epoch 32, Val Loss: 87.60508
Epoch 33, Val Loss: 89.53246
Epoch 34, Val Loss: 96.75822
Epoch 35, Val Loss: 94.52547
Epoch 36, Val Loss: 90.50839
Epoch 37, Val Loss: 84.27465
Epoch 38, Val Loss: 91.60838
Epoch 39, Val Loss: 88.22197
Epoch 40, Val Loss: 90.07645
Epoch 41, Val Loss: 86.49998
Epoch 42, Val Loss: 100.43338
Epoch 43, Val Loss: 83.68077
Epoch 44, Val Loss: 107.44857
Epoch 45, Val Loss: 87.26841
Epoch 46, Val Loss: 91.83819
Epoch 47, Val Loss: 82.65378
Epoch 48, Val Loss: 88.96940
Epoch 49, Val Loss: 84.10335
Epoch 50, Val Loss: 83.05853
Epoch 51, Val Loss: 84.31238
Epoch 52, Val Loss: 82.11924
Epoch 53, Val Loss: 88.88654
Epoch 54, Val Loss: 83.98486
Epoch 55, Val Loss: 79.46892
Epoch 56, Val Loss: 87.35762
Epoch 57, Val Loss: 78.86853
Epoch 58, Val Loss: 82.29031
Epoch 59, Val Loss: 92.46628
Epoch 60, Val Loss: 85.64497
Epoch 61, Val Loss: 82.91573
Epoch 62, Val Loss: 82.42097
Epoch 63, Val Loss: 90.61387
Epoch 64, Val Loss: 81.93744
Epoch 65, Val Loss: 82.19827
Epoch 66, Val Loss: 81.22195
Epoch 67, Val Loss: 83.16774
Epoch 68, Val Loss: 82.32958
Epoch 69, Val Loss: 85.47238
Epoch 70, Val Loss: 82.32604
Epoch 71, Val Loss: 95.41471
Epoch 72, Val Loss: 81.06551
Epoch 73, Val Loss: 82.64751
Epoch 74, Val Loss: 102.33551
Epoch 75, Val Loss: 84.31857
Epoch 76, Val Loss: 80.40571
Epoch 77, Val Loss: 80.08915
Epoch 78, Val Loss: 85.96454
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.04116617058509, 'MSE - std': 8.386101830445767, 'R2 - mean': 0.5102720934495005, 'R2 - std': 0.02976723477536515} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 976.75427
Epoch 1, Val Loss: 435.11270
Epoch 2, Val Loss: 156.13571
Epoch 3, Val Loss: 134.14899
Epoch 4, Val Loss: 147.37436
Epoch 5, Val Loss: 128.65350
Epoch 6, Val Loss: 136.97426
Epoch 7, Val Loss: 118.70940
Epoch 8, Val Loss: 114.27473
Epoch 9, Val Loss: 108.30872
Epoch 10, Val Loss: 121.96716
Epoch 11, Val Loss: 123.80466
Epoch 12, Val Loss: 99.74310
Epoch 13, Val Loss: 95.86165
Epoch 14, Val Loss: 106.29657
Epoch 15, Val Loss: 117.16844
Epoch 16, Val Loss: 95.13406
Epoch 17, Val Loss: 93.05554
Epoch 18, Val Loss: 108.17005
Epoch 19, Val Loss: 95.90079
Epoch 20, Val Loss: 98.74015
Epoch 21, Val Loss: 88.66309
Epoch 22, Val Loss: 112.42966
Epoch 23, Val Loss: 93.26658
Epoch 24, Val Loss: 93.15195
Epoch 25, Val Loss: 113.11360
Epoch 26, Val Loss: 89.92764
Epoch 27, Val Loss: 89.66696
Epoch 28, Val Loss: 96.59247
Epoch 29, Val Loss: 89.03593
Epoch 30, Val Loss: 97.60332
Epoch 31, Val Loss: 89.01329
Epoch 32, Val Loss: 102.08249
Epoch 33, Val Loss: 108.96936
Epoch 34, Val Loss: 95.57677
Epoch 35, Val Loss: 91.94221
Epoch 36, Val Loss: 88.05762
Epoch 37, Val Loss: 88.25544
Epoch 38, Val Loss: 83.96138
Epoch 39, Val Loss: 84.62108
Epoch 40, Val Loss: 88.15613
Epoch 41, Val Loss: 95.77779
Epoch 42, Val Loss: 82.42305
Epoch 43, Val Loss: 82.67265
Epoch 44, Val Loss: 85.60680
Epoch 45, Val Loss: 84.36927
Epoch 46, Val Loss: 80.30714
Epoch 47, Val Loss: 80.52654
Epoch 48, Val Loss: 77.82641
Epoch 49, Val Loss: 84.88197
Epoch 50, Val Loss: 81.62691
Epoch 51, Val Loss: 81.14856
Epoch 52, Val Loss: 92.38974
Epoch 53, Val Loss: 76.00300
Epoch 54, Val Loss: 77.43655
Epoch 55, Val Loss: 92.48088
Epoch 56, Val Loss: 77.03577
Epoch 57, Val Loss: 74.72332
Epoch 58, Val Loss: 75.32657
Epoch 59, Val Loss: 79.17752
Epoch 60, Val Loss: 78.32021
Epoch 61, Val Loss: 79.02142
Epoch 62, Val Loss: 78.16603
Epoch 63, Val Loss: 82.80032
Epoch 64, Val Loss: 88.18239
Epoch 65, Val Loss: 75.82790
Epoch 66, Val Loss: 77.26146
Epoch 67, Val Loss: 87.14188
Epoch 68, Val Loss: 82.51517
Epoch 69, Val Loss: 78.99753
Epoch 70, Val Loss: 85.67953
Epoch 71, Val Loss: 73.86335
Epoch 72, Val Loss: 75.36722
Epoch 73, Val Loss: 77.20821
Epoch 74, Val Loss: 77.20665
Epoch 75, Val Loss: 73.62173
Epoch 76, Val Loss: 73.56924
Epoch 77, Val Loss: 74.82064
Epoch 78, Val Loss: 75.48815
Epoch 79, Val Loss: 77.13712
Epoch 80, Val Loss: 85.09558
Epoch 81, Val Loss: 77.15872
Epoch 82, Val Loss: 76.55309
Epoch 83, Val Loss: 77.96021
Epoch 84, Val Loss: 82.27295
Epoch 85, Val Loss: 74.96461
Epoch 86, Val Loss: 78.12956
Epoch 87, Val Loss: 76.09819
Epoch 88, Val Loss: 74.20450
Epoch 89, Val Loss: 73.44974
Epoch 90, Val Loss: 73.52434
Epoch 91, Val Loss: 79.74109
Epoch 92, Val Loss: 86.84038
Epoch 93, Val Loss: 75.36263
Epoch 94, Val Loss: 75.14316
Epoch 95, Val Loss: 75.04741
Epoch 96, Val Loss: 78.11247
Epoch 97, Val Loss: 77.84609
Epoch 98, Val Loss: 74.14663
Epoch 99, Val Loss: 82.52722
DID NOT SAVE RESULTS
{'MSE - mean': 78.06372837240887, 'MSE - std': 7.751316128613183, 'R2 - mean': 0.5152060408511419, 'R2 - std': 0.028394470602320043} 
 

Results After CV: {'MSE - mean': 78.06372837240887, 'MSE - std': 7.751316128613183, 'R2 - mean': 0.5152060408511419, 'R2 - std': 0.028394470602320043}
Train time: 424.36468356441475
Inference time: 0.193919783399906
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 48 finished with value: 78.06372837240887 and parameters: {'p_m': 0.29631718745922775, 'alpha': 9.99043102871034, 'K': 2, 'beta': 5.3826802066371675}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1099.42639
Epoch 1, Val Loss: 410.23459
Epoch 2, Val Loss: 180.71092
Epoch 3, Val Loss: 161.55856
Epoch 4, Val Loss: 152.54930
Epoch 5, Val Loss: 136.51862
Epoch 6, Val Loss: 120.86057
Epoch 7, Val Loss: 125.85168
Epoch 8, Val Loss: 129.35156
Epoch 9, Val Loss: 120.07710
Epoch 10, Val Loss: 114.57010
Epoch 11, Val Loss: 111.38503
Epoch 12, Val Loss: 111.72041
Epoch 13, Val Loss: 116.60187
Epoch 14, Val Loss: 110.70193
Epoch 15, Val Loss: 114.50048
Epoch 16, Val Loss: 114.61597
Epoch 17, Val Loss: 113.69688
Epoch 18, Val Loss: 120.44059
Epoch 19, Val Loss: 118.99359
Epoch 20, Val Loss: 107.53586
Epoch 21, Val Loss: 124.05820
Epoch 22, Val Loss: 105.58101
Epoch 23, Val Loss: 111.66975
Epoch 24, Val Loss: 109.18538
Epoch 25, Val Loss: 100.81635
Epoch 26, Val Loss: 113.75022
Epoch 27, Val Loss: 107.55889
Epoch 28, Val Loss: 112.57483
Epoch 29, Val Loss: 104.57202
Epoch 30, Val Loss: 101.21918
Epoch 31, Val Loss: 95.21899
Epoch 32, Val Loss: 103.11909
Epoch 33, Val Loss: 104.84524
Epoch 34, Val Loss: 103.21590
Epoch 35, Val Loss: 95.57513
Epoch 36, Val Loss: 96.92328
Epoch 37, Val Loss: 99.10323
Epoch 38, Val Loss: 92.95889
Epoch 39, Val Loss: 99.14145
Epoch 40, Val Loss: 95.96408
Epoch 41, Val Loss: 89.35558
Epoch 42, Val Loss: 108.26608
Epoch 43, Val Loss: 108.05366
Epoch 44, Val Loss: 87.80937
Epoch 45, Val Loss: 89.08588
Epoch 46, Val Loss: 103.28010
Epoch 47, Val Loss: 98.42924
Epoch 48, Val Loss: 100.81993
Epoch 49, Val Loss: 85.98778
Epoch 50, Val Loss: 90.49005
Epoch 51, Val Loss: 89.82896
Epoch 52, Val Loss: 88.84869
Epoch 53, Val Loss: 90.24544
Epoch 54, Val Loss: 85.77267
Epoch 55, Val Loss: 91.19286
Epoch 56, Val Loss: 95.04949
Epoch 57, Val Loss: 93.35328
Epoch 58, Val Loss: 84.49154
Epoch 59, Val Loss: 87.42651
Epoch 60, Val Loss: 89.42335
Epoch 61, Val Loss: 88.59923
Epoch 62, Val Loss: 87.54351
Epoch 63, Val Loss: 96.01796
Epoch 64, Val Loss: 95.17776
Epoch 65, Val Loss: 91.03420
Epoch 66, Val Loss: 89.92440
Epoch 67, Val Loss: 87.32144
Epoch 68, Val Loss: 85.20107
Epoch 69, Val Loss: 91.50677
Epoch 70, Val Loss: 93.82666
Epoch 71, Val Loss: 88.95999
Epoch 72, Val Loss: 88.78882
Epoch 73, Val Loss: 90.46928
Epoch 74, Val Loss: 93.27321
Epoch 75, Val Loss: 88.76492
Epoch 76, Val Loss: 88.64322
Epoch 77, Val Loss: 96.87394
Epoch 78, Val Loss: 85.82504
Epoch 79, Val Loss: 87.76640
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.78237381170212, 'MSE - std': 0.0, 'R2 - mean': 0.4826355729083397, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 551.73334
Epoch 1, Val Loss: 285.66553
Epoch 2, Val Loss: 177.09134
Epoch 3, Val Loss: 145.86972
Epoch 4, Val Loss: 131.41936
Epoch 5, Val Loss: 131.33327
Epoch 6, Val Loss: 104.59428
Epoch 7, Val Loss: 108.18787
Epoch 8, Val Loss: 107.05418
Epoch 9, Val Loss: 113.12286
Epoch 10, Val Loss: 102.57975
Epoch 11, Val Loss: 97.34822
Epoch 12, Val Loss: 94.80286
Epoch 13, Val Loss: 94.02695
Epoch 14, Val Loss: 96.16527
Epoch 15, Val Loss: 99.46810
Epoch 16, Val Loss: 83.29637
Epoch 17, Val Loss: 95.25108
Epoch 18, Val Loss: 94.87492
Epoch 19, Val Loss: 98.56206
Epoch 20, Val Loss: 87.80298
Epoch 21, Val Loss: 80.60805
Epoch 22, Val Loss: 91.04297
Epoch 23, Val Loss: 91.64561
Epoch 24, Val Loss: 87.48970
Epoch 25, Val Loss: 87.33234
Epoch 26, Val Loss: 77.39062
Epoch 27, Val Loss: 105.06269
Epoch 28, Val Loss: 98.34626
Epoch 29, Val Loss: 81.46341
Epoch 30, Val Loss: 84.93130
Epoch 31, Val Loss: 83.99465
Epoch 32, Val Loss: 85.16408
Epoch 33, Val Loss: 80.31901
Epoch 34, Val Loss: 80.43659
Epoch 35, Val Loss: 87.99048
Epoch 36, Val Loss: 77.12138
Epoch 37, Val Loss: 83.79153
Epoch 38, Val Loss: 74.74381
Epoch 39, Val Loss: 74.24712
Epoch 40, Val Loss: 90.45589
Epoch 41, Val Loss: 83.13724
Epoch 42, Val Loss: 82.28650
Epoch 43, Val Loss: 86.70784
Epoch 44, Val Loss: 76.54595
Epoch 45, Val Loss: 75.81720
Epoch 46, Val Loss: 75.13659
Epoch 47, Val Loss: 82.12670
Epoch 48, Val Loss: 72.97270
Epoch 49, Val Loss: 74.29505
Epoch 50, Val Loss: 71.42650
Epoch 51, Val Loss: 75.01309
Epoch 52, Val Loss: 82.05571
Epoch 53, Val Loss: 71.29887
Epoch 54, Val Loss: 71.89086
Epoch 55, Val Loss: 73.29965
Epoch 56, Val Loss: 70.29437
Epoch 57, Val Loss: 72.32134
Epoch 58, Val Loss: 73.30856
Epoch 59, Val Loss: 74.18985
Epoch 60, Val Loss: 82.37989
Epoch 61, Val Loss: 82.86068
Epoch 62, Val Loss: 71.97717
Epoch 63, Val Loss: 76.28996
Epoch 64, Val Loss: 73.37086
Epoch 65, Val Loss: 75.18515
Epoch 66, Val Loss: 72.07400
Epoch 67, Val Loss: 74.51901
Epoch 68, Val Loss: 95.15134
Epoch 69, Val Loss: 76.80551
Epoch 70, Val Loss: 70.78828
Epoch 71, Val Loss: 74.02663
Epoch 72, Val Loss: 70.40569
Epoch 73, Val Loss: 77.56493
Epoch 74, Val Loss: 72.08887
Epoch 75, Val Loss: 69.35878
Epoch 76, Val Loss: 80.04430
Epoch 77, Val Loss: 72.72952
Epoch 78, Val Loss: 72.68350
Epoch 79, Val Loss: 72.02061
Epoch 80, Val Loss: 76.99384
Epoch 81, Val Loss: 73.75244
Epoch 82, Val Loss: 78.04153
Epoch 83, Val Loss: 72.74765
Epoch 84, Val Loss: 77.10085
Epoch 85, Val Loss: 75.03038
Epoch 86, Val Loss: 71.23676
Epoch 87, Val Loss: 72.68017
Epoch 88, Val Loss: 72.24549
Epoch 89, Val Loss: 86.68835
Epoch 90, Val Loss: 71.25869
Epoch 91, Val Loss: 73.37038
Epoch 92, Val Loss: 75.51731
Epoch 93, Val Loss: 77.91169
Epoch 94, Val Loss: 77.15920
Epoch 95, Val Loss: 72.08826
Epoch 96, Val Loss: 79.04757
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.80356800223251, 'MSE - std': 5.978805809469613, 'R2 - mean': 0.4962475410440453, 'R2 - std': 0.013611968135705588} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 924.68549
Epoch 1, Val Loss: 302.48599
Epoch 2, Val Loss: 185.28073
Epoch 3, Val Loss: 167.51540
Epoch 4, Val Loss: 145.75275
Epoch 5, Val Loss: 128.34541
Epoch 6, Val Loss: 115.94855
Epoch 7, Val Loss: 100.50852
Epoch 8, Val Loss: 98.81791
Epoch 9, Val Loss: 103.11127
Epoch 10, Val Loss: 88.26667
Epoch 11, Val Loss: 93.64288
Epoch 12, Val Loss: 83.94657
Epoch 13, Val Loss: 95.68166
Epoch 14, Val Loss: 82.78404
Epoch 15, Val Loss: 85.06916
Epoch 16, Val Loss: 95.33620
Epoch 17, Val Loss: 80.14103
Epoch 18, Val Loss: 93.49173
Epoch 19, Val Loss: 83.08360
Epoch 20, Val Loss: 92.02247
Epoch 21, Val Loss: 78.98943
Epoch 22, Val Loss: 94.54539
Epoch 23, Val Loss: 78.11972
Epoch 24, Val Loss: 84.60547
Epoch 25, Val Loss: 81.61179
Epoch 26, Val Loss: 85.14016
Epoch 27, Val Loss: 85.73477
Epoch 28, Val Loss: 77.55804
Epoch 29, Val Loss: 78.48245
Epoch 30, Val Loss: 81.71418
Epoch 31, Val Loss: 79.77963
Epoch 32, Val Loss: 104.16767
Epoch 33, Val Loss: 88.16868
Epoch 34, Val Loss: 76.38125
Epoch 35, Val Loss: 77.12227
Epoch 36, Val Loss: 78.97910
Epoch 37, Val Loss: 82.54472
Epoch 38, Val Loss: 104.20712
Epoch 39, Val Loss: 77.15725
Epoch 40, Val Loss: 82.13915
Epoch 41, Val Loss: 88.77624
Epoch 42, Val Loss: 84.17544
Epoch 43, Val Loss: 71.28012
Epoch 44, Val Loss: 83.44239
Epoch 45, Val Loss: 78.77070
Epoch 46, Val Loss: 73.43443
Epoch 47, Val Loss: 78.77498
Epoch 48, Val Loss: 81.85284
Epoch 49, Val Loss: 72.03746
Epoch 50, Val Loss: 84.46338
Epoch 51, Val Loss: 70.33302
Epoch 52, Val Loss: 70.92460
Epoch 53, Val Loss: 78.63914
Epoch 54, Val Loss: 79.37302
Epoch 55, Val Loss: 111.60974
Epoch 56, Val Loss: 72.22386
Epoch 57, Val Loss: 79.85866
Epoch 58, Val Loss: 74.24307
Epoch 59, Val Loss: 74.70882
Epoch 60, Val Loss: 89.69035
Epoch 61, Val Loss: 73.42876
Epoch 62, Val Loss: 72.21830
Epoch 63, Val Loss: 78.02047
Epoch 64, Val Loss: 74.96876
Epoch 65, Val Loss: 70.15602
Epoch 66, Val Loss: 75.75434
Epoch 67, Val Loss: 72.34482
Epoch 68, Val Loss: 70.85712
Epoch 69, Val Loss: 71.77289
Epoch 70, Val Loss: 69.90337
Epoch 71, Val Loss: 69.44595
Epoch 72, Val Loss: 71.56505
Epoch 73, Val Loss: 76.44038
Epoch 74, Val Loss: 71.66544
Epoch 75, Val Loss: 72.58694
Epoch 76, Val Loss: 75.09363
Epoch 77, Val Loss: 72.78215
Epoch 78, Val Loss: 77.86855
Epoch 79, Val Loss: 76.55964
Epoch 80, Val Loss: 75.12055
Epoch 81, Val Loss: 77.16389
Epoch 82, Val Loss: 74.10225
Epoch 83, Val Loss: 69.86566
Epoch 84, Val Loss: 83.25719
Epoch 85, Val Loss: 74.38024
Epoch 86, Val Loss: 69.35709
Epoch 87, Val Loss: 78.73856
Epoch 88, Val Loss: 74.00404
Epoch 89, Val Loss: 71.18958
Epoch 90, Val Loss: 71.66951
Epoch 91, Val Loss: 72.21194
Epoch 92, Val Loss: 69.50089
Epoch 93, Val Loss: 68.57762
Epoch 94, Val Loss: 71.81834
Epoch 95, Val Loss: 71.07944
Epoch 96, Val Loss: 75.42656
Epoch 97, Val Loss: 70.74709
Epoch 98, Val Loss: 71.03768
Epoch 99, Val Loss: 74.43999
DID NOT SAVE RESULTS
{'MSE - mean': 77.84979810624836, 'MSE - std': 8.53875976374493, 'R2 - mean': 0.5119490468669133, 'R2 - std': 0.024831398562359653} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 799.65564
Epoch 1, Val Loss: 414.71307
Epoch 2, Val Loss: 178.25934
Epoch 3, Val Loss: 176.71321
Epoch 4, Val Loss: 143.15771
Epoch 5, Val Loss: 136.05992
Epoch 6, Val Loss: 140.61414
Epoch 7, Val Loss: 127.18223
Epoch 8, Val Loss: 114.64902
Epoch 9, Val Loss: 131.59558
Epoch 10, Val Loss: 94.62438
Epoch 11, Val Loss: 96.67470
Epoch 12, Val Loss: 106.74588
Epoch 13, Val Loss: 102.68714
Epoch 14, Val Loss: 101.51928
Epoch 15, Val Loss: 102.22040
Epoch 16, Val Loss: 93.85402
Epoch 17, Val Loss: 93.05116
Epoch 18, Val Loss: 102.18571
Epoch 19, Val Loss: 108.77769
Epoch 20, Val Loss: 100.92123
Epoch 21, Val Loss: 92.27531
Epoch 22, Val Loss: 99.03551
Epoch 23, Val Loss: 94.02060
Epoch 24, Val Loss: 99.23297
Epoch 25, Val Loss: 95.16112
Epoch 26, Val Loss: 88.60233
Epoch 27, Val Loss: 97.73758
Epoch 28, Val Loss: 88.62189
Epoch 29, Val Loss: 90.77880
Epoch 30, Val Loss: 86.70009
Epoch 31, Val Loss: 88.97452
Epoch 32, Val Loss: 88.70605
Epoch 33, Val Loss: 91.62111
Epoch 34, Val Loss: 91.39248
Epoch 35, Val Loss: 87.58447
Epoch 36, Val Loss: 96.49922
Epoch 37, Val Loss: 84.66460
Epoch 38, Val Loss: 86.43828
Epoch 39, Val Loss: 87.43397
Epoch 40, Val Loss: 86.89384
Epoch 41, Val Loss: 86.14857
Epoch 42, Val Loss: 82.88831
Epoch 43, Val Loss: 87.69705
Epoch 44, Val Loss: 83.35336
Epoch 45, Val Loss: 81.78953
Epoch 46, Val Loss: 83.30287
Epoch 47, Val Loss: 85.59522
Epoch 48, Val Loss: 88.95956
Epoch 49, Val Loss: 86.58251
Epoch 50, Val Loss: 91.26521
Epoch 51, Val Loss: 84.50195
Epoch 52, Val Loss: 84.00510
Epoch 53, Val Loss: 97.92014
Epoch 54, Val Loss: 79.47243
Epoch 55, Val Loss: 91.20615
Epoch 56, Val Loss: 83.49746
Epoch 57, Val Loss: 84.96376
Epoch 58, Val Loss: 89.37627
Epoch 59, Val Loss: 87.49206
Epoch 60, Val Loss: 84.83793
Epoch 61, Val Loss: 82.51340
Epoch 62, Val Loss: 83.73584
Epoch 63, Val Loss: 79.91279
Epoch 64, Val Loss: 81.08231
Epoch 65, Val Loss: 81.39304
Epoch 66, Val Loss: 80.77959
Epoch 67, Val Loss: 82.41737
Epoch 68, Val Loss: 80.43404
Epoch 69, Val Loss: 82.22097
Epoch 70, Val Loss: 78.85709
Epoch 71, Val Loss: 81.77867
Epoch 72, Val Loss: 78.06335
Epoch 73, Val Loss: 88.14240
Epoch 74, Val Loss: 87.58684
Epoch 75, Val Loss: 81.61021
Epoch 76, Val Loss: 80.81214
Epoch 77, Val Loss: 80.92351
Epoch 78, Val Loss: 82.24095
Epoch 79, Val Loss: 79.33366
Epoch 80, Val Loss: 81.47625
Epoch 81, Val Loss: 81.38955
Epoch 82, Val Loss: 84.56831
Epoch 83, Val Loss: 81.19276
Epoch 84, Val Loss: 80.82030
Epoch 85, Val Loss: 81.05100
Epoch 86, Val Loss: 81.36393
Epoch 87, Val Loss: 80.76247
Epoch 88, Val Loss: 86.16678
Epoch 89, Val Loss: 79.14772
Epoch 90, Val Loss: 90.48521
Epoch 91, Val Loss: 90.03326
Epoch 92, Val Loss: 82.14512
Epoch 93, Val Loss: 82.14795
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.19090094458255, 'MSE - std': 8.433569898102547, 'R2 - mean': 0.503299913138974, 'R2 - std': 0.026208229788625522} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 979.01868
Epoch 1, Val Loss: 442.67194
Epoch 2, Val Loss: 173.05428
Epoch 3, Val Loss: 138.54912
Epoch 4, Val Loss: 128.36159
Epoch 5, Val Loss: 114.80443
Epoch 6, Val Loss: 114.08197
Epoch 7, Val Loss: 139.07324
Epoch 8, Val Loss: 109.07076
Epoch 9, Val Loss: 110.63954
Epoch 10, Val Loss: 101.97222
Epoch 11, Val Loss: 101.67186
Epoch 12, Val Loss: 119.76628
Epoch 13, Val Loss: 104.46622
Epoch 14, Val Loss: 99.34104
Epoch 15, Val Loss: 112.94468
Epoch 16, Val Loss: 98.20460
Epoch 17, Val Loss: 94.62315
Epoch 18, Val Loss: 101.25924
Epoch 19, Val Loss: 106.85577
Epoch 20, Val Loss: 90.67424
Epoch 21, Val Loss: 97.24182
Epoch 22, Val Loss: 88.43433
Epoch 23, Val Loss: 111.76490
Epoch 24, Val Loss: 94.99835
Epoch 25, Val Loss: 89.66718
Epoch 26, Val Loss: 95.62602
Epoch 27, Val Loss: 86.77032
Epoch 28, Val Loss: 92.74487
Epoch 29, Val Loss: 86.23081
Epoch 30, Val Loss: 102.81219
Epoch 31, Val Loss: 87.88092
Epoch 32, Val Loss: 98.40505
Epoch 33, Val Loss: 87.28117
Epoch 34, Val Loss: 81.45879
Epoch 35, Val Loss: 93.14388
Epoch 36, Val Loss: 88.24321
Epoch 37, Val Loss: 85.54846
Epoch 38, Val Loss: 82.23635
Epoch 39, Val Loss: 89.95573
Epoch 40, Val Loss: 83.26488
Epoch 41, Val Loss: 80.58584
Epoch 42, Val Loss: 88.93946
Epoch 43, Val Loss: 82.88971
Epoch 44, Val Loss: 93.82145
Epoch 45, Val Loss: 78.75667
Epoch 46, Val Loss: 84.10372
Epoch 47, Val Loss: 79.99861
Epoch 48, Val Loss: 72.15367
Epoch 49, Val Loss: 81.24171
Epoch 50, Val Loss: 78.14106
Epoch 51, Val Loss: 76.83215
Epoch 52, Val Loss: 76.36562
Epoch 53, Val Loss: 77.65816
Epoch 54, Val Loss: 76.22830
Epoch 55, Val Loss: 74.03561
Epoch 56, Val Loss: 83.85339
Epoch 57, Val Loss: 79.52177
Epoch 58, Val Loss: 81.65269
Epoch 59, Val Loss: 75.50764
Epoch 60, Val Loss: 74.75552
Epoch 61, Val Loss: 75.21899
Epoch 62, Val Loss: 74.47551
Epoch 63, Val Loss: 77.06154
Epoch 64, Val Loss: 80.77367
Epoch 65, Val Loss: 77.89223
Epoch 66, Val Loss: 78.33220
Epoch 67, Val Loss: 81.52084
Epoch 68, Val Loss: 77.78798
Epoch 69, Val Loss: 80.87584
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.6215550763092, 'MSE - std': 8.170157085271468, 'R2 - mean': 0.5118983430672261, 'R2 - std': 0.02907282297691377} 
 

Results After CV: {'MSE - mean': 78.6215550763092, 'MSE - std': 8.170157085271468, 'R2 - mean': 0.5118983430672261, 'R2 - std': 0.02907282297691377}
Train time: 425.1582284321892
Inference time: 0.1910051316022873
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 49 finished with value: 78.6215550763092 and parameters: {'p_m': 0.2921517956962912, 'alpha': 9.960355984016271, 'K': 2, 'beta': 5.407882561686133}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1120.83008
Epoch 1, Val Loss: 384.83142
Epoch 2, Val Loss: 162.84103
Epoch 3, Val Loss: 142.35956
Epoch 4, Val Loss: 124.43610
Epoch 5, Val Loss: 117.56631
Epoch 6, Val Loss: 111.59084
Epoch 7, Val Loss: 123.44324
Epoch 8, Val Loss: 106.75945
Epoch 9, Val Loss: 108.11039
Epoch 10, Val Loss: 99.37535
Epoch 11, Val Loss: 107.96555
Epoch 12, Val Loss: 103.03667
Epoch 13, Val Loss: 106.28120
Epoch 14, Val Loss: 102.78674
Epoch 15, Val Loss: 100.59740
Epoch 16, Val Loss: 104.34025
Epoch 17, Val Loss: 103.82259
Epoch 18, Val Loss: 101.33698
Epoch 19, Val Loss: 104.70874
Epoch 20, Val Loss: 106.26175
Epoch 21, Val Loss: 101.56919
Epoch 22, Val Loss: 101.54317
Epoch 23, Val Loss: 116.11092
Epoch 24, Val Loss: 108.11791
Epoch 25, Val Loss: 97.26389
Epoch 26, Val Loss: 103.65150
Epoch 27, Val Loss: 91.42178
Epoch 28, Val Loss: 96.55605
Epoch 29, Val Loss: 99.99768
Epoch 30, Val Loss: 95.42303
Epoch 31, Val Loss: 97.17226
Epoch 32, Val Loss: 96.15781
Epoch 33, Val Loss: 97.87891
Epoch 34, Val Loss: 96.78777
Epoch 35, Val Loss: 98.54895
Epoch 36, Val Loss: 94.05641
Epoch 37, Val Loss: 100.91579
Epoch 38, Val Loss: 109.71416
Epoch 39, Val Loss: 95.96935
Epoch 40, Val Loss: 92.74221
Epoch 41, Val Loss: 93.34759
Epoch 42, Val Loss: 102.06111
Epoch 43, Val Loss: 115.59398
Epoch 44, Val Loss: 102.85766
Epoch 45, Val Loss: 100.73409
Epoch 46, Val Loss: 93.03127
Epoch 47, Val Loss: 94.69801
Epoch 48, Val Loss: 97.79514
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 95.028244628348, 'MSE - std': 0.0, 'R2 - mean': 0.4462388058699187, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1635.24634
Epoch 1, Val Loss: 358.35504
Epoch 2, Val Loss: 159.33884
Epoch 3, Val Loss: 151.62581
Epoch 4, Val Loss: 123.08665
Epoch 5, Val Loss: 114.38714
Epoch 6, Val Loss: 112.69643
Epoch 7, Val Loss: 112.36935
Epoch 8, Val Loss: 102.15302
Epoch 9, Val Loss: 99.26154
Epoch 10, Val Loss: 100.73133
Epoch 11, Val Loss: 92.59268
Epoch 12, Val Loss: 102.31646
Epoch 13, Val Loss: 93.31074
Epoch 14, Val Loss: 87.84009
Epoch 15, Val Loss: 92.27161
Epoch 16, Val Loss: 86.53683
Epoch 17, Val Loss: 90.05468
Epoch 18, Val Loss: 93.22852
Epoch 19, Val Loss: 95.43388
Epoch 20, Val Loss: 89.99885
Epoch 21, Val Loss: 97.65582
Epoch 22, Val Loss: 87.11273
Epoch 23, Val Loss: 91.34416
Epoch 24, Val Loss: 89.64136
Epoch 25, Val Loss: 99.22036
Epoch 26, Val Loss: 78.89345
Epoch 27, Val Loss: 97.10901
Epoch 28, Val Loss: 84.37734
Epoch 29, Val Loss: 93.40953
Epoch 30, Val Loss: 81.55059
Epoch 31, Val Loss: 83.78575
Epoch 32, Val Loss: 89.36786
Epoch 33, Val Loss: 87.99230
Epoch 34, Val Loss: 79.29676
Epoch 35, Val Loss: 95.56854
Epoch 36, Val Loss: 84.50107
Epoch 37, Val Loss: 81.80065
Epoch 38, Val Loss: 82.18071
Epoch 39, Val Loss: 79.39266
Epoch 40, Val Loss: 82.62957
Epoch 41, Val Loss: 80.48611
Epoch 42, Val Loss: 89.14639
Epoch 43, Val Loss: 92.21584
Epoch 44, Val Loss: 80.40467
Epoch 45, Val Loss: 85.34579
Epoch 46, Val Loss: 90.83941
Epoch 47, Val Loss: 82.85401
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 91.82187923880028, 'MSE - std': 3.2063653895477344, 'R2 - mean': 0.4404367742313405, 'R2 - std': 0.005802031638578231} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1191.09595
Epoch 1, Val Loss: 356.08630
Epoch 2, Val Loss: 144.90901
Epoch 3, Val Loss: 120.28593
Epoch 4, Val Loss: 108.34505
Epoch 5, Val Loss: 104.62435
Epoch 6, Val Loss: 93.95621
Epoch 7, Val Loss: 92.03012
Epoch 8, Val Loss: 88.47109
Epoch 9, Val Loss: 96.72855
Epoch 10, Val Loss: 84.27405
Epoch 11, Val Loss: 87.80499
Epoch 12, Val Loss: 82.92635
Epoch 13, Val Loss: 79.89812
Epoch 14, Val Loss: 85.96066
Epoch 15, Val Loss: 78.33487
Epoch 16, Val Loss: 82.92390
Epoch 17, Val Loss: 92.81413
Epoch 18, Val Loss: 83.08169
Epoch 19, Val Loss: 84.32460
Epoch 20, Val Loss: 77.17879
Epoch 21, Val Loss: 75.52066
Epoch 22, Val Loss: 82.33877
Epoch 23, Val Loss: 80.01657
Epoch 24, Val Loss: 80.53296
Epoch 25, Val Loss: 79.08044
Epoch 26, Val Loss: 84.18242
Epoch 27, Val Loss: 78.53377
Epoch 28, Val Loss: 88.91035
Epoch 29, Val Loss: 78.12848
Epoch 30, Val Loss: 83.85471
Epoch 31, Val Loss: 78.83595
Epoch 32, Val Loss: 87.15087
Epoch 33, Val Loss: 86.43839
Epoch 34, Val Loss: 78.14302
Epoch 35, Val Loss: 85.10040
Epoch 36, Val Loss: 97.06732
Epoch 37, Val Loss: 78.40419
Epoch 38, Val Loss: 77.23520
Epoch 39, Val Loss: 83.01752
Epoch 40, Val Loss: 85.83723
Epoch 41, Val Loss: 85.11638
Epoch 42, Val Loss: 74.78505
Epoch 43, Val Loss: 84.47475
Epoch 44, Val Loss: 84.05132
Epoch 45, Val Loss: 85.07421
Epoch 46, Val Loss: 82.74013
Epoch 47, Val Loss: 81.13369
Epoch 48, Val Loss: 85.53312
Epoch 49, Val Loss: 84.41186
Epoch 50, Val Loss: 84.83755
Epoch 51, Val Loss: 81.09312
Epoch 52, Val Loss: 85.31795
Epoch 53, Val Loss: 80.73270
Epoch 54, Val Loss: 85.40683
Epoch 55, Val Loss: 74.82910
Epoch 56, Val Loss: 74.72630
Epoch 57, Val Loss: 75.62650
Epoch 58, Val Loss: 78.63960
Epoch 59, Val Loss: 83.43034
Epoch 60, Val Loss: 73.43964
Epoch 61, Val Loss: 77.74753
Epoch 62, Val Loss: 74.46761
Epoch 63, Val Loss: 76.11121
Epoch 64, Val Loss: 75.24612
Epoch 65, Val Loss: 83.83002
Epoch 66, Val Loss: 73.97989
Epoch 67, Val Loss: 75.09264
Epoch 68, Val Loss: 73.67430
Epoch 69, Val Loss: 89.70002
Epoch 70, Val Loss: 74.83133
Epoch 71, Val Loss: 75.81754
Epoch 72, Val Loss: 72.84839
Epoch 73, Val Loss: 78.60873
Epoch 74, Val Loss: 72.02798
Epoch 75, Val Loss: 75.72465
Epoch 76, Val Loss: 75.16382
Epoch 77, Val Loss: 77.57175
Epoch 78, Val Loss: 75.30726
Epoch 79, Val Loss: 84.00910
Epoch 80, Val Loss: 70.67152
Epoch 81, Val Loss: 75.93155
Epoch 82, Val Loss: 71.49182
Epoch 83, Val Loss: 70.82752
Epoch 84, Val Loss: 73.96121
Epoch 85, Val Loss: 74.47400
Epoch 86, Val Loss: 73.87202
Epoch 87, Val Loss: 90.68820
Epoch 88, Val Loss: 72.95351
Epoch 89, Val Loss: 103.69981
Epoch 90, Val Loss: 73.03999
Epoch 91, Val Loss: 71.55145
Epoch 92, Val Loss: 75.54891
Epoch 93, Val Loss: 77.22334
Epoch 94, Val Loss: 75.53440
Epoch 95, Val Loss: 70.97273
Epoch 96, Val Loss: 72.82577
Epoch 97, Val Loss: 71.89246
Epoch 98, Val Loss: 73.93594
Epoch 99, Val Loss: 71.77334
DID NOT SAVE RESULTS
{'MSE - mean': 85.04632898235444, 'MSE - std': 9.933278171351065, 'R2 - mean': 0.46678189166306133, 'R2 - std': 0.03755759318352328} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1695.38306
Epoch 1, Val Loss: 296.40454
Epoch 2, Val Loss: 153.61044
Epoch 3, Val Loss: 146.28917
Epoch 4, Val Loss: 121.88316
Epoch 5, Val Loss: 124.04298
Epoch 6, Val Loss: 110.24692
Epoch 7, Val Loss: 108.11391
Epoch 8, Val Loss: 103.30028
Epoch 9, Val Loss: 105.18842
Epoch 10, Val Loss: 105.50252
Epoch 11, Val Loss: 99.13622
Epoch 12, Val Loss: 97.71176
Epoch 13, Val Loss: 107.05311
Epoch 14, Val Loss: 100.00232
Epoch 15, Val Loss: 91.94331
Epoch 16, Val Loss: 91.78233
Epoch 17, Val Loss: 94.04942
Epoch 18, Val Loss: 97.50587
Epoch 19, Val Loss: 89.86831
Epoch 20, Val Loss: 93.94506
Epoch 21, Val Loss: 102.09843
Epoch 22, Val Loss: 98.49580
Epoch 23, Val Loss: 92.14762
Epoch 24, Val Loss: 92.67524
Epoch 25, Val Loss: 96.63589
Epoch 26, Val Loss: 90.26038
Epoch 27, Val Loss: 97.46974
Epoch 28, Val Loss: 98.58441
Epoch 29, Val Loss: 90.02458
Epoch 30, Val Loss: 93.57427
Epoch 31, Val Loss: 96.71551
Epoch 32, Val Loss: 92.20518
Epoch 33, Val Loss: 87.34058
Epoch 34, Val Loss: 91.84667
Epoch 35, Val Loss: 85.37875
Epoch 36, Val Loss: 87.48306
Epoch 37, Val Loss: 103.25122
Epoch 38, Val Loss: 84.52699
Epoch 39, Val Loss: 91.07217
Epoch 40, Val Loss: 89.93144
Epoch 41, Val Loss: 86.24863
Epoch 42, Val Loss: 103.77612
Epoch 43, Val Loss: 82.74140
Epoch 44, Val Loss: 88.82941
Epoch 45, Val Loss: 88.14120
Epoch 46, Val Loss: 87.51058
Epoch 47, Val Loss: 91.64288
Epoch 48, Val Loss: 96.22237
Epoch 49, Val Loss: 88.17234
Epoch 50, Val Loss: 88.47602
Epoch 51, Val Loss: 83.92763
Epoch 52, Val Loss: 78.89363
Epoch 53, Val Loss: 83.64180
Epoch 54, Val Loss: 92.43205
Epoch 55, Val Loss: 84.20343
Epoch 56, Val Loss: 87.27483
Epoch 57, Val Loss: 84.34629
Epoch 58, Val Loss: 90.62122
Epoch 59, Val Loss: 87.26257
Epoch 60, Val Loss: 89.07346
Epoch 61, Val Loss: 86.86575
Epoch 62, Val Loss: 83.90144
Epoch 63, Val Loss: 79.42208
Epoch 64, Val Loss: 84.75923
Epoch 65, Val Loss: 85.25845
Epoch 66, Val Loss: 80.53519
Epoch 67, Val Loss: 86.17626
Epoch 68, Val Loss: 89.70647
Epoch 69, Val Loss: 86.60861
Epoch 70, Val Loss: 81.49029
Epoch 71, Val Loss: 83.13137
Epoch 72, Val Loss: 85.94337
Epoch 73, Val Loss: 83.72307
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.49183475244133, 'MSE - std': 8.95940691207533, 'R2 - mean': 0.46400994008924556, 'R2 - std': 0.03287827171380842} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1055.77209
Epoch 1, Val Loss: 361.37048
Epoch 2, Val Loss: 164.68726
Epoch 3, Val Loss: 130.72124
Epoch 4, Val Loss: 132.12000
Epoch 5, Val Loss: 118.18246
Epoch 6, Val Loss: 106.38313
Epoch 7, Val Loss: 96.97906
Epoch 8, Val Loss: 105.20670
Epoch 9, Val Loss: 101.40511
Epoch 10, Val Loss: 95.29553
Epoch 11, Val Loss: 104.15877
Epoch 12, Val Loss: 88.78268
Epoch 13, Val Loss: 90.91475
Epoch 14, Val Loss: 97.57228
Epoch 15, Val Loss: 93.41077
Epoch 16, Val Loss: 90.87679
Epoch 17, Val Loss: 88.93404
Epoch 18, Val Loss: 94.75388
Epoch 19, Val Loss: 90.92928
Epoch 20, Val Loss: 86.40347
Epoch 21, Val Loss: 85.96695
Epoch 22, Val Loss: 97.35917
Epoch 23, Val Loss: 95.39024
Epoch 24, Val Loss: 95.44568
Epoch 25, Val Loss: 90.44620
Epoch 26, Val Loss: 87.62445
Epoch 27, Val Loss: 92.66713
Epoch 28, Val Loss: 86.91879
Epoch 29, Val Loss: 83.56627
Epoch 30, Val Loss: 84.78619
Epoch 31, Val Loss: 84.28797
Epoch 32, Val Loss: 78.99388
Epoch 33, Val Loss: 84.46751
Epoch 34, Val Loss: 80.37456
Epoch 35, Val Loss: 84.91163
Epoch 36, Val Loss: 85.50591
Epoch 37, Val Loss: 91.34045
Epoch 38, Val Loss: 92.29932
Epoch 39, Val Loss: 87.81760
Epoch 40, Val Loss: 85.05099
Epoch 41, Val Loss: 84.97391
Epoch 42, Val Loss: 85.79727
Epoch 43, Val Loss: 83.41316
Epoch 44, Val Loss: 89.91858
Epoch 45, Val Loss: 84.49770
Epoch 46, Val Loss: 92.92387
Epoch 47, Val Loss: 87.52457
Epoch 48, Val Loss: 80.70940
Epoch 49, Val Loss: 90.03383
Epoch 50, Val Loss: 89.51532
Epoch 51, Val Loss: 99.22087
Epoch 52, Val Loss: 82.66593
Epoch 53, Val Loss: 93.27165
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.86131475121805, 'MSE - std': 8.65165646974447, 'R2 - mean': 0.47294673264636095, 'R2 - std': 0.0344129284651171} 
 

Results After CV: {'MSE - mean': 84.86131475121805, 'MSE - std': 8.65165646974447, 'R2 - mean': 0.47294673264636095, 'R2 - std': 0.0344129284651171}
Train time: 302.02106934679324
Inference time: 0.20970683100749737
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 50 finished with value: 84.86131475121805 and parameters: {'p_m': 0.20151924190433046, 'alpha': 2.333247002983965, 'K': 2, 'beta': 3.8541221380707085}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 831.10449
Epoch 1, Val Loss: 483.93927
Epoch 2, Val Loss: 174.28246
Epoch 3, Val Loss: 150.52066
Epoch 4, Val Loss: 130.48694
Epoch 5, Val Loss: 107.11483
Epoch 6, Val Loss: 107.19207
Epoch 7, Val Loss: 103.67497
Epoch 8, Val Loss: 119.14706
Epoch 9, Val Loss: 118.32355
Epoch 10, Val Loss: 96.13907
Epoch 11, Val Loss: 99.29781
Epoch 12, Val Loss: 96.93423
Epoch 13, Val Loss: 99.87989
Epoch 14, Val Loss: 95.78284
Epoch 15, Val Loss: 98.27119
Epoch 16, Val Loss: 97.56787
Epoch 17, Val Loss: 110.20584
Epoch 18, Val Loss: 100.64111
Epoch 19, Val Loss: 97.33423
Epoch 20, Val Loss: 101.23844
Epoch 21, Val Loss: 122.15523
Epoch 22, Val Loss: 96.80166
Epoch 23, Val Loss: 105.31393
Epoch 24, Val Loss: 91.72107
Epoch 25, Val Loss: 97.74197
Epoch 26, Val Loss: 109.38328
Epoch 27, Val Loss: 97.98813
Epoch 28, Val Loss: 107.22820
Epoch 29, Val Loss: 97.40422
Epoch 30, Val Loss: 94.54163
Epoch 31, Val Loss: 96.76843
Epoch 32, Val Loss: 94.73869
Epoch 33, Val Loss: 108.03394
Epoch 34, Val Loss: 115.74193
Epoch 35, Val Loss: 99.60444
Epoch 36, Val Loss: 98.57950
Epoch 37, Val Loss: 92.13531
Epoch 38, Val Loss: 95.41747
Epoch 39, Val Loss: 105.04569
Epoch 40, Val Loss: 98.77868
Epoch 41, Val Loss: 115.01524
Epoch 42, Val Loss: 104.84982
Epoch 43, Val Loss: 96.71490
Epoch 44, Val Loss: 99.75608
Epoch 45, Val Loss: 93.20920
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 97.19456081255571, 'MSE - std': 0.0, 'R2 - mean': 0.4336149608044664, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1305.03418
Epoch 1, Val Loss: 465.75742
Epoch 2, Val Loss: 168.71976
Epoch 3, Val Loss: 140.44019
Epoch 4, Val Loss: 122.00867
Epoch 5, Val Loss: 111.88673
Epoch 6, Val Loss: 108.21237
Epoch 7, Val Loss: 99.73457
Epoch 8, Val Loss: 92.34300
Epoch 9, Val Loss: 89.54921
Epoch 10, Val Loss: 95.00386
Epoch 11, Val Loss: 86.92456
Epoch 12, Val Loss: 96.19646
Epoch 13, Val Loss: 89.36174
Epoch 14, Val Loss: 85.69571
Epoch 15, Val Loss: 83.80991
Epoch 16, Val Loss: 82.46227
Epoch 17, Val Loss: 87.53041
Epoch 18, Val Loss: 83.48234
Epoch 19, Val Loss: 81.44172
Epoch 20, Val Loss: 80.17894
Epoch 21, Val Loss: 83.08610
Epoch 22, Val Loss: 75.11632
Epoch 23, Val Loss: 82.96751
Epoch 24, Val Loss: 79.63725
Epoch 25, Val Loss: 84.09041
Epoch 26, Val Loss: 77.99895
Epoch 27, Val Loss: 82.99618
Epoch 28, Val Loss: 84.48151
Epoch 29, Val Loss: 81.93550
Epoch 30, Val Loss: 77.95547
Epoch 31, Val Loss: 80.32157
Epoch 32, Val Loss: 78.35501
Epoch 33, Val Loss: 78.24551
Epoch 34, Val Loss: 86.89865
Epoch 35, Val Loss: 87.79545
Epoch 36, Val Loss: 81.27373
Epoch 37, Val Loss: 79.06468
Epoch 38, Val Loss: 77.64172
Epoch 39, Val Loss: 79.59233
Epoch 40, Val Loss: 82.49168
Epoch 41, Val Loss: 81.37408
Epoch 42, Val Loss: 90.24633
Epoch 43, Val Loss: 76.74870
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 90.27699331852915, 'MSE - std': 6.917567494026557, 'R2 - mean': 0.4508917214598334, 'R2 - std': 0.01727676065536704} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 772.96472
Epoch 1, Val Loss: 425.46527
Epoch 2, Val Loss: 151.03487
Epoch 3, Val Loss: 135.63908
Epoch 4, Val Loss: 115.73222
Epoch 5, Val Loss: 97.53825
Epoch 6, Val Loss: 103.58328
Epoch 7, Val Loss: 108.58035
Epoch 8, Val Loss: 90.36810
Epoch 9, Val Loss: 92.79916
Epoch 10, Val Loss: 90.73705
Epoch 11, Val Loss: 87.39640
Epoch 12, Val Loss: 95.91612
Epoch 13, Val Loss: 97.65834
Epoch 14, Val Loss: 89.34351
Epoch 15, Val Loss: 80.29530
Epoch 16, Val Loss: 81.71252
Epoch 17, Val Loss: 76.52299
Epoch 18, Val Loss: 83.71493
Epoch 19, Val Loss: 78.01193
Epoch 20, Val Loss: 82.81491
Epoch 21, Val Loss: 100.02986
Epoch 22, Val Loss: 83.83801
Epoch 23, Val Loss: 85.63229
Epoch 24, Val Loss: 76.67062
Epoch 25, Val Loss: 81.19127
Epoch 26, Val Loss: 81.03020
Epoch 27, Val Loss: 87.01549
Epoch 28, Val Loss: 77.81183
Epoch 29, Val Loss: 79.27154
Epoch 30, Val Loss: 84.59831
Epoch 31, Val Loss: 84.65327
Epoch 32, Val Loss: 95.48447
Epoch 33, Val Loss: 81.73520
Epoch 34, Val Loss: 81.19359
Epoch 35, Val Loss: 79.66149
Epoch 36, Val Loss: 82.52695
Epoch 37, Val Loss: 84.23293
Epoch 38, Val Loss: 81.23595
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.18792705778492, 'MSE - std': 8.083486404956846, 'R2 - mean': 0.45915680053350805, 'R2 - std': 0.018319771742121013} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 990.75562
Epoch 1, Val Loss: 352.13837
Epoch 2, Val Loss: 167.09261
Epoch 3, Val Loss: 152.85323
Epoch 4, Val Loss: 158.81100
Epoch 5, Val Loss: 113.98882
Epoch 6, Val Loss: 119.87170
Epoch 7, Val Loss: 110.94763
Epoch 8, Val Loss: 107.71393
Epoch 9, Val Loss: 107.77070
Epoch 10, Val Loss: 99.24990
Epoch 11, Val Loss: 101.33062
Epoch 12, Val Loss: 106.60592
Epoch 13, Val Loss: 98.68948
Epoch 14, Val Loss: 95.94648
Epoch 15, Val Loss: 97.28427
Epoch 16, Val Loss: 101.71703
Epoch 17, Val Loss: 92.33885
Epoch 18, Val Loss: 99.36610
Epoch 19, Val Loss: 108.56287
Epoch 20, Val Loss: 89.01811
Epoch 21, Val Loss: 101.38040
Epoch 22, Val Loss: 94.81787
Epoch 23, Val Loss: 92.85960
Epoch 24, Val Loss: 85.42220
Epoch 25, Val Loss: 92.67471
Epoch 26, Val Loss: 89.92150
Epoch 27, Val Loss: 94.33058
Epoch 28, Val Loss: 90.68938
Epoch 29, Val Loss: 97.90432
Epoch 30, Val Loss: 93.19917
Epoch 31, Val Loss: 88.93406
Epoch 32, Val Loss: 94.96091
Epoch 33, Val Loss: 95.35999
Epoch 34, Val Loss: 92.18267
Epoch 35, Val Loss: 89.75491
Epoch 36, Val Loss: 88.30428
Epoch 37, Val Loss: 96.25385
Epoch 38, Val Loss: 87.93005
Epoch 39, Val Loss: 93.44106
Epoch 40, Val Loss: 91.09976
Epoch 41, Val Loss: 93.41116
Epoch 42, Val Loss: 85.35357
Epoch 43, Val Loss: 93.43327
Epoch 44, Val Loss: 92.68121
Epoch 45, Val Loss: 86.13506
Epoch 46, Val Loss: 89.14978
Epoch 47, Val Loss: 85.52190
Epoch 48, Val Loss: 88.18851
Epoch 49, Val Loss: 84.16915
Epoch 50, Val Loss: 89.66006
Epoch 51, Val Loss: 90.37484
Epoch 52, Val Loss: 88.80305
Epoch 53, Val Loss: 83.71331
Epoch 54, Val Loss: 86.85127
Epoch 55, Val Loss: 91.58428
Epoch 56, Val Loss: 90.82377
Epoch 57, Val Loss: 87.84490
Epoch 58, Val Loss: 96.24705
Epoch 59, Val Loss: 82.18114
Epoch 60, Val Loss: 83.78186
Epoch 61, Val Loss: 89.02539
Epoch 62, Val Loss: 85.14689
Epoch 63, Val Loss: 90.88216
Epoch 64, Val Loss: 85.77982
Epoch 65, Val Loss: 82.79086
Epoch 66, Val Loss: 83.57965
Epoch 67, Val Loss: 87.91608
Epoch 68, Val Loss: 88.76909
Epoch 69, Val Loss: 98.88713
Epoch 70, Val Loss: 84.61723
Epoch 71, Val Loss: 88.45008
Epoch 72, Val Loss: 89.87648
Epoch 73, Val Loss: 84.82004
Epoch 74, Val Loss: 90.52825
Epoch 75, Val Loss: 81.23779
Epoch 76, Val Loss: 89.67335
Epoch 77, Val Loss: 108.76407
Epoch 78, Val Loss: 91.91132
Epoch 79, Val Loss: 83.69624
Epoch 80, Val Loss: 88.78922
Epoch 81, Val Loss: 84.08261
Epoch 82, Val Loss: 83.02289
Epoch 83, Val Loss: 88.43680
Epoch 84, Val Loss: 87.72678
Epoch 85, Val Loss: 89.99059
Epoch 86, Val Loss: 83.78922
Epoch 87, Val Loss: 84.58521
Epoch 88, Val Loss: 85.47751
Epoch 89, Val Loss: 85.18903
Epoch 90, Val Loss: 83.79781
Epoch 91, Val Loss: 89.70335
Epoch 92, Val Loss: 89.61059
Epoch 93, Val Loss: 83.36684
Epoch 94, Val Loss: 81.31571
Epoch 95, Val Loss: 81.55480
Epoch 96, Val Loss: 82.87918
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.96919012827529, 'MSE - std': 7.130089782062895, 'R2 - mean': 0.4605614104714403, 'R2 - std': 0.016050835328598176} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1183.20715
Epoch 1, Val Loss: 393.71863
Epoch 2, Val Loss: 180.22131
Epoch 3, Val Loss: 145.56529
Epoch 4, Val Loss: 118.22459
Epoch 5, Val Loss: 114.21350
Epoch 6, Val Loss: 105.91883
Epoch 7, Val Loss: 102.78780
Epoch 8, Val Loss: 107.53310
Epoch 9, Val Loss: 108.64934
Epoch 10, Val Loss: 96.59187
Epoch 11, Val Loss: 101.60591
Epoch 12, Val Loss: 97.71410
Epoch 13, Val Loss: 105.14120
Epoch 14, Val Loss: 107.79116
Epoch 15, Val Loss: 107.73154
Epoch 16, Val Loss: 101.15110
Epoch 17, Val Loss: 99.82427
Epoch 18, Val Loss: 97.87894
Epoch 19, Val Loss: 102.18713
Epoch 20, Val Loss: 113.12061
Epoch 21, Val Loss: 102.47987
Epoch 22, Val Loss: 105.50446
Epoch 23, Val Loss: 101.43634
Epoch 24, Val Loss: 109.71788
Epoch 25, Val Loss: 93.32608
Epoch 26, Val Loss: 92.47550
Epoch 27, Val Loss: 96.93954
Epoch 28, Val Loss: 97.79149
Epoch 29, Val Loss: 92.42752
Epoch 30, Val Loss: 96.20119
Epoch 31, Val Loss: 94.48727
Epoch 32, Val Loss: 88.58588
Epoch 33, Val Loss: 92.31097
Epoch 34, Val Loss: 92.28117
Epoch 35, Val Loss: 88.81462
Epoch 36, Val Loss: 92.55499
Epoch 37, Val Loss: 89.41919
Epoch 38, Val Loss: 90.02030
Epoch 39, Val Loss: 85.73816
Epoch 40, Val Loss: 91.93011
Epoch 41, Val Loss: 93.01813
Epoch 42, Val Loss: 100.19144
Epoch 43, Val Loss: 87.38602
Epoch 44, Val Loss: 89.78686
Epoch 45, Val Loss: 86.89626
Epoch 46, Val Loss: 91.73949
Epoch 47, Val Loss: 90.04975
Epoch 48, Val Loss: 87.17240
Epoch 49, Val Loss: 88.37724
Epoch 50, Val Loss: 90.98518
Epoch 51, Val Loss: 92.47531
Epoch 52, Val Loss: 88.68225
Epoch 53, Val Loss: 97.35809
Epoch 54, Val Loss: 84.85065
Epoch 55, Val Loss: 84.74241
Epoch 56, Val Loss: 91.23425
Epoch 57, Val Loss: 86.33901
Epoch 58, Val Loss: 88.22901
Epoch 59, Val Loss: 90.65093
Epoch 60, Val Loss: 88.24184
Epoch 61, Val Loss: 84.60742
Epoch 62, Val Loss: 87.11414
Epoch 63, Val Loss: 89.59679
Epoch 64, Val Loss: 81.48725
Epoch 65, Val Loss: 93.02205
Epoch 66, Val Loss: 86.62372
Epoch 67, Val Loss: 87.72512
Epoch 68, Val Loss: 79.48945
Epoch 69, Val Loss: 79.66974
Epoch 70, Val Loss: 85.82304
Epoch 71, Val Loss: 108.36075
Epoch 72, Val Loss: 90.72313
Epoch 73, Val Loss: 83.66887
Epoch 74, Val Loss: 87.13501
Epoch 75, Val Loss: 96.02791
Epoch 76, Val Loss: 89.33063
Epoch 77, Val Loss: 84.65576
Epoch 78, Val Loss: 80.13771
Epoch 79, Val Loss: 85.59397
Epoch 80, Val Loss: 84.11162
Epoch 81, Val Loss: 91.55479
Epoch 82, Val Loss: 80.90866
Epoch 83, Val Loss: 79.79174
Epoch 84, Val Loss: 82.04444
Epoch 85, Val Loss: 78.92381
Epoch 86, Val Loss: 82.24651
Epoch 87, Val Loss: 79.53755
Epoch 88, Val Loss: 75.60953
Epoch 89, Val Loss: 77.97270
Epoch 90, Val Loss: 80.61904
Epoch 91, Val Loss: 78.10884
Epoch 92, Val Loss: 79.38606
Epoch 93, Val Loss: 84.81967
Epoch 94, Val Loss: 99.04672
Epoch 95, Val Loss: 80.23099
Epoch 96, Val Loss: 76.43802
Epoch 97, Val Loss: 79.22672
Epoch 98, Val Loss: 81.85126
Epoch 99, Val Loss: 78.82967
DID NOT SAVE RESULTS
{'MSE - mean': 85.15823024323264, 'MSE - std': 7.3340880183671695, 'R2 - mean': 0.4707207925562476, 'R2 - std': 0.02487881888629429} 
 

Results After CV: {'MSE - mean': 85.15823024323264, 'MSE - std': 7.3340880183671695, 'R2 - mean': 0.4707207925562476, 'R2 - std': 0.02487881888629429}
Train time: 303.30395767880253
Inference time: 0.18811900159926154
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 51 finished with value: 85.15823024323264 and parameters: {'p_m': 0.10371512175335566, 'alpha': 8.664134807032571, 'K': 2, 'beta': 5.923392788095624}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1379.95435
Epoch 1, Val Loss: 354.98428
Epoch 2, Val Loss: 185.94131
Epoch 3, Val Loss: 161.59000
Epoch 4, Val Loss: 154.46486
Epoch 5, Val Loss: 144.06865
Epoch 6, Val Loss: 129.08167
Epoch 7, Val Loss: 122.74211
Epoch 8, Val Loss: 119.58701
Epoch 9, Val Loss: 124.65025
Epoch 10, Val Loss: 117.69563
Epoch 11, Val Loss: 104.80457
Epoch 12, Val Loss: 116.11629
Epoch 13, Val Loss: 104.30660
Epoch 14, Val Loss: 99.38050
Epoch 15, Val Loss: 107.78149
Epoch 16, Val Loss: 111.47552
Epoch 17, Val Loss: 129.73677
Epoch 18, Val Loss: 108.36546
Epoch 19, Val Loss: 104.71487
Epoch 20, Val Loss: 103.56294
Epoch 21, Val Loss: 114.99313
Epoch 22, Val Loss: 117.56082
Epoch 23, Val Loss: 97.97266
Epoch 24, Val Loss: 107.21346
Epoch 25, Val Loss: 97.60667
Epoch 26, Val Loss: 95.04462
Epoch 27, Val Loss: 109.62698
Epoch 28, Val Loss: 104.74921
Epoch 29, Val Loss: 93.37021
Epoch 30, Val Loss: 110.63342
Epoch 31, Val Loss: 98.05443
Epoch 32, Val Loss: 99.16934
Epoch 33, Val Loss: 99.20979
Epoch 34, Val Loss: 97.74667
Epoch 35, Val Loss: 94.98802
Epoch 36, Val Loss: 93.64461
Epoch 37, Val Loss: 104.28293
Epoch 38, Val Loss: 97.25140
Epoch 39, Val Loss: 90.46689
Epoch 40, Val Loss: 100.30462
Epoch 41, Val Loss: 89.72243
Epoch 42, Val Loss: 115.07933
Epoch 43, Val Loss: 93.01950
Epoch 44, Val Loss: 89.65108
Epoch 45, Val Loss: 94.93916
Epoch 46, Val Loss: 90.52423
Epoch 47, Val Loss: 91.12682
Epoch 48, Val Loss: 90.59883
Epoch 49, Val Loss: 86.24342
Epoch 50, Val Loss: 100.52495
Epoch 51, Val Loss: 94.83624
Epoch 52, Val Loss: 97.52496
Epoch 53, Val Loss: 86.13391
Epoch 54, Val Loss: 83.89296
Epoch 55, Val Loss: 84.38200
Epoch 56, Val Loss: 85.06853
Epoch 57, Val Loss: 94.11088
Epoch 58, Val Loss: 88.03285
Epoch 59, Val Loss: 91.64858
Epoch 60, Val Loss: 88.73310
Epoch 61, Val Loss: 94.76821
Epoch 62, Val Loss: 86.01601
Epoch 63, Val Loss: 87.94719
Epoch 64, Val Loss: 90.61213
Epoch 65, Val Loss: 85.60634
Epoch 66, Val Loss: 85.22089
Epoch 67, Val Loss: 88.36974
Epoch 68, Val Loss: 84.38960
Epoch 69, Val Loss: 89.08286
Epoch 70, Val Loss: 84.15939
Epoch 71, Val Loss: 92.09882
Epoch 72, Val Loss: 84.37813
Epoch 73, Val Loss: 87.68414
Epoch 74, Val Loss: 109.09863
Epoch 75, Val Loss: 93.73366
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.46498910934353, 'MSE - std': 0.0, 'R2 - mean': 0.48448507915213157, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1234.02100
Epoch 1, Val Loss: 359.16904
Epoch 2, Val Loss: 144.68571
Epoch 3, Val Loss: 136.45044
Epoch 4, Val Loss: 123.58484
Epoch 5, Val Loss: 104.51969
Epoch 6, Val Loss: 106.46213
Epoch 7, Val Loss: 97.77414
Epoch 8, Val Loss: 96.91669
Epoch 9, Val Loss: 89.47072
Epoch 10, Val Loss: 89.65711
Epoch 11, Val Loss: 86.07407
Epoch 12, Val Loss: 88.56585
Epoch 13, Val Loss: 81.18811
Epoch 14, Val Loss: 82.36806
Epoch 15, Val Loss: 96.66189
Epoch 16, Val Loss: 90.06893
Epoch 17, Val Loss: 87.74214
Epoch 18, Val Loss: 75.23185
Epoch 19, Val Loss: 84.85754
Epoch 20, Val Loss: 82.26732
Epoch 21, Val Loss: 78.24608
Epoch 22, Val Loss: 79.11706
Epoch 23, Val Loss: 94.40240
Epoch 24, Val Loss: 75.69106
Epoch 25, Val Loss: 81.55521
Epoch 26, Val Loss: 76.09659
Epoch 27, Val Loss: 88.59245
Epoch 28, Val Loss: 86.69064
Epoch 29, Val Loss: 77.02483
Epoch 30, Val Loss: 78.15903
Epoch 31, Val Loss: 77.91066
Epoch 32, Val Loss: 75.78304
Epoch 33, Val Loss: 78.74355
Epoch 34, Val Loss: 78.79052
Epoch 35, Val Loss: 81.26914
Epoch 36, Val Loss: 82.10441
Epoch 37, Val Loss: 73.22055
Epoch 38, Val Loss: 73.26529
Epoch 39, Val Loss: 78.15006
Epoch 40, Val Loss: 72.83672
Epoch 41, Val Loss: 72.71680
Epoch 42, Val Loss: 79.59577
Epoch 43, Val Loss: 73.10457
Epoch 44, Val Loss: 75.86214
Epoch 45, Val Loss: 75.48736
Epoch 46, Val Loss: 78.15671
Epoch 47, Val Loss: 75.88982
Epoch 48, Val Loss: 85.89153
Epoch 49, Val Loss: 76.58531
Epoch 50, Val Loss: 74.46188
Epoch 51, Val Loss: 79.12601
Epoch 52, Val Loss: 79.68501
Epoch 53, Val Loss: 73.73042
Epoch 54, Val Loss: 76.83084
Epoch 55, Val Loss: 73.92596
Epoch 56, Val Loss: 82.09927
Epoch 57, Val Loss: 81.39775
Epoch 58, Val Loss: 72.87403
Epoch 59, Val Loss: 86.77548
Epoch 60, Val Loss: 86.19635
Epoch 61, Val Loss: 73.28362
Epoch 62, Val Loss: 77.44372
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.30500026293151, 'MSE - std': 3.1599888464120127, 'R2 - mean': 0.48020075080290975, 'R2 - std': 0.004284328349221822} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1510.49426
Epoch 1, Val Loss: 376.36496
Epoch 2, Val Loss: 153.64000
Epoch 3, Val Loss: 137.38016
Epoch 4, Val Loss: 129.93361
Epoch 5, Val Loss: 121.69263
Epoch 6, Val Loss: 102.19467
Epoch 7, Val Loss: 85.33694
Epoch 8, Val Loss: 102.94112
Epoch 9, Val Loss: 88.40971
Epoch 10, Val Loss: 89.13088
Epoch 11, Val Loss: 88.41911
Epoch 12, Val Loss: 75.81600
Epoch 13, Val Loss: 82.34606
Epoch 14, Val Loss: 99.04858
Epoch 15, Val Loss: 83.50928
Epoch 16, Val Loss: 81.00000
Epoch 17, Val Loss: 82.46667
Epoch 18, Val Loss: 78.70906
Epoch 19, Val Loss: 85.19023
Epoch 20, Val Loss: 83.97847
Epoch 21, Val Loss: 86.45803
Epoch 22, Val Loss: 76.56944
Epoch 23, Val Loss: 79.38747
Epoch 24, Val Loss: 91.95628
Epoch 25, Val Loss: 80.61658
Epoch 26, Val Loss: 89.41470
Epoch 27, Val Loss: 71.47906
Epoch 28, Val Loss: 77.22571
Epoch 29, Val Loss: 76.36995
Epoch 30, Val Loss: 75.31434
Epoch 31, Val Loss: 79.63744
Epoch 32, Val Loss: 91.55315
Epoch 33, Val Loss: 71.98159
Epoch 34, Val Loss: 78.76591
Epoch 35, Val Loss: 75.29397
Epoch 36, Val Loss: 89.03630
Epoch 37, Val Loss: 77.69531
Epoch 38, Val Loss: 74.24461
Epoch 39, Val Loss: 73.76787
Epoch 40, Val Loss: 70.33636
Epoch 41, Val Loss: 77.71239
Epoch 42, Val Loss: 74.15309
Epoch 43, Val Loss: 85.08602
Epoch 44, Val Loss: 73.84482
Epoch 45, Val Loss: 72.61986
Epoch 46, Val Loss: 72.47636
Epoch 47, Val Loss: 72.88625
Epoch 48, Val Loss: 81.43036
Epoch 49, Val Loss: 72.98201
Epoch 50, Val Loss: 71.18631
Epoch 51, Val Loss: 69.88023
Epoch 52, Val Loss: 72.40135
Epoch 53, Val Loss: 75.35558
Epoch 54, Val Loss: 83.95141
Epoch 55, Val Loss: 76.10573
Epoch 56, Val Loss: 77.24980
Epoch 57, Val Loss: 68.20038
Epoch 58, Val Loss: 71.28964
Epoch 59, Val Loss: 76.06576
Epoch 60, Val Loss: 73.04492
Epoch 61, Val Loss: 70.92651
Epoch 62, Val Loss: 73.47040
Epoch 63, Val Loss: 71.17761
Epoch 64, Val Loss: 72.79945
Epoch 65, Val Loss: 74.65054
Epoch 66, Val Loss: 73.29337
Epoch 67, Val Loss: 77.18263
Epoch 68, Val Loss: 69.89550
Epoch 69, Val Loss: 74.09248
Epoch 70, Val Loss: 74.72070
Epoch 71, Val Loss: 69.19499
Epoch 72, Val Loss: 84.94533
Epoch 73, Val Loss: 71.13843
Epoch 74, Val Loss: 73.72704
Epoch 75, Val Loss: 71.78069
Epoch 76, Val Loss: 76.66979
Epoch 77, Val Loss: 75.66139
Epoch 78, Val Loss: 86.56787
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.02377037109223, 'MSE - std': 7.901885725184796, 'R2 - mean': 0.49784794346820255, 'R2 - std': 0.025200868983718688} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 487.84711
Epoch 1, Val Loss: 358.35522
Epoch 2, Val Loss: 171.15633
Epoch 3, Val Loss: 137.94081
Epoch 4, Val Loss: 121.98973
Epoch 5, Val Loss: 113.75616
Epoch 6, Val Loss: 115.46101
Epoch 7, Val Loss: 109.88055
Epoch 8, Val Loss: 108.59689
Epoch 9, Val Loss: 101.31855
Epoch 10, Val Loss: 102.22644
Epoch 11, Val Loss: 101.30618
Epoch 12, Val Loss: 96.58339
Epoch 13, Val Loss: 92.58781
Epoch 14, Val Loss: 99.36027
Epoch 15, Val Loss: 99.78178
Epoch 16, Val Loss: 91.88577
Epoch 17, Val Loss: 96.94038
Epoch 18, Val Loss: 96.68369
Epoch 19, Val Loss: 98.26968
Epoch 20, Val Loss: 92.38079
Epoch 21, Val Loss: 103.11583
Epoch 22, Val Loss: 89.65102
Epoch 23, Val Loss: 87.49868
Epoch 24, Val Loss: 100.87095
Epoch 25, Val Loss: 85.19252
Epoch 26, Val Loss: 90.25097
Epoch 27, Val Loss: 90.68061
Epoch 28, Val Loss: 89.67797
Epoch 29, Val Loss: 90.25775
Epoch 30, Val Loss: 87.53964
Epoch 31, Val Loss: 93.49428
Epoch 32, Val Loss: 94.46693
Epoch 33, Val Loss: 89.57895
Epoch 34, Val Loss: 88.76089
Epoch 35, Val Loss: 84.18979
Epoch 36, Val Loss: 87.72926
Epoch 37, Val Loss: 90.32140
Epoch 38, Val Loss: 90.14819
Epoch 39, Val Loss: 93.01882
Epoch 40, Val Loss: 87.30824
Epoch 41, Val Loss: 84.91679
Epoch 42, Val Loss: 86.59863
Epoch 43, Val Loss: 85.79185
Epoch 44, Val Loss: 86.92181
Epoch 45, Val Loss: 86.71926
Epoch 46, Val Loss: 88.55916
Epoch 47, Val Loss: 86.06145
Epoch 48, Val Loss: 81.51713
Epoch 49, Val Loss: 83.48090
Epoch 50, Val Loss: 99.61137
Epoch 51, Val Loss: 90.08898
Epoch 52, Val Loss: 85.43622
Epoch 53, Val Loss: 82.47697
Epoch 54, Val Loss: 83.92935
Epoch 55, Val Loss: 89.32876
Epoch 56, Val Loss: 82.16052
Epoch 57, Val Loss: 84.72882
Epoch 58, Val Loss: 83.24059
Epoch 59, Val Loss: 82.78419
Epoch 60, Val Loss: 84.15993
Epoch 61, Val Loss: 92.04078
Epoch 62, Val Loss: 84.59781
Epoch 63, Val Loss: 97.03008
Epoch 64, Val Loss: 83.36829
Epoch 65, Val Loss: 82.36592
Epoch 66, Val Loss: 79.95383
Epoch 67, Val Loss: 86.14537
Epoch 68, Val Loss: 87.06149
Epoch 69, Val Loss: 89.86823
Epoch 70, Val Loss: 80.96091
Epoch 71, Val Loss: 86.53141
Epoch 72, Val Loss: 78.30093
Epoch 73, Val Loss: 81.60696
Epoch 74, Val Loss: 82.68527
Epoch 75, Val Loss: 81.38008
Epoch 76, Val Loss: 87.72952
Epoch 77, Val Loss: 82.32672
Epoch 78, Val Loss: 79.20914
Epoch 79, Val Loss: 84.71210
Epoch 80, Val Loss: 82.63480
Epoch 81, Val Loss: 91.98815
Epoch 82, Val Loss: 106.32602
Epoch 83, Val Loss: 95.76024
Epoch 84, Val Loss: 82.65300
Epoch 85, Val Loss: 79.56895
Epoch 86, Val Loss: 82.22099
Epoch 87, Val Loss: 85.46075
Epoch 88, Val Loss: 86.57629
Epoch 89, Val Loss: 84.36304
Epoch 90, Val Loss: 79.90717
Epoch 91, Val Loss: 83.34185
Epoch 92, Val Loss: 79.00352
Epoch 93, Val Loss: 84.12562
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.5101445930498, 'MSE - std': 8.085543817533528, 'R2 - mean': 0.48859653559790306, 'R2 - std': 0.027075422266307016} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 729.12646
Epoch 1, Val Loss: 351.58777
Epoch 2, Val Loss: 149.27394
Epoch 3, Val Loss: 136.00085
Epoch 4, Val Loss: 130.28896
Epoch 5, Val Loss: 129.43724
Epoch 6, Val Loss: 114.98547
Epoch 7, Val Loss: 112.46039
Epoch 8, Val Loss: 105.43441
Epoch 9, Val Loss: 107.98289
Epoch 10, Val Loss: 120.65183
Epoch 11, Val Loss: 115.08869
Epoch 12, Val Loss: 104.91727
Epoch 13, Val Loss: 106.76846
Epoch 14, Val Loss: 99.74916
Epoch 15, Val Loss: 113.00136
Epoch 16, Val Loss: 99.28423
Epoch 17, Val Loss: 104.71481
Epoch 18, Val Loss: 97.04137
Epoch 19, Val Loss: 103.00040
Epoch 20, Val Loss: 119.23184
Epoch 21, Val Loss: 99.60963
Epoch 22, Val Loss: 94.22234
Epoch 23, Val Loss: 104.98117
Epoch 24, Val Loss: 108.26645
Epoch 25, Val Loss: 95.56783
Epoch 26, Val Loss: 98.04816
Epoch 27, Val Loss: 98.48494
Epoch 28, Val Loss: 107.46471
Epoch 29, Val Loss: 98.62773
Epoch 30, Val Loss: 102.19448
Epoch 31, Val Loss: 99.10607
Epoch 32, Val Loss: 86.39218
Epoch 33, Val Loss: 87.43293
Epoch 34, Val Loss: 88.16069
Epoch 35, Val Loss: 89.35305
Epoch 36, Val Loss: 86.16825
Epoch 37, Val Loss: 92.39185
Epoch 38, Val Loss: 98.67405
Epoch 39, Val Loss: 78.98748
Epoch 40, Val Loss: 100.84773
Epoch 41, Val Loss: 93.43920
Epoch 42, Val Loss: 80.87434
Epoch 43, Val Loss: 84.81944
Epoch 44, Val Loss: 82.41928
Epoch 45, Val Loss: 80.39956
Epoch 46, Val Loss: 88.13156
Epoch 47, Val Loss: 84.22133
Epoch 48, Val Loss: 87.68866
Epoch 49, Val Loss: 79.43338
Epoch 50, Val Loss: 91.20386
Epoch 51, Val Loss: 83.36928
Epoch 52, Val Loss: 82.99490
Epoch 53, Val Loss: 97.80836
Epoch 54, Val Loss: 85.38960
Epoch 55, Val Loss: 87.60679
Epoch 56, Val Loss: 81.63455
Epoch 57, Val Loss: 80.61636
Epoch 58, Val Loss: 82.87656
Epoch 59, Val Loss: 78.64630
Epoch 60, Val Loss: 82.81354
Epoch 61, Val Loss: 91.02449
Epoch 62, Val Loss: 82.00519
Epoch 63, Val Loss: 79.50085
Epoch 64, Val Loss: 81.75309
Epoch 65, Val Loss: 98.07941
Epoch 66, Val Loss: 77.76077
Epoch 67, Val Loss: 80.15384
Epoch 68, Val Loss: 87.14438
Epoch 69, Val Loss: 78.78487
Epoch 70, Val Loss: 77.04285
Epoch 71, Val Loss: 81.63062
Epoch 72, Val Loss: 77.97469
Epoch 73, Val Loss: 93.61729
Epoch 74, Val Loss: 78.75754
Epoch 75, Val Loss: 79.64120
Epoch 76, Val Loss: 83.79982
Epoch 77, Val Loss: 87.48418
Epoch 78, Val Loss: 88.58773
Epoch 79, Val Loss: 78.86211
Epoch 80, Val Loss: 82.88486
Epoch 81, Val Loss: 80.88389
Epoch 82, Val Loss: 76.32864
Epoch 83, Val Loss: 78.66890
Epoch 84, Val Loss: 82.09974
Epoch 85, Val Loss: 83.08908
Epoch 86, Val Loss: 80.05975
Epoch 87, Val Loss: 79.73595
Epoch 88, Val Loss: 80.49176
Epoch 89, Val Loss: 80.94939
Epoch 90, Val Loss: 82.90891
Epoch 91, Val Loss: 83.26302
Epoch 92, Val Loss: 83.90884
Epoch 93, Val Loss: 78.02252
Epoch 94, Val Loss: 84.68195
Epoch 95, Val Loss: 91.66726
Epoch 96, Val Loss: 81.69101
Epoch 97, Val Loss: 79.64404
Epoch 98, Val Loss: 75.29567
Epoch 99, Val Loss: 77.29333
DID NOT SAVE RESULTS
{'MSE - mean': 81.37174391774354, 'MSE - std': 7.581862531750013, 'R2 - mean': 0.49452392282832325, 'R2 - std': 0.026962909157515993} 
 

Results After CV: {'MSE - mean': 81.37174391774354, 'MSE - std': 7.581862531750013, 'R2 - mean': 0.49452392282832325, 'R2 - std': 0.026962909157515993}
Train time: 3464.981184975791
Inference time: 0.17953554859268478
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 52 finished with value: 81.37174391774354 and parameters: {'p_m': 0.31722012172112735, 'alpha': 9.030706121222147, 'K': 20, 'beta': 4.682441921139377}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 532.40576
Epoch 1, Val Loss: 423.88208
Epoch 2, Val Loss: 188.58485
Epoch 3, Val Loss: 160.45322
Epoch 4, Val Loss: 137.25829
Epoch 5, Val Loss: 127.69181
Epoch 6, Val Loss: 124.57295
Epoch 7, Val Loss: 121.65596
Epoch 8, Val Loss: 118.37462
Epoch 9, Val Loss: 109.27287
Epoch 10, Val Loss: 103.65828
Epoch 11, Val Loss: 104.77831
Epoch 12, Val Loss: 112.69944
Epoch 13, Val Loss: 121.07605
Epoch 14, Val Loss: 109.08442
Epoch 15, Val Loss: 105.03535
Epoch 16, Val Loss: 109.42708
Epoch 17, Val Loss: 111.02539
Epoch 18, Val Loss: 100.03522
Epoch 19, Val Loss: 107.29472
Epoch 20, Val Loss: 104.43709
Epoch 21, Val Loss: 101.00955
Epoch 22, Val Loss: 101.29296
Epoch 23, Val Loss: 118.48192
Epoch 24, Val Loss: 107.20981
Epoch 25, Val Loss: 102.52204
Epoch 26, Val Loss: 104.54102
Epoch 27, Val Loss: 99.54910
Epoch 28, Val Loss: 105.07661
Epoch 29, Val Loss: 119.59078
Epoch 30, Val Loss: 112.14436
Epoch 31, Val Loss: 110.45704
Epoch 32, Val Loss: 97.62529
Epoch 33, Val Loss: 98.82327
Epoch 34, Val Loss: 104.80298
Epoch 35, Val Loss: 97.24257
Epoch 36, Val Loss: 99.06907
Epoch 37, Val Loss: 97.25362
Epoch 38, Val Loss: 104.89912
Epoch 39, Val Loss: 97.20029
Epoch 40, Val Loss: 97.45202
Epoch 41, Val Loss: 100.02479
Epoch 42, Val Loss: 107.28886
Epoch 43, Val Loss: 98.37746
Epoch 44, Val Loss: 103.74136
Epoch 45, Val Loss: 93.32333
Epoch 46, Val Loss: 94.75809
Epoch 47, Val Loss: 119.52643
Epoch 48, Val Loss: 89.53818
Epoch 49, Val Loss: 108.02911
Epoch 50, Val Loss: 89.62490
Epoch 51, Val Loss: 92.96522
Epoch 52, Val Loss: 90.80801
Epoch 53, Val Loss: 88.19954
Epoch 54, Val Loss: 93.71153
Epoch 55, Val Loss: 89.53442
Epoch 56, Val Loss: 89.26832
Epoch 57, Val Loss: 91.27054
Epoch 58, Val Loss: 90.22049
Epoch 59, Val Loss: 86.98351
Epoch 60, Val Loss: 96.57428
Epoch 61, Val Loss: 90.83994
Epoch 62, Val Loss: 99.67199
Epoch 63, Val Loss: 92.49512
Epoch 64, Val Loss: 86.75827
Epoch 65, Val Loss: 86.37289
Epoch 66, Val Loss: 91.88707
Epoch 67, Val Loss: 95.71098
Epoch 68, Val Loss: 90.27860
Epoch 69, Val Loss: 86.56987
Epoch 70, Val Loss: 89.91267
Epoch 71, Val Loss: 85.72786
Epoch 72, Val Loss: 87.99520
Epoch 73, Val Loss: 89.78995
Epoch 74, Val Loss: 91.75130
Epoch 75, Val Loss: 96.80984
Epoch 76, Val Loss: 93.19591
Epoch 77, Val Loss: 87.01320
Epoch 78, Val Loss: 86.01738
Epoch 79, Val Loss: 85.34740
Epoch 80, Val Loss: 86.28784
Epoch 81, Val Loss: 85.88188
Epoch 82, Val Loss: 87.97192
Epoch 83, Val Loss: 94.93186
Epoch 84, Val Loss: 86.15070
Epoch 85, Val Loss: 84.96796
Epoch 86, Val Loss: 89.97016
Epoch 87, Val Loss: 94.71858
Epoch 88, Val Loss: 87.75996
Epoch 89, Val Loss: 86.81658
Epoch 90, Val Loss: 81.08264
Epoch 91, Val Loss: 85.97502
Epoch 92, Val Loss: 83.93069
Epoch 93, Val Loss: 101.13482
Epoch 94, Val Loss: 87.08729
Epoch 95, Val Loss: 86.85524
Epoch 96, Val Loss: 84.73074
Epoch 97, Val Loss: 92.68710
Epoch 98, Val Loss: 88.80553
Epoch 99, Val Loss: 90.10431
DID NOT SAVE RESULTS
{'MSE - mean': 85.55853720654706, 'MSE - std': 0.0, 'R2 - mean': 0.501421941267904, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 492.30182
Epoch 1, Val Loss: 422.50580
Epoch 2, Val Loss: 164.31503
Epoch 3, Val Loss: 136.07213
Epoch 4, Val Loss: 116.15715
Epoch 5, Val Loss: 112.84695
Epoch 6, Val Loss: 110.42646
Epoch 7, Val Loss: 103.89409
Epoch 8, Val Loss: 102.44206
Epoch 9, Val Loss: 94.54143
Epoch 10, Val Loss: 101.64262
Epoch 11, Val Loss: 93.69939
Epoch 12, Val Loss: 83.94728
Epoch 13, Val Loss: 87.65009
Epoch 14, Val Loss: 84.42554
Epoch 15, Val Loss: 85.31201
Epoch 16, Val Loss: 97.59389
Epoch 17, Val Loss: 108.24371
Epoch 18, Val Loss: 91.74041
Epoch 19, Val Loss: 91.25393
Epoch 20, Val Loss: 89.58461
Epoch 21, Val Loss: 84.47531
Epoch 22, Val Loss: 100.81686
Epoch 23, Val Loss: 120.51418
Epoch 24, Val Loss: 90.17848
Epoch 25, Val Loss: 83.39892
Epoch 26, Val Loss: 85.78455
Epoch 27, Val Loss: 84.77357
Epoch 28, Val Loss: 81.96243
Epoch 29, Val Loss: 84.64589
Epoch 30, Val Loss: 95.30229
Epoch 31, Val Loss: 78.99828
Epoch 32, Val Loss: 86.52804
Epoch 33, Val Loss: 87.21261
Epoch 34, Val Loss: 76.36301
Epoch 35, Val Loss: 86.29127
Epoch 36, Val Loss: 80.81225
Epoch 37, Val Loss: 81.54453
Epoch 38, Val Loss: 76.90952
Epoch 39, Val Loss: 87.81276
Epoch 40, Val Loss: 81.20043
Epoch 41, Val Loss: 90.24036
Epoch 42, Val Loss: 79.64651
Epoch 43, Val Loss: 100.73244
Epoch 44, Val Loss: 78.15804
Epoch 45, Val Loss: 79.12068
Epoch 46, Val Loss: 82.84695
Epoch 47, Val Loss: 75.45299
Epoch 48, Val Loss: 86.10643
Epoch 49, Val Loss: 88.45746
Epoch 50, Val Loss: 82.59470
Epoch 51, Val Loss: 79.25038
Epoch 52, Val Loss: 75.73889
Epoch 53, Val Loss: 73.61446
Epoch 54, Val Loss: 77.67955
Epoch 55, Val Loss: 78.55672
Epoch 56, Val Loss: 72.85178
Epoch 57, Val Loss: 74.62321
Epoch 58, Val Loss: 75.58466
Epoch 59, Val Loss: 109.91534
Epoch 60, Val Loss: 76.40881
Epoch 61, Val Loss: 72.46048
Epoch 62, Val Loss: 84.92400
Epoch 63, Val Loss: 72.29973
Epoch 64, Val Loss: 73.38752
Epoch 65, Val Loss: 69.99244
Epoch 66, Val Loss: 81.18840
Epoch 67, Val Loss: 76.06506
Epoch 68, Val Loss: 73.94968
Epoch 69, Val Loss: 72.40468
Epoch 70, Val Loss: 72.90942
Epoch 71, Val Loss: 79.21053
Epoch 72, Val Loss: 73.89334
Epoch 73, Val Loss: 79.53255
Epoch 74, Val Loss: 103.91674
Epoch 75, Val Loss: 70.30032
Epoch 76, Val Loss: 73.22862
Epoch 77, Val Loss: 74.77985
Epoch 78, Val Loss: 70.94589
Epoch 79, Val Loss: 72.43473
Epoch 80, Val Loss: 90.28814
Epoch 81, Val Loss: 72.33889
Epoch 82, Val Loss: 71.91370
Epoch 83, Val Loss: 70.84032
Epoch 84, Val Loss: 67.67487
Epoch 85, Val Loss: 73.30383
Epoch 86, Val Loss: 76.62708
Epoch 87, Val Loss: 72.82706
Epoch 88, Val Loss: 70.85826
Epoch 89, Val Loss: 75.73515
Epoch 90, Val Loss: 85.36728
Epoch 91, Val Loss: 68.35423
Epoch 92, Val Loss: 83.80756
Epoch 93, Val Loss: 82.80462
Epoch 94, Val Loss: 74.55982
Epoch 95, Val Loss: 77.90233
Epoch 96, Val Loss: 72.21056
Epoch 97, Val Loss: 70.44926
Epoch 98, Val Loss: 72.02021
Epoch 99, Val Loss: 70.30840
DID NOT SAVE RESULTS
{'MSE - mean': 79.9066796012466, 'MSE - std': 5.651857605300464, 'R2 - mean': 0.5138388094970067, 'R2 - std': 0.012416868229102707} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 879.61383
Epoch 1, Val Loss: 523.35120
Epoch 2, Val Loss: 173.60109
Epoch 3, Val Loss: 127.05165
Epoch 4, Val Loss: 129.07120
Epoch 5, Val Loss: 109.90270
Epoch 6, Val Loss: 97.04317
Epoch 7, Val Loss: 86.93209
Epoch 8, Val Loss: 93.96770
Epoch 9, Val Loss: 104.33649
Epoch 10, Val Loss: 84.05339
Epoch 11, Val Loss: 81.67496
Epoch 12, Val Loss: 86.74799
Epoch 13, Val Loss: 91.13139
Epoch 14, Val Loss: 86.84682
Epoch 15, Val Loss: 87.02700
Epoch 16, Val Loss: 87.57204
Epoch 17, Val Loss: 89.80386
Epoch 18, Val Loss: 93.02950
Epoch 19, Val Loss: 88.43208
Epoch 20, Val Loss: 82.57692
Epoch 21, Val Loss: 81.07951
Epoch 22, Val Loss: 83.44619
Epoch 23, Val Loss: 85.58917
Epoch 24, Val Loss: 75.62491
Epoch 25, Val Loss: 78.43912
Epoch 26, Val Loss: 83.29479
Epoch 27, Val Loss: 100.22662
Epoch 28, Val Loss: 82.08704
Epoch 29, Val Loss: 88.95715
Epoch 30, Val Loss: 87.98988
Epoch 31, Val Loss: 83.23331
Epoch 32, Val Loss: 76.01376
Epoch 33, Val Loss: 77.29408
Epoch 34, Val Loss: 87.69911
Epoch 35, Val Loss: 86.77582
Epoch 36, Val Loss: 76.47495
Epoch 37, Val Loss: 94.79041
Epoch 38, Val Loss: 80.19528
Epoch 39, Val Loss: 80.33340
Epoch 40, Val Loss: 74.26499
Epoch 41, Val Loss: 88.99310
Epoch 42, Val Loss: 80.17851
Epoch 43, Val Loss: 81.75201
Epoch 44, Val Loss: 93.59334
Epoch 45, Val Loss: 85.17584
Epoch 46, Val Loss: 82.75687
Epoch 47, Val Loss: 81.24323
Epoch 48, Val Loss: 73.74223
Epoch 49, Val Loss: 76.64729
Epoch 50, Val Loss: 80.88472
Epoch 51, Val Loss: 75.39101
Epoch 52, Val Loss: 71.12367
Epoch 53, Val Loss: 73.55823
Epoch 54, Val Loss: 79.15004
Epoch 55, Val Loss: 74.00807
Epoch 56, Val Loss: 80.92171
Epoch 57, Val Loss: 75.16618
Epoch 58, Val Loss: 70.30084
Epoch 59, Val Loss: 74.25851
Epoch 60, Val Loss: 78.30548
Epoch 61, Val Loss: 81.70270
Epoch 62, Val Loss: 73.44375
Epoch 63, Val Loss: 74.50285
Epoch 64, Val Loss: 72.76675
Epoch 65, Val Loss: 88.61155
Epoch 66, Val Loss: 79.43866
Epoch 67, Val Loss: 75.89261
Epoch 68, Val Loss: 72.46577
Epoch 69, Val Loss: 71.57756
Epoch 70, Val Loss: 73.01959
Epoch 71, Val Loss: 74.00983
Epoch 72, Val Loss: 71.74645
Epoch 73, Val Loss: 69.96878
Epoch 74, Val Loss: 69.27094
Epoch 75, Val Loss: 69.44831
Epoch 76, Val Loss: 68.73737
Epoch 77, Val Loss: 71.00951
Epoch 78, Val Loss: 75.68339
Epoch 79, Val Loss: 72.05468
Epoch 80, Val Loss: 74.19802
Epoch 81, Val Loss: 79.39919
Epoch 82, Val Loss: 71.07763
Epoch 83, Val Loss: 69.74272
Epoch 84, Val Loss: 72.16443
Epoch 85, Val Loss: 74.20285
Epoch 86, Val Loss: 85.52982
Epoch 87, Val Loss: 71.26710
Epoch 88, Val Loss: 69.40250
Epoch 89, Val Loss: 69.23700
Epoch 90, Val Loss: 80.37317
Epoch 91, Val Loss: 72.82088
Epoch 92, Val Loss: 76.46328
Epoch 93, Val Loss: 70.47020
Epoch 94, Val Loss: 75.50439
Epoch 95, Val Loss: 72.56935
Epoch 96, Val Loss: 70.97537
Epoch 97, Val Loss: 68.97388
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.41960573812042, 'MSE - std': 6.753890077640965, 'R2 - mean': 0.5203088316083623, 'R2 - std': 0.013656797452384663} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 745.92688
Epoch 1, Val Loss: 564.70807
Epoch 2, Val Loss: 185.23633
Epoch 3, Val Loss: 175.99020
Epoch 4, Val Loss: 154.71124
Epoch 5, Val Loss: 135.86618
Epoch 6, Val Loss: 138.07799
Epoch 7, Val Loss: 129.41362
Epoch 8, Val Loss: 115.27061
Epoch 9, Val Loss: 113.42867
Epoch 10, Val Loss: 133.34634
Epoch 11, Val Loss: 107.63450
Epoch 12, Val Loss: 96.26334
Epoch 13, Val Loss: 100.43687
Epoch 14, Val Loss: 103.82474
Epoch 15, Val Loss: 100.47494
Epoch 16, Val Loss: 104.40019
Epoch 17, Val Loss: 96.98769
Epoch 18, Val Loss: 102.20422
Epoch 19, Val Loss: 93.95848
Epoch 20, Val Loss: 96.66286
Epoch 21, Val Loss: 108.68909
Epoch 22, Val Loss: 112.79173
Epoch 23, Val Loss: 93.78091
Epoch 24, Val Loss: 92.20433
Epoch 25, Val Loss: 99.11627
Epoch 26, Val Loss: 95.65050
Epoch 27, Val Loss: 98.02643
Epoch 28, Val Loss: 93.84930
Epoch 29, Val Loss: 91.64531
Epoch 30, Val Loss: 94.83708
Epoch 31, Val Loss: 91.84599
Epoch 32, Val Loss: 97.03522
Epoch 33, Val Loss: 92.62469
Epoch 34, Val Loss: 95.40327
Epoch 35, Val Loss: 89.97224
Epoch 36, Val Loss: 89.70063
Epoch 37, Val Loss: 98.99883
Epoch 38, Val Loss: 88.13599
Epoch 39, Val Loss: 86.34187
Epoch 40, Val Loss: 86.32685
Epoch 41, Val Loss: 92.68924
Epoch 42, Val Loss: 92.62162
Epoch 43, Val Loss: 93.28989
Epoch 44, Val Loss: 93.08668
Epoch 45, Val Loss: 92.11464
Epoch 46, Val Loss: 92.37191
Epoch 47, Val Loss: 97.35133
Epoch 48, Val Loss: 94.01434
Epoch 49, Val Loss: 87.15313
Epoch 50, Val Loss: 87.36547
Epoch 51, Val Loss: 84.78603
Epoch 52, Val Loss: 92.52840
Epoch 53, Val Loss: 91.84103
Epoch 54, Val Loss: 97.07955
Epoch 55, Val Loss: 88.80464
Epoch 56, Val Loss: 87.81038
Epoch 57, Val Loss: 89.32427
Epoch 58, Val Loss: 89.44297
Epoch 59, Val Loss: 83.44744
Epoch 60, Val Loss: 105.68208
Epoch 61, Val Loss: 94.09261
Epoch 62, Val Loss: 83.03876
Epoch 63, Val Loss: 82.44238
Epoch 64, Val Loss: 92.29378
Epoch 65, Val Loss: 116.00622
Epoch 66, Val Loss: 84.08609
Epoch 67, Val Loss: 80.66463
Epoch 68, Val Loss: 82.67686
Epoch 69, Val Loss: 82.21273
Epoch 70, Val Loss: 83.08092
Epoch 71, Val Loss: 78.83401
Epoch 72, Val Loss: 84.60623
Epoch 73, Val Loss: 82.99095
Epoch 74, Val Loss: 82.88356
Epoch 75, Val Loss: 86.64423
Epoch 76, Val Loss: 89.18511
Epoch 77, Val Loss: 84.53206
Epoch 78, Val Loss: 93.65658
Epoch 79, Val Loss: 80.87625
Epoch 80, Val Loss: 81.56282
Epoch 81, Val Loss: 82.97536
Epoch 82, Val Loss: 81.55544
Epoch 83, Val Loss: 84.30844
Epoch 84, Val Loss: 86.00335
Epoch 85, Val Loss: 81.20911
Epoch 86, Val Loss: 78.60258
Epoch 87, Val Loss: 79.58088
Epoch 88, Val Loss: 82.70825
Epoch 89, Val Loss: 77.86201
Epoch 90, Val Loss: 86.16796
Epoch 91, Val Loss: 78.85178
Epoch 92, Val Loss: 76.78657
Epoch 93, Val Loss: 76.80883
Epoch 94, Val Loss: 79.97086
Epoch 95, Val Loss: 80.49808
Epoch 96, Val Loss: 86.56117
Epoch 97, Val Loss: 78.53671
Epoch 98, Val Loss: 79.20094
Epoch 99, Val Loss: 81.47817
DID NOT SAVE RESULTS
{'MSE - mean': 78.97484319032446, 'MSE - std': 7.334779389803162, 'R2 - mean': 0.5104291838286279, 'R2 - std': 0.020801524180848525} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 506.58484
Epoch 1, Val Loss: 326.31531
Epoch 2, Val Loss: 175.28949
Epoch 3, Val Loss: 157.79324
Epoch 4, Val Loss: 137.09412
Epoch 5, Val Loss: 117.41096
Epoch 6, Val Loss: 113.57545
Epoch 7, Val Loss: 110.56090
Epoch 8, Val Loss: 108.97424
Epoch 9, Val Loss: 104.76929
Epoch 10, Val Loss: 105.51228
Epoch 11, Val Loss: 96.71652
Epoch 12, Val Loss: 115.95912
Epoch 13, Val Loss: 101.35342
Epoch 14, Val Loss: 107.29478
Epoch 15, Val Loss: 111.06589
Epoch 16, Val Loss: 105.79380
Epoch 17, Val Loss: 95.71355
Epoch 18, Val Loss: 94.64294
Epoch 19, Val Loss: 97.09678
Epoch 20, Val Loss: 89.81388
Epoch 21, Val Loss: 93.86277
Epoch 22, Val Loss: 81.37744
Epoch 23, Val Loss: 92.00632
Epoch 24, Val Loss: 96.99837
Epoch 25, Val Loss: 94.48216
Epoch 26, Val Loss: 87.10465
Epoch 27, Val Loss: 88.88946
Epoch 28, Val Loss: 97.52994
Epoch 29, Val Loss: 88.11516
Epoch 30, Val Loss: 94.42514
Epoch 31, Val Loss: 115.19060
Epoch 32, Val Loss: 91.81367
Epoch 33, Val Loss: 83.45532
Epoch 34, Val Loss: 82.90210
Epoch 35, Val Loss: 85.15514
Epoch 36, Val Loss: 96.86738
Epoch 37, Val Loss: 87.13387
Epoch 38, Val Loss: 85.21362
Epoch 39, Val Loss: 97.36052
Epoch 40, Val Loss: 92.23474
Epoch 41, Val Loss: 88.80823
Epoch 42, Val Loss: 97.30029
Epoch 43, Val Loss: 76.87180
Epoch 44, Val Loss: 86.03493
Epoch 45, Val Loss: 83.88117
Epoch 46, Val Loss: 78.71085
Epoch 47, Val Loss: 77.29684
Epoch 48, Val Loss: 82.14896
Epoch 49, Val Loss: 84.84161
Epoch 50, Val Loss: 81.90444
Epoch 51, Val Loss: 85.61227
Epoch 52, Val Loss: 82.44438
Epoch 53, Val Loss: 79.50838
Epoch 54, Val Loss: 81.17053
Epoch 55, Val Loss: 89.10738
Epoch 56, Val Loss: 75.06589
Epoch 57, Val Loss: 82.29575
Epoch 58, Val Loss: 85.44437
Epoch 59, Val Loss: 87.70994
Epoch 60, Val Loss: 85.21960
Epoch 61, Val Loss: 82.55951
Epoch 62, Val Loss: 82.77071
Epoch 63, Val Loss: 83.40727
Epoch 64, Val Loss: 82.29430
Epoch 65, Val Loss: 99.69479
Epoch 66, Val Loss: 81.56490
Epoch 67, Val Loss: 74.82456
Epoch 68, Val Loss: 78.86418
Epoch 69, Val Loss: 77.58418
Epoch 70, Val Loss: 74.78754
Epoch 71, Val Loss: 79.73570
Epoch 72, Val Loss: 78.91838
Epoch 73, Val Loss: 77.93373
Epoch 74, Val Loss: 80.21239
Epoch 75, Val Loss: 75.12190
Epoch 76, Val Loss: 78.17439
Epoch 77, Val Loss: 84.39634
Epoch 78, Val Loss: 76.54449
Epoch 79, Val Loss: 81.95886
Epoch 80, Val Loss: 79.45519
Epoch 81, Val Loss: 78.80756
Epoch 82, Val Loss: 84.06965
Epoch 83, Val Loss: 92.42359
Epoch 84, Val Loss: 79.51534
Epoch 85, Val Loss: 76.86850
Epoch 86, Val Loss: 77.48808
Epoch 87, Val Loss: 85.67085
Epoch 88, Val Loss: 79.18759
Epoch 89, Val Loss: 78.22027
Epoch 90, Val Loss: 77.11267
Epoch 91, Val Loss: 79.64108
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.17639356270362, 'MSE - std': 6.751983278197339, 'R2 - mean': 0.514292374400951, 'R2 - std': 0.02014595969889461} 
 

Results After CV: {'MSE - mean': 78.17639356270362, 'MSE - std': 6.751983278197339, 'R2 - mean': 0.514292374400951, 'R2 - std': 0.02014595969889461}
Train time: 471.3342432171921
Inference time: 0.19090697220526637
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 53 finished with value: 78.17639356270362 and parameters: {'p_m': 0.14952251499443728, 'alpha': 9.598849634858004, 'K': 2, 'beta': 7.323809956501625}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 822.73071
Epoch 1, Val Loss: 466.60385
Epoch 2, Val Loss: 186.53625
Epoch 3, Val Loss: 169.08476
Epoch 4, Val Loss: 159.97418
Epoch 5, Val Loss: 134.48207
Epoch 6, Val Loss: 124.28193
Epoch 7, Val Loss: 126.85810
Epoch 8, Val Loss: 109.38545
Epoch 9, Val Loss: 107.08138
Epoch 10, Val Loss: 127.97985
Epoch 11, Val Loss: 147.39250
Epoch 12, Val Loss: 103.04135
Epoch 13, Val Loss: 96.46237
Epoch 14, Val Loss: 107.29309
Epoch 15, Val Loss: 98.18257
Epoch 16, Val Loss: 105.41571
Epoch 17, Val Loss: 97.91609
Epoch 18, Val Loss: 106.09499
Epoch 19, Val Loss: 99.71954
Epoch 20, Val Loss: 99.71958
Epoch 21, Val Loss: 100.42880
Epoch 22, Val Loss: 107.65195
Epoch 23, Val Loss: 107.37790
Epoch 24, Val Loss: 110.63792
Epoch 25, Val Loss: 98.56686
Epoch 26, Val Loss: 97.71630
Epoch 27, Val Loss: 98.20687
Epoch 28, Val Loss: 98.00063
Epoch 29, Val Loss: 101.32772
Epoch 30, Val Loss: 90.14969
Epoch 31, Val Loss: 98.37062
Epoch 32, Val Loss: 100.18358
Epoch 33, Val Loss: 104.20627
Epoch 34, Val Loss: 98.72062
Epoch 35, Val Loss: 102.73357
Epoch 36, Val Loss: 101.91650
Epoch 37, Val Loss: 98.86020
Epoch 38, Val Loss: 97.32910
Epoch 39, Val Loss: 91.87672
Epoch 40, Val Loss: 99.16042
Epoch 41, Val Loss: 93.64237
Epoch 42, Val Loss: 90.39458
Epoch 43, Val Loss: 106.83870
Epoch 44, Val Loss: 94.54179
Epoch 45, Val Loss: 91.82197
Epoch 46, Val Loss: 106.08325
Epoch 47, Val Loss: 87.26906
Epoch 48, Val Loss: 87.08825
Epoch 49, Val Loss: 100.44057
Epoch 50, Val Loss: 89.80783
Epoch 51, Val Loss: 90.08183
Epoch 52, Val Loss: 85.51384
Epoch 53, Val Loss: 85.22626
Epoch 54, Val Loss: 83.48607
Epoch 55, Val Loss: 88.08182
Epoch 56, Val Loss: 84.15254
Epoch 57, Val Loss: 88.27818
Epoch 58, Val Loss: 90.35886
Epoch 59, Val Loss: 89.44436
Epoch 60, Val Loss: 87.37866
Epoch 61, Val Loss: 85.60724
Epoch 62, Val Loss: 83.93708
Epoch 63, Val Loss: 95.55566
Epoch 64, Val Loss: 84.98807
Epoch 65, Val Loss: 98.50285
Epoch 66, Val Loss: 87.84174
Epoch 67, Val Loss: 86.94279
Epoch 68, Val Loss: 92.56020
Epoch 69, Val Loss: 94.02245
Epoch 70, Val Loss: 91.60037
Epoch 71, Val Loss: 83.95670
Epoch 72, Val Loss: 84.54626
Epoch 73, Val Loss: 86.37210
Epoch 74, Val Loss: 85.38798
Epoch 75, Val Loss: 87.48411
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.69278783630405, 'MSE - std': 0.0, 'R2 - mean': 0.4889849528553605, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 927.27356
Epoch 1, Val Loss: 522.50708
Epoch 2, Val Loss: 198.81474
Epoch 3, Val Loss: 153.65396
Epoch 4, Val Loss: 126.43489
Epoch 5, Val Loss: 118.40717
Epoch 6, Val Loss: 113.34972
Epoch 7, Val Loss: 125.70947
Epoch 8, Val Loss: 109.39372
Epoch 9, Val Loss: 100.95761
Epoch 10, Val Loss: 109.98334
Epoch 11, Val Loss: 91.77555
Epoch 12, Val Loss: 90.93778
Epoch 13, Val Loss: 92.71507
Epoch 14, Val Loss: 94.96983
Epoch 15, Val Loss: 93.98765
Epoch 16, Val Loss: 91.64497
Epoch 17, Val Loss: 92.31682
Epoch 18, Val Loss: 115.07163
Epoch 19, Val Loss: 91.09512
Epoch 20, Val Loss: 88.26942
Epoch 21, Val Loss: 90.88232
Epoch 22, Val Loss: 88.03937
Epoch 23, Val Loss: 91.50533
Epoch 24, Val Loss: 89.25407
Epoch 25, Val Loss: 86.93130
Epoch 26, Val Loss: 106.96307
Epoch 27, Val Loss: 90.79942
Epoch 28, Val Loss: 90.11523
Epoch 29, Val Loss: 79.43946
Epoch 30, Val Loss: 85.29141
Epoch 31, Val Loss: 83.44361
Epoch 32, Val Loss: 86.66661
Epoch 33, Val Loss: 81.07803
Epoch 34, Val Loss: 91.55849
Epoch 35, Val Loss: 82.94868
Epoch 36, Val Loss: 96.67570
Epoch 37, Val Loss: 99.23019
Epoch 38, Val Loss: 82.88905
Epoch 39, Val Loss: 86.07264
Epoch 40, Val Loss: 81.58514
Epoch 41, Val Loss: 82.14922
Epoch 42, Val Loss: 79.94234
Epoch 43, Val Loss: 73.06764
Epoch 44, Val Loss: 76.85043
Epoch 45, Val Loss: 82.90328
Epoch 46, Val Loss: 83.33015
Epoch 47, Val Loss: 80.99024
Epoch 48, Val Loss: 74.94714
Epoch 49, Val Loss: 72.10670
Epoch 50, Val Loss: 75.06992
Epoch 51, Val Loss: 76.34171
Epoch 52, Val Loss: 85.66174
Epoch 53, Val Loss: 69.62568
Epoch 54, Val Loss: 81.14191
Epoch 55, Val Loss: 71.75206
Epoch 56, Val Loss: 75.11360
Epoch 57, Val Loss: 72.66470
Epoch 58, Val Loss: 79.41589
Epoch 59, Val Loss: 79.34328
Epoch 60, Val Loss: 78.00022
Epoch 61, Val Loss: 69.42664
Epoch 62, Val Loss: 71.97836
Epoch 63, Val Loss: 75.93679
Epoch 64, Val Loss: 72.71267
Epoch 65, Val Loss: 74.38176
Epoch 66, Val Loss: 79.55020
Epoch 67, Val Loss: 70.51247
Epoch 68, Val Loss: 68.98705
Epoch 69, Val Loss: 72.26723
Epoch 70, Val Loss: 68.84869
Epoch 71, Val Loss: 75.11727
Epoch 72, Val Loss: 71.42558
Epoch 73, Val Loss: 91.72211
Epoch 74, Val Loss: 67.30114
Epoch 75, Val Loss: 70.03275
Epoch 76, Val Loss: 74.87735
Epoch 77, Val Loss: 78.91811
Epoch 78, Val Loss: 74.48664
Epoch 79, Val Loss: 69.93247
Epoch 80, Val Loss: 80.33960
Epoch 81, Val Loss: 70.44273
Epoch 82, Val Loss: 67.69733
Epoch 83, Val Loss: 70.49950
Epoch 84, Val Loss: 69.91303
Epoch 85, Val Loss: 71.43190
Epoch 86, Val Loss: 87.99458
Epoch 87, Val Loss: 84.25311
Epoch 88, Val Loss: 69.83125
Epoch 89, Val Loss: 68.07851
Epoch 90, Val Loss: 72.21417
Epoch 91, Val Loss: 71.99696
Epoch 92, Val Loss: 72.02083
Epoch 93, Val Loss: 70.99673
Epoch 94, Val Loss: 71.53963
Epoch 95, Val Loss: 69.94376
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.04039475966873, 'MSE - std': 6.65239307663532, 'R2 - mean': 0.5071954733821297, 'R2 - std': 0.01821052052676919} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 823.51453
Epoch 1, Val Loss: 469.06238
Epoch 2, Val Loss: 158.56563
Epoch 3, Val Loss: 125.25581
Epoch 4, Val Loss: 106.78071
Epoch 5, Val Loss: 102.07685
Epoch 6, Val Loss: 94.37120
Epoch 7, Val Loss: 100.44724
Epoch 8, Val Loss: 87.79424
Epoch 9, Val Loss: 100.60574
Epoch 10, Val Loss: 92.34197
Epoch 11, Val Loss: 95.48145
Epoch 12, Val Loss: 87.98046
Epoch 13, Val Loss: 87.80928
Epoch 14, Val Loss: 83.09793
Epoch 15, Val Loss: 83.30396
Epoch 16, Val Loss: 90.26818
Epoch 17, Val Loss: 86.59422
Epoch 18, Val Loss: 88.45919
Epoch 19, Val Loss: 83.67307
Epoch 20, Val Loss: 88.94313
Epoch 21, Val Loss: 76.52840
Epoch 22, Val Loss: 90.91628
Epoch 23, Val Loss: 77.96323
Epoch 24, Val Loss: 78.97686
Epoch 25, Val Loss: 107.45349
Epoch 26, Val Loss: 79.05902
Epoch 27, Val Loss: 85.83364
Epoch 28, Val Loss: 80.96650
Epoch 29, Val Loss: 78.26611
Epoch 30, Val Loss: 76.35943
Epoch 31, Val Loss: 78.20060
Epoch 32, Val Loss: 85.26604
Epoch 33, Val Loss: 85.81943
Epoch 34, Val Loss: 81.34019
Epoch 35, Val Loss: 83.16682
Epoch 36, Val Loss: 79.52457
Epoch 37, Val Loss: 86.64522
Epoch 38, Val Loss: 78.00067
Epoch 39, Val Loss: 85.85678
Epoch 40, Val Loss: 90.91293
Epoch 41, Val Loss: 81.69403
Epoch 42, Val Loss: 81.16868
Epoch 43, Val Loss: 99.45128
Epoch 44, Val Loss: 75.60880
Epoch 45, Val Loss: 78.24240
Epoch 46, Val Loss: 76.13428
Epoch 47, Val Loss: 76.57919
Epoch 48, Val Loss: 73.92563
Epoch 49, Val Loss: 85.16319
Epoch 50, Val Loss: 73.08588
Epoch 51, Val Loss: 77.14317
Epoch 52, Val Loss: 76.02916
Epoch 53, Val Loss: 84.63587
Epoch 54, Val Loss: 71.13811
Epoch 55, Val Loss: 71.28767
Epoch 56, Val Loss: 74.10498
Epoch 57, Val Loss: 70.87929
Epoch 58, Val Loss: 69.28638
Epoch 59, Val Loss: 91.21048
Epoch 60, Val Loss: 81.54201
Epoch 61, Val Loss: 75.44510
Epoch 62, Val Loss: 76.77979
Epoch 63, Val Loss: 76.58189
Epoch 64, Val Loss: 72.78958
Epoch 65, Val Loss: 73.44717
Epoch 66, Val Loss: 71.29125
Epoch 67, Val Loss: 80.99678
Epoch 68, Val Loss: 70.44611
Epoch 69, Val Loss: 71.47427
Epoch 70, Val Loss: 69.63136
Epoch 71, Val Loss: 87.95767
Epoch 72, Val Loss: 70.10078
Epoch 73, Val Loss: 70.54736
Epoch 74, Val Loss: 73.43329
Epoch 75, Val Loss: 71.42377
Epoch 76, Val Loss: 76.63397
Epoch 77, Val Loss: 71.38819
Epoch 78, Val Loss: 68.67249
Epoch 79, Val Loss: 74.85954
Epoch 80, Val Loss: 69.53815
Epoch 81, Val Loss: 71.08376
Epoch 82, Val Loss: 67.91302
Epoch 83, Val Loss: 74.16620
Epoch 84, Val Loss: 69.58451
Epoch 85, Val Loss: 74.04431
Epoch 86, Val Loss: 76.71938
Epoch 87, Val Loss: 93.09335
Epoch 88, Val Loss: 70.11908
Epoch 89, Val Loss: 69.46664
Epoch 90, Val Loss: 72.53629
Epoch 91, Val Loss: 73.11379
Epoch 92, Val Loss: 68.39007
Epoch 93, Val Loss: 67.28931
Epoch 94, Val Loss: 71.28018
Epoch 95, Val Loss: 79.23292
Epoch 96, Val Loss: 71.47568
Epoch 97, Val Loss: 85.57887
Epoch 98, Val Loss: 76.41246
Epoch 99, Val Loss: 75.85922
DID NOT SAVE RESULTS
{'MSE - mean': 76.6579080398832, 'MSE - std': 8.241072065912904, 'R2 - mean': 0.5193581719277215, 'R2 - std': 0.022736413753986634} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 990.61932
Epoch 1, Val Loss: 569.00610
Epoch 2, Val Loss: 184.00909
Epoch 3, Val Loss: 143.51619
Epoch 4, Val Loss: 147.58461
Epoch 5, Val Loss: 139.20834
Epoch 6, Val Loss: 124.48276
Epoch 7, Val Loss: 120.53178
Epoch 8, Val Loss: 111.45256
Epoch 9, Val Loss: 117.02073
Epoch 10, Val Loss: 101.21983
Epoch 11, Val Loss: 106.52964
Epoch 12, Val Loss: 115.91930
Epoch 13, Val Loss: 98.92389
Epoch 14, Val Loss: 103.19823
Epoch 15, Val Loss: 104.99131
Epoch 16, Val Loss: 99.12095
Epoch 17, Val Loss: 108.93442
Epoch 18, Val Loss: 100.46480
Epoch 19, Val Loss: 96.67863
Epoch 20, Val Loss: 89.03481
Epoch 21, Val Loss: 97.24260
Epoch 22, Val Loss: 88.45968
Epoch 23, Val Loss: 98.56179
Epoch 24, Val Loss: 90.70766
Epoch 25, Val Loss: 96.23906
Epoch 26, Val Loss: 86.49838
Epoch 27, Val Loss: 90.13677
Epoch 28, Val Loss: 91.16059
Epoch 29, Val Loss: 89.29125
Epoch 30, Val Loss: 86.35410
Epoch 31, Val Loss: 85.40140
Epoch 32, Val Loss: 94.04362
Epoch 33, Val Loss: 90.63662
Epoch 34, Val Loss: 86.99548
Epoch 35, Val Loss: 85.52193
Epoch 36, Val Loss: 91.01558
Epoch 37, Val Loss: 83.21206
Epoch 38, Val Loss: 91.37305
Epoch 39, Val Loss: 87.66683
Epoch 40, Val Loss: 97.04449
Epoch 41, Val Loss: 86.18423
Epoch 42, Val Loss: 83.16794
Epoch 43, Val Loss: 87.19395
Epoch 44, Val Loss: 88.03484
Epoch 45, Val Loss: 88.62129
Epoch 46, Val Loss: 80.69413
Epoch 47, Val Loss: 86.16685
Epoch 48, Val Loss: 86.65527
Epoch 49, Val Loss: 85.79498
Epoch 50, Val Loss: 101.33460
Epoch 51, Val Loss: 82.64749
Epoch 52, Val Loss: 90.90545
Epoch 53, Val Loss: 83.95160
Epoch 54, Val Loss: 83.62891
Epoch 55, Val Loss: 88.45376
Epoch 56, Val Loss: 84.54684
Epoch 57, Val Loss: 84.49574
Epoch 58, Val Loss: 92.81769
Epoch 59, Val Loss: 81.56051
Epoch 60, Val Loss: 88.84927
Epoch 61, Val Loss: 79.85140
Epoch 62, Val Loss: 78.02055
Epoch 63, Val Loss: 79.29672
Epoch 64, Val Loss: 79.45538
Epoch 65, Val Loss: 79.44288
Epoch 66, Val Loss: 83.64714
Epoch 67, Val Loss: 86.28868
Epoch 68, Val Loss: 87.10231
Epoch 69, Val Loss: 82.66756
Epoch 70, Val Loss: 80.54691
Epoch 71, Val Loss: 83.89729
Epoch 72, Val Loss: 80.75891
Epoch 73, Val Loss: 104.95100
Epoch 74, Val Loss: 83.60322
Epoch 75, Val Loss: 79.97475
Epoch 76, Val Loss: 79.79845
Epoch 77, Val Loss: 79.49387
Epoch 78, Val Loss: 80.30771
Epoch 79, Val Loss: 90.06501
Epoch 80, Val Loss: 78.57090
Epoch 81, Val Loss: 78.71855
Epoch 82, Val Loss: 85.20068
Epoch 83, Val Loss: 101.48887
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.48860935560558, 'MSE - std': 8.658814088151708, 'R2 - mean': 0.5077084024671688, 'R2 - std': 0.02819325749618935} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 827.35162
Epoch 1, Val Loss: 396.04358
Epoch 2, Val Loss: 172.28758
Epoch 3, Val Loss: 149.69470
Epoch 4, Val Loss: 137.03424
Epoch 5, Val Loss: 118.85841
Epoch 6, Val Loss: 111.69604
Epoch 7, Val Loss: 131.48999
Epoch 8, Val Loss: 104.12550
Epoch 9, Val Loss: 94.76711
Epoch 10, Val Loss: 98.98846
Epoch 11, Val Loss: 107.77317
Epoch 12, Val Loss: 98.37699
Epoch 13, Val Loss: 96.07106
Epoch 14, Val Loss: 94.75529
Epoch 15, Val Loss: 90.09180
Epoch 16, Val Loss: 105.27309
Epoch 17, Val Loss: 85.96426
Epoch 18, Val Loss: 111.36293
Epoch 19, Val Loss: 88.54427
Epoch 20, Val Loss: 86.22062
Epoch 21, Val Loss: 93.27168
Epoch 22, Val Loss: 101.81736
Epoch 23, Val Loss: 103.03340
Epoch 24, Val Loss: 107.62713
Epoch 25, Val Loss: 106.81995
Epoch 26, Val Loss: 99.53674
Epoch 27, Val Loss: 89.53910
Epoch 28, Val Loss: 81.31815
Epoch 29, Val Loss: 90.26607
Epoch 30, Val Loss: 83.91705
Epoch 31, Val Loss: 102.85289
Epoch 32, Val Loss: 92.79962
Epoch 33, Val Loss: 85.80729
Epoch 34, Val Loss: 89.43835
Epoch 35, Val Loss: 91.08536
Epoch 36, Val Loss: 88.64656
Epoch 37, Val Loss: 85.72054
Epoch 38, Val Loss: 81.11109
Epoch 39, Val Loss: 93.68377
Epoch 40, Val Loss: 92.59879
Epoch 41, Val Loss: 93.20141
Epoch 42, Val Loss: 91.84799
Epoch 43, Val Loss: 83.71880
Epoch 44, Val Loss: 81.25534
Epoch 45, Val Loss: 86.47375
Epoch 46, Val Loss: 90.63084
Epoch 47, Val Loss: 83.18529
Epoch 48, Val Loss: 82.00845
Epoch 49, Val Loss: 85.38890
Epoch 50, Val Loss: 78.90327
Epoch 51, Val Loss: 100.47299
Epoch 52, Val Loss: 77.02983
Epoch 53, Val Loss: 80.56900
Epoch 54, Val Loss: 76.23917
Epoch 55, Val Loss: 76.83292
Epoch 56, Val Loss: 79.39066
Epoch 57, Val Loss: 80.83495
Epoch 58, Val Loss: 82.70007
Epoch 59, Val Loss: 73.74192
Epoch 60, Val Loss: 77.96201
Epoch 61, Val Loss: 82.52786
Epoch 62, Val Loss: 75.64810
Epoch 63, Val Loss: 85.42531
Epoch 64, Val Loss: 75.98381
Epoch 65, Val Loss: 75.28281
Epoch 66, Val Loss: 77.22703
Epoch 67, Val Loss: 77.05233
Epoch 68, Val Loss: 75.36311
Epoch 69, Val Loss: 88.69563
Epoch 70, Val Loss: 77.75105
Epoch 71, Val Loss: 72.87833
Epoch 72, Val Loss: 71.97357
Epoch 73, Val Loss: 76.17513
Epoch 74, Val Loss: 76.34784
Epoch 75, Val Loss: 72.58531
Epoch 76, Val Loss: 76.75616
Epoch 77, Val Loss: 74.86558
Epoch 78, Val Loss: 72.63924
Epoch 79, Val Loss: 83.46245
Epoch 80, Val Loss: 73.63242
Epoch 81, Val Loss: 85.67500
Epoch 82, Val Loss: 70.69455
Epoch 83, Val Loss: 75.20397
Epoch 84, Val Loss: 84.44344
Epoch 85, Val Loss: 78.82544
Epoch 86, Val Loss: 73.79852
Epoch 87, Val Loss: 71.91351
Epoch 88, Val Loss: 71.24021
Epoch 89, Val Loss: 72.76151
Epoch 90, Val Loss: 77.81880
Epoch 91, Val Loss: 75.18121
Epoch 92, Val Loss: 78.57054
Epoch 93, Val Loss: 72.01496
Epoch 94, Val Loss: 74.15576
Epoch 95, Val Loss: 80.92876
Epoch 96, Val Loss: 71.36024
Epoch 97, Val Loss: 87.57674
Epoch 98, Val Loss: 70.56284
Epoch 99, Val Loss: 75.35345
DID NOT SAVE RESULTS
{'MSE - mean': 78.15810071343482, 'MSE - std': 8.189081884930932, 'R2 - mean': 0.5148081492141051, 'R2 - std': 0.02893982429248119} 
 

Results After CV: {'MSE - mean': 78.15810071343482, 'MSE - std': 8.189081884930932, 'R2 - mean': 0.5148081492141051, 'R2 - std': 0.02893982429248119}
Train time: 430.13782194019876
Inference time: 0.19305291880154982
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 54 finished with value: 78.15810071343482 and parameters: {'p_m': 0.14640189807098336, 'alpha': 9.613380645959197, 'K': 2, 'beta': 7.261183912027121}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 795.47906
Epoch 1, Val Loss: 460.00864
Epoch 2, Val Loss: 195.10994
Epoch 3, Val Loss: 152.00578
Epoch 4, Val Loss: 147.34976
Epoch 5, Val Loss: 124.40988
Epoch 6, Val Loss: 124.11563
Epoch 7, Val Loss: 126.22128
Epoch 8, Val Loss: 115.90378
Epoch 9, Val Loss: 114.72693
Epoch 10, Val Loss: 103.49434
Epoch 11, Val Loss: 114.63983
Epoch 12, Val Loss: 106.05854
Epoch 13, Val Loss: 103.55350
Epoch 14, Val Loss: 104.44840
Epoch 15, Val Loss: 106.27477
Epoch 16, Val Loss: 102.66956
Epoch 17, Val Loss: 110.44926
Epoch 18, Val Loss: 102.55882
Epoch 19, Val Loss: 102.18978
Epoch 20, Val Loss: 94.55402
Epoch 21, Val Loss: 98.01697
Epoch 22, Val Loss: 96.04082
Epoch 23, Val Loss: 106.09479
Epoch 24, Val Loss: 101.74548
Epoch 25, Val Loss: 108.57631
Epoch 26, Val Loss: 105.33385
Epoch 27, Val Loss: 103.93870
Epoch 28, Val Loss: 94.78841
Epoch 29, Val Loss: 100.85698
Epoch 30, Val Loss: 96.49719
Epoch 31, Val Loss: 94.19800
Epoch 32, Val Loss: 116.15181
Epoch 33, Val Loss: 110.75111
Epoch 34, Val Loss: 93.35924
Epoch 35, Val Loss: 98.66469
Epoch 36, Val Loss: 99.12119
Epoch 37, Val Loss: 97.18309
Epoch 38, Val Loss: 94.63969
Epoch 39, Val Loss: 103.22005
Epoch 40, Val Loss: 97.89121
Epoch 41, Val Loss: 95.12669
Epoch 42, Val Loss: 105.71144
Epoch 43, Val Loss: 96.17573
Epoch 44, Val Loss: 89.64201
Epoch 45, Val Loss: 90.74103
Epoch 46, Val Loss: 92.82607
Epoch 47, Val Loss: 92.00803
Epoch 48, Val Loss: 98.71024
Epoch 49, Val Loss: 88.05437
Epoch 50, Val Loss: 86.41092
Epoch 51, Val Loss: 96.36417
Epoch 52, Val Loss: 87.44419
Epoch 53, Val Loss: 118.39487
Epoch 54, Val Loss: 92.05885
Epoch 55, Val Loss: 87.31400
Epoch 56, Val Loss: 94.26180
Epoch 57, Val Loss: 86.89347
Epoch 58, Val Loss: 86.17253
Epoch 59, Val Loss: 84.49348
Epoch 60, Val Loss: 89.60188
Epoch 61, Val Loss: 88.88255
Epoch 62, Val Loss: 88.65176
Epoch 63, Val Loss: 91.97615
Epoch 64, Val Loss: 89.93796
Epoch 65, Val Loss: 89.83031
Epoch 66, Val Loss: 88.07008
Epoch 67, Val Loss: 85.94418
Epoch 68, Val Loss: 87.93716
Epoch 69, Val Loss: 91.23416
Epoch 70, Val Loss: 110.96100
Epoch 71, Val Loss: 82.26101
Epoch 72, Val Loss: 87.71690
Epoch 73, Val Loss: 82.55299
Epoch 74, Val Loss: 87.37128
Epoch 75, Val Loss: 89.24520
Epoch 76, Val Loss: 87.39244
Epoch 77, Val Loss: 85.52068
Epoch 78, Val Loss: 89.94646
Epoch 79, Val Loss: 87.14159
Epoch 80, Val Loss: 87.08046
Epoch 81, Val Loss: 92.88695
Epoch 82, Val Loss: 86.49893
Epoch 83, Val Loss: 82.88139
Epoch 84, Val Loss: 85.53958
Epoch 85, Val Loss: 84.97385
Epoch 86, Val Loss: 81.72740
Epoch 87, Val Loss: 88.89362
Epoch 88, Val Loss: 85.39414
Epoch 89, Val Loss: 91.81464
Epoch 90, Val Loss: 88.36969
Epoch 91, Val Loss: 83.42436
Epoch 92, Val Loss: 88.26667
Epoch 93, Val Loss: 86.37149
Epoch 94, Val Loss: 85.83318
Epoch 95, Val Loss: 84.36638
Epoch 96, Val Loss: 83.74197
Epoch 97, Val Loss: 83.44585
Epoch 98, Val Loss: 82.31654
Epoch 99, Val Loss: 82.68967
DID NOT SAVE RESULTS
{'MSE - mean': 86.74668596711645, 'MSE - std': 0.0, 'R2 - mean': 0.49449820318318716, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 718.73816
Epoch 1, Val Loss: 357.41241
Epoch 2, Val Loss: 142.16306
Epoch 3, Val Loss: 130.02551
Epoch 4, Val Loss: 118.40378
Epoch 5, Val Loss: 108.16087
Epoch 6, Val Loss: 101.99692
Epoch 7, Val Loss: 105.39342
Epoch 8, Val Loss: 103.17853
Epoch 9, Val Loss: 97.38570
Epoch 10, Val Loss: 103.03174
Epoch 11, Val Loss: 91.25754
Epoch 12, Val Loss: 98.04646
Epoch 13, Val Loss: 94.97710
Epoch 14, Val Loss: 93.70086
Epoch 15, Val Loss: 102.37904
Epoch 16, Val Loss: 98.88466
Epoch 17, Val Loss: 89.86677
Epoch 18, Val Loss: 84.66544
Epoch 19, Val Loss: 89.61792
Epoch 20, Val Loss: 89.08473
Epoch 21, Val Loss: 75.28930
Epoch 22, Val Loss: 97.77515
Epoch 23, Val Loss: 96.41306
Epoch 24, Val Loss: 87.05965
Epoch 25, Val Loss: 81.47008
Epoch 26, Val Loss: 86.09711
Epoch 27, Val Loss: 86.96947
Epoch 28, Val Loss: 79.48618
Epoch 29, Val Loss: 84.50216
Epoch 30, Val Loss: 79.03886
Epoch 31, Val Loss: 85.76717
Epoch 32, Val Loss: 79.07322
Epoch 33, Val Loss: 81.04268
Epoch 34, Val Loss: 81.71832
Epoch 35, Val Loss: 98.38540
Epoch 36, Val Loss: 81.56520
Epoch 37, Val Loss: 79.97105
Epoch 38, Val Loss: 78.23610
Epoch 39, Val Loss: 97.14038
Epoch 40, Val Loss: 81.29827
Epoch 41, Val Loss: 88.37584
Epoch 42, Val Loss: 80.31586
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.79303150506371, 'MSE - std': 0.9536544620527465, 'R2 - mean': 0.47661231263279336, 'R2 - std': 0.0178858905503938} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 603.78027
Epoch 1, Val Loss: 345.81403
Epoch 2, Val Loss: 168.56306
Epoch 3, Val Loss: 136.78236
Epoch 4, Val Loss: 124.06087
Epoch 5, Val Loss: 113.07858
Epoch 6, Val Loss: 95.84300
Epoch 7, Val Loss: 95.60337
Epoch 8, Val Loss: 91.67121
Epoch 9, Val Loss: 105.36069
Epoch 10, Val Loss: 83.95840
Epoch 11, Val Loss: 88.86298
Epoch 12, Val Loss: 84.97959
Epoch 13, Val Loss: 84.17152
Epoch 14, Val Loss: 82.06728
Epoch 15, Val Loss: 113.45146
Epoch 16, Val Loss: 89.68807
Epoch 17, Val Loss: 83.95927
Epoch 18, Val Loss: 86.30271
Epoch 19, Val Loss: 86.24287
Epoch 20, Val Loss: 78.60810
Epoch 21, Val Loss: 75.22594
Epoch 22, Val Loss: 80.12271
Epoch 23, Val Loss: 83.40289
Epoch 24, Val Loss: 85.53148
Epoch 25, Val Loss: 80.55956
Epoch 26, Val Loss: 78.67138
Epoch 27, Val Loss: 82.46449
Epoch 28, Val Loss: 83.83223
Epoch 29, Val Loss: 78.73477
Epoch 30, Val Loss: 85.13335
Epoch 31, Val Loss: 85.51948
Epoch 32, Val Loss: 84.35025
Epoch 33, Val Loss: 78.57704
Epoch 34, Val Loss: 80.41094
Epoch 35, Val Loss: 94.46822
Epoch 36, Val Loss: 85.64397
Epoch 37, Val Loss: 81.56842
Epoch 38, Val Loss: 77.35976
Epoch 39, Val Loss: 79.16272
Epoch 40, Val Loss: 77.44910
Epoch 41, Val Loss: 92.67256
Epoch 42, Val Loss: 80.98641
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.74459161974005, 'MSE - std': 4.380898997259926, 'R2 - mean': 0.4793554341788679, 'R2 - std': 0.015110244388720323} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 832.14075
Epoch 1, Val Loss: 427.73135
Epoch 2, Val Loss: 196.62248
Epoch 3, Val Loss: 142.81174
Epoch 4, Val Loss: 130.19490
Epoch 5, Val Loss: 149.46613
Epoch 6, Val Loss: 138.42432
Epoch 7, Val Loss: 123.69553
Epoch 8, Val Loss: 114.19235
Epoch 9, Val Loss: 108.09338
Epoch 10, Val Loss: 113.48395
Epoch 11, Val Loss: 105.35840
Epoch 12, Val Loss: 102.32972
Epoch 13, Val Loss: 102.54504
Epoch 14, Val Loss: 102.09193
Epoch 15, Val Loss: 100.89507
Epoch 16, Val Loss: 137.87212
Epoch 17, Val Loss: 104.46293
Epoch 18, Val Loss: 98.06001
Epoch 19, Val Loss: 95.93638
Epoch 20, Val Loss: 101.71422
Epoch 21, Val Loss: 90.72478
Epoch 22, Val Loss: 106.56340
Epoch 23, Val Loss: 90.91578
Epoch 24, Val Loss: 114.52423
Epoch 25, Val Loss: 97.33513
Epoch 26, Val Loss: 103.28878
Epoch 27, Val Loss: 95.13767
Epoch 28, Val Loss: 99.52126
Epoch 29, Val Loss: 93.83388
Epoch 30, Val Loss: 90.61638
Epoch 31, Val Loss: 90.34161
Epoch 32, Val Loss: 94.64203
Epoch 33, Val Loss: 91.79786
Epoch 34, Val Loss: 84.08654
Epoch 35, Val Loss: 89.52071
Epoch 36, Val Loss: 91.35260
Epoch 37, Val Loss: 85.00913
Epoch 38, Val Loss: 92.96577
Epoch 39, Val Loss: 87.23412
Epoch 40, Val Loss: 93.67056
Epoch 41, Val Loss: 88.16808
Epoch 42, Val Loss: 86.68344
Epoch 43, Val Loss: 89.00890
Epoch 44, Val Loss: 85.74072
Epoch 45, Val Loss: 83.31166
Epoch 46, Val Loss: 98.79623
Epoch 47, Val Loss: 100.48213
Epoch 48, Val Loss: 87.00980
Epoch 49, Val Loss: 85.67977
Epoch 50, Val Loss: 95.53605
Epoch 51, Val Loss: 85.16069
Epoch 52, Val Loss: 92.13245
Epoch 53, Val Loss: 84.84933
Epoch 54, Val Loss: 87.76317
Epoch 55, Val Loss: 85.50325
Epoch 56, Val Loss: 83.27445
Epoch 57, Val Loss: 100.42727
Epoch 58, Val Loss: 81.26157
Epoch 59, Val Loss: 80.72355
Epoch 60, Val Loss: 80.40291
Epoch 61, Val Loss: 81.25821
Epoch 62, Val Loss: 83.55637
Epoch 63, Val Loss: 92.03207
Epoch 64, Val Loss: 85.24836
Epoch 65, Val Loss: 90.69731
Epoch 66, Val Loss: 76.14355
Epoch 67, Val Loss: 80.31336
Epoch 68, Val Loss: 81.52013
Epoch 69, Val Loss: 79.87984
Epoch 70, Val Loss: 88.69886
Epoch 71, Val Loss: 84.50478
Epoch 72, Val Loss: 81.02982
Epoch 73, Val Loss: 79.93181
Epoch 74, Val Loss: 80.30565
Epoch 75, Val Loss: 85.35006
Epoch 76, Val Loss: 79.39232
Epoch 77, Val Loss: 80.51469
Epoch 78, Val Loss: 85.95523
Epoch 79, Val Loss: 88.39674
Epoch 80, Val Loss: 79.29649
Epoch 81, Val Loss: 84.11115
Epoch 82, Val Loss: 86.44542
Epoch 83, Val Loss: 76.77657
Epoch 84, Val Loss: 92.27595
Epoch 85, Val Loss: 88.74110
Epoch 86, Val Loss: 80.77504
Epoch 87, Val Loss: 84.77009
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.8277741530246, 'MSE - std': 4.232500468917052, 'R2 - mean': 0.4790597849293517, 'R2 - std': 0.013095871087917708} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1042.18677
Epoch 1, Val Loss: 462.36127
Epoch 2, Val Loss: 171.91576
Epoch 3, Val Loss: 149.54909
Epoch 4, Val Loss: 150.54044
Epoch 5, Val Loss: 122.66829
Epoch 6, Val Loss: 113.45454
Epoch 7, Val Loss: 116.11494
Epoch 8, Val Loss: 102.62743
Epoch 9, Val Loss: 139.25211
Epoch 10, Val Loss: 106.35738
Epoch 11, Val Loss: 101.47036
Epoch 12, Val Loss: 121.58046
Epoch 13, Val Loss: 97.73982
Epoch 14, Val Loss: 96.27518
Epoch 15, Val Loss: 99.04609
Epoch 16, Val Loss: 118.38223
Epoch 17, Val Loss: 96.17888
Epoch 18, Val Loss: 121.60635
Epoch 19, Val Loss: 102.84341
Epoch 20, Val Loss: 89.65753
Epoch 21, Val Loss: 103.54521
Epoch 22, Val Loss: 102.82333
Epoch 23, Val Loss: 96.21636
Epoch 24, Val Loss: 92.91975
Epoch 25, Val Loss: 93.22058
Epoch 26, Val Loss: 97.56638
Epoch 27, Val Loss: 96.38495
Epoch 28, Val Loss: 98.54376
Epoch 29, Val Loss: 100.27287
Epoch 30, Val Loss: 99.08067
Epoch 31, Val Loss: 95.35419
Epoch 32, Val Loss: 85.15956
Epoch 33, Val Loss: 96.21400
Epoch 34, Val Loss: 99.85651
Epoch 35, Val Loss: 90.27582
Epoch 36, Val Loss: 91.40102
Epoch 37, Val Loss: 95.92854
Epoch 38, Val Loss: 95.41119
Epoch 39, Val Loss: 86.94865
Epoch 40, Val Loss: 88.73930
Epoch 41, Val Loss: 94.22018
Epoch 42, Val Loss: 91.72569
Epoch 43, Val Loss: 84.99344
Epoch 44, Val Loss: 90.82048
Epoch 45, Val Loss: 98.67054
Epoch 46, Val Loss: 91.01637
Epoch 47, Val Loss: 88.32166
Epoch 48, Val Loss: 84.28362
Epoch 49, Val Loss: 88.56734
Epoch 50, Val Loss: 78.81481
Epoch 51, Val Loss: 77.56151
Epoch 52, Val Loss: 80.64743
Epoch 53, Val Loss: 91.87076
Epoch 54, Val Loss: 100.50151
Epoch 55, Val Loss: 80.78366
Epoch 56, Val Loss: 81.59131
Epoch 57, Val Loss: 84.23144
Epoch 58, Val Loss: 81.02568
Epoch 59, Val Loss: 79.56232
Epoch 60, Val Loss: 78.78233
Epoch 61, Val Loss: 77.94598
Epoch 62, Val Loss: 90.72345
Epoch 63, Val Loss: 103.03642
Epoch 64, Val Loss: 76.84232
Epoch 65, Val Loss: 79.19563
Epoch 66, Val Loss: 83.29561
Epoch 67, Val Loss: 80.96731
Epoch 68, Val Loss: 89.01926
Epoch 69, Val Loss: 80.53334
Epoch 70, Val Loss: 79.52048
Epoch 71, Val Loss: 79.89820
Epoch 72, Val Loss: 75.00124
Epoch 73, Val Loss: 72.90820
Epoch 74, Val Loss: 77.24242
Epoch 75, Val Loss: 80.92821
Epoch 76, Val Loss: 76.84209
Epoch 77, Val Loss: 76.68604
Epoch 78, Val Loss: 76.22726
Epoch 79, Val Loss: 75.85960
Epoch 80, Val Loss: 76.43460
Epoch 81, Val Loss: 73.18089
Epoch 82, Val Loss: 75.81950
Epoch 83, Val Loss: 71.63570
Epoch 84, Val Loss: 75.10807
Epoch 85, Val Loss: 72.84329
Epoch 86, Val Loss: 82.28389
Epoch 87, Val Loss: 77.52615
Epoch 88, Val Loss: 76.93208
Epoch 89, Val Loss: 78.68324
Epoch 90, Val Loss: 75.73372
Epoch 91, Val Loss: 75.13703
Epoch 92, Val Loss: 77.08910
Epoch 93, Val Loss: 71.48438
Epoch 94, Val Loss: 71.21159
Epoch 95, Val Loss: 72.35741
Epoch 96, Val Loss: 88.14812
Epoch 97, Val Loss: 80.07577
Epoch 98, Val Loss: 74.14584
Epoch 99, Val Loss: 78.20141
DID NOT SAVE RESULTS
{'MSE - mean': 81.49162444997953, 'MSE - std': 6.013454075292906, 'R2 - mean': 0.4927535214824137, 'R2 - std': 0.029787164262140703} 
 

Results After CV: {'MSE - mean': 81.49162444997953, 'MSE - std': 6.013454075292906, 'R2 - mean': 0.4927535214824137, 'R2 - std': 0.029787164262140703}
Train time: 345.94134331879906
Inference time: 0.17605043000075965
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 55 finished with value: 81.49162444997953 and parameters: {'p_m': 0.14972970953528103, 'alpha': 9.574202730481987, 'K': 2, 'beta': 7.304737241768306}. Best is trial 41 with value: 77.75526758879647.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 895.40430
Epoch 1, Val Loss: 486.29468
Epoch 2, Val Loss: 168.39468
Epoch 3, Val Loss: 149.37894
Epoch 4, Val Loss: 152.12469
Epoch 5, Val Loss: 128.88226
Epoch 6, Val Loss: 117.01951
Epoch 7, Val Loss: 129.76312
Epoch 8, Val Loss: 132.05843
Epoch 9, Val Loss: 119.87540
Epoch 10, Val Loss: 113.49129
Epoch 11, Val Loss: 128.30232
Epoch 12, Val Loss: 115.64233
Epoch 13, Val Loss: 104.78004
Epoch 14, Val Loss: 113.95078
Epoch 15, Val Loss: 100.81635
Epoch 16, Val Loss: 104.86414
Epoch 17, Val Loss: 105.46658
Epoch 18, Val Loss: 119.42633
Epoch 19, Val Loss: 98.07535
Epoch 20, Val Loss: 112.83126
Epoch 21, Val Loss: 116.77763
Epoch 22, Val Loss: 102.34865
Epoch 23, Val Loss: 120.90267
Epoch 24, Val Loss: 106.88930
Epoch 25, Val Loss: 97.98672
Epoch 26, Val Loss: 93.89031
Epoch 27, Val Loss: 122.24893
Epoch 28, Val Loss: 104.74925
Epoch 29, Val Loss: 101.77278
Epoch 30, Val Loss: 93.75060
Epoch 31, Val Loss: 96.25179
Epoch 32, Val Loss: 104.15545
Epoch 33, Val Loss: 102.21254
Epoch 34, Val Loss: 109.33104
Epoch 35, Val Loss: 109.17653
Epoch 36, Val Loss: 93.83372
Epoch 37, Val Loss: 90.40538
Epoch 38, Val Loss: 91.77824
Epoch 39, Val Loss: 102.56842
Epoch 40, Val Loss: 96.64375
Epoch 41, Val Loss: 94.81274
Epoch 42, Val Loss: 95.59821
Epoch 43, Val Loss: 114.18143
Epoch 44, Val Loss: 91.73967
Epoch 45, Val Loss: 86.59816
Epoch 46, Val Loss: 91.41513
Epoch 47, Val Loss: 91.58980
Epoch 48, Val Loss: 93.45086
Epoch 49, Val Loss: 112.03365
Epoch 50, Val Loss: 97.63174
Epoch 51, Val Loss: 103.90668
Epoch 52, Val Loss: 88.25104
Epoch 53, Val Loss: 90.83532
Epoch 54, Val Loss: 89.66162
Epoch 55, Val Loss: 86.64098
Epoch 56, Val Loss: 91.94225
Epoch 57, Val Loss: 84.36540
Epoch 58, Val Loss: 93.32767
Epoch 59, Val Loss: 89.99522
Epoch 60, Val Loss: 87.08900
Epoch 61, Val Loss: 87.28095
Epoch 62, Val Loss: 95.03280
Epoch 63, Val Loss: 88.91478
Epoch 64, Val Loss: 92.44830
Epoch 65, Val Loss: 95.25500
Epoch 66, Val Loss: 93.03104
Epoch 67, Val Loss: 94.64140
Epoch 68, Val Loss: 84.90627
Epoch 69, Val Loss: 98.16768
Epoch 70, Val Loss: 86.03508
Epoch 71, Val Loss: 85.38507
Epoch 72, Val Loss: 85.31297
Epoch 73, Val Loss: 84.18677
Epoch 74, Val Loss: 91.19221
Epoch 75, Val Loss: 86.92015
Epoch 76, Val Loss: 85.33186
Epoch 77, Val Loss: 96.11550
Epoch 78, Val Loss: 90.84842
Epoch 79, Val Loss: 92.09593
Epoch 80, Val Loss: 84.86612
Epoch 81, Val Loss: 84.37672
Epoch 82, Val Loss: 84.46931
Epoch 83, Val Loss: 88.42178
Epoch 84, Val Loss: 83.30904
Epoch 85, Val Loss: 84.33675
Epoch 86, Val Loss: 82.45315
Epoch 87, Val Loss: 101.76228
Epoch 88, Val Loss: 84.34306
Epoch 89, Val Loss: 85.90778
Epoch 90, Val Loss: 90.56331
Epoch 91, Val Loss: 81.38265
Epoch 92, Val Loss: 80.56947
Epoch 93, Val Loss: 85.79265
Epoch 94, Val Loss: 93.07802
Epoch 95, Val Loss: 105.33925
Epoch 96, Val Loss: 84.06268
Epoch 97, Val Loss: 83.61852
Epoch 98, Val Loss: 82.63899
Epoch 99, Val Loss: 82.65244
DID NOT SAVE RESULTS
{'MSE - mean': 84.84456748349058, 'MSE - std': 0.0, 'R2 - mean': 0.5055824803577162, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1135.61865
Epoch 1, Val Loss: 484.79404
Epoch 2, Val Loss: 153.70697
Epoch 3, Val Loss: 145.30299
Epoch 4, Val Loss: 120.84674
Epoch 5, Val Loss: 130.79149
Epoch 6, Val Loss: 115.74590
Epoch 7, Val Loss: 103.32376
Epoch 8, Val Loss: 127.69064
Epoch 9, Val Loss: 93.62336
Epoch 10, Val Loss: 96.73914
Epoch 11, Val Loss: 96.29322
Epoch 12, Val Loss: 86.46806
Epoch 13, Val Loss: 102.99831
Epoch 14, Val Loss: 95.16219
Epoch 15, Val Loss: 83.78181
Epoch 16, Val Loss: 96.97227
Epoch 17, Val Loss: 109.91524
Epoch 18, Val Loss: 88.72485
Epoch 19, Val Loss: 86.02026
Epoch 20, Val Loss: 86.28951
Epoch 21, Val Loss: 99.66506
Epoch 22, Val Loss: 95.69096
Epoch 23, Val Loss: 87.21858
Epoch 24, Val Loss: 82.24277
Epoch 25, Val Loss: 81.42958
Epoch 26, Val Loss: 86.72219
Epoch 27, Val Loss: 83.61329
Epoch 28, Val Loss: 81.48636
Epoch 29, Val Loss: 83.57610
Epoch 30, Val Loss: 95.45808
Epoch 31, Val Loss: 82.87021
Epoch 32, Val Loss: 89.96503
Epoch 33, Val Loss: 91.23891
Epoch 34, Val Loss: 83.68932
Epoch 35, Val Loss: 101.57614
Epoch 36, Val Loss: 81.49366
Epoch 37, Val Loss: 80.04932
Epoch 38, Val Loss: 78.05495
Epoch 39, Val Loss: 85.59262
Epoch 40, Val Loss: 74.38835
Epoch 41, Val Loss: 82.15702
Epoch 42, Val Loss: 80.43040
Epoch 43, Val Loss: 82.31874
Epoch 44, Val Loss: 77.10426
Epoch 45, Val Loss: 88.25724
Epoch 46, Val Loss: 78.40327
Epoch 47, Val Loss: 77.37752
Epoch 48, Val Loss: 84.45322
Epoch 49, Val Loss: 74.06946
Epoch 50, Val Loss: 72.30112
Epoch 51, Val Loss: 78.16206
Epoch 52, Val Loss: 70.91384
Epoch 53, Val Loss: 91.84380
Epoch 54, Val Loss: 72.17697
Epoch 55, Val Loss: 71.41010
Epoch 56, Val Loss: 70.16508
Epoch 57, Val Loss: 72.31754
Epoch 58, Val Loss: 73.99313
Epoch 59, Val Loss: 85.34692
Epoch 60, Val Loss: 75.12482
Epoch 61, Val Loss: 68.67529
Epoch 62, Val Loss: 70.23781
Epoch 63, Val Loss: 69.15929
Epoch 64, Val Loss: 68.73925
Epoch 65, Val Loss: 72.81428
Epoch 66, Val Loss: 75.66048
Epoch 67, Val Loss: 74.87629
Epoch 68, Val Loss: 73.25332
Epoch 69, Val Loss: 68.28965
Epoch 70, Val Loss: 71.03410
Epoch 71, Val Loss: 72.93130
Epoch 72, Val Loss: 70.31976
Epoch 73, Val Loss: 66.14764
Epoch 74, Val Loss: 70.64954
Epoch 75, Val Loss: 79.28073
Epoch 76, Val Loss: 75.57144
Epoch 77, Val Loss: 76.34351
Epoch 78, Val Loss: 69.71239
Epoch 79, Val Loss: 71.76464
Epoch 80, Val Loss: 70.40831
Epoch 81, Val Loss: 71.38332
Epoch 82, Val Loss: 69.27810
Epoch 83, Val Loss: 70.29001
Epoch 84, Val Loss: 77.47392
Epoch 85, Val Loss: 66.58784
Epoch 86, Val Loss: 68.15967
Epoch 87, Val Loss: 85.11451
Epoch 88, Val Loss: 66.47412
Epoch 89, Val Loss: 70.27265
Epoch 90, Val Loss: 72.37341
Epoch 91, Val Loss: 65.51328
Epoch 92, Val Loss: 73.44090
Epoch 93, Val Loss: 81.81387
Epoch 94, Val Loss: 73.37131
Epoch 95, Val Loss: 69.82204
Epoch 96, Val Loss: 69.08867
Epoch 97, Val Loss: 68.33318
Epoch 98, Val Loss: 68.60323
Epoch 99, Val Loss: 70.44790
DID NOT SAVE RESULTS
{'MSE - mean': 78.48398361111336, 'MSE - std': 6.360583872377212, 'R2 - mean': 0.522718295345849, 'R2 - std': 0.01713581498813277} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1252.31812
Epoch 1, Val Loss: 426.22406
Epoch 2, Val Loss: 161.85921
Epoch 3, Val Loss: 134.57895
Epoch 4, Val Loss: 119.51577
Epoch 5, Val Loss: 122.76703
Epoch 6, Val Loss: 115.84618
Epoch 7, Val Loss: 100.53668
Epoch 8, Val Loss: 90.74280
Epoch 9, Val Loss: 92.37682
Epoch 10, Val Loss: 94.35530
Epoch 11, Val Loss: 82.58871
Epoch 12, Val Loss: 85.75109
Epoch 13, Val Loss: 92.17010
Epoch 14, Val Loss: 92.58181
Epoch 15, Val Loss: 83.58988
Epoch 16, Val Loss: 83.38046
Epoch 17, Val Loss: 82.26048
Epoch 18, Val Loss: 88.18429
Epoch 19, Val Loss: 91.49800
Epoch 20, Val Loss: 88.96618
Epoch 21, Val Loss: 85.14724
Epoch 22, Val Loss: 80.57800
Epoch 23, Val Loss: 85.54810
Epoch 24, Val Loss: 85.65726
Epoch 25, Val Loss: 83.26523
Epoch 26, Val Loss: 80.01408
Epoch 27, Val Loss: 84.35428
Epoch 28, Val Loss: 81.45010
Epoch 29, Val Loss: 82.80511
Epoch 30, Val Loss: 80.21769
Epoch 31, Val Loss: 80.24002
Epoch 32, Val Loss: 74.69650
Epoch 33, Val Loss: 80.31845
Epoch 34, Val Loss: 73.96446
Epoch 35, Val Loss: 98.85252
Epoch 36, Val Loss: 87.43319
Epoch 37, Val Loss: 80.03040
Epoch 38, Val Loss: 86.75988
Epoch 39, Val Loss: 71.74263
Epoch 40, Val Loss: 74.25748
Epoch 41, Val Loss: 73.88123
Epoch 42, Val Loss: 75.17419
Epoch 43, Val Loss: 75.36134
Epoch 44, Val Loss: 83.04346
Epoch 45, Val Loss: 115.44308
Epoch 46, Val Loss: 72.17860
Epoch 47, Val Loss: 72.55750
Epoch 48, Val Loss: 82.80012
Epoch 49, Val Loss: 75.21917
Epoch 50, Val Loss: 75.57553
Epoch 51, Val Loss: 72.32928
Epoch 52, Val Loss: 77.03215
Epoch 53, Val Loss: 77.79381
Epoch 54, Val Loss: 72.60551
Epoch 55, Val Loss: 73.04693
Epoch 56, Val Loss: 72.54163
Epoch 57, Val Loss: 71.23163
Epoch 58, Val Loss: 78.32092
Epoch 59, Val Loss: 68.43513
Epoch 60, Val Loss: 70.93923
Epoch 61, Val Loss: 70.33044
Epoch 62, Val Loss: 77.84435
Epoch 63, Val Loss: 77.11035
Epoch 64, Val Loss: 73.48264
Epoch 65, Val Loss: 82.80770
Epoch 66, Val Loss: 73.33708
Epoch 67, Val Loss: 75.95415
Epoch 68, Val Loss: 70.39290
Epoch 69, Val Loss: 74.18117
Epoch 70, Val Loss: 68.03996
Epoch 71, Val Loss: 73.67763
Epoch 72, Val Loss: 76.43533
Epoch 73, Val Loss: 70.88275
Epoch 74, Val Loss: 73.93575
Epoch 75, Val Loss: 71.13852
Epoch 76, Val Loss: 66.78943
Epoch 77, Val Loss: 69.56911
Epoch 78, Val Loss: 69.54286
Epoch 79, Val Loss: 69.49031
Epoch 80, Val Loss: 68.82377
Epoch 81, Val Loss: 68.16136
Epoch 82, Val Loss: 88.09111
Epoch 83, Val Loss: 90.52042
Epoch 84, Val Loss: 68.70514
Epoch 85, Val Loss: 66.56412
Epoch 86, Val Loss: 68.24194
Epoch 87, Val Loss: 74.61079
Epoch 88, Val Loss: 68.01533
Epoch 89, Val Loss: 66.52339
Epoch 90, Val Loss: 72.06235
Epoch 91, Val Loss: 72.28745
Epoch 92, Val Loss: 81.01099
Epoch 93, Val Loss: 69.17257
Epoch 94, Val Loss: 66.62434
Epoch 95, Val Loss: 82.07047
Epoch 96, Val Loss: 67.10070
Epoch 97, Val Loss: 84.68374
Epoch 98, Val Loss: 87.13380
Epoch 99, Val Loss: 69.16476
DID NOT SAVE RESULTS
{'MSE - mean': 75.01802116096701, 'MSE - std': 7.141228387096938, 'R2 - mean': 0.5292739657935635, 'R2 - std': 0.01678425056145641} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 464.83679
Epoch 1, Val Loss: 307.20532
Epoch 2, Val Loss: 174.57680
Epoch 3, Val Loss: 138.66075
Epoch 4, Val Loss: 137.61938
Epoch 5, Val Loss: 130.68007
Epoch 6, Val Loss: 124.19513
Epoch 7, Val Loss: 135.81976
Epoch 8, Val Loss: 115.68575
Epoch 9, Val Loss: 132.01442
Epoch 10, Val Loss: 121.75074
Epoch 11, Val Loss: 107.39485
Epoch 12, Val Loss: 101.56031
Epoch 13, Val Loss: 101.32191
Epoch 14, Val Loss: 97.29235
Epoch 15, Val Loss: 103.38025
Epoch 16, Val Loss: 97.39883
Epoch 17, Val Loss: 122.98962
Epoch 18, Val Loss: 108.64588
Epoch 19, Val Loss: 100.67914
Epoch 20, Val Loss: 97.01421
Epoch 21, Val Loss: 111.13708
Epoch 22, Val Loss: 88.72811
Epoch 23, Val Loss: 95.98192
Epoch 24, Val Loss: 87.37842
Epoch 25, Val Loss: 90.95689
Epoch 26, Val Loss: 94.76006
Epoch 27, Val Loss: 90.52300
Epoch 28, Val Loss: 93.57548
Epoch 29, Val Loss: 88.40536
Epoch 30, Val Loss: 87.05920
Epoch 31, Val Loss: 91.97598
Epoch 32, Val Loss: 109.17593
Epoch 33, Val Loss: 86.83262
Epoch 34, Val Loss: 91.65319
Epoch 35, Val Loss: 95.15704
Epoch 36, Val Loss: 85.68877
Epoch 37, Val Loss: 93.00661
Epoch 38, Val Loss: 95.14719
Epoch 39, Val Loss: 84.12068
Epoch 40, Val Loss: 93.98976
Epoch 41, Val Loss: 92.12891
Epoch 42, Val Loss: 112.36832
Epoch 43, Val Loss: 84.52660
Epoch 44, Val Loss: 103.31430
Epoch 45, Val Loss: 87.03484
Epoch 46, Val Loss: 85.39865
Epoch 47, Val Loss: 83.53688
Epoch 48, Val Loss: 86.09019
Epoch 49, Val Loss: 82.73413
Epoch 50, Val Loss: 82.54616
Epoch 51, Val Loss: 86.13712
Epoch 52, Val Loss: 82.29945
Epoch 53, Val Loss: 83.09767
Epoch 54, Val Loss: 93.80698
Epoch 55, Val Loss: 80.55158
Epoch 56, Val Loss: 83.67747
Epoch 57, Val Loss: 83.35890
Epoch 58, Val Loss: 79.42890
Epoch 59, Val Loss: 82.81527
Epoch 60, Val Loss: 85.52705
Epoch 61, Val Loss: 81.90943
Epoch 62, Val Loss: 77.89557
Epoch 63, Val Loss: 81.55518
Epoch 64, Val Loss: 77.38292
Epoch 65, Val Loss: 79.65357
Epoch 66, Val Loss: 78.24946
Epoch 67, Val Loss: 76.92663
Epoch 68, Val Loss: 80.72073
Epoch 69, Val Loss: 79.25523
Epoch 70, Val Loss: 83.44078
Epoch 71, Val Loss: 77.46752
Epoch 72, Val Loss: 80.52311
Epoch 73, Val Loss: 76.43140
Epoch 74, Val Loss: 86.44083
Epoch 75, Val Loss: 80.38753
Epoch 76, Val Loss: 81.96217
Epoch 77, Val Loss: 90.49680
Epoch 78, Val Loss: 80.11978
Epoch 79, Val Loss: 78.23715
Epoch 80, Val Loss: 82.96785
Epoch 81, Val Loss: 81.77659
Epoch 82, Val Loss: 77.86605
Epoch 83, Val Loss: 79.55661
Epoch 84, Val Loss: 80.25539
Epoch 85, Val Loss: 77.61892
Epoch 86, Val Loss: 84.12580
Epoch 87, Val Loss: 77.76410
Epoch 88, Val Loss: 77.64766
Epoch 89, Val Loss: 78.96507
Epoch 90, Val Loss: 76.14709
Epoch 91, Val Loss: 77.44221
Epoch 92, Val Loss: 76.02972
Epoch 93, Val Loss: 84.34959
Epoch 94, Val Loss: 78.83915
Epoch 95, Val Loss: 77.99773
Epoch 96, Val Loss: 81.18827
Epoch 97, Val Loss: 93.81786
Epoch 98, Val Loss: 80.98607
Epoch 99, Val Loss: 84.04204
DID NOT SAVE RESULTS
{'MSE - mean': 77.69383840704896, 'MSE - std': 7.728379581826854, 'R2 - mean': 0.518530251998914, 'R2 - std': 0.02361282402607394} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 568.67010
Epoch 1, Val Loss: 330.49359
Epoch 2, Val Loss: 172.20403
Epoch 3, Val Loss: 144.12523
Epoch 4, Val Loss: 135.75514
Epoch 5, Val Loss: 115.41521
Epoch 6, Val Loss: 116.12307
Epoch 7, Val Loss: 126.72112
Epoch 8, Val Loss: 102.53836
Epoch 9, Val Loss: 104.49100
Epoch 10, Val Loss: 108.62035
Epoch 11, Val Loss: 98.12737
Epoch 12, Val Loss: 99.89186
Epoch 13, Val Loss: 110.23259
Epoch 14, Val Loss: 102.24224
Epoch 15, Val Loss: 104.21609
Epoch 16, Val Loss: 100.72383
Epoch 17, Val Loss: 101.93050
Epoch 18, Val Loss: 95.46689
Epoch 19, Val Loss: 97.47413
Epoch 20, Val Loss: 90.20956
Epoch 21, Val Loss: 90.87686
Epoch 22, Val Loss: 94.56889
Epoch 23, Val Loss: 100.54625
Epoch 24, Val Loss: 102.16246
Epoch 25, Val Loss: 90.46554
Epoch 26, Val Loss: 96.65389
Epoch 27, Val Loss: 89.03019
Epoch 28, Val Loss: 100.05788
Epoch 29, Val Loss: 96.21121
Epoch 30, Val Loss: 99.27564
Epoch 31, Val Loss: 106.00336
Epoch 32, Val Loss: 89.47910
Epoch 33, Val Loss: 91.37970
Epoch 34, Val Loss: 100.21245
Epoch 35, Val Loss: 101.75826
Epoch 36, Val Loss: 87.62053
Epoch 37, Val Loss: 93.54368
Epoch 38, Val Loss: 85.12096
Epoch 39, Val Loss: 89.43619
Epoch 40, Val Loss: 90.03218
Epoch 41, Val Loss: 88.21513
Epoch 42, Val Loss: 85.59141
Epoch 43, Val Loss: 105.99294
Epoch 44, Val Loss: 86.85843
Epoch 45, Val Loss: 103.96719
Epoch 46, Val Loss: 87.18637
Epoch 47, Val Loss: 94.49087
Epoch 48, Val Loss: 85.26911
Epoch 49, Val Loss: 91.12460
Epoch 50, Val Loss: 82.84921
Epoch 51, Val Loss: 99.95700
Epoch 52, Val Loss: 83.04675
Epoch 53, Val Loss: 94.20854
Epoch 54, Val Loss: 84.07102
Epoch 55, Val Loss: 99.17705
Epoch 56, Val Loss: 79.21806
Epoch 57, Val Loss: 82.92743
Epoch 58, Val Loss: 85.34722
Epoch 59, Val Loss: 86.57010
Epoch 60, Val Loss: 86.71371
Epoch 61, Val Loss: 81.55267
Epoch 62, Val Loss: 81.13031
Epoch 63, Val Loss: 81.73461
Epoch 64, Val Loss: 82.64352
Epoch 65, Val Loss: 83.01569
Epoch 66, Val Loss: 87.28845
Epoch 67, Val Loss: 83.84885
Epoch 68, Val Loss: 86.68893
Epoch 69, Val Loss: 78.32142
Epoch 70, Val Loss: 77.11532
Epoch 71, Val Loss: 77.76884
Epoch 72, Val Loss: 77.27116
Epoch 73, Val Loss: 83.54363
Epoch 74, Val Loss: 75.85947
Epoch 75, Val Loss: 78.27287
Epoch 76, Val Loss: 79.54898
Epoch 77, Val Loss: 76.17753
Epoch 78, Val Loss: 85.38994
Epoch 79, Val Loss: 77.65299
Epoch 80, Val Loss: 78.29182
Epoch 81, Val Loss: 78.77218
Epoch 82, Val Loss: 84.91882
Epoch 83, Val Loss: 79.05607
Epoch 84, Val Loss: 78.27829
Epoch 85, Val Loss: 78.27536
Epoch 86, Val Loss: 72.45261
Epoch 87, Val Loss: 72.15502
Epoch 88, Val Loss: 89.00690
Epoch 89, Val Loss: 73.29593
Epoch 90, Val Loss: 75.22913
Epoch 91, Val Loss: 83.55527
Epoch 92, Val Loss: 88.72711
Epoch 93, Val Loss: 74.99754
Epoch 94, Val Loss: 77.57563
Epoch 95, Val Loss: 76.18753
Epoch 96, Val Loss: 72.52738
Epoch 97, Val Loss: 76.99367
Epoch 98, Val Loss: 80.18272
Epoch 99, Val Loss: 74.21312
DID NOT SAVE RESULTS
{'MSE - mean': 77.02717411419609, 'MSE - std': 7.039889621726936, 'R2 - mean': 0.5215535040293313, 'R2 - std': 0.021968445055277775} 
 

Results After CV: {'MSE - mean': 77.02717411419609, 'MSE - std': 7.039889621726936, 'R2 - mean': 0.5215535040293313, 'R2 - std': 0.021968445055277775}
Train time: 472.6788736975985
Inference time: 0.19752701559336855
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 56 finished with value: 77.02717411419609 and parameters: {'p_m': 0.19543335210332746, 'alpha': 9.619143087097799, 'K': 2, 'beta': 6.291092231131599}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 534.38409
Epoch 1, Val Loss: 402.15936
Epoch 2, Val Loss: 188.35231
Epoch 3, Val Loss: 140.31671
Epoch 4, Val Loss: 136.62715
Epoch 5, Val Loss: 125.63406
Epoch 6, Val Loss: 130.68636
Epoch 7, Val Loss: 119.22540
Epoch 8, Val Loss: 145.79903
Epoch 9, Val Loss: 114.63011
Epoch 10, Val Loss: 117.00587
Epoch 11, Val Loss: 116.83354
Epoch 12, Val Loss: 115.89934
Epoch 13, Val Loss: 118.44418
Epoch 14, Val Loss: 111.50388
Epoch 15, Val Loss: 113.29825
Epoch 16, Val Loss: 123.15723
Epoch 17, Val Loss: 108.45224
Epoch 18, Val Loss: 109.16048
Epoch 19, Val Loss: 104.74812
Epoch 20, Val Loss: 102.41574
Epoch 21, Val Loss: 98.33383
Epoch 22, Val Loss: 100.84830
Epoch 23, Val Loss: 113.23549
Epoch 24, Val Loss: 139.04028
Epoch 25, Val Loss: 97.59526
Epoch 26, Val Loss: 98.40501
Epoch 27, Val Loss: 100.45270
Epoch 28, Val Loss: 98.68196
Epoch 29, Val Loss: 92.05828
Epoch 30, Val Loss: 95.31898
Epoch 31, Val Loss: 129.38286
Epoch 32, Val Loss: 86.79939
Epoch 33, Val Loss: 94.18946
Epoch 34, Val Loss: 89.16879
Epoch 35, Val Loss: 94.17456
Epoch 36, Val Loss: 84.59212
Epoch 37, Val Loss: 87.89186
Epoch 38, Val Loss: 99.73598
Epoch 39, Val Loss: 93.85771
Epoch 40, Val Loss: 86.22643
Epoch 41, Val Loss: 88.44748
Epoch 42, Val Loss: 91.81703
Epoch 43, Val Loss: 85.33696
Epoch 44, Val Loss: 88.16535
Epoch 45, Val Loss: 89.84171
Epoch 46, Val Loss: 90.80741
Epoch 47, Val Loss: 84.40891
Epoch 48, Val Loss: 94.80875
Epoch 49, Val Loss: 88.09412
Epoch 50, Val Loss: 82.88242
Epoch 51, Val Loss: 89.48106
Epoch 52, Val Loss: 92.02071
Epoch 53, Val Loss: 84.26543
Epoch 54, Val Loss: 90.88030
Epoch 55, Val Loss: 83.27531
Epoch 56, Val Loss: 85.41112
Epoch 57, Val Loss: 109.45645
Epoch 58, Val Loss: 84.43224
Epoch 59, Val Loss: 86.84885
Epoch 60, Val Loss: 84.90343
Epoch 61, Val Loss: 89.85625
Epoch 62, Val Loss: 86.73944
Epoch 63, Val Loss: 88.16977
Epoch 64, Val Loss: 87.29623
Epoch 65, Val Loss: 87.81737
Epoch 66, Val Loss: 82.04980
Epoch 67, Val Loss: 85.23015
Epoch 68, Val Loss: 87.11667
Epoch 69, Val Loss: 85.46886
Epoch 70, Val Loss: 86.70953
Epoch 71, Val Loss: 98.86807
Epoch 72, Val Loss: 85.85831
Epoch 73, Val Loss: 88.08897
Epoch 74, Val Loss: 87.16586
Epoch 75, Val Loss: 84.60686
Epoch 76, Val Loss: 81.15773
Epoch 77, Val Loss: 85.19498
Epoch 78, Val Loss: 85.21919
Epoch 79, Val Loss: 95.98200
Epoch 80, Val Loss: 90.23734
Epoch 81, Val Loss: 86.14104
Epoch 82, Val Loss: 85.09252
Epoch 83, Val Loss: 94.57543
Epoch 84, Val Loss: 85.53052
Epoch 85, Val Loss: 92.12012
Epoch 86, Val Loss: 85.99609
Epoch 87, Val Loss: 89.62708
Epoch 88, Val Loss: 86.53755
Epoch 89, Val Loss: 88.14888
Epoch 90, Val Loss: 92.29607
Epoch 91, Val Loss: 90.23653
Epoch 92, Val Loss: 90.54906
Epoch 93, Val Loss: 94.37842
Epoch 94, Val Loss: 88.02682
Epoch 95, Val Loss: 85.74635
Epoch 96, Val Loss: 88.77671
Epoch 97, Val Loss: 85.29292
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.83270972444548, 'MSE - std': 0.0, 'R2 - mean': 0.505651579464347, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 875.52527
Epoch 1, Val Loss: 436.01517
Epoch 2, Val Loss: 165.24309
Epoch 3, Val Loss: 151.54527
Epoch 4, Val Loss: 139.91959
Epoch 5, Val Loss: 137.17719
Epoch 6, Val Loss: 107.97635
Epoch 7, Val Loss: 116.06574
Epoch 8, Val Loss: 108.84470
Epoch 9, Val Loss: 115.08739
Epoch 10, Val Loss: 106.38698
Epoch 11, Val Loss: 96.24529
Epoch 12, Val Loss: 89.31320
Epoch 13, Val Loss: 86.16827
Epoch 14, Val Loss: 89.50924
Epoch 15, Val Loss: 103.90904
Epoch 16, Val Loss: 97.60281
Epoch 17, Val Loss: 91.09956
Epoch 18, Val Loss: 86.32341
Epoch 19, Val Loss: 94.61108
Epoch 20, Val Loss: 102.51410
Epoch 21, Val Loss: 88.58897
Epoch 22, Val Loss: 87.89362
Epoch 23, Val Loss: 89.27740
Epoch 24, Val Loss: 80.65686
Epoch 25, Val Loss: 82.36208
Epoch 26, Val Loss: 80.29707
Epoch 27, Val Loss: 93.63397
Epoch 28, Val Loss: 81.81450
Epoch 29, Val Loss: 78.48431
Epoch 30, Val Loss: 82.36146
Epoch 31, Val Loss: 91.64414
Epoch 32, Val Loss: 91.26487
Epoch 33, Val Loss: 83.85005
Epoch 34, Val Loss: 94.39135
Epoch 35, Val Loss: 84.23832
Epoch 36, Val Loss: 76.89504
Epoch 37, Val Loss: 78.64339
Epoch 38, Val Loss: 77.97316
Epoch 39, Val Loss: 73.93821
Epoch 40, Val Loss: 77.47758
Epoch 41, Val Loss: 88.91718
Epoch 42, Val Loss: 81.07555
Epoch 43, Val Loss: 81.28928
Epoch 44, Val Loss: 85.21980
Epoch 45, Val Loss: 82.47047
Epoch 46, Val Loss: 85.47706
Epoch 47, Val Loss: 73.41107
Epoch 48, Val Loss: 78.84293
Epoch 49, Val Loss: 90.42923
Epoch 50, Val Loss: 85.32153
Epoch 51, Val Loss: 75.66293
Epoch 52, Val Loss: 75.25543
Epoch 53, Val Loss: 85.38716
Epoch 54, Val Loss: 77.73025
Epoch 55, Val Loss: 72.56200
Epoch 56, Val Loss: 78.29241
Epoch 57, Val Loss: 76.71564
Epoch 58, Val Loss: 89.04831
Epoch 59, Val Loss: 115.11806
Epoch 60, Val Loss: 73.69056
Epoch 61, Val Loss: 72.44168
Epoch 62, Val Loss: 72.30216
Epoch 63, Val Loss: 74.47098
Epoch 64, Val Loss: 74.53334
Epoch 65, Val Loss: 70.03742
Epoch 66, Val Loss: 77.31846
Epoch 67, Val Loss: 74.76086
Epoch 68, Val Loss: 73.21410
Epoch 69, Val Loss: 71.75237
Epoch 70, Val Loss: 75.06075
Epoch 71, Val Loss: 68.67587
Epoch 72, Val Loss: 74.86739
Epoch 73, Val Loss: 71.17123
Epoch 74, Val Loss: 71.81497
Epoch 75, Val Loss: 74.21660
Epoch 76, Val Loss: 80.55117
Epoch 77, Val Loss: 76.05002
Epoch 78, Val Loss: 68.60114
Epoch 79, Val Loss: 69.74789
Epoch 80, Val Loss: 84.45361
Epoch 81, Val Loss: 71.27395
Epoch 82, Val Loss: 86.00360
Epoch 83, Val Loss: 83.91248
Epoch 84, Val Loss: 75.11858
Epoch 85, Val Loss: 69.41695
Epoch 86, Val Loss: 73.29143
Epoch 87, Val Loss: 67.84510
Epoch 88, Val Loss: 69.33849
Epoch 89, Val Loss: 70.75119
Epoch 90, Val Loss: 73.52844
Epoch 91, Val Loss: 70.96552
Epoch 92, Val Loss: 69.66217
Epoch 93, Val Loss: 70.02124
Epoch 94, Val Loss: 71.58157
Epoch 95, Val Loss: 68.81837
Epoch 96, Val Loss: 71.44221
Epoch 97, Val Loss: 74.53779
Epoch 98, Val Loss: 69.34984
Epoch 99, Val Loss: 68.95399
DID NOT SAVE RESULTS
{'MSE - mean': 80.15538808770881, 'MSE - std': 4.677321636736657, 'R2 - mean': 0.5120514906616591, 'R2 - std': 0.0063999111973120915} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 984.83374
Epoch 1, Val Loss: 452.54965
Epoch 2, Val Loss: 143.90338
Epoch 3, Val Loss: 142.61874
Epoch 4, Val Loss: 139.05794
Epoch 5, Val Loss: 118.71001
Epoch 6, Val Loss: 114.00504
Epoch 7, Val Loss: 106.36667
Epoch 8, Val Loss: 96.22119
Epoch 9, Val Loss: 92.79163
Epoch 10, Val Loss: 131.49124
Epoch 11, Val Loss: 89.91714
Epoch 12, Val Loss: 79.18073
Epoch 13, Val Loss: 90.10368
Epoch 14, Val Loss: 90.62851
Epoch 15, Val Loss: 99.56533
Epoch 16, Val Loss: 99.41965
Epoch 17, Val Loss: 97.99100
Epoch 18, Val Loss: 85.88190
Epoch 19, Val Loss: 87.24194
Epoch 20, Val Loss: 75.96910
Epoch 21, Val Loss: 89.50275
Epoch 22, Val Loss: 89.72134
Epoch 23, Val Loss: 91.82823
Epoch 24, Val Loss: 79.05518
Epoch 25, Val Loss: 73.74271
Epoch 26, Val Loss: 75.40051
Epoch 27, Val Loss: 74.31656
Epoch 28, Val Loss: 85.44267
Epoch 29, Val Loss: 82.11175
Epoch 30, Val Loss: 82.61980
Epoch 31, Val Loss: 82.49992
Epoch 32, Val Loss: 85.60059
Epoch 33, Val Loss: 81.94652
Epoch 34, Val Loss: 81.83015
Epoch 35, Val Loss: 80.16444
Epoch 36, Val Loss: 80.45239
Epoch 37, Val Loss: 84.05270
Epoch 38, Val Loss: 72.73785
Epoch 39, Val Loss: 76.29414
Epoch 40, Val Loss: 74.15827
Epoch 41, Val Loss: 73.70115
Epoch 42, Val Loss: 74.18455
Epoch 43, Val Loss: 74.08363
Epoch 44, Val Loss: 73.36064
Epoch 45, Val Loss: 78.21174
Epoch 46, Val Loss: 71.95783
Epoch 47, Val Loss: 75.19330
Epoch 48, Val Loss: 76.66470
Epoch 49, Val Loss: 70.50525
Epoch 50, Val Loss: 79.58847
Epoch 51, Val Loss: 75.43590
Epoch 52, Val Loss: 70.85175
Epoch 53, Val Loss: 83.03563
Epoch 54, Val Loss: 76.99187
Epoch 55, Val Loss: 81.83398
Epoch 56, Val Loss: 88.43597
Epoch 57, Val Loss: 72.29506
Epoch 58, Val Loss: 70.89011
Epoch 59, Val Loss: 80.76095
Epoch 60, Val Loss: 69.73576
Epoch 61, Val Loss: 76.12613
Epoch 62, Val Loss: 71.87304
Epoch 63, Val Loss: 77.08346
Epoch 64, Val Loss: 76.48204
Epoch 65, Val Loss: 73.03140
Epoch 66, Val Loss: 68.86526
Epoch 67, Val Loss: 73.93476
Epoch 68, Val Loss: 85.10745
Epoch 69, Val Loss: 68.42228
Epoch 70, Val Loss: 82.88982
Epoch 71, Val Loss: 72.34277
Epoch 72, Val Loss: 68.50343
Epoch 73, Val Loss: 88.01672
Epoch 74, Val Loss: 70.83163
Epoch 75, Val Loss: 70.16773
Epoch 76, Val Loss: 91.12189
Epoch 77, Val Loss: 66.82889
Epoch 78, Val Loss: 81.80255
Epoch 79, Val Loss: 68.05885
Epoch 80, Val Loss: 69.49361
Epoch 81, Val Loss: 71.28218
Epoch 82, Val Loss: 69.74655
Epoch 83, Val Loss: 69.39007
Epoch 84, Val Loss: 81.72036
Epoch 85, Val Loss: 70.38084
Epoch 86, Val Loss: 75.56426
Epoch 87, Val Loss: 76.55411
Epoch 88, Val Loss: 69.19588
Epoch 89, Val Loss: 66.91570
Epoch 90, Val Loss: 78.66994
Epoch 91, Val Loss: 71.38620
Epoch 92, Val Loss: 65.61223
Epoch 93, Val Loss: 72.59389
Epoch 94, Val Loss: 72.43107
Epoch 95, Val Loss: 67.63505
Epoch 96, Val Loss: 67.85984
Epoch 97, Val Loss: 70.10551
Epoch 98, Val Loss: 68.66936
Epoch 99, Val Loss: 66.82907
DID NOT SAVE RESULTS
{'MSE - mean': 75.4250619857794, 'MSE - std': 7.703042376674695, 'R2 - mean': 0.5269161311292375, 'R2 - std': 0.021661509212188526} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 452.15634
Epoch 1, Val Loss: 382.38144
Epoch 2, Val Loss: 175.28734
Epoch 3, Val Loss: 162.17467
Epoch 4, Val Loss: 160.31645
Epoch 5, Val Loss: 141.30544
Epoch 6, Val Loss: 119.41817
Epoch 7, Val Loss: 138.79703
Epoch 8, Val Loss: 124.62435
Epoch 9, Val Loss: 117.08002
Epoch 10, Val Loss: 129.56790
Epoch 11, Val Loss: 99.55383
Epoch 12, Val Loss: 106.99629
Epoch 13, Val Loss: 103.63527
Epoch 14, Val Loss: 98.79618
Epoch 15, Val Loss: 110.46914
Epoch 16, Val Loss: 98.00171
Epoch 17, Val Loss: 107.57632
Epoch 18, Val Loss: 103.07253
Epoch 19, Val Loss: 103.84210
Epoch 20, Val Loss: 95.57571
Epoch 21, Val Loss: 95.45997
Epoch 22, Val Loss: 97.37336
Epoch 23, Val Loss: 103.04598
Epoch 24, Val Loss: 95.01381
Epoch 25, Val Loss: 93.33370
Epoch 26, Val Loss: 91.66774
Epoch 27, Val Loss: 97.13615
Epoch 28, Val Loss: 92.12490
Epoch 29, Val Loss: 88.57761
Epoch 30, Val Loss: 93.65017
Epoch 31, Val Loss: 96.32327
Epoch 32, Val Loss: 87.86739
Epoch 33, Val Loss: 90.67519
Epoch 34, Val Loss: 89.27993
Epoch 35, Val Loss: 94.08713
Epoch 36, Val Loss: 95.47782
Epoch 37, Val Loss: 85.44075
Epoch 38, Val Loss: 84.84382
Epoch 39, Val Loss: 83.97060
Epoch 40, Val Loss: 88.51144
Epoch 41, Val Loss: 88.99625
Epoch 42, Val Loss: 91.73566
Epoch 43, Val Loss: 82.02177
Epoch 44, Val Loss: 83.75778
Epoch 45, Val Loss: 82.64585
Epoch 46, Val Loss: 91.58378
Epoch 47, Val Loss: 82.67143
Epoch 48, Val Loss: 87.02159
Epoch 49, Val Loss: 89.88483
Epoch 50, Val Loss: 81.77232
Epoch 51, Val Loss: 88.65527
Epoch 52, Val Loss: 78.82988
Epoch 53, Val Loss: 80.47414
Epoch 54, Val Loss: 81.27850
Epoch 55, Val Loss: 82.75600
Epoch 56, Val Loss: 80.05780
Epoch 57, Val Loss: 79.88251
Epoch 58, Val Loss: 82.20562
Epoch 59, Val Loss: 83.78899
Epoch 60, Val Loss: 84.28856
Epoch 61, Val Loss: 84.41006
Epoch 62, Val Loss: 82.12708
Epoch 63, Val Loss: 81.66306
Epoch 64, Val Loss: 79.53859
Epoch 65, Val Loss: 102.02101
Epoch 66, Val Loss: 107.89890
Epoch 67, Val Loss: 82.74911
Epoch 68, Val Loss: 84.47536
Epoch 69, Val Loss: 85.17543
Epoch 70, Val Loss: 79.37064
Epoch 71, Val Loss: 81.96453
Epoch 72, Val Loss: 80.24059
Epoch 73, Val Loss: 86.35274
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.17607353117188, 'MSE - std': 9.311976655556954, 'R2 - mean': 0.5097087556472161, 'R2 - std': 0.035216431519251294} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 693.40155
Epoch 1, Val Loss: 394.28964
Epoch 2, Val Loss: 161.88116
Epoch 3, Val Loss: 140.34674
Epoch 4, Val Loss: 120.34268
Epoch 5, Val Loss: 127.90919
Epoch 6, Val Loss: 132.76666
Epoch 7, Val Loss: 112.87291
Epoch 8, Val Loss: 117.81207
Epoch 9, Val Loss: 113.89622
Epoch 10, Val Loss: 115.75870
Epoch 11, Val Loss: 131.59595
Epoch 12, Val Loss: 99.39008
Epoch 13, Val Loss: 102.90939
Epoch 14, Val Loss: 124.70209
Epoch 15, Val Loss: 92.49041
Epoch 16, Val Loss: 97.36610
Epoch 17, Val Loss: 92.93678
Epoch 18, Val Loss: 91.19549
Epoch 19, Val Loss: 94.03609
Epoch 20, Val Loss: 94.37902
Epoch 21, Val Loss: 83.73123
Epoch 22, Val Loss: 97.34490
Epoch 23, Val Loss: 95.63288
Epoch 24, Val Loss: 93.75076
Epoch 25, Val Loss: 101.46083
Epoch 26, Val Loss: 92.18396
Epoch 27, Val Loss: 101.68201
Epoch 28, Val Loss: 93.80312
Epoch 29, Val Loss: 85.33813
Epoch 30, Val Loss: 92.33640
Epoch 31, Val Loss: 88.55334
Epoch 32, Val Loss: 85.43677
Epoch 33, Val Loss: 96.32259
Epoch 34, Val Loss: 96.04308
Epoch 35, Val Loss: 93.72540
Epoch 36, Val Loss: 89.74919
Epoch 37, Val Loss: 85.15108
Epoch 38, Val Loss: 90.86061
Epoch 39, Val Loss: 81.79853
Epoch 40, Val Loss: 80.83584
Epoch 41, Val Loss: 85.00597
Epoch 42, Val Loss: 78.18424
Epoch 43, Val Loss: 82.61618
Epoch 44, Val Loss: 82.06795
Epoch 45, Val Loss: 80.07985
Epoch 46, Val Loss: 79.65154
Epoch 47, Val Loss: 80.81845
Epoch 48, Val Loss: 82.83188
Epoch 49, Val Loss: 80.60455
Epoch 50, Val Loss: 75.96903
Epoch 51, Val Loss: 80.37592
Epoch 52, Val Loss: 78.48114
Epoch 53, Val Loss: 75.06306
Epoch 54, Val Loss: 83.84038
Epoch 55, Val Loss: 76.47383
Epoch 56, Val Loss: 76.74457
Epoch 57, Val Loss: 77.84287
Epoch 58, Val Loss: 73.99074
Epoch 59, Val Loss: 76.49971
Epoch 60, Val Loss: 82.52135
Epoch 61, Val Loss: 78.15726
Epoch 62, Val Loss: 80.29443
Epoch 63, Val Loss: 78.15571
Epoch 64, Val Loss: 74.75527
Epoch 65, Val Loss: 77.67012
Epoch 66, Val Loss: 78.19573
Epoch 67, Val Loss: 73.90942
Epoch 68, Val Loss: 79.51709
Epoch 69, Val Loss: 79.60622
Epoch 70, Val Loss: 75.03859
Epoch 71, Val Loss: 79.79962
Epoch 72, Val Loss: 77.20992
Epoch 73, Val Loss: 86.27247
Epoch 74, Val Loss: 77.51099
Epoch 75, Val Loss: 80.41179
Epoch 76, Val Loss: 80.32954
Epoch 77, Val Loss: 83.05026
Epoch 78, Val Loss: 75.39425
Epoch 79, Val Loss: 73.88519
Epoch 80, Val Loss: 89.26794
Epoch 81, Val Loss: 80.37714
Epoch 82, Val Loss: 78.23698
Epoch 83, Val Loss: 75.90530
Epoch 84, Val Loss: 74.38166
Epoch 85, Val Loss: 73.32085
Epoch 86, Val Loss: 80.89003
Epoch 87, Val Loss: 80.31810
Epoch 88, Val Loss: 76.69659
Epoch 89, Val Loss: 80.69482
Epoch 90, Val Loss: 82.48875
Epoch 91, Val Loss: 77.35245
Epoch 92, Val Loss: 77.86941
Epoch 93, Val Loss: 77.29295
Epoch 94, Val Loss: 79.97154
Epoch 95, Val Loss: 75.93591
Epoch 96, Val Loss: 81.05763
Epoch 97, Val Loss: 79.32746
Epoch 98, Val Loss: 79.14812
Epoch 99, Val Loss: 76.03811
DID NOT SAVE RESULTS
{'MSE - mean': 78.16534046608822, 'MSE - std': 8.570685661154755, 'R2 - mean': 0.5147949677011983, 'R2 - std': 0.03310039050211318} 
 

Results After CV: {'MSE - mean': 78.16534046608822, 'MSE - std': 8.570685661154755, 'R2 - mean': 0.5147949677011983, 'R2 - std': 0.03310039050211318}
Train time: 439.9940560730116
Inference time: 0.17930592580232768
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 57 finished with value: 78.16534046608822 and parameters: {'p_m': 0.20105500719309696, 'alpha': 8.246754852238322, 'K': 2, 'beta': 8.044872364502181}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1148.42444
Epoch 1, Val Loss: 429.49356
Epoch 2, Val Loss: 162.69569
Epoch 3, Val Loss: 166.87727
Epoch 4, Val Loss: 148.48650
Epoch 5, Val Loss: 150.23994
Epoch 6, Val Loss: 137.49945
Epoch 7, Val Loss: 136.93793
Epoch 8, Val Loss: 117.15819
Epoch 9, Val Loss: 111.68614
Epoch 10, Val Loss: 119.88951
Epoch 11, Val Loss: 112.87556
Epoch 12, Val Loss: 141.50554
Epoch 13, Val Loss: 112.09137
Epoch 14, Val Loss: 107.63686
Epoch 15, Val Loss: 118.43382
Epoch 16, Val Loss: 105.18764
Epoch 17, Val Loss: 99.56599
Epoch 18, Val Loss: 107.60146
Epoch 19, Val Loss: 102.78728
Epoch 20, Val Loss: 112.36399
Epoch 21, Val Loss: 101.02882
Epoch 22, Val Loss: 104.01579
Epoch 23, Val Loss: 99.96309
Epoch 24, Val Loss: 100.40460
Epoch 25, Val Loss: 96.29288
Epoch 26, Val Loss: 126.83276
Epoch 27, Val Loss: 100.21499
Epoch 28, Val Loss: 99.14470
Epoch 29, Val Loss: 104.95734
Epoch 30, Val Loss: 99.64206
Epoch 31, Val Loss: 101.20892
Epoch 32, Val Loss: 97.85638
Epoch 33, Val Loss: 109.76623
Epoch 34, Val Loss: 98.41843
Epoch 35, Val Loss: 94.29710
Epoch 36, Val Loss: 90.00874
Epoch 37, Val Loss: 91.03832
Epoch 38, Val Loss: 97.24841
Epoch 39, Val Loss: 93.93697
Epoch 40, Val Loss: 88.82140
Epoch 41, Val Loss: 96.83966
Epoch 42, Val Loss: 90.94057
Epoch 43, Val Loss: 93.76768
Epoch 44, Val Loss: 94.80347
Epoch 45, Val Loss: 89.19450
Epoch 46, Val Loss: 86.43890
Epoch 47, Val Loss: 86.59838
Epoch 48, Val Loss: 96.84017
Epoch 49, Val Loss: 88.97418
Epoch 50, Val Loss: 88.90509
Epoch 51, Val Loss: 88.76624
Epoch 52, Val Loss: 93.20501
Epoch 53, Val Loss: 89.23532
Epoch 54, Val Loss: 87.79861
Epoch 55, Val Loss: 85.50824
Epoch 56, Val Loss: 87.09023
Epoch 57, Val Loss: 91.39336
Epoch 58, Val Loss: 92.71700
Epoch 59, Val Loss: 88.18135
Epoch 60, Val Loss: 85.54028
Epoch 61, Val Loss: 86.98888
Epoch 62, Val Loss: 89.60829
Epoch 63, Val Loss: 85.54884
Epoch 64, Val Loss: 97.65627
Epoch 65, Val Loss: 91.38589
Epoch 66, Val Loss: 86.96005
Epoch 67, Val Loss: 87.26294
Epoch 68, Val Loss: 81.27796
Epoch 69, Val Loss: 91.03634
Epoch 70, Val Loss: 89.58994
Epoch 71, Val Loss: 83.46358
Epoch 72, Val Loss: 88.40857
Epoch 73, Val Loss: 86.88953
Epoch 74, Val Loss: 83.07500
Epoch 75, Val Loss: 84.17753
Epoch 76, Val Loss: 87.73996
Epoch 77, Val Loss: 83.26626
Epoch 78, Val Loss: 84.10197
Epoch 79, Val Loss: 86.29160
Epoch 80, Val Loss: 83.05782
Epoch 81, Val Loss: 86.10140
Epoch 82, Val Loss: 84.66769
Epoch 83, Val Loss: 85.93472
Epoch 84, Val Loss: 86.98467
Epoch 85, Val Loss: 87.75735
Epoch 86, Val Loss: 89.48008
Epoch 87, Val Loss: 84.43957
Epoch 88, Val Loss: 90.60608
Epoch 89, Val Loss: 88.09573
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.43817471112672, 'MSE - std': 0.0, 'R2 - mean': 0.5021233335692468, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 388.27567
Epoch 1, Val Loss: 307.58676
Epoch 2, Val Loss: 197.99503
Epoch 3, Val Loss: 140.60843
Epoch 4, Val Loss: 158.20177
Epoch 5, Val Loss: 126.86575
Epoch 6, Val Loss: 126.11720
Epoch 7, Val Loss: 124.86854
Epoch 8, Val Loss: 117.76554
Epoch 9, Val Loss: 122.52091
Epoch 10, Val Loss: 96.20905
Epoch 11, Val Loss: 114.56512
Epoch 12, Val Loss: 95.86861
Epoch 13, Val Loss: 98.83710
Epoch 14, Val Loss: 101.75539
Epoch 15, Val Loss: 98.71639
Epoch 16, Val Loss: 87.14040
Epoch 17, Val Loss: 90.53346
Epoch 18, Val Loss: 93.50397
Epoch 19, Val Loss: 91.75573
Epoch 20, Val Loss: 95.37883
Epoch 21, Val Loss: 93.12032
Epoch 22, Val Loss: 84.41766
Epoch 23, Val Loss: 93.74831
Epoch 24, Val Loss: 95.79820
Epoch 25, Val Loss: 101.52110
Epoch 26, Val Loss: 87.29272
Epoch 27, Val Loss: 86.18762
Epoch 28, Val Loss: 96.22657
Epoch 29, Val Loss: 96.54787
Epoch 30, Val Loss: 83.21228
Epoch 31, Val Loss: 90.83475
Epoch 32, Val Loss: 83.73727
Epoch 33, Val Loss: 90.25444
Epoch 34, Val Loss: 83.03671
Epoch 35, Val Loss: 81.38709
Epoch 36, Val Loss: 78.74336
Epoch 37, Val Loss: 80.59113
Epoch 38, Val Loss: 83.91346
Epoch 39, Val Loss: 77.30945
Epoch 40, Val Loss: 81.39403
Epoch 41, Val Loss: 105.72098
Epoch 42, Val Loss: 75.77634
Epoch 43, Val Loss: 80.18450
Epoch 44, Val Loss: 86.96849
Epoch 45, Val Loss: 87.06525
Epoch 46, Val Loss: 74.21846
Epoch 47, Val Loss: 73.69327
Epoch 48, Val Loss: 75.14262
Epoch 49, Val Loss: 74.08599
Epoch 50, Val Loss: 75.44316
Epoch 51, Val Loss: 76.59557
Epoch 52, Val Loss: 76.08807
Epoch 53, Val Loss: 82.89398
Epoch 54, Val Loss: 77.31781
Epoch 55, Val Loss: 79.01185
Epoch 56, Val Loss: 72.99713
Epoch 57, Val Loss: 78.66406
Epoch 58, Val Loss: 74.18328
Epoch 59, Val Loss: 73.37811
Epoch 60, Val Loss: 76.30839
Epoch 61, Val Loss: 77.51141
Epoch 62, Val Loss: 78.10487
Epoch 63, Val Loss: 77.41967
Epoch 64, Val Loss: 82.12907
Epoch 65, Val Loss: 75.22131
Epoch 66, Val Loss: 80.39906
Epoch 67, Val Loss: 79.03363
Epoch 68, Val Loss: 76.19868
Epoch 69, Val Loss: 82.38735
Epoch 70, Val Loss: 88.69534
Epoch 71, Val Loss: 77.05109
Epoch 72, Val Loss: 76.18793
Epoch 73, Val Loss: 71.73187
Epoch 74, Val Loss: 72.52649
Epoch 75, Val Loss: 85.32528
Epoch 76, Val Loss: 75.60560
Epoch 77, Val Loss: 74.55219
Epoch 78, Val Loss: 75.82938
Epoch 79, Val Loss: 74.52287
Epoch 80, Val Loss: 78.99346
Epoch 81, Val Loss: 80.69261
Epoch 82, Val Loss: 75.63979
Epoch 83, Val Loss: 77.80284
Epoch 84, Val Loss: 71.05419
Epoch 85, Val Loss: 79.47266
Epoch 86, Val Loss: 78.49217
Epoch 87, Val Loss: 76.59978
Epoch 88, Val Loss: 72.93649
Epoch 89, Val Loss: 83.87595
Epoch 90, Val Loss: 72.88242
Epoch 91, Val Loss: 77.03705
Epoch 92, Val Loss: 72.17461
Epoch 93, Val Loss: 79.70001
Epoch 94, Val Loss: 76.01797
Epoch 95, Val Loss: 74.71436
Epoch 96, Val Loss: 75.53322
Epoch 97, Val Loss: 73.14311
Epoch 98, Val Loss: 75.55904
Epoch 99, Val Loss: 71.42316
DID NOT SAVE RESULTS
{'MSE - mean': 82.52071960813757, 'MSE - std': 2.9174551029891447, 'R2 - mean': 0.4971280259778377, 'R2 - std': 0.004995307591409093} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 611.20587
Epoch 1, Val Loss: 383.84128
Epoch 2, Val Loss: 162.74248
Epoch 3, Val Loss: 177.28461
Epoch 4, Val Loss: 134.97272
Epoch 5, Val Loss: 113.07516
Epoch 6, Val Loss: 103.98941
Epoch 7, Val Loss: 102.06824
Epoch 8, Val Loss: 103.82014
Epoch 9, Val Loss: 99.60020
Epoch 10, Val Loss: 95.84189
Epoch 11, Val Loss: 102.98396
Epoch 12, Val Loss: 93.41827
Epoch 13, Val Loss: 104.36208
Epoch 14, Val Loss: 96.97649
Epoch 15, Val Loss: 86.24403
Epoch 16, Val Loss: 99.72005
Epoch 17, Val Loss: 99.80579
Epoch 18, Val Loss: 99.00552
Epoch 19, Val Loss: 86.46857
Epoch 20, Val Loss: 84.63707
Epoch 21, Val Loss: 84.61424
Epoch 22, Val Loss: 88.26281
Epoch 23, Val Loss: 84.89788
Epoch 24, Val Loss: 91.55369
Epoch 25, Val Loss: 104.69202
Epoch 26, Val Loss: 98.17365
Epoch 27, Val Loss: 78.93954
Epoch 28, Val Loss: 83.49899
Epoch 29, Val Loss: 80.62505
Epoch 30, Val Loss: 82.21085
Epoch 31, Val Loss: 89.15594
Epoch 32, Val Loss: 84.54317
Epoch 33, Val Loss: 76.80699
Epoch 34, Val Loss: 81.07018
Epoch 35, Val Loss: 77.61092
Epoch 36, Val Loss: 80.07767
Epoch 37, Val Loss: 81.14517
Epoch 38, Val Loss: 80.62460
Epoch 39, Val Loss: 73.75403
Epoch 40, Val Loss: 81.70529
Epoch 41, Val Loss: 80.35767
Epoch 42, Val Loss: 74.74336
Epoch 43, Val Loss: 75.39214
Epoch 44, Val Loss: 73.57260
Epoch 45, Val Loss: 72.50325
Epoch 46, Val Loss: 74.07390
Epoch 47, Val Loss: 71.22154
Epoch 48, Val Loss: 73.88537
Epoch 49, Val Loss: 77.93195
Epoch 50, Val Loss: 74.29071
Epoch 51, Val Loss: 74.32713
Epoch 52, Val Loss: 73.21201
Epoch 53, Val Loss: 73.41493
Epoch 54, Val Loss: 73.99738
Epoch 55, Val Loss: 77.48915
Epoch 56, Val Loss: 70.69088
Epoch 57, Val Loss: 74.89582
Epoch 58, Val Loss: 71.86853
Epoch 59, Val Loss: 73.31218
Epoch 60, Val Loss: 70.36532
Epoch 61, Val Loss: 75.37843
Epoch 62, Val Loss: 71.61949
Epoch 63, Val Loss: 74.55495
Epoch 64, Val Loss: 73.55370
Epoch 65, Val Loss: 74.76520
Epoch 66, Val Loss: 71.64341
Epoch 67, Val Loss: 75.10368
Epoch 68, Val Loss: 70.56203
Epoch 69, Val Loss: 70.97705
Epoch 70, Val Loss: 75.09814
Epoch 71, Val Loss: 78.37587
Epoch 72, Val Loss: 70.74422
Epoch 73, Val Loss: 74.23092
Epoch 74, Val Loss: 74.54955
Epoch 75, Val Loss: 71.38744
Epoch 76, Val Loss: 73.21957
Epoch 77, Val Loss: 75.69699
Epoch 78, Val Loss: 71.23425
Epoch 79, Val Loss: 83.11999
Epoch 80, Val Loss: 71.00718
Epoch 81, Val Loss: 70.17623
Epoch 82, Val Loss: 72.76402
Epoch 83, Val Loss: 73.04562
Epoch 84, Val Loss: 72.05422
Epoch 85, Val Loss: 73.99836
Epoch 86, Val Loss: 73.58645
Epoch 87, Val Loss: 75.71193
Epoch 88, Val Loss: 77.55166
Epoch 89, Val Loss: 76.42521
Epoch 90, Val Loss: 76.29565
Epoch 91, Val Loss: 75.97369
Epoch 92, Val Loss: 70.13040
Epoch 93, Val Loss: 75.99626
Epoch 94, Val Loss: 76.66963
Epoch 95, Val Loss: 83.87291
Epoch 96, Val Loss: 70.41845
Epoch 97, Val Loss: 73.41679
Epoch 98, Val Loss: 74.76779
Epoch 99, Val Loss: 70.19124
DID NOT SAVE RESULTS
{'MSE - mean': 78.51602197186965, 'MSE - std': 6.144067802997557, 'R2 - mean': 0.5067908959080033, 'R2 - std': 0.01426104867099388} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 658.66046
Epoch 1, Val Loss: 391.06094
Epoch 2, Val Loss: 162.94254
Epoch 3, Val Loss: 170.51974
Epoch 4, Val Loss: 127.20450
Epoch 5, Val Loss: 128.78581
Epoch 6, Val Loss: 117.31827
Epoch 7, Val Loss: 129.08974
Epoch 8, Val Loss: 123.05631
Epoch 9, Val Loss: 106.87054
Epoch 10, Val Loss: 121.71391
Epoch 11, Val Loss: 105.62660
Epoch 12, Val Loss: 100.08425
Epoch 13, Val Loss: 101.34209
Epoch 14, Val Loss: 107.01531
Epoch 15, Val Loss: 106.64006
Epoch 16, Val Loss: 95.61813
Epoch 17, Val Loss: 93.95361
Epoch 18, Val Loss: 99.63682
Epoch 19, Val Loss: 98.13937
Epoch 20, Val Loss: 95.82393
Epoch 21, Val Loss: 106.14944
Epoch 22, Val Loss: 98.86993
Epoch 23, Val Loss: 88.53977
Epoch 24, Val Loss: 98.03734
Epoch 25, Val Loss: 111.30337
Epoch 26, Val Loss: 89.95159
Epoch 27, Val Loss: 90.48611
Epoch 28, Val Loss: 90.04813
Epoch 29, Val Loss: 87.28888
Epoch 30, Val Loss: 93.04533
Epoch 31, Val Loss: 83.40335
Epoch 32, Val Loss: 92.70449
Epoch 33, Val Loss: 86.56693
Epoch 34, Val Loss: 84.65204
Epoch 35, Val Loss: 88.46738
Epoch 36, Val Loss: 104.17603
Epoch 37, Val Loss: 86.46251
Epoch 38, Val Loss: 96.17273
Epoch 39, Val Loss: 87.30624
Epoch 40, Val Loss: 80.32079
Epoch 41, Val Loss: 80.79298
Epoch 42, Val Loss: 83.30336
Epoch 43, Val Loss: 81.85461
Epoch 44, Val Loss: 84.56675
Epoch 45, Val Loss: 85.94141
Epoch 46, Val Loss: 88.58551
Epoch 47, Val Loss: 82.07912
Epoch 48, Val Loss: 80.85563
Epoch 49, Val Loss: 98.57684
Epoch 50, Val Loss: 80.79765
Epoch 51, Val Loss: 82.20113
Epoch 52, Val Loss: 79.87805
Epoch 53, Val Loss: 83.03812
Epoch 54, Val Loss: 81.94908
Epoch 55, Val Loss: 83.38728
Epoch 56, Val Loss: 88.88226
Epoch 57, Val Loss: 87.59613
Epoch 58, Val Loss: 87.47773
Epoch 59, Val Loss: 83.64414
Epoch 60, Val Loss: 80.62463
Epoch 61, Val Loss: 85.82288
Epoch 62, Val Loss: 82.39481
Epoch 63, Val Loss: 93.03280
Epoch 64, Val Loss: 85.29704
Epoch 65, Val Loss: 82.26015
Epoch 66, Val Loss: 82.41480
Epoch 67, Val Loss: 92.57526
Epoch 68, Val Loss: 102.26526
Epoch 69, Val Loss: 82.61849
Epoch 70, Val Loss: 87.97118
Epoch 71, Val Loss: 89.94692
Epoch 72, Val Loss: 85.88985
Epoch 73, Val Loss: 79.39166
Epoch 74, Val Loss: 81.40330
Epoch 75, Val Loss: 83.86325
Epoch 76, Val Loss: 83.52261
Epoch 77, Val Loss: 81.88626
Epoch 78, Val Loss: 81.82990
Epoch 79, Val Loss: 87.85577
Epoch 80, Val Loss: 87.78713
Epoch 81, Val Loss: 89.94977
Epoch 82, Val Loss: 81.76987
Epoch 83, Val Loss: 78.63687
Epoch 84, Val Loss: 91.67748
Epoch 85, Val Loss: 80.00433
Epoch 86, Val Loss: 82.91431
Epoch 87, Val Loss: 84.77870
Epoch 88, Val Loss: 81.81598
Epoch 89, Val Loss: 83.86652
Epoch 90, Val Loss: 106.38024
Epoch 91, Val Loss: 86.50612
Epoch 92, Val Loss: 82.21997
Epoch 93, Val Loss: 87.07854
Epoch 94, Val Loss: 81.98558
Epoch 95, Val Loss: 85.09795
Epoch 96, Val Loss: 90.30440
Epoch 97, Val Loss: 84.76940
Epoch 98, Val Loss: 88.81504
Epoch 99, Val Loss: 83.85838
DID NOT SAVE RESULTS
{'MSE - mean': 81.1891542723236, 'MSE - std': 7.053303180997113, 'R2 - mean': 0.4964434333392299, 'R2 - std': 0.021765639819078086} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 517.85889
Epoch 1, Val Loss: 381.97461
Epoch 2, Val Loss: 181.81207
Epoch 3, Val Loss: 148.50159
Epoch 4, Val Loss: 172.55798
Epoch 5, Val Loss: 135.13449
Epoch 6, Val Loss: 118.89751
Epoch 7, Val Loss: 150.63010
Epoch 8, Val Loss: 111.92583
Epoch 9, Val Loss: 129.51662
Epoch 10, Val Loss: 101.94440
Epoch 11, Val Loss: 115.70709
Epoch 12, Val Loss: 119.28400
Epoch 13, Val Loss: 110.70485
Epoch 14, Val Loss: 114.37057
Epoch 15, Val Loss: 106.98021
Epoch 16, Val Loss: 101.93587
Epoch 17, Val Loss: 117.54414
Epoch 18, Val Loss: 121.22689
Epoch 19, Val Loss: 100.15827
Epoch 20, Val Loss: 109.15885
Epoch 21, Val Loss: 109.44505
Epoch 22, Val Loss: 103.23514
Epoch 23, Val Loss: 103.15886
Epoch 24, Val Loss: 99.47433
Epoch 25, Val Loss: 118.44312
Epoch 26, Val Loss: 94.28987
Epoch 27, Val Loss: 97.98421
Epoch 28, Val Loss: 91.71316
Epoch 29, Val Loss: 94.42616
Epoch 30, Val Loss: 92.81544
Epoch 31, Val Loss: 87.42998
Epoch 32, Val Loss: 104.49219
Epoch 33, Val Loss: 93.93129
Epoch 34, Val Loss: 89.28787
Epoch 35, Val Loss: 84.40605
Epoch 36, Val Loss: 88.95537
Epoch 37, Val Loss: 85.01485
Epoch 38, Val Loss: 84.91103
Epoch 39, Val Loss: 95.81696
Epoch 40, Val Loss: 82.90768
Epoch 41, Val Loss: 87.96369
Epoch 42, Val Loss: 84.52306
Epoch 43, Val Loss: 83.07283
Epoch 44, Val Loss: 84.39828
Epoch 45, Val Loss: 82.33546
Epoch 46, Val Loss: 79.73619
Epoch 47, Val Loss: 79.48380
Epoch 48, Val Loss: 86.91536
Epoch 49, Val Loss: 80.18935
Epoch 50, Val Loss: 83.66266
Epoch 51, Val Loss: 85.04433
Epoch 52, Val Loss: 79.08403
Epoch 53, Val Loss: 90.75970
Epoch 54, Val Loss: 84.34425
Epoch 55, Val Loss: 82.13149
Epoch 56, Val Loss: 78.05682
Epoch 57, Val Loss: 81.32843
Epoch 58, Val Loss: 79.31339
Epoch 59, Val Loss: 81.62590
Epoch 60, Val Loss: 79.49226
Epoch 61, Val Loss: 75.76459
Epoch 62, Val Loss: 76.80060
Epoch 63, Val Loss: 80.90280
Epoch 64, Val Loss: 76.15756
Epoch 65, Val Loss: 77.10886
Epoch 66, Val Loss: 81.31596
Epoch 67, Val Loss: 79.42419
Epoch 68, Val Loss: 75.84150
Epoch 69, Val Loss: 79.93520
Epoch 70, Val Loss: 80.27608
Epoch 71, Val Loss: 79.76796
Epoch 72, Val Loss: 78.40877
Epoch 73, Val Loss: 79.24316
Epoch 74, Val Loss: 84.72763
Epoch 75, Val Loss: 77.69073
Epoch 76, Val Loss: 75.41321
Epoch 77, Val Loss: 75.52708
Epoch 78, Val Loss: 79.86263
Epoch 79, Val Loss: 81.58821
Epoch 80, Val Loss: 81.77440
Epoch 81, Val Loss: 96.36433
Epoch 82, Val Loss: 80.57819
Epoch 83, Val Loss: 76.33871
Epoch 84, Val Loss: 83.51117
Epoch 85, Val Loss: 76.17284
Epoch 86, Val Loss: 80.05678
Epoch 87, Val Loss: 81.32691
Epoch 88, Val Loss: 75.44298
Epoch 89, Val Loss: 80.94697
Epoch 90, Val Loss: 79.17587
Epoch 91, Val Loss: 84.85394
Epoch 92, Val Loss: 77.94415
Epoch 93, Val Loss: 78.09364
Epoch 94, Val Loss: 76.23549
Epoch 95, Val Loss: 81.84785
Epoch 96, Val Loss: 82.17841
Epoch 97, Val Loss: 85.93646
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.68126558616505, 'MSE - std': 6.3899195832625795, 'R2 - mean': 0.4985040958226685, 'R2 - std': 0.019899240710883295} 
 

Results After CV: {'MSE - mean': 80.68126558616505, 'MSE - std': 6.3899195832625795, 'R2 - mean': 0.4985040958226685, 'R2 - std': 0.019899240710883295}
Train time: 463.21990330700646
Inference time: 0.17359589760308153
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 58 finished with value: 80.68126558616505 and parameters: {'p_m': 0.2756639481168725, 'alpha': 9.121241677109818, 'K': 2, 'beta': 6.711423351381157}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 551.62170
Epoch 1, Val Loss: 392.80087
Epoch 2, Val Loss: 172.20988
Epoch 3, Val Loss: 159.28412
Epoch 4, Val Loss: 150.83075
Epoch 5, Val Loss: 137.21936
Epoch 6, Val Loss: 137.18185
Epoch 7, Val Loss: 120.89842
Epoch 8, Val Loss: 111.38490
Epoch 9, Val Loss: 108.51992
Epoch 10, Val Loss: 111.32506
Epoch 11, Val Loss: 117.93016
Epoch 12, Val Loss: 108.51591
Epoch 13, Val Loss: 108.40878
Epoch 14, Val Loss: 115.72322
Epoch 15, Val Loss: 103.39223
Epoch 16, Val Loss: 106.19125
Epoch 17, Val Loss: 99.18588
Epoch 18, Val Loss: 102.90699
Epoch 19, Val Loss: 109.54505
Epoch 20, Val Loss: 111.56609
Epoch 21, Val Loss: 128.89233
Epoch 22, Val Loss: 101.08225
Epoch 23, Val Loss: 100.63917
Epoch 24, Val Loss: 101.52072
Epoch 25, Val Loss: 103.89598
Epoch 26, Val Loss: 122.67999
Epoch 27, Val Loss: 107.72192
Epoch 28, Val Loss: 100.01678
Epoch 29, Val Loss: 93.23505
Epoch 30, Val Loss: 114.91930
Epoch 31, Val Loss: 105.11625
Epoch 32, Val Loss: 111.78442
Epoch 33, Val Loss: 95.59256
Epoch 34, Val Loss: 97.28827
Epoch 35, Val Loss: 94.53613
Epoch 36, Val Loss: 98.17762
Epoch 37, Val Loss: 98.28326
Epoch 38, Val Loss: 102.29167
Epoch 39, Val Loss: 93.85812
Epoch 40, Val Loss: 94.16969
Epoch 41, Val Loss: 93.69009
Epoch 42, Val Loss: 99.06634
Epoch 43, Val Loss: 98.94836
Epoch 44, Val Loss: 94.34851
Epoch 45, Val Loss: 91.14960
Epoch 46, Val Loss: 96.47916
Epoch 47, Val Loss: 90.45060
Epoch 48, Val Loss: 94.78202
Epoch 49, Val Loss: 100.43145
Epoch 50, Val Loss: 97.86534
Epoch 51, Val Loss: 88.21445
Epoch 52, Val Loss: 87.72609
Epoch 53, Val Loss: 91.49992
Epoch 54, Val Loss: 88.66491
Epoch 55, Val Loss: 88.66719
Epoch 56, Val Loss: 85.99796
Epoch 57, Val Loss: 84.00243
Epoch 58, Val Loss: 89.74309
Epoch 59, Val Loss: 85.80577
Epoch 60, Val Loss: 87.07449
Epoch 61, Val Loss: 84.13968
Epoch 62, Val Loss: 86.16667
Epoch 63, Val Loss: 91.26897
Epoch 64, Val Loss: 87.94083
Epoch 65, Val Loss: 116.88756
Epoch 66, Val Loss: 87.47070
Epoch 67, Val Loss: 86.55927
Epoch 68, Val Loss: 83.39122
Epoch 69, Val Loss: 85.72401
Epoch 70, Val Loss: 82.81210
Epoch 71, Val Loss: 85.49303
Epoch 72, Val Loss: 89.13294
Epoch 73, Val Loss: 88.36843
Epoch 74, Val Loss: 87.82040
Epoch 75, Val Loss: 85.68748
Epoch 76, Val Loss: 89.05129
Epoch 77, Val Loss: 86.31566
Epoch 78, Val Loss: 80.10340
Epoch 79, Val Loss: 84.37265
Epoch 80, Val Loss: 99.26788
Epoch 81, Val Loss: 95.39388
Epoch 82, Val Loss: 90.67625
Epoch 83, Val Loss: 85.72412
Epoch 84, Val Loss: 85.12514
Epoch 85, Val Loss: 86.18100
Epoch 86, Val Loss: 84.27704
Epoch 87, Val Loss: 87.83393
Epoch 88, Val Loss: 89.82847
Epoch 89, Val Loss: 87.11774
Epoch 90, Val Loss: 81.68555
Epoch 91, Val Loss: 84.30849
Epoch 92, Val Loss: 80.54932
Epoch 93, Val Loss: 85.88133
Epoch 94, Val Loss: 84.94321
Epoch 95, Val Loss: 83.27530
Epoch 96, Val Loss: 89.43234
Epoch 97, Val Loss: 83.33730
Epoch 98, Val Loss: 85.19701
Epoch 99, Val Loss: 84.16512
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.44733616015132, 'MSE - std': 0.0, 'R2 - mean': 0.5020699467580764, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 638.21753
Epoch 1, Val Loss: 393.81076
Epoch 2, Val Loss: 182.92374
Epoch 3, Val Loss: 145.11795
Epoch 4, Val Loss: 146.07361
Epoch 5, Val Loss: 141.14032
Epoch 6, Val Loss: 111.18100
Epoch 7, Val Loss: 120.85078
Epoch 8, Val Loss: 107.18929
Epoch 9, Val Loss: 94.88332
Epoch 10, Val Loss: 97.28400
Epoch 11, Val Loss: 100.20053
Epoch 12, Val Loss: 90.82388
Epoch 13, Val Loss: 100.33020
Epoch 14, Val Loss: 99.95514
Epoch 15, Val Loss: 106.30960
Epoch 16, Val Loss: 103.75954
Epoch 17, Val Loss: 97.12896
Epoch 18, Val Loss: 89.58131
Epoch 19, Val Loss: 86.51838
Epoch 20, Val Loss: 93.96375
Epoch 21, Val Loss: 98.31857
Epoch 22, Val Loss: 91.82263
Epoch 23, Val Loss: 90.38135
Epoch 24, Val Loss: 80.69920
Epoch 25, Val Loss: 88.74530
Epoch 26, Val Loss: 96.77176
Epoch 27, Val Loss: 81.19096
Epoch 28, Val Loss: 82.62194
Epoch 29, Val Loss: 83.75411
Epoch 30, Val Loss: 81.07476
Epoch 31, Val Loss: 85.68417
Epoch 32, Val Loss: 80.03814
Epoch 33, Val Loss: 80.36611
Epoch 34, Val Loss: 75.50175
Epoch 35, Val Loss: 73.66776
Epoch 36, Val Loss: 90.50256
Epoch 37, Val Loss: 85.55507
Epoch 38, Val Loss: 83.86877
Epoch 39, Val Loss: 79.13636
Epoch 40, Val Loss: 74.53250
Epoch 41, Val Loss: 76.27514
Epoch 42, Val Loss: 76.49508
Epoch 43, Val Loss: 76.66730
Epoch 44, Val Loss: 77.91033
Epoch 45, Val Loss: 75.79688
Epoch 46, Val Loss: 75.44279
Epoch 47, Val Loss: 75.98821
Epoch 48, Val Loss: 73.02888
Epoch 49, Val Loss: 72.86496
Epoch 50, Val Loss: 80.40379
Epoch 51, Val Loss: 74.69972
Epoch 52, Val Loss: 85.83710
Epoch 53, Val Loss: 72.68686
Epoch 54, Val Loss: 74.20561
Epoch 55, Val Loss: 75.87514
Epoch 56, Val Loss: 74.50421
Epoch 57, Val Loss: 77.42784
Epoch 58, Val Loss: 76.68841
Epoch 59, Val Loss: 79.33152
Epoch 60, Val Loss: 79.88718
Epoch 61, Val Loss: 72.56532
Epoch 62, Val Loss: 74.43517
Epoch 63, Val Loss: 75.77657
Epoch 64, Val Loss: 75.12509
Epoch 65, Val Loss: 76.25037
Epoch 66, Val Loss: 75.61209
Epoch 67, Val Loss: 77.89448
Epoch 68, Val Loss: 72.34987
Epoch 69, Val Loss: 77.81265
Epoch 70, Val Loss: 72.26442
Epoch 71, Val Loss: 71.54472
Epoch 72, Val Loss: 86.31031
Epoch 73, Val Loss: 71.47764
Epoch 74, Val Loss: 72.27685
Epoch 75, Val Loss: 74.94522
Epoch 76, Val Loss: 77.33939
Epoch 77, Val Loss: 73.94730
Epoch 78, Val Loss: 76.86148
Epoch 79, Val Loss: 71.03703
Epoch 80, Val Loss: 72.75441
Epoch 81, Val Loss: 78.29118
Epoch 82, Val Loss: 77.07762
Epoch 83, Val Loss: 76.81529
Epoch 84, Val Loss: 74.59962
Epoch 85, Val Loss: 79.57685
Epoch 86, Val Loss: 73.19978
Epoch 87, Val Loss: 77.30047
Epoch 88, Val Loss: 77.93866
Epoch 89, Val Loss: 76.28453
Epoch 90, Val Loss: 81.84756
Epoch 91, Val Loss: 74.68342
Epoch 92, Val Loss: 75.28181
Epoch 93, Val Loss: 74.14792
Epoch 94, Val Loss: 74.99265
Epoch 95, Val Loss: 71.98095
Epoch 96, Val Loss: 73.44328
Epoch 97, Val Loss: 78.38139
Epoch 98, Val Loss: 74.61935
Epoch 99, Val Loss: 84.30842
DID NOT SAVE RESULTS
{'MSE - mean': 81.85220880650621, 'MSE - std': 3.595127353645104, 'R2 - mean': 0.5013956434373251, 'R2 - std': 0.0006743033207512461} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1692.68872
Epoch 1, Val Loss: 429.78424
Epoch 2, Val Loss: 151.52077
Epoch 3, Val Loss: 123.33235
Epoch 4, Val Loss: 111.75560
Epoch 5, Val Loss: 103.65437
Epoch 6, Val Loss: 96.37746
Epoch 7, Val Loss: 94.45721
Epoch 8, Val Loss: 89.49992
Epoch 9, Val Loss: 86.81467
Epoch 10, Val Loss: 95.01034
Epoch 11, Val Loss: 83.66191
Epoch 12, Val Loss: 78.00450
Epoch 13, Val Loss: 91.01880
Epoch 14, Val Loss: 93.67027
Epoch 15, Val Loss: 95.05747
Epoch 16, Val Loss: 79.48586
Epoch 17, Val Loss: 81.07326
Epoch 18, Val Loss: 99.90898
Epoch 19, Val Loss: 83.36819
Epoch 20, Val Loss: 87.44556
Epoch 21, Val Loss: 85.84624
Epoch 22, Val Loss: 88.40839
Epoch 23, Val Loss: 80.26257
Epoch 24, Val Loss: 82.36134
Epoch 25, Val Loss: 88.71562
Epoch 26, Val Loss: 91.13864
Epoch 27, Val Loss: 80.35344
Epoch 28, Val Loss: 88.71943
Epoch 29, Val Loss: 82.90076
Epoch 30, Val Loss: 80.05644
Epoch 31, Val Loss: 79.48228
Epoch 32, Val Loss: 105.40797
Epoch 33, Val Loss: 78.56198
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.74212645170918, 'MSE - std': 2.9395345508476027, 'R2 - mean': 0.4849575183368304, 'R2 - std': 0.02325353815984318} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1081.71558
Epoch 1, Val Loss: 478.95737
Epoch 2, Val Loss: 183.89751
Epoch 3, Val Loss: 170.67445
Epoch 4, Val Loss: 164.45013
Epoch 5, Val Loss: 148.77483
Epoch 6, Val Loss: 130.52225
Epoch 7, Val Loss: 129.25256
Epoch 8, Val Loss: 116.35814
Epoch 9, Val Loss: 112.46515
Epoch 10, Val Loss: 109.37462
Epoch 11, Val Loss: 121.27341
Epoch 12, Val Loss: 119.73158
Epoch 13, Val Loss: 101.77884
Epoch 14, Val Loss: 111.10628
Epoch 15, Val Loss: 94.45963
Epoch 16, Val Loss: 112.98886
Epoch 17, Val Loss: 95.67254
Epoch 18, Val Loss: 121.11827
Epoch 19, Val Loss: 95.77820
Epoch 20, Val Loss: 99.63790
Epoch 21, Val Loss: 91.31295
Epoch 22, Val Loss: 87.08132
Epoch 23, Val Loss: 91.07039
Epoch 24, Val Loss: 112.00244
Epoch 25, Val Loss: 93.55231
Epoch 26, Val Loss: 92.05320
Epoch 27, Val Loss: 95.03462
Epoch 28, Val Loss: 100.21380
Epoch 29, Val Loss: 92.85995
Epoch 30, Val Loss: 139.15121
Epoch 31, Val Loss: 93.79881
Epoch 32, Val Loss: 87.93749
Epoch 33, Val Loss: 88.26318
Epoch 34, Val Loss: 88.50632
Epoch 35, Val Loss: 87.94643
Epoch 36, Val Loss: 92.64132
Epoch 37, Val Loss: 88.03564
Epoch 38, Val Loss: 86.84264
Epoch 39, Val Loss: 93.92212
Epoch 40, Val Loss: 83.71784
Epoch 41, Val Loss: 89.04120
Epoch 42, Val Loss: 89.37317
Epoch 43, Val Loss: 87.58052
Epoch 44, Val Loss: 82.38933
Epoch 45, Val Loss: 109.33646
Epoch 46, Val Loss: 84.53100
Epoch 47, Val Loss: 88.08635
Epoch 48, Val Loss: 85.77025
Epoch 49, Val Loss: 84.30850
Epoch 50, Val Loss: 79.79952
Epoch 51, Val Loss: 78.46004
Epoch 52, Val Loss: 82.41144
Epoch 53, Val Loss: 82.47939
Epoch 54, Val Loss: 79.75346
Epoch 55, Val Loss: 82.50183
Epoch 56, Val Loss: 80.11143
Epoch 57, Val Loss: 85.06253
Epoch 58, Val Loss: 79.71867
Epoch 59, Val Loss: 80.15837
Epoch 60, Val Loss: 81.60793
Epoch 61, Val Loss: 81.96305
Epoch 62, Val Loss: 79.95076
Epoch 63, Val Loss: 80.85635
Epoch 64, Val Loss: 85.67430
Epoch 65, Val Loss: 81.29337
Epoch 66, Val Loss: 81.10084
Epoch 67, Val Loss: 85.01886
Epoch 68, Val Loss: 81.40602
Epoch 69, Val Loss: 85.09500
Epoch 70, Val Loss: 79.64605
Epoch 71, Val Loss: 80.80216
Epoch 72, Val Loss: 78.10495
Epoch 73, Val Loss: 80.45917
Epoch 74, Val Loss: 80.69823
Epoch 75, Val Loss: 92.00060
Epoch 76, Val Loss: 86.22749
Epoch 77, Val Loss: 78.81190
Epoch 78, Val Loss: 80.92641
Epoch 79, Val Loss: 83.45227
Epoch 80, Val Loss: 84.64391
Epoch 81, Val Loss: 86.31215
Epoch 82, Val Loss: 85.00621
Epoch 83, Val Loss: 77.24622
Epoch 84, Val Loss: 77.28533
Epoch 85, Val Loss: 78.32812
Epoch 86, Val Loss: 79.74990
Epoch 87, Val Loss: 80.65626
Epoch 88, Val Loss: 82.95531
Epoch 89, Val Loss: 77.95329
Epoch 90, Val Loss: 81.70778
Epoch 91, Val Loss: 79.31855
Epoch 92, Val Loss: 79.78515
Epoch 93, Val Loss: 86.23064
Epoch 94, Val Loss: 77.63033
Epoch 95, Val Loss: 83.13120
Epoch 96, Val Loss: 79.71051
Epoch 97, Val Loss: 83.69292
Epoch 98, Val Loss: 78.02400
Epoch 99, Val Loss: 94.01797
DID NOT SAVE RESULTS
{'MSE - mean': 83.25480439651852, 'MSE - std': 3.6531125394460475, 'R2 - mean': 0.4821893814146502, 'R2 - std': 0.02070103919549145} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 726.01001
Epoch 1, Val Loss: 440.13272
Epoch 2, Val Loss: 184.90649
Epoch 3, Val Loss: 142.25610
Epoch 4, Val Loss: 123.64378
Epoch 5, Val Loss: 114.25710
Epoch 6, Val Loss: 115.21039
Epoch 7, Val Loss: 126.12727
Epoch 8, Val Loss: 103.43393
Epoch 9, Val Loss: 100.13702
Epoch 10, Val Loss: 111.48241
Epoch 11, Val Loss: 102.03679
Epoch 12, Val Loss: 105.41313
Epoch 13, Val Loss: 99.32590
Epoch 14, Val Loss: 101.25457
Epoch 15, Val Loss: 109.53442
Epoch 16, Val Loss: 96.39336
Epoch 17, Val Loss: 93.73960
Epoch 18, Val Loss: 89.56882
Epoch 19, Val Loss: 93.98518
Epoch 20, Val Loss: 106.51514
Epoch 21, Val Loss: 99.71289
Epoch 22, Val Loss: 93.90779
Epoch 23, Val Loss: 86.81927
Epoch 24, Val Loss: 92.89790
Epoch 25, Val Loss: 97.89651
Epoch 26, Val Loss: 93.79375
Epoch 27, Val Loss: 94.36919
Epoch 28, Val Loss: 95.23770
Epoch 29, Val Loss: 93.51173
Epoch 30, Val Loss: 88.61674
Epoch 31, Val Loss: 88.61633
Epoch 32, Val Loss: 91.41837
Epoch 33, Val Loss: 92.79625
Epoch 34, Val Loss: 93.36089
Epoch 35, Val Loss: 92.21323
Epoch 36, Val Loss: 108.45956
Epoch 37, Val Loss: 110.99751
Epoch 38, Val Loss: 92.77989
Epoch 39, Val Loss: 91.94789
Epoch 40, Val Loss: 104.41582
Epoch 41, Val Loss: 85.18067
Epoch 42, Val Loss: 85.85449
Epoch 43, Val Loss: 83.66066
Epoch 44, Val Loss: 82.95782
Epoch 45, Val Loss: 88.07940
Epoch 46, Val Loss: 79.93079
Epoch 47, Val Loss: 85.42262
Epoch 48, Val Loss: 83.77090
Epoch 49, Val Loss: 90.71541
Epoch 50, Val Loss: 82.82967
Epoch 51, Val Loss: 81.29593
Epoch 52, Val Loss: 84.27575
Epoch 53, Val Loss: 87.76952
Epoch 54, Val Loss: 82.66573
Epoch 55, Val Loss: 78.80247
Epoch 56, Val Loss: 84.73811
Epoch 57, Val Loss: 87.18815
Epoch 58, Val Loss: 87.40055
Epoch 59, Val Loss: 80.67154
Epoch 60, Val Loss: 86.77361
Epoch 61, Val Loss: 84.18874
Epoch 62, Val Loss: 78.02130
Epoch 63, Val Loss: 79.85973
Epoch 64, Val Loss: 78.64764
Epoch 65, Val Loss: 80.06194
Epoch 66, Val Loss: 77.76796
Epoch 67, Val Loss: 79.09673
Epoch 68, Val Loss: 83.93907
Epoch 69, Val Loss: 76.05878
Epoch 70, Val Loss: 81.25522
Epoch 71, Val Loss: 80.50065
Epoch 72, Val Loss: 84.03454
Epoch 73, Val Loss: 79.65994
Epoch 74, Val Loss: 81.92972
Epoch 75, Val Loss: 77.02222
Epoch 76, Val Loss: 84.72430
Epoch 77, Val Loss: 85.20580
Epoch 78, Val Loss: 81.49786
Epoch 79, Val Loss: 76.52789
Epoch 80, Val Loss: 81.22886
Epoch 81, Val Loss: 87.88813
Epoch 82, Val Loss: 81.73006
Epoch 83, Val Loss: 86.15553
Epoch 84, Val Loss: 76.75785
Epoch 85, Val Loss: 83.05420
Epoch 86, Val Loss: 78.25337
Epoch 87, Val Loss: 80.35310
Epoch 88, Val Loss: 79.04772
Epoch 89, Val Loss: 79.37056
Epoch 90, Val Loss: 78.05817
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.90002040409072, 'MSE - std': 4.244754839238748, 'R2 - mean': 0.4898212220294857, 'R2 - std': 0.023995965988049577} 
 

Results After CV: {'MSE - mean': 81.90002040409072, 'MSE - std': 4.244754839238748, 'R2 - mean': 0.4898212220294857, 'R2 - std': 0.023995965988049577}
Train time: 397.69847000259904
Inference time: 0.18723764699534512
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 59 finished with value: 81.90002040409072 and parameters: {'p_m': 0.2248989197947005, 'alpha': 9.960350834925167, 'K': 2, 'beta': 5.558681743165105}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1221.68591
Epoch 1, Val Loss: 393.33435
Epoch 2, Val Loss: 173.12500
Epoch 3, Val Loss: 169.59612
Epoch 4, Val Loss: 165.04544
Epoch 5, Val Loss: 133.55841
Epoch 6, Val Loss: 126.05208
Epoch 7, Val Loss: 133.90424
Epoch 8, Val Loss: 134.30939
Epoch 9, Val Loss: 127.21266
Epoch 10, Val Loss: 116.96991
Epoch 11, Val Loss: 109.63937
Epoch 12, Val Loss: 124.32355
Epoch 13, Val Loss: 143.94980
Epoch 14, Val Loss: 115.14233
Epoch 15, Val Loss: 106.07706
Epoch 16, Val Loss: 104.45116
Epoch 17, Val Loss: 110.50987
Epoch 18, Val Loss: 106.92139
Epoch 19, Val Loss: 122.17158
Epoch 20, Val Loss: 112.99600
Epoch 21, Val Loss: 119.63713
Epoch 22, Val Loss: 118.81197
Epoch 23, Val Loss: 109.01461
Epoch 24, Val Loss: 106.63802
Epoch 25, Val Loss: 105.68843
Epoch 26, Val Loss: 106.35155
Epoch 27, Val Loss: 114.58717
Epoch 28, Val Loss: 104.63557
Epoch 29, Val Loss: 99.76205
Epoch 30, Val Loss: 112.47772
Epoch 31, Val Loss: 95.67214
Epoch 32, Val Loss: 101.09892
Epoch 33, Val Loss: 97.71326
Epoch 34, Val Loss: 108.97871
Epoch 35, Val Loss: 108.92346
Epoch 36, Val Loss: 94.07359
Epoch 37, Val Loss: 92.60193
Epoch 38, Val Loss: 109.68620
Epoch 39, Val Loss: 98.89211
Epoch 40, Val Loss: 92.42879
Epoch 41, Val Loss: 91.20845
Epoch 42, Val Loss: 91.10352
Epoch 43, Val Loss: 90.15456
Epoch 44, Val Loss: 86.50645
Epoch 45, Val Loss: 92.77960
Epoch 46, Val Loss: 91.36263
Epoch 47, Val Loss: 88.78839
Epoch 48, Val Loss: 88.18661
Epoch 49, Val Loss: 88.40269
Epoch 50, Val Loss: 97.94210
Epoch 51, Val Loss: 91.09296
Epoch 52, Val Loss: 85.64139
Epoch 53, Val Loss: 90.92735
Epoch 54, Val Loss: 83.35077
Epoch 55, Val Loss: 90.36447
Epoch 56, Val Loss: 86.40532
Epoch 57, Val Loss: 86.51527
Epoch 58, Val Loss: 87.09837
Epoch 59, Val Loss: 100.26218
Epoch 60, Val Loss: 85.97204
Epoch 61, Val Loss: 84.52504
Epoch 62, Val Loss: 92.63351
Epoch 63, Val Loss: 93.17946
Epoch 64, Val Loss: 89.30659
Epoch 65, Val Loss: 86.85635
Epoch 66, Val Loss: 85.22203
Epoch 67, Val Loss: 83.82724
Epoch 68, Val Loss: 80.23578
Epoch 69, Val Loss: 83.04526
Epoch 70, Val Loss: 83.32872
Epoch 71, Val Loss: 84.12441
Epoch 72, Val Loss: 86.12865
Epoch 73, Val Loss: 84.52128
Epoch 74, Val Loss: 84.03063
Epoch 75, Val Loss: 91.15660
Epoch 76, Val Loss: 87.33862
Epoch 77, Val Loss: 82.86023
Epoch 78, Val Loss: 85.87860
Epoch 79, Val Loss: 86.79942
Epoch 80, Val Loss: 86.28157
Epoch 81, Val Loss: 85.99532
Epoch 82, Val Loss: 91.65588
Epoch 83, Val Loss: 87.43686
Epoch 84, Val Loss: 86.76492
Epoch 85, Val Loss: 86.33417
Epoch 86, Val Loss: 102.25854
Epoch 87, Val Loss: 85.17097
Epoch 88, Val Loss: 94.23306
Epoch 89, Val Loss: 82.64963
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.11147077204126, 'MSE - std': 0.0, 'R2 - mean': 0.5098544787717951, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1337.30225
Epoch 1, Val Loss: 347.54477
Epoch 2, Val Loss: 171.91008
Epoch 3, Val Loss: 162.36716
Epoch 4, Val Loss: 155.93962
Epoch 5, Val Loss: 151.69548
Epoch 6, Val Loss: 134.84592
Epoch 7, Val Loss: 130.21175
Epoch 8, Val Loss: 113.98375
Epoch 9, Val Loss: 109.65887
Epoch 10, Val Loss: 121.09911
Epoch 11, Val Loss: 102.98000
Epoch 12, Val Loss: 110.40803
Epoch 13, Val Loss: 98.42609
Epoch 14, Val Loss: 84.67658
Epoch 15, Val Loss: 92.17561
Epoch 16, Val Loss: 104.35986
Epoch 17, Val Loss: 98.65409
Epoch 18, Val Loss: 83.37428
Epoch 19, Val Loss: 97.65523
Epoch 20, Val Loss: 102.05221
Epoch 21, Val Loss: 94.85432
Epoch 22, Val Loss: 96.49022
Epoch 23, Val Loss: 93.17265
Epoch 24, Val Loss: 96.36834
Epoch 25, Val Loss: 104.93439
Epoch 26, Val Loss: 88.67818
Epoch 27, Val Loss: 85.23329
Epoch 28, Val Loss: 83.61261
Epoch 29, Val Loss: 93.33346
Epoch 30, Val Loss: 79.84462
Epoch 31, Val Loss: 84.96925
Epoch 32, Val Loss: 80.13562
Epoch 33, Val Loss: 85.24005
Epoch 34, Val Loss: 92.46680
Epoch 35, Val Loss: 86.21653
Epoch 36, Val Loss: 85.48293
Epoch 37, Val Loss: 97.35156
Epoch 38, Val Loss: 80.99352
Epoch 39, Val Loss: 93.40388
Epoch 40, Val Loss: 79.59089
Epoch 41, Val Loss: 84.53944
Epoch 42, Val Loss: 75.90903
Epoch 43, Val Loss: 95.04089
Epoch 44, Val Loss: 76.61874
Epoch 45, Val Loss: 76.99081
Epoch 46, Val Loss: 82.08383
Epoch 47, Val Loss: 74.27666
Epoch 48, Val Loss: 74.71658
Epoch 49, Val Loss: 79.01422
Epoch 50, Val Loss: 80.44285
Epoch 51, Val Loss: 72.85823
Epoch 52, Val Loss: 79.81841
Epoch 53, Val Loss: 74.20689
Epoch 54, Val Loss: 88.50118
Epoch 55, Val Loss: 76.18681
Epoch 56, Val Loss: 76.36569
Epoch 57, Val Loss: 72.14084
Epoch 58, Val Loss: 72.12742
Epoch 59, Val Loss: 70.37292
Epoch 60, Val Loss: 83.80428
Epoch 61, Val Loss: 85.59895
Epoch 62, Val Loss: 71.36198
Epoch 63, Val Loss: 66.97066
Epoch 64, Val Loss: 74.36821
Epoch 65, Val Loss: 72.62156
Epoch 66, Val Loss: 73.65186
Epoch 67, Val Loss: 70.93644
Epoch 68, Val Loss: 72.08864
Epoch 69, Val Loss: 72.00895
Epoch 70, Val Loss: 75.58827
Epoch 71, Val Loss: 76.11204
Epoch 72, Val Loss: 68.29328
Epoch 73, Val Loss: 71.07526
Epoch 74, Val Loss: 73.21570
Epoch 75, Val Loss: 72.85680
Epoch 76, Val Loss: 75.85485
Epoch 77, Val Loss: 75.59944
Epoch 78, Val Loss: 69.33284
Epoch 79, Val Loss: 72.73744
Epoch 80, Val Loss: 74.16316
Epoch 81, Val Loss: 78.72712
Epoch 82, Val Loss: 70.18329
Epoch 83, Val Loss: 68.52682
Epoch 84, Val Loss: 71.15757
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.31221349167059, 'MSE - std': 4.799257280370668, 'R2 - mean': 0.5172316326085118, 'R2 - std': 0.007377153836716721} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 619.24579
Epoch 1, Val Loss: 373.19916
Epoch 2, Val Loss: 191.08356
Epoch 3, Val Loss: 136.54361
Epoch 4, Val Loss: 130.40903
Epoch 5, Val Loss: 133.76630
Epoch 6, Val Loss: 124.27347
Epoch 7, Val Loss: 97.73174
Epoch 8, Val Loss: 93.73717
Epoch 9, Val Loss: 103.02613
Epoch 10, Val Loss: 99.66439
Epoch 11, Val Loss: 87.37610
Epoch 12, Val Loss: 85.88986
Epoch 13, Val Loss: 96.65001
Epoch 14, Val Loss: 85.36636
Epoch 15, Val Loss: 77.67832
Epoch 16, Val Loss: 82.48403
Epoch 17, Val Loss: 90.64397
Epoch 18, Val Loss: 81.32266
Epoch 19, Val Loss: 87.73756
Epoch 20, Val Loss: 84.41145
Epoch 21, Val Loss: 83.53290
Epoch 22, Val Loss: 80.70688
Epoch 23, Val Loss: 82.97398
Epoch 24, Val Loss: 87.95625
Epoch 25, Val Loss: 87.18780
Epoch 26, Val Loss: 88.04189
Epoch 27, Val Loss: 80.11366
Epoch 28, Val Loss: 86.64574
Epoch 29, Val Loss: 86.68585
Epoch 30, Val Loss: 83.45741
Epoch 31, Val Loss: 80.55629
Epoch 32, Val Loss: 83.32446
Epoch 33, Val Loss: 85.38512
Epoch 34, Val Loss: 82.37184
Epoch 35, Val Loss: 76.72884
Epoch 36, Val Loss: 80.50123
Epoch 37, Val Loss: 78.02966
Epoch 38, Val Loss: 71.88919
Epoch 39, Val Loss: 82.76039
Epoch 40, Val Loss: 70.58076
Epoch 41, Val Loss: 76.38741
Epoch 42, Val Loss: 70.93186
Epoch 43, Val Loss: 74.50797
Epoch 44, Val Loss: 72.11781
Epoch 45, Val Loss: 75.27837
Epoch 46, Val Loss: 70.19942
Epoch 47, Val Loss: 68.34902
Epoch 48, Val Loss: 70.30198
Epoch 49, Val Loss: 75.79701
Epoch 50, Val Loss: 71.09080
Epoch 51, Val Loss: 73.48217
Epoch 52, Val Loss: 71.77524
Epoch 53, Val Loss: 73.92726
Epoch 54, Val Loss: 73.01859
Epoch 55, Val Loss: 98.10587
Epoch 56, Val Loss: 72.70557
Epoch 57, Val Loss: 70.12079
Epoch 58, Val Loss: 77.99901
Epoch 59, Val Loss: 75.15585
Epoch 60, Val Loss: 73.36797
Epoch 61, Val Loss: 71.36379
Epoch 62, Val Loss: 70.02887
Epoch 63, Val Loss: 77.92754
Epoch 64, Val Loss: 72.43147
Epoch 65, Val Loss: 71.56624
Epoch 66, Val Loss: 85.39397
Epoch 67, Val Loss: 67.36254
Epoch 68, Val Loss: 69.51355
Epoch 69, Val Loss: 75.22778
Epoch 70, Val Loss: 78.96953
Epoch 71, Val Loss: 68.90617
Epoch 72, Val Loss: 68.96136
Epoch 73, Val Loss: 70.89662
Epoch 74, Val Loss: 70.74446
Epoch 75, Val Loss: 71.83483
Epoch 76, Val Loss: 68.05797
Epoch 77, Val Loss: 73.13606
Epoch 78, Val Loss: 71.45160
Epoch 79, Val Loss: 87.05748
Epoch 80, Val Loss: 70.52947
Epoch 81, Val Loss: 69.08942
Epoch 82, Val Loss: 69.89623
Epoch 83, Val Loss: 72.47549
Epoch 84, Val Loss: 82.89398
Epoch 85, Val Loss: 75.22968
Epoch 86, Val Loss: 74.73016
Epoch 87, Val Loss: 70.47086
Epoch 88, Val Loss: 74.44077
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 75.84150933511215, 'MSE - std': 6.280670477491346, 'R2 - mean': 0.5237925165928957, 'R2 - std': 0.011062187689006742} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 825.87720
Epoch 1, Val Loss: 499.49844
Epoch 2, Val Loss: 157.61621
Epoch 3, Val Loss: 152.82893
Epoch 4, Val Loss: 140.99423
Epoch 5, Val Loss: 130.29521
Epoch 6, Val Loss: 125.59386
Epoch 7, Val Loss: 124.35409
Epoch 8, Val Loss: 116.52151
Epoch 9, Val Loss: 113.74012
Epoch 10, Val Loss: 116.25076
Epoch 11, Val Loss: 107.45366
Epoch 12, Val Loss: 110.19637
Epoch 13, Val Loss: 100.86297
Epoch 14, Val Loss: 102.21948
Epoch 15, Val Loss: 96.01200
Epoch 16, Val Loss: 106.79353
Epoch 17, Val Loss: 101.67893
Epoch 18, Val Loss: 92.12337
Epoch 19, Val Loss: 101.01260
Epoch 20, Val Loss: 94.93165
Epoch 21, Val Loss: 96.99272
Epoch 22, Val Loss: 104.60641
Epoch 23, Val Loss: 98.39114
Epoch 24, Val Loss: 93.46836
Epoch 25, Val Loss: 97.12785
Epoch 26, Val Loss: 88.76820
Epoch 27, Val Loss: 87.46536
Epoch 28, Val Loss: 86.02693
Epoch 29, Val Loss: 89.80913
Epoch 30, Val Loss: 93.18485
Epoch 31, Val Loss: 89.33617
Epoch 32, Val Loss: 91.04761
Epoch 33, Val Loss: 98.78260
Epoch 34, Val Loss: 88.01202
Epoch 35, Val Loss: 89.33155
Epoch 36, Val Loss: 91.80299
Epoch 37, Val Loss: 89.31923
Epoch 38, Val Loss: 88.83108
Epoch 39, Val Loss: 87.00626
Epoch 40, Val Loss: 86.83438
Epoch 41, Val Loss: 93.96206
Epoch 42, Val Loss: 83.84235
Epoch 43, Val Loss: 89.50815
Epoch 44, Val Loss: 82.74680
Epoch 45, Val Loss: 81.96921
Epoch 46, Val Loss: 82.38042
Epoch 47, Val Loss: 87.75723
Epoch 48, Val Loss: 82.14733
Epoch 49, Val Loss: 94.55177
Epoch 50, Val Loss: 84.34317
Epoch 51, Val Loss: 87.28369
Epoch 52, Val Loss: 87.32134
Epoch 53, Val Loss: 81.11342
Epoch 54, Val Loss: 80.43024
Epoch 55, Val Loss: 84.10152
Epoch 56, Val Loss: 90.95778
Epoch 57, Val Loss: 90.08279
Epoch 58, Val Loss: 80.42262
Epoch 59, Val Loss: 77.22679
Epoch 60, Val Loss: 88.55062
Epoch 61, Val Loss: 85.08488
Epoch 62, Val Loss: 81.92087
Epoch 63, Val Loss: 87.22935
Epoch 64, Val Loss: 77.92132
Epoch 65, Val Loss: 78.15066
Epoch 66, Val Loss: 79.33652
Epoch 67, Val Loss: 78.28895
Epoch 68, Val Loss: 94.06393
Epoch 69, Val Loss: 90.39024
Epoch 70, Val Loss: 84.52867
Epoch 71, Val Loss: 79.52067
Epoch 72, Val Loss: 82.71534
Epoch 73, Val Loss: 83.32078
Epoch 74, Val Loss: 88.84731
Epoch 75, Val Loss: 85.43517
Epoch 76, Val Loss: 78.88488
Epoch 77, Val Loss: 90.34392
Epoch 78, Val Loss: 77.42690
Epoch 79, Val Loss: 79.82011
Epoch 80, Val Loss: 80.52164
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.86930447694415, 'MSE - std': 7.555643354329793, 'R2 - mean': 0.5110761448350801, 'R2 - std': 0.024018687087328884} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 834.21277
Epoch 1, Val Loss: 506.97354
Epoch 2, Val Loss: 172.37086
Epoch 3, Val Loss: 147.18239
Epoch 4, Val Loss: 146.15269
Epoch 5, Val Loss: 144.38431
Epoch 6, Val Loss: 141.44406
Epoch 7, Val Loss: 135.09372
Epoch 8, Val Loss: 125.29412
Epoch 9, Val Loss: 132.57048
Epoch 10, Val Loss: 128.47141
Epoch 11, Val Loss: 129.76733
Epoch 12, Val Loss: 110.25551
Epoch 13, Val Loss: 98.47542
Epoch 14, Val Loss: 105.31384
Epoch 15, Val Loss: 110.51225
Epoch 16, Val Loss: 100.69602
Epoch 17, Val Loss: 116.76501
Epoch 18, Val Loss: 127.31664
Epoch 19, Val Loss: 104.16284
Epoch 20, Val Loss: 101.19283
Epoch 21, Val Loss: 116.45415
Epoch 22, Val Loss: 104.95412
Epoch 23, Val Loss: 97.39287
Epoch 24, Val Loss: 100.18889
Epoch 25, Val Loss: 105.07536
Epoch 26, Val Loss: 90.61255
Epoch 27, Val Loss: 96.54898
Epoch 28, Val Loss: 101.19775
Epoch 29, Val Loss: 97.43633
Epoch 30, Val Loss: 92.97722
Epoch 31, Val Loss: 86.89876
Epoch 32, Val Loss: 92.18674
Epoch 33, Val Loss: 88.29108
Epoch 34, Val Loss: 95.43592
Epoch 35, Val Loss: 89.45610
Epoch 36, Val Loss: 88.36852
Epoch 37, Val Loss: 86.73324
Epoch 38, Val Loss: 88.42565
Epoch 39, Val Loss: 83.20071
Epoch 40, Val Loss: 82.15619
Epoch 41, Val Loss: 91.10201
Epoch 42, Val Loss: 112.03371
Epoch 43, Val Loss: 96.06666
Epoch 44, Val Loss: 98.77558
Epoch 45, Val Loss: 88.01506
Epoch 46, Val Loss: 78.78812
Epoch 47, Val Loss: 77.41034
Epoch 48, Val Loss: 80.87079
Epoch 49, Val Loss: 81.99905
Epoch 50, Val Loss: 85.64240
Epoch 51, Val Loss: 79.78804
Epoch 52, Val Loss: 91.43385
Epoch 53, Val Loss: 79.31437
Epoch 54, Val Loss: 76.71668
Epoch 55, Val Loss: 78.79976
Epoch 56, Val Loss: 81.37216
Epoch 57, Val Loss: 80.04594
Epoch 58, Val Loss: 77.65756
Epoch 59, Val Loss: 82.10484
Epoch 60, Val Loss: 83.69149
Epoch 61, Val Loss: 81.12509
Epoch 62, Val Loss: 78.83852
Epoch 63, Val Loss: 92.33432
Epoch 64, Val Loss: 76.36909
Epoch 65, Val Loss: 76.87039
Epoch 66, Val Loss: 76.69229
Epoch 67, Val Loss: 82.23067
Epoch 68, Val Loss: 81.32590
Epoch 69, Val Loss: 81.93728
Epoch 70, Val Loss: 87.08495
Epoch 71, Val Loss: 83.79961
Epoch 72, Val Loss: 76.03467
Epoch 73, Val Loss: 74.47763
Epoch 74, Val Loss: 77.95953
Epoch 75, Val Loss: 88.27640
Epoch 76, Val Loss: 74.80967
Epoch 77, Val Loss: 76.37405
Epoch 78, Val Loss: 81.25993
Epoch 79, Val Loss: 76.35387
Epoch 80, Val Loss: 79.04726
Epoch 81, Val Loss: 86.11626
Epoch 82, Val Loss: 79.44218
Epoch 83, Val Loss: 89.38286
Epoch 84, Val Loss: 78.26989
Epoch 85, Val Loss: 78.16458
Epoch 86, Val Loss: 80.64797
Epoch 87, Val Loss: 76.90405
Epoch 88, Val Loss: 79.66155
Epoch 89, Val Loss: 78.83655
Epoch 90, Val Loss: 88.20053
Epoch 91, Val Loss: 79.75385
Epoch 92, Val Loss: 78.92236
Epoch 93, Val Loss: 91.86097
Epoch 94, Val Loss: 84.69283
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.32429308881031, 'MSE - std': 6.845315686733865, 'R2 - mean': 0.5133528777905397, 'R2 - std': 0.021960234864889728} 
 

Results After CV: {'MSE - mean': 78.32429308881031, 'MSE - std': 6.845315686733865, 'R2 - mean': 0.5133528777905397, 'R2 - std': 0.021960234864889728}
Train time: 417.3623392064066
Inference time: 0.18756302359979599
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 60 finished with value: 78.32429308881031 and parameters: {'p_m': 0.2448785366597567, 'alpha': 9.432868155661657, 'K': 2, 'beta': 6.121362020997916}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 649.10834
Epoch 1, Val Loss: 325.44730
Epoch 2, Val Loss: 232.90379
Epoch 3, Val Loss: 180.06842
Epoch 4, Val Loss: 180.82751
Epoch 5, Val Loss: 163.07234
Epoch 6, Val Loss: 142.51555
Epoch 7, Val Loss: 124.60587
Epoch 8, Val Loss: 124.78464
Epoch 9, Val Loss: 121.84793
Epoch 10, Val Loss: 114.02708
Epoch 11, Val Loss: 126.09762
Epoch 12, Val Loss: 113.20865
Epoch 13, Val Loss: 102.89464
Epoch 14, Val Loss: 103.73354
Epoch 15, Val Loss: 112.73756
Epoch 16, Val Loss: 99.35814
Epoch 17, Val Loss: 101.50494
Epoch 18, Val Loss: 111.74908
Epoch 19, Val Loss: 110.50806
Epoch 20, Val Loss: 120.76157
Epoch 21, Val Loss: 116.72849
Epoch 22, Val Loss: 109.70476
Epoch 23, Val Loss: 108.54294
Epoch 24, Val Loss: 103.27574
Epoch 25, Val Loss: 101.57776
Epoch 26, Val Loss: 102.57709
Epoch 27, Val Loss: 113.18056
Epoch 28, Val Loss: 104.85982
Epoch 29, Val Loss: 95.84843
Epoch 30, Val Loss: 98.55923
Epoch 31, Val Loss: 95.80383
Epoch 32, Val Loss: 91.81104
Epoch 33, Val Loss: 93.57158
Epoch 34, Val Loss: 95.98622
Epoch 35, Val Loss: 104.67686
Epoch 36, Val Loss: 90.42385
Epoch 37, Val Loss: 89.74547
Epoch 38, Val Loss: 87.95422
Epoch 39, Val Loss: 98.62167
Epoch 40, Val Loss: 84.43310
Epoch 41, Val Loss: 90.03780
Epoch 42, Val Loss: 95.18051
Epoch 43, Val Loss: 93.08308
Epoch 44, Val Loss: 88.19969
Epoch 45, Val Loss: 88.61870
Epoch 46, Val Loss: 95.90894
Epoch 47, Val Loss: 94.08972
Epoch 48, Val Loss: 89.86647
Epoch 49, Val Loss: 84.07898
Epoch 50, Val Loss: 91.76512
Epoch 51, Val Loss: 89.85620
Epoch 52, Val Loss: 92.03763
Epoch 53, Val Loss: 89.70561
Epoch 54, Val Loss: 92.49709
Epoch 55, Val Loss: 92.66224
Epoch 56, Val Loss: 87.91263
Epoch 57, Val Loss: 84.49191
Epoch 58, Val Loss: 84.62149
Epoch 59, Val Loss: 87.21429
Epoch 60, Val Loss: 82.87012
Epoch 61, Val Loss: 85.84418
Epoch 62, Val Loss: 92.17973
Epoch 63, Val Loss: 88.14571
Epoch 64, Val Loss: 83.63467
Epoch 65, Val Loss: 89.50282
Epoch 66, Val Loss: 82.83344
Epoch 67, Val Loss: 85.46896
Epoch 68, Val Loss: 82.30756
Epoch 69, Val Loss: 81.69102
Epoch 70, Val Loss: 85.19682
Epoch 71, Val Loss: 85.28809
Epoch 72, Val Loss: 89.76096
Epoch 73, Val Loss: 101.86128
Epoch 74, Val Loss: 85.16216
Epoch 75, Val Loss: 85.63440
Epoch 76, Val Loss: 95.77528
Epoch 77, Val Loss: 84.92216
Epoch 78, Val Loss: 81.54583
Epoch 79, Val Loss: 93.48325
Epoch 80, Val Loss: 88.22552
Epoch 81, Val Loss: 86.28346
Epoch 82, Val Loss: 89.90311
Epoch 83, Val Loss: 82.27409
Epoch 84, Val Loss: 84.55496
Epoch 85, Val Loss: 82.94675
Epoch 86, Val Loss: 84.64789
Epoch 87, Val Loss: 90.63120
Epoch 88, Val Loss: 91.28117
Epoch 89, Val Loss: 83.37471
Epoch 90, Val Loss: 82.31697
Epoch 91, Val Loss: 85.16602
Epoch 92, Val Loss: 91.91393
Epoch 93, Val Loss: 86.07948
Epoch 94, Val Loss: 85.21759
Epoch 95, Val Loss: 98.15078
Epoch 96, Val Loss: 84.86079
Epoch 97, Val Loss: 84.97104
Epoch 98, Val Loss: 86.59846
Epoch 99, Val Loss: 87.15565
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.0450267592646, 'MSE - std': 0.0, 'R2 - mean': 0.5044143374717645, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 423.96722
Epoch 1, Val Loss: 377.20172
Epoch 2, Val Loss: 157.72690
Epoch 3, Val Loss: 146.24686
Epoch 4, Val Loss: 129.05496
Epoch 5, Val Loss: 126.55339
Epoch 6, Val Loss: 126.86166
Epoch 7, Val Loss: 120.54957
Epoch 8, Val Loss: 116.00653
Epoch 9, Val Loss: 115.65556
Epoch 10, Val Loss: 103.17876
Epoch 11, Val Loss: 99.06665
Epoch 12, Val Loss: 98.17029
Epoch 13, Val Loss: 101.89034
Epoch 14, Val Loss: 87.34311
Epoch 15, Val Loss: 94.31625
Epoch 16, Val Loss: 84.74054
Epoch 17, Val Loss: 98.14408
Epoch 18, Val Loss: 89.04157
Epoch 19, Val Loss: 92.24763
Epoch 20, Val Loss: 85.88019
Epoch 21, Val Loss: 90.01295
Epoch 22, Val Loss: 84.15239
Epoch 23, Val Loss: 91.60756
Epoch 24, Val Loss: 84.73653
Epoch 25, Val Loss: 81.90887
Epoch 26, Val Loss: 83.30973
Epoch 27, Val Loss: 91.72026
Epoch 28, Val Loss: 87.16689
Epoch 29, Val Loss: 80.29705
Epoch 30, Val Loss: 83.25520
Epoch 31, Val Loss: 80.46862
Epoch 32, Val Loss: 78.96130
Epoch 33, Val Loss: 77.43201
Epoch 34, Val Loss: 78.74235
Epoch 35, Val Loss: 78.16727
Epoch 36, Val Loss: 86.03402
Epoch 37, Val Loss: 85.29527
Epoch 38, Val Loss: 74.95574
Epoch 39, Val Loss: 79.15776
Epoch 40, Val Loss: 73.18605
Epoch 41, Val Loss: 77.79189
Epoch 42, Val Loss: 115.41947
Epoch 43, Val Loss: 85.44160
Epoch 44, Val Loss: 79.87966
Epoch 45, Val Loss: 75.51050
Epoch 46, Val Loss: 77.46294
Epoch 47, Val Loss: 77.33472
Epoch 48, Val Loss: 74.54608
Epoch 49, Val Loss: 72.37543
Epoch 50, Val Loss: 75.32727
Epoch 51, Val Loss: 72.16538
Epoch 52, Val Loss: 74.56688
Epoch 53, Val Loss: 71.35352
Epoch 54, Val Loss: 81.19167
Epoch 55, Val Loss: 74.74346
Epoch 56, Val Loss: 73.30149
Epoch 57, Val Loss: 84.93253
Epoch 58, Val Loss: 70.71764
Epoch 59, Val Loss: 86.66053
Epoch 60, Val Loss: 83.81654
Epoch 61, Val Loss: 73.45314
Epoch 62, Val Loss: 74.82706
Epoch 63, Val Loss: 72.23608
Epoch 64, Val Loss: 72.37240
Epoch 65, Val Loss: 72.95084
Epoch 66, Val Loss: 78.61755
Epoch 67, Val Loss: 73.09663
Epoch 68, Val Loss: 71.05013
Epoch 69, Val Loss: 78.44783
Epoch 70, Val Loss: 68.71573
Epoch 71, Val Loss: 71.32710
Epoch 72, Val Loss: 70.65585
Epoch 73, Val Loss: 71.65768
Epoch 74, Val Loss: 72.26331
Epoch 75, Val Loss: 75.84859
Epoch 76, Val Loss: 73.45114
Epoch 77, Val Loss: 82.28459
Epoch 78, Val Loss: 72.52930
Epoch 79, Val Loss: 83.18549
Epoch 80, Val Loss: 74.78412
Epoch 81, Val Loss: 81.06380
Epoch 82, Val Loss: 70.70838
Epoch 83, Val Loss: 73.88087
Epoch 84, Val Loss: 68.60489
Epoch 85, Val Loss: 70.10104
Epoch 86, Val Loss: 76.82961
Epoch 87, Val Loss: 82.76368
Epoch 88, Val Loss: 81.88217
Epoch 89, Val Loss: 68.40613
Epoch 90, Val Loss: 73.41126
Epoch 91, Val Loss: 70.22519
Epoch 92, Val Loss: 69.77934
Epoch 93, Val Loss: 69.07337
Epoch 94, Val Loss: 72.89276
Epoch 95, Val Loss: 83.59539
Epoch 96, Val Loss: 80.90527
Epoch 97, Val Loss: 73.52290
Epoch 98, Val Loss: 75.17425
Epoch 99, Val Loss: 71.78540
DID NOT SAVE RESULTS
{'MSE - mean': 80.53997768163708, 'MSE - std': 4.505049077627518, 'R2 - mean': 0.5096564848044286, 'R2 - std': 0.005242147332664149} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 586.78760
Epoch 1, Val Loss: 493.96548
Epoch 2, Val Loss: 150.87642
Epoch 3, Val Loss: 132.35429
Epoch 4, Val Loss: 127.64363
Epoch 5, Val Loss: 113.33530
Epoch 6, Val Loss: 98.66532
Epoch 7, Val Loss: 105.93692
Epoch 8, Val Loss: 103.96638
Epoch 9, Val Loss: 95.89049
Epoch 10, Val Loss: 103.26605
Epoch 11, Val Loss: 90.39592
Epoch 12, Val Loss: 113.88798
Epoch 13, Val Loss: 103.36214
Epoch 14, Val Loss: 81.75238
Epoch 15, Val Loss: 87.09222
Epoch 16, Val Loss: 87.64170
Epoch 17, Val Loss: 80.16148
Epoch 18, Val Loss: 94.26570
Epoch 19, Val Loss: 88.56374
Epoch 20, Val Loss: 83.52729
Epoch 21, Val Loss: 86.21949
Epoch 22, Val Loss: 101.14417
Epoch 23, Val Loss: 81.66525
Epoch 24, Val Loss: 87.90296
Epoch 25, Val Loss: 88.58734
Epoch 26, Val Loss: 76.21517
Epoch 27, Val Loss: 86.34180
Epoch 28, Val Loss: 83.01907
Epoch 29, Val Loss: 80.44248
Epoch 30, Val Loss: 83.06592
Epoch 31, Val Loss: 75.91652
Epoch 32, Val Loss: 97.07816
Epoch 33, Val Loss: 86.38284
Epoch 34, Val Loss: 73.28043
Epoch 35, Val Loss: 74.47942
Epoch 36, Val Loss: 78.99261
Epoch 37, Val Loss: 109.28234
Epoch 38, Val Loss: 79.50676
Epoch 39, Val Loss: 72.76727
Epoch 40, Val Loss: 68.94991
Epoch 41, Val Loss: 74.84587
Epoch 42, Val Loss: 73.06206
Epoch 43, Val Loss: 73.88699
Epoch 44, Val Loss: 87.69188
Epoch 45, Val Loss: 74.14100
Epoch 46, Val Loss: 72.16180
Epoch 47, Val Loss: 73.71855
Epoch 48, Val Loss: 75.85873
Epoch 49, Val Loss: 84.91663
Epoch 50, Val Loss: 66.64038
Epoch 51, Val Loss: 80.62498
Epoch 52, Val Loss: 78.17924
Epoch 53, Val Loss: 74.24702
Epoch 54, Val Loss: 69.28168
Epoch 55, Val Loss: 71.25199
Epoch 56, Val Loss: 68.85840
Epoch 57, Val Loss: 69.21031
Epoch 58, Val Loss: 67.93689
Epoch 59, Val Loss: 67.87629
Epoch 60, Val Loss: 71.99200
Epoch 61, Val Loss: 69.76540
Epoch 62, Val Loss: 74.06258
Epoch 63, Val Loss: 84.02483
Epoch 64, Val Loss: 67.45625
Epoch 65, Val Loss: 74.86546
Epoch 66, Val Loss: 70.38794
Epoch 67, Val Loss: 69.30962
Epoch 68, Val Loss: 69.24054
Epoch 69, Val Loss: 66.84372
Epoch 70, Val Loss: 72.00888
Epoch 71, Val Loss: 67.26649
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.10959794742841, 'MSE - std': 7.265455294735176, 'R2 - mean': 0.5224418615736223, 'R2 - std': 0.01858095236253279} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 622.56616
Epoch 1, Val Loss: 409.78271
Epoch 2, Val Loss: 197.49516
Epoch 3, Val Loss: 166.86847
Epoch 4, Val Loss: 173.47093
Epoch 5, Val Loss: 127.97807
Epoch 6, Val Loss: 127.74994
Epoch 7, Val Loss: 126.00304
Epoch 8, Val Loss: 109.58435
Epoch 9, Val Loss: 111.84707
Epoch 10, Val Loss: 103.91889
Epoch 11, Val Loss: 110.02922
Epoch 12, Val Loss: 109.92789
Epoch 13, Val Loss: 101.59892
Epoch 14, Val Loss: 101.40179
Epoch 15, Val Loss: 94.94458
Epoch 16, Val Loss: 93.32004
Epoch 17, Val Loss: 106.95004
Epoch 18, Val Loss: 101.18130
Epoch 19, Val Loss: 96.92440
Epoch 20, Val Loss: 90.75167
Epoch 21, Val Loss: 93.25279
Epoch 22, Val Loss: 104.87646
Epoch 23, Val Loss: 92.89586
Epoch 24, Val Loss: 92.76641
Epoch 25, Val Loss: 91.19652
Epoch 26, Val Loss: 99.29762
Epoch 27, Val Loss: 89.35639
Epoch 28, Val Loss: 89.95489
Epoch 29, Val Loss: 91.95314
Epoch 30, Val Loss: 94.22842
Epoch 31, Val Loss: 88.58263
Epoch 32, Val Loss: 82.43226
Epoch 33, Val Loss: 78.56379
Epoch 34, Val Loss: 100.56507
Epoch 35, Val Loss: 86.56804
Epoch 36, Val Loss: 83.10044
Epoch 37, Val Loss: 82.16162
Epoch 38, Val Loss: 90.17493
Epoch 39, Val Loss: 83.88198
Epoch 40, Val Loss: 93.19769
Epoch 41, Val Loss: 95.62399
Epoch 42, Val Loss: 89.69330
Epoch 43, Val Loss: 82.79057
Epoch 44, Val Loss: 83.54163
Epoch 45, Val Loss: 83.50538
Epoch 46, Val Loss: 83.46907
Epoch 47, Val Loss: 83.96857
Epoch 48, Val Loss: 84.51337
Epoch 49, Val Loss: 79.88821
Epoch 50, Val Loss: 77.49641
Epoch 51, Val Loss: 84.05370
Epoch 52, Val Loss: 84.75578
Epoch 53, Val Loss: 83.75526
Epoch 54, Val Loss: 82.87386
Epoch 55, Val Loss: 87.80240
Epoch 56, Val Loss: 79.32272
Epoch 57, Val Loss: 91.19138
Epoch 58, Val Loss: 80.62310
Epoch 59, Val Loss: 82.46126
Epoch 60, Val Loss: 89.01872
Epoch 61, Val Loss: 79.85536
Epoch 62, Val Loss: 80.77461
Epoch 63, Val Loss: 82.80976
Epoch 64, Val Loss: 105.85679
Epoch 65, Val Loss: 85.19488
Epoch 66, Val Loss: 78.31908
Epoch 67, Val Loss: 79.82736
Epoch 68, Val Loss: 86.02025
Epoch 69, Val Loss: 82.90888
Epoch 70, Val Loss: 85.68740
Epoch 71, Val Loss: 81.25587
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.33280520536394, 'MSE - std': 8.411737368859733, 'R2 - mean': 0.5084904670506752, 'R2 - std': 0.029032104133678995} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 568.80090
Epoch 1, Val Loss: 407.30972
Epoch 2, Val Loss: 196.40135
Epoch 3, Val Loss: 142.18085
Epoch 4, Val Loss: 147.09183
Epoch 5, Val Loss: 130.56195
Epoch 6, Val Loss: 126.02991
Epoch 7, Val Loss: 131.65598
Epoch 8, Val Loss: 130.94049
Epoch 9, Val Loss: 114.47516
Epoch 10, Val Loss: 126.44768
Epoch 11, Val Loss: 107.01913
Epoch 12, Val Loss: 117.65300
Epoch 13, Val Loss: 105.55721
Epoch 14, Val Loss: 94.71773
Epoch 15, Val Loss: 93.93845
Epoch 16, Val Loss: 101.98392
Epoch 17, Val Loss: 99.23937
Epoch 18, Val Loss: 106.98425
Epoch 19, Val Loss: 95.26100
Epoch 20, Val Loss: 106.68978
Epoch 21, Val Loss: 95.16374
Epoch 22, Val Loss: 113.86478
Epoch 23, Val Loss: 86.94834
Epoch 24, Val Loss: 91.45090
Epoch 25, Val Loss: 93.32166
Epoch 26, Val Loss: 101.96013
Epoch 27, Val Loss: 94.32217
Epoch 28, Val Loss: 100.79519
Epoch 29, Val Loss: 92.73373
Epoch 30, Val Loss: 89.75104
Epoch 31, Val Loss: 88.01347
Epoch 32, Val Loss: 90.95654
Epoch 33, Val Loss: 92.32571
Epoch 34, Val Loss: 101.82690
Epoch 35, Val Loss: 86.57914
Epoch 36, Val Loss: 92.18170
Epoch 37, Val Loss: 90.22122
Epoch 38, Val Loss: 86.78207
Epoch 39, Val Loss: 86.45656
Epoch 40, Val Loss: 85.80703
Epoch 41, Val Loss: 89.47624
Epoch 42, Val Loss: 79.78735
Epoch 43, Val Loss: 80.90703
Epoch 44, Val Loss: 89.85659
Epoch 45, Val Loss: 82.23073
Epoch 46, Val Loss: 91.70099
Epoch 47, Val Loss: 79.29147
Epoch 48, Val Loss: 84.31213
Epoch 49, Val Loss: 99.00896
Epoch 50, Val Loss: 79.10675
Epoch 51, Val Loss: 79.86366
Epoch 52, Val Loss: 83.20258
Epoch 53, Val Loss: 82.67621
Epoch 54, Val Loss: 78.85266
Epoch 55, Val Loss: 82.55182
Epoch 56, Val Loss: 85.69580
Epoch 57, Val Loss: 84.12882
Epoch 58, Val Loss: 83.33072
Epoch 59, Val Loss: 77.03271
Epoch 60, Val Loss: 77.66090
Epoch 61, Val Loss: 78.13271
Epoch 62, Val Loss: 75.61714
Epoch 63, Val Loss: 75.72498
Epoch 64, Val Loss: 77.46948
Epoch 65, Val Loss: 76.09305
Epoch 66, Val Loss: 77.91682
Epoch 67, Val Loss: 83.29181
Epoch 68, Val Loss: 76.01875
Epoch 69, Val Loss: 75.07982
Epoch 70, Val Loss: 86.05556
Epoch 71, Val Loss: 81.15520
Epoch 72, Val Loss: 80.56454
Epoch 73, Val Loss: 83.23888
Epoch 74, Val Loss: 80.44485
Epoch 75, Val Loss: 72.63306
Epoch 76, Val Loss: 74.90340
Epoch 77, Val Loss: 79.64786
Epoch 78, Val Loss: 77.84518
Epoch 79, Val Loss: 78.09983
Epoch 80, Val Loss: 80.55328
Epoch 81, Val Loss: 78.35421
Epoch 82, Val Loss: 84.71813
Epoch 83, Val Loss: 76.35529
Epoch 84, Val Loss: 75.14201
Epoch 85, Val Loss: 87.48201
Epoch 86, Val Loss: 82.03383
Epoch 87, Val Loss: 87.38297
Epoch 88, Val Loss: 95.21280
Epoch 89, Val Loss: 90.59703
Epoch 90, Val Loss: 74.92658
Epoch 91, Val Loss: 82.33268
Epoch 92, Val Loss: 75.36617
Epoch 93, Val Loss: 73.03166
Epoch 94, Val Loss: 74.16788
Epoch 95, Val Loss: 72.07939
Epoch 96, Val Loss: 77.05724
Epoch 97, Val Loss: 80.93349
Epoch 98, Val Loss: 74.50529
Epoch 99, Val Loss: 74.35663
DID NOT SAVE RESULTS
{'MSE - mean': 78.22687354720179, 'MSE - std': 7.84207879201925, 'R2 - mean': 0.5142207875545624, 'R2 - std': 0.028383740920676782} 
 

Results After CV: {'MSE - mean': 78.22687354720179, 'MSE - std': 7.84207879201925, 'R2 - mean': 0.5142207875545624, 'R2 - std': 0.028383740920676782}
Train time: 425.08942540359567
Inference time: 0.20628038300201296
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 61 finished with value: 78.22687354720179 and parameters: {'p_m': 0.1991616786391977, 'alpha': 8.492390687884019, 'K': 2, 'beta': 7.94494439585762}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1258.15137
Epoch 1, Val Loss: 468.56015
Epoch 2, Val Loss: 181.43027
Epoch 3, Val Loss: 158.67134
Epoch 4, Val Loss: 146.26224
Epoch 5, Val Loss: 138.24696
Epoch 6, Val Loss: 120.26813
Epoch 7, Val Loss: 132.34901
Epoch 8, Val Loss: 122.69439
Epoch 9, Val Loss: 111.77601
Epoch 10, Val Loss: 109.99069
Epoch 11, Val Loss: 112.57963
Epoch 12, Val Loss: 109.69737
Epoch 13, Val Loss: 108.25842
Epoch 14, Val Loss: 109.01516
Epoch 15, Val Loss: 108.51632
Epoch 16, Val Loss: 95.09692
Epoch 17, Val Loss: 98.68021
Epoch 18, Val Loss: 107.20739
Epoch 19, Val Loss: 97.69327
Epoch 20, Val Loss: 107.06411
Epoch 21, Val Loss: 103.31885
Epoch 22, Val Loss: 103.05989
Epoch 23, Val Loss: 91.83609
Epoch 24, Val Loss: 97.92130
Epoch 25, Val Loss: 93.77832
Epoch 26, Val Loss: 104.33412
Epoch 27, Val Loss: 92.19898
Epoch 28, Val Loss: 95.18462
Epoch 29, Val Loss: 97.51945
Epoch 30, Val Loss: 100.82954
Epoch 31, Val Loss: 100.50136
Epoch 32, Val Loss: 100.40216
Epoch 33, Val Loss: 99.78004
Epoch 34, Val Loss: 115.32921
Epoch 35, Val Loss: 98.10833
Epoch 36, Val Loss: 115.09589
Epoch 37, Val Loss: 91.83575
Epoch 38, Val Loss: 98.69718
Epoch 39, Val Loss: 98.94344
Epoch 40, Val Loss: 104.05064
Epoch 41, Val Loss: 92.91141
Epoch 42, Val Loss: 91.42071
Epoch 43, Val Loss: 88.95962
Epoch 44, Val Loss: 95.82584
Epoch 45, Val Loss: 90.54869
Epoch 46, Val Loss: 91.63348
Epoch 47, Val Loss: 93.11256
Epoch 48, Val Loss: 89.41129
Epoch 49, Val Loss: 96.08463
Epoch 50, Val Loss: 97.72649
Epoch 51, Val Loss: 97.42832
Epoch 52, Val Loss: 87.31965
Epoch 53, Val Loss: 91.96075
Epoch 54, Val Loss: 91.96947
Epoch 55, Val Loss: 84.09676
Epoch 56, Val Loss: 91.78654
Epoch 57, Val Loss: 89.73962
Epoch 58, Val Loss: 88.88210
Epoch 59, Val Loss: 92.06261
Epoch 60, Val Loss: 83.09826
Epoch 61, Val Loss: 87.16570
Epoch 62, Val Loss: 89.43607
Epoch 63, Val Loss: 91.73116
Epoch 64, Val Loss: 90.50788
Epoch 65, Val Loss: 93.76534
Epoch 66, Val Loss: 87.36687
Epoch 67, Val Loss: 87.99295
Epoch 68, Val Loss: 84.19605
Epoch 69, Val Loss: 83.26302
Epoch 70, Val Loss: 89.01105
Epoch 71, Val Loss: 88.66759
Epoch 72, Val Loss: 94.58417
Epoch 73, Val Loss: 94.15680
Epoch 74, Val Loss: 86.92513
Epoch 75, Val Loss: 86.29071
Epoch 76, Val Loss: 90.53500
Epoch 77, Val Loss: 85.98871
Epoch 78, Val Loss: 84.40674
Epoch 79, Val Loss: 86.91953
Epoch 80, Val Loss: 83.96935
Epoch 81, Val Loss: 85.74547
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.95930616755778, 'MSE - std': 0.0, 'R2 - mean': 0.49325919454367095, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 716.45520
Epoch 1, Val Loss: 348.98074
Epoch 2, Val Loss: 156.92621
Epoch 3, Val Loss: 140.51189
Epoch 4, Val Loss: 122.78958
Epoch 5, Val Loss: 112.71859
Epoch 6, Val Loss: 117.26090
Epoch 7, Val Loss: 97.87177
Epoch 8, Val Loss: 114.10083
Epoch 9, Val Loss: 94.65331
Epoch 10, Val Loss: 93.12254
Epoch 11, Val Loss: 87.58454
Epoch 12, Val Loss: 89.85593
Epoch 13, Val Loss: 93.14657
Epoch 14, Val Loss: 96.42117
Epoch 15, Val Loss: 87.78503
Epoch 16, Val Loss: 90.09155
Epoch 17, Val Loss: 93.43013
Epoch 18, Val Loss: 102.72057
Epoch 19, Val Loss: 89.94360
Epoch 20, Val Loss: 89.54121
Epoch 21, Val Loss: 84.62643
Epoch 22, Val Loss: 102.02826
Epoch 23, Val Loss: 85.04201
Epoch 24, Val Loss: 83.78577
Epoch 25, Val Loss: 77.99047
Epoch 26, Val Loss: 76.14776
Epoch 27, Val Loss: 95.81862
Epoch 28, Val Loss: 91.43414
Epoch 29, Val Loss: 108.24372
Epoch 30, Val Loss: 80.51339
Epoch 31, Val Loss: 77.50098
Epoch 32, Val Loss: 82.27753
Epoch 33, Val Loss: 84.04027
Epoch 34, Val Loss: 84.12583
Epoch 35, Val Loss: 86.41940
Epoch 36, Val Loss: 83.69019
Epoch 37, Val Loss: 92.17519
Epoch 38, Val Loss: 86.62672
Epoch 39, Val Loss: 80.06924
Epoch 40, Val Loss: 77.13964
Epoch 41, Val Loss: 110.59473
Epoch 42, Val Loss: 98.58963
Epoch 43, Val Loss: 77.42065
Epoch 44, Val Loss: 72.41042
Epoch 45, Val Loss: 69.58513
Epoch 46, Val Loss: 75.59631
Epoch 47, Val Loss: 72.25435
Epoch 48, Val Loss: 79.48127
Epoch 49, Val Loss: 82.22124
Epoch 50, Val Loss: 86.08249
Epoch 51, Val Loss: 75.80757
Epoch 52, Val Loss: 77.35637
Epoch 53, Val Loss: 80.78120
Epoch 54, Val Loss: 74.84591
Epoch 55, Val Loss: 71.41425
Epoch 56, Val Loss: 77.62839
Epoch 57, Val Loss: 76.65427
Epoch 58, Val Loss: 73.47807
Epoch 59, Val Loss: 76.72423
Epoch 60, Val Loss: 74.01503
Epoch 61, Val Loss: 73.36823
Epoch 62, Val Loss: 87.32267
Epoch 63, Val Loss: 73.15552
Epoch 64, Val Loss: 72.80082
Epoch 65, Val Loss: 70.56491
Epoch 66, Val Loss: 71.97137
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.75769064261203, 'MSE - std': 5.201615524945758, 'R2 - mean': 0.5024164610222606, 'R2 - std': 0.009157266478589554} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 855.40381
Epoch 1, Val Loss: 401.64194
Epoch 2, Val Loss: 166.15993
Epoch 3, Val Loss: 152.40245
Epoch 4, Val Loss: 137.58199
Epoch 5, Val Loss: 110.63778
Epoch 6, Val Loss: 104.17075
Epoch 7, Val Loss: 96.43049
Epoch 8, Val Loss: 101.20338
Epoch 9, Val Loss: 96.77284
Epoch 10, Val Loss: 91.38250
Epoch 11, Val Loss: 102.27685
Epoch 12, Val Loss: 81.66826
Epoch 13, Val Loss: 91.99780
Epoch 14, Val Loss: 90.20624
Epoch 15, Val Loss: 84.26373
Epoch 16, Val Loss: 94.10021
Epoch 17, Val Loss: 93.72514
Epoch 18, Val Loss: 87.20876
Epoch 19, Val Loss: 91.12074
Epoch 20, Val Loss: 77.87396
Epoch 21, Val Loss: 80.61688
Epoch 22, Val Loss: 85.32686
Epoch 23, Val Loss: 89.39951
Epoch 24, Val Loss: 88.07756
Epoch 25, Val Loss: 84.66948
Epoch 26, Val Loss: 82.40984
Epoch 27, Val Loss: 82.42491
Epoch 28, Val Loss: 78.14310
Epoch 29, Val Loss: 90.38013
Epoch 30, Val Loss: 85.53935
Epoch 31, Val Loss: 83.10784
Epoch 32, Val Loss: 85.38212
Epoch 33, Val Loss: 81.88095
Epoch 34, Val Loss: 83.82045
Epoch 35, Val Loss: 90.52684
Epoch 36, Val Loss: 85.47757
Epoch 37, Val Loss: 89.79232
Epoch 38, Val Loss: 78.15445
Epoch 39, Val Loss: 85.00391
Epoch 40, Val Loss: 100.59502
Epoch 41, Val Loss: 75.19034
Epoch 42, Val Loss: 73.56967
Epoch 43, Val Loss: 75.04938
Epoch 44, Val Loss: 74.60852
Epoch 45, Val Loss: 96.12074
Epoch 46, Val Loss: 104.72259
Epoch 47, Val Loss: 75.42670
Epoch 48, Val Loss: 78.63088
Epoch 49, Val Loss: 78.01407
Epoch 50, Val Loss: 74.51086
Epoch 51, Val Loss: 74.49008
Epoch 52, Val Loss: 77.97613
Epoch 53, Val Loss: 73.24189
Epoch 54, Val Loss: 76.13931
Epoch 55, Val Loss: 74.36516
Epoch 56, Val Loss: 77.96840
Epoch 57, Val Loss: 81.40000
Epoch 58, Val Loss: 72.27264
Epoch 59, Val Loss: 92.10987
Epoch 60, Val Loss: 75.10793
Epoch 61, Val Loss: 75.28538
Epoch 62, Val Loss: 89.78900
Epoch 63, Val Loss: 85.83874
Epoch 64, Val Loss: 72.64293
Epoch 65, Val Loss: 73.46857
Epoch 66, Val Loss: 68.60107
Epoch 67, Val Loss: 75.35121
Epoch 68, Val Loss: 72.24903
Epoch 69, Val Loss: 71.98846
Epoch 70, Val Loss: 75.06000
Epoch 71, Val Loss: 67.34753
Epoch 72, Val Loss: 71.20095
Epoch 73, Val Loss: 74.55624
Epoch 74, Val Loss: 77.06055
Epoch 75, Val Loss: 76.97171
Epoch 76, Val Loss: 72.40865
Epoch 77, Val Loss: 72.32916
Epoch 78, Val Loss: 67.44142
Epoch 79, Val Loss: 69.08331
Epoch 80, Val Loss: 68.52698
Epoch 81, Val Loss: 79.83675
Epoch 82, Val Loss: 78.57121
Epoch 83, Val Loss: 71.26962
Epoch 84, Val Loss: 71.37331
Epoch 85, Val Loss: 73.46678
Epoch 86, Val Loss: 69.10728
Epoch 87, Val Loss: 68.67580
Epoch 88, Val Loss: 77.57607
Epoch 89, Val Loss: 70.80963
Epoch 90, Val Loss: 68.92362
Epoch 91, Val Loss: 67.94170
Epoch 92, Val Loss: 67.73158
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.27981512774869, 'MSE - std': 7.624998861166891, 'R2 - mean': 0.515206272932294, 'R2 - std': 0.019571976487519106} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 730.86426
Epoch 1, Val Loss: 431.37891
Epoch 2, Val Loss: 148.59750
Epoch 3, Val Loss: 136.30313
Epoch 4, Val Loss: 158.79726
Epoch 5, Val Loss: 132.87605
Epoch 6, Val Loss: 109.28343
Epoch 7, Val Loss: 107.48856
Epoch 8, Val Loss: 98.69608
Epoch 9, Val Loss: 114.24348
Epoch 10, Val Loss: 100.51572
Epoch 11, Val Loss: 107.79615
Epoch 12, Val Loss: 97.26905
Epoch 13, Val Loss: 101.57643
Epoch 14, Val Loss: 96.74027
Epoch 15, Val Loss: 98.60066
Epoch 16, Val Loss: 97.63042
Epoch 17, Val Loss: 101.63188
Epoch 18, Val Loss: 93.85771
Epoch 19, Val Loss: 103.57559
Epoch 20, Val Loss: 94.70963
Epoch 21, Val Loss: 101.06897
Epoch 22, Val Loss: 95.29766
Epoch 23, Val Loss: 86.12752
Epoch 24, Val Loss: 91.13427
Epoch 25, Val Loss: 95.37038
Epoch 26, Val Loss: 87.04755
Epoch 27, Val Loss: 90.41180
Epoch 28, Val Loss: 102.98487
Epoch 29, Val Loss: 89.11811
Epoch 30, Val Loss: 95.07388
Epoch 31, Val Loss: 83.71263
Epoch 32, Val Loss: 85.67538
Epoch 33, Val Loss: 91.05104
Epoch 34, Val Loss: 80.20657
Epoch 35, Val Loss: 85.80169
Epoch 36, Val Loss: 99.55586
Epoch 37, Val Loss: 97.23216
Epoch 38, Val Loss: 101.99056
Epoch 39, Val Loss: 84.56019
Epoch 40, Val Loss: 82.55948
Epoch 41, Val Loss: 92.13280
Epoch 42, Val Loss: 84.45068
Epoch 43, Val Loss: 81.74132
Epoch 44, Val Loss: 80.05345
Epoch 45, Val Loss: 93.03814
Epoch 46, Val Loss: 112.05409
Epoch 47, Val Loss: 113.27679
Epoch 48, Val Loss: 84.88677
Epoch 49, Val Loss: 78.58688
Epoch 50, Val Loss: 84.22946
Epoch 51, Val Loss: 82.33539
Epoch 52, Val Loss: 87.18537
Epoch 53, Val Loss: 81.11829
Epoch 54, Val Loss: 82.26637
Epoch 55, Val Loss: 81.39412
Epoch 56, Val Loss: 85.00807
Epoch 57, Val Loss: 82.38157
Epoch 58, Val Loss: 78.85741
Epoch 59, Val Loss: 81.27509
Epoch 60, Val Loss: 81.06602
Epoch 61, Val Loss: 84.71684
Epoch 62, Val Loss: 81.49470
Epoch 63, Val Loss: 82.14986
Epoch 64, Val Loss: 80.15074
Epoch 65, Val Loss: 77.86362
Epoch 66, Val Loss: 76.61832
Epoch 67, Val Loss: 79.66180
Epoch 68, Val Loss: 76.16708
Epoch 69, Val Loss: 74.25351
Epoch 70, Val Loss: 81.21407
Epoch 71, Val Loss: 75.54747
Epoch 72, Val Loss: 81.71197
Epoch 73, Val Loss: 80.77155
Epoch 74, Val Loss: 77.08381
Epoch 75, Val Loss: 79.49327
Epoch 76, Val Loss: 78.09445
Epoch 77, Val Loss: 77.90636
Epoch 78, Val Loss: 79.35252
Epoch 79, Val Loss: 83.84161
Epoch 80, Val Loss: 83.21380
Epoch 81, Val Loss: 76.61563
Epoch 82, Val Loss: 75.03081
Epoch 83, Val Loss: 76.16137
Epoch 84, Val Loss: 78.19292
Epoch 85, Val Loss: 89.66963
Epoch 86, Val Loss: 76.23252
Epoch 87, Val Loss: 74.94978
Epoch 88, Val Loss: 77.92190
Epoch 89, Val Loss: 77.58118
Epoch 90, Val Loss: 88.52745
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.94816879426922, 'MSE - std': 7.208027996225792, 'R2 - mean': 0.5106283405697889, 'R2 - std': 0.018712805558440876} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 804.53711
Epoch 1, Val Loss: 589.86633
Epoch 2, Val Loss: 179.52496
Epoch 3, Val Loss: 143.83710
Epoch 4, Val Loss: 139.15366
Epoch 5, Val Loss: 131.32973
Epoch 6, Val Loss: 106.55946
Epoch 7, Val Loss: 111.07699
Epoch 8, Val Loss: 105.68681
Epoch 9, Val Loss: 124.31532
Epoch 10, Val Loss: 107.59917
Epoch 11, Val Loss: 113.98186
Epoch 12, Val Loss: 106.12941
Epoch 13, Val Loss: 106.21700
Epoch 14, Val Loss: 100.54986
Epoch 15, Val Loss: 103.59678
Epoch 16, Val Loss: 101.80750
Epoch 17, Val Loss: 95.17664
Epoch 18, Val Loss: 91.89227
Epoch 19, Val Loss: 106.87836
Epoch 20, Val Loss: 103.27571
Epoch 21, Val Loss: 100.64230
Epoch 22, Val Loss: 97.28335
Epoch 23, Val Loss: 99.97397
Epoch 24, Val Loss: 96.65888
Epoch 25, Val Loss: 96.07587
Epoch 26, Val Loss: 96.52585
Epoch 27, Val Loss: 97.67652
Epoch 28, Val Loss: 119.48477
Epoch 29, Val Loss: 102.17229
Epoch 30, Val Loss: 113.71664
Epoch 31, Val Loss: 109.05147
Epoch 32, Val Loss: 90.13023
Epoch 33, Val Loss: 93.17915
Epoch 34, Val Loss: 98.77650
Epoch 35, Val Loss: 91.85359
Epoch 36, Val Loss: 87.60562
Epoch 37, Val Loss: 92.05926
Epoch 38, Val Loss: 90.30277
Epoch 39, Val Loss: 89.11490
Epoch 40, Val Loss: 95.18056
Epoch 41, Val Loss: 92.59010
Epoch 42, Val Loss: 83.98785
Epoch 43, Val Loss: 86.39169
Epoch 44, Val Loss: 93.56046
Epoch 45, Val Loss: 86.34090
Epoch 46, Val Loss: 84.95700
Epoch 47, Val Loss: 96.21583
Epoch 48, Val Loss: 83.17465
Epoch 49, Val Loss: 79.22185
Epoch 50, Val Loss: 83.61169
Epoch 51, Val Loss: 79.98134
Epoch 52, Val Loss: 82.05431
Epoch 53, Val Loss: 97.04452
Epoch 54, Val Loss: 82.30527
Epoch 55, Val Loss: 85.29893
Epoch 56, Val Loss: 88.13615
Epoch 57, Val Loss: 88.01015
Epoch 58, Val Loss: 83.18875
Epoch 59, Val Loss: 87.59547
Epoch 60, Val Loss: 78.26465
Epoch 61, Val Loss: 76.09935
Epoch 62, Val Loss: 100.73756
Epoch 63, Val Loss: 79.34783
Epoch 64, Val Loss: 88.94167
Epoch 65, Val Loss: 77.20010
Epoch 66, Val Loss: 78.18923
Epoch 67, Val Loss: 78.80549
Epoch 68, Val Loss: 76.52969
Epoch 69, Val Loss: 77.32983
Epoch 70, Val Loss: 78.77344
Epoch 71, Val Loss: 79.98483
Epoch 72, Val Loss: 74.90961
Epoch 73, Val Loss: 77.86682
Epoch 74, Val Loss: 77.80291
Epoch 75, Val Loss: 78.67723
Epoch 76, Val Loss: 74.04209
Epoch 77, Val Loss: 76.28539
Epoch 78, Val Loss: 83.02646
Epoch 79, Val Loss: 80.16378
Epoch 80, Val Loss: 76.39231
Epoch 81, Val Loss: 76.57751
Epoch 82, Val Loss: 88.41313
Epoch 83, Val Loss: 75.11538
Epoch 84, Val Loss: 81.16995
Epoch 85, Val Loss: 75.62135
Epoch 86, Val Loss: 73.95631
Epoch 87, Val Loss: 84.86549
Epoch 88, Val Loss: 81.39902
Epoch 89, Val Loss: 75.09344
Epoch 90, Val Loss: 77.40125
Epoch 91, Val Loss: 77.04807
Epoch 92, Val Loss: 73.99762
Epoch 93, Val Loss: 76.66193
Epoch 94, Val Loss: 77.21127
Epoch 95, Val Loss: 84.62328
Epoch 96, Val Loss: 77.84804
Epoch 97, Val Loss: 72.99271
Epoch 98, Val Loss: 80.38750
Epoch 99, Val Loss: 74.77357
DID NOT SAVE RESULTS
{'MSE - mean': 78.10723603987859, 'MSE - std': 6.662822649983114, 'R2 - mean': 0.5147515913867302, 'R2 - std': 0.01865851180271469} 
 

Results After CV: {'MSE - mean': 78.10723603987859, 'MSE - std': 6.662822649983114, 'R2 - mean': 0.5147515913867302, 'R2 - std': 0.01865851180271469}
Train time: 410.59210924460206
Inference time: 0.18202152360463514
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 62 finished with value: 78.10723603987859 and parameters: {'p_m': 0.18858054381373185, 'alpha': 8.219314090269496, 'K': 2, 'beta': 6.304160746547912}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 715.29944
Epoch 1, Val Loss: 443.43594
Epoch 2, Val Loss: 169.33884
Epoch 3, Val Loss: 157.15707
Epoch 4, Val Loss: 137.94142
Epoch 5, Val Loss: 138.35347
Epoch 6, Val Loss: 134.40694
Epoch 7, Val Loss: 126.00974
Epoch 8, Val Loss: 125.98336
Epoch 9, Val Loss: 112.86324
Epoch 10, Val Loss: 113.04867
Epoch 11, Val Loss: 105.83124
Epoch 12, Val Loss: 111.68556
Epoch 13, Val Loss: 119.82050
Epoch 14, Val Loss: 109.69856
Epoch 15, Val Loss: 106.10827
Epoch 16, Val Loss: 104.46210
Epoch 17, Val Loss: 98.90377
Epoch 18, Val Loss: 114.71764
Epoch 19, Val Loss: 110.44135
Epoch 20, Val Loss: 105.98642
Epoch 21, Val Loss: 100.97564
Epoch 22, Val Loss: 92.95830
Epoch 23, Val Loss: 98.52625
Epoch 24, Val Loss: 108.01908
Epoch 25, Val Loss: 96.83377
Epoch 26, Val Loss: 105.37251
Epoch 27, Val Loss: 95.01948
Epoch 28, Val Loss: 96.38588
Epoch 29, Val Loss: 99.68808
Epoch 30, Val Loss: 97.13593
Epoch 31, Val Loss: 98.82684
Epoch 32, Val Loss: 98.12234
Epoch 33, Val Loss: 105.03566
Epoch 34, Val Loss: 102.35738
Epoch 35, Val Loss: 100.58089
Epoch 36, Val Loss: 96.71634
Epoch 37, Val Loss: 97.09583
Epoch 38, Val Loss: 98.11562
Epoch 39, Val Loss: 96.83284
Epoch 40, Val Loss: 99.41313
Epoch 41, Val Loss: 98.42581
Epoch 42, Val Loss: 104.76983
Epoch 43, Val Loss: 93.19796
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 98.95957194081534, 'MSE - std': 0.0, 'R2 - mean': 0.42332965380063303, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1204.94165
Epoch 1, Val Loss: 382.56104
Epoch 2, Val Loss: 152.73660
Epoch 3, Val Loss: 138.02696
Epoch 4, Val Loss: 115.95352
Epoch 5, Val Loss: 108.97427
Epoch 6, Val Loss: 104.81416
Epoch 7, Val Loss: 107.12160
Epoch 8, Val Loss: 97.47254
Epoch 9, Val Loss: 91.95644
Epoch 10, Val Loss: 96.77837
Epoch 11, Val Loss: 105.17219
Epoch 12, Val Loss: 91.70035
Epoch 13, Val Loss: 86.85625
Epoch 14, Val Loss: 97.84556
Epoch 15, Val Loss: 88.75623
Epoch 16, Val Loss: 82.44543
Epoch 17, Val Loss: 87.09804
Epoch 18, Val Loss: 101.48773
Epoch 19, Val Loss: 87.12414
Epoch 20, Val Loss: 92.53229
Epoch 21, Val Loss: 82.54424
Epoch 22, Val Loss: 80.99478
Epoch 23, Val Loss: 102.54449
Epoch 24, Val Loss: 80.83781
Epoch 25, Val Loss: 82.60969
Epoch 26, Val Loss: 81.69139
Epoch 27, Val Loss: 90.39651
Epoch 28, Val Loss: 87.46537
Epoch 29, Val Loss: 86.37424
Epoch 30, Val Loss: 95.89194
Epoch 31, Val Loss: 82.80878
Epoch 32, Val Loss: 84.81278
Epoch 33, Val Loss: 90.46452
Epoch 34, Val Loss: 88.33157
Epoch 35, Val Loss: 89.22928
Epoch 36, Val Loss: 77.32605
Epoch 37, Val Loss: 87.60945
Epoch 38, Val Loss: 81.46738
Epoch 39, Val Loss: 78.01043
Epoch 40, Val Loss: 82.24529
Epoch 41, Val Loss: 83.65559
Epoch 42, Val Loss: 78.23736
Epoch 43, Val Loss: 76.73318
Epoch 44, Val Loss: 74.47762
Epoch 45, Val Loss: 86.22057
Epoch 46, Val Loss: 73.47677
Epoch 47, Val Loss: 87.51515
Epoch 48, Val Loss: 77.23077
Epoch 49, Val Loss: 78.63716
Epoch 50, Val Loss: 74.49572
Epoch 51, Val Loss: 74.49110
Epoch 52, Val Loss: 77.69786
Epoch 53, Val Loss: 81.76035
Epoch 54, Val Loss: 83.60519
Epoch 55, Val Loss: 81.48059
Epoch 56, Val Loss: 79.10059
Epoch 57, Val Loss: 73.04763
Epoch 58, Val Loss: 77.87737
Epoch 59, Val Loss: 71.49637
Epoch 60, Val Loss: 77.10023
Epoch 61, Val Loss: 75.64983
Epoch 62, Val Loss: 69.64716
Epoch 63, Val Loss: 70.28819
Epoch 64, Val Loss: 85.26505
Epoch 65, Val Loss: 73.51675
Epoch 66, Val Loss: 73.20141
Epoch 67, Val Loss: 81.45796
Epoch 68, Val Loss: 70.10551
Epoch 69, Val Loss: 71.90709
Epoch 70, Val Loss: 78.02371
Epoch 71, Val Loss: 68.00063
Epoch 72, Val Loss: 74.08573
Epoch 73, Val Loss: 70.61242
Epoch 74, Val Loss: 80.97247
Epoch 75, Val Loss: 69.95879
Epoch 76, Val Loss: 87.74259
Epoch 77, Val Loss: 68.86864
Epoch 78, Val Loss: 79.12973
Epoch 79, Val Loss: 81.75475
Epoch 80, Val Loss: 71.11612
Epoch 81, Val Loss: 72.05911
Epoch 82, Val Loss: 83.86429
Epoch 83, Val Loss: 67.31239
Epoch 84, Val Loss: 70.85378
Epoch 85, Val Loss: 71.50848
Epoch 86, Val Loss: 76.76011
Epoch 87, Val Loss: 70.96638
Epoch 88, Val Loss: 70.78365
Epoch 89, Val Loss: 69.03395
Epoch 90, Val Loss: 70.47302
Epoch 91, Val Loss: 68.64535
Epoch 92, Val Loss: 68.60899
Epoch 93, Val Loss: 67.62164
Epoch 94, Val Loss: 81.17048
Epoch 95, Val Loss: 71.84812
Epoch 96, Val Loss: 71.29789
Epoch 97, Val Loss: 70.91473
Epoch 98, Val Loss: 72.33379
Epoch 99, Val Loss: 76.98813
DID NOT SAVE RESULTS
{'MSE - mean': 87.15540976723915, 'MSE - std': 11.80416217357618, 'R2 - mean': 0.47129507875318033, 'R2 - std': 0.0479654249525473} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 421.33362
Epoch 1, Val Loss: 273.16193
Epoch 2, Val Loss: 141.72685
Epoch 3, Val Loss: 117.73772
Epoch 4, Val Loss: 103.27762
Epoch 5, Val Loss: 122.11786
Epoch 6, Val Loss: 93.22467
Epoch 7, Val Loss: 98.79737
Epoch 8, Val Loss: 85.16216
Epoch 9, Val Loss: 86.56869
Epoch 10, Val Loss: 117.74366
Epoch 11, Val Loss: 86.95405
Epoch 12, Val Loss: 86.42831
Epoch 13, Val Loss: 88.42464
Epoch 14, Val Loss: 91.19163
Epoch 15, Val Loss: 80.10121
Epoch 16, Val Loss: 79.11351
Epoch 17, Val Loss: 81.61715
Epoch 18, Val Loss: 83.51357
Epoch 19, Val Loss: 80.37500
Epoch 20, Val Loss: 84.39990
Epoch 21, Val Loss: 82.94668
Epoch 22, Val Loss: 88.85751
Epoch 23, Val Loss: 83.12674
Epoch 24, Val Loss: 108.36741
Epoch 25, Val Loss: 84.45115
Epoch 26, Val Loss: 78.60376
Epoch 27, Val Loss: 76.72841
Epoch 28, Val Loss: 89.82626
Epoch 29, Val Loss: 106.06296
Epoch 30, Val Loss: 78.95775
Epoch 31, Val Loss: 83.88001
Epoch 32, Val Loss: 75.64484
Epoch 33, Val Loss: 78.38516
Epoch 34, Val Loss: 82.22240
Epoch 35, Val Loss: 74.29225
Epoch 36, Val Loss: 75.72765
Epoch 37, Val Loss: 72.76085
Epoch 38, Val Loss: 81.62189
Epoch 39, Val Loss: 75.99679
Epoch 40, Val Loss: 77.74806
Epoch 41, Val Loss: 74.61414
Epoch 42, Val Loss: 81.33919
Epoch 43, Val Loss: 75.53271
Epoch 44, Val Loss: 73.94447
Epoch 45, Val Loss: 82.67147
Epoch 46, Val Loss: 84.60481
Epoch 47, Val Loss: 74.60049
Epoch 48, Val Loss: 101.26508
Epoch 49, Val Loss: 75.54190
Epoch 50, Val Loss: 74.86899
Epoch 51, Val Loss: 88.71504
Epoch 52, Val Loss: 71.38688
Epoch 53, Val Loss: 74.45824
Epoch 54, Val Loss: 71.94472
Epoch 55, Val Loss: 73.47403
Epoch 56, Val Loss: 76.38179
Epoch 57, Val Loss: 72.13981
Epoch 58, Val Loss: 76.51936
Epoch 59, Val Loss: 78.06636
Epoch 60, Val Loss: 70.45055
Epoch 61, Val Loss: 77.21106
Epoch 62, Val Loss: 72.76661
Epoch 63, Val Loss: 85.49551
Epoch 64, Val Loss: 72.09865
Epoch 65, Val Loss: 74.85113
Epoch 66, Val Loss: 79.02541
Epoch 67, Val Loss: 67.80907
Epoch 68, Val Loss: 95.17409
Epoch 69, Val Loss: 77.99788
Epoch 70, Val Loss: 68.80638
Epoch 71, Val Loss: 73.17548
Epoch 72, Val Loss: 70.76570
Epoch 73, Val Loss: 71.22006
Epoch 74, Val Loss: 76.86637
Epoch 75, Val Loss: 71.09660
Epoch 76, Val Loss: 73.99020
Epoch 77, Val Loss: 83.23876
Epoch 78, Val Loss: 69.98792
Epoch 79, Val Loss: 69.44271
Epoch 80, Val Loss: 69.02988
Epoch 81, Val Loss: 67.37669
Epoch 82, Val Loss: 81.92439
Epoch 83, Val Loss: 69.27161
Epoch 84, Val Loss: 70.49388
Epoch 85, Val Loss: 78.38757
Epoch 86, Val Loss: 69.79986
Epoch 87, Val Loss: 77.82545
Epoch 88, Val Loss: 78.75578
Epoch 89, Val Loss: 81.16631
Epoch 90, Val Loss: 71.52376
Epoch 91, Val Loss: 71.43471
Epoch 92, Val Loss: 68.09116
Epoch 93, Val Loss: 68.43233
Epoch 94, Val Loss: 69.21512
Epoch 95, Val Loss: 69.49709
Epoch 96, Val Loss: 80.35554
Epoch 97, Val Loss: 68.57340
Epoch 98, Val Loss: 72.41551
Epoch 99, Val Loss: 68.13412
DID NOT SAVE RESULTS
{'MSE - mean': 80.41089013100289, 'MSE - std': 13.559839723507467, 'R2 - mean': 0.49760016500995263, 'R2 - std': 0.054015767326507785} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1256.43457
Epoch 1, Val Loss: 434.84061
Epoch 2, Val Loss: 165.58710
Epoch 3, Val Loss: 139.72488
Epoch 4, Val Loss: 143.40594
Epoch 5, Val Loss: 121.44971
Epoch 6, Val Loss: 117.44674
Epoch 7, Val Loss: 108.65839
Epoch 8, Val Loss: 103.52806
Epoch 9, Val Loss: 103.55656
Epoch 10, Val Loss: 105.90910
Epoch 11, Val Loss: 110.47948
Epoch 12, Val Loss: 103.92776
Epoch 13, Val Loss: 110.04861
Epoch 14, Val Loss: 93.13541
Epoch 15, Val Loss: 91.17897
Epoch 16, Val Loss: 106.78824
Epoch 17, Val Loss: 96.95920
Epoch 18, Val Loss: 96.29183
Epoch 19, Val Loss: 94.03083
Epoch 20, Val Loss: 98.89811
Epoch 21, Val Loss: 94.37081
Epoch 22, Val Loss: 102.29247
Epoch 23, Val Loss: 96.66074
Epoch 24, Val Loss: 88.88466
Epoch 25, Val Loss: 85.85896
Epoch 26, Val Loss: 95.33842
Epoch 27, Val Loss: 91.62153
Epoch 28, Val Loss: 86.47270
Epoch 29, Val Loss: 96.24118
Epoch 30, Val Loss: 90.55748
Epoch 31, Val Loss: 95.01509
Epoch 32, Val Loss: 86.05853
Epoch 33, Val Loss: 93.44735
Epoch 34, Val Loss: 88.36938
Epoch 35, Val Loss: 91.70274
Epoch 36, Val Loss: 88.29118
Epoch 37, Val Loss: 94.32492
Epoch 38, Val Loss: 93.59305
Epoch 39, Val Loss: 95.10728
Epoch 40, Val Loss: 92.95940
Epoch 41, Val Loss: 95.42516
Epoch 42, Val Loss: 86.55224
Epoch 43, Val Loss: 91.60645
Epoch 44, Val Loss: 84.17303
Epoch 45, Val Loss: 89.97157
Epoch 46, Val Loss: 83.02367
Epoch 47, Val Loss: 95.58021
Epoch 48, Val Loss: 92.03062
Epoch 49, Val Loss: 84.72878
Epoch 50, Val Loss: 95.45689
Epoch 51, Val Loss: 85.64631
Epoch 52, Val Loss: 83.90151
Epoch 53, Val Loss: 83.89924
Epoch 54, Val Loss: 81.79048
Epoch 55, Val Loss: 85.15936
Epoch 56, Val Loss: 92.98783
Epoch 57, Val Loss: 83.35037
Epoch 58, Val Loss: 81.76447
Epoch 59, Val Loss: 91.84931
Epoch 60, Val Loss: 84.29346
Epoch 61, Val Loss: 82.53605
Epoch 62, Val Loss: 87.80065
Epoch 63, Val Loss: 94.03117
Epoch 64, Val Loss: 82.05940
Epoch 65, Val Loss: 78.74789
Epoch 66, Val Loss: 78.61163
Epoch 67, Val Loss: 77.45232
Epoch 68, Val Loss: 88.98318
Epoch 69, Val Loss: 80.09628
Epoch 70, Val Loss: 78.76502
Epoch 71, Val Loss: 84.31738
Epoch 72, Val Loss: 81.89812
Epoch 73, Val Loss: 78.65675
Epoch 74, Val Loss: 84.21880
Epoch 75, Val Loss: 80.07462
Epoch 76, Val Loss: 80.92274
Epoch 77, Val Loss: 83.84640
Epoch 78, Val Loss: 75.44637
Epoch 79, Val Loss: 82.57780
Epoch 80, Val Loss: 80.33728
Epoch 81, Val Loss: 85.13340
Epoch 82, Val Loss: 80.32608
Epoch 83, Val Loss: 80.75124
Epoch 84, Val Loss: 77.64941
Epoch 85, Val Loss: 78.73998
Epoch 86, Val Loss: 81.59921
Epoch 87, Val Loss: 85.55107
Epoch 88, Val Loss: 80.99143
Epoch 89, Val Loss: 78.58606
Epoch 90, Val Loss: 80.07324
Epoch 91, Val Loss: 76.87466
Epoch 92, Val Loss: 80.39616
Epoch 93, Val Loss: 89.33180
Epoch 94, Val Loss: 76.32327
Epoch 95, Val Loss: 92.33266
Epoch 96, Val Loss: 78.32105
Epoch 97, Val Loss: 76.17612
Epoch 98, Val Loss: 80.95976
Epoch 99, Val Loss: 86.25406
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.59344845806082, 'MSE - std': 11.920456056128495, 'R2 - mean': 0.49564409082841354, 'R2 - std': 0.04690155667474825} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 679.29236
Epoch 1, Val Loss: 466.71909
Epoch 2, Val Loss: 163.45825
Epoch 3, Val Loss: 133.41783
Epoch 4, Val Loss: 113.34439
Epoch 5, Val Loss: 123.95644
Epoch 6, Val Loss: 107.52697
Epoch 7, Val Loss: 121.77551
Epoch 8, Val Loss: 118.28117
Epoch 9, Val Loss: 103.57462
Epoch 10, Val Loss: 100.22925
Epoch 11, Val Loss: 94.47172
Epoch 12, Val Loss: 90.86824
Epoch 13, Val Loss: 90.97157
Epoch 14, Val Loss: 90.31053
Epoch 15, Val Loss: 92.36121
Epoch 16, Val Loss: 89.31612
Epoch 17, Val Loss: 82.85183
Epoch 18, Val Loss: 94.02207
Epoch 19, Val Loss: 95.29601
Epoch 20, Val Loss: 91.14919
Epoch 21, Val Loss: 84.95432
Epoch 22, Val Loss: 87.86093
Epoch 23, Val Loss: 94.75865
Epoch 24, Val Loss: 95.87092
Epoch 25, Val Loss: 85.73611
Epoch 26, Val Loss: 93.27803
Epoch 27, Val Loss: 83.16450
Epoch 28, Val Loss: 88.61713
Epoch 29, Val Loss: 83.47452
Epoch 30, Val Loss: 83.87897
Epoch 31, Val Loss: 93.51122
Epoch 32, Val Loss: 84.38561
Epoch 33, Val Loss: 90.51264
Epoch 34, Val Loss: 103.47839
Epoch 35, Val Loss: 80.59731
Epoch 36, Val Loss: 80.69508
Epoch 37, Val Loss: 81.61970
Epoch 38, Val Loss: 105.09941
Epoch 39, Val Loss: 89.95678
Epoch 40, Val Loss: 98.06660
Epoch 41, Val Loss: 78.97504
Epoch 42, Val Loss: 86.27821
Epoch 43, Val Loss: 80.85801
Epoch 44, Val Loss: 74.27405
Epoch 45, Val Loss: 74.36455
Epoch 46, Val Loss: 79.68441
Epoch 47, Val Loss: 93.42924
Epoch 48, Val Loss: 87.14896
Epoch 49, Val Loss: 86.29212
Epoch 50, Val Loss: 106.93082
Epoch 51, Val Loss: 84.26761
Epoch 52, Val Loss: 78.35641
Epoch 53, Val Loss: 79.82939
Epoch 54, Val Loss: 85.93791
Epoch 55, Val Loss: 78.57812
Epoch 56, Val Loss: 78.45068
Epoch 57, Val Loss: 79.25264
Epoch 58, Val Loss: 78.68431
Epoch 59, Val Loss: 76.44298
Epoch 60, Val Loss: 86.31921
Epoch 61, Val Loss: 75.02513
Epoch 62, Val Loss: 83.20536
Epoch 63, Val Loss: 76.42148
Epoch 64, Val Loss: 77.61407
Epoch 65, Val Loss: 72.42651
Epoch 66, Val Loss: 93.60540
Epoch 67, Val Loss: 74.12708
Epoch 68, Val Loss: 73.19962
Epoch 69, Val Loss: 76.49096
Epoch 70, Val Loss: 82.25626
Epoch 71, Val Loss: 71.22798
Epoch 72, Val Loss: 84.81752
Epoch 73, Val Loss: 78.86732
Epoch 74, Val Loss: 76.88201
Epoch 75, Val Loss: 72.92135
Epoch 76, Val Loss: 81.00722
Epoch 77, Val Loss: 79.53487
Epoch 78, Val Loss: 76.29568
Epoch 79, Val Loss: 85.23554
Epoch 80, Val Loss: 71.43193
Epoch 81, Val Loss: 71.47954
Epoch 82, Val Loss: 75.61250
Epoch 83, Val Loss: 72.88006
Epoch 84, Val Loss: 74.51138
Epoch 85, Val Loss: 73.94436
Epoch 86, Val Loss: 73.67046
Epoch 87, Val Loss: 74.81622
Epoch 88, Val Loss: 79.65521
Epoch 89, Val Loss: 96.88700
Epoch 90, Val Loss: 74.83586
Epoch 91, Val Loss: 78.94293
Epoch 92, Val Loss: 77.28803
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.67628523550735, 'MSE - std': 11.33048442726607, 'R2 - mean': 0.5061958077730117, 'R2 - std': 0.046959128364220885} 
 

Results After CV: {'MSE - mean': 79.67628523550735, 'MSE - std': 11.33048442726607, 'R2 - mean': 0.5061958077730117, 'R2 - std': 0.046959128364220885}
Train time: 410.73167950900387
Inference time: 0.16780747760203668
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 63 finished with value: 79.67628523550735 and parameters: {'p_m': 0.17670368738252487, 'alpha': 8.856164386828098, 'K': 2, 'beta': 5.1241442881210535}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1366.47510
Epoch 1, Val Loss: 453.90433
Epoch 2, Val Loss: 189.13672
Epoch 3, Val Loss: 159.75293
Epoch 4, Val Loss: 138.27020
Epoch 5, Val Loss: 132.93286
Epoch 6, Val Loss: 118.81647
Epoch 7, Val Loss: 124.91022
Epoch 8, Val Loss: 115.29452
Epoch 9, Val Loss: 116.61609
Epoch 10, Val Loss: 105.24159
Epoch 11, Val Loss: 103.88103
Epoch 12, Val Loss: 104.41378
Epoch 13, Val Loss: 98.71124
Epoch 14, Val Loss: 103.40281
Epoch 15, Val Loss: 102.16120
Epoch 16, Val Loss: 101.64326
Epoch 17, Val Loss: 104.98781
Epoch 18, Val Loss: 99.09137
Epoch 19, Val Loss: 99.39152
Epoch 20, Val Loss: 132.00613
Epoch 21, Val Loss: 98.14647
Epoch 22, Val Loss: 100.36301
Epoch 23, Val Loss: 104.50927
Epoch 24, Val Loss: 112.21519
Epoch 25, Val Loss: 112.21494
Epoch 26, Val Loss: 94.97241
Epoch 27, Val Loss: 102.47179
Epoch 28, Val Loss: 100.13381
Epoch 29, Val Loss: 104.12383
Epoch 30, Val Loss: 99.65617
Epoch 31, Val Loss: 99.10855
Epoch 32, Val Loss: 101.59988
Epoch 33, Val Loss: 100.32660
Epoch 34, Val Loss: 98.87897
Epoch 35, Val Loss: 105.64427
Epoch 36, Val Loss: 106.23237
Epoch 37, Val Loss: 101.09044
Epoch 38, Val Loss: 108.52605
Epoch 39, Val Loss: 108.65026
Epoch 40, Val Loss: 101.21112
Epoch 41, Val Loss: 105.00758
Epoch 42, Val Loss: 99.94931
Epoch 43, Val Loss: 99.56999
Epoch 44, Val Loss: 103.73289
Epoch 45, Val Loss: 101.85265
Epoch 46, Val Loss: 117.76318
Epoch 47, Val Loss: 101.66975
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 99.2011119970841, 'MSE - std': 0.0, 'R2 - mean': 0.42192211954055325, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1389.50159
Epoch 1, Val Loss: 358.74625
Epoch 2, Val Loss: 180.69702
Epoch 3, Val Loss: 133.44235
Epoch 4, Val Loss: 115.12836
Epoch 5, Val Loss: 111.32684
Epoch 6, Val Loss: 104.48695
Epoch 7, Val Loss: 96.71436
Epoch 8, Val Loss: 100.15919
Epoch 9, Val Loss: 93.01847
Epoch 10, Val Loss: 96.01973
Epoch 11, Val Loss: 86.64415
Epoch 12, Val Loss: 87.31750
Epoch 13, Val Loss: 86.48235
Epoch 14, Val Loss: 81.37197
Epoch 15, Val Loss: 89.72584
Epoch 16, Val Loss: 91.16692
Epoch 17, Val Loss: 85.53835
Epoch 18, Val Loss: 89.39021
Epoch 19, Val Loss: 92.09141
Epoch 20, Val Loss: 84.71528
Epoch 21, Val Loss: 81.59167
Epoch 22, Val Loss: 114.53403
Epoch 23, Val Loss: 86.80002
Epoch 24, Val Loss: 82.71429
Epoch 25, Val Loss: 83.55447
Epoch 26, Val Loss: 89.07453
Epoch 27, Val Loss: 86.44972
Epoch 28, Val Loss: 92.41365
Epoch 29, Val Loss: 84.51884
Epoch 30, Val Loss: 84.08135
Epoch 31, Val Loss: 82.59370
Epoch 32, Val Loss: 82.16981
Epoch 33, Val Loss: 89.43243
Epoch 34, Val Loss: 92.22075
Epoch 35, Val Loss: 93.98626
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 95.16611770113346, 'MSE - std': 4.034994295950632, 'R2 - mean': 0.42025366101034417, 'R2 - std': 0.0016684585302090826} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1750.59619
Epoch 1, Val Loss: 324.49716
Epoch 2, Val Loss: 172.61647
Epoch 3, Val Loss: 148.52748
Epoch 4, Val Loss: 112.73097
Epoch 5, Val Loss: 98.44946
Epoch 6, Val Loss: 94.95166
Epoch 7, Val Loss: 94.35239
Epoch 8, Val Loss: 95.66816
Epoch 9, Val Loss: 95.49059
Epoch 10, Val Loss: 87.51582
Epoch 11, Val Loss: 85.22578
Epoch 12, Val Loss: 89.96361
Epoch 13, Val Loss: 87.21204
Epoch 14, Val Loss: 93.58621
Epoch 15, Val Loss: 84.65587
Epoch 16, Val Loss: 94.77029
Epoch 17, Val Loss: 87.87916
Epoch 18, Val Loss: 90.11131
Epoch 19, Val Loss: 84.58283
Epoch 20, Val Loss: 81.36751
Epoch 21, Val Loss: 103.49783
Epoch 22, Val Loss: 83.68591
Epoch 23, Val Loss: 85.57282
Epoch 24, Val Loss: 81.05539
Epoch 25, Val Loss: 79.92921
Epoch 26, Val Loss: 87.59515
Epoch 27, Val Loss: 91.78955
Epoch 28, Val Loss: 81.07819
Epoch 29, Val Loss: 87.40020
Epoch 30, Val Loss: 83.32513
Epoch 31, Val Loss: 79.93290
Epoch 32, Val Loss: 82.99800
Epoch 33, Val Loss: 80.40340
Epoch 34, Val Loss: 84.93573
Epoch 35, Val Loss: 96.62939
Epoch 36, Val Loss: 76.36115
Epoch 37, Val Loss: 79.39091
Epoch 38, Val Loss: 76.85266
Epoch 39, Val Loss: 77.98160
Epoch 40, Val Loss: 81.59064
Epoch 41, Val Loss: 73.10057
Epoch 42, Val Loss: 78.62631
Epoch 43, Val Loss: 79.16191
Epoch 44, Val Loss: 76.87538
Epoch 45, Val Loss: 80.23108
Epoch 46, Val Loss: 75.64182
Epoch 47, Val Loss: 80.22224
Epoch 48, Val Loss: 82.52092
Epoch 49, Val Loss: 79.80325
Epoch 50, Val Loss: 80.04031
Epoch 51, Val Loss: 83.54105
Epoch 52, Val Loss: 80.30653
Epoch 53, Val Loss: 74.64619
Epoch 54, Val Loss: 76.54485
Epoch 55, Val Loss: 74.07461
Epoch 56, Val Loss: 82.67628
Epoch 57, Val Loss: 83.13913
Epoch 58, Val Loss: 77.25943
Epoch 59, Val Loss: 77.31905
Epoch 60, Val Loss: 83.21008
Epoch 61, Val Loss: 91.77016
Epoch 62, Val Loss: 74.05956
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.20521248507832, 'MSE - std': 10.380872900004281, 'R2 - mean': 0.44707993487824815, 'R2 - std': 0.03796253120094765} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1230.42932
Epoch 1, Val Loss: 368.89441
Epoch 2, Val Loss: 151.11714
Epoch 3, Val Loss: 130.03667
Epoch 4, Val Loss: 124.45660
Epoch 5, Val Loss: 117.54440
Epoch 6, Val Loss: 123.42986
Epoch 7, Val Loss: 115.01900
Epoch 8, Val Loss: 101.87711
Epoch 9, Val Loss: 111.41205
Epoch 10, Val Loss: 109.05422
Epoch 11, Val Loss: 103.42481
Epoch 12, Val Loss: 99.04684
Epoch 13, Val Loss: 104.24806
Epoch 14, Val Loss: 108.53796
Epoch 15, Val Loss: 93.42910
Epoch 16, Val Loss: 103.09144
Epoch 17, Val Loss: 95.24685
Epoch 18, Val Loss: 105.25241
Epoch 19, Val Loss: 104.58515
Epoch 20, Val Loss: 99.62360
Epoch 21, Val Loss: 95.69553
Epoch 22, Val Loss: 99.08065
Epoch 23, Val Loss: 97.82192
Epoch 24, Val Loss: 93.82374
Epoch 25, Val Loss: 94.03672
Epoch 26, Val Loss: 106.12021
Epoch 27, Val Loss: 93.38596
Epoch 28, Val Loss: 103.08885
Epoch 29, Val Loss: 93.35782
Epoch 30, Val Loss: 98.13201
Epoch 31, Val Loss: 89.69173
Epoch 32, Val Loss: 110.97383
Epoch 33, Val Loss: 105.67557
Epoch 34, Val Loss: 97.62125
Epoch 35, Val Loss: 91.87316
Epoch 36, Val Loss: 94.69997
Epoch 37, Val Loss: 98.75079
Epoch 38, Val Loss: 97.17983
Epoch 39, Val Loss: 91.78044
Epoch 40, Val Loss: 91.80308
Epoch 41, Val Loss: 93.91458
Epoch 42, Val Loss: 96.42684
Epoch 43, Val Loss: 109.93018
Epoch 44, Val Loss: 99.68749
Epoch 45, Val Loss: 92.62838
Epoch 46, Val Loss: 87.61378
Epoch 47, Val Loss: 89.54832
Epoch 48, Val Loss: 93.13244
Epoch 49, Val Loss: 89.11951
Epoch 50, Val Loss: 96.06837
Epoch 51, Val Loss: 87.68642
Epoch 52, Val Loss: 89.73122
Epoch 53, Val Loss: 87.60953
Epoch 54, Val Loss: 92.48127
Epoch 55, Val Loss: 89.57866
Epoch 56, Val Loss: 89.60913
Epoch 57, Val Loss: 87.02172
Epoch 58, Val Loss: 92.21376
Epoch 59, Val Loss: 86.16904
Epoch 60, Val Loss: 93.98232
Epoch 61, Val Loss: 87.14099
Epoch 62, Val Loss: 84.59315
Epoch 63, Val Loss: 89.59124
Epoch 64, Val Loss: 89.91801
Epoch 65, Val Loss: 82.12500
Epoch 66, Val Loss: 89.07589
Epoch 67, Val Loss: 86.88751
Epoch 68, Val Loss: 93.95368
Epoch 69, Val Loss: 85.33055
Epoch 70, Val Loss: 84.28944
Epoch 71, Val Loss: 93.87508
Epoch 72, Val Loss: 89.86359
Epoch 73, Val Loss: 91.04444
Epoch 74, Val Loss: 80.69739
Epoch 75, Val Loss: 85.26776
Epoch 76, Val Loss: 92.26329
Epoch 77, Val Loss: 91.10043
Epoch 78, Val Loss: 84.26899
Epoch 79, Val Loss: 87.78857
Epoch 80, Val Loss: 93.69350
Epoch 81, Val Loss: 93.76439
Epoch 82, Val Loss: 83.39847
Epoch 83, Val Loss: 79.62212
Epoch 84, Val Loss: 81.71120
Epoch 85, Val Loss: 85.42889
Epoch 86, Val Loss: 82.11111
Epoch 87, Val Loss: 78.18963
Epoch 88, Val Loss: 90.44051
Epoch 89, Val Loss: 87.21829
Epoch 90, Val Loss: 81.02367
Epoch 91, Val Loss: 79.32008
Epoch 92, Val Loss: 79.93654
Epoch 93, Val Loss: 82.37601
Epoch 94, Val Loss: 76.58183
Epoch 95, Val Loss: 78.57785
Epoch 96, Val Loss: 79.66772
Epoch 97, Val Loss: 77.00467
Epoch 98, Val Loss: 78.45392
Epoch 99, Val Loss: 83.86390
DID NOT SAVE RESULTS
{'MSE - mean': 88.04367008284595, 'MSE - std': 8.994452705289493, 'R2 - mean': 0.45413145943585453, 'R2 - std': 0.035071887989481985} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1577.11670
Epoch 1, Val Loss: 471.79147
Epoch 2, Val Loss: 184.36868
Epoch 3, Val Loss: 138.08403
Epoch 4, Val Loss: 136.32535
Epoch 5, Val Loss: 130.52853
Epoch 6, Val Loss: 106.86831
Epoch 7, Val Loss: 101.51463
Epoch 8, Val Loss: 105.01291
Epoch 9, Val Loss: 104.23264
Epoch 10, Val Loss: 95.41716
Epoch 11, Val Loss: 94.58841
Epoch 12, Val Loss: 88.84616
Epoch 13, Val Loss: 95.95950
Epoch 14, Val Loss: 104.15491
Epoch 15, Val Loss: 97.96941
Epoch 16, Val Loss: 111.26428
Epoch 17, Val Loss: 88.79005
Epoch 18, Val Loss: 99.78771
Epoch 19, Val Loss: 90.74296
Epoch 20, Val Loss: 90.75768
Epoch 21, Val Loss: 92.70827
Epoch 22, Val Loss: 87.76025
Epoch 23, Val Loss: 103.43449
Epoch 24, Val Loss: 90.51597
Epoch 25, Val Loss: 100.29329
Epoch 26, Val Loss: 91.82503
Epoch 27, Val Loss: 90.56500
Epoch 28, Val Loss: 96.00612
Epoch 29, Val Loss: 93.11652
Epoch 30, Val Loss: 88.32417
Epoch 31, Val Loss: 101.68757
Epoch 32, Val Loss: 89.41254
Epoch 33, Val Loss: 88.60133
Epoch 34, Val Loss: 92.02199
Epoch 35, Val Loss: 86.20887
Epoch 36, Val Loss: 86.70921
Epoch 37, Val Loss: 84.84322
Epoch 38, Val Loss: 100.55800
Epoch 39, Val Loss: 88.22930
Epoch 40, Val Loss: 88.30676
Epoch 41, Val Loss: 98.42142
Epoch 42, Val Loss: 88.88786
Epoch 43, Val Loss: 87.58760
Epoch 44, Val Loss: 85.48605
Epoch 45, Val Loss: 83.17403
Epoch 46, Val Loss: 99.74721
Epoch 47, Val Loss: 81.19042
Epoch 48, Val Loss: 79.93971
Epoch 49, Val Loss: 81.94662
Epoch 50, Val Loss: 89.34338
Epoch 51, Val Loss: 91.94386
Epoch 52, Val Loss: 86.72283
Epoch 53, Val Loss: 89.87510
Epoch 54, Val Loss: 82.08029
Epoch 55, Val Loss: 93.58788
Epoch 56, Val Loss: 90.11295
Epoch 57, Val Loss: 85.61493
Epoch 58, Val Loss: 82.58998
Epoch 59, Val Loss: 89.64664
Epoch 60, Val Loss: 82.16336
Epoch 61, Val Loss: 78.26528
Epoch 62, Val Loss: 86.41153
Epoch 63, Val Loss: 97.67189
Epoch 64, Val Loss: 83.82140
Epoch 65, Val Loss: 82.21866
Epoch 66, Val Loss: 87.78941
Epoch 67, Val Loss: 76.17259
Epoch 68, Val Loss: 120.27176
Epoch 69, Val Loss: 86.53300
Epoch 70, Val Loss: 88.79079
Epoch 71, Val Loss: 85.94957
Epoch 72, Val Loss: 94.97330
Epoch 73, Val Loss: 82.70916
Epoch 74, Val Loss: 81.01295
Epoch 75, Val Loss: 89.92714
Epoch 76, Val Loss: 76.98190
Epoch 77, Val Loss: 80.08543
Epoch 78, Val Loss: 82.50499
Epoch 79, Val Loss: 79.02787
Epoch 80, Val Loss: 81.02010
Epoch 81, Val Loss: 77.51362
Epoch 82, Val Loss: 78.60912
Epoch 83, Val Loss: 79.57073
Epoch 84, Val Loss: 82.36935
Epoch 85, Val Loss: 79.95941
Epoch 86, Val Loss: 112.24841
Epoch 87, Val Loss: 93.63472
Epoch 88, Val Loss: 75.99995
Epoch 89, Val Loss: 83.11833
Epoch 90, Val Loss: 76.94151
Epoch 91, Val Loss: 78.92851
Epoch 92, Val Loss: 76.99514
Epoch 93, Val Loss: 75.43970
Epoch 94, Val Loss: 78.94052
Epoch 95, Val Loss: 80.77992
Epoch 96, Val Loss: 80.71873
Epoch 97, Val Loss: 78.10795
Epoch 98, Val Loss: 82.49426
Epoch 99, Val Loss: 72.78728
DID NOT SAVE RESULTS
{'MSE - mean': 85.41085002871269, 'MSE - std': 9.61494198234897, 'R2 - mean': 0.46938341986257903, 'R2 - std': 0.043755217393482385} 
 

Results After CV: {'MSE - mean': 85.41085002871269, 'MSE - std': 9.61494198234897, 'R2 - mean': 0.46938341986257903, 'R2 - std': 0.043755217393482385}
Train time: 327.2285763816035
Inference time: 0.19786130000138655
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 64 finished with value: 85.41085002871269 and parameters: {'p_m': 0.10249972291903081, 'alpha': 9.317283941255756, 'K': 2, 'beta': 6.248748563863077}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 599.31305
Epoch 1, Val Loss: 335.67575
Epoch 2, Val Loss: 180.99229
Epoch 3, Val Loss: 138.88905
Epoch 4, Val Loss: 121.46890
Epoch 5, Val Loss: 129.20509
Epoch 6, Val Loss: 117.00506
Epoch 7, Val Loss: 105.59218
Epoch 8, Val Loss: 112.83214
Epoch 9, Val Loss: 104.64909
Epoch 10, Val Loss: 108.16562
Epoch 11, Val Loss: 105.55608
Epoch 12, Val Loss: 110.05843
Epoch 13, Val Loss: 105.62535
Epoch 14, Val Loss: 121.51822
Epoch 15, Val Loss: 102.48731
Epoch 16, Val Loss: 108.73922
Epoch 17, Val Loss: 101.45445
Epoch 18, Val Loss: 99.85240
Epoch 19, Val Loss: 121.77992
Epoch 20, Val Loss: 103.69485
Epoch 21, Val Loss: 101.36682
Epoch 22, Val Loss: 98.67744
Epoch 23, Val Loss: 106.21288
Epoch 24, Val Loss: 94.16249
Epoch 25, Val Loss: 101.50024
Epoch 26, Val Loss: 99.72026
Epoch 27, Val Loss: 102.27228
Epoch 28, Val Loss: 106.37123
Epoch 29, Val Loss: 98.51034
Epoch 30, Val Loss: 105.27819
Epoch 31, Val Loss: 100.43133
Epoch 32, Val Loss: 100.91607
Epoch 33, Val Loss: 112.26865
Epoch 34, Val Loss: 106.53355
Epoch 35, Val Loss: 95.81298
Epoch 36, Val Loss: 99.47760
Epoch 37, Val Loss: 98.10028
Epoch 38, Val Loss: 95.83849
Epoch 39, Val Loss: 102.90652
Epoch 40, Val Loss: 105.57872
Epoch 41, Val Loss: 104.40140
Epoch 42, Val Loss: 94.52938
Epoch 43, Val Loss: 99.56177
Epoch 44, Val Loss: 90.64469
Epoch 45, Val Loss: 96.74197
Epoch 46, Val Loss: 94.87854
Epoch 47, Val Loss: 106.32242
Epoch 48, Val Loss: 87.20641
Epoch 49, Val Loss: 96.92184
Epoch 50, Val Loss: 90.55463
Epoch 51, Val Loss: 97.82767
Epoch 52, Val Loss: 97.75529
Epoch 53, Val Loss: 94.56189
Epoch 54, Val Loss: 92.86656
Epoch 55, Val Loss: 87.25637
Epoch 56, Val Loss: 94.67429
Epoch 57, Val Loss: 90.72388
Epoch 58, Val Loss: 88.17078
Epoch 59, Val Loss: 88.48286
Epoch 60, Val Loss: 88.14913
Epoch 61, Val Loss: 88.33643
Epoch 62, Val Loss: 89.98947
Epoch 63, Val Loss: 92.77216
Epoch 64, Val Loss: 90.39909
Epoch 65, Val Loss: 88.60414
Epoch 66, Val Loss: 98.17026
Epoch 67, Val Loss: 91.56200
Epoch 68, Val Loss: 86.67947
Epoch 69, Val Loss: 97.79936
Epoch 70, Val Loss: 99.27422
Epoch 71, Val Loss: 84.84808
Epoch 72, Val Loss: 87.76444
Epoch 73, Val Loss: 87.00259
Epoch 74, Val Loss: 90.18674
Epoch 75, Val Loss: 85.63388
Epoch 76, Val Loss: 95.15031
Epoch 77, Val Loss: 91.95007
Epoch 78, Val Loss: 90.05252
Epoch 79, Val Loss: 94.53175
Epoch 80, Val Loss: 100.54131
Epoch 81, Val Loss: 93.72972
Epoch 82, Val Loss: 85.83485
Epoch 83, Val Loss: 92.26588
Epoch 84, Val Loss: 85.85897
Epoch 85, Val Loss: 84.74128
Epoch 86, Val Loss: 85.87856
Epoch 87, Val Loss: 89.35737
Epoch 88, Val Loss: 91.83478
Epoch 89, Val Loss: 89.97938
Epoch 90, Val Loss: 98.59199
Epoch 91, Val Loss: 82.91412
Epoch 92, Val Loss: 85.39758
Epoch 93, Val Loss: 88.13691
Epoch 94, Val Loss: 85.65193
Epoch 95, Val Loss: 84.79272
Epoch 96, Val Loss: 83.05215
Epoch 97, Val Loss: 92.74921
Epoch 98, Val Loss: 86.59458
Epoch 99, Val Loss: 84.38091
DID NOT SAVE RESULTS
{'MSE - mean': 87.94821401472373, 'MSE - std': 0.0, 'R2 - mean': 0.4874964995420644, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1388.91248
Epoch 1, Val Loss: 417.38098
Epoch 2, Val Loss: 159.30075
Epoch 3, Val Loss: 142.25851
Epoch 4, Val Loss: 119.24499
Epoch 5, Val Loss: 103.64107
Epoch 6, Val Loss: 101.19968
Epoch 7, Val Loss: 88.98872
Epoch 8, Val Loss: 94.82508
Epoch 9, Val Loss: 93.69389
Epoch 10, Val Loss: 87.47360
Epoch 11, Val Loss: 91.85938
Epoch 12, Val Loss: 91.83669
Epoch 13, Val Loss: 85.56212
Epoch 14, Val Loss: 76.78316
Epoch 15, Val Loss: 90.90839
Epoch 16, Val Loss: 78.99883
Epoch 17, Val Loss: 82.16297
Epoch 18, Val Loss: 81.72031
Epoch 19, Val Loss: 81.69257
Epoch 20, Val Loss: 81.91087
Epoch 21, Val Loss: 79.79404
Epoch 22, Val Loss: 83.09711
Epoch 23, Val Loss: 88.29021
Epoch 24, Val Loss: 86.71813
Epoch 25, Val Loss: 87.69402
Epoch 26, Val Loss: 82.40150
Epoch 27, Val Loss: 85.12776
Epoch 28, Val Loss: 77.45393
Epoch 29, Val Loss: 81.02472
Epoch 30, Val Loss: 87.02834
Epoch 31, Val Loss: 80.69908
Epoch 32, Val Loss: 83.30830
Epoch 33, Val Loss: 90.44691
Epoch 34, Val Loss: 94.08219
Epoch 35, Val Loss: 73.35045
Epoch 36, Val Loss: 80.94607
Epoch 37, Val Loss: 96.56820
Epoch 38, Val Loss: 83.95370
Epoch 39, Val Loss: 82.43552
Epoch 40, Val Loss: 79.58259
Epoch 41, Val Loss: 88.78166
Epoch 42, Val Loss: 84.67319
Epoch 43, Val Loss: 76.57635
Epoch 44, Val Loss: 85.86199
Epoch 45, Val Loss: 129.70291
Epoch 46, Val Loss: 85.08398
Epoch 47, Val Loss: 80.73672
Epoch 48, Val Loss: 71.93329
Epoch 49, Val Loss: 75.20627
Epoch 50, Val Loss: 78.81786
Epoch 51, Val Loss: 83.15404
Epoch 52, Val Loss: 80.03136
Epoch 53, Val Loss: 75.37322
Epoch 54, Val Loss: 74.42987
Epoch 55, Val Loss: 76.35912
Epoch 56, Val Loss: 74.25219
Epoch 57, Val Loss: 76.86623
Epoch 58, Val Loss: 70.05706
Epoch 59, Val Loss: 74.37270
Epoch 60, Val Loss: 73.80072
Epoch 61, Val Loss: 77.10670
Epoch 62, Val Loss: 78.22312
Epoch 63, Val Loss: 73.55727
Epoch 64, Val Loss: 73.52892
Epoch 65, Val Loss: 76.01583
Epoch 66, Val Loss: 76.52361
Epoch 67, Val Loss: 75.42251
Epoch 68, Val Loss: 73.40364
Epoch 69, Val Loss: 69.56839
Epoch 70, Val Loss: 80.10211
Epoch 71, Val Loss: 70.14376
Epoch 72, Val Loss: 78.83733
Epoch 73, Val Loss: 73.80703
Epoch 74, Val Loss: 68.15639
Epoch 75, Val Loss: 84.29097
Epoch 76, Val Loss: 70.47190
Epoch 77, Val Loss: 89.45050
Epoch 78, Val Loss: 74.43426
Epoch 79, Val Loss: 81.14722
Epoch 80, Val Loss: 70.58985
Epoch 81, Val Loss: 72.19627
Epoch 82, Val Loss: 73.52323
Epoch 83, Val Loss: 70.61240
Epoch 84, Val Loss: 78.83987
Epoch 85, Val Loss: 67.62376
Epoch 86, Val Loss: 69.05800
Epoch 87, Val Loss: 68.06915
Epoch 88, Val Loss: 66.58299
Epoch 89, Val Loss: 71.59181
Epoch 90, Val Loss: 68.93230
Epoch 91, Val Loss: 70.62597
Epoch 92, Val Loss: 74.35258
Epoch 93, Val Loss: 71.59826
Epoch 94, Val Loss: 69.54744
Epoch 95, Val Loss: 67.05541
Epoch 96, Val Loss: 68.97609
Epoch 97, Val Loss: 68.25071
Epoch 98, Val Loss: 83.50053
Epoch 99, Val Loss: 68.22025
DID NOT SAVE RESULTS
{'MSE - mean': 81.34636813948464, 'MSE - std': 6.601845875239086, 'R2 - mean': 0.5053139495333057, 'R2 - std': 0.017817449991241185} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 750.70959
Epoch 1, Val Loss: 329.33905
Epoch 2, Val Loss: 174.39694
Epoch 3, Val Loss: 140.36536
Epoch 4, Val Loss: 107.13121
Epoch 5, Val Loss: 110.41048
Epoch 6, Val Loss: 95.96004
Epoch 7, Val Loss: 91.41681
Epoch 8, Val Loss: 91.35521
Epoch 9, Val Loss: 98.55371
Epoch 10, Val Loss: 87.45312
Epoch 11, Val Loss: 90.49350
Epoch 12, Val Loss: 90.04376
Epoch 13, Val Loss: 87.57666
Epoch 14, Val Loss: 86.59301
Epoch 15, Val Loss: 83.17058
Epoch 16, Val Loss: 94.18326
Epoch 17, Val Loss: 79.36777
Epoch 18, Val Loss: 83.41572
Epoch 19, Val Loss: 88.85234
Epoch 20, Val Loss: 85.57900
Epoch 21, Val Loss: 103.75610
Epoch 22, Val Loss: 92.13954
Epoch 23, Val Loss: 101.60080
Epoch 24, Val Loss: 88.45050
Epoch 25, Val Loss: 86.49479
Epoch 26, Val Loss: 86.60252
Epoch 27, Val Loss: 90.01421
Epoch 28, Val Loss: 90.87544
Epoch 29, Val Loss: 87.35190
Epoch 30, Val Loss: 81.95013
Epoch 31, Val Loss: 83.30811
Epoch 32, Val Loss: 84.86743
Epoch 33, Val Loss: 74.88165
Epoch 34, Val Loss: 83.69816
Epoch 35, Val Loss: 76.06986
Epoch 36, Val Loss: 90.19259
Epoch 37, Val Loss: 78.23479
Epoch 38, Val Loss: 79.52026
Epoch 39, Val Loss: 77.17032
Epoch 40, Val Loss: 74.20292
Epoch 41, Val Loss: 83.32762
Epoch 42, Val Loss: 82.18411
Epoch 43, Val Loss: 94.91646
Epoch 44, Val Loss: 76.92057
Epoch 45, Val Loss: 82.86592
Epoch 46, Val Loss: 84.84248
Epoch 47, Val Loss: 79.97320
Epoch 48, Val Loss: 74.70163
Epoch 49, Val Loss: 77.57243
Epoch 50, Val Loss: 76.21292
Epoch 51, Val Loss: 78.79190
Epoch 52, Val Loss: 79.55228
Epoch 53, Val Loss: 77.32391
Epoch 54, Val Loss: 69.26968
Epoch 55, Val Loss: 71.41029
Epoch 56, Val Loss: 77.14956
Epoch 57, Val Loss: 77.74835
Epoch 58, Val Loss: 78.08259
Epoch 59, Val Loss: 68.40411
Epoch 60, Val Loss: 69.74727
Epoch 61, Val Loss: 71.36919
Epoch 62, Val Loss: 71.46606
Epoch 63, Val Loss: 69.13457
Epoch 64, Val Loss: 75.48005
Epoch 65, Val Loss: 72.36700
Epoch 66, Val Loss: 82.37351
Epoch 67, Val Loss: 90.02164
Epoch 68, Val Loss: 72.94501
Epoch 69, Val Loss: 68.06170
Epoch 70, Val Loss: 68.38763
Epoch 71, Val Loss: 67.39411
Epoch 72, Val Loss: 69.46670
Epoch 73, Val Loss: 74.53506
Epoch 74, Val Loss: 68.34444
Epoch 75, Val Loss: 81.33873
Epoch 76, Val Loss: 71.55264
Epoch 77, Val Loss: 73.11836
Epoch 78, Val Loss: 67.57129
Epoch 79, Val Loss: 67.85688
Epoch 80, Val Loss: 69.12428
Epoch 81, Val Loss: 69.68788
Epoch 82, Val Loss: 73.29501
Epoch 83, Val Loss: 87.35778
Epoch 84, Val Loss: 72.05249
Epoch 85, Val Loss: 68.23795
Epoch 86, Val Loss: 66.11850
Epoch 87, Val Loss: 79.08757
Epoch 88, Val Loss: 68.92476
Epoch 89, Val Loss: 68.67288
Epoch 90, Val Loss: 69.10747
Epoch 91, Val Loss: 68.89426
Epoch 92, Val Loss: 79.01602
Epoch 93, Val Loss: 73.21667
Epoch 94, Val Loss: 71.13234
Epoch 95, Val Loss: 70.86998
Epoch 96, Val Loss: 66.94025
Epoch 97, Val Loss: 69.40279
Epoch 98, Val Loss: 68.29926
Epoch 99, Val Loss: 68.95720
DID NOT SAVE RESULTS
{'MSE - mean': 76.47070507677184, 'MSE - std': 8.752166964575768, 'R2 - mean': 0.5207330247294556, 'R2 - std': 0.02621329387803012} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1077.51550
Epoch 1, Val Loss: 488.98907
Epoch 2, Val Loss: 161.63692
Epoch 3, Val Loss: 137.43796
Epoch 4, Val Loss: 120.77967
Epoch 5, Val Loss: 117.37328
Epoch 6, Val Loss: 109.68566
Epoch 7, Val Loss: 102.70662
Epoch 8, Val Loss: 105.71655
Epoch 9, Val Loss: 100.41405
Epoch 10, Val Loss: 99.40488
Epoch 11, Val Loss: 106.01537
Epoch 12, Val Loss: 93.67087
Epoch 13, Val Loss: 96.47962
Epoch 14, Val Loss: 95.14473
Epoch 15, Val Loss: 114.89709
Epoch 16, Val Loss: 109.48117
Epoch 17, Val Loss: 89.80030
Epoch 18, Val Loss: 97.46280
Epoch 19, Val Loss: 109.71680
Epoch 20, Val Loss: 100.00018
Epoch 21, Val Loss: 87.95314
Epoch 22, Val Loss: 92.78101
Epoch 23, Val Loss: 103.47565
Epoch 24, Val Loss: 95.55773
Epoch 25, Val Loss: 96.41986
Epoch 26, Val Loss: 89.58705
Epoch 27, Val Loss: 85.29487
Epoch 28, Val Loss: 90.24462
Epoch 29, Val Loss: 96.93849
Epoch 30, Val Loss: 84.56856
Epoch 31, Val Loss: 88.71011
Epoch 32, Val Loss: 86.24828
Epoch 33, Val Loss: 109.99027
Epoch 34, Val Loss: 85.46510
Epoch 35, Val Loss: 92.31005
Epoch 36, Val Loss: 101.10513
Epoch 37, Val Loss: 91.93800
Epoch 38, Val Loss: 91.95186
Epoch 39, Val Loss: 87.89821
Epoch 40, Val Loss: 89.96770
Epoch 41, Val Loss: 89.03433
Epoch 42, Val Loss: 89.16187
Epoch 43, Val Loss: 111.69455
Epoch 44, Val Loss: 88.79463
Epoch 45, Val Loss: 85.09018
Epoch 46, Val Loss: 86.97460
Epoch 47, Val Loss: 85.47022
Epoch 48, Val Loss: 94.59576
Epoch 49, Val Loss: 99.41126
Epoch 50, Val Loss: 83.57410
Epoch 51, Val Loss: 95.86485
Epoch 52, Val Loss: 85.52293
Epoch 53, Val Loss: 85.07217
Epoch 54, Val Loss: 88.98894
Epoch 55, Val Loss: 109.09927
Epoch 56, Val Loss: 82.38683
Epoch 57, Val Loss: 81.67413
Epoch 58, Val Loss: 81.55566
Epoch 59, Val Loss: 79.18156
Epoch 60, Val Loss: 81.96767
Epoch 61, Val Loss: 78.54070
Epoch 62, Val Loss: 87.47911
Epoch 63, Val Loss: 77.61083
Epoch 64, Val Loss: 87.68728
Epoch 65, Val Loss: 81.06986
Epoch 66, Val Loss: 78.78477
Epoch 67, Val Loss: 78.01826
Epoch 68, Val Loss: 81.11347
Epoch 69, Val Loss: 92.40248
Epoch 70, Val Loss: 80.01145
Epoch 71, Val Loss: 80.59480
Epoch 72, Val Loss: 78.64078
Epoch 73, Val Loss: 78.94379
Epoch 74, Val Loss: 82.88912
Epoch 75, Val Loss: 92.91303
Epoch 76, Val Loss: 82.06463
Epoch 77, Val Loss: 81.44558
Epoch 78, Val Loss: 86.09575
Epoch 79, Val Loss: 85.65530
Epoch 80, Val Loss: 79.21765
Epoch 81, Val Loss: 79.59351
Epoch 82, Val Loss: 82.01469
Epoch 83, Val Loss: 77.99181
Epoch 84, Val Loss: 80.74692
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.49137216856381, 'MSE - std': 9.209973342532724, 'R2 - mean': 0.5078815987753439, 'R2 - std': 0.03179355326342158} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 980.50262
Epoch 1, Val Loss: 450.21500
Epoch 2, Val Loss: 178.75543
Epoch 3, Val Loss: 136.12070
Epoch 4, Val Loss: 118.71712
Epoch 5, Val Loss: 106.98450
Epoch 6, Val Loss: 108.55658
Epoch 7, Val Loss: 95.22980
Epoch 8, Val Loss: 96.48027
Epoch 9, Val Loss: 100.32838
Epoch 10, Val Loss: 113.78423
Epoch 11, Val Loss: 96.92154
Epoch 12, Val Loss: 93.13052
Epoch 13, Val Loss: 99.34092
Epoch 14, Val Loss: 92.44296
Epoch 15, Val Loss: 89.50858
Epoch 16, Val Loss: 93.05432
Epoch 17, Val Loss: 85.81046
Epoch 18, Val Loss: 92.77622
Epoch 19, Val Loss: 93.03942
Epoch 20, Val Loss: 96.95522
Epoch 21, Val Loss: 82.74840
Epoch 22, Val Loss: 87.01711
Epoch 23, Val Loss: 88.68169
Epoch 24, Val Loss: 87.78585
Epoch 25, Val Loss: 88.59370
Epoch 26, Val Loss: 87.55570
Epoch 27, Val Loss: 93.69582
Epoch 28, Val Loss: 90.21108
Epoch 29, Val Loss: 81.72703
Epoch 30, Val Loss: 84.92517
Epoch 31, Val Loss: 88.27670
Epoch 32, Val Loss: 85.50979
Epoch 33, Val Loss: 89.01746
Epoch 34, Val Loss: 92.84236
Epoch 35, Val Loss: 95.12206
Epoch 36, Val Loss: 91.04074
Epoch 37, Val Loss: 83.96934
Epoch 38, Val Loss: 83.24028
Epoch 39, Val Loss: 84.03899
Epoch 40, Val Loss: 89.80676
Epoch 41, Val Loss: 86.98030
Epoch 42, Val Loss: 96.31075
Epoch 43, Val Loss: 84.12304
Epoch 44, Val Loss: 85.95716
Epoch 45, Val Loss: 96.00648
Epoch 46, Val Loss: 87.23723
Epoch 47, Val Loss: 87.90869
Epoch 48, Val Loss: 89.54050
Epoch 49, Val Loss: 86.63155
Epoch 50, Val Loss: 79.28548
Epoch 51, Val Loss: 80.13840
Epoch 52, Val Loss: 75.41098
Epoch 53, Val Loss: 75.74388
Epoch 54, Val Loss: 78.23421
Epoch 55, Val Loss: 78.52298
Epoch 56, Val Loss: 78.94466
Epoch 57, Val Loss: 78.95261
Epoch 58, Val Loss: 75.07333
Epoch 59, Val Loss: 92.24754
Epoch 60, Val Loss: 85.34480
Epoch 61, Val Loss: 77.69267
Epoch 62, Val Loss: 91.20592
Epoch 63, Val Loss: 82.29279
Epoch 64, Val Loss: 75.27470
Epoch 65, Val Loss: 79.57900
Epoch 66, Val Loss: 79.22544
Epoch 67, Val Loss: 88.31909
Epoch 68, Val Loss: 82.44881
Epoch 69, Val Loss: 81.62720
Epoch 70, Val Loss: 77.84795
Epoch 71, Val Loss: 77.69580
Epoch 72, Val Loss: 76.57831
Epoch 73, Val Loss: 82.99398
Epoch 74, Val Loss: 83.44643
Epoch 75, Val Loss: 77.53519
Epoch 76, Val Loss: 74.87041
Epoch 77, Val Loss: 79.11181
Epoch 78, Val Loss: 84.16011
Epoch 79, Val Loss: 75.36883
Epoch 80, Val Loss: 77.98311
Epoch 81, Val Loss: 75.35295
Epoch 82, Val Loss: 79.24849
Epoch 83, Val Loss: 77.06668
Epoch 84, Val Loss: 85.64944
Epoch 85, Val Loss: 76.84114
Epoch 86, Val Loss: 75.31519
Epoch 87, Val Loss: 82.33369
Epoch 88, Val Loss: 79.85602
Epoch 89, Val Loss: 80.52651
Epoch 90, Val Loss: 76.05206
Epoch 91, Val Loss: 75.20203
Epoch 92, Val Loss: 74.32922
Epoch 93, Val Loss: 83.58195
Epoch 94, Val Loss: 74.99667
Epoch 95, Val Loss: 76.09727
Epoch 96, Val Loss: 88.30477
Epoch 97, Val Loss: 79.04922
Epoch 98, Val Loss: 85.39543
Epoch 99, Val Loss: 72.90577
DID NOT SAVE RESULTS
{'MSE - mean': 78.61292856887357, 'MSE - std': 8.42291753536016, 'R2 - mean': 0.5121081057846738, 'R2 - std': 0.029666773826806325} 
 

Results After CV: {'MSE - mean': 78.61292856887357, 'MSE - std': 8.42291753536016, 'R2 - mean': 0.5121081057846738, 'R2 - std': 0.029666773826806325}
Train time: 1927.8577745531977
Inference time: 0.17561024040332995
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 65 finished with value: 78.61292856887357 and parameters: {'p_m': 0.135338015251731, 'alpha': 7.612037898322402, 'K': 10, 'beta': 6.917042010548027}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 838.33777
Epoch 1, Val Loss: 437.40784
Epoch 2, Val Loss: 180.58644
Epoch 3, Val Loss: 146.48801
Epoch 4, Val Loss: 139.47220
Epoch 5, Val Loss: 143.44014
Epoch 6, Val Loss: 131.62228
Epoch 7, Val Loss: 114.93578
Epoch 8, Val Loss: 124.85709
Epoch 9, Val Loss: 108.26591
Epoch 10, Val Loss: 105.73158
Epoch 11, Val Loss: 115.78708
Epoch 12, Val Loss: 106.60625
Epoch 13, Val Loss: 101.54298
Epoch 14, Val Loss: 102.03020
Epoch 15, Val Loss: 100.18243
Epoch 16, Val Loss: 108.23879
Epoch 17, Val Loss: 111.14738
Epoch 18, Val Loss: 104.79579
Epoch 19, Val Loss: 122.35374
Epoch 20, Val Loss: 111.29298
Epoch 21, Val Loss: 111.30142
Epoch 22, Val Loss: 101.10057
Epoch 23, Val Loss: 108.84014
Epoch 24, Val Loss: 98.23242
Epoch 25, Val Loss: 101.96196
Epoch 26, Val Loss: 102.17288
Epoch 27, Val Loss: 110.39781
Epoch 28, Val Loss: 107.22853
Epoch 29, Val Loss: 100.92563
Epoch 30, Val Loss: 100.39096
Epoch 31, Val Loss: 106.71422
Epoch 32, Val Loss: 95.68838
Epoch 33, Val Loss: 99.80343
Epoch 34, Val Loss: 97.30027
Epoch 35, Val Loss: 97.83117
Epoch 36, Val Loss: 102.38278
Epoch 37, Val Loss: 95.34393
Epoch 38, Val Loss: 93.39685
Epoch 39, Val Loss: 92.07101
Epoch 40, Val Loss: 100.39391
Epoch 41, Val Loss: 93.12718
Epoch 42, Val Loss: 95.98923
Epoch 43, Val Loss: 115.28222
Epoch 44, Val Loss: 102.80720
Epoch 45, Val Loss: 90.19102
Epoch 46, Val Loss: 94.90527
Epoch 47, Val Loss: 103.72436
Epoch 48, Val Loss: 91.19592
Epoch 49, Val Loss: 102.37386
Epoch 50, Val Loss: 89.12347
Epoch 51, Val Loss: 90.75000
Epoch 52, Val Loss: 94.50747
Epoch 53, Val Loss: 104.57077
Epoch 54, Val Loss: 87.10133
Epoch 55, Val Loss: 90.92233
Epoch 56, Val Loss: 88.84854
Epoch 57, Val Loss: 88.84995
Epoch 58, Val Loss: 87.46506
Epoch 59, Val Loss: 93.24527
Epoch 60, Val Loss: 91.98855
Epoch 61, Val Loss: 91.08252
Epoch 62, Val Loss: 87.43446
Epoch 63, Val Loss: 106.26715
Epoch 64, Val Loss: 88.14495
Epoch 65, Val Loss: 86.10055
Epoch 66, Val Loss: 87.94075
Epoch 67, Val Loss: 87.03098
Epoch 68, Val Loss: 100.47691
Epoch 69, Val Loss: 89.20340
Epoch 70, Val Loss: 85.48086
Epoch 71, Val Loss: 94.80329
Epoch 72, Val Loss: 88.16454
Epoch 73, Val Loss: 85.14747
Epoch 74, Val Loss: 94.57476
Epoch 75, Val Loss: 91.13962
Epoch 76, Val Loss: 89.10274
Epoch 77, Val Loss: 83.14513
Epoch 78, Val Loss: 89.34360
Epoch 79, Val Loss: 83.20767
Epoch 80, Val Loss: 85.69823
Epoch 81, Val Loss: 91.37636
Epoch 82, Val Loss: 85.91493
Epoch 83, Val Loss: 89.71844
Epoch 84, Val Loss: 86.00143
Epoch 85, Val Loss: 87.89104
Epoch 86, Val Loss: 84.38382
Epoch 87, Val Loss: 86.11864
Epoch 88, Val Loss: 94.61073
Epoch 89, Val Loss: 91.18388
Epoch 90, Val Loss: 84.61911
Epoch 91, Val Loss: 81.13489
Epoch 92, Val Loss: 83.88265
Epoch 93, Val Loss: 84.94581
Epoch 94, Val Loss: 85.92209
Epoch 95, Val Loss: 81.79185
Epoch 96, Val Loss: 83.56962
Epoch 97, Val Loss: 87.34996
Epoch 98, Val Loss: 88.16753
Epoch 99, Val Loss: 82.10118
DID NOT SAVE RESULTS
{'MSE - mean': 85.76106584247962, 'MSE - std': 0.0, 'R2 - mean': 0.5002417395319023, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 817.79688
Epoch 1, Val Loss: 418.36072
Epoch 2, Val Loss: 173.20869
Epoch 3, Val Loss: 138.08165
Epoch 4, Val Loss: 119.86183
Epoch 5, Val Loss: 121.00689
Epoch 6, Val Loss: 109.68069
Epoch 7, Val Loss: 112.98000
Epoch 8, Val Loss: 119.84385
Epoch 9, Val Loss: 103.02854
Epoch 10, Val Loss: 110.83942
Epoch 11, Val Loss: 94.33372
Epoch 12, Val Loss: 95.09786
Epoch 13, Val Loss: 103.49209
Epoch 14, Val Loss: 93.03775
Epoch 15, Val Loss: 115.34859
Epoch 16, Val Loss: 90.96716
Epoch 17, Val Loss: 94.30390
Epoch 18, Val Loss: 101.65417
Epoch 19, Val Loss: 84.97569
Epoch 20, Val Loss: 91.78264
Epoch 21, Val Loss: 89.60645
Epoch 22, Val Loss: 84.62060
Epoch 23, Val Loss: 89.06187
Epoch 24, Val Loss: 83.76801
Epoch 25, Val Loss: 90.51933
Epoch 26, Val Loss: 88.16364
Epoch 27, Val Loss: 84.60378
Epoch 28, Val Loss: 75.13141
Epoch 29, Val Loss: 88.25238
Epoch 30, Val Loss: 77.32009
Epoch 31, Val Loss: 91.52005
Epoch 32, Val Loss: 84.74129
Epoch 33, Val Loss: 79.02792
Epoch 34, Val Loss: 76.73582
Epoch 35, Val Loss: 76.61076
Epoch 36, Val Loss: 76.76119
Epoch 37, Val Loss: 81.68060
Epoch 38, Val Loss: 110.68657
Epoch 39, Val Loss: 84.46040
Epoch 40, Val Loss: 76.32266
Epoch 41, Val Loss: 86.04329
Epoch 42, Val Loss: 76.90276
Epoch 43, Val Loss: 79.82018
Epoch 44, Val Loss: 82.12639
Epoch 45, Val Loss: 77.04226
Epoch 46, Val Loss: 77.78021
Epoch 47, Val Loss: 73.42941
Epoch 48, Val Loss: 71.58872
Epoch 49, Val Loss: 72.74521
Epoch 50, Val Loss: 79.14261
Epoch 51, Val Loss: 78.76522
Epoch 52, Val Loss: 75.22492
Epoch 53, Val Loss: 75.49806
Epoch 54, Val Loss: 95.44566
Epoch 55, Val Loss: 75.24998
Epoch 56, Val Loss: 74.21240
Epoch 57, Val Loss: 74.42657
Epoch 58, Val Loss: 74.51093
Epoch 59, Val Loss: 72.75053
Epoch 60, Val Loss: 76.79038
Epoch 61, Val Loss: 83.96705
Epoch 62, Val Loss: 75.79365
Epoch 63, Val Loss: 74.21970
Epoch 64, Val Loss: 74.78252
Epoch 65, Val Loss: 74.73728
Epoch 66, Val Loss: 69.23861
Epoch 67, Val Loss: 73.81135
Epoch 68, Val Loss: 74.04796
Epoch 69, Val Loss: 79.09932
Epoch 70, Val Loss: 74.33203
Epoch 71, Val Loss: 78.37611
Epoch 72, Val Loss: 74.33623
Epoch 73, Val Loss: 80.13947
Epoch 74, Val Loss: 73.09045
Epoch 75, Val Loss: 69.25608
Epoch 76, Val Loss: 77.12674
Epoch 77, Val Loss: 72.47195
Epoch 78, Val Loss: 73.86578
Epoch 79, Val Loss: 73.25196
Epoch 80, Val Loss: 72.51616
Epoch 81, Val Loss: 69.44496
Epoch 82, Val Loss: 73.70876
Epoch 83, Val Loss: 73.11665
Epoch 84, Val Loss: 70.37586
Epoch 85, Val Loss: 70.47135
Epoch 86, Val Loss: 74.85716
Epoch 87, Val Loss: 75.66816
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.60852658762354, 'MSE - std': 4.15253925485608, 'R2 - mean': 0.5030370222885424, 'R2 - std': 0.002795282756640094} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1549.22815
Epoch 1, Val Loss: 432.24060
Epoch 2, Val Loss: 158.15860
Epoch 3, Val Loss: 139.67717
Epoch 4, Val Loss: 125.46537
Epoch 5, Val Loss: 106.62351
Epoch 6, Val Loss: 126.06171
Epoch 7, Val Loss: 107.72153
Epoch 8, Val Loss: 101.83287
Epoch 9, Val Loss: 95.07398
Epoch 10, Val Loss: 93.00633
Epoch 11, Val Loss: 93.92340
Epoch 12, Val Loss: 91.72333
Epoch 13, Val Loss: 102.80045
Epoch 14, Val Loss: 98.76188
Epoch 15, Val Loss: 88.40762
Epoch 16, Val Loss: 90.98685
Epoch 17, Val Loss: 88.85191
Epoch 18, Val Loss: 87.04327
Epoch 19, Val Loss: 89.03067
Epoch 20, Val Loss: 87.64079
Epoch 21, Val Loss: 96.74303
Epoch 22, Val Loss: 79.42206
Epoch 23, Val Loss: 87.40442
Epoch 24, Val Loss: 89.43620
Epoch 25, Val Loss: 81.40261
Epoch 26, Val Loss: 81.15740
Epoch 27, Val Loss: 90.53439
Epoch 28, Val Loss: 82.88195
Epoch 29, Val Loss: 84.86609
Epoch 30, Val Loss: 81.49828
Epoch 31, Val Loss: 79.31725
Epoch 32, Val Loss: 79.42480
Epoch 33, Val Loss: 84.31226
Epoch 34, Val Loss: 84.84135
Epoch 35, Val Loss: 79.13055
Epoch 36, Val Loss: 78.88028
Epoch 37, Val Loss: 89.75012
Epoch 38, Val Loss: 83.46458
Epoch 39, Val Loss: 84.41242
Epoch 40, Val Loss: 86.20876
Epoch 41, Val Loss: 78.47314
Epoch 42, Val Loss: 95.63672
Epoch 43, Val Loss: 80.40546
Epoch 44, Val Loss: 102.69020
Epoch 45, Val Loss: 83.35033
Epoch 46, Val Loss: 78.86523
Epoch 47, Val Loss: 79.10515
Epoch 48, Val Loss: 78.61555
Epoch 49, Val Loss: 85.90147
Epoch 50, Val Loss: 73.78275
Epoch 51, Val Loss: 80.74477
Epoch 52, Val Loss: 75.72548
Epoch 53, Val Loss: 75.61941
Epoch 54, Val Loss: 82.76584
Epoch 55, Val Loss: 76.62558
Epoch 56, Val Loss: 75.86060
Epoch 57, Val Loss: 72.49043
Epoch 58, Val Loss: 77.74779
Epoch 59, Val Loss: 72.61940
Epoch 60, Val Loss: 80.53585
Epoch 61, Val Loss: 71.90370
Epoch 62, Val Loss: 73.83590
Epoch 63, Val Loss: 83.12486
Epoch 64, Val Loss: 74.70216
Epoch 65, Val Loss: 73.53373
Epoch 66, Val Loss: 75.54829
Epoch 67, Val Loss: 73.30988
Epoch 68, Val Loss: 68.58066
Epoch 69, Val Loss: 71.52140
Epoch 70, Val Loss: 71.16472
Epoch 71, Val Loss: 71.41555
Epoch 72, Val Loss: 72.80225
Epoch 73, Val Loss: 72.29485
Epoch 74, Val Loss: 72.93862
Epoch 75, Val Loss: 72.33074
Epoch 76, Val Loss: 71.85309
Epoch 77, Val Loss: 71.17628
Epoch 78, Val Loss: 72.95176
Epoch 79, Val Loss: 72.35297
Epoch 80, Val Loss: 84.88312
Epoch 81, Val Loss: 69.69659
Epoch 82, Val Loss: 78.80710
Epoch 83, Val Loss: 70.75520
Epoch 84, Val Loss: 81.20889
Epoch 85, Val Loss: 71.21577
Epoch 86, Val Loss: 70.43753
Epoch 87, Val Loss: 79.37341
Epoch 88, Val Loss: 84.20282
Epoch 89, Val Loss: 71.48468
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.70845380426832, 'MSE - std': 6.474322894302037, 'R2 - mean': 0.5120706831276446, 'R2 - std': 0.012977793601825032} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 436.53418
Epoch 1, Val Loss: 405.19659
Epoch 2, Val Loss: 161.38165
Epoch 3, Val Loss: 142.84802
Epoch 4, Val Loss: 134.10677
Epoch 5, Val Loss: 127.57157
Epoch 6, Val Loss: 129.72937
Epoch 7, Val Loss: 117.07021
Epoch 8, Val Loss: 107.03542
Epoch 9, Val Loss: 104.36450
Epoch 10, Val Loss: 103.13490
Epoch 11, Val Loss: 101.59059
Epoch 12, Val Loss: 103.88728
Epoch 13, Val Loss: 106.45425
Epoch 14, Val Loss: 98.42999
Epoch 15, Val Loss: 100.18386
Epoch 16, Val Loss: 111.35127
Epoch 17, Val Loss: 97.17570
Epoch 18, Val Loss: 106.25332
Epoch 19, Val Loss: 94.54284
Epoch 20, Val Loss: 91.15285
Epoch 21, Val Loss: 97.69316
Epoch 22, Val Loss: 105.65256
Epoch 23, Val Loss: 94.35368
Epoch 24, Val Loss: 91.59032
Epoch 25, Val Loss: 92.28686
Epoch 26, Val Loss: 89.28928
Epoch 27, Val Loss: 105.45738
Epoch 28, Val Loss: 99.76687
Epoch 29, Val Loss: 93.37618
Epoch 30, Val Loss: 104.66750
Epoch 31, Val Loss: 96.23395
Epoch 32, Val Loss: 92.78970
Epoch 33, Val Loss: 96.33702
Epoch 34, Val Loss: 90.13619
Epoch 35, Val Loss: 85.03941
Epoch 36, Val Loss: 89.20016
Epoch 37, Val Loss: 85.96515
Epoch 38, Val Loss: 88.87733
Epoch 39, Val Loss: 89.01448
Epoch 40, Val Loss: 88.17760
Epoch 41, Val Loss: 92.35975
Epoch 42, Val Loss: 82.12766
Epoch 43, Val Loss: 89.64059
Epoch 44, Val Loss: 109.24905
Epoch 45, Val Loss: 86.85213
Epoch 46, Val Loss: 81.02492
Epoch 47, Val Loss: 82.63939
Epoch 48, Val Loss: 87.27930
Epoch 49, Val Loss: 88.38835
Epoch 50, Val Loss: 87.84132
Epoch 51, Val Loss: 83.22885
Epoch 52, Val Loss: 80.52897
Epoch 53, Val Loss: 105.15979
Epoch 54, Val Loss: 84.12155
Epoch 55, Val Loss: 87.35713
Epoch 56, Val Loss: 79.56371
Epoch 57, Val Loss: 80.54541
Epoch 58, Val Loss: 82.86958
Epoch 59, Val Loss: 83.21943
Epoch 60, Val Loss: 78.83420
Epoch 61, Val Loss: 92.65846
Epoch 62, Val Loss: 79.05715
Epoch 63, Val Loss: 79.04151
Epoch 64, Val Loss: 82.24249
Epoch 65, Val Loss: 80.75093
Epoch 66, Val Loss: 80.75363
Epoch 67, Val Loss: 78.86808
Epoch 68, Val Loss: 87.09190
Epoch 69, Val Loss: 80.56565
Epoch 70, Val Loss: 82.41246
Epoch 71, Val Loss: 80.08126
Epoch 72, Val Loss: 85.06023
Epoch 73, Val Loss: 82.42965
Epoch 74, Val Loss: 79.72204
Epoch 75, Val Loss: 119.12627
Epoch 76, Val Loss: 87.93218
Epoch 77, Val Loss: 79.55948
Epoch 78, Val Loss: 81.38866
Epoch 79, Val Loss: 79.64396
Epoch 80, Val Loss: 95.22579
Epoch 81, Val Loss: 80.37512
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.52145051182458, 'MSE - std': 7.428088188419005, 'R2 - mean': 0.5007749859751394, 'R2 - std': 0.02256314844080995} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 680.15723
Epoch 1, Val Loss: 447.54971
Epoch 2, Val Loss: 156.31424
Epoch 3, Val Loss: 141.83899
Epoch 4, Val Loss: 164.26624
Epoch 5, Val Loss: 128.24712
Epoch 6, Val Loss: 137.73920
Epoch 7, Val Loss: 138.33429
Epoch 8, Val Loss: 130.58865
Epoch 9, Val Loss: 114.85036
Epoch 10, Val Loss: 123.38933
Epoch 11, Val Loss: 122.98389
Epoch 12, Val Loss: 109.19979
Epoch 13, Val Loss: 114.36757
Epoch 14, Val Loss: 112.09544
Epoch 15, Val Loss: 102.57912
Epoch 16, Val Loss: 107.37978
Epoch 17, Val Loss: 109.94523
Epoch 18, Val Loss: 95.41254
Epoch 19, Val Loss: 111.61195
Epoch 20, Val Loss: 114.47001
Epoch 21, Val Loss: 105.61823
Epoch 22, Val Loss: 100.99506
Epoch 23, Val Loss: 116.33528
Epoch 24, Val Loss: 106.26868
Epoch 25, Val Loss: 101.12752
Epoch 26, Val Loss: 101.96011
Epoch 27, Val Loss: 104.46568
Epoch 28, Val Loss: 90.88216
Epoch 29, Val Loss: 92.40299
Epoch 30, Val Loss: 97.70527
Epoch 31, Val Loss: 94.00867
Epoch 32, Val Loss: 90.31831
Epoch 33, Val Loss: 105.81173
Epoch 34, Val Loss: 95.94818
Epoch 35, Val Loss: 91.46949
Epoch 36, Val Loss: 91.98506
Epoch 37, Val Loss: 85.39416
Epoch 38, Val Loss: 90.06522
Epoch 39, Val Loss: 82.33101
Epoch 40, Val Loss: 93.94146
Epoch 41, Val Loss: 85.15204
Epoch 42, Val Loss: 83.79012
Epoch 43, Val Loss: 82.95599
Epoch 44, Val Loss: 80.25957
Epoch 45, Val Loss: 85.66034
Epoch 46, Val Loss: 90.44857
Epoch 47, Val Loss: 106.87379
Epoch 48, Val Loss: 85.60072
Epoch 49, Val Loss: 91.91526
Epoch 50, Val Loss: 106.60877
Epoch 51, Val Loss: 85.31202
Epoch 52, Val Loss: 95.79043
Epoch 53, Val Loss: 80.04446
Epoch 54, Val Loss: 80.67729
Epoch 55, Val Loss: 79.63252
Epoch 56, Val Loss: 75.31532
Epoch 57, Val Loss: 77.85174
Epoch 58, Val Loss: 80.45356
Epoch 59, Val Loss: 77.04101
Epoch 60, Val Loss: 80.65280
Epoch 61, Val Loss: 78.79890
Epoch 62, Val Loss: 77.65038
Epoch 63, Val Loss: 78.39838
Epoch 64, Val Loss: 78.48073
Epoch 65, Val Loss: 79.82480
Epoch 66, Val Loss: 77.25775
Epoch 67, Val Loss: 88.51387
Epoch 68, Val Loss: 81.55325
Epoch 69, Val Loss: 77.05217
Epoch 70, Val Loss: 76.78047
Epoch 71, Val Loss: 86.81837
Epoch 72, Val Loss: 80.40930
Epoch 73, Val Loss: 85.96445
Epoch 74, Val Loss: 80.19250
Epoch 75, Val Loss: 77.56080
Epoch 76, Val Loss: 82.82728
Epoch 77, Val Loss: 76.16493
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.48578305059425, 'MSE - std': 6.959283272647343, 'R2 - mean': 0.5061168167381453, 'R2 - std': 0.022834560596867413} 
 

Results After CV: {'MSE - mean': 79.48578305059425, 'MSE - std': 6.959283272647343, 'R2 - mean': 0.5061168167381453, 'R2 - std': 0.022834560596867413}
Train time: 359.6934019208071
Inference time: 0.17526384619995952
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 66 finished with value: 79.48578305059425 and parameters: {'p_m': 0.23352210154681138, 'alpha': 9.731946229196447, 'K': 2, 'beta': 5.743465471897358}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1591.69800
Epoch 1, Val Loss: 324.83337
Epoch 2, Val Loss: 206.01659
Epoch 3, Val Loss: 200.57446
Epoch 4, Val Loss: 154.58652
Epoch 5, Val Loss: 131.19678
Epoch 6, Val Loss: 129.03828
Epoch 7, Val Loss: 116.03400
Epoch 8, Val Loss: 117.15592
Epoch 9, Val Loss: 112.08698
Epoch 10, Val Loss: 118.66431
Epoch 11, Val Loss: 122.78413
Epoch 12, Val Loss: 109.48537
Epoch 13, Val Loss: 103.50076
Epoch 14, Val Loss: 107.75646
Epoch 15, Val Loss: 101.67828
Epoch 16, Val Loss: 100.29057
Epoch 17, Val Loss: 127.98927
Epoch 18, Val Loss: 99.60252
Epoch 19, Val Loss: 106.74492
Epoch 20, Val Loss: 103.38307
Epoch 21, Val Loss: 99.93235
Epoch 22, Val Loss: 97.22299
Epoch 23, Val Loss: 110.82454
Epoch 24, Val Loss: 104.36132
Epoch 25, Val Loss: 93.90459
Epoch 26, Val Loss: 94.75548
Epoch 27, Val Loss: 91.88789
Epoch 28, Val Loss: 90.67829
Epoch 29, Val Loss: 98.52722
Epoch 30, Val Loss: 99.21078
Epoch 31, Val Loss: 85.61518
Epoch 32, Val Loss: 88.63582
Epoch 33, Val Loss: 82.61711
Epoch 34, Val Loss: 89.04568
Epoch 35, Val Loss: 85.87854
Epoch 36, Val Loss: 82.84833
Epoch 37, Val Loss: 83.67705
Epoch 38, Val Loss: 83.72052
Epoch 39, Val Loss: 91.45500
Epoch 40, Val Loss: 90.80276
Epoch 41, Val Loss: 92.88142
Epoch 42, Val Loss: 92.82633
Epoch 43, Val Loss: 84.48627
Epoch 44, Val Loss: 94.15097
Epoch 45, Val Loss: 100.83115
Epoch 46, Val Loss: 87.69867
Epoch 47, Val Loss: 87.59949
Epoch 48, Val Loss: 84.83586
Epoch 49, Val Loss: 88.12225
Epoch 50, Val Loss: 90.33140
Epoch 51, Val Loss: 86.87566
Epoch 52, Val Loss: 87.60236
Epoch 53, Val Loss: 89.55746
Epoch 54, Val Loss: 86.22269
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.10044195345662, 'MSE - std': 0.0, 'R2 - mean': 0.4924367493681393, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 617.96088
Epoch 1, Val Loss: 314.46939
Epoch 2, Val Loss: 211.91121
Epoch 3, Val Loss: 148.45787
Epoch 4, Val Loss: 133.15135
Epoch 5, Val Loss: 122.14725
Epoch 6, Val Loss: 136.59729
Epoch 7, Val Loss: 102.02847
Epoch 8, Val Loss: 94.42805
Epoch 9, Val Loss: 90.40862
Epoch 10, Val Loss: 88.10514
Epoch 11, Val Loss: 106.72240
Epoch 12, Val Loss: 92.23222
Epoch 13, Val Loss: 82.49941
Epoch 14, Val Loss: 84.73958
Epoch 15, Val Loss: 82.07294
Epoch 16, Val Loss: 79.57410
Epoch 17, Val Loss: 79.60229
Epoch 18, Val Loss: 86.81698
Epoch 19, Val Loss: 95.54510
Epoch 20, Val Loss: 81.41825
Epoch 21, Val Loss: 113.70009
Epoch 22, Val Loss: 74.31718
Epoch 23, Val Loss: 76.67647
Epoch 24, Val Loss: 83.66058
Epoch 25, Val Loss: 83.44487
Epoch 26, Val Loss: 79.88474
Epoch 27, Val Loss: 80.26862
Epoch 28, Val Loss: 74.02029
Epoch 29, Val Loss: 79.92034
Epoch 30, Val Loss: 74.48521
Epoch 31, Val Loss: 86.22430
Epoch 32, Val Loss: 72.83937
Epoch 33, Val Loss: 83.60076
Epoch 34, Val Loss: 74.83662
Epoch 35, Val Loss: 74.42490
Epoch 36, Val Loss: 80.82368
Epoch 37, Val Loss: 74.59743
Epoch 38, Val Loss: 72.68523
Epoch 39, Val Loss: 76.33637
Epoch 40, Val Loss: 72.21700
Epoch 41, Val Loss: 82.14750
Epoch 42, Val Loss: 71.00179
Epoch 43, Val Loss: 79.62294
Epoch 44, Val Loss: 79.03385
Epoch 45, Val Loss: 73.78561
Epoch 46, Val Loss: 76.30810
Epoch 47, Val Loss: 78.25487
Epoch 48, Val Loss: 77.87348
Epoch 49, Val Loss: 75.48694
Epoch 50, Val Loss: 73.22589
Epoch 51, Val Loss: 72.71166
Epoch 52, Val Loss: 75.61446
Epoch 53, Val Loss: 83.68275
Epoch 54, Val Loss: 78.05916
Epoch 55, Val Loss: 76.00248
Epoch 56, Val Loss: 76.96219
Epoch 57, Val Loss: 71.03031
Epoch 58, Val Loss: 74.62810
Epoch 59, Val Loss: 74.45320
Epoch 60, Val Loss: 75.95982
Epoch 61, Val Loss: 80.98066
Epoch 62, Val Loss: 76.41586
Epoch 63, Val Loss: 74.17886
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.77543131683088, 'MSE - std': 4.325010636625748, 'R2 - mean': 0.4959622944844942, 'R2 - std': 0.003525545116354889} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1206.30994
Epoch 1, Val Loss: 402.17322
Epoch 2, Val Loss: 174.64246
Epoch 3, Val Loss: 146.96376
Epoch 4, Val Loss: 133.73415
Epoch 5, Val Loss: 118.50706
Epoch 6, Val Loss: 107.28155
Epoch 7, Val Loss: 95.39787
Epoch 8, Val Loss: 92.08971
Epoch 9, Val Loss: 100.58666
Epoch 10, Val Loss: 93.39642
Epoch 11, Val Loss: 85.80736
Epoch 12, Val Loss: 98.01753
Epoch 13, Val Loss: 83.88167
Epoch 14, Val Loss: 76.96539
Epoch 15, Val Loss: 92.38582
Epoch 16, Val Loss: 80.07668
Epoch 17, Val Loss: 76.56613
Epoch 18, Val Loss: 92.99377
Epoch 19, Val Loss: 92.41965
Epoch 20, Val Loss: 78.49879
Epoch 21, Val Loss: 84.44752
Epoch 22, Val Loss: 81.97218
Epoch 23, Val Loss: 84.18223
Epoch 24, Val Loss: 79.00024
Epoch 25, Val Loss: 78.19096
Epoch 26, Val Loss: 78.06534
Epoch 27, Val Loss: 77.51615
Epoch 28, Val Loss: 79.81869
Epoch 29, Val Loss: 82.05620
Epoch 30, Val Loss: 76.04307
Epoch 31, Val Loss: 75.46212
Epoch 32, Val Loss: 97.79910
Epoch 33, Val Loss: 82.37740
Epoch 34, Val Loss: 72.95058
Epoch 35, Val Loss: 81.24797
Epoch 36, Val Loss: 80.07812
Epoch 37, Val Loss: 73.41664
Epoch 38, Val Loss: 72.90193
Epoch 39, Val Loss: 73.46173
Epoch 40, Val Loss: 74.81418
Epoch 41, Val Loss: 73.02014
Epoch 42, Val Loss: 73.54655
Epoch 43, Val Loss: 75.32571
Epoch 44, Val Loss: 69.65273
Epoch 45, Val Loss: 76.64241
Epoch 46, Val Loss: 83.34208
Epoch 47, Val Loss: 82.07239
Epoch 48, Val Loss: 72.60656
Epoch 49, Val Loss: 72.42419
Epoch 50, Val Loss: 74.77682
Epoch 51, Val Loss: 75.39037
Epoch 52, Val Loss: 74.24001
Epoch 53, Val Loss: 72.91928
Epoch 54, Val Loss: 71.01795
Epoch 55, Val Loss: 72.96745
Epoch 56, Val Loss: 71.02766
Epoch 57, Val Loss: 72.57464
Epoch 58, Val Loss: 72.63161
Epoch 59, Val Loss: 76.96352
Epoch 60, Val Loss: 73.70386
Epoch 61, Val Loss: 70.94155
Epoch 62, Val Loss: 77.36382
Epoch 63, Val Loss: 70.06967
Epoch 64, Val Loss: 77.12800
Epoch 65, Val Loss: 73.60432
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.17336428071094, 'MSE - std': 7.40462828334418, 'R2 - mean': 0.5094580827016085, 'R2 - std': 0.019301785188095152} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 906.02448
Epoch 1, Val Loss: 401.73401
Epoch 2, Val Loss: 193.49426
Epoch 3, Val Loss: 162.88098
Epoch 4, Val Loss: 143.37393
Epoch 5, Val Loss: 135.48447
Epoch 6, Val Loss: 113.68696
Epoch 7, Val Loss: 118.78198
Epoch 8, Val Loss: 114.68137
Epoch 9, Val Loss: 103.70703
Epoch 10, Val Loss: 94.69815
Epoch 11, Val Loss: 99.16879
Epoch 12, Val Loss: 94.26173
Epoch 13, Val Loss: 108.19755
Epoch 14, Val Loss: 90.50887
Epoch 15, Val Loss: 93.47234
Epoch 16, Val Loss: 90.98266
Epoch 17, Val Loss: 87.10847
Epoch 18, Val Loss: 87.05445
Epoch 19, Val Loss: 92.56023
Epoch 20, Val Loss: 92.12805
Epoch 21, Val Loss: 89.63326
Epoch 22, Val Loss: 87.75304
Epoch 23, Val Loss: 83.02112
Epoch 24, Val Loss: 88.32406
Epoch 25, Val Loss: 86.50251
Epoch 26, Val Loss: 83.09602
Epoch 27, Val Loss: 86.02753
Epoch 28, Val Loss: 83.18953
Epoch 29, Val Loss: 87.05389
Epoch 30, Val Loss: 93.51916
Epoch 31, Val Loss: 83.11024
Epoch 32, Val Loss: 83.01833
Epoch 33, Val Loss: 88.47917
Epoch 34, Val Loss: 85.77176
Epoch 35, Val Loss: 88.78247
Epoch 36, Val Loss: 86.45344
Epoch 37, Val Loss: 82.44355
Epoch 38, Val Loss: 82.01063
Epoch 39, Val Loss: 83.25534
Epoch 40, Val Loss: 82.63446
Epoch 41, Val Loss: 91.18144
Epoch 42, Val Loss: 85.45840
Epoch 43, Val Loss: 83.73253
Epoch 44, Val Loss: 87.70966
Epoch 45, Val Loss: 82.80939
Epoch 46, Val Loss: 92.13329
Epoch 47, Val Loss: 84.23992
Epoch 48, Val Loss: 90.59860
Epoch 49, Val Loss: 89.54668
Epoch 50, Val Loss: 81.34807
Epoch 51, Val Loss: 82.16403
Epoch 52, Val Loss: 93.94366
Epoch 53, Val Loss: 87.83170
Epoch 54, Val Loss: 78.98192
Epoch 55, Val Loss: 85.08154
Epoch 56, Val Loss: 86.30963
Epoch 57, Val Loss: 81.56802
Epoch 58, Val Loss: 85.89018
Epoch 59, Val Loss: 82.11098
Epoch 60, Val Loss: 82.99001
Epoch 61, Val Loss: 86.89577
Epoch 62, Val Loss: 85.70722
Epoch 63, Val Loss: 78.98763
Epoch 64, Val Loss: 81.80068
Epoch 65, Val Loss: 83.88407
Epoch 66, Val Loss: 86.04751
Epoch 67, Val Loss: 86.62231
Epoch 68, Val Loss: 78.56650
Epoch 69, Val Loss: 82.64159
Epoch 70, Val Loss: 80.03667
Epoch 71, Val Loss: 99.01572
Epoch 72, Val Loss: 81.38600
Epoch 73, Val Loss: 81.31475
Epoch 74, Val Loss: 80.78036
Epoch 75, Val Loss: 83.60604
Epoch 76, Val Loss: 82.67463
Epoch 77, Val Loss: 85.42780
Epoch 78, Val Loss: 83.21754
Epoch 79, Val Loss: 82.03173
Epoch 80, Val Loss: 80.52613
Epoch 81, Val Loss: 82.54479
Epoch 82, Val Loss: 88.19299
Epoch 83, Val Loss: 82.07371
Epoch 84, Val Loss: 85.74509
Epoch 85, Val Loss: 78.94750
Epoch 86, Val Loss: 85.74609
Epoch 87, Val Loss: 83.34241
Epoch 88, Val Loss: 85.25325
Epoch 89, Val Loss: 85.85541
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.72348788199753, 'MSE - std': 7.786576985838633, 'R2 - mean': 0.4996943362085463, 'R2 - std': 0.023778381364758207} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1041.10742
Epoch 1, Val Loss: 419.39297
Epoch 2, Val Loss: 156.51898
Epoch 3, Val Loss: 142.20493
Epoch 4, Val Loss: 141.31458
Epoch 5, Val Loss: 126.24637
Epoch 6, Val Loss: 123.11420
Epoch 7, Val Loss: 108.57089
Epoch 8, Val Loss: 104.51662
Epoch 9, Val Loss: 106.44211
Epoch 10, Val Loss: 114.57409
Epoch 11, Val Loss: 104.34317
Epoch 12, Val Loss: 94.84439
Epoch 13, Val Loss: 103.75741
Epoch 14, Val Loss: 103.40298
Epoch 15, Val Loss: 104.69386
Epoch 16, Val Loss: 97.26933
Epoch 17, Val Loss: 93.01826
Epoch 18, Val Loss: 93.80594
Epoch 19, Val Loss: 89.82110
Epoch 20, Val Loss: 87.39540
Epoch 21, Val Loss: 97.22315
Epoch 22, Val Loss: 103.52316
Epoch 23, Val Loss: 96.45828
Epoch 24, Val Loss: 80.98420
Epoch 25, Val Loss: 92.59521
Epoch 26, Val Loss: 93.60207
Epoch 27, Val Loss: 91.38287
Epoch 28, Val Loss: 88.56889
Epoch 29, Val Loss: 89.19440
Epoch 30, Val Loss: 86.21155
Epoch 31, Val Loss: 84.35800
Epoch 32, Val Loss: 83.32126
Epoch 33, Val Loss: 87.83321
Epoch 34, Val Loss: 86.89839
Epoch 35, Val Loss: 81.09975
Epoch 36, Val Loss: 80.86367
Epoch 37, Val Loss: 83.11572
Epoch 38, Val Loss: 87.36371
Epoch 39, Val Loss: 83.79819
Epoch 40, Val Loss: 79.63007
Epoch 41, Val Loss: 82.38144
Epoch 42, Val Loss: 83.56691
Epoch 43, Val Loss: 77.20795
Epoch 44, Val Loss: 94.39520
Epoch 45, Val Loss: 78.89290
Epoch 46, Val Loss: 85.50893
Epoch 47, Val Loss: 84.28791
Epoch 48, Val Loss: 79.14273
Epoch 49, Val Loss: 79.91123
Epoch 50, Val Loss: 78.95482
Epoch 51, Val Loss: 75.62821
Epoch 52, Val Loss: 76.46291
Epoch 53, Val Loss: 87.37344
Epoch 54, Val Loss: 100.30053
Epoch 55, Val Loss: 79.77268
Epoch 56, Val Loss: 87.16512
Epoch 57, Val Loss: 81.83096
Epoch 58, Val Loss: 81.67009
Epoch 59, Val Loss: 85.24248
Epoch 60, Val Loss: 78.05736
Epoch 61, Val Loss: 79.94568
Epoch 62, Val Loss: 77.69689
Epoch 63, Val Loss: 77.73335
Epoch 64, Val Loss: 80.75332
Epoch 65, Val Loss: 78.65494
Epoch 66, Val Loss: 82.57331
Epoch 67, Val Loss: 77.98552
Epoch 68, Val Loss: 87.41785
Epoch 69, Val Loss: 78.06110
Epoch 70, Val Loss: 76.84105
Epoch 71, Val Loss: 74.66779
Epoch 72, Val Loss: 76.86993
Epoch 73, Val Loss: 78.18777
Epoch 74, Val Loss: 80.28243
Epoch 75, Val Loss: 76.80751
Epoch 76, Val Loss: 82.38376
Epoch 77, Val Loss: 78.72031
Epoch 78, Val Loss: 80.36256
Epoch 79, Val Loss: 76.23233
Epoch 80, Val Loss: 81.21123
Epoch 81, Val Loss: 78.54111
Epoch 82, Val Loss: 79.66667
Epoch 83, Val Loss: 83.39876
Epoch 84, Val Loss: 82.88891
Epoch 85, Val Loss: 86.11850
Epoch 86, Val Loss: 80.82532
Epoch 87, Val Loss: 89.43016
Epoch 88, Val Loss: 83.29812
Epoch 89, Val Loss: 86.74604
Epoch 90, Val Loss: 75.10983
Epoch 91, Val Loss: 80.35040
Epoch 92, Val Loss: 83.16994
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.77235056713626, 'MSE - std': 7.219644983792454, 'R2 - mean': 0.5044687481084523, 'R2 - std': 0.02331328317123441} 
 

Results After CV: {'MSE - mean': 79.77235056713626, 'MSE - std': 7.219644983792454, 'R2 - mean': 0.5044687481084523, 'R2 - std': 0.02331328317123441}
Train time: 2012.7829343056014
Inference time: 0.17780410300474614
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 67 finished with value: 79.77235056713626 and parameters: {'p_m': 0.30808422066375496, 'alpha': 1.1188315584139001, 'K': 15, 'beta': 6.692277669142312}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 866.91919
Epoch 1, Val Loss: 539.01965
Epoch 2, Val Loss: 330.74603
Epoch 3, Val Loss: 266.47250
Epoch 4, Val Loss: 207.43404
Epoch 5, Val Loss: 171.57056
Epoch 6, Val Loss: 165.97665
Epoch 7, Val Loss: 161.62511
Epoch 8, Val Loss: 135.78931
Epoch 9, Val Loss: 134.33997
Epoch 10, Val Loss: 124.09604
Epoch 11, Val Loss: 113.18398
Epoch 12, Val Loss: 111.93901
Epoch 13, Val Loss: 101.89350
Epoch 14, Val Loss: 109.72116
Epoch 15, Val Loss: 105.63078
Epoch 16, Val Loss: 119.63434
Epoch 17, Val Loss: 100.97262
Epoch 18, Val Loss: 97.88195
Epoch 19, Val Loss: 100.57611
Epoch 20, Val Loss: 101.30034
Epoch 21, Val Loss: 90.83862
Epoch 22, Val Loss: 90.44028
Epoch 23, Val Loss: 89.34162
Epoch 24, Val Loss: 87.21804
Epoch 25, Val Loss: 89.96806
Epoch 26, Val Loss: 89.42426
Epoch 27, Val Loss: 89.69568
Epoch 28, Val Loss: 86.19084
Epoch 29, Val Loss: 87.02493
Epoch 30, Val Loss: 90.40676
Epoch 31, Val Loss: 87.51237
Epoch 32, Val Loss: 89.51591
Epoch 33, Val Loss: 100.91592
Epoch 34, Val Loss: 84.63268
Epoch 35, Val Loss: 86.88290
Epoch 36, Val Loss: 89.48129
Epoch 37, Val Loss: 92.90974
Epoch 38, Val Loss: 88.09048
Epoch 39, Val Loss: 96.15292
Epoch 40, Val Loss: 85.91280
Epoch 41, Val Loss: 94.91154
Epoch 42, Val Loss: 88.12181
Epoch 43, Val Loss: 85.26889
Epoch 44, Val Loss: 84.21104
Epoch 45, Val Loss: 86.11373
Epoch 46, Val Loss: 93.15089
Epoch 47, Val Loss: 88.76528
Epoch 48, Val Loss: 85.94088
Epoch 49, Val Loss: 92.80662
Epoch 50, Val Loss: 88.76315
Epoch 51, Val Loss: 88.52117
Epoch 52, Val Loss: 85.03537
Epoch 53, Val Loss: 89.83064
Epoch 54, Val Loss: 102.39313
Epoch 55, Val Loss: 90.41610
Epoch 56, Val Loss: 86.38640
Epoch 57, Val Loss: 93.88635
Epoch 58, Val Loss: 89.63855
Epoch 59, Val Loss: 93.42609
Epoch 60, Val Loss: 89.84694
Epoch 61, Val Loss: 98.53262
Epoch 62, Val Loss: 93.94077
Epoch 63, Val Loss: 87.31927
Epoch 64, Val Loss: 89.17648
Epoch 65, Val Loss: 86.06535
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.35757535135131, 'MSE - std': 0.0, 'R2 - mean': 0.485111014852874, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1399.47339
Epoch 1, Val Loss: 634.30853
Epoch 2, Val Loss: 330.41965
Epoch 3, Val Loss: 242.76227
Epoch 4, Val Loss: 200.10373
Epoch 5, Val Loss: 167.94417
Epoch 6, Val Loss: 149.05525
Epoch 7, Val Loss: 131.07062
Epoch 8, Val Loss: 123.63113
Epoch 9, Val Loss: 117.02754
Epoch 10, Val Loss: 116.31853
Epoch 11, Val Loss: 106.21112
Epoch 12, Val Loss: 109.42418
Epoch 13, Val Loss: 99.25854
Epoch 14, Val Loss: 98.64354
Epoch 15, Val Loss: 94.00973
Epoch 16, Val Loss: 90.90267
Epoch 17, Val Loss: 91.40613
Epoch 18, Val Loss: 86.84890
Epoch 19, Val Loss: 90.15202
Epoch 20, Val Loss: 85.24670
Epoch 21, Val Loss: 83.02586
Epoch 22, Val Loss: 81.16496
Epoch 23, Val Loss: 81.63278
Epoch 24, Val Loss: 80.10974
Epoch 25, Val Loss: 81.18265
Epoch 26, Val Loss: 78.64804
Epoch 27, Val Loss: 78.58472
Epoch 28, Val Loss: 79.93160
Epoch 29, Val Loss: 73.89437
Epoch 30, Val Loss: 75.59791
Epoch 31, Val Loss: 78.37439
Epoch 32, Val Loss: 72.37887
Epoch 33, Val Loss: 76.24986
Epoch 34, Val Loss: 79.98604
Epoch 35, Val Loss: 77.21243
Epoch 36, Val Loss: 76.82018
Epoch 37, Val Loss: 75.99525
Epoch 38, Val Loss: 74.89058
Epoch 39, Val Loss: 82.39235
Epoch 40, Val Loss: 72.58276
Epoch 41, Val Loss: 76.46866
Epoch 42, Val Loss: 73.25748
Epoch 43, Val Loss: 77.00461
Epoch 44, Val Loss: 72.54966
Epoch 45, Val Loss: 75.55476
Epoch 46, Val Loss: 75.04954
Epoch 47, Val Loss: 77.47674
Epoch 48, Val Loss: 71.84834
Epoch 49, Val Loss: 73.65328
Epoch 50, Val Loss: 78.26669
Epoch 51, Val Loss: 77.22570
Epoch 52, Val Loss: 78.55463
Epoch 53, Val Loss: 72.35741
Epoch 54, Val Loss: 73.10410
Epoch 55, Val Loss: 77.86271
Epoch 56, Val Loss: 88.40864
Epoch 57, Val Loss: 73.87023
Epoch 58, Val Loss: 73.08347
Epoch 59, Val Loss: 79.05749
Epoch 60, Val Loss: 81.56898
Epoch 61, Val Loss: 74.67105
Epoch 62, Val Loss: 74.66357
Epoch 63, Val Loss: 87.81322
Epoch 64, Val Loss: 73.73499
Epoch 65, Val Loss: 77.96122
Epoch 66, Val Loss: 75.37048
Epoch 67, Val Loss: 72.95297
Epoch 68, Val Loss: 76.44289
Epoch 69, Val Loss: 75.83023
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.72580015678916, 'MSE - std': 3.6317751945621524, 'R2 - mean': 0.48386635523717186, 'R2 - std': 0.0012446596157021372} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 857.32886
Epoch 1, Val Loss: 551.21729
Epoch 2, Val Loss: 289.28351
Epoch 3, Val Loss: 203.43007
Epoch 4, Val Loss: 186.73317
Epoch 5, Val Loss: 138.52602
Epoch 6, Val Loss: 147.08276
Epoch 7, Val Loss: 113.16025
Epoch 8, Val Loss: 104.99136
Epoch 9, Val Loss: 115.26732
Epoch 10, Val Loss: 104.23095
Epoch 11, Val Loss: 90.98647
Epoch 12, Val Loss: 108.36496
Epoch 13, Val Loss: 98.98911
Epoch 14, Val Loss: 82.34275
Epoch 15, Val Loss: 85.50896
Epoch 16, Val Loss: 78.85106
Epoch 17, Val Loss: 81.34892
Epoch 18, Val Loss: 82.51338
Epoch 19, Val Loss: 78.44487
Epoch 20, Val Loss: 77.71812
Epoch 21, Val Loss: 76.08701
Epoch 22, Val Loss: 75.38022
Epoch 23, Val Loss: 74.39961
Epoch 24, Val Loss: 74.62834
Epoch 25, Val Loss: 75.58001
Epoch 26, Val Loss: 74.48859
Epoch 27, Val Loss: 77.18253
Epoch 28, Val Loss: 74.29981
Epoch 29, Val Loss: 89.09643
Epoch 30, Val Loss: 72.11990
Epoch 31, Val Loss: 82.64490
Epoch 32, Val Loss: 71.14828
Epoch 33, Val Loss: 73.59795
Epoch 34, Val Loss: 76.89786
Epoch 35, Val Loss: 76.84724
Epoch 36, Val Loss: 85.40753
Epoch 37, Val Loss: 72.20276
Epoch 38, Val Loss: 74.08611
Epoch 39, Val Loss: 88.62933
Epoch 40, Val Loss: 75.94787
Epoch 41, Val Loss: 75.58618
Epoch 42, Val Loss: 77.34077
Epoch 43, Val Loss: 71.99799
Epoch 44, Val Loss: 70.64429
Epoch 45, Val Loss: 69.96861
Epoch 46, Val Loss: 71.32996
Epoch 47, Val Loss: 71.99791
Epoch 48, Val Loss: 72.97314
Epoch 49, Val Loss: 76.14306
Epoch 50, Val Loss: 68.48185
Epoch 51, Val Loss: 79.86179
Epoch 52, Val Loss: 74.37216
Epoch 53, Val Loss: 72.36338
Epoch 54, Val Loss: 74.74354
Epoch 55, Val Loss: 72.76928
Epoch 56, Val Loss: 71.27576
Epoch 57, Val Loss: 72.37891
Epoch 58, Val Loss: 71.85432
Epoch 59, Val Loss: 71.80911
Epoch 60, Val Loss: 72.07591
Epoch 61, Val Loss: 78.63633
Epoch 62, Val Loss: 80.34596
Epoch 63, Val Loss: 72.57623
Epoch 64, Val Loss: 68.25671
Epoch 65, Val Loss: 84.09612
Epoch 66, Val Loss: 75.40276
Epoch 67, Val Loss: 77.87165
Epoch 68, Val Loss: 76.12982
Epoch 69, Val Loss: 70.78242
Epoch 70, Val Loss: 72.23081
Epoch 71, Val Loss: 75.67242
Epoch 72, Val Loss: 83.42299
Epoch 73, Val Loss: 76.92068
Epoch 74, Val Loss: 70.82114
Epoch 75, Val Loss: 81.65054
Epoch 76, Val Loss: 73.19253
Epoch 77, Val Loss: 79.13236
Epoch 78, Val Loss: 70.17651
Epoch 79, Val Loss: 74.89313
Epoch 80, Val Loss: 81.42607
Epoch 81, Val Loss: 71.16819
Epoch 82, Val Loss: 76.79347
Epoch 83, Val Loss: 74.59900
Epoch 84, Val Loss: 80.42107
Epoch 85, Val Loss: 75.79607
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.31597609251469, 'MSE - std': 8.205217051081858, 'R2 - mean': 0.5024536004803052, 'R2 - std': 0.026305971878949296} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 809.20898
Epoch 1, Val Loss: 621.90601
Epoch 2, Val Loss: 321.73053
Epoch 3, Val Loss: 256.56790
Epoch 4, Val Loss: 208.30678
Epoch 5, Val Loss: 162.16040
Epoch 6, Val Loss: 153.00134
Epoch 7, Val Loss: 142.68147
Epoch 8, Val Loss: 142.20134
Epoch 9, Val Loss: 127.01099
Epoch 10, Val Loss: 119.06226
Epoch 11, Val Loss: 110.13430
Epoch 12, Val Loss: 119.93165
Epoch 13, Val Loss: 103.45404
Epoch 14, Val Loss: 101.31184
Epoch 15, Val Loss: 96.11310
Epoch 16, Val Loss: 95.20438
Epoch 17, Val Loss: 95.20172
Epoch 18, Val Loss: 95.50422
Epoch 19, Val Loss: 90.44775
Epoch 20, Val Loss: 92.89601
Epoch 21, Val Loss: 93.34663
Epoch 22, Val Loss: 89.35681
Epoch 23, Val Loss: 86.10468
Epoch 24, Val Loss: 87.95276
Epoch 25, Val Loss: 86.26271
Epoch 26, Val Loss: 84.93030
Epoch 27, Val Loss: 101.84988
Epoch 28, Val Loss: 82.80575
Epoch 29, Val Loss: 87.78343
Epoch 30, Val Loss: 83.67762
Epoch 31, Val Loss: 89.53906
Epoch 32, Val Loss: 83.44942
Epoch 33, Val Loss: 86.19431
Epoch 34, Val Loss: 89.70735
Epoch 35, Val Loss: 81.38136
Epoch 36, Val Loss: 82.96748
Epoch 37, Val Loss: 81.11979
Epoch 38, Val Loss: 85.53194
Epoch 39, Val Loss: 91.12184
Epoch 40, Val Loss: 81.10222
Epoch 41, Val Loss: 81.52013
Epoch 42, Val Loss: 82.12608
Epoch 43, Val Loss: 81.28702
Epoch 44, Val Loss: 79.34371
Epoch 45, Val Loss: 81.42253
Epoch 46, Val Loss: 81.25320
Epoch 47, Val Loss: 86.10200
Epoch 48, Val Loss: 80.78394
Epoch 49, Val Loss: 88.44366
Epoch 50, Val Loss: 88.49055
Epoch 51, Val Loss: 89.79602
Epoch 52, Val Loss: 84.94186
Epoch 53, Val Loss: 80.39213
Epoch 54, Val Loss: 80.61599
Epoch 55, Val Loss: 81.00985
Epoch 56, Val Loss: 83.07568
Epoch 57, Val Loss: 83.65359
Epoch 58, Val Loss: 79.91344
Epoch 59, Val Loss: 83.50287
Epoch 60, Val Loss: 81.46740
Epoch 61, Val Loss: 81.54066
Epoch 62, Val Loss: 99.22047
Epoch 63, Val Loss: 83.37991
Epoch 64, Val Loss: 80.51273
Epoch 65, Val Loss: 77.87148
Epoch 66, Val Loss: 78.69079
Epoch 67, Val Loss: 82.48991
Epoch 68, Val Loss: 79.27539
Epoch 69, Val Loss: 84.42622
Epoch 70, Val Loss: 85.23081
Epoch 71, Val Loss: 83.71046
Epoch 72, Val Loss: 84.64880
Epoch 73, Val Loss: 89.16004
Epoch 74, Val Loss: 84.48811
Epoch 75, Val Loss: 83.17222
Epoch 76, Val Loss: 81.45472
Epoch 77, Val Loss: 81.19402
Epoch 78, Val Loss: 83.62883
Epoch 79, Val Loss: 82.50869
Epoch 80, Val Loss: 85.91357
Epoch 81, Val Loss: 81.63976
Epoch 82, Val Loss: 81.72451
Epoch 83, Val Loss: 84.13416
Epoch 84, Val Loss: 94.62916
Epoch 85, Val Loss: 81.52974
Epoch 86, Val Loss: 83.45626
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.77937739252047, 'MSE - std': 8.288499745800436, 'R2 - mean': 0.49324884534670993, 'R2 - std': 0.027806216365776903} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1744.85181
Epoch 1, Val Loss: 746.20947
Epoch 2, Val Loss: 319.74728
Epoch 3, Val Loss: 249.24460
Epoch 4, Val Loss: 187.99971
Epoch 5, Val Loss: 177.26056
Epoch 6, Val Loss: 178.28644
Epoch 7, Val Loss: 143.10460
Epoch 8, Val Loss: 115.32095
Epoch 9, Val Loss: 114.59890
Epoch 10, Val Loss: 110.86754
Epoch 11, Val Loss: 103.95847
Epoch 12, Val Loss: 98.93132
Epoch 13, Val Loss: 98.48740
Epoch 14, Val Loss: 89.06020
Epoch 15, Val Loss: 89.22742
Epoch 16, Val Loss: 84.14186
Epoch 17, Val Loss: 87.83545
Epoch 18, Val Loss: 79.24715
Epoch 19, Val Loss: 86.41109
Epoch 20, Val Loss: 84.56359
Epoch 21, Val Loss: 86.62013
Epoch 22, Val Loss: 85.91640
Epoch 23, Val Loss: 82.03217
Epoch 24, Val Loss: 80.99805
Epoch 25, Val Loss: 82.86392
Epoch 26, Val Loss: 77.83838
Epoch 27, Val Loss: 79.20469
Epoch 28, Val Loss: 79.95851
Epoch 29, Val Loss: 80.28139
Epoch 30, Val Loss: 78.75903
Epoch 31, Val Loss: 82.75997
Epoch 32, Val Loss: 81.34534
Epoch 33, Val Loss: 82.05786
Epoch 34, Val Loss: 84.41590
Epoch 35, Val Loss: 81.96529
Epoch 36, Val Loss: 81.14131
Epoch 37, Val Loss: 78.63741
Epoch 38, Val Loss: 79.75606
Epoch 39, Val Loss: 93.57718
Epoch 40, Val Loss: 82.71859
Epoch 41, Val Loss: 82.38155
Epoch 42, Val Loss: 82.47854
Epoch 43, Val Loss: 78.33828
Epoch 44, Val Loss: 85.35508
Epoch 45, Val Loss: 97.47820
Epoch 46, Val Loss: 83.47406
Epoch 47, Val Loss: 80.24220
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.13035118074065, 'MSE - std': 7.526242257808088, 'R2 - mean': 0.49609325302856766, 'R2 - std': 0.025512960531987764} 
 

Results After CV: {'MSE - mean': 81.13035118074065, 'MSE - std': 7.526242257808088, 'R2 - mean': 0.49609325302856766, 'R2 - std': 0.025512960531987764}
Train time: 773.3596377780079
Inference time: 0.20686061740270817
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 68 finished with value: 81.13035118074065 and parameters: {'p_m': 0.8668167891709097, 'alpha': 8.339472754955356, 'K': 5, 'beta': 5.259229176312326}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 785.18115
Epoch 1, Val Loss: 559.30859
Epoch 2, Val Loss: 164.69482
Epoch 3, Val Loss: 157.17363
Epoch 4, Val Loss: 143.10580
Epoch 5, Val Loss: 130.94083
Epoch 6, Val Loss: 125.42878
Epoch 7, Val Loss: 127.05816
Epoch 8, Val Loss: 107.13899
Epoch 9, Val Loss: 114.37697
Epoch 10, Val Loss: 111.44439
Epoch 11, Val Loss: 110.89973
Epoch 12, Val Loss: 111.15578
Epoch 13, Val Loss: 109.44299
Epoch 14, Val Loss: 108.68299
Epoch 15, Val Loss: 96.60767
Epoch 16, Val Loss: 105.30842
Epoch 17, Val Loss: 102.01271
Epoch 18, Val Loss: 97.49122
Epoch 19, Val Loss: 99.30012
Epoch 20, Val Loss: 122.77232
Epoch 21, Val Loss: 102.71037
Epoch 22, Val Loss: 98.84627
Epoch 23, Val Loss: 98.15266
Epoch 24, Val Loss: 100.04275
Epoch 25, Val Loss: 99.30820
Epoch 26, Val Loss: 102.95053
Epoch 27, Val Loss: 98.27187
Epoch 28, Val Loss: 99.83691
Epoch 29, Val Loss: 98.82591
Epoch 30, Val Loss: 102.74069
Epoch 31, Val Loss: 112.15685
Epoch 32, Val Loss: 93.61431
Epoch 33, Val Loss: 102.82777
Epoch 34, Val Loss: 104.02314
Epoch 35, Val Loss: 106.48076
Epoch 36, Val Loss: 106.69476
Epoch 37, Val Loss: 96.28641
Epoch 38, Val Loss: 99.03658
Epoch 39, Val Loss: 95.09933
Epoch 40, Val Loss: 96.20285
Epoch 41, Val Loss: 90.18163
Epoch 42, Val Loss: 93.56428
Epoch 43, Val Loss: 96.48158
Epoch 44, Val Loss: 93.90622
Epoch 45, Val Loss: 95.11700
Epoch 46, Val Loss: 90.38313
Epoch 47, Val Loss: 100.38235
Epoch 48, Val Loss: 95.17581
Epoch 49, Val Loss: 90.32448
Epoch 50, Val Loss: 114.07553
Epoch 51, Val Loss: 90.31982
Epoch 52, Val Loss: 90.60493
Epoch 53, Val Loss: 97.85284
Epoch 54, Val Loss: 91.38353
Epoch 55, Val Loss: 92.03255
Epoch 56, Val Loss: 88.43274
Epoch 57, Val Loss: 96.62403
Epoch 58, Val Loss: 93.41498
Epoch 59, Val Loss: 95.09983
Epoch 60, Val Loss: 87.60902
Epoch 61, Val Loss: 91.96046
Epoch 62, Val Loss: 92.75713
Epoch 63, Val Loss: 91.68607
Epoch 64, Val Loss: 86.99777
Epoch 65, Val Loss: 92.60710
Epoch 66, Val Loss: 83.62427
Epoch 67, Val Loss: 94.72677
Epoch 68, Val Loss: 88.80120
Epoch 69, Val Loss: 84.96941
Epoch 70, Val Loss: 92.94558
Epoch 71, Val Loss: 87.22191
Epoch 72, Val Loss: 91.40710
Epoch 73, Val Loss: 92.67207
Epoch 74, Val Loss: 95.66045
Epoch 75, Val Loss: 86.53432
Epoch 76, Val Loss: 85.22104
Epoch 77, Val Loss: 83.71794
Epoch 78, Val Loss: 83.21488
Epoch 79, Val Loss: 87.73288
Epoch 80, Val Loss: 90.11221
Epoch 81, Val Loss: 83.19057
Epoch 82, Val Loss: 84.24472
Epoch 83, Val Loss: 83.99848
Epoch 84, Val Loss: 85.36197
Epoch 85, Val Loss: 84.20628
Epoch 86, Val Loss: 86.06559
Epoch 87, Val Loss: 83.68813
Epoch 88, Val Loss: 91.77261
Epoch 89, Val Loss: 86.05853
Epoch 90, Val Loss: 84.35616
Epoch 91, Val Loss: 92.27522
Epoch 92, Val Loss: 90.76316
Epoch 93, Val Loss: 88.80657
Epoch 94, Val Loss: 86.40048
Epoch 95, Val Loss: 83.84616
Epoch 96, Val Loss: 83.84262
Epoch 97, Val Loss: 82.66175
Epoch 98, Val Loss: 82.21389
Epoch 99, Val Loss: 81.88242
DID NOT SAVE RESULTS
{'MSE - mean': 86.93591921159833, 'MSE - std': 0.0, 'R2 - mean': 0.4933954781160955, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 527.78113
Epoch 1, Val Loss: 287.32764
Epoch 2, Val Loss: 162.88020
Epoch 3, Val Loss: 147.35075
Epoch 4, Val Loss: 123.36536
Epoch 5, Val Loss: 116.61381
Epoch 6, Val Loss: 126.62659
Epoch 7, Val Loss: 110.93345
Epoch 8, Val Loss: 118.17479
Epoch 9, Val Loss: 111.11754
Epoch 10, Val Loss: 89.10519
Epoch 11, Val Loss: 90.92024
Epoch 12, Val Loss: 87.77959
Epoch 13, Val Loss: 92.96141
Epoch 14, Val Loss: 83.03761
Epoch 15, Val Loss: 97.14705
Epoch 16, Val Loss: 100.42557
Epoch 17, Val Loss: 98.16216
Epoch 18, Val Loss: 91.40108
Epoch 19, Val Loss: 90.04459
Epoch 20, Val Loss: 87.90195
Epoch 21, Val Loss: 86.04057
Epoch 22, Val Loss: 79.46616
Epoch 23, Val Loss: 88.94395
Epoch 24, Val Loss: 80.95204
Epoch 25, Val Loss: 91.19641
Epoch 26, Val Loss: 80.70222
Epoch 27, Val Loss: 84.07460
Epoch 28, Val Loss: 88.88068
Epoch 29, Val Loss: 83.55491
Epoch 30, Val Loss: 90.12042
Epoch 31, Val Loss: 85.78058
Epoch 32, Val Loss: 90.44682
Epoch 33, Val Loss: 81.94998
Epoch 34, Val Loss: 88.39489
Epoch 35, Val Loss: 88.92735
Epoch 36, Val Loss: 85.14342
Epoch 37, Val Loss: 84.31727
Epoch 38, Val Loss: 80.07252
Epoch 39, Val Loss: 76.40911
Epoch 40, Val Loss: 77.71049
Epoch 41, Val Loss: 79.84427
Epoch 42, Val Loss: 76.32304
Epoch 43, Val Loss: 84.77657
Epoch 44, Val Loss: 77.79451
Epoch 45, Val Loss: 77.03917
Epoch 46, Val Loss: 81.19788
Epoch 47, Val Loss: 77.97157
Epoch 48, Val Loss: 86.77287
Epoch 49, Val Loss: 74.96119
Epoch 50, Val Loss: 74.51085
Epoch 51, Val Loss: 73.64055
Epoch 52, Val Loss: 93.75113
Epoch 53, Val Loss: 77.04646
Epoch 54, Val Loss: 72.72288
Epoch 55, Val Loss: 72.65643
Epoch 56, Val Loss: 70.17950
Epoch 57, Val Loss: 73.54631
Epoch 58, Val Loss: 71.17305
Epoch 59, Val Loss: 88.02455
Epoch 60, Val Loss: 68.08069
Epoch 61, Val Loss: 75.20893
Epoch 62, Val Loss: 70.90124
Epoch 63, Val Loss: 69.74523
Epoch 64, Val Loss: 69.80634
Epoch 65, Val Loss: 77.44096
Epoch 66, Val Loss: 70.27369
Epoch 67, Val Loss: 74.13882
Epoch 68, Val Loss: 80.28702
Epoch 69, Val Loss: 72.65733
Epoch 70, Val Loss: 77.70533
Epoch 71, Val Loss: 71.70853
Epoch 72, Val Loss: 73.03763
Epoch 73, Val Loss: 79.73729
Epoch 74, Val Loss: 73.84163
Epoch 75, Val Loss: 68.27976
Epoch 76, Val Loss: 72.28352
Epoch 77, Val Loss: 72.20451
Epoch 78, Val Loss: 72.17731
Epoch 79, Val Loss: 71.94435
Epoch 80, Val Loss: 70.05166
Epoch 81, Val Loss: 72.05499
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.03936845232055, 'MSE - std': 5.896550759277787, 'R2 - mean': 0.5069928802699915, 'R2 - std': 0.013597402153895877} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 530.99030
Epoch 1, Val Loss: 361.43304
Epoch 2, Val Loss: 134.23990
Epoch 3, Val Loss: 114.38976
Epoch 4, Val Loss: 114.30632
Epoch 5, Val Loss: 91.82076
Epoch 6, Val Loss: 98.09017
Epoch 7, Val Loss: 92.79958
Epoch 8, Val Loss: 106.53114
Epoch 9, Val Loss: 83.88309
Epoch 10, Val Loss: 78.29985
Epoch 11, Val Loss: 86.03468
Epoch 12, Val Loss: 81.74857
Epoch 13, Val Loss: 77.58511
Epoch 14, Val Loss: 83.77082
Epoch 15, Val Loss: 92.06647
Epoch 16, Val Loss: 91.89913
Epoch 17, Val Loss: 87.62537
Epoch 18, Val Loss: 90.01967
Epoch 19, Val Loss: 86.85548
Epoch 20, Val Loss: 86.49173
Epoch 21, Val Loss: 87.85418
Epoch 22, Val Loss: 84.73346
Epoch 23, Val Loss: 80.98856
Epoch 24, Val Loss: 83.93449
Epoch 25, Val Loss: 81.75113
Epoch 26, Val Loss: 81.77893
Epoch 27, Val Loss: 86.22284
Epoch 28, Val Loss: 94.43055
Epoch 29, Val Loss: 78.55984
Epoch 30, Val Loss: 84.42859
Epoch 31, Val Loss: 78.08831
Epoch 32, Val Loss: 77.46273
Epoch 33, Val Loss: 80.94626
Epoch 34, Val Loss: 83.86047
Epoch 35, Val Loss: 83.77891
Epoch 36, Val Loss: 81.44704
Epoch 37, Val Loss: 79.18060
Epoch 38, Val Loss: 89.29203
Epoch 39, Val Loss: 110.34106
Epoch 40, Val Loss: 87.24372
Epoch 41, Val Loss: 74.61268
Epoch 42, Val Loss: 76.39011
Epoch 43, Val Loss: 96.82476
Epoch 44, Val Loss: 80.78542
Epoch 45, Val Loss: 89.01312
Epoch 46, Val Loss: 75.64579
Epoch 47, Val Loss: 74.35617
Epoch 48, Val Loss: 81.82781
Epoch 49, Val Loss: 78.83311
Epoch 50, Val Loss: 77.36130
Epoch 51, Val Loss: 77.34322
Epoch 52, Val Loss: 82.39019
Epoch 53, Val Loss: 77.38921
Epoch 54, Val Loss: 76.85761
Epoch 55, Val Loss: 79.04102
Epoch 56, Val Loss: 78.58708
Epoch 57, Val Loss: 79.73325
Epoch 58, Val Loss: 72.99297
Epoch 59, Val Loss: 72.15251
Epoch 60, Val Loss: 70.47298
Epoch 61, Val Loss: 74.46583
Epoch 62, Val Loss: 103.21825
Epoch 63, Val Loss: 72.41055
Epoch 64, Val Loss: 70.49036
Epoch 65, Val Loss: 69.44305
Epoch 66, Val Loss: 74.89622
Epoch 67, Val Loss: 67.61545
Epoch 68, Val Loss: 72.25324
Epoch 69, Val Loss: 72.34475
Epoch 70, Val Loss: 72.58905
Epoch 71, Val Loss: 68.40786
Epoch 72, Val Loss: 72.59941
Epoch 73, Val Loss: 69.95304
Epoch 74, Val Loss: 76.25059
Epoch 75, Val Loss: 70.41450
Epoch 76, Val Loss: 70.96740
Epoch 77, Val Loss: 65.96073
Epoch 78, Val Loss: 71.79706
Epoch 79, Val Loss: 69.58846
Epoch 80, Val Loss: 86.83463
Epoch 81, Val Loss: 79.99615
Epoch 82, Val Loss: 71.55535
Epoch 83, Val Loss: 69.83498
Epoch 84, Val Loss: 66.99127
Epoch 85, Val Loss: 73.57084
Epoch 86, Val Loss: 70.25153
Epoch 87, Val Loss: 68.80022
Epoch 88, Val Loss: 69.53986
Epoch 89, Val Loss: 68.14194
Epoch 90, Val Loss: 72.42912
Epoch 91, Val Loss: 71.41044
Epoch 92, Val Loss: 67.32230
Epoch 93, Val Loss: 73.99879
Epoch 94, Val Loss: 70.93861
Epoch 95, Val Loss: 71.50653
Epoch 96, Val Loss: 70.63295
Epoch 97, Val Loss: 87.19846
Epoch 98, Val Loss: 77.36197
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.404925961868, 'MSE - std': 8.132383104956606, 'R2 - mean': 0.5209188336522411, 'R2 - std': 0.02260804986649003} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1557.11072
Epoch 1, Val Loss: 409.45383
Epoch 2, Val Loss: 169.71115
Epoch 3, Val Loss: 156.42004
Epoch 4, Val Loss: 132.98372
Epoch 5, Val Loss: 137.16864
Epoch 6, Val Loss: 118.80171
Epoch 7, Val Loss: 112.69397
Epoch 8, Val Loss: 111.21634
Epoch 9, Val Loss: 114.07113
Epoch 10, Val Loss: 115.69302
Epoch 11, Val Loss: 113.32947
Epoch 12, Val Loss: 104.64954
Epoch 13, Val Loss: 97.01031
Epoch 14, Val Loss: 100.60955
Epoch 15, Val Loss: 109.13330
Epoch 16, Val Loss: 102.26460
Epoch 17, Val Loss: 99.98376
Epoch 18, Val Loss: 92.82400
Epoch 19, Val Loss: 96.84604
Epoch 20, Val Loss: 100.04474
Epoch 21, Val Loss: 98.09889
Epoch 22, Val Loss: 94.77705
Epoch 23, Val Loss: 98.77335
Epoch 24, Val Loss: 90.84502
Epoch 25, Val Loss: 91.60130
Epoch 26, Val Loss: 95.75705
Epoch 27, Val Loss: 90.74080
Epoch 28, Val Loss: 92.01216
Epoch 29, Val Loss: 91.24574
Epoch 30, Val Loss: 92.16925
Epoch 31, Val Loss: 106.17992
Epoch 32, Val Loss: 95.47288
Epoch 33, Val Loss: 102.78480
Epoch 34, Val Loss: 95.55059
Epoch 35, Val Loss: 90.00824
Epoch 36, Val Loss: 110.21555
Epoch 37, Val Loss: 88.66895
Epoch 38, Val Loss: 91.94051
Epoch 39, Val Loss: 94.85412
Epoch 40, Val Loss: 100.14748
Epoch 41, Val Loss: 104.89439
Epoch 42, Val Loss: 87.74687
Epoch 43, Val Loss: 93.55358
Epoch 44, Val Loss: 108.29504
Epoch 45, Val Loss: 88.26346
Epoch 46, Val Loss: 98.15007
Epoch 47, Val Loss: 97.73082
Epoch 48, Val Loss: 85.58866
Epoch 49, Val Loss: 85.40176
Epoch 50, Val Loss: 92.97441
Epoch 51, Val Loss: 86.94630
Epoch 52, Val Loss: 91.64232
Epoch 53, Val Loss: 79.48489
Epoch 54, Val Loss: 82.98092
Epoch 55, Val Loss: 85.70312
Epoch 56, Val Loss: 83.93678
Epoch 57, Val Loss: 94.65732
Epoch 58, Val Loss: 85.72382
Epoch 59, Val Loss: 81.97990
Epoch 60, Val Loss: 81.38602
Epoch 61, Val Loss: 85.15967
Epoch 62, Val Loss: 89.92870
Epoch 63, Val Loss: 82.03763
Epoch 64, Val Loss: 92.08848
Epoch 65, Val Loss: 85.48698
Epoch 66, Val Loss: 86.92906
Epoch 67, Val Loss: 104.33499
Epoch 68, Val Loss: 82.33310
Epoch 69, Val Loss: 80.59070
Epoch 70, Val Loss: 83.35460
Epoch 71, Val Loss: 80.04305
Epoch 72, Val Loss: 77.34343
Epoch 73, Val Loss: 76.44828
Epoch 74, Val Loss: 79.15517
Epoch 75, Val Loss: 80.81729
Epoch 76, Val Loss: 79.67139
Epoch 77, Val Loss: 82.45830
Epoch 78, Val Loss: 81.01614
Epoch 79, Val Loss: 84.79775
Epoch 80, Val Loss: 77.06338
Epoch 81, Val Loss: 77.71782
Epoch 82, Val Loss: 80.77302
Epoch 83, Val Loss: 77.65213
Epoch 84, Val Loss: 75.86733
Epoch 85, Val Loss: 76.21670
Epoch 86, Val Loss: 78.97622
Epoch 87, Val Loss: 82.85680
Epoch 88, Val Loss: 85.94946
Epoch 89, Val Loss: 80.37174
Epoch 90, Val Loss: 77.83636
Epoch 91, Val Loss: 79.69086
Epoch 92, Val Loss: 80.56680
Epoch 93, Val Loss: 80.82513
Epoch 94, Val Loss: 82.68994
Epoch 95, Val Loss: 78.49622
Epoch 96, Val Loss: 77.57787
Epoch 97, Val Loss: 77.57858
Epoch 98, Val Loss: 77.28885
Epoch 99, Val Loss: 76.66190
DID NOT SAVE RESULTS
{'MSE - mean': 78.6341542805086, 'MSE - std': 8.031819091228662, 'R2 - mean': 0.5128623489930729, 'R2 - std': 0.024042956853609174} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 488.08167
Epoch 1, Val Loss: 304.04349
Epoch 2, Val Loss: 162.90329
Epoch 3, Val Loss: 133.90515
Epoch 4, Val Loss: 119.68551
Epoch 5, Val Loss: 118.85251
Epoch 6, Val Loss: 122.50123
Epoch 7, Val Loss: 121.05183
Epoch 8, Val Loss: 99.94735
Epoch 9, Val Loss: 108.51430
Epoch 10, Val Loss: 94.11713
Epoch 11, Val Loss: 107.00438
Epoch 12, Val Loss: 110.58884
Epoch 13, Val Loss: 100.94241
Epoch 14, Val Loss: 108.66586
Epoch 15, Val Loss: 92.92459
Epoch 16, Val Loss: 98.98764
Epoch 17, Val Loss: 94.82562
Epoch 18, Val Loss: 91.78321
Epoch 19, Val Loss: 83.64368
Epoch 20, Val Loss: 90.06532
Epoch 21, Val Loss: 95.11456
Epoch 22, Val Loss: 101.28358
Epoch 23, Val Loss: 97.54517
Epoch 24, Val Loss: 88.01751
Epoch 25, Val Loss: 92.39352
Epoch 26, Val Loss: 92.07243
Epoch 27, Val Loss: 98.13345
Epoch 28, Val Loss: 86.25398
Epoch 29, Val Loss: 104.95411
Epoch 30, Val Loss: 86.10190
Epoch 31, Val Loss: 93.90280
Epoch 32, Val Loss: 102.76691
Epoch 33, Val Loss: 97.80203
Epoch 34, Val Loss: 86.07558
Epoch 35, Val Loss: 88.00404
Epoch 36, Val Loss: 98.97644
Epoch 37, Val Loss: 84.96549
Epoch 38, Val Loss: 88.51660
Epoch 39, Val Loss: 105.59370
Epoch 40, Val Loss: 89.85336
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.8711814774552, 'MSE - std': 7.59796285035156, 'R2 - mean': 0.5039006998870914, 'R2 - std': 0.027994564440379704} 
 

Results After CV: {'MSE - mean': 79.8711814774552, 'MSE - std': 7.59796285035156, 'R2 - mean': 0.5039006998870914, 'R2 - std': 0.027994564440379704}
Train time: 399.33876235280184
Inference time: 0.189833065593848
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 69 finished with value: 79.8711814774552 and parameters: {'p_m': 0.17141925622528661, 'alpha': 9.12652619451571, 'K': 2, 'beta': 6.047746552963484}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1076.98950
Epoch 1, Val Loss: 415.94220
Epoch 2, Val Loss: 218.90497
Epoch 3, Val Loss: 171.21223
Epoch 4, Val Loss: 154.39149
Epoch 5, Val Loss: 136.72130
Epoch 6, Val Loss: 135.12402
Epoch 7, Val Loss: 131.22084
Epoch 8, Val Loss: 123.23415
Epoch 9, Val Loss: 128.88176
Epoch 10, Val Loss: 125.27519
Epoch 11, Val Loss: 135.55728
Epoch 12, Val Loss: 111.86917
Epoch 13, Val Loss: 113.28703
Epoch 14, Val Loss: 106.84942
Epoch 15, Val Loss: 104.97253
Epoch 16, Val Loss: 101.29472
Epoch 17, Val Loss: 102.92918
Epoch 18, Val Loss: 110.38410
Epoch 19, Val Loss: 101.58484
Epoch 20, Val Loss: 108.56699
Epoch 21, Val Loss: 97.62312
Epoch 22, Val Loss: 115.00633
Epoch 23, Val Loss: 126.93390
Epoch 24, Val Loss: 104.32169
Epoch 25, Val Loss: 95.95492
Epoch 26, Val Loss: 99.64194
Epoch 27, Val Loss: 106.16275
Epoch 28, Val Loss: 98.77594
Epoch 29, Val Loss: 92.10410
Epoch 30, Val Loss: 89.51884
Epoch 31, Val Loss: 99.66132
Epoch 32, Val Loss: 89.49770
Epoch 33, Val Loss: 89.66904
Epoch 34, Val Loss: 106.58439
Epoch 35, Val Loss: 88.66596
Epoch 36, Val Loss: 87.85931
Epoch 37, Val Loss: 87.03978
Epoch 38, Val Loss: 92.93771
Epoch 39, Val Loss: 88.64904
Epoch 40, Val Loss: 86.18280
Epoch 41, Val Loss: 82.86430
Epoch 42, Val Loss: 90.07644
Epoch 43, Val Loss: 90.71453
Epoch 44, Val Loss: 89.61948
Epoch 45, Val Loss: 93.29572
Epoch 46, Val Loss: 87.25708
Epoch 47, Val Loss: 85.55724
Epoch 48, Val Loss: 98.43987
Epoch 49, Val Loss: 85.90291
Epoch 50, Val Loss: 85.08560
Epoch 51, Val Loss: 86.07297
Epoch 52, Val Loss: 82.37766
Epoch 53, Val Loss: 91.31831
Epoch 54, Val Loss: 89.02287
Epoch 55, Val Loss: 93.19257
Epoch 56, Val Loss: 86.88951
Epoch 57, Val Loss: 85.57780
Epoch 58, Val Loss: 90.90040
Epoch 59, Val Loss: 86.58157
Epoch 60, Val Loss: 86.41917
Epoch 61, Val Loss: 87.00928
Epoch 62, Val Loss: 87.71854
Epoch 63, Val Loss: 86.44417
Epoch 64, Val Loss: 85.78906
Epoch 65, Val Loss: 87.83012
Epoch 66, Val Loss: 95.26979
Epoch 67, Val Loss: 83.91344
Epoch 68, Val Loss: 86.77161
Epoch 69, Val Loss: 88.07339
Epoch 70, Val Loss: 89.19284
Epoch 71, Val Loss: 88.97589
Epoch 72, Val Loss: 86.14934
Epoch 73, Val Loss: 90.33298
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.9164568980755, 'MSE - std': 0.0, 'R2 - mean': 0.49350889149144606, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 646.91571
Epoch 1, Val Loss: 391.86639
Epoch 2, Val Loss: 163.61435
Epoch 3, Val Loss: 162.28383
Epoch 4, Val Loss: 135.10924
Epoch 5, Val Loss: 129.94838
Epoch 6, Val Loss: 128.86736
Epoch 7, Val Loss: 121.39059
Epoch 8, Val Loss: 101.31941
Epoch 9, Val Loss: 95.75378
Epoch 10, Val Loss: 104.94617
Epoch 11, Val Loss: 108.98055
Epoch 12, Val Loss: 91.24863
Epoch 13, Val Loss: 87.35024
Epoch 14, Val Loss: 100.63002
Epoch 15, Val Loss: 108.32759
Epoch 16, Val Loss: 92.14762
Epoch 17, Val Loss: 90.12891
Epoch 18, Val Loss: 95.04789
Epoch 19, Val Loss: 88.25520
Epoch 20, Val Loss: 87.58364
Epoch 21, Val Loss: 91.55869
Epoch 22, Val Loss: 91.83461
Epoch 23, Val Loss: 89.94878
Epoch 24, Val Loss: 84.78059
Epoch 25, Val Loss: 80.14993
Epoch 26, Val Loss: 95.85856
Epoch 27, Val Loss: 88.89835
Epoch 28, Val Loss: 83.96199
Epoch 29, Val Loss: 79.20294
Epoch 30, Val Loss: 78.58884
Epoch 31, Val Loss: 82.09570
Epoch 32, Val Loss: 90.08433
Epoch 33, Val Loss: 83.70757
Epoch 34, Val Loss: 74.86908
Epoch 35, Val Loss: 77.16090
Epoch 36, Val Loss: 76.32887
Epoch 37, Val Loss: 80.02269
Epoch 38, Val Loss: 77.95399
Epoch 39, Val Loss: 76.29539
Epoch 40, Val Loss: 77.66724
Epoch 41, Val Loss: 82.04716
Epoch 42, Val Loss: 71.40718
Epoch 43, Val Loss: 70.35538
Epoch 44, Val Loss: 74.07842
Epoch 45, Val Loss: 77.76624
Epoch 46, Val Loss: 74.58765
Epoch 47, Val Loss: 75.70518
Epoch 48, Val Loss: 85.01379
Epoch 49, Val Loss: 75.27911
Epoch 50, Val Loss: 86.68264
Epoch 51, Val Loss: 79.14388
Epoch 52, Val Loss: 75.03908
Epoch 53, Val Loss: 75.96313
Epoch 54, Val Loss: 78.28326
Epoch 55, Val Loss: 75.38041
Epoch 56, Val Loss: 84.04501
Epoch 57, Val Loss: 84.51418
Epoch 58, Val Loss: 74.43215
Epoch 59, Val Loss: 76.68824
Epoch 60, Val Loss: 78.02077
Epoch 61, Val Loss: 75.41284
Epoch 62, Val Loss: 83.70854
Epoch 63, Val Loss: 72.74473
Epoch 64, Val Loss: 72.85687
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.76713325657681, 'MSE - std': 4.1493236414986825, 'R2 - mean': 0.49596439646928486, 'R2 - std': 0.002455504977838807} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1130.72144
Epoch 1, Val Loss: 471.68958
Epoch 2, Val Loss: 153.76863
Epoch 3, Val Loss: 138.55635
Epoch 4, Val Loss: 118.49464
Epoch 5, Val Loss: 112.33017
Epoch 6, Val Loss: 124.26696
Epoch 7, Val Loss: 92.17730
Epoch 8, Val Loss: 114.76064
Epoch 9, Val Loss: 88.21969
Epoch 10, Val Loss: 90.73091
Epoch 11, Val Loss: 105.56675
Epoch 12, Val Loss: 103.20554
Epoch 13, Val Loss: 87.69548
Epoch 14, Val Loss: 84.13759
Epoch 15, Val Loss: 91.40541
Epoch 16, Val Loss: 87.48131
Epoch 17, Val Loss: 83.56994
Epoch 18, Val Loss: 77.30474
Epoch 19, Val Loss: 84.08543
Epoch 20, Val Loss: 92.65725
Epoch 21, Val Loss: 75.15899
Epoch 22, Val Loss: 74.14299
Epoch 23, Val Loss: 80.12064
Epoch 24, Val Loss: 82.75764
Epoch 25, Val Loss: 81.38880
Epoch 26, Val Loss: 84.64780
Epoch 27, Val Loss: 76.63315
Epoch 28, Val Loss: 81.96655
Epoch 29, Val Loss: 78.57524
Epoch 30, Val Loss: 77.24381
Epoch 31, Val Loss: 82.37907
Epoch 32, Val Loss: 88.66776
Epoch 33, Val Loss: 76.15590
Epoch 34, Val Loss: 73.30597
Epoch 35, Val Loss: 72.99320
Epoch 36, Val Loss: 69.27495
Epoch 37, Val Loss: 72.22260
Epoch 38, Val Loss: 77.80307
Epoch 39, Val Loss: 78.22214
Epoch 40, Val Loss: 68.46997
Epoch 41, Val Loss: 68.63366
Epoch 42, Val Loss: 69.47141
Epoch 43, Val Loss: 77.75750
Epoch 44, Val Loss: 70.58456
Epoch 45, Val Loss: 76.67010
Epoch 46, Val Loss: 74.65218
Epoch 47, Val Loss: 67.48955
Epoch 48, Val Loss: 71.40078
Epoch 49, Val Loss: 71.38341
Epoch 50, Val Loss: 76.54680
Epoch 51, Val Loss: 73.54734
Epoch 52, Val Loss: 75.69106
Epoch 53, Val Loss: 68.36639
Epoch 54, Val Loss: 70.42669
Epoch 55, Val Loss: 70.16599
Epoch 56, Val Loss: 69.98630
Epoch 57, Val Loss: 67.64170
Epoch 58, Val Loss: 74.82294
Epoch 59, Val Loss: 71.43681
Epoch 60, Val Loss: 71.20673
Epoch 61, Val Loss: 73.89275
Epoch 62, Val Loss: 69.86095
Epoch 63, Val Loss: 71.30808
Epoch 64, Val Loss: 77.92345
Epoch 65, Val Loss: 70.50630
Epoch 66, Val Loss: 74.30144
Epoch 67, Val Loss: 67.92862
Epoch 68, Val Loss: 77.57234
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.85249384819913, 'MSE - std': 7.732094508175503, 'R2 - mean': 0.5115789105983054, 'R2 - std': 0.022173086676604753} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1331.36768
Epoch 1, Val Loss: 433.03421
Epoch 2, Val Loss: 185.04004
Epoch 3, Val Loss: 168.63918
Epoch 4, Val Loss: 155.71181
Epoch 5, Val Loss: 143.72127
Epoch 6, Val Loss: 134.44632
Epoch 7, Val Loss: 118.81883
Epoch 8, Val Loss: 110.39838
Epoch 9, Val Loss: 120.37701
Epoch 10, Val Loss: 128.76216
Epoch 11, Val Loss: 116.49506
Epoch 12, Val Loss: 101.89880
Epoch 13, Val Loss: 112.84297
Epoch 14, Val Loss: 102.86235
Epoch 15, Val Loss: 108.07294
Epoch 16, Val Loss: 103.48201
Epoch 17, Val Loss: 104.79465
Epoch 18, Val Loss: 91.09317
Epoch 19, Val Loss: 100.99274
Epoch 20, Val Loss: 96.30415
Epoch 21, Val Loss: 94.07210
Epoch 22, Val Loss: 115.22370
Epoch 23, Val Loss: 98.51808
Epoch 24, Val Loss: 88.08936
Epoch 25, Val Loss: 104.22366
Epoch 26, Val Loss: 93.49516
Epoch 27, Val Loss: 89.97161
Epoch 28, Val Loss: 88.31338
Epoch 29, Val Loss: 93.08797
Epoch 30, Val Loss: 87.36996
Epoch 31, Val Loss: 90.83739
Epoch 32, Val Loss: 92.68810
Epoch 33, Val Loss: 87.35525
Epoch 34, Val Loss: 88.11646
Epoch 35, Val Loss: 81.35649
Epoch 36, Val Loss: 92.39789
Epoch 37, Val Loss: 90.05333
Epoch 38, Val Loss: 92.31196
Epoch 39, Val Loss: 81.21088
Epoch 40, Val Loss: 83.30824
Epoch 41, Val Loss: 80.47908
Epoch 42, Val Loss: 83.29133
Epoch 43, Val Loss: 81.37403
Epoch 44, Val Loss: 84.85764
Epoch 45, Val Loss: 86.70392
Epoch 46, Val Loss: 81.55618
Epoch 47, Val Loss: 83.78394
Epoch 48, Val Loss: 83.26015
Epoch 49, Val Loss: 81.90215
Epoch 50, Val Loss: 82.75975
Epoch 51, Val Loss: 80.56375
Epoch 52, Val Loss: 94.79164
Epoch 53, Val Loss: 82.12872
Epoch 54, Val Loss: 106.86098
Epoch 55, Val Loss: 81.45399
Epoch 56, Val Loss: 84.55113
Epoch 57, Val Loss: 83.78020
Epoch 58, Val Loss: 80.61205
Epoch 59, Val Loss: 83.79123
Epoch 60, Val Loss: 81.34818
Epoch 61, Val Loss: 82.66969
Epoch 62, Val Loss: 89.39652
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.50653212776506, 'MSE - std': 9.213845633508164, 'R2 - mean': 0.49515026066877493, 'R2 - std': 0.03432835482654767} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 829.65387
Epoch 1, Val Loss: 409.41382
Epoch 2, Val Loss: 204.30981
Epoch 3, Val Loss: 153.56630
Epoch 4, Val Loss: 139.67279
Epoch 5, Val Loss: 130.57489
Epoch 6, Val Loss: 162.78401
Epoch 7, Val Loss: 121.92620
Epoch 8, Val Loss: 106.30810
Epoch 9, Val Loss: 113.17033
Epoch 10, Val Loss: 130.58688
Epoch 11, Val Loss: 106.09862
Epoch 12, Val Loss: 104.29462
Epoch 13, Val Loss: 95.73189
Epoch 14, Val Loss: 93.73537
Epoch 15, Val Loss: 97.37659
Epoch 16, Val Loss: 92.21988
Epoch 17, Val Loss: 97.42336
Epoch 18, Val Loss: 99.76821
Epoch 19, Val Loss: 95.49282
Epoch 20, Val Loss: 91.13901
Epoch 21, Val Loss: 95.03144
Epoch 22, Val Loss: 84.51194
Epoch 23, Val Loss: 85.08617
Epoch 24, Val Loss: 85.16753
Epoch 25, Val Loss: 81.06419
Epoch 26, Val Loss: 85.56599
Epoch 27, Val Loss: 84.18391
Epoch 28, Val Loss: 78.54328
Epoch 29, Val Loss: 83.08846
Epoch 30, Val Loss: 76.85105
Epoch 31, Val Loss: 97.70061
Epoch 32, Val Loss: 80.41047
Epoch 33, Val Loss: 73.22651
Epoch 34, Val Loss: 83.14348
Epoch 35, Val Loss: 73.76014
Epoch 36, Val Loss: 83.61724
Epoch 37, Val Loss: 73.60282
Epoch 38, Val Loss: 79.59532
Epoch 39, Val Loss: 76.93279
Epoch 40, Val Loss: 90.86162
Epoch 41, Val Loss: 76.21951
Epoch 42, Val Loss: 77.56593
Epoch 43, Val Loss: 80.62012
Epoch 44, Val Loss: 78.56068
Epoch 45, Val Loss: 76.58961
Epoch 46, Val Loss: 75.80080
Epoch 47, Val Loss: 77.99880
Epoch 48, Val Loss: 80.11546
Epoch 49, Val Loss: 85.48280
Epoch 50, Val Loss: 75.39964
Epoch 51, Val Loss: 81.03689
Epoch 52, Val Loss: 78.67782
Epoch 53, Val Loss: 74.25786
Epoch 54, Val Loss: 82.08824
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.12783621247164, 'MSE - std': 8.690176683697581, 'R2 - mean': 0.5025327545286642, 'R2 - std': 0.03406983443521703} 
 

Results After CV: {'MSE - mean': 80.12783621247164, 'MSE - std': 8.690176683697581, 'R2 - mean': 0.5025327545286642, 'R2 - std': 0.03406983443521703}
Train time: 739.0202772680088
Inference time: 0.19194987979717554
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 70 finished with value: 80.12783621247164 and parameters: {'p_m': 0.3635609796422704, 'alpha': 9.785478832691838, 'K': 5, 'beta': 5.707286166960377}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 495.43747
Epoch 1, Val Loss: 418.39554
Epoch 2, Val Loss: 216.24323
Epoch 3, Val Loss: 174.87860
Epoch 4, Val Loss: 164.28656
Epoch 5, Val Loss: 155.36967
Epoch 6, Val Loss: 145.54121
Epoch 7, Val Loss: 122.41254
Epoch 8, Val Loss: 134.27690
Epoch 9, Val Loss: 126.52583
Epoch 10, Val Loss: 132.85297
Epoch 11, Val Loss: 120.09197
Epoch 12, Val Loss: 115.13826
Epoch 13, Val Loss: 109.44046
Epoch 14, Val Loss: 107.18192
Epoch 15, Val Loss: 110.01377
Epoch 16, Val Loss: 108.94688
Epoch 17, Val Loss: 110.73497
Epoch 18, Val Loss: 109.63130
Epoch 19, Val Loss: 108.79076
Epoch 20, Val Loss: 130.52164
Epoch 21, Val Loss: 109.80022
Epoch 22, Val Loss: 104.39841
Epoch 23, Val Loss: 103.05559
Epoch 24, Val Loss: 104.75946
Epoch 25, Val Loss: 98.48158
Epoch 26, Val Loss: 106.05389
Epoch 27, Val Loss: 120.78109
Epoch 28, Val Loss: 107.17921
Epoch 29, Val Loss: 106.60001
Epoch 30, Val Loss: 127.76627
Epoch 31, Val Loss: 98.54817
Epoch 32, Val Loss: 92.18549
Epoch 33, Val Loss: 94.13128
Epoch 34, Val Loss: 95.31216
Epoch 35, Val Loss: 103.05994
Epoch 36, Val Loss: 91.95399
Epoch 37, Val Loss: 112.55319
Epoch 38, Val Loss: 92.95438
Epoch 39, Val Loss: 90.89880
Epoch 40, Val Loss: 94.81138
Epoch 41, Val Loss: 97.93900
Epoch 42, Val Loss: 119.52206
Epoch 43, Val Loss: 98.72368
Epoch 44, Val Loss: 90.20757
Epoch 45, Val Loss: 90.40591
Epoch 46, Val Loss: 87.71721
Epoch 47, Val Loss: 90.22815
Epoch 48, Val Loss: 91.74178
Epoch 49, Val Loss: 96.33778
Epoch 50, Val Loss: 86.83849
Epoch 51, Val Loss: 92.41552
Epoch 52, Val Loss: 89.42622
Epoch 53, Val Loss: 92.93753
Epoch 54, Val Loss: 88.32039
Epoch 55, Val Loss: 85.67987
Epoch 56, Val Loss: 86.24643
Epoch 57, Val Loss: 86.57247
Epoch 58, Val Loss: 87.39621
Epoch 59, Val Loss: 89.53258
Epoch 60, Val Loss: 86.56056
Epoch 61, Val Loss: 86.33795
Epoch 62, Val Loss: 88.12459
Epoch 63, Val Loss: 91.70502
Epoch 64, Val Loss: 88.29217
Epoch 65, Val Loss: 88.23323
Epoch 66, Val Loss: 84.74105
Epoch 67, Val Loss: 85.76683
Epoch 68, Val Loss: 87.41785
Epoch 69, Val Loss: 85.77434
Epoch 70, Val Loss: 86.92312
Epoch 71, Val Loss: 84.32565
Epoch 72, Val Loss: 83.71210
Epoch 73, Val Loss: 92.03130
Epoch 74, Val Loss: 87.27303
Epoch 75, Val Loss: 94.07986
Epoch 76, Val Loss: 90.01021
Epoch 77, Val Loss: 93.75580
Epoch 78, Val Loss: 87.20088
Epoch 79, Val Loss: 99.88940
Epoch 80, Val Loss: 80.81531
Epoch 81, Val Loss: 87.20891
Epoch 82, Val Loss: 87.90562
Epoch 83, Val Loss: 81.77161
Epoch 84, Val Loss: 85.29625
Epoch 85, Val Loss: 87.72534
Epoch 86, Val Loss: 92.55289
Epoch 87, Val Loss: 84.99214
Epoch 88, Val Loss: 85.04129
Epoch 89, Val Loss: 87.99841
Epoch 90, Val Loss: 91.31927
Epoch 91, Val Loss: 87.49008
Epoch 92, Val Loss: 86.24375
Epoch 93, Val Loss: 90.30455
Epoch 94, Val Loss: 84.86345
Epoch 95, Val Loss: 82.85613
Epoch 96, Val Loss: 85.28310
Epoch 97, Val Loss: 85.25484
Epoch 98, Val Loss: 83.24646
Epoch 99, Val Loss: 84.31673
DID NOT SAVE RESULTS
{'MSE - mean': 83.95079951932443, 'MSE - std': 0.0, 'R2 - mean': 0.5107907636112639, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 501.90787
Epoch 1, Val Loss: 428.81567
Epoch 2, Val Loss: 189.70349
Epoch 3, Val Loss: 150.33330
Epoch 4, Val Loss: 144.12050
Epoch 5, Val Loss: 126.74647
Epoch 6, Val Loss: 127.06660
Epoch 7, Val Loss: 131.53447
Epoch 8, Val Loss: 118.68350
Epoch 9, Val Loss: 103.55481
Epoch 10, Val Loss: 103.91499
Epoch 11, Val Loss: 111.20731
Epoch 12, Val Loss: 94.14243
Epoch 13, Val Loss: 106.42545
Epoch 14, Val Loss: 96.87341
Epoch 15, Val Loss: 100.74912
Epoch 16, Val Loss: 98.97507
Epoch 17, Val Loss: 89.42206
Epoch 18, Val Loss: 99.61733
Epoch 19, Val Loss: 98.73049
Epoch 20, Val Loss: 92.07542
Epoch 21, Val Loss: 101.14904
Epoch 22, Val Loss: 83.23405
Epoch 23, Val Loss: 89.42981
Epoch 24, Val Loss: 102.89100
Epoch 25, Val Loss: 86.70108
Epoch 26, Val Loss: 111.24350
Epoch 27, Val Loss: 86.49078
Epoch 28, Val Loss: 84.07360
Epoch 29, Val Loss: 83.57716
Epoch 30, Val Loss: 79.47444
Epoch 31, Val Loss: 80.81813
Epoch 32, Val Loss: 87.54272
Epoch 33, Val Loss: 100.69247
Epoch 34, Val Loss: 82.79405
Epoch 35, Val Loss: 105.88641
Epoch 36, Val Loss: 86.53715
Epoch 37, Val Loss: 79.53788
Epoch 38, Val Loss: 81.31628
Epoch 39, Val Loss: 83.74940
Epoch 40, Val Loss: 87.73087
Epoch 41, Val Loss: 81.23719
Epoch 42, Val Loss: 76.23910
Epoch 43, Val Loss: 77.07314
Epoch 44, Val Loss: 77.06348
Epoch 45, Val Loss: 91.80594
Epoch 46, Val Loss: 84.16684
Epoch 47, Val Loss: 76.25475
Epoch 48, Val Loss: 79.77166
Epoch 49, Val Loss: 80.98247
Epoch 50, Val Loss: 71.07050
Epoch 51, Val Loss: 76.93573
Epoch 52, Val Loss: 80.70505
Epoch 53, Val Loss: 78.81628
Epoch 54, Val Loss: 75.38335
Epoch 55, Val Loss: 79.47660
Epoch 56, Val Loss: 79.35312
Epoch 57, Val Loss: 74.56329
Epoch 58, Val Loss: 75.42265
Epoch 59, Val Loss: 73.67752
Epoch 60, Val Loss: 73.12942
Epoch 61, Val Loss: 74.50845
Epoch 62, Val Loss: 90.30897
Epoch 63, Val Loss: 89.31584
Epoch 64, Val Loss: 80.46756
Epoch 65, Val Loss: 90.06210
Epoch 66, Val Loss: 76.10207
Epoch 67, Val Loss: 75.00837
Epoch 68, Val Loss: 72.58050
Epoch 69, Val Loss: 76.80139
Epoch 70, Val Loss: 94.26754
Epoch 71, Val Loss: 81.10445
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.26614675752242, 'MSE - std': 2.684652761802006, 'R2 - mean': 0.5047211790023125, 'R2 - std': 0.0060695846089513505} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 490.44476
Epoch 1, Val Loss: 357.64435
Epoch 2, Val Loss: 157.00198
Epoch 3, Val Loss: 128.08089
Epoch 4, Val Loss: 132.75165
Epoch 5, Val Loss: 132.79996
Epoch 6, Val Loss: 119.07471
Epoch 7, Val Loss: 104.05078
Epoch 8, Val Loss: 113.30082
Epoch 9, Val Loss: 95.39304
Epoch 10, Val Loss: 110.55324
Epoch 11, Val Loss: 91.86959
Epoch 12, Val Loss: 92.61241
Epoch 13, Val Loss: 100.74863
Epoch 14, Val Loss: 89.25818
Epoch 15, Val Loss: 93.96761
Epoch 16, Val Loss: 86.06972
Epoch 17, Val Loss: 90.40563
Epoch 18, Val Loss: 79.88015
Epoch 19, Val Loss: 90.16408
Epoch 20, Val Loss: 76.20872
Epoch 21, Val Loss: 84.73222
Epoch 22, Val Loss: 97.57410
Epoch 23, Val Loss: 75.37381
Epoch 24, Val Loss: 109.13901
Epoch 25, Val Loss: 83.12813
Epoch 26, Val Loss: 81.06731
Epoch 27, Val Loss: 77.96681
Epoch 28, Val Loss: 84.48508
Epoch 29, Val Loss: 79.48117
Epoch 30, Val Loss: 86.35881
Epoch 31, Val Loss: 78.01599
Epoch 32, Val Loss: 99.15637
Epoch 33, Val Loss: 85.36787
Epoch 34, Val Loss: 78.35915
Epoch 35, Val Loss: 84.94794
Epoch 36, Val Loss: 89.61795
Epoch 37, Val Loss: 73.57414
Epoch 38, Val Loss: 78.14937
Epoch 39, Val Loss: 93.08791
Epoch 40, Val Loss: 87.17546
Epoch 41, Val Loss: 73.59701
Epoch 42, Val Loss: 77.73420
Epoch 43, Val Loss: 74.48817
Epoch 44, Val Loss: 72.66354
Epoch 45, Val Loss: 72.35385
Epoch 46, Val Loss: 76.42650
Epoch 47, Val Loss: 71.72483
Epoch 48, Val Loss: 76.47594
Epoch 49, Val Loss: 73.25181
Epoch 50, Val Loss: 71.38277
Epoch 51, Val Loss: 69.20747
Epoch 52, Val Loss: 70.06429
Epoch 53, Val Loss: 69.50038
Epoch 54, Val Loss: 71.45360
Epoch 55, Val Loss: 73.19975
Epoch 56, Val Loss: 74.28368
Epoch 57, Val Loss: 73.27473
Epoch 58, Val Loss: 67.29314
Epoch 59, Val Loss: 75.96996
Epoch 60, Val Loss: 75.54750
Epoch 61, Val Loss: 77.24062
Epoch 62, Val Loss: 69.30383
Epoch 63, Val Loss: 70.07103
Epoch 64, Val Loss: 71.29807
Epoch 65, Val Loss: 70.13022
Epoch 66, Val Loss: 72.86034
Epoch 67, Val Loss: 70.13686
Epoch 68, Val Loss: 68.39431
Epoch 69, Val Loss: 82.76031
Epoch 70, Val Loss: 70.81602
Epoch 71, Val Loss: 82.21912
Epoch 72, Val Loss: 76.97713
Epoch 73, Val Loss: 66.61477
Epoch 74, Val Loss: 75.35609
Epoch 75, Val Loss: 76.41118
Epoch 76, Val Loss: 71.04308
Epoch 77, Val Loss: 69.11098
Epoch 78, Val Loss: 70.68011
Epoch 79, Val Loss: 82.93311
Epoch 80, Val Loss: 67.85701
Epoch 81, Val Loss: 71.56590
Epoch 82, Val Loss: 74.32777
Epoch 83, Val Loss: 68.33999
Epoch 84, Val Loss: 78.82623
Epoch 85, Val Loss: 70.08537
Epoch 86, Val Loss: 68.68914
Epoch 87, Val Loss: 70.07639
Epoch 88, Val Loss: 70.99995
Epoch 89, Val Loss: 71.92001
Epoch 90, Val Loss: 71.54431
Epoch 91, Val Loss: 72.66852
Epoch 92, Val Loss: 69.28352
Epoch 93, Val Loss: 70.44382
Epoch 94, Val Loss: 71.83347
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.73454943600017, 'MSE - std': 6.7731569844858655, 'R2 - mean': 0.5182050636917716, 'R2 - std': 0.019702542920159813} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 799.96057
Epoch 1, Val Loss: 435.13455
Epoch 2, Val Loss: 169.06863
Epoch 3, Val Loss: 162.47800
Epoch 4, Val Loss: 152.04962
Epoch 5, Val Loss: 136.02222
Epoch 6, Val Loss: 117.12904
Epoch 7, Val Loss: 127.88805
Epoch 8, Val Loss: 116.25120
Epoch 9, Val Loss: 106.84504
Epoch 10, Val Loss: 104.65560
Epoch 11, Val Loss: 111.78338
Epoch 12, Val Loss: 116.20100
Epoch 13, Val Loss: 105.02808
Epoch 14, Val Loss: 100.95299
Epoch 15, Val Loss: 100.00474
Epoch 16, Val Loss: 99.25356
Epoch 17, Val Loss: 101.95105
Epoch 18, Val Loss: 94.48489
Epoch 19, Val Loss: 97.01508
Epoch 20, Val Loss: 102.47641
Epoch 21, Val Loss: 99.33315
Epoch 22, Val Loss: 108.17666
Epoch 23, Val Loss: 110.67379
Epoch 24, Val Loss: 99.49744
Epoch 25, Val Loss: 92.90215
Epoch 26, Val Loss: 101.84750
Epoch 27, Val Loss: 98.66206
Epoch 28, Val Loss: 92.23000
Epoch 29, Val Loss: 93.47619
Epoch 30, Val Loss: 94.07584
Epoch 31, Val Loss: 91.16845
Epoch 32, Val Loss: 96.20549
Epoch 33, Val Loss: 87.93138
Epoch 34, Val Loss: 92.63451
Epoch 35, Val Loss: 94.25616
Epoch 36, Val Loss: 105.09055
Epoch 37, Val Loss: 87.24403
Epoch 38, Val Loss: 83.42737
Epoch 39, Val Loss: 83.26605
Epoch 40, Val Loss: 93.16306
Epoch 41, Val Loss: 90.01123
Epoch 42, Val Loss: 86.51468
Epoch 43, Val Loss: 100.80642
Epoch 44, Val Loss: 80.15131
Epoch 45, Val Loss: 80.98308
Epoch 46, Val Loss: 84.93439
Epoch 47, Val Loss: 84.04844
Epoch 48, Val Loss: 85.15779
Epoch 49, Val Loss: 84.50735
Epoch 50, Val Loss: 88.18584
Epoch 51, Val Loss: 80.85225
Epoch 52, Val Loss: 84.47001
Epoch 53, Val Loss: 81.40228
Epoch 54, Val Loss: 78.31995
Epoch 55, Val Loss: 80.33867
Epoch 56, Val Loss: 81.32581
Epoch 57, Val Loss: 88.36464
Epoch 58, Val Loss: 80.44318
Epoch 59, Val Loss: 78.35926
Epoch 60, Val Loss: 81.49771
Epoch 61, Val Loss: 82.00237
Epoch 62, Val Loss: 81.53954
Epoch 63, Val Loss: 77.73004
Epoch 64, Val Loss: 85.61358
Epoch 65, Val Loss: 84.85309
Epoch 66, Val Loss: 78.20789
Epoch 67, Val Loss: 79.74615
Epoch 68, Val Loss: 85.34777
Epoch 69, Val Loss: 80.59734
Epoch 70, Val Loss: 79.18721
Epoch 71, Val Loss: 84.59937
Epoch 72, Val Loss: 86.49455
Epoch 73, Val Loss: 77.04105
Epoch 74, Val Loss: 82.60371
Epoch 75, Val Loss: 87.62091
Epoch 76, Val Loss: 87.61868
Epoch 77, Val Loss: 91.79416
Epoch 78, Val Loss: 76.69425
Epoch 79, Val Loss: 80.04596
Epoch 80, Val Loss: 82.90047
Epoch 81, Val Loss: 83.28027
Epoch 82, Val Loss: 80.05325
Epoch 83, Val Loss: 79.28053
Epoch 84, Val Loss: 76.99852
Epoch 85, Val Loss: 82.82859
Epoch 86, Val Loss: 82.35349
Epoch 87, Val Loss: 78.70193
Epoch 88, Val Loss: 84.13635
Epoch 89, Val Loss: 79.58636
Epoch 90, Val Loss: 80.43201
Epoch 91, Val Loss: 77.29297
Epoch 92, Val Loss: 90.60269
Epoch 93, Val Loss: 77.41808
Epoch 94, Val Loss: 77.54471
Epoch 95, Val Loss: 76.75883
Epoch 96, Val Loss: 77.70496
Epoch 97, Val Loss: 76.83430
Epoch 98, Val Loss: 86.37320
Epoch 99, Val Loss: 75.76021
DID NOT SAVE RESULTS
{'MSE - mean': 78.90818812468414, 'MSE - std': 6.96999692246695, 'R2 - mean': 0.5106663201895593, 'R2 - std': 0.021485823440515424} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 880.14954
Epoch 1, Val Loss: 424.98517
Epoch 2, Val Loss: 192.19734
Epoch 3, Val Loss: 154.92499
Epoch 4, Val Loss: 139.05038
Epoch 5, Val Loss: 137.77823
Epoch 6, Val Loss: 168.96436
Epoch 7, Val Loss: 118.24467
Epoch 8, Val Loss: 111.29551
Epoch 9, Val Loss: 135.11113
Epoch 10, Val Loss: 117.84986
Epoch 11, Val Loss: 116.73425
Epoch 12, Val Loss: 110.97404
Epoch 13, Val Loss: 101.96482
Epoch 14, Val Loss: 112.45848
Epoch 15, Val Loss: 117.79179
Epoch 16, Val Loss: 119.53171
Epoch 17, Val Loss: 106.75761
Epoch 18, Val Loss: 114.63833
Epoch 19, Val Loss: 97.19473
Epoch 20, Val Loss: 95.26731
Epoch 21, Val Loss: 99.75735
Epoch 22, Val Loss: 88.60974
Epoch 23, Val Loss: 96.51377
Epoch 24, Val Loss: 108.21933
Epoch 25, Val Loss: 129.04073
Epoch 26, Val Loss: 109.04779
Epoch 27, Val Loss: 86.41884
Epoch 28, Val Loss: 111.51437
Epoch 29, Val Loss: 91.93784
Epoch 30, Val Loss: 85.36589
Epoch 31, Val Loss: 87.98382
Epoch 32, Val Loss: 84.28780
Epoch 33, Val Loss: 86.91588
Epoch 34, Val Loss: 84.08784
Epoch 35, Val Loss: 90.33197
Epoch 36, Val Loss: 89.86908
Epoch 37, Val Loss: 80.44212
Epoch 38, Val Loss: 95.43493
Epoch 39, Val Loss: 100.90679
Epoch 40, Val Loss: 94.10023
Epoch 41, Val Loss: 77.35430
Epoch 42, Val Loss: 87.17212
Epoch 43, Val Loss: 80.81516
Epoch 44, Val Loss: 83.14915
Epoch 45, Val Loss: 75.07203
Epoch 46, Val Loss: 78.70007
Epoch 47, Val Loss: 84.45252
Epoch 48, Val Loss: 80.26651
Epoch 49, Val Loss: 81.76857
Epoch 50, Val Loss: 88.06311
Epoch 51, Val Loss: 80.34576
Epoch 52, Val Loss: 79.78545
Epoch 53, Val Loss: 91.06838
Epoch 54, Val Loss: 77.84405
Epoch 55, Val Loss: 85.46065
Epoch 56, Val Loss: 85.54712
Epoch 57, Val Loss: 76.87531
Epoch 58, Val Loss: 79.86255
Epoch 59, Val Loss: 83.07916
Epoch 60, Val Loss: 79.59915
Epoch 61, Val Loss: 78.14866
Epoch 62, Val Loss: 90.13257
Epoch 63, Val Loss: 81.44476
Epoch 64, Val Loss: 75.76373
Epoch 65, Val Loss: 76.13850
Epoch 66, Val Loss: 75.25108
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.37834487064701, 'MSE - std': 6.323576612547176, 'R2 - mean': 0.5128811188971287, 'R2 - std': 0.019721405132337985} 
 

Results After CV: {'MSE - mean': 78.37834487064701, 'MSE - std': 6.323576612547176, 'R2 - mean': 0.5128811188971287, 'R2 - std': 0.019721405132337985}
Train time: 411.9257285093947
Inference time: 0.2098975703935139
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 71 finished with value: 78.37834487064701 and parameters: {'p_m': 0.20090391418932219, 'alpha': 7.261933219107953, 'K': 2, 'beta': 8.191688614951136}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 874.78870
Epoch 1, Val Loss: 524.15698
Epoch 2, Val Loss: 179.92979
Epoch 3, Val Loss: 162.41385
Epoch 4, Val Loss: 159.40327
Epoch 5, Val Loss: 146.99132
Epoch 6, Val Loss: 139.28104
Epoch 7, Val Loss: 136.11880
Epoch 8, Val Loss: 120.83138
Epoch 9, Val Loss: 113.47268
Epoch 10, Val Loss: 113.49395
Epoch 11, Val Loss: 115.52470
Epoch 12, Val Loss: 121.79674
Epoch 13, Val Loss: 122.01665
Epoch 14, Val Loss: 133.41661
Epoch 15, Val Loss: 117.36366
Epoch 16, Val Loss: 111.88938
Epoch 17, Val Loss: 108.63274
Epoch 18, Val Loss: 113.70037
Epoch 19, Val Loss: 111.34928
Epoch 20, Val Loss: 111.95708
Epoch 21, Val Loss: 109.23319
Epoch 22, Val Loss: 116.76971
Epoch 23, Val Loss: 116.79304
Epoch 24, Val Loss: 103.34547
Epoch 25, Val Loss: 106.34606
Epoch 26, Val Loss: 102.55337
Epoch 27, Val Loss: 126.74565
Epoch 28, Val Loss: 99.36375
Epoch 29, Val Loss: 102.67484
Epoch 30, Val Loss: 94.71220
Epoch 31, Val Loss: 98.37939
Epoch 32, Val Loss: 105.66164
Epoch 33, Val Loss: 96.27387
Epoch 34, Val Loss: 101.47495
Epoch 35, Val Loss: 92.13278
Epoch 36, Val Loss: 95.52686
Epoch 37, Val Loss: 95.10130
Epoch 38, Val Loss: 92.27998
Epoch 39, Val Loss: 92.99848
Epoch 40, Val Loss: 97.92827
Epoch 41, Val Loss: 94.66872
Epoch 42, Val Loss: 92.55402
Epoch 43, Val Loss: 88.81362
Epoch 44, Val Loss: 89.32450
Epoch 45, Val Loss: 101.55473
Epoch 46, Val Loss: 92.28571
Epoch 47, Val Loss: 98.14551
Epoch 48, Val Loss: 94.68980
Epoch 49, Val Loss: 102.86639
Epoch 50, Val Loss: 87.06163
Epoch 51, Val Loss: 96.35735
Epoch 52, Val Loss: 95.40337
Epoch 53, Val Loss: 89.80319
Epoch 54, Val Loss: 90.35466
Epoch 55, Val Loss: 87.60799
Epoch 56, Val Loss: 93.78041
Epoch 57, Val Loss: 89.98906
Epoch 58, Val Loss: 86.57628
Epoch 59, Val Loss: 85.34063
Epoch 60, Val Loss: 92.58578
Epoch 61, Val Loss: 85.63460
Epoch 62, Val Loss: 92.29559
Epoch 63, Val Loss: 89.80141
Epoch 64, Val Loss: 108.31348
Epoch 65, Val Loss: 86.75787
Epoch 66, Val Loss: 93.30913
Epoch 67, Val Loss: 86.13664
Epoch 68, Val Loss: 89.28627
Epoch 69, Val Loss: 89.04370
Epoch 70, Val Loss: 87.87238
Epoch 71, Val Loss: 89.01434
Epoch 72, Val Loss: 93.81835
Epoch 73, Val Loss: 85.95962
Epoch 74, Val Loss: 83.87769
Epoch 75, Val Loss: 88.17274
Epoch 76, Val Loss: 90.60965
Epoch 77, Val Loss: 90.53185
Epoch 78, Val Loss: 89.16285
Epoch 79, Val Loss: 88.55379
Epoch 80, Val Loss: 88.59161
Epoch 81, Val Loss: 85.86944
Epoch 82, Val Loss: 87.89969
Epoch 83, Val Loss: 84.46919
Epoch 84, Val Loss: 86.77090
Epoch 85, Val Loss: 85.03297
Epoch 86, Val Loss: 83.79099
Epoch 87, Val Loss: 90.10983
Epoch 88, Val Loss: 85.97130
Epoch 89, Val Loss: 85.90488
Epoch 90, Val Loss: 88.83836
Epoch 91, Val Loss: 85.30426
Epoch 92, Val Loss: 85.06167
Epoch 93, Val Loss: 90.09369
Epoch 94, Val Loss: 89.68880
Epoch 95, Val Loss: 85.61927
Epoch 96, Val Loss: 89.54449
Epoch 97, Val Loss: 83.27986
Epoch 98, Val Loss: 83.49855
Epoch 99, Val Loss: 84.34057
DID NOT SAVE RESULTS
{'MSE - mean': 86.0132191464122, 'MSE - std': 0.0, 'R2 - mean': 0.4987723583470174, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 824.45850
Epoch 1, Val Loss: 413.59137
Epoch 2, Val Loss: 164.30829
Epoch 3, Val Loss: 167.17982
Epoch 4, Val Loss: 149.36896
Epoch 5, Val Loss: 156.98323
Epoch 6, Val Loss: 127.98618
Epoch 7, Val Loss: 151.70145
Epoch 8, Val Loss: 108.98312
Epoch 9, Val Loss: 119.43419
Epoch 10, Val Loss: 118.52904
Epoch 11, Val Loss: 101.69048
Epoch 12, Val Loss: 109.54343
Epoch 13, Val Loss: 119.55794
Epoch 14, Val Loss: 97.15237
Epoch 15, Val Loss: 94.80376
Epoch 16, Val Loss: 101.84090
Epoch 17, Val Loss: 105.62809
Epoch 18, Val Loss: 95.49196
Epoch 19, Val Loss: 101.86040
Epoch 20, Val Loss: 90.19776
Epoch 21, Val Loss: 112.01742
Epoch 22, Val Loss: 89.55466
Epoch 23, Val Loss: 79.83094
Epoch 24, Val Loss: 94.50771
Epoch 25, Val Loss: 85.49171
Epoch 26, Val Loss: 87.40841
Epoch 27, Val Loss: 97.55473
Epoch 28, Val Loss: 92.58530
Epoch 29, Val Loss: 91.70003
Epoch 30, Val Loss: 96.32748
Epoch 31, Val Loss: 89.02204
Epoch 32, Val Loss: 84.48904
Epoch 33, Val Loss: 97.46466
Epoch 34, Val Loss: 97.77464
Epoch 35, Val Loss: 90.86822
Epoch 36, Val Loss: 107.81760
Epoch 37, Val Loss: 87.71210
Epoch 38, Val Loss: 81.85616
Epoch 39, Val Loss: 83.92018
Epoch 40, Val Loss: 76.46974
Epoch 41, Val Loss: 94.12069
Epoch 42, Val Loss: 78.86179
Epoch 43, Val Loss: 79.47935
Epoch 44, Val Loss: 91.08463
Epoch 45, Val Loss: 78.46290
Epoch 46, Val Loss: 81.37695
Epoch 47, Val Loss: 84.80621
Epoch 48, Val Loss: 81.31024
Epoch 49, Val Loss: 85.67191
Epoch 50, Val Loss: 81.38753
Epoch 51, Val Loss: 71.75868
Epoch 52, Val Loss: 73.02584
Epoch 53, Val Loss: 74.04025
Epoch 54, Val Loss: 84.43584
Epoch 55, Val Loss: 75.13905
Epoch 56, Val Loss: 74.76978
Epoch 57, Val Loss: 74.22993
Epoch 58, Val Loss: 75.07965
Epoch 59, Val Loss: 71.37701
Epoch 60, Val Loss: 70.48609
Epoch 61, Val Loss: 72.71198
Epoch 62, Val Loss: 76.13625
Epoch 63, Val Loss: 74.52784
Epoch 64, Val Loss: 70.74494
Epoch 65, Val Loss: 81.05082
Epoch 66, Val Loss: 76.11022
Epoch 67, Val Loss: 71.26628
Epoch 68, Val Loss: 67.16824
Epoch 69, Val Loss: 68.55041
Epoch 70, Val Loss: 72.02084
Epoch 71, Val Loss: 68.72124
Epoch 72, Val Loss: 80.47791
Epoch 73, Val Loss: 81.48109
Epoch 74, Val Loss: 74.99931
Epoch 75, Val Loss: 73.09795
Epoch 76, Val Loss: 79.11378
Epoch 77, Val Loss: 69.78468
Epoch 78, Val Loss: 71.75126
Epoch 79, Val Loss: 89.05877
Epoch 80, Val Loss: 69.29468
Epoch 81, Val Loss: 82.61906
Epoch 82, Val Loss: 68.38844
Epoch 83, Val Loss: 75.45009
Epoch 84, Val Loss: 69.68887
Epoch 85, Val Loss: 69.05737
Epoch 86, Val Loss: 81.99745
Epoch 87, Val Loss: 79.95105
Epoch 88, Val Loss: 73.41273
Epoch 89, Val Loss: 66.73674
Epoch 90, Val Loss: 75.31946
Epoch 91, Val Loss: 71.05130
Epoch 92, Val Loss: 67.23274
Epoch 93, Val Loss: 67.54586
Epoch 94, Val Loss: 71.69556
Epoch 95, Val Loss: 74.04700
Epoch 96, Val Loss: 79.44656
Epoch 97, Val Loss: 71.43438
Epoch 98, Val Loss: 76.89784
Epoch 99, Val Loss: 67.10962
DID NOT SAVE RESULTS
{'MSE - mean': 80.61907115979443, 'MSE - std': 5.39414798661776, 'R2 - mean': 0.5094194047010868, 'R2 - std': 0.010647046354069434} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 865.33875
Epoch 1, Val Loss: 450.97574
Epoch 2, Val Loss: 167.85741
Epoch 3, Val Loss: 164.32024
Epoch 4, Val Loss: 130.21858
Epoch 5, Val Loss: 128.73436
Epoch 6, Val Loss: 101.22600
Epoch 7, Val Loss: 119.69208
Epoch 8, Val Loss: 97.61509
Epoch 9, Val Loss: 99.86583
Epoch 10, Val Loss: 121.44757
Epoch 11, Val Loss: 95.80273
Epoch 12, Val Loss: 103.86288
Epoch 13, Val Loss: 95.23466
Epoch 14, Val Loss: 88.25494
Epoch 15, Val Loss: 101.48884
Epoch 16, Val Loss: 91.18556
Epoch 17, Val Loss: 88.97256
Epoch 18, Val Loss: 82.83362
Epoch 19, Val Loss: 88.03250
Epoch 20, Val Loss: 82.78716
Epoch 21, Val Loss: 96.30241
Epoch 22, Val Loss: 99.71783
Epoch 23, Val Loss: 76.22333
Epoch 24, Val Loss: 79.46419
Epoch 25, Val Loss: 86.87679
Epoch 26, Val Loss: 86.48154
Epoch 27, Val Loss: 82.20345
Epoch 28, Val Loss: 81.32363
Epoch 29, Val Loss: 79.20535
Epoch 30, Val Loss: 78.25041
Epoch 31, Val Loss: 93.41351
Epoch 32, Val Loss: 84.83645
Epoch 33, Val Loss: 86.65322
Epoch 34, Val Loss: 82.12375
Epoch 35, Val Loss: 77.91409
Epoch 36, Val Loss: 82.19315
Epoch 37, Val Loss: 84.39060
Epoch 38, Val Loss: 76.05983
Epoch 39, Val Loss: 78.31371
Epoch 40, Val Loss: 74.15960
Epoch 41, Val Loss: 90.70465
Epoch 42, Val Loss: 72.14675
Epoch 43, Val Loss: 75.61697
Epoch 44, Val Loss: 71.91277
Epoch 45, Val Loss: 71.21178
Epoch 46, Val Loss: 78.67331
Epoch 47, Val Loss: 73.80643
Epoch 48, Val Loss: 74.87090
Epoch 49, Val Loss: 83.68305
Epoch 50, Val Loss: 74.32222
Epoch 51, Val Loss: 109.46666
Epoch 52, Val Loss: 72.05199
Epoch 53, Val Loss: 80.03462
Epoch 54, Val Loss: 81.73416
Epoch 55, Val Loss: 70.05260
Epoch 56, Val Loss: 70.98708
Epoch 57, Val Loss: 75.18521
Epoch 58, Val Loss: 78.17523
Epoch 59, Val Loss: 79.34470
Epoch 60, Val Loss: 68.63751
Epoch 61, Val Loss: 74.58215
Epoch 62, Val Loss: 83.58952
Epoch 63, Val Loss: 72.32060
Epoch 64, Val Loss: 70.95130
Epoch 65, Val Loss: 72.35936
Epoch 66, Val Loss: 74.06489
Epoch 67, Val Loss: 89.58986
Epoch 68, Val Loss: 69.95922
Epoch 69, Val Loss: 69.62188
Epoch 70, Val Loss: 70.49560
Epoch 71, Val Loss: 72.09643
Epoch 72, Val Loss: 73.08089
Epoch 73, Val Loss: 68.93349
Epoch 74, Val Loss: 74.13564
Epoch 75, Val Loss: 69.73823
Epoch 76, Val Loss: 74.07835
Epoch 77, Val Loss: 75.77837
Epoch 78, Val Loss: 72.09192
Epoch 79, Val Loss: 65.31237
Epoch 80, Val Loss: 68.41896
Epoch 81, Val Loss: 76.47234
Epoch 82, Val Loss: 84.28806
Epoch 83, Val Loss: 70.87691
Epoch 84, Val Loss: 69.79659
Epoch 85, Val Loss: 67.66863
Epoch 86, Val Loss: 65.82077
Epoch 87, Val Loss: 67.14665
Epoch 88, Val Loss: 69.52652
Epoch 89, Val Loss: 71.00739
Epoch 90, Val Loss: 68.61044
Epoch 91, Val Loss: 81.60947
Epoch 92, Val Loss: 66.31288
Epoch 93, Val Loss: 78.04264
Epoch 94, Val Loss: 65.69734
Epoch 95, Val Loss: 66.86568
Epoch 96, Val Loss: 66.09776
Epoch 97, Val Loss: 72.27078
Epoch 98, Val Loss: 68.97498
Epoch 99, Val Loss: 69.59023
DID NOT SAVE RESULTS
{'MSE - mean': 75.70017254103719, 'MSE - std': 8.233408503018588, 'R2 - mean': 0.5253900024150718, 'R2 - std': 0.024201095981952737} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 418.26617
Epoch 1, Val Loss: 327.60867
Epoch 2, Val Loss: 199.40067
Epoch 3, Val Loss: 184.14523
Epoch 4, Val Loss: 198.96233
Epoch 5, Val Loss: 154.20970
Epoch 6, Val Loss: 135.54944
Epoch 7, Val Loss: 135.08859
Epoch 8, Val Loss: 134.99416
Epoch 9, Val Loss: 135.85233
Epoch 10, Val Loss: 105.58858
Epoch 11, Val Loss: 109.05064
Epoch 12, Val Loss: 113.04040
Epoch 13, Val Loss: 106.97900
Epoch 14, Val Loss: 108.73450
Epoch 15, Val Loss: 119.05669
Epoch 16, Val Loss: 113.23068
Epoch 17, Val Loss: 99.55487
Epoch 18, Val Loss: 119.09714
Epoch 19, Val Loss: 103.42696
Epoch 20, Val Loss: 96.28754
Epoch 21, Val Loss: 91.47021
Epoch 22, Val Loss: 103.16108
Epoch 23, Val Loss: 102.34707
Epoch 24, Val Loss: 87.42519
Epoch 25, Val Loss: 87.29614
Epoch 26, Val Loss: 94.54259
Epoch 27, Val Loss: 89.26289
Epoch 28, Val Loss: 95.69964
Epoch 29, Val Loss: 91.87549
Epoch 30, Val Loss: 91.75013
Epoch 31, Val Loss: 87.53643
Epoch 32, Val Loss: 109.54584
Epoch 33, Val Loss: 85.29867
Epoch 34, Val Loss: 92.69768
Epoch 35, Val Loss: 82.48128
Epoch 36, Val Loss: 84.15370
Epoch 37, Val Loss: 82.18190
Epoch 38, Val Loss: 82.80998
Epoch 39, Val Loss: 85.08891
Epoch 40, Val Loss: 105.21147
Epoch 41, Val Loss: 81.67971
Epoch 42, Val Loss: 85.05118
Epoch 43, Val Loss: 82.70518
Epoch 44, Val Loss: 82.90931
Epoch 45, Val Loss: 84.74459
Epoch 46, Val Loss: 82.24551
Epoch 47, Val Loss: 90.49849
Epoch 48, Val Loss: 105.97864
Epoch 49, Val Loss: 82.63300
Epoch 50, Val Loss: 85.31226
Epoch 51, Val Loss: 86.69852
Epoch 52, Val Loss: 80.40606
Epoch 53, Val Loss: 91.37833
Epoch 54, Val Loss: 81.42419
Epoch 55, Val Loss: 79.66252
Epoch 56, Val Loss: 84.38813
Epoch 57, Val Loss: 86.90797
Epoch 58, Val Loss: 83.71911
Epoch 59, Val Loss: 80.49292
Epoch 60, Val Loss: 85.14066
Epoch 61, Val Loss: 80.44386
Epoch 62, Val Loss: 82.33633
Epoch 63, Val Loss: 78.46115
Epoch 64, Val Loss: 80.00941
Epoch 65, Val Loss: 82.79401
Epoch 66, Val Loss: 76.94696
Epoch 67, Val Loss: 82.10545
Epoch 68, Val Loss: 78.04459
Epoch 69, Val Loss: 77.90194
Epoch 70, Val Loss: 83.84159
Epoch 71, Val Loss: 78.12177
Epoch 72, Val Loss: 77.91196
Epoch 73, Val Loss: 76.03059
Epoch 74, Val Loss: 90.87233
Epoch 75, Val Loss: 76.70982
Epoch 76, Val Loss: 80.16915
Epoch 77, Val Loss: 81.48821
Epoch 78, Val Loss: 80.77885
Epoch 79, Val Loss: 77.98386
Epoch 80, Val Loss: 89.03831
Epoch 81, Val Loss: 87.82040
Epoch 82, Val Loss: 80.45039
Epoch 83, Val Loss: 81.54831
Epoch 84, Val Loss: 76.24445
Epoch 85, Val Loss: 82.52309
Epoch 86, Val Loss: 77.29258
Epoch 87, Val Loss: 79.85975
Epoch 88, Val Loss: 81.75442
Epoch 89, Val Loss: 80.19899
Epoch 90, Val Loss: 79.24557
Epoch 91, Val Loss: 76.58485
Epoch 92, Val Loss: 78.34404
Epoch 93, Val Loss: 83.32600
Epoch 94, Val Loss: 77.24108
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.37191213856593, 'MSE - std': 8.500372880891357, 'R2 - mean': 0.5146197355547052, 'R2 - std': 0.028058256000263133} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 521.66089
Epoch 1, Val Loss: 317.66757
Epoch 2, Val Loss: 186.86673
Epoch 3, Val Loss: 159.73312
Epoch 4, Val Loss: 149.61180
Epoch 5, Val Loss: 145.39406
Epoch 6, Val Loss: 148.13504
Epoch 7, Val Loss: 117.52902
Epoch 8, Val Loss: 125.13335
Epoch 9, Val Loss: 124.83562
Epoch 10, Val Loss: 120.90160
Epoch 11, Val Loss: 131.82861
Epoch 12, Val Loss: 111.61898
Epoch 13, Val Loss: 111.96982
Epoch 14, Val Loss: 98.47789
Epoch 15, Val Loss: 98.13575
Epoch 16, Val Loss: 100.81025
Epoch 17, Val Loss: 104.10076
Epoch 18, Val Loss: 99.93280
Epoch 19, Val Loss: 99.97871
Epoch 20, Val Loss: 87.30764
Epoch 21, Val Loss: 89.89749
Epoch 22, Val Loss: 100.65414
Epoch 23, Val Loss: 109.21289
Epoch 24, Val Loss: 93.61735
Epoch 25, Val Loss: 99.86491
Epoch 26, Val Loss: 98.42373
Epoch 27, Val Loss: 115.26386
Epoch 28, Val Loss: 125.01326
Epoch 29, Val Loss: 99.85648
Epoch 30, Val Loss: 87.32632
Epoch 31, Val Loss: 94.54585
Epoch 32, Val Loss: 90.57666
Epoch 33, Val Loss: 86.73611
Epoch 34, Val Loss: 110.25150
Epoch 35, Val Loss: 80.88081
Epoch 36, Val Loss: 82.69279
Epoch 37, Val Loss: 87.94914
Epoch 38, Val Loss: 90.82364
Epoch 39, Val Loss: 79.91940
Epoch 40, Val Loss: 85.97675
Epoch 41, Val Loss: 79.83663
Epoch 42, Val Loss: 109.25850
Epoch 43, Val Loss: 84.91925
Epoch 44, Val Loss: 81.77200
Epoch 45, Val Loss: 87.82630
Epoch 46, Val Loss: 84.28345
Epoch 47, Val Loss: 83.37242
Epoch 48, Val Loss: 82.71701
Epoch 49, Val Loss: 81.43326
Epoch 50, Val Loss: 84.28477
Epoch 51, Val Loss: 77.39533
Epoch 52, Val Loss: 77.67546
Epoch 53, Val Loss: 88.12929
Epoch 54, Val Loss: 93.86088
Epoch 55, Val Loss: 82.10318
Epoch 56, Val Loss: 76.43894
Epoch 57, Val Loss: 76.97844
Epoch 58, Val Loss: 82.45195
Epoch 59, Val Loss: 80.38773
Epoch 60, Val Loss: 81.69657
Epoch 61, Val Loss: 80.30210
Epoch 62, Val Loss: 80.41973
Epoch 63, Val Loss: 76.17328
Epoch 64, Val Loss: 86.92500
Epoch 65, Val Loss: 84.39072
Epoch 66, Val Loss: 78.30868
Epoch 67, Val Loss: 79.50361
Epoch 68, Val Loss: 81.72437
Epoch 69, Val Loss: 100.23415
Epoch 70, Val Loss: 73.73986
Epoch 71, Val Loss: 75.41879
Epoch 72, Val Loss: 73.38748
Epoch 73, Val Loss: 77.64583
Epoch 74, Val Loss: 79.58817
Epoch 75, Val Loss: 82.90906
Epoch 76, Val Loss: 83.71284
Epoch 77, Val Loss: 77.21262
Epoch 78, Val Loss: 72.90181
Epoch 79, Val Loss: 80.36429
Epoch 80, Val Loss: 72.22239
Epoch 81, Val Loss: 78.55642
Epoch 82, Val Loss: 77.68466
Epoch 83, Val Loss: 78.11504
Epoch 84, Val Loss: 79.80321
Epoch 85, Val Loss: 82.74615
Epoch 86, Val Loss: 75.63460
Epoch 87, Val Loss: 73.59921
Epoch 88, Val Loss: 77.29952
Epoch 89, Val Loss: 72.80835
Epoch 90, Val Loss: 76.30930
Epoch 91, Val Loss: 81.49292
Epoch 92, Val Loss: 95.58028
Epoch 93, Val Loss: 77.53169
Epoch 94, Val Loss: 89.80960
Epoch 95, Val Loss: 77.67384
Epoch 96, Val Loss: 74.36604
Epoch 97, Val Loss: 80.82738
Epoch 98, Val Loss: 75.95615
Epoch 99, Val Loss: 72.07326
DID NOT SAVE RESULTS
{'MSE - mean': 77.16532593149007, 'MSE - std': 7.9767457269100275, 'R2 - mean': 0.5209607114650197, 'R2 - std': 0.028118401195690333} 
 

Results After CV: {'MSE - mean': 77.16532593149007, 'MSE - std': 7.9767457269100275, 'R2 - mean': 0.5209607114650197, 'R2 - std': 0.028118401195690333}
Train time: 465.51205176220975
Inference time: 0.19380311480490492
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 72 finished with value: 77.16532593149007 and parameters: {'p_m': 0.19306107676728185, 'alpha': 8.205984988610417, 'K': 2, 'beta': 8.837306557985862}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 560.23114
Epoch 1, Val Loss: 442.57922
Epoch 2, Val Loss: 185.51538
Epoch 3, Val Loss: 152.79369
Epoch 4, Val Loss: 138.09064
Epoch 5, Val Loss: 129.07756
Epoch 6, Val Loss: 125.86412
Epoch 7, Val Loss: 124.67465
Epoch 8, Val Loss: 109.31380
Epoch 9, Val Loss: 110.62637
Epoch 10, Val Loss: 113.32333
Epoch 11, Val Loss: 118.68050
Epoch 12, Val Loss: 105.41551
Epoch 13, Val Loss: 100.88998
Epoch 14, Val Loss: 107.34435
Epoch 15, Val Loss: 114.65370
Epoch 16, Val Loss: 98.05228
Epoch 17, Val Loss: 109.47785
Epoch 18, Val Loss: 97.51433
Epoch 19, Val Loss: 104.84842
Epoch 20, Val Loss: 103.16010
Epoch 21, Val Loss: 105.57692
Epoch 22, Val Loss: 101.15877
Epoch 23, Val Loss: 102.92136
Epoch 24, Val Loss: 114.20522
Epoch 25, Val Loss: 110.29015
Epoch 26, Val Loss: 99.29387
Epoch 27, Val Loss: 102.02402
Epoch 28, Val Loss: 102.24554
Epoch 29, Val Loss: 95.81351
Epoch 30, Val Loss: 96.31550
Epoch 31, Val Loss: 102.16110
Epoch 32, Val Loss: 96.72088
Epoch 33, Val Loss: 106.76158
Epoch 34, Val Loss: 97.62648
Epoch 35, Val Loss: 102.18759
Epoch 36, Val Loss: 97.34546
Epoch 37, Val Loss: 100.47372
Epoch 38, Val Loss: 96.10223
Epoch 39, Val Loss: 94.92101
Epoch 40, Val Loss: 104.28659
Epoch 41, Val Loss: 89.82037
Epoch 42, Val Loss: 89.55428
Epoch 43, Val Loss: 97.91342
Epoch 44, Val Loss: 94.15184
Epoch 45, Val Loss: 90.19134
Epoch 46, Val Loss: 88.51108
Epoch 47, Val Loss: 107.04222
Epoch 48, Val Loss: 91.75803
Epoch 49, Val Loss: 90.67230
Epoch 50, Val Loss: 87.72858
Epoch 51, Val Loss: 86.68056
Epoch 52, Val Loss: 92.02654
Epoch 53, Val Loss: 88.98553
Epoch 54, Val Loss: 94.48070
Epoch 55, Val Loss: 86.05955
Epoch 56, Val Loss: 89.55102
Epoch 57, Val Loss: 84.82658
Epoch 58, Val Loss: 89.19382
Epoch 59, Val Loss: 86.51881
Epoch 60, Val Loss: 90.91825
Epoch 61, Val Loss: 87.99960
Epoch 62, Val Loss: 88.09859
Epoch 63, Val Loss: 87.00096
Epoch 64, Val Loss: 83.48955
Epoch 65, Val Loss: 86.97680
Epoch 66, Val Loss: 84.81441
Epoch 67, Val Loss: 88.18227
Epoch 68, Val Loss: 103.37439
Epoch 69, Val Loss: 82.72892
Epoch 70, Val Loss: 89.38211
Epoch 71, Val Loss: 84.46358
Epoch 72, Val Loss: 85.54643
Epoch 73, Val Loss: 86.06895
Epoch 74, Val Loss: 85.81805
Epoch 75, Val Loss: 85.34756
Epoch 76, Val Loss: 96.24246
Epoch 77, Val Loss: 82.76723
Epoch 78, Val Loss: 83.45208
Epoch 79, Val Loss: 86.67793
Epoch 80, Val Loss: 91.56429
Epoch 81, Val Loss: 90.05769
Epoch 82, Val Loss: 93.00570
Epoch 83, Val Loss: 93.95193
Epoch 84, Val Loss: 84.56846
Epoch 85, Val Loss: 82.54214
Epoch 86, Val Loss: 90.77567
Epoch 87, Val Loss: 87.77072
Epoch 88, Val Loss: 84.67926
Epoch 89, Val Loss: 81.90569
Epoch 90, Val Loss: 83.68983
Epoch 91, Val Loss: 92.64294
Epoch 92, Val Loss: 82.68832
Epoch 93, Val Loss: 84.02908
Epoch 94, Val Loss: 82.67346
Epoch 95, Val Loss: 87.93961
Epoch 96, Val Loss: 87.43229
Epoch 97, Val Loss: 82.80457
Epoch 98, Val Loss: 82.26508
Epoch 99, Val Loss: 81.19321
DID NOT SAVE RESULTS
{'MSE - mean': 86.34396472568724, 'MSE - std': 0.0, 'R2 - mean': 0.4968449938287217, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 447.25250
Epoch 1, Val Loss: 284.43320
Epoch 2, Val Loss: 146.29340
Epoch 3, Val Loss: 130.74399
Epoch 4, Val Loss: 119.87051
Epoch 5, Val Loss: 135.25845
Epoch 6, Val Loss: 106.82876
Epoch 7, Val Loss: 114.17667
Epoch 8, Val Loss: 97.84902
Epoch 9, Val Loss: 118.33411
Epoch 10, Val Loss: 93.20623
Epoch 11, Val Loss: 97.77687
Epoch 12, Val Loss: 103.20540
Epoch 13, Val Loss: 101.14146
Epoch 14, Val Loss: 92.46449
Epoch 15, Val Loss: 91.98582
Epoch 16, Val Loss: 91.54117
Epoch 17, Val Loss: 91.02110
Epoch 18, Val Loss: 93.45904
Epoch 19, Val Loss: 95.04259
Epoch 20, Val Loss: 93.84820
Epoch 21, Val Loss: 93.20806
Epoch 22, Val Loss: 117.60138
Epoch 23, Val Loss: 91.72048
Epoch 24, Val Loss: 90.90625
Epoch 25, Val Loss: 84.18921
Epoch 26, Val Loss: 94.02823
Epoch 27, Val Loss: 85.94659
Epoch 28, Val Loss: 79.97266
Epoch 29, Val Loss: 98.38345
Epoch 30, Val Loss: 87.80998
Epoch 31, Val Loss: 85.54513
Epoch 32, Val Loss: 94.96789
Epoch 33, Val Loss: 90.51238
Epoch 34, Val Loss: 89.97695
Epoch 35, Val Loss: 94.93041
Epoch 36, Val Loss: 78.21591
Epoch 37, Val Loss: 88.69012
Epoch 38, Val Loss: 84.08714
Epoch 39, Val Loss: 88.08115
Epoch 40, Val Loss: 89.37594
Epoch 41, Val Loss: 82.42359
Epoch 42, Val Loss: 78.61555
Epoch 43, Val Loss: 91.02361
Epoch 44, Val Loss: 78.06693
Epoch 45, Val Loss: 75.60776
Epoch 46, Val Loss: 80.35297
Epoch 47, Val Loss: 76.47372
Epoch 48, Val Loss: 79.28470
Epoch 49, Val Loss: 83.41286
Epoch 50, Val Loss: 78.05463
Epoch 51, Val Loss: 86.68045
Epoch 52, Val Loss: 90.98309
Epoch 53, Val Loss: 73.85291
Epoch 54, Val Loss: 76.48167
Epoch 55, Val Loss: 84.37016
Epoch 56, Val Loss: 71.03192
Epoch 57, Val Loss: 76.13896
Epoch 58, Val Loss: 74.75295
Epoch 59, Val Loss: 72.65881
Epoch 60, Val Loss: 74.90770
Epoch 61, Val Loss: 76.34250
Epoch 62, Val Loss: 74.77727
Epoch 63, Val Loss: 73.96658
Epoch 64, Val Loss: 69.63406
Epoch 65, Val Loss: 86.66365
Epoch 66, Val Loss: 77.35722
Epoch 67, Val Loss: 76.24352
Epoch 68, Val Loss: 73.22923
Epoch 69, Val Loss: 76.02009
Epoch 70, Val Loss: 70.70924
Epoch 71, Val Loss: 70.66029
Epoch 72, Val Loss: 69.91621
Epoch 73, Val Loss: 69.15977
Epoch 74, Val Loss: 71.17054
Epoch 75, Val Loss: 73.82673
Epoch 76, Val Loss: 69.03471
Epoch 77, Val Loss: 75.72449
Epoch 78, Val Loss: 71.90025
Epoch 79, Val Loss: 71.28413
Epoch 80, Val Loss: 75.75076
Epoch 81, Val Loss: 76.02255
Epoch 82, Val Loss: 71.63374
Epoch 83, Val Loss: 70.76119
Epoch 84, Val Loss: 70.33460
Epoch 85, Val Loss: 67.02534
Epoch 86, Val Loss: 70.68740
Epoch 87, Val Loss: 67.75661
Epoch 88, Val Loss: 72.14017
Epoch 89, Val Loss: 72.94295
Epoch 90, Val Loss: 71.67817
Epoch 91, Val Loss: 69.40829
Epoch 92, Val Loss: 73.41645
Epoch 93, Val Loss: 70.13974
Epoch 94, Val Loss: 68.83205
Epoch 95, Val Loss: 72.11016
Epoch 96, Val Loss: 70.31606
Epoch 97, Val Loss: 76.22099
Epoch 98, Val Loss: 73.16798
Epoch 99, Val Loss: 76.32676
DID NOT SAVE RESULTS
{'MSE - mean': 80.4388281775687, 'MSE - std': 5.905136548118556, 'R2 - mean': 0.5106607443544213, 'R2 - std': 0.013815750525699555} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1216.20752
Epoch 1, Val Loss: 439.01477
Epoch 2, Val Loss: 216.04367
Epoch 3, Val Loss: 165.50221
Epoch 4, Val Loss: 127.26788
Epoch 5, Val Loss: 117.35729
Epoch 6, Val Loss: 111.25467
Epoch 7, Val Loss: 101.65521
Epoch 8, Val Loss: 99.10139
Epoch 9, Val Loss: 106.71603
Epoch 10, Val Loss: 89.56987
Epoch 11, Val Loss: 91.40923
Epoch 12, Val Loss: 98.56075
Epoch 13, Val Loss: 90.84342
Epoch 14, Val Loss: 103.36333
Epoch 15, Val Loss: 91.56728
Epoch 16, Val Loss: 84.47807
Epoch 17, Val Loss: 84.71510
Epoch 18, Val Loss: 75.65253
Epoch 19, Val Loss: 86.84532
Epoch 20, Val Loss: 76.68057
Epoch 21, Val Loss: 79.01031
Epoch 22, Val Loss: 82.49707
Epoch 23, Val Loss: 84.27371
Epoch 24, Val Loss: 78.75894
Epoch 25, Val Loss: 83.93227
Epoch 26, Val Loss: 74.57973
Epoch 27, Val Loss: 81.38979
Epoch 28, Val Loss: 94.78310
Epoch 29, Val Loss: 87.29253
Epoch 30, Val Loss: 85.34025
Epoch 31, Val Loss: 87.95892
Epoch 32, Val Loss: 74.28856
Epoch 33, Val Loss: 76.96587
Epoch 34, Val Loss: 74.67023
Epoch 35, Val Loss: 82.34453
Epoch 36, Val Loss: 85.88137
Epoch 37, Val Loss: 81.73085
Epoch 38, Val Loss: 78.82220
Epoch 39, Val Loss: 86.73580
Epoch 40, Val Loss: 78.77713
Epoch 41, Val Loss: 76.44257
Epoch 42, Val Loss: 78.57263
Epoch 43, Val Loss: 78.48802
Epoch 44, Val Loss: 72.19489
Epoch 45, Val Loss: 80.65498
Epoch 46, Val Loss: 75.38680
Epoch 47, Val Loss: 91.54031
Epoch 48, Val Loss: 75.12463
Epoch 49, Val Loss: 74.73766
Epoch 50, Val Loss: 75.66553
Epoch 51, Val Loss: 72.45967
Epoch 52, Val Loss: 72.60383
Epoch 53, Val Loss: 70.47417
Epoch 54, Val Loss: 77.82420
Epoch 55, Val Loss: 74.14983
Epoch 56, Val Loss: 78.42705
Epoch 57, Val Loss: 70.34290
Epoch 58, Val Loss: 73.34511
Epoch 59, Val Loss: 75.60031
Epoch 60, Val Loss: 75.55882
Epoch 61, Val Loss: 72.94303
Epoch 62, Val Loss: 73.34422
Epoch 63, Val Loss: 81.24734
Epoch 64, Val Loss: 81.91589
Epoch 65, Val Loss: 75.29410
Epoch 66, Val Loss: 75.12816
Epoch 67, Val Loss: 81.83958
Epoch 68, Val Loss: 71.13641
Epoch 69, Val Loss: 69.19138
Epoch 70, Val Loss: 72.68875
Epoch 71, Val Loss: 77.16829
Epoch 72, Val Loss: 70.83753
Epoch 73, Val Loss: 78.39722
Epoch 74, Val Loss: 68.84626
Epoch 75, Val Loss: 73.39473
Epoch 76, Val Loss: 73.31433
Epoch 77, Val Loss: 71.89987
Epoch 78, Val Loss: 91.95142
Epoch 79, Val Loss: 70.28378
Epoch 80, Val Loss: 75.55385
Epoch 81, Val Loss: 72.04423
Epoch 82, Val Loss: 74.16345
Epoch 83, Val Loss: 71.83141
Epoch 84, Val Loss: 70.35565
Epoch 85, Val Loss: 69.38831
Epoch 86, Val Loss: 71.39054
Epoch 87, Val Loss: 70.17896
Epoch 88, Val Loss: 70.51162
Epoch 89, Val Loss: 71.49298
Epoch 90, Val Loss: 71.68259
Epoch 91, Val Loss: 70.58315
Epoch 92, Val Loss: 73.41437
Epoch 93, Val Loss: 67.47047
Epoch 94, Val Loss: 71.34268
Epoch 95, Val Loss: 72.72945
Epoch 96, Val Loss: 74.29473
Epoch 97, Val Loss: 68.91572
Epoch 98, Val Loss: 88.88667
Epoch 99, Val Loss: 70.56113
DID NOT SAVE RESULTS
{'MSE - mean': 76.1209355437731, 'MSE - std': 7.7804553441249755, 'R2 - mean': 0.5225819414419376, 'R2 - std': 0.02028496623260016} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1132.43958
Epoch 1, Val Loss: 370.51498
Epoch 2, Val Loss: 163.74530
Epoch 3, Val Loss: 146.71512
Epoch 4, Val Loss: 147.89915
Epoch 5, Val Loss: 127.52335
Epoch 6, Val Loss: 118.72538
Epoch 7, Val Loss: 140.72813
Epoch 8, Val Loss: 112.66225
Epoch 9, Val Loss: 110.92413
Epoch 10, Val Loss: 107.17510
Epoch 11, Val Loss: 110.61172
Epoch 12, Val Loss: 111.03375
Epoch 13, Val Loss: 105.71244
Epoch 14, Val Loss: 98.66499
Epoch 15, Val Loss: 109.80205
Epoch 16, Val Loss: 104.69712
Epoch 17, Val Loss: 100.80462
Epoch 18, Val Loss: 99.81448
Epoch 19, Val Loss: 94.84043
Epoch 20, Val Loss: 92.41933
Epoch 21, Val Loss: 91.81873
Epoch 22, Val Loss: 103.74699
Epoch 23, Val Loss: 106.68063
Epoch 24, Val Loss: 93.93114
Epoch 25, Val Loss: 90.00665
Epoch 26, Val Loss: 96.26659
Epoch 27, Val Loss: 92.73069
Epoch 28, Val Loss: 92.09212
Epoch 29, Val Loss: 94.65804
Epoch 30, Val Loss: 91.11743
Epoch 31, Val Loss: 97.05247
Epoch 32, Val Loss: 96.71998
Epoch 33, Val Loss: 99.57698
Epoch 34, Val Loss: 94.97293
Epoch 35, Val Loss: 89.48946
Epoch 36, Val Loss: 86.92990
Epoch 37, Val Loss: 92.38154
Epoch 38, Val Loss: 90.99887
Epoch 39, Val Loss: 98.97328
Epoch 40, Val Loss: 92.15797
Epoch 41, Val Loss: 90.55409
Epoch 42, Val Loss: 91.52224
Epoch 43, Val Loss: 99.59508
Epoch 44, Val Loss: 93.83444
Epoch 45, Val Loss: 90.29725
Epoch 46, Val Loss: 111.80882
Epoch 47, Val Loss: 83.99018
Epoch 48, Val Loss: 119.28477
Epoch 49, Val Loss: 84.56600
Epoch 50, Val Loss: 83.34390
Epoch 51, Val Loss: 82.52410
Epoch 52, Val Loss: 108.94080
Epoch 53, Val Loss: 83.73898
Epoch 54, Val Loss: 80.14706
Epoch 55, Val Loss: 90.79755
Epoch 56, Val Loss: 90.95495
Epoch 57, Val Loss: 83.89189
Epoch 58, Val Loss: 86.05296
Epoch 59, Val Loss: 82.77219
Epoch 60, Val Loss: 89.16875
Epoch 61, Val Loss: 77.78415
Epoch 62, Val Loss: 89.07069
Epoch 63, Val Loss: 79.88210
Epoch 64, Val Loss: 80.86812
Epoch 65, Val Loss: 88.74828
Epoch 66, Val Loss: 87.96653
Epoch 67, Val Loss: 82.97420
Epoch 68, Val Loss: 75.60568
Epoch 69, Val Loss: 84.16861
Epoch 70, Val Loss: 85.60176
Epoch 71, Val Loss: 83.05675
Epoch 72, Val Loss: 84.48419
Epoch 73, Val Loss: 82.18905
Epoch 74, Val Loss: 77.95893
Epoch 75, Val Loss: 79.53773
Epoch 76, Val Loss: 79.06506
Epoch 77, Val Loss: 79.37160
Epoch 78, Val Loss: 83.01659
Epoch 79, Val Loss: 81.84691
Epoch 80, Val Loss: 79.88197
Epoch 81, Val Loss: 88.25963
Epoch 82, Val Loss: 82.04740
Epoch 83, Val Loss: 80.65535
Epoch 84, Val Loss: 83.43002
Epoch 85, Val Loss: 80.53714
Epoch 86, Val Loss: 80.76464
Epoch 87, Val Loss: 79.20188
Epoch 88, Val Loss: 79.26559
Epoch 89, Val Loss: 79.62759
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.84178750512118, 'MSE - std': 8.222573818954567, 'R2 - mean': 0.5115889995055549, 'R2 - std': 0.02590645109897034} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 582.71442
Epoch 1, Val Loss: 306.10657
Epoch 2, Val Loss: 212.66283
Epoch 3, Val Loss: 119.92375
Epoch 4, Val Loss: 121.79807
Epoch 5, Val Loss: 136.18146
Epoch 6, Val Loss: 125.75879
Epoch 7, Val Loss: 113.46411
Epoch 8, Val Loss: 103.84917
Epoch 9, Val Loss: 95.32951
Epoch 10, Val Loss: 116.49507
Epoch 11, Val Loss: 110.82228
Epoch 12, Val Loss: 116.54741
Epoch 13, Val Loss: 100.71461
Epoch 14, Val Loss: 93.98432
Epoch 15, Val Loss: 90.94046
Epoch 16, Val Loss: 98.51485
Epoch 17, Val Loss: 98.18690
Epoch 18, Val Loss: 109.46971
Epoch 19, Val Loss: 95.70293
Epoch 20, Val Loss: 95.88380
Epoch 21, Val Loss: 96.87835
Epoch 22, Val Loss: 97.62209
Epoch 23, Val Loss: 89.90294
Epoch 24, Val Loss: 90.57970
Epoch 25, Val Loss: 95.20013
Epoch 26, Val Loss: 99.08705
Epoch 27, Val Loss: 95.52322
Epoch 28, Val Loss: 102.40626
Epoch 29, Val Loss: 96.06606
Epoch 30, Val Loss: 97.95830
Epoch 31, Val Loss: 89.86272
Epoch 32, Val Loss: 90.08849
Epoch 33, Val Loss: 93.93119
Epoch 34, Val Loss: 91.45497
Epoch 35, Val Loss: 87.45884
Epoch 36, Val Loss: 87.22247
Epoch 37, Val Loss: 84.10153
Epoch 38, Val Loss: 88.87840
Epoch 39, Val Loss: 84.26318
Epoch 40, Val Loss: 94.49973
Epoch 41, Val Loss: 81.28789
Epoch 42, Val Loss: 81.96390
Epoch 43, Val Loss: 82.86183
Epoch 44, Val Loss: 85.71016
Epoch 45, Val Loss: 89.51130
Epoch 46, Val Loss: 83.44379
Epoch 47, Val Loss: 85.85558
Epoch 48, Val Loss: 105.60110
Epoch 49, Val Loss: 81.47402
Epoch 50, Val Loss: 84.39529
Epoch 51, Val Loss: 106.65575
Epoch 52, Val Loss: 85.04174
Epoch 53, Val Loss: 90.19315
Epoch 54, Val Loss: 82.03220
Epoch 55, Val Loss: 84.49992
Epoch 56, Val Loss: 89.25278
Epoch 57, Val Loss: 81.38197
Epoch 58, Val Loss: 84.09538
Epoch 59, Val Loss: 75.66058
Epoch 60, Val Loss: 80.89718
Epoch 61, Val Loss: 79.06863
Epoch 62, Val Loss: 84.22633
Epoch 63, Val Loss: 81.31871
Epoch 64, Val Loss: 83.36611
Epoch 65, Val Loss: 79.71931
Epoch 66, Val Loss: 79.52821
Epoch 67, Val Loss: 80.84351
Epoch 68, Val Loss: 80.43220
Epoch 69, Val Loss: 79.32227
Epoch 70, Val Loss: 83.72768
Epoch 71, Val Loss: 82.04250
Epoch 72, Val Loss: 79.60061
Epoch 73, Val Loss: 80.42269
Epoch 74, Val Loss: 84.53297
Epoch 75, Val Loss: 80.06415
Epoch 76, Val Loss: 77.70412
Epoch 77, Val Loss: 82.07609
Epoch 78, Val Loss: 80.09470
Epoch 79, Val Loss: 75.37782
Epoch 80, Val Loss: 79.93358
Epoch 81, Val Loss: 79.80714
Epoch 82, Val Loss: 74.31441
Epoch 83, Val Loss: 94.05844
Epoch 84, Val Loss: 73.97430
Epoch 85, Val Loss: 78.41440
Epoch 86, Val Loss: 77.17659
Epoch 87, Val Loss: 86.98503
Epoch 88, Val Loss: 74.58617
Epoch 89, Val Loss: 76.15796
Epoch 90, Val Loss: 87.77754
Epoch 91, Val Loss: 73.84973
Epoch 92, Val Loss: 76.03366
Epoch 93, Val Loss: 85.59434
Epoch 94, Val Loss: 81.74835
Epoch 95, Val Loss: 71.70447
Epoch 96, Val Loss: 76.16582
Epoch 97, Val Loss: 79.29670
Epoch 98, Val Loss: 86.34969
Epoch 99, Val Loss: 76.48824
DID NOT SAVE RESULTS
{'MSE - mean': 77.78651007822933, 'MSE - std': 7.651340925442781, 'R2 - mean': 0.5169978199713692, 'R2 - std': 0.025572186495493882} 
 

Results After CV: {'MSE - mean': 77.78651007822933, 'MSE - std': 7.651340925442781, 'R2 - mean': 0.5169978199713692, 'R2 - std': 0.025572186495493882}
Train time: 459.4746121507953
Inference time: 0.1948222984035965
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 73 finished with value: 77.78651007822933 and parameters: {'p_m': 0.1606737400194203, 'alpha': 8.656481913714131, 'K': 2, 'beta': 6.399786649570741}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1080.77173
Epoch 1, Val Loss: 304.21198
Epoch 2, Val Loss: 170.01260
Epoch 3, Val Loss: 156.14459
Epoch 4, Val Loss: 150.66159
Epoch 5, Val Loss: 148.30891
Epoch 6, Val Loss: 118.62874
Epoch 7, Val Loss: 114.27744
Epoch 8, Val Loss: 107.63010
Epoch 9, Val Loss: 115.99645
Epoch 10, Val Loss: 109.88447
Epoch 11, Val Loss: 102.27367
Epoch 12, Val Loss: 104.60023
Epoch 13, Val Loss: 104.92915
Epoch 14, Val Loss: 110.00867
Epoch 15, Val Loss: 102.88293
Epoch 16, Val Loss: 105.85064
Epoch 17, Val Loss: 109.54134
Epoch 18, Val Loss: 101.76285
Epoch 19, Val Loss: 112.35923
Epoch 20, Val Loss: 100.80980
Epoch 21, Val Loss: 102.61655
Epoch 22, Val Loss: 107.74245
Epoch 23, Val Loss: 104.68782
Epoch 24, Val Loss: 99.78954
Epoch 25, Val Loss: 100.40456
Epoch 26, Val Loss: 115.43999
Epoch 27, Val Loss: 104.79778
Epoch 28, Val Loss: 96.57292
Epoch 29, Val Loss: 103.51923
Epoch 30, Val Loss: 98.08808
Epoch 31, Val Loss: 108.45262
Epoch 32, Val Loss: 103.48624
Epoch 33, Val Loss: 100.33533
Epoch 34, Val Loss: 103.49007
Epoch 35, Val Loss: 97.71264
Epoch 36, Val Loss: 110.53493
Epoch 37, Val Loss: 96.11407
Epoch 38, Val Loss: 98.03006
Epoch 39, Val Loss: 89.83828
Epoch 40, Val Loss: 115.68152
Epoch 41, Val Loss: 97.12663
Epoch 42, Val Loss: 91.42841
Epoch 43, Val Loss: 107.42793
Epoch 44, Val Loss: 99.31236
Epoch 45, Val Loss: 96.83337
Epoch 46, Val Loss: 90.39380
Epoch 47, Val Loss: 93.23528
Epoch 48, Val Loss: 90.52563
Epoch 49, Val Loss: 93.43024
Epoch 50, Val Loss: 99.09452
Epoch 51, Val Loss: 101.23921
Epoch 52, Val Loss: 88.71747
Epoch 53, Val Loss: 88.56866
Epoch 54, Val Loss: 90.09063
Epoch 55, Val Loss: 85.50652
Epoch 56, Val Loss: 88.50679
Epoch 57, Val Loss: 103.32371
Epoch 58, Val Loss: 88.67950
Epoch 59, Val Loss: 92.49331
Epoch 60, Val Loss: 89.88229
Epoch 61, Val Loss: 88.88667
Epoch 62, Val Loss: 88.32150
Epoch 63, Val Loss: 88.29253
Epoch 64, Val Loss: 93.58032
Epoch 65, Val Loss: 95.15044
Epoch 66, Val Loss: 82.62141
Epoch 67, Val Loss: 84.40485
Epoch 68, Val Loss: 87.25654
Epoch 69, Val Loss: 84.00001
Epoch 70, Val Loss: 94.22970
Epoch 71, Val Loss: 111.35519
Epoch 72, Val Loss: 86.77605
Epoch 73, Val Loss: 83.81540
Epoch 74, Val Loss: 86.75350
Epoch 75, Val Loss: 84.20624
Epoch 76, Val Loss: 84.16842
Epoch 77, Val Loss: 85.13941
Epoch 78, Val Loss: 89.42812
Epoch 79, Val Loss: 91.82529
Epoch 80, Val Loss: 87.41074
Epoch 81, Val Loss: 95.86565
Epoch 82, Val Loss: 88.15315
Epoch 83, Val Loss: 86.43613
Epoch 84, Val Loss: 85.87323
Epoch 85, Val Loss: 93.48527
Epoch 86, Val Loss: 83.24408
Epoch 87, Val Loss: 85.30246
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.8160519977452, 'MSE - std': 0.0, 'R2 - mean': 0.4940939842469827, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1450.77551
Epoch 1, Val Loss: 403.24619
Epoch 2, Val Loss: 171.32976
Epoch 3, Val Loss: 151.70038
Epoch 4, Val Loss: 129.85179
Epoch 5, Val Loss: 123.64891
Epoch 6, Val Loss: 116.23576
Epoch 7, Val Loss: 125.97034
Epoch 8, Val Loss: 109.62598
Epoch 9, Val Loss: 116.08731
Epoch 10, Val Loss: 101.87659
Epoch 11, Val Loss: 112.11922
Epoch 12, Val Loss: 111.71135
Epoch 13, Val Loss: 106.76949
Epoch 14, Val Loss: 92.94704
Epoch 15, Val Loss: 91.58340
Epoch 16, Val Loss: 101.54878
Epoch 17, Val Loss: 98.73403
Epoch 18, Val Loss: 96.59545
Epoch 19, Val Loss: 91.81318
Epoch 20, Val Loss: 104.20409
Epoch 21, Val Loss: 96.81507
Epoch 22, Val Loss: 93.44596
Epoch 23, Val Loss: 93.13547
Epoch 24, Val Loss: 84.27798
Epoch 25, Val Loss: 97.49378
Epoch 26, Val Loss: 88.62101
Epoch 27, Val Loss: 87.80357
Epoch 28, Val Loss: 81.43305
Epoch 29, Val Loss: 101.81689
Epoch 30, Val Loss: 92.02673
Epoch 31, Val Loss: 98.33485
Epoch 32, Val Loss: 80.57736
Epoch 33, Val Loss: 90.14771
Epoch 34, Val Loss: 89.31236
Epoch 35, Val Loss: 91.93714
Epoch 36, Val Loss: 89.32928
Epoch 37, Val Loss: 80.14591
Epoch 38, Val Loss: 82.52618
Epoch 39, Val Loss: 80.58344
Epoch 40, Val Loss: 86.52424
Epoch 41, Val Loss: 89.19145
Epoch 42, Val Loss: 83.18850
Epoch 43, Val Loss: 85.71696
Epoch 44, Val Loss: 80.76199
Epoch 45, Val Loss: 82.79319
Epoch 46, Val Loss: 79.26737
Epoch 47, Val Loss: 80.92872
Epoch 48, Val Loss: 77.22214
Epoch 49, Val Loss: 80.69452
Epoch 50, Val Loss: 78.91548
Epoch 51, Val Loss: 81.91667
Epoch 52, Val Loss: 80.66394
Epoch 53, Val Loss: 85.84438
Epoch 54, Val Loss: 79.45677
Epoch 55, Val Loss: 83.31631
Epoch 56, Val Loss: 85.42559
Epoch 57, Val Loss: 79.25607
Epoch 58, Val Loss: 83.89290
Epoch 59, Val Loss: 93.39377
Epoch 60, Val Loss: 77.90267
Epoch 61, Val Loss: 80.86494
Epoch 62, Val Loss: 73.49596
Epoch 63, Val Loss: 77.51480
Epoch 64, Val Loss: 79.57880
Epoch 65, Val Loss: 75.41548
Epoch 66, Val Loss: 75.95647
Epoch 67, Val Loss: 82.80028
Epoch 68, Val Loss: 77.49257
Epoch 69, Val Loss: 72.23353
Epoch 70, Val Loss: 75.23393
Epoch 71, Val Loss: 77.59976
Epoch 72, Val Loss: 91.06412
Epoch 73, Val Loss: 76.52737
Epoch 74, Val Loss: 83.64373
Epoch 75, Val Loss: 69.78780
Epoch 76, Val Loss: 72.34696
Epoch 77, Val Loss: 74.54685
Epoch 78, Val Loss: 72.81294
Epoch 79, Val Loss: 74.68652
Epoch 80, Val Loss: 78.34569
Epoch 81, Val Loss: 75.92644
Epoch 82, Val Loss: 75.40396
Epoch 83, Val Loss: 73.32114
Epoch 84, Val Loss: 74.45535
Epoch 85, Val Loss: 72.11757
Epoch 86, Val Loss: 71.80246
Epoch 87, Val Loss: 71.04921
Epoch 88, Val Loss: 76.26971
Epoch 89, Val Loss: 77.84103
Epoch 90, Val Loss: 71.49792
Epoch 91, Val Loss: 73.20789
Epoch 92, Val Loss: 69.31426
Epoch 93, Val Loss: 74.58024
Epoch 94, Val Loss: 81.22145
Epoch 95, Val Loss: 77.05533
Epoch 96, Val Loss: 73.57137
Epoch 97, Val Loss: 87.34993
Epoch 98, Val Loss: 72.26569
Epoch 99, Val Loss: 76.70592
DID NOT SAVE RESULTS
{'MSE - mean': 82.23521220682709, 'MSE - std': 4.5808397909181195, 'R2 - mean': 0.49933029815722263, 'R2 - std': 0.005236313910239931} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1489.52063
Epoch 1, Val Loss: 387.17007
Epoch 2, Val Loss: 157.44228
Epoch 3, Val Loss: 136.45425
Epoch 4, Val Loss: 128.22723
Epoch 5, Val Loss: 119.27052
Epoch 6, Val Loss: 109.34644
Epoch 7, Val Loss: 94.82323
Epoch 8, Val Loss: 95.93270
Epoch 9, Val Loss: 97.34525
Epoch 10, Val Loss: 91.05162
Epoch 11, Val Loss: 94.98106
Epoch 12, Val Loss: 85.09930
Epoch 13, Val Loss: 92.17326
Epoch 14, Val Loss: 92.26882
Epoch 15, Val Loss: 85.60782
Epoch 16, Val Loss: 104.07636
Epoch 17, Val Loss: 85.09984
Epoch 18, Val Loss: 80.83943
Epoch 19, Val Loss: 86.56766
Epoch 20, Val Loss: 82.95596
Epoch 21, Val Loss: 82.11208
Epoch 22, Val Loss: 81.40349
Epoch 23, Val Loss: 90.71758
Epoch 24, Val Loss: 92.76398
Epoch 25, Val Loss: 79.66090
Epoch 26, Val Loss: 82.41655
Epoch 27, Val Loss: 82.86282
Epoch 28, Val Loss: 83.45778
Epoch 29, Val Loss: 83.98485
Epoch 30, Val Loss: 79.53378
Epoch 31, Val Loss: 84.32530
Epoch 32, Val Loss: 94.28992
Epoch 33, Val Loss: 82.33508
Epoch 34, Val Loss: 83.85921
Epoch 35, Val Loss: 83.49731
Epoch 36, Val Loss: 83.08655
Epoch 37, Val Loss: 79.41726
Epoch 38, Val Loss: 75.61622
Epoch 39, Val Loss: 80.12372
Epoch 40, Val Loss: 75.04549
Epoch 41, Val Loss: 76.90295
Epoch 42, Val Loss: 80.17430
Epoch 43, Val Loss: 87.26492
Epoch 44, Val Loss: 78.16969
Epoch 45, Val Loss: 80.68135
Epoch 46, Val Loss: 77.91185
Epoch 47, Val Loss: 77.36263
Epoch 48, Val Loss: 84.34032
Epoch 49, Val Loss: 74.77927
Epoch 50, Val Loss: 79.17385
Epoch 51, Val Loss: 84.55664
Epoch 52, Val Loss: 89.80968
Epoch 53, Val Loss: 77.24952
Epoch 54, Val Loss: 81.66673
Epoch 55, Val Loss: 73.38519
Epoch 56, Val Loss: 98.43108
Epoch 57, Val Loss: 74.40468
Epoch 58, Val Loss: 77.66539
Epoch 59, Val Loss: 72.98384
Epoch 60, Val Loss: 73.64497
Epoch 61, Val Loss: 100.61945
Epoch 62, Val Loss: 78.43102
Epoch 63, Val Loss: 76.27851
Epoch 64, Val Loss: 77.28117
Epoch 65, Val Loss: 77.49874
Epoch 66, Val Loss: 76.63389
Epoch 67, Val Loss: 72.70406
Epoch 68, Val Loss: 76.51056
Epoch 69, Val Loss: 76.74221
Epoch 70, Val Loss: 76.67623
Epoch 71, Val Loss: 72.62430
Epoch 72, Val Loss: 76.44614
Epoch 73, Val Loss: 73.60091
Epoch 74, Val Loss: 71.48877
Epoch 75, Val Loss: 82.16029
Epoch 76, Val Loss: 79.87502
Epoch 77, Val Loss: 84.93750
Epoch 78, Val Loss: 72.37625
Epoch 79, Val Loss: 80.73399
Epoch 80, Val Loss: 73.07625
Epoch 81, Val Loss: 73.19070
Epoch 82, Val Loss: 70.73036
Epoch 83, Val Loss: 77.85712
Epoch 84, Val Loss: 74.29554
Epoch 85, Val Loss: 73.93431
Epoch 86, Val Loss: 76.80315
Epoch 87, Val Loss: 74.96159
Epoch 88, Val Loss: 75.40327
Epoch 89, Val Loss: 73.59647
Epoch 90, Val Loss: 73.00561
Epoch 91, Val Loss: 83.26216
Epoch 92, Val Loss: 71.07887
Epoch 93, Val Loss: 74.66254
Epoch 94, Val Loss: 81.22021
Epoch 95, Val Loss: 72.84252
Epoch 96, Val Loss: 73.26883
Epoch 97, Val Loss: 69.92046
Epoch 98, Val Loss: 79.87228
Epoch 99, Val Loss: 70.91199
DID NOT SAVE RESULTS
{'MSE - mean': 78.27169219934672, 'MSE - std': 6.73857382236282, 'R2 - mean': 0.5086219606418159, 'R2 - std': 0.013818440783951568} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 986.03650
Epoch 1, Val Loss: 383.64337
Epoch 2, Val Loss: 166.77069
Epoch 3, Val Loss: 151.10068
Epoch 4, Val Loss: 127.13438
Epoch 5, Val Loss: 122.77628
Epoch 6, Val Loss: 116.77541
Epoch 7, Val Loss: 120.23103
Epoch 8, Val Loss: 119.23036
Epoch 9, Val Loss: 105.21494
Epoch 10, Val Loss: 102.20905
Epoch 11, Val Loss: 99.01785
Epoch 12, Val Loss: 99.27728
Epoch 13, Val Loss: 97.69928
Epoch 14, Val Loss: 90.56885
Epoch 15, Val Loss: 97.43615
Epoch 16, Val Loss: 99.16824
Epoch 17, Val Loss: 95.60661
Epoch 18, Val Loss: 102.60281
Epoch 19, Val Loss: 95.26743
Epoch 20, Val Loss: 112.43901
Epoch 21, Val Loss: 99.73493
Epoch 22, Val Loss: 89.10263
Epoch 23, Val Loss: 97.59811
Epoch 24, Val Loss: 100.75774
Epoch 25, Val Loss: 96.45078
Epoch 26, Val Loss: 89.14461
Epoch 27, Val Loss: 89.79798
Epoch 28, Val Loss: 93.06866
Epoch 29, Val Loss: 96.54774
Epoch 30, Val Loss: 88.32030
Epoch 31, Val Loss: 92.07494
Epoch 32, Val Loss: 83.06444
Epoch 33, Val Loss: 115.69500
Epoch 34, Val Loss: 87.33437
Epoch 35, Val Loss: 91.17510
Epoch 36, Val Loss: 89.07783
Epoch 37, Val Loss: 90.56770
Epoch 38, Val Loss: 92.15589
Epoch 39, Val Loss: 133.82831
Epoch 40, Val Loss: 87.67889
Epoch 41, Val Loss: 79.33765
Epoch 42, Val Loss: 90.76962
Epoch 43, Val Loss: 98.98224
Epoch 44, Val Loss: 81.11319
Epoch 45, Val Loss: 85.63721
Epoch 46, Val Loss: 96.17193
Epoch 47, Val Loss: 82.06479
Epoch 48, Val Loss: 82.44097
Epoch 49, Val Loss: 86.54877
Epoch 50, Val Loss: 84.84901
Epoch 51, Val Loss: 80.49554
Epoch 52, Val Loss: 80.32512
Epoch 53, Val Loss: 81.52393
Epoch 54, Val Loss: 81.73777
Epoch 55, Val Loss: 79.84289
Epoch 56, Val Loss: 87.62598
Epoch 57, Val Loss: 90.24683
Epoch 58, Val Loss: 93.95575
Epoch 59, Val Loss: 80.48503
Epoch 60, Val Loss: 81.34336
Epoch 61, Val Loss: 85.85999
Epoch 62, Val Loss: 77.48235
Epoch 63, Val Loss: 78.31266
Epoch 64, Val Loss: 82.17633
Epoch 65, Val Loss: 79.20161
Epoch 66, Val Loss: 83.62691
Epoch 67, Val Loss: 83.86513
Epoch 68, Val Loss: 86.93773
Epoch 69, Val Loss: 87.51096
Epoch 70, Val Loss: 92.40298
Epoch 71, Val Loss: 80.16103
Epoch 72, Val Loss: 79.59737
Epoch 73, Val Loss: 83.77018
Epoch 74, Val Loss: 79.55289
Epoch 75, Val Loss: 81.68803
Epoch 76, Val Loss: 77.24728
Epoch 77, Val Loss: 76.92160
Epoch 78, Val Loss: 80.95451
Epoch 79, Val Loss: 85.91133
Epoch 80, Val Loss: 81.30826
Epoch 81, Val Loss: 79.83627
Epoch 82, Val Loss: 78.39684
Epoch 83, Val Loss: 81.37677
Epoch 84, Val Loss: 80.04406
Epoch 85, Val Loss: 87.73787
Epoch 86, Val Loss: 78.70985
Epoch 87, Val Loss: 89.62772
Epoch 88, Val Loss: 80.22054
Epoch 89, Val Loss: 79.34637
Epoch 90, Val Loss: 79.06915
Epoch 91, Val Loss: 78.25187
Epoch 92, Val Loss: 85.95559
Epoch 93, Val Loss: 77.40236
Epoch 94, Val Loss: 80.99984
Epoch 95, Val Loss: 81.40520
Epoch 96, Val Loss: 80.63327
Epoch 97, Val Loss: 76.64197
Epoch 98, Val Loss: 91.01217
Epoch 99, Val Loss: 86.40881
DID NOT SAVE RESULTS
{'MSE - mean': 80.52280092804565, 'MSE - std': 7.018458120901533, 'R2 - mean': 0.5007118351841551, 'R2 - std': 0.018191268057573134} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 2189.28076
Epoch 1, Val Loss: 410.98337
Epoch 2, Val Loss: 193.70007
Epoch 3, Val Loss: 155.07996
Epoch 4, Val Loss: 138.33156
Epoch 5, Val Loss: 120.19402
Epoch 6, Val Loss: 122.36092
Epoch 7, Val Loss: 129.03094
Epoch 8, Val Loss: 111.18338
Epoch 9, Val Loss: 122.17231
Epoch 10, Val Loss: 102.61867
Epoch 11, Val Loss: 103.49776
Epoch 12, Val Loss: 108.59293
Epoch 13, Val Loss: 109.04029
Epoch 14, Val Loss: 117.38654
Epoch 15, Val Loss: 116.88882
Epoch 16, Val Loss: 117.08495
Epoch 17, Val Loss: 103.28026
Epoch 18, Val Loss: 99.19888
Epoch 19, Val Loss: 104.93091
Epoch 20, Val Loss: 98.25239
Epoch 21, Val Loss: 95.33450
Epoch 22, Val Loss: 98.84924
Epoch 23, Val Loss: 102.65361
Epoch 24, Val Loss: 96.44930
Epoch 25, Val Loss: 101.74889
Epoch 26, Val Loss: 89.74419
Epoch 27, Val Loss: 89.66533
Epoch 28, Val Loss: 91.82504
Epoch 29, Val Loss: 97.81370
Epoch 30, Val Loss: 92.68680
Epoch 31, Val Loss: 91.11917
Epoch 32, Val Loss: 86.16312
Epoch 33, Val Loss: 90.12103
Epoch 34, Val Loss: 86.25987
Epoch 35, Val Loss: 96.22051
Epoch 36, Val Loss: 93.26953
Epoch 37, Val Loss: 102.39821
Epoch 38, Val Loss: 97.71207
Epoch 39, Val Loss: 88.22148
Epoch 40, Val Loss: 88.95554
Epoch 41, Val Loss: 115.32552
Epoch 42, Val Loss: 85.64198
Epoch 43, Val Loss: 83.45423
Epoch 44, Val Loss: 85.28306
Epoch 45, Val Loss: 85.93007
Epoch 46, Val Loss: 83.65956
Epoch 47, Val Loss: 89.00754
Epoch 48, Val Loss: 85.88538
Epoch 49, Val Loss: 94.62933
Epoch 50, Val Loss: 85.74634
Epoch 51, Val Loss: 86.12340
Epoch 52, Val Loss: 76.52850
Epoch 53, Val Loss: 83.83407
Epoch 54, Val Loss: 81.47193
Epoch 55, Val Loss: 87.11434
Epoch 56, Val Loss: 84.36119
Epoch 57, Val Loss: 79.54344
Epoch 58, Val Loss: 77.62831
Epoch 59, Val Loss: 82.41021
Epoch 60, Val Loss: 80.43966
Epoch 61, Val Loss: 76.05577
Epoch 62, Val Loss: 85.40952
Epoch 63, Val Loss: 86.95350
Epoch 64, Val Loss: 79.66698
Epoch 65, Val Loss: 84.11768
Epoch 66, Val Loss: 79.59560
Epoch 67, Val Loss: 79.86670
Epoch 68, Val Loss: 85.53256
Epoch 69, Val Loss: 79.42056
Epoch 70, Val Loss: 78.44925
Epoch 71, Val Loss: 95.39452
Epoch 72, Val Loss: 79.00790
Epoch 73, Val Loss: 84.43137
Epoch 74, Val Loss: 77.93102
Epoch 75, Val Loss: 79.02164
Epoch 76, Val Loss: 75.34058
Epoch 77, Val Loss: 74.39312
Epoch 78, Val Loss: 77.45823
Epoch 79, Val Loss: 76.15109
Epoch 80, Val Loss: 80.52151
Epoch 81, Val Loss: 78.88246
Epoch 82, Val Loss: 75.57950
Epoch 83, Val Loss: 82.76787
Epoch 84, Val Loss: 86.12793
Epoch 85, Val Loss: 84.31952
Epoch 86, Val Loss: 79.13689
Epoch 87, Val Loss: 79.34583
Epoch 88, Val Loss: 82.69166
Epoch 89, Val Loss: 100.42313
Epoch 90, Val Loss: 86.28224
Epoch 91, Val Loss: 83.80576
Epoch 92, Val Loss: 79.53216
Epoch 93, Val Loss: 78.61900
Epoch 94, Val Loss: 80.42965
Epoch 95, Val Loss: 76.87856
Epoch 96, Val Loss: 79.30024
Epoch 97, Val Loss: 72.92874
Epoch 98, Val Loss: 75.72184
Epoch 99, Val Loss: 73.60843
DID NOT SAVE RESULTS
{'MSE - mean': 79.14657570823073, 'MSE - std': 6.8544136830583495, 'R2 - mean': 0.508200417152272, 'R2 - std': 0.022114547845407437} 
 

Results After CV: {'MSE - mean': 79.14657570823073, 'MSE - std': 6.8544136830583495, 'R2 - mean': 0.508200417152272, 'R2 - std': 0.022114547845407437}
Train time: 448.3506711548078
Inference time: 0.18873250580509193
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 74 finished with value: 79.14657570823073 and parameters: {'p_m': 0.22853007795199495, 'alpha': 8.643179262660215, 'K': 2, 'beta': 4.833885888469835}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 636.72052
Epoch 1, Val Loss: 368.42819
Epoch 2, Val Loss: 235.61467
Epoch 3, Val Loss: 201.31792
Epoch 4, Val Loss: 161.37318
Epoch 5, Val Loss: 143.92081
Epoch 6, Val Loss: 152.63603
Epoch 7, Val Loss: 126.82830
Epoch 8, Val Loss: 109.94330
Epoch 9, Val Loss: 120.47846
Epoch 10, Val Loss: 120.65045
Epoch 11, Val Loss: 142.90497
Epoch 12, Val Loss: 124.08405
Epoch 13, Val Loss: 104.18651
Epoch 14, Val Loss: 119.29214
Epoch 15, Val Loss: 127.06342
Epoch 16, Val Loss: 113.92274
Epoch 17, Val Loss: 109.52672
Epoch 18, Val Loss: 109.72449
Epoch 19, Val Loss: 122.40197
Epoch 20, Val Loss: 105.92668
Epoch 21, Val Loss: 101.14389
Epoch 22, Val Loss: 113.27481
Epoch 23, Val Loss: 105.09157
Epoch 24, Val Loss: 105.68240
Epoch 25, Val Loss: 101.06018
Epoch 26, Val Loss: 119.70831
Epoch 27, Val Loss: 93.63415
Epoch 28, Val Loss: 98.16540
Epoch 29, Val Loss: 92.48135
Epoch 30, Val Loss: 93.31058
Epoch 31, Val Loss: 105.98293
Epoch 32, Val Loss: 92.24959
Epoch 33, Val Loss: 97.14161
Epoch 34, Val Loss: 95.13310
Epoch 35, Val Loss: 90.82604
Epoch 36, Val Loss: 93.01501
Epoch 37, Val Loss: 90.30708
Epoch 38, Val Loss: 87.68048
Epoch 39, Val Loss: 96.32106
Epoch 40, Val Loss: 89.01643
Epoch 41, Val Loss: 86.81688
Epoch 42, Val Loss: 87.46699
Epoch 43, Val Loss: 97.66902
Epoch 44, Val Loss: 91.35754
Epoch 45, Val Loss: 107.48812
Epoch 46, Val Loss: 85.26648
Epoch 47, Val Loss: 87.96671
Epoch 48, Val Loss: 93.64690
Epoch 49, Val Loss: 88.34384
Epoch 50, Val Loss: 88.63582
Epoch 51, Val Loss: 89.28120
Epoch 52, Val Loss: 96.78761
Epoch 53, Val Loss: 109.00394
Epoch 54, Val Loss: 91.10693
Epoch 55, Val Loss: 91.02701
Epoch 56, Val Loss: 87.99670
Epoch 57, Val Loss: 88.27684
Epoch 58, Val Loss: 91.22288
Epoch 59, Val Loss: 87.43155
Epoch 60, Val Loss: 85.90042
Epoch 61, Val Loss: 85.57153
Epoch 62, Val Loss: 86.16653
Epoch 63, Val Loss: 92.21933
Epoch 64, Val Loss: 93.04547
Epoch 65, Val Loss: 88.17124
Epoch 66, Val Loss: 88.26874
Epoch 67, Val Loss: 87.22446
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.7370757790016, 'MSE - std': 0.0, 'R2 - mean': 0.4828995396140079, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 909.19092
Epoch 1, Val Loss: 399.01312
Epoch 2, Val Loss: 186.61115
Epoch 3, Val Loss: 177.82654
Epoch 4, Val Loss: 143.08173
Epoch 5, Val Loss: 143.61989
Epoch 6, Val Loss: 119.79489
Epoch 7, Val Loss: 140.35439
Epoch 8, Val Loss: 107.51666
Epoch 9, Val Loss: 128.48967
Epoch 10, Val Loss: 101.51266
Epoch 11, Val Loss: 116.27464
Epoch 12, Val Loss: 87.07667
Epoch 13, Val Loss: 104.92623
Epoch 14, Val Loss: 101.26106
Epoch 15, Val Loss: 90.15058
Epoch 16, Val Loss: 88.57013
Epoch 17, Val Loss: 98.98131
Epoch 18, Val Loss: 102.59220
Epoch 19, Val Loss: 90.96529
Epoch 20, Val Loss: 89.12834
Epoch 21, Val Loss: 88.11360
Epoch 22, Val Loss: 93.66592
Epoch 23, Val Loss: 93.87065
Epoch 24, Val Loss: 79.95041
Epoch 25, Val Loss: 81.55962
Epoch 26, Val Loss: 82.07292
Epoch 27, Val Loss: 87.36264
Epoch 28, Val Loss: 94.92009
Epoch 29, Val Loss: 81.57403
Epoch 30, Val Loss: 81.84003
Epoch 31, Val Loss: 91.98737
Epoch 32, Val Loss: 76.10663
Epoch 33, Val Loss: 85.12970
Epoch 34, Val Loss: 85.46172
Epoch 35, Val Loss: 81.33852
Epoch 36, Val Loss: 81.05566
Epoch 37, Val Loss: 81.69418
Epoch 38, Val Loss: 75.60934
Epoch 39, Val Loss: 91.64389
Epoch 40, Val Loss: 78.23296
Epoch 41, Val Loss: 73.86235
Epoch 42, Val Loss: 79.55375
Epoch 43, Val Loss: 75.53232
Epoch 44, Val Loss: 77.09529
Epoch 45, Val Loss: 72.15174
Epoch 46, Val Loss: 72.03201
Epoch 47, Val Loss: 75.11089
Epoch 48, Val Loss: 76.07961
Epoch 49, Val Loss: 75.38847
Epoch 50, Val Loss: 76.49213
Epoch 51, Val Loss: 73.80596
Epoch 52, Val Loss: 75.83485
Epoch 53, Val Loss: 74.34167
Epoch 54, Val Loss: 75.68497
Epoch 55, Val Loss: 71.60395
Epoch 56, Val Loss: 71.10712
Epoch 57, Val Loss: 73.26757
Epoch 58, Val Loss: 70.68606
Epoch 59, Val Loss: 73.10037
Epoch 60, Val Loss: 75.28443
Epoch 61, Val Loss: 71.77956
Epoch 62, Val Loss: 75.07357
Epoch 63, Val Loss: 76.65131
Epoch 64, Val Loss: 75.34377
Epoch 65, Val Loss: 75.23411
Epoch 66, Val Loss: 76.68483
Epoch 67, Val Loss: 72.89499
Epoch 68, Val Loss: 72.48376
Epoch 69, Val Loss: 71.96821
Epoch 70, Val Loss: 75.96646
Epoch 71, Val Loss: 76.52823
Epoch 72, Val Loss: 73.81673
Epoch 73, Val Loss: 72.81063
Epoch 74, Val Loss: 75.98354
Epoch 75, Val Loss: 70.92930
Epoch 76, Val Loss: 69.98005
Epoch 77, Val Loss: 77.91806
Epoch 78, Val Loss: 77.02553
Epoch 79, Val Loss: 71.29613
Epoch 80, Val Loss: 78.30495
Epoch 81, Val Loss: 76.52491
Epoch 82, Val Loss: 74.59544
Epoch 83, Val Loss: 82.92399
Epoch 84, Val Loss: 74.20602
Epoch 85, Val Loss: 71.34976
Epoch 86, Val Loss: 72.12558
Epoch 87, Val Loss: 74.48399
Epoch 88, Val Loss: 78.72882
Epoch 89, Val Loss: 70.81395
Epoch 90, Val Loss: 73.98929
Epoch 91, Val Loss: 83.33041
Epoch 92, Val Loss: 71.87231
Epoch 93, Val Loss: 73.23271
Epoch 94, Val Loss: 84.93103
Epoch 95, Val Loss: 81.86205
Epoch 96, Val Loss: 70.23432
Epoch 97, Val Loss: 72.53010
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.63985672794013, 'MSE - std': 5.097219051061465, 'R2 - mean': 0.49089951828348655, 'R2 - std': 0.007999978669478658} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 995.93945
Epoch 1, Val Loss: 496.69897
Epoch 2, Val Loss: 177.53929
Epoch 3, Val Loss: 145.49765
Epoch 4, Val Loss: 128.81818
Epoch 5, Val Loss: 117.49867
Epoch 6, Val Loss: 114.32745
Epoch 7, Val Loss: 117.18230
Epoch 8, Val Loss: 95.86972
Epoch 9, Val Loss: 102.46270
Epoch 10, Val Loss: 106.15712
Epoch 11, Val Loss: 94.78926
Epoch 12, Val Loss: 91.71439
Epoch 13, Val Loss: 91.22655
Epoch 14, Val Loss: 86.23285
Epoch 15, Val Loss: 88.76617
Epoch 16, Val Loss: 88.19150
Epoch 17, Val Loss: 83.71241
Epoch 18, Val Loss: 91.36964
Epoch 19, Val Loss: 91.89604
Epoch 20, Val Loss: 91.88391
Epoch 21, Val Loss: 81.24056
Epoch 22, Val Loss: 76.80424
Epoch 23, Val Loss: 103.19445
Epoch 24, Val Loss: 90.58658
Epoch 25, Val Loss: 85.03767
Epoch 26, Val Loss: 82.38670
Epoch 27, Val Loss: 78.03738
Epoch 28, Val Loss: 93.25867
Epoch 29, Val Loss: 81.87867
Epoch 30, Val Loss: 71.34128
Epoch 31, Val Loss: 74.27055
Epoch 32, Val Loss: 75.93237
Epoch 33, Val Loss: 73.61822
Epoch 34, Val Loss: 70.73059
Epoch 35, Val Loss: 89.18604
Epoch 36, Val Loss: 73.44089
Epoch 37, Val Loss: 74.87479
Epoch 38, Val Loss: 73.20222
Epoch 39, Val Loss: 67.82938
Epoch 40, Val Loss: 81.01604
Epoch 41, Val Loss: 69.31328
Epoch 42, Val Loss: 83.32546
Epoch 43, Val Loss: 74.54781
Epoch 44, Val Loss: 69.74139
Epoch 45, Val Loss: 73.17391
Epoch 46, Val Loss: 70.53627
Epoch 47, Val Loss: 73.02357
Epoch 48, Val Loss: 71.20980
Epoch 49, Val Loss: 77.66914
Epoch 50, Val Loss: 71.93485
Epoch 51, Val Loss: 69.87440
Epoch 52, Val Loss: 70.60595
Epoch 53, Val Loss: 67.60188
Epoch 54, Val Loss: 72.67973
Epoch 55, Val Loss: 71.67322
Epoch 56, Val Loss: 72.24852
Epoch 57, Val Loss: 71.24825
Epoch 58, Val Loss: 74.45822
Epoch 59, Val Loss: 71.45502
Epoch 60, Val Loss: 69.26382
Epoch 61, Val Loss: 71.56001
Epoch 62, Val Loss: 69.10896
Epoch 63, Val Loss: 83.18988
Epoch 64, Val Loss: 77.88481
Epoch 65, Val Loss: 72.40965
Epoch 66, Val Loss: 69.59590
Epoch 67, Val Loss: 71.92007
Epoch 68, Val Loss: 75.42486
Epoch 69, Val Loss: 73.44489
Epoch 70, Val Loss: 67.95660
Epoch 71, Val Loss: 71.52918
Epoch 72, Val Loss: 72.68946
Epoch 73, Val Loss: 69.69478
Epoch 74, Val Loss: 71.70964
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.43310968365728, 'MSE - std': 8.45822228776822, 'R2 - mean': 0.5082103892200344, 'R2 - std': 0.02533769808615304} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 716.02686
Epoch 1, Val Loss: 487.51147
Epoch 2, Val Loss: 184.22398
Epoch 3, Val Loss: 162.78365
Epoch 4, Val Loss: 158.95035
Epoch 5, Val Loss: 145.03003
Epoch 6, Val Loss: 126.42907
Epoch 7, Val Loss: 160.73372
Epoch 8, Val Loss: 119.36911
Epoch 9, Val Loss: 141.40668
Epoch 10, Val Loss: 122.06633
Epoch 11, Val Loss: 111.24022
Epoch 12, Val Loss: 127.55201
Epoch 13, Val Loss: 103.59802
Epoch 14, Val Loss: 104.03074
Epoch 15, Val Loss: 123.87269
Epoch 16, Val Loss: 90.18909
Epoch 17, Val Loss: 99.32904
Epoch 18, Val Loss: 89.37885
Epoch 19, Val Loss: 88.42026
Epoch 20, Val Loss: 107.94210
Epoch 21, Val Loss: 87.52370
Epoch 22, Val Loss: 97.82402
Epoch 23, Val Loss: 94.65636
Epoch 24, Val Loss: 96.64139
Epoch 25, Val Loss: 112.64686
Epoch 26, Val Loss: 88.09998
Epoch 27, Val Loss: 90.50636
Epoch 28, Val Loss: 87.58888
Epoch 29, Val Loss: 85.96152
Epoch 30, Val Loss: 92.61539
Epoch 31, Val Loss: 87.90730
Epoch 32, Val Loss: 85.81070
Epoch 33, Val Loss: 85.88474
Epoch 34, Val Loss: 89.74930
Epoch 35, Val Loss: 80.72217
Epoch 36, Val Loss: 82.15607
Epoch 37, Val Loss: 89.47272
Epoch 38, Val Loss: 80.00787
Epoch 39, Val Loss: 88.88486
Epoch 40, Val Loss: 86.59575
Epoch 41, Val Loss: 93.21066
Epoch 42, Val Loss: 86.55857
Epoch 43, Val Loss: 86.55412
Epoch 44, Val Loss: 84.12975
Epoch 45, Val Loss: 82.11145
Epoch 46, Val Loss: 80.00795
Epoch 47, Val Loss: 82.97954
Epoch 48, Val Loss: 85.71258
Epoch 49, Val Loss: 94.30887
Epoch 50, Val Loss: 82.19073
Epoch 51, Val Loss: 82.75224
Epoch 52, Val Loss: 82.23327
Epoch 53, Val Loss: 78.95602
Epoch 54, Val Loss: 90.56281
Epoch 55, Val Loss: 83.29694
Epoch 56, Val Loss: 78.68941
Epoch 57, Val Loss: 80.47823
Epoch 58, Val Loss: 82.04920
Epoch 59, Val Loss: 81.22758
Epoch 60, Val Loss: 88.43752
Epoch 61, Val Loss: 82.23610
Epoch 62, Val Loss: 80.91963
Epoch 63, Val Loss: 80.80671
Epoch 64, Val Loss: 90.25124
Epoch 65, Val Loss: 83.83716
Epoch 66, Val Loss: 81.41431
Epoch 67, Val Loss: 87.76495
Epoch 68, Val Loss: 81.69968
Epoch 69, Val Loss: 97.19431
Epoch 70, Val Loss: 88.23917
Epoch 71, Val Loss: 81.57593
Epoch 72, Val Loss: 80.36512
Epoch 73, Val Loss: 83.97867
Epoch 74, Val Loss: 83.10679
Epoch 75, Val Loss: 80.65524
Epoch 76, Val Loss: 84.30229
Epoch 77, Val Loss: 80.27061
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.16459476147106, 'MSE - std': 8.720044460490575, 'R2 - mean': 0.4972825802284578, 'R2 - std': 0.028978444338817272} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 739.26312
Epoch 1, Val Loss: 450.75308
Epoch 2, Val Loss: 184.67145
Epoch 3, Val Loss: 165.61812
Epoch 4, Val Loss: 133.03940
Epoch 5, Val Loss: 159.06299
Epoch 6, Val Loss: 138.46915
Epoch 7, Val Loss: 124.74136
Epoch 8, Val Loss: 119.40959
Epoch 9, Val Loss: 119.72555
Epoch 10, Val Loss: 128.16350
Epoch 11, Val Loss: 119.39996
Epoch 12, Val Loss: 102.37262
Epoch 13, Val Loss: 105.79492
Epoch 14, Val Loss: 102.55650
Epoch 15, Val Loss: 107.44726
Epoch 16, Val Loss: 111.56605
Epoch 17, Val Loss: 104.63251
Epoch 18, Val Loss: 110.15410
Epoch 19, Val Loss: 101.72623
Epoch 20, Val Loss: 102.71507
Epoch 21, Val Loss: 117.42084
Epoch 22, Val Loss: 98.12112
Epoch 23, Val Loss: 103.06204
Epoch 24, Val Loss: 96.12953
Epoch 25, Val Loss: 115.65988
Epoch 26, Val Loss: 100.42101
Epoch 27, Val Loss: 96.20085
Epoch 28, Val Loss: 89.77160
Epoch 29, Val Loss: 92.62189
Epoch 30, Val Loss: 84.27031
Epoch 31, Val Loss: 86.76020
Epoch 32, Val Loss: 86.19877
Epoch 33, Val Loss: 94.96558
Epoch 34, Val Loss: 83.93373
Epoch 35, Val Loss: 85.70433
Epoch 36, Val Loss: 87.36469
Epoch 37, Val Loss: 90.80825
Epoch 38, Val Loss: 78.51382
Epoch 39, Val Loss: 84.10532
Epoch 40, Val Loss: 81.76340
Epoch 41, Val Loss: 84.84966
Epoch 42, Val Loss: 87.12936
Epoch 43, Val Loss: 80.49383
Epoch 44, Val Loss: 77.37005
Epoch 45, Val Loss: 80.81061
Epoch 46, Val Loss: 81.99619
Epoch 47, Val Loss: 81.53868
Epoch 48, Val Loss: 95.28723
Epoch 49, Val Loss: 82.29735
Epoch 50, Val Loss: 79.11903
Epoch 51, Val Loss: 80.58449
Epoch 52, Val Loss: 76.30727
Epoch 53, Val Loss: 81.03646
Epoch 54, Val Loss: 80.95799
Epoch 55, Val Loss: 82.17861
Epoch 56, Val Loss: 77.84022
Epoch 57, Val Loss: 86.93030
Epoch 58, Val Loss: 78.65407
Epoch 59, Val Loss: 82.89445
Epoch 60, Val Loss: 84.15882
Epoch 61, Val Loss: 88.23211
Epoch 62, Val Loss: 83.25433
Epoch 63, Val Loss: 76.60593
Epoch 64, Val Loss: 97.52869
Epoch 65, Val Loss: 80.27495
Epoch 66, Val Loss: 85.80134
Epoch 67, Val Loss: 79.34518
Epoch 68, Val Loss: 77.50799
Epoch 69, Val Loss: 80.87749
Epoch 70, Val Loss: 81.22517
Epoch 71, Val Loss: 86.29639
Epoch 72, Val Loss: 88.63028
Epoch 73, Val Loss: 77.63766
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.44999067691803, 'MSE - std': 7.929311212519367, 'R2 - mean': 0.5005026382351161, 'R2 - std': 0.026707214068549357} 
 

Results After CV: {'MSE - mean': 80.44999067691803, 'MSE - std': 7.929311212519367, 'R2 - mean': 0.5005026382351161, 'R2 - std': 0.026707214068549357}
Train time: 888.201869918796
Inference time: 0.18347723420592957
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 75 finished with value: 80.44999067691803 and parameters: {'p_m': 0.25516184328583436, 'alpha': 7.918709530035201, 'K': 5, 'beta': 9.460291412650015}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 957.01068
Epoch 1, Val Loss: 389.50562
Epoch 2, Val Loss: 175.30296
Epoch 3, Val Loss: 151.92987
Epoch 4, Val Loss: 143.16074
Epoch 5, Val Loss: 140.87131
Epoch 6, Val Loss: 121.98816
Epoch 7, Val Loss: 117.99496
Epoch 8, Val Loss: 118.89780
Epoch 9, Val Loss: 121.96646
Epoch 10, Val Loss: 113.41194
Epoch 11, Val Loss: 99.03387
Epoch 12, Val Loss: 121.42482
Epoch 13, Val Loss: 107.82034
Epoch 14, Val Loss: 107.08243
Epoch 15, Val Loss: 121.07937
Epoch 16, Val Loss: 100.74730
Epoch 17, Val Loss: 103.99907
Epoch 18, Val Loss: 102.14089
Epoch 19, Val Loss: 120.23966
Epoch 20, Val Loss: 101.46355
Epoch 21, Val Loss: 126.42902
Epoch 22, Val Loss: 100.69207
Epoch 23, Val Loss: 97.52098
Epoch 24, Val Loss: 154.70811
Epoch 25, Val Loss: 97.30486
Epoch 26, Val Loss: 99.86565
Epoch 27, Val Loss: 96.31814
Epoch 28, Val Loss: 109.37926
Epoch 29, Val Loss: 101.03575
Epoch 30, Val Loss: 95.69988
Epoch 31, Val Loss: 110.03346
Epoch 32, Val Loss: 104.68787
Epoch 33, Val Loss: 107.57884
Epoch 34, Val Loss: 105.19476
Epoch 35, Val Loss: 101.91690
Epoch 36, Val Loss: 97.25332
Epoch 37, Val Loss: 95.35985
Epoch 38, Val Loss: 108.26187
Epoch 39, Val Loss: 115.06764
Epoch 40, Val Loss: 99.46604
Epoch 41, Val Loss: 106.85914
Epoch 42, Val Loss: 104.58201
Epoch 43, Val Loss: 93.85902
Epoch 44, Val Loss: 97.22796
Epoch 45, Val Loss: 96.80733
Epoch 46, Val Loss: 100.03391
Epoch 47, Val Loss: 100.16572
Epoch 48, Val Loss: 97.39495
Epoch 49, Val Loss: 95.39247
Epoch 50, Val Loss: 88.44481
Epoch 51, Val Loss: 88.96165
Epoch 52, Val Loss: 90.06432
Epoch 53, Val Loss: 90.77692
Epoch 54, Val Loss: 92.74776
Epoch 55, Val Loss: 90.32033
Epoch 56, Val Loss: 98.44704
Epoch 57, Val Loss: 92.35141
Epoch 58, Val Loss: 86.81854
Epoch 59, Val Loss: 95.66386
Epoch 60, Val Loss: 90.27687
Epoch 61, Val Loss: 88.80773
Epoch 62, Val Loss: 90.07007
Epoch 63, Val Loss: 92.37939
Epoch 64, Val Loss: 92.27483
Epoch 65, Val Loss: 86.66749
Epoch 66, Val Loss: 95.85219
Epoch 67, Val Loss: 90.47975
Epoch 68, Val Loss: 89.53698
Epoch 69, Val Loss: 92.48849
Epoch 70, Val Loss: 88.63368
Epoch 71, Val Loss: 90.99486
Epoch 72, Val Loss: 85.95622
Epoch 73, Val Loss: 88.70547
Epoch 74, Val Loss: 83.62553
Epoch 75, Val Loss: 86.09129
Epoch 76, Val Loss: 88.65091
Epoch 77, Val Loss: 85.48896
Epoch 78, Val Loss: 96.80887
Epoch 79, Val Loss: 89.10625
Epoch 80, Val Loss: 89.59000
Epoch 81, Val Loss: 92.22774
Epoch 82, Val Loss: 90.36536
Epoch 83, Val Loss: 95.07452
Epoch 84, Val Loss: 89.63918
Epoch 85, Val Loss: 96.18855
Epoch 86, Val Loss: 105.13235
Epoch 87, Val Loss: 87.95312
Epoch 88, Val Loss: 89.50334
Epoch 89, Val Loss: 89.30634
Epoch 90, Val Loss: 94.89091
Epoch 91, Val Loss: 87.53555
Epoch 92, Val Loss: 89.74624
Epoch 93, Val Loss: 87.73259
Epoch 94, Val Loss: 87.12238
Epoch 95, Val Loss: 93.24441
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.74178317691998, 'MSE - std': 0.0, 'R2 - mean': 0.48869944070649995, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 465.68503
Epoch 1, Val Loss: 274.79242
Epoch 2, Val Loss: 166.91882
Epoch 3, Val Loss: 139.47253
Epoch 4, Val Loss: 119.57096
Epoch 5, Val Loss: 118.22424
Epoch 6, Val Loss: 124.76461
Epoch 7, Val Loss: 94.86937
Epoch 8, Val Loss: 118.20692
Epoch 9, Val Loss: 93.74418
Epoch 10, Val Loss: 86.38866
Epoch 11, Val Loss: 101.78814
Epoch 12, Val Loss: 90.76409
Epoch 13, Val Loss: 90.24142
Epoch 14, Val Loss: 93.35284
Epoch 15, Val Loss: 83.70673
Epoch 16, Val Loss: 87.91051
Epoch 17, Val Loss: 88.66866
Epoch 18, Val Loss: 98.92433
Epoch 19, Val Loss: 90.57232
Epoch 20, Val Loss: 86.10406
Epoch 21, Val Loss: 82.86485
Epoch 22, Val Loss: 85.69044
Epoch 23, Val Loss: 83.50554
Epoch 24, Val Loss: 90.14702
Epoch 25, Val Loss: 85.49061
Epoch 26, Val Loss: 94.68015
Epoch 27, Val Loss: 80.12315
Epoch 28, Val Loss: 85.13557
Epoch 29, Val Loss: 92.93753
Epoch 30, Val Loss: 76.49684
Epoch 31, Val Loss: 82.82343
Epoch 32, Val Loss: 87.94708
Epoch 33, Val Loss: 74.76917
Epoch 34, Val Loss: 112.57189
Epoch 35, Val Loss: 86.56486
Epoch 36, Val Loss: 71.82423
Epoch 37, Val Loss: 93.24573
Epoch 38, Val Loss: 78.09578
Epoch 39, Val Loss: 86.41282
Epoch 40, Val Loss: 83.46018
Epoch 41, Val Loss: 78.85577
Epoch 42, Val Loss: 87.88456
Epoch 43, Val Loss: 88.30656
Epoch 44, Val Loss: 78.00827
Epoch 45, Val Loss: 73.16975
Epoch 46, Val Loss: 87.30492
Epoch 47, Val Loss: 77.30453
Epoch 48, Val Loss: 76.37235
Epoch 49, Val Loss: 80.86703
Epoch 50, Val Loss: 77.89359
Epoch 51, Val Loss: 70.55125
Epoch 52, Val Loss: 88.39183
Epoch 53, Val Loss: 76.23459
Epoch 54, Val Loss: 78.42622
Epoch 55, Val Loss: 75.46683
Epoch 56, Val Loss: 70.53467
Epoch 57, Val Loss: 76.81586
Epoch 58, Val Loss: 74.10690
Epoch 59, Val Loss: 80.19199
Epoch 60, Val Loss: 87.25017
Epoch 61, Val Loss: 85.76570
Epoch 62, Val Loss: 82.33368
Epoch 63, Val Loss: 73.64536
Epoch 64, Val Loss: 78.55802
Epoch 65, Val Loss: 72.56812
Epoch 66, Val Loss: 77.60606
Epoch 67, Val Loss: 75.09485
Epoch 68, Val Loss: 73.39581
Epoch 69, Val Loss: 74.88353
Epoch 70, Val Loss: 71.22063
Epoch 71, Val Loss: 73.63142
Epoch 72, Val Loss: 73.20055
Epoch 73, Val Loss: 72.04703
Epoch 74, Val Loss: 71.11403
Epoch 75, Val Loss: 68.70206
Epoch 76, Val Loss: 83.74606
Epoch 77, Val Loss: 72.32006
Epoch 78, Val Loss: 70.89233
Epoch 79, Val Loss: 72.29745
Epoch 80, Val Loss: 68.08325
Epoch 81, Val Loss: 70.14272
Epoch 82, Val Loss: 70.73431
Epoch 83, Val Loss: 73.45142
Epoch 84, Val Loss: 67.73485
Epoch 85, Val Loss: 73.49348
Epoch 86, Val Loss: 77.45536
Epoch 87, Val Loss: 67.84196
Epoch 88, Val Loss: 68.83385
Epoch 89, Val Loss: 67.16212
Epoch 90, Val Loss: 67.89770
Epoch 91, Val Loss: 72.66313
Epoch 92, Val Loss: 74.11430
Epoch 93, Val Loss: 78.03209
Epoch 94, Val Loss: 69.96846
Epoch 95, Val Loss: 69.47809
Epoch 96, Val Loss: 68.37238
Epoch 97, Val Loss: 78.97021
Epoch 98, Val Loss: 72.55045
Epoch 99, Val Loss: 69.93391
DID NOT SAVE RESULTS
{'MSE - mean': 81.34522996004293, 'MSE - std': 6.396553216877059, 'R2 - mean': 0.5052641693101511, 'R2 - std': 0.016564728603651102} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 983.03387
Epoch 1, Val Loss: 429.13544
Epoch 2, Val Loss: 153.99329
Epoch 3, Val Loss: 132.03339
Epoch 4, Val Loss: 110.27458
Epoch 5, Val Loss: 103.32598
Epoch 6, Val Loss: 99.10696
Epoch 7, Val Loss: 123.85963
Epoch 8, Val Loss: 86.48243
Epoch 9, Val Loss: 99.23636
Epoch 10, Val Loss: 85.42995
Epoch 11, Val Loss: 89.01145
Epoch 12, Val Loss: 87.67886
Epoch 13, Val Loss: 86.79962
Epoch 14, Val Loss: 94.11557
Epoch 15, Val Loss: 83.24799
Epoch 16, Val Loss: 86.32970
Epoch 17, Val Loss: 87.31812
Epoch 18, Val Loss: 88.95789
Epoch 19, Val Loss: 88.70962
Epoch 20, Val Loss: 85.35471
Epoch 21, Val Loss: 91.22906
Epoch 22, Val Loss: 93.14717
Epoch 23, Val Loss: 95.29248
Epoch 24, Val Loss: 84.39233
Epoch 25, Val Loss: 84.99871
Epoch 26, Val Loss: 82.41795
Epoch 27, Val Loss: 82.06416
Epoch 28, Val Loss: 84.65343
Epoch 29, Val Loss: 86.53470
Epoch 30, Val Loss: 98.90479
Epoch 31, Val Loss: 79.86710
Epoch 32, Val Loss: 91.98617
Epoch 33, Val Loss: 89.81920
Epoch 34, Val Loss: 94.46319
Epoch 35, Val Loss: 84.69759
Epoch 36, Val Loss: 82.27585
Epoch 37, Val Loss: 79.41900
Epoch 38, Val Loss: 86.79089
Epoch 39, Val Loss: 80.78922
Epoch 40, Val Loss: 90.34488
Epoch 41, Val Loss: 84.73776
Epoch 42, Val Loss: 81.57257
Epoch 43, Val Loss: 76.98741
Epoch 44, Val Loss: 81.68036
Epoch 45, Val Loss: 85.27658
Epoch 46, Val Loss: 81.13226
Epoch 47, Val Loss: 77.53217
Epoch 48, Val Loss: 90.82773
Epoch 49, Val Loss: 91.79068
Epoch 50, Val Loss: 80.11467
Epoch 51, Val Loss: 80.41844
Epoch 52, Val Loss: 75.17920
Epoch 53, Val Loss: 85.98495
Epoch 54, Val Loss: 84.31596
Epoch 55, Val Loss: 80.38089
Epoch 56, Val Loss: 74.99465
Epoch 57, Val Loss: 76.27726
Epoch 58, Val Loss: 75.73058
Epoch 59, Val Loss: 76.44666
Epoch 60, Val Loss: 76.19022
Epoch 61, Val Loss: 73.62823
Epoch 62, Val Loss: 73.69817
Epoch 63, Val Loss: 74.63187
Epoch 64, Val Loss: 72.07745
Epoch 65, Val Loss: 100.30885
Epoch 66, Val Loss: 88.49658
Epoch 67, Val Loss: 94.08882
Epoch 68, Val Loss: 73.69363
Epoch 69, Val Loss: 73.87505
Epoch 70, Val Loss: 73.45395
Epoch 71, Val Loss: 76.24966
Epoch 72, Val Loss: 74.40916
Epoch 73, Val Loss: 73.63071
Epoch 74, Val Loss: 68.84550
Epoch 75, Val Loss: 78.43521
Epoch 76, Val Loss: 70.19268
Epoch 77, Val Loss: 78.40515
Epoch 78, Val Loss: 68.70323
Epoch 79, Val Loss: 69.52941
Epoch 80, Val Loss: 69.35950
Epoch 81, Val Loss: 71.03422
Epoch 82, Val Loss: 74.09890
Epoch 83, Val Loss: 101.95828
Epoch 84, Val Loss: 69.66821
Epoch 85, Val Loss: 68.76823
Epoch 86, Val Loss: 76.37539
Epoch 87, Val Loss: 73.22041
Epoch 88, Val Loss: 79.29772
Epoch 89, Val Loss: 71.82915
Epoch 90, Val Loss: 73.05904
Epoch 91, Val Loss: 78.98778
Epoch 92, Val Loss: 79.42918
Epoch 93, Val Loss: 69.69073
Epoch 94, Val Loss: 72.55883
Epoch 95, Val Loss: 71.52382
Epoch 96, Val Loss: 82.46278
Epoch 97, Val Loss: 69.81339
Epoch 98, Val Loss: 70.57259
Epoch 99, Val Loss: 82.81829
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.40342060568045, 'MSE - std': 7.638912488688373, 'R2 - mean': 0.5144258468067908, 'R2 - std': 0.018729642056909388} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 726.27704
Epoch 1, Val Loss: 436.36264
Epoch 2, Val Loss: 173.63960
Epoch 3, Val Loss: 132.49174
Epoch 4, Val Loss: 121.04602
Epoch 5, Val Loss: 125.15919
Epoch 6, Val Loss: 128.76392
Epoch 7, Val Loss: 104.44692
Epoch 8, Val Loss: 103.14744
Epoch 9, Val Loss: 107.51904
Epoch 10, Val Loss: 107.84304
Epoch 11, Val Loss: 98.79849
Epoch 12, Val Loss: 100.10742
Epoch 13, Val Loss: 98.82234
Epoch 14, Val Loss: 105.40040
Epoch 15, Val Loss: 96.65173
Epoch 16, Val Loss: 93.54185
Epoch 17, Val Loss: 94.85784
Epoch 18, Val Loss: 103.60025
Epoch 19, Val Loss: 110.24379
Epoch 20, Val Loss: 98.47344
Epoch 21, Val Loss: 93.79509
Epoch 22, Val Loss: 94.33877
Epoch 23, Val Loss: 95.77534
Epoch 24, Val Loss: 96.65670
Epoch 25, Val Loss: 91.66885
Epoch 26, Val Loss: 94.00646
Epoch 27, Val Loss: 105.08861
Epoch 28, Val Loss: 92.01269
Epoch 29, Val Loss: 105.47992
Epoch 30, Val Loss: 95.12811
Epoch 31, Val Loss: 100.25203
Epoch 32, Val Loss: 109.65561
Epoch 33, Val Loss: 90.89118
Epoch 34, Val Loss: 103.40456
Epoch 35, Val Loss: 93.17213
Epoch 36, Val Loss: 84.45203
Epoch 37, Val Loss: 95.45560
Epoch 38, Val Loss: 86.50158
Epoch 39, Val Loss: 90.97808
Epoch 40, Val Loss: 97.12945
Epoch 41, Val Loss: 88.60187
Epoch 42, Val Loss: 94.16441
Epoch 43, Val Loss: 82.87093
Epoch 44, Val Loss: 83.95709
Epoch 45, Val Loss: 91.75409
Epoch 46, Val Loss: 85.50295
Epoch 47, Val Loss: 90.80892
Epoch 48, Val Loss: 105.18149
Epoch 49, Val Loss: 92.81129
Epoch 50, Val Loss: 88.23300
Epoch 51, Val Loss: 89.55923
Epoch 52, Val Loss: 82.98516
Epoch 53, Val Loss: 84.77356
Epoch 54, Val Loss: 82.06053
Epoch 55, Val Loss: 78.89659
Epoch 56, Val Loss: 96.51237
Epoch 57, Val Loss: 89.48176
Epoch 58, Val Loss: 80.58675
Epoch 59, Val Loss: 82.55530
Epoch 60, Val Loss: 79.65108
Epoch 61, Val Loss: 87.52042
Epoch 62, Val Loss: 83.95341
Epoch 63, Val Loss: 87.43549
Epoch 64, Val Loss: 96.85757
Epoch 65, Val Loss: 80.72826
Epoch 66, Val Loss: 82.91903
Epoch 67, Val Loss: 79.09403
Epoch 68, Val Loss: 77.93901
Epoch 69, Val Loss: 89.85059
Epoch 70, Val Loss: 88.15820
Epoch 71, Val Loss: 83.05786
Epoch 72, Val Loss: 80.25088
Epoch 73, Val Loss: 84.37423
Epoch 74, Val Loss: 77.58873
Epoch 75, Val Loss: 77.24912
Epoch 76, Val Loss: 86.11336
Epoch 77, Val Loss: 76.57886
Epoch 78, Val Loss: 77.73036
Epoch 79, Val Loss: 83.60355
Epoch 80, Val Loss: 82.32117
Epoch 81, Val Loss: 78.15027
Epoch 82, Val Loss: 79.84462
Epoch 83, Val Loss: 76.87302
Epoch 84, Val Loss: 85.87454
Epoch 85, Val Loss: 78.11098
Epoch 86, Val Loss: 75.82272
Epoch 87, Val Loss: 77.07861
Epoch 88, Val Loss: 75.02655
Epoch 89, Val Loss: 77.25153
Epoch 90, Val Loss: 77.60155
Epoch 91, Val Loss: 76.29067
Epoch 92, Val Loss: 85.80693
Epoch 93, Val Loss: 79.33067
Epoch 94, Val Loss: 78.43283
Epoch 95, Val Loss: 75.56214
Epoch 96, Val Loss: 81.42815
Epoch 97, Val Loss: 78.73830
Epoch 98, Val Loss: 81.20972
Epoch 99, Val Loss: 80.83455
DID NOT SAVE RESULTS
{'MSE - mean': 79.4198312467374, 'MSE - std': 7.480807017126065, 'R2 - mean': 0.5077720421087701, 'R2 - std': 0.019897712671640682} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 756.93719
Epoch 1, Val Loss: 420.38177
Epoch 2, Val Loss: 169.06456
Epoch 3, Val Loss: 136.73965
Epoch 4, Val Loss: 124.07987
Epoch 5, Val Loss: 124.42603
Epoch 6, Val Loss: 106.41037
Epoch 7, Val Loss: 108.16310
Epoch 8, Val Loss: 106.48378
Epoch 9, Val Loss: 125.20923
Epoch 10, Val Loss: 88.50496
Epoch 11, Val Loss: 96.42198
Epoch 12, Val Loss: 106.75887
Epoch 13, Val Loss: 92.96921
Epoch 14, Val Loss: 91.60476
Epoch 15, Val Loss: 83.65651
Epoch 16, Val Loss: 108.63187
Epoch 17, Val Loss: 97.22148
Epoch 18, Val Loss: 85.43076
Epoch 19, Val Loss: 87.37139
Epoch 20, Val Loss: 85.58366
Epoch 21, Val Loss: 103.64008
Epoch 22, Val Loss: 89.97049
Epoch 23, Val Loss: 94.33599
Epoch 24, Val Loss: 94.50114
Epoch 25, Val Loss: 87.79021
Epoch 26, Val Loss: 89.83189
Epoch 27, Val Loss: 85.92108
Epoch 28, Val Loss: 93.52138
Epoch 29, Val Loss: 85.97302
Epoch 30, Val Loss: 91.64569
Epoch 31, Val Loss: 91.88792
Epoch 32, Val Loss: 85.81085
Epoch 33, Val Loss: 96.07094
Epoch 34, Val Loss: 85.53791
Epoch 35, Val Loss: 93.57793
Epoch 36, Val Loss: 96.23743
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.39234858618393, 'MSE - std': 6.96800823794595, 'R2 - mean': 0.5005018555066134, 'R2 - std': 0.02298168028172121} 
 

Results After CV: {'MSE - mean': 80.39234858618393, 'MSE - std': 6.96800823794595, 'R2 - mean': 0.5005018555066134, 'R2 - std': 0.02298168028172121}
Train time: 400.69628290720283
Inference time: 0.20262990639894268
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 76 finished with value: 80.39234858618393 and parameters: {'p_m': 0.16748002019418276, 'alpha': 7.649280959580485, 'K': 2, 'beta': 6.231543877189242}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 770.09845
Epoch 1, Val Loss: 397.46069
Epoch 2, Val Loss: 163.79257
Epoch 3, Val Loss: 138.68372
Epoch 4, Val Loss: 119.97224
Epoch 5, Val Loss: 118.88747
Epoch 6, Val Loss: 112.68472
Epoch 7, Val Loss: 109.64561
Epoch 8, Val Loss: 106.23624
Epoch 9, Val Loss: 100.76568
Epoch 10, Val Loss: 108.31226
Epoch 11, Val Loss: 115.34567
Epoch 12, Val Loss: 103.65037
Epoch 13, Val Loss: 96.18225
Epoch 14, Val Loss: 101.26925
Epoch 15, Val Loss: 101.90507
Epoch 16, Val Loss: 103.34711
Epoch 17, Val Loss: 106.95535
Epoch 18, Val Loss: 97.63712
Epoch 19, Val Loss: 96.61293
Epoch 20, Val Loss: 110.63533
Epoch 21, Val Loss: 96.08200
Epoch 22, Val Loss: 95.46185
Epoch 23, Val Loss: 99.79604
Epoch 24, Val Loss: 94.88007
Epoch 25, Val Loss: 104.34224
Epoch 26, Val Loss: 95.88358
Epoch 27, Val Loss: 95.91658
Epoch 28, Val Loss: 103.21750
Epoch 29, Val Loss: 100.17236
Epoch 30, Val Loss: 104.07496
Epoch 31, Val Loss: 100.44124
Epoch 32, Val Loss: 98.86782
Epoch 33, Val Loss: 99.22617
Epoch 34, Val Loss: 93.32442
Epoch 35, Val Loss: 105.13390
Epoch 36, Val Loss: 97.94184
Epoch 37, Val Loss: 105.42552
Epoch 38, Val Loss: 93.04688
Epoch 39, Val Loss: 98.16042
Epoch 40, Val Loss: 116.18009
Epoch 41, Val Loss: 95.92828
Epoch 42, Val Loss: 90.31568
Epoch 43, Val Loss: 105.03705
Epoch 44, Val Loss: 113.20424
Epoch 45, Val Loss: 98.27628
Epoch 46, Val Loss: 105.49056
Epoch 47, Val Loss: 89.21854
Epoch 48, Val Loss: 92.71031
Epoch 49, Val Loss: 102.18753
Epoch 50, Val Loss: 88.68846
Epoch 51, Val Loss: 104.86325
Epoch 52, Val Loss: 102.69526
Epoch 53, Val Loss: 92.72290
Epoch 54, Val Loss: 93.80100
Epoch 55, Val Loss: 93.59698
Epoch 56, Val Loss: 102.24864
Epoch 57, Val Loss: 101.07903
Epoch 58, Val Loss: 95.68260
Epoch 59, Val Loss: 98.87423
Epoch 60, Val Loss: 88.54077
Epoch 61, Val Loss: 90.66657
Epoch 62, Val Loss: 90.41091
Epoch 63, Val Loss: 97.19450
Epoch 64, Val Loss: 91.32423
Epoch 65, Val Loss: 95.36166
Epoch 66, Val Loss: 94.37462
Epoch 67, Val Loss: 89.76035
Epoch 68, Val Loss: 91.67763
Epoch 69, Val Loss: 91.84102
Epoch 70, Val Loss: 92.54931
Epoch 71, Val Loss: 93.21893
Epoch 72, Val Loss: 94.37726
Epoch 73, Val Loss: 87.94456
Epoch 74, Val Loss: 89.67966
Epoch 75, Val Loss: 88.16274
Epoch 76, Val Loss: 92.47486
Epoch 77, Val Loss: 88.65498
Epoch 78, Val Loss: 96.70970
Epoch 79, Val Loss: 103.26876
Epoch 80, Val Loss: 90.43768
Epoch 81, Val Loss: 88.75448
Epoch 82, Val Loss: 92.38534
Epoch 83, Val Loss: 97.35433
Epoch 84, Val Loss: 90.67330
Epoch 85, Val Loss: 93.50990
Epoch 86, Val Loss: 86.14105
Epoch 87, Val Loss: 86.01092
Epoch 88, Val Loss: 94.30214
Epoch 89, Val Loss: 88.03259
Epoch 90, Val Loss: 90.30682
Epoch 91, Val Loss: 88.44199
Epoch 92, Val Loss: 94.92923
Epoch 93, Val Loss: 84.89478
Epoch 94, Val Loss: 94.19913
Epoch 95, Val Loss: 95.43593
Epoch 96, Val Loss: 89.90778
Epoch 97, Val Loss: 92.67882
Epoch 98, Val Loss: 88.63733
Epoch 99, Val Loss: 86.25731
DID NOT SAVE RESULTS
{'MSE - mean': 89.13960218488565, 'MSE - std': 0.0, 'R2 - mean': 0.4805538843400101, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 369.24088
Epoch 1, Val Loss: 197.81161
Epoch 2, Val Loss: 143.26184
Epoch 3, Val Loss: 121.64235
Epoch 4, Val Loss: 129.83194
Epoch 5, Val Loss: 100.17214
Epoch 6, Val Loss: 96.71439
Epoch 7, Val Loss: 95.40626
Epoch 8, Val Loss: 87.21209
Epoch 9, Val Loss: 92.74860
Epoch 10, Val Loss: 95.13857
Epoch 11, Val Loss: 94.51254
Epoch 12, Val Loss: 83.88337
Epoch 13, Val Loss: 88.61774
Epoch 14, Val Loss: 83.18961
Epoch 15, Val Loss: 85.96767
Epoch 16, Val Loss: 83.84993
Epoch 17, Val Loss: 97.15694
Epoch 18, Val Loss: 88.25452
Epoch 19, Val Loss: 81.62684
Epoch 20, Val Loss: 81.60690
Epoch 21, Val Loss: 85.94402
Epoch 22, Val Loss: 87.91274
Epoch 23, Val Loss: 80.78025
Epoch 24, Val Loss: 90.01205
Epoch 25, Val Loss: 81.26804
Epoch 26, Val Loss: 87.64940
Epoch 27, Val Loss: 86.58244
Epoch 28, Val Loss: 81.85441
Epoch 29, Val Loss: 89.34323
Epoch 30, Val Loss: 83.30447
Epoch 31, Val Loss: 88.19459
Epoch 32, Val Loss: 85.69274
Epoch 33, Val Loss: 85.45821
Epoch 34, Val Loss: 83.24775
Epoch 35, Val Loss: 72.37080
Epoch 36, Val Loss: 88.44785
Epoch 37, Val Loss: 81.00114
Epoch 38, Val Loss: 80.80487
Epoch 39, Val Loss: 77.84759
Epoch 40, Val Loss: 82.56525
Epoch 41, Val Loss: 79.91428
Epoch 42, Val Loss: 79.65707
Epoch 43, Val Loss: 89.89281
Epoch 44, Val Loss: 82.22803
Epoch 45, Val Loss: 74.73820
Epoch 46, Val Loss: 77.13724
Epoch 47, Val Loss: 92.25541
Epoch 48, Val Loss: 78.05597
Epoch 49, Val Loss: 77.22848
Epoch 50, Val Loss: 76.42218
Epoch 51, Val Loss: 85.24499
Epoch 52, Val Loss: 83.73826
Epoch 53, Val Loss: 104.66771
Epoch 54, Val Loss: 86.49401
Epoch 55, Val Loss: 78.97092
Epoch 56, Val Loss: 80.67734
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.50928204531694, 'MSE - std': 3.6303201395687097, 'R2 - mean': 0.479083848752812, 'R2 - std': 0.0014700355871981041} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 566.75330
Epoch 1, Val Loss: 349.98001
Epoch 2, Val Loss: 150.68109
Epoch 3, Val Loss: 122.71071
Epoch 4, Val Loss: 106.41295
Epoch 5, Val Loss: 106.45187
Epoch 6, Val Loss: 98.11238
Epoch 7, Val Loss: 97.70574
Epoch 8, Val Loss: 93.31276
Epoch 9, Val Loss: 89.60651
Epoch 10, Val Loss: 86.60014
Epoch 11, Val Loss: 85.49828
Epoch 12, Val Loss: 88.57790
Epoch 13, Val Loss: 82.41195
Epoch 14, Val Loss: 92.65849
Epoch 15, Val Loss: 84.82741
Epoch 16, Val Loss: 87.39238
Epoch 17, Val Loss: 92.66659
Epoch 18, Val Loss: 84.22087
Epoch 19, Val Loss: 86.91113
Epoch 20, Val Loss: 85.01059
Epoch 21, Val Loss: 88.79673
Epoch 22, Val Loss: 82.69080
Epoch 23, Val Loss: 86.72972
Epoch 24, Val Loss: 91.48109
Epoch 25, Val Loss: 90.98348
Epoch 26, Val Loss: 83.00043
Epoch 27, Val Loss: 83.33419
Epoch 28, Val Loss: 89.00179
Epoch 29, Val Loss: 80.43944
Epoch 30, Val Loss: 84.58669
Epoch 31, Val Loss: 86.91270
Epoch 32, Val Loss: 83.27048
Epoch 33, Val Loss: 88.03470
Epoch 34, Val Loss: 102.78680
Epoch 35, Val Loss: 83.25697
Epoch 36, Val Loss: 86.23743
Epoch 37, Val Loss: 80.23585
Epoch 38, Val Loss: 83.40942
Epoch 39, Val Loss: 85.46554
Epoch 40, Val Loss: 94.93713
Epoch 41, Val Loss: 83.93751
Epoch 42, Val Loss: 78.57253
Epoch 43, Val Loss: 96.55952
Epoch 44, Val Loss: 83.12119
Epoch 45, Val Loss: 85.81760
Epoch 46, Val Loss: 83.07697
Epoch 47, Val Loss: 85.88575
Epoch 48, Val Loss: 81.34830
Epoch 49, Val Loss: 99.41965
Epoch 50, Val Loss: 85.39696
Epoch 51, Val Loss: 79.26708
Epoch 52, Val Loss: 74.89108
Epoch 53, Val Loss: 77.23566
Epoch 54, Val Loss: 79.86071
Epoch 55, Val Loss: 84.48948
Epoch 56, Val Loss: 81.63033
Epoch 57, Val Loss: 85.00608
Epoch 58, Val Loss: 75.41910
Epoch 59, Val Loss: 79.74036
Epoch 60, Val Loss: 85.29597
Epoch 61, Val Loss: 78.56551
Epoch 62, Val Loss: 77.24933
Epoch 63, Val Loss: 76.55994
Epoch 64, Val Loss: 77.21803
Epoch 65, Val Loss: 86.92152
Epoch 66, Val Loss: 76.72248
Epoch 67, Val Loss: 83.68723
Epoch 68, Val Loss: 74.81675
Epoch 69, Val Loss: 81.60714
Epoch 70, Val Loss: 77.53026
Epoch 71, Val Loss: 77.49651
Epoch 72, Val Loss: 72.51149
Epoch 73, Val Loss: 69.38464
Epoch 74, Val Loss: 76.14944
Epoch 75, Val Loss: 77.21474
Epoch 76, Val Loss: 77.27782
Epoch 77, Val Loss: 74.07530
Epoch 78, Val Loss: 73.65860
Epoch 79, Val Loss: 71.50639
Epoch 80, Val Loss: 73.97318
Epoch 81, Val Loss: 77.90217
Epoch 82, Val Loss: 79.09053
Epoch 83, Val Loss: 78.00352
Epoch 84, Val Loss: 78.08074
Epoch 85, Val Loss: 80.59818
Epoch 86, Val Loss: 74.47015
Epoch 87, Val Loss: 85.17056
Epoch 88, Val Loss: 105.10677
Epoch 89, Val Loss: 72.35338
Epoch 90, Val Loss: 77.12296
Epoch 91, Val Loss: 77.50585
Epoch 92, Val Loss: 77.16069
Epoch 93, Val Loss: 80.72951
Epoch 94, Val Loss: 76.03088
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.1420151169254, 'MSE - std': 8.14869671205462, 'R2 - mean': 0.4972239398565839, 'R2 - std': 0.02568202640482339} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 505.08661
Epoch 1, Val Loss: 306.11026
Epoch 2, Val Loss: 157.76813
Epoch 3, Val Loss: 132.97070
Epoch 4, Val Loss: 125.26411
Epoch 5, Val Loss: 118.30097
Epoch 6, Val Loss: 111.97810
Epoch 7, Val Loss: 104.56344
Epoch 8, Val Loss: 107.11166
Epoch 9, Val Loss: 102.41951
Epoch 10, Val Loss: 102.19704
Epoch 11, Val Loss: 100.38712
Epoch 12, Val Loss: 92.49033
Epoch 13, Val Loss: 91.84200
Epoch 14, Val Loss: 104.47154
Epoch 15, Val Loss: 92.65997
Epoch 16, Val Loss: 92.22256
Epoch 17, Val Loss: 88.44546
Epoch 18, Val Loss: 88.50819
Epoch 19, Val Loss: 91.22549
Epoch 20, Val Loss: 86.75140
Epoch 21, Val Loss: 88.23566
Epoch 22, Val Loss: 90.04099
Epoch 23, Val Loss: 88.09438
Epoch 24, Val Loss: 88.23997
Epoch 25, Val Loss: 90.54393
Epoch 26, Val Loss: 90.24369
Epoch 27, Val Loss: 94.33777
Epoch 28, Val Loss: 88.12203
Epoch 29, Val Loss: 88.44781
Epoch 30, Val Loss: 93.62662
Epoch 31, Val Loss: 96.76910
Epoch 32, Val Loss: 90.81221
Epoch 33, Val Loss: 98.10052
Epoch 34, Val Loss: 96.63426
Epoch 35, Val Loss: 89.48232
Epoch 36, Val Loss: 88.36535
Epoch 37, Val Loss: 87.89767
Epoch 38, Val Loss: 92.95216
Epoch 39, Val Loss: 104.52668
Epoch 40, Val Loss: 92.28764
Epoch 41, Val Loss: 82.25798
Epoch 42, Val Loss: 85.03803
Epoch 43, Val Loss: 91.61365
Epoch 44, Val Loss: 90.81139
Epoch 45, Val Loss: 85.05827
Epoch 46, Val Loss: 83.52061
Epoch 47, Val Loss: 88.52998
Epoch 48, Val Loss: 98.98869
Epoch 49, Val Loss: 90.18870
Epoch 50, Val Loss: 87.06817
Epoch 51, Val Loss: 85.92435
Epoch 52, Val Loss: 85.70953
Epoch 53, Val Loss: 87.50827
Epoch 54, Val Loss: 92.21484
Epoch 55, Val Loss: 82.21717
Epoch 56, Val Loss: 80.87618
Epoch 57, Val Loss: 87.23013
Epoch 58, Val Loss: 91.50546
Epoch 59, Val Loss: 82.80695
Epoch 60, Val Loss: 81.70070
Epoch 61, Val Loss: 82.57587
Epoch 62, Val Loss: 81.61048
Epoch 63, Val Loss: 86.87955
Epoch 64, Val Loss: 85.08869
Epoch 65, Val Loss: 86.98617
Epoch 66, Val Loss: 86.61166
Epoch 67, Val Loss: 80.73570
Epoch 68, Val Loss: 91.20171
Epoch 69, Val Loss: 79.88139
Epoch 70, Val Loss: 81.90777
Epoch 71, Val Loss: 91.87653
Epoch 72, Val Loss: 77.18916
Epoch 73, Val Loss: 80.23410
Epoch 74, Val Loss: 89.66779
Epoch 75, Val Loss: 80.12392
Epoch 76, Val Loss: 85.21282
Epoch 77, Val Loss: 78.33749
Epoch 78, Val Loss: 77.52162
Epoch 79, Val Loss: 83.48113
Epoch 80, Val Loss: 79.73397
Epoch 81, Val Loss: 77.89304
Epoch 82, Val Loss: 81.11320
Epoch 83, Val Loss: 81.86949
Epoch 84, Val Loss: 79.86870
Epoch 85, Val Loss: 77.26109
Epoch 86, Val Loss: 82.09113
Epoch 87, Val Loss: 84.51955
Epoch 88, Val Loss: 84.85944
Epoch 89, Val Loss: 77.33482
Epoch 90, Val Loss: 96.27509
Epoch 91, Val Loss: 79.45147
Epoch 92, Val Loss: 89.81544
Epoch 93, Val Loss: 85.39914
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 82.11839881810359, 'MSE - std': 7.843418972720737, 'R2 - mean': 0.49100759567404795, 'R2 - std': 0.024710395892837956} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1042.42480
Epoch 1, Val Loss: 334.91223
Epoch 2, Val Loss: 144.72716
Epoch 3, Val Loss: 127.81016
Epoch 4, Val Loss: 111.03430
Epoch 5, Val Loss: 110.22921
Epoch 6, Val Loss: 107.92992
Epoch 7, Val Loss: 96.93261
Epoch 8, Val Loss: 99.65996
Epoch 9, Val Loss: 99.66085
Epoch 10, Val Loss: 92.25994
Epoch 11, Val Loss: 96.81390
Epoch 12, Val Loss: 101.05190
Epoch 13, Val Loss: 94.98648
Epoch 14, Val Loss: 93.79214
Epoch 15, Val Loss: 99.20947
Epoch 16, Val Loss: 91.33130
Epoch 17, Val Loss: 88.97548
Epoch 18, Val Loss: 93.19894
Epoch 19, Val Loss: 95.89439
Epoch 20, Val Loss: 90.83388
Epoch 21, Val Loss: 87.24745
Epoch 22, Val Loss: 91.72858
Epoch 23, Val Loss: 101.57823
Epoch 24, Val Loss: 92.79685
Epoch 25, Val Loss: 95.04622
Epoch 26, Val Loss: 89.96161
Epoch 27, Val Loss: 89.11312
Epoch 28, Val Loss: 85.59399
Epoch 29, Val Loss: 89.32766
Epoch 30, Val Loss: 85.99470
Epoch 31, Val Loss: 100.24033
Epoch 32, Val Loss: 94.50785
Epoch 33, Val Loss: 86.29967
Epoch 34, Val Loss: 90.62560
Epoch 35, Val Loss: 83.93513
Epoch 36, Val Loss: 80.78613
Epoch 37, Val Loss: 85.18549
Epoch 38, Val Loss: 86.66577
Epoch 39, Val Loss: 95.58840
Epoch 40, Val Loss: 84.67406
Epoch 41, Val Loss: 86.51789
Epoch 42, Val Loss: 89.94944
Epoch 43, Val Loss: 88.27312
Epoch 44, Val Loss: 90.01942
Epoch 45, Val Loss: 89.20461
Epoch 46, Val Loss: 89.33993
Epoch 47, Val Loss: 88.79477
Epoch 48, Val Loss: 82.61336
Epoch 49, Val Loss: 87.57368
Epoch 50, Val Loss: 84.63111
Epoch 51, Val Loss: 81.82983
Epoch 52, Val Loss: 85.59705
Epoch 53, Val Loss: 86.65356
Epoch 54, Val Loss: 78.28093
Epoch 55, Val Loss: 83.83755
Epoch 56, Val Loss: 84.16811
Epoch 57, Val Loss: 78.08998
Epoch 58, Val Loss: 92.31658
Epoch 59, Val Loss: 76.82926
Epoch 60, Val Loss: 82.14526
Epoch 61, Val Loss: 91.57502
Epoch 62, Val Loss: 84.05327
Epoch 63, Val Loss: 85.07642
Epoch 64, Val Loss: 78.86522
Epoch 65, Val Loss: 78.06892
Epoch 66, Val Loss: 78.01617
Epoch 67, Val Loss: 87.35586
Epoch 68, Val Loss: 89.17739
Epoch 69, Val Loss: 78.78074
Epoch 70, Val Loss: 77.36123
Epoch 71, Val Loss: 79.87786
Epoch 72, Val Loss: 78.00432
Epoch 73, Val Loss: 78.46404
Epoch 74, Val Loss: 81.78650
Epoch 75, Val Loss: 80.33452
Epoch 76, Val Loss: 78.02431
Epoch 77, Val Loss: 79.72711
Epoch 78, Val Loss: 76.68921
Epoch 79, Val Loss: 81.89544
Epoch 80, Val Loss: 82.37891
Epoch 81, Val Loss: 78.16904
Epoch 82, Val Loss: 83.57440
Epoch 83, Val Loss: 78.64571
Epoch 84, Val Loss: 74.91657
Epoch 85, Val Loss: 80.67680
Epoch 86, Val Loss: 84.26518
Epoch 87, Val Loss: 97.50705
Epoch 88, Val Loss: 72.42883
Epoch 89, Val Loss: 77.18385
Epoch 90, Val Loss: 75.54518
Epoch 91, Val Loss: 75.79208
Epoch 92, Val Loss: 76.74718
Epoch 93, Val Loss: 85.07748
Epoch 94, Val Loss: 78.58976
Epoch 95, Val Loss: 78.87517
Epoch 96, Val Loss: 76.67986
Epoch 97, Val Loss: 81.66533
Epoch 98, Val Loss: 74.68474
Epoch 99, Val Loss: 81.40992
DID NOT SAVE RESULTS
{'MSE - mean': 80.43901490625002, 'MSE - std': 7.777962344912633, 'R2 - mean': 0.50033692652459, 'R2 - std': 0.028924532643072036} 
 

Results After CV: {'MSE - mean': 80.43901490625002, 'MSE - std': 7.777962344912633, 'R2 - mean': 0.50033692652459, 'R2 - std': 0.028924532643072036}
Train time: 1023.4616058338027
Inference time: 0.182962317194324
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 77 finished with value: 80.43901490625002 and parameters: {'p_m': 0.18239600832712277, 'alpha': 8.189287056965867, 'K': 5, 'beta': 4.2146629465315915}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 637.82556
Epoch 1, Val Loss: 368.38272
Epoch 2, Val Loss: 222.37930
Epoch 3, Val Loss: 151.73016
Epoch 4, Val Loss: 124.41344
Epoch 5, Val Loss: 131.66464
Epoch 6, Val Loss: 113.46268
Epoch 7, Val Loss: 108.58658
Epoch 8, Val Loss: 111.72888
Epoch 9, Val Loss: 111.06389
Epoch 10, Val Loss: 101.49732
Epoch 11, Val Loss: 100.43324
Epoch 12, Val Loss: 99.93433
Epoch 13, Val Loss: 100.28854
Epoch 14, Val Loss: 99.51401
Epoch 15, Val Loss: 105.91678
Epoch 16, Val Loss: 114.81631
Epoch 17, Val Loss: 98.50488
Epoch 18, Val Loss: 99.85950
Epoch 19, Val Loss: 100.99275
Epoch 20, Val Loss: 106.88430
Epoch 21, Val Loss: 101.46168
Epoch 22, Val Loss: 110.21730
Epoch 23, Val Loss: 104.73415
Epoch 24, Val Loss: 99.94876
Epoch 25, Val Loss: 94.77856
Epoch 26, Val Loss: 98.62440
Epoch 27, Val Loss: 95.35491
Epoch 28, Val Loss: 103.20284
Epoch 29, Val Loss: 107.12289
Epoch 30, Val Loss: 99.18892
Epoch 31, Val Loss: 105.95377
Epoch 32, Val Loss: 116.32217
Epoch 33, Val Loss: 103.98187
Epoch 34, Val Loss: 96.74135
Epoch 35, Val Loss: 102.37032
Epoch 36, Val Loss: 95.33255
Epoch 37, Val Loss: 102.20183
Epoch 38, Val Loss: 103.91389
Epoch 39, Val Loss: 100.00783
Epoch 40, Val Loss: 102.52383
Epoch 41, Val Loss: 101.98625
Epoch 42, Val Loss: 101.67755
Epoch 43, Val Loss: 108.99721
Epoch 44, Val Loss: 108.33330
Epoch 45, Val Loss: 99.01863
Epoch 46, Val Loss: 102.47614
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 102.14052494416045, 'MSE - std': 0.0, 'R2 - mean': 0.40479318245473817, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 839.32855
Epoch 1, Val Loss: 352.91699
Epoch 2, Val Loss: 178.45680
Epoch 3, Val Loss: 131.99944
Epoch 4, Val Loss: 109.16956
Epoch 5, Val Loss: 101.52531
Epoch 6, Val Loss: 102.47079
Epoch 7, Val Loss: 89.16154
Epoch 8, Val Loss: 92.66262
Epoch 9, Val Loss: 79.69726
Epoch 10, Val Loss: 90.83336
Epoch 11, Val Loss: 81.86731
Epoch 12, Val Loss: 77.76948
Epoch 13, Val Loss: 80.49081
Epoch 14, Val Loss: 89.77510
Epoch 15, Val Loss: 80.18021
Epoch 16, Val Loss: 78.79374
Epoch 17, Val Loss: 85.68121
Epoch 18, Val Loss: 98.00675
Epoch 19, Val Loss: 85.82380
Epoch 20, Val Loss: 77.89348
Epoch 21, Val Loss: 84.96387
Epoch 22, Val Loss: 84.52423
Epoch 23, Val Loss: 98.08885
Epoch 24, Val Loss: 81.44259
Epoch 25, Val Loss: 80.53600
Epoch 26, Val Loss: 79.85751
Epoch 27, Val Loss: 89.06727
Epoch 28, Val Loss: 79.20786
Epoch 29, Val Loss: 89.11024
Epoch 30, Val Loss: 86.33231
Epoch 31, Val Loss: 87.42076
Epoch 32, Val Loss: 78.41430
Epoch 33, Val Loss: 78.54418
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 94.01244408716734, 'MSE - std': 8.128080856993108, 'R2 - mean': 0.4284263064785563, 'R2 - std': 0.02363312402381812} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 705.03027
Epoch 1, Val Loss: 413.87891
Epoch 2, Val Loss: 175.47110
Epoch 3, Val Loss: 115.07130
Epoch 4, Val Loss: 112.11369
Epoch 5, Val Loss: 99.57914
Epoch 6, Val Loss: 91.02969
Epoch 7, Val Loss: 87.69600
Epoch 8, Val Loss: 82.53634
Epoch 9, Val Loss: 82.36211
Epoch 10, Val Loss: 79.55627
Epoch 11, Val Loss: 76.11805
Epoch 12, Val Loss: 86.11900
Epoch 13, Val Loss: 81.04994
Epoch 14, Val Loss: 85.60157
Epoch 15, Val Loss: 84.82218
Epoch 16, Val Loss: 78.75883
Epoch 17, Val Loss: 84.58797
Epoch 18, Val Loss: 88.12697
Epoch 19, Val Loss: 81.86716
Epoch 20, Val Loss: 92.05101
Epoch 21, Val Loss: 91.42659
Epoch 22, Val Loss: 86.84415
Epoch 23, Val Loss: 87.43808
Epoch 24, Val Loss: 91.13064
Epoch 25, Val Loss: 90.37643
Epoch 26, Val Loss: 85.41957
Epoch 27, Val Loss: 96.90070
Epoch 28, Val Loss: 83.72335
Epoch 29, Val Loss: 79.85849
Epoch 30, Val Loss: 80.43422
Epoch 31, Val Loss: 104.83449
Epoch 32, Val Loss: 80.64228
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.9590864913978, 'MSE - std': 9.752776267640682, 'R2 - mean': 0.4422921712364955, 'R2 - std': 0.027511345145612768} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 489.52390
Epoch 1, Val Loss: 237.61850
Epoch 2, Val Loss: 163.07898
Epoch 3, Val Loss: 123.50267
Epoch 4, Val Loss: 116.15674
Epoch 5, Val Loss: 117.15110
Epoch 6, Val Loss: 109.93462
Epoch 7, Val Loss: 107.18393
Epoch 8, Val Loss: 109.81123
Epoch 9, Val Loss: 98.84988
Epoch 10, Val Loss: 96.44324
Epoch 11, Val Loss: 97.08449
Epoch 12, Val Loss: 93.90625
Epoch 13, Val Loss: 96.70763
Epoch 14, Val Loss: 95.33384
Epoch 15, Val Loss: 95.09489
Epoch 16, Val Loss: 91.31353
Epoch 17, Val Loss: 86.62611
Epoch 18, Val Loss: 95.81718
Epoch 19, Val Loss: 89.20389
Epoch 20, Val Loss: 92.41647
Epoch 21, Val Loss: 93.23536
Epoch 22, Val Loss: 85.10953
Epoch 23, Val Loss: 91.51276
Epoch 24, Val Loss: 88.70563
Epoch 25, Val Loss: 87.33326
Epoch 26, Val Loss: 85.40845
Epoch 27, Val Loss: 87.06611
Epoch 28, Val Loss: 89.69904
Epoch 29, Val Loss: 92.74735
Epoch 30, Val Loss: 91.75039
Epoch 31, Val Loss: 88.71770
Epoch 32, Val Loss: 99.03349
Epoch 33, Val Loss: 98.07719
Epoch 34, Val Loss: 101.40907
Epoch 35, Val Loss: 87.85844
Epoch 36, Val Loss: 90.79282
Epoch 37, Val Loss: 89.28581
Epoch 38, Val Loss: 84.14182
Epoch 39, Val Loss: 87.02039
Epoch 40, Val Loss: 94.47681
Epoch 41, Val Loss: 90.75206
Epoch 42, Val Loss: 92.62509
Epoch 43, Val Loss: 87.78127
Epoch 44, Val Loss: 84.71561
Epoch 45, Val Loss: 86.74290
Epoch 46, Val Loss: 87.23602
Epoch 47, Val Loss: 101.10921
Epoch 48, Val Loss: 88.21058
Epoch 49, Val Loss: 83.84473
Epoch 50, Val Loss: 88.55166
Epoch 51, Val Loss: 91.24903
Epoch 52, Val Loss: 88.37997
Epoch 53, Val Loss: 100.18536
Epoch 54, Val Loss: 95.93536
Epoch 55, Val Loss: 90.30688
Epoch 56, Val Loss: 85.28123
Epoch 57, Val Loss: 88.05961
Epoch 58, Val Loss: 80.57623
Epoch 59, Val Loss: 81.46407
Epoch 60, Val Loss: 83.53334
Epoch 61, Val Loss: 86.84042
Epoch 62, Val Loss: 83.57388
Epoch 63, Val Loss: 88.47135
Epoch 64, Val Loss: 85.70931
Epoch 65, Val Loss: 81.43109
Epoch 66, Val Loss: 78.26839
Epoch 67, Val Loss: 94.08974
Epoch 68, Val Loss: 103.18124
Epoch 69, Val Loss: 97.57816
Epoch 70, Val Loss: 85.78820
Epoch 71, Val Loss: 82.40478
Epoch 72, Val Loss: 83.53986
Epoch 73, Val Loss: 78.21825
Epoch 74, Val Loss: 83.71324
Epoch 75, Val Loss: 83.97045
Epoch 76, Val Loss: 82.11694
Epoch 77, Val Loss: 85.50606
Epoch 78, Val Loss: 82.66469
Epoch 79, Val Loss: 79.75096
Epoch 80, Val Loss: 81.41638
Epoch 81, Val Loss: 81.43461
Epoch 82, Val Loss: 80.78893
Epoch 83, Val Loss: 84.81113
Epoch 84, Val Loss: 80.26524
Epoch 85, Val Loss: 79.75769
Epoch 86, Val Loss: 78.62822
Epoch 87, Val Loss: 81.32884
Epoch 88, Val Loss: 82.54046
Epoch 89, Val Loss: 83.52210
Epoch 90, Val Loss: 80.05190
Epoch 91, Val Loss: 86.20073
Epoch 92, Val Loss: 81.80495
Epoch 93, Val Loss: 80.61149
Epoch 94, Val Loss: 81.39612
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 89.15530069981196, 'MSE - std': 8.45298667582898, 'R2 - mean': 0.4472672803950452, 'R2 - std': 0.025335957002040197} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 558.08917
Epoch 1, Val Loss: 332.68991
Epoch 2, Val Loss: 184.78752
Epoch 3, Val Loss: 150.84581
Epoch 4, Val Loss: 114.01924
Epoch 5, Val Loss: 100.99095
Epoch 6, Val Loss: 111.56244
Epoch 7, Val Loss: 95.05791
Epoch 8, Val Loss: 98.36460
Epoch 9, Val Loss: 99.75011
Epoch 10, Val Loss: 96.37129
Epoch 11, Val Loss: 84.31954
Epoch 12, Val Loss: 90.32571
Epoch 13, Val Loss: 88.01257
Epoch 14, Val Loss: 82.58398
Epoch 15, Val Loss: 92.38162
Epoch 16, Val Loss: 81.38591
Epoch 17, Val Loss: 88.53770
Epoch 18, Val Loss: 90.75258
Epoch 19, Val Loss: 96.82565
Epoch 20, Val Loss: 84.09224
Epoch 21, Val Loss: 83.57607
Epoch 22, Val Loss: 91.93036
Epoch 23, Val Loss: 85.49910
Epoch 24, Val Loss: 85.87003
Epoch 25, Val Loss: 84.91345
Epoch 26, Val Loss: 89.35840
Epoch 27, Val Loss: 87.61472
Epoch 28, Val Loss: 95.03577
Epoch 29, Val Loss: 98.23563
Epoch 30, Val Loss: 109.63223
Epoch 31, Val Loss: 83.23666
Epoch 32, Val Loss: 85.55997
Epoch 33, Val Loss: 83.21975
Epoch 34, Val Loss: 85.48451
Epoch 35, Val Loss: 97.02441
Epoch 36, Val Loss: 88.86031
Epoch 37, Val Loss: 80.90466
Epoch 38, Val Loss: 93.59912
Epoch 39, Val Loss: 81.35788
Epoch 40, Val Loss: 84.47504
Epoch 41, Val Loss: 86.39375
Epoch 42, Val Loss: 86.42639
Epoch 43, Val Loss: 86.25286
Epoch 44, Val Loss: 85.37808
Epoch 45, Val Loss: 90.75306
Epoch 46, Val Loss: 85.65617
Epoch 47, Val Loss: 82.23215
Epoch 48, Val Loss: 84.71366
Epoch 49, Val Loss: 78.11443
Epoch 50, Val Loss: 84.48225
Epoch 51, Val Loss: 82.91054
Epoch 52, Val Loss: 94.43492
Epoch 53, Val Loss: 81.06806
Epoch 54, Val Loss: 81.93161
Epoch 55, Val Loss: 85.19523
Epoch 56, Val Loss: 88.06089
Epoch 57, Val Loss: 82.73975
Epoch 58, Val Loss: 87.35363
Epoch 59, Val Loss: 93.97791
Epoch 60, Val Loss: 93.65514
Epoch 61, Val Loss: 87.02466
Epoch 62, Val Loss: 82.87170
Epoch 63, Val Loss: 85.64178
Epoch 64, Val Loss: 78.73021
Epoch 65, Val Loss: 73.17999
Epoch 66, Val Loss: 80.48277
Epoch 67, Val Loss: 78.77489
Epoch 68, Val Loss: 78.28059
Epoch 69, Val Loss: 83.00222
Epoch 70, Val Loss: 81.70012
Epoch 71, Val Loss: 78.01915
Epoch 72, Val Loss: 78.26118
Epoch 73, Val Loss: 83.65958
Epoch 74, Val Loss: 105.80587
Epoch 75, Val Loss: 90.63846
Epoch 76, Val Loss: 79.10133
Epoch 77, Val Loss: 85.29930
Epoch 78, Val Loss: 75.64868
Epoch 79, Val Loss: 88.96185
Epoch 80, Val Loss: 75.73428
Epoch 81, Val Loss: 84.50336
Epoch 82, Val Loss: 74.80029
Epoch 83, Val Loss: 80.56552
Epoch 84, Val Loss: 83.66722
Epoch 85, Val Loss: 77.28403
Epoch 86, Val Loss: 77.32359
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.31514917298082, 'MSE - std': 9.456650029203722, 'R2 - mean': 0.46379803737444575, 'R2 - std': 0.040082318782917015} 
 

Results After CV: {'MSE - mean': 86.31514917298082, 'MSE - std': 9.456650029203722, 'R2 - mean': 0.46379803737444575, 'R2 - std': 0.040082318782917015}
Train time: 1258.7751723547874
Inference time: 0.19272214600350707
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 78 finished with value: 86.31514917298082 and parameters: {'p_m': 0.1200613229106498, 'alpha': 8.92674308627214, 'K': 10, 'beta': 6.430569881024528}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 487.46783
Epoch 1, Val Loss: 413.24866
Epoch 2, Val Loss: 192.67822
Epoch 3, Val Loss: 160.42529
Epoch 4, Val Loss: 156.81535
Epoch 5, Val Loss: 144.30728
Epoch 6, Val Loss: 139.44708
Epoch 7, Val Loss: 117.34953
Epoch 8, Val Loss: 117.89597
Epoch 9, Val Loss: 117.51481
Epoch 10, Val Loss: 125.37533
Epoch 11, Val Loss: 103.59428
Epoch 12, Val Loss: 110.40997
Epoch 13, Val Loss: 106.18781
Epoch 14, Val Loss: 103.90138
Epoch 15, Val Loss: 110.82531
Epoch 16, Val Loss: 107.24385
Epoch 17, Val Loss: 93.56443
Epoch 18, Val Loss: 109.63058
Epoch 19, Val Loss: 112.25027
Epoch 20, Val Loss: 95.75655
Epoch 21, Val Loss: 96.62819
Epoch 22, Val Loss: 96.95356
Epoch 23, Val Loss: 96.33988
Epoch 24, Val Loss: 93.13065
Epoch 25, Val Loss: 96.10470
Epoch 26, Val Loss: 90.52608
Epoch 27, Val Loss: 92.29128
Epoch 28, Val Loss: 102.26425
Epoch 29, Val Loss: 94.64545
Epoch 30, Val Loss: 96.51746
Epoch 31, Val Loss: 98.87286
Epoch 32, Val Loss: 86.65175
Epoch 33, Val Loss: 96.67058
Epoch 34, Val Loss: 89.51243
Epoch 35, Val Loss: 89.99575
Epoch 36, Val Loss: 89.76675
Epoch 37, Val Loss: 95.05512
Epoch 38, Val Loss: 91.02562
Epoch 39, Val Loss: 89.71182
Epoch 40, Val Loss: 88.84417
Epoch 41, Val Loss: 85.95998
Epoch 42, Val Loss: 92.30581
Epoch 43, Val Loss: 87.27116
Epoch 44, Val Loss: 84.79711
Epoch 45, Val Loss: 88.33164
Epoch 46, Val Loss: 105.28673
Epoch 47, Val Loss: 93.60558
Epoch 48, Val Loss: 84.99390
Epoch 49, Val Loss: 86.86259
Epoch 50, Val Loss: 87.20013
Epoch 51, Val Loss: 100.44547
Epoch 52, Val Loss: 86.98682
Epoch 53, Val Loss: 89.00864
Epoch 54, Val Loss: 84.65381
Epoch 55, Val Loss: 94.23058
Epoch 56, Val Loss: 86.13108
Epoch 57, Val Loss: 86.77031
Epoch 58, Val Loss: 88.20669
Epoch 59, Val Loss: 92.49537
Epoch 60, Val Loss: 86.92305
Epoch 61, Val Loss: 89.95638
Epoch 62, Val Loss: 91.35563
Epoch 63, Val Loss: 93.62920
Epoch 64, Val Loss: 88.75716
Epoch 65, Val Loss: 83.74982
Epoch 66, Val Loss: 98.26475
Epoch 67, Val Loss: 86.36455
Epoch 68, Val Loss: 90.23306
Epoch 69, Val Loss: 91.00075
Epoch 70, Val Loss: 89.87576
Epoch 71, Val Loss: 83.39854
Epoch 72, Val Loss: 95.48402
Epoch 73, Val Loss: 88.11028
Epoch 74, Val Loss: 85.93278
Epoch 75, Val Loss: 85.51634
Epoch 76, Val Loss: 85.40001
Epoch 77, Val Loss: 84.39539
Epoch 78, Val Loss: 87.34167
Epoch 79, Val Loss: 89.60883
Epoch 80, Val Loss: 91.80536
Epoch 81, Val Loss: 88.45909
Epoch 82, Val Loss: 85.55382
Epoch 83, Val Loss: 89.18932
Epoch 84, Val Loss: 86.93492
Epoch 85, Val Loss: 85.77329
Epoch 86, Val Loss: 91.92461
Epoch 87, Val Loss: 89.43263
Epoch 88, Val Loss: 92.63573
Epoch 89, Val Loss: 89.04076
Epoch 90, Val Loss: 94.79778
Epoch 91, Val Loss: 86.76990
Epoch 92, Val Loss: 86.41194
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.76293488604608, 'MSE - std': 0.0, 'R2 - mean': 0.48857618266096436, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 741.76813
Epoch 1, Val Loss: 403.98657
Epoch 2, Val Loss: 187.84268
Epoch 3, Val Loss: 155.91809
Epoch 4, Val Loss: 142.87787
Epoch 5, Val Loss: 148.24280
Epoch 6, Val Loss: 134.84882
Epoch 7, Val Loss: 129.35898
Epoch 8, Val Loss: 152.69946
Epoch 9, Val Loss: 103.09669
Epoch 10, Val Loss: 101.85712
Epoch 11, Val Loss: 108.90785
Epoch 12, Val Loss: 89.54112
Epoch 13, Val Loss: 95.02818
Epoch 14, Val Loss: 92.85918
Epoch 15, Val Loss: 91.25790
Epoch 16, Val Loss: 85.72951
Epoch 17, Val Loss: 82.59267
Epoch 18, Val Loss: 85.73384
Epoch 19, Val Loss: 84.83662
Epoch 20, Val Loss: 91.73260
Epoch 21, Val Loss: 120.66222
Epoch 22, Val Loss: 83.10155
Epoch 23, Val Loss: 85.04312
Epoch 24, Val Loss: 94.56490
Epoch 25, Val Loss: 83.39131
Epoch 26, Val Loss: 83.79973
Epoch 27, Val Loss: 77.01671
Epoch 28, Val Loss: 85.38284
Epoch 29, Val Loss: 81.19994
Epoch 30, Val Loss: 81.44830
Epoch 31, Val Loss: 88.44601
Epoch 32, Val Loss: 78.37970
Epoch 33, Val Loss: 76.44949
Epoch 34, Val Loss: 79.13322
Epoch 35, Val Loss: 76.52898
Epoch 36, Val Loss: 74.60799
Epoch 37, Val Loss: 74.62334
Epoch 38, Val Loss: 80.62321
Epoch 39, Val Loss: 80.14753
Epoch 40, Val Loss: 75.70614
Epoch 41, Val Loss: 71.24837
Epoch 42, Val Loss: 76.80293
Epoch 43, Val Loss: 79.99091
Epoch 44, Val Loss: 80.98564
Epoch 45, Val Loss: 78.05604
Epoch 46, Val Loss: 96.35970
Epoch 47, Val Loss: 83.54839
Epoch 48, Val Loss: 76.67784
Epoch 49, Val Loss: 74.21432
Epoch 50, Val Loss: 76.54700
Epoch 51, Val Loss: 76.22706
Epoch 52, Val Loss: 74.78036
Epoch 53, Val Loss: 75.34042
Epoch 54, Val Loss: 77.43584
Epoch 55, Val Loss: 73.93066
Epoch 56, Val Loss: 73.16804
Epoch 57, Val Loss: 76.08672
Epoch 58, Val Loss: 75.30679
Epoch 59, Val Loss: 73.11274
Epoch 60, Val Loss: 78.48930
Epoch 61, Val Loss: 72.55915
Epoch 62, Val Loss: 76.29354
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.86964292849368, 'MSE - std': 3.8932919575523997, 'R2 - mean': 0.48916430832056623, 'R2 - std': 0.000588125659601868} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 428.25677
Epoch 1, Val Loss: 304.81821
Epoch 2, Val Loss: 194.28076
Epoch 3, Val Loss: 158.98975
Epoch 4, Val Loss: 125.31557
Epoch 5, Val Loss: 127.16531
Epoch 6, Val Loss: 97.82348
Epoch 7, Val Loss: 94.22485
Epoch 8, Val Loss: 88.28541
Epoch 9, Val Loss: 90.91582
Epoch 10, Val Loss: 77.73318
Epoch 11, Val Loss: 93.46539
Epoch 12, Val Loss: 84.32170
Epoch 13, Val Loss: 91.25824
Epoch 14, Val Loss: 98.39277
Epoch 15, Val Loss: 88.07816
Epoch 16, Val Loss: 96.25632
Epoch 17, Val Loss: 94.24571
Epoch 18, Val Loss: 88.12296
Epoch 19, Val Loss: 86.15687
Epoch 20, Val Loss: 92.40015
Epoch 21, Val Loss: 88.17236
Epoch 22, Val Loss: 79.54810
Epoch 23, Val Loss: 77.70939
Epoch 24, Val Loss: 91.27618
Epoch 25, Val Loss: 74.40710
Epoch 26, Val Loss: 78.68427
Epoch 27, Val Loss: 91.88129
Epoch 28, Val Loss: 78.22990
Epoch 29, Val Loss: 84.37195
Epoch 30, Val Loss: 78.40266
Epoch 31, Val Loss: 91.19609
Epoch 32, Val Loss: 76.36067
Epoch 33, Val Loss: 85.39857
Epoch 34, Val Loss: 75.71422
Epoch 35, Val Loss: 71.93690
Epoch 36, Val Loss: 72.73919
Epoch 37, Val Loss: 76.72401
Epoch 38, Val Loss: 77.89175
Epoch 39, Val Loss: 78.44219
Epoch 40, Val Loss: 74.79424
Epoch 41, Val Loss: 77.38095
Epoch 42, Val Loss: 74.01804
Epoch 43, Val Loss: 74.89922
Epoch 44, Val Loss: 77.92458
Epoch 45, Val Loss: 86.93596
Epoch 46, Val Loss: 70.36126
Epoch 47, Val Loss: 84.83508
Epoch 48, Val Loss: 73.61333
Epoch 49, Val Loss: 70.96074
Epoch 50, Val Loss: 70.52132
Epoch 51, Val Loss: 72.66509
Epoch 52, Val Loss: 79.84134
Epoch 53, Val Loss: 76.30418
Epoch 54, Val Loss: 70.22392
Epoch 55, Val Loss: 68.16648
Epoch 56, Val Loss: 71.23682
Epoch 57, Val Loss: 80.93829
Epoch 58, Val Loss: 68.89414
Epoch 59, Val Loss: 77.26695
Epoch 60, Val Loss: 70.90703
Epoch 61, Val Loss: 80.22177
Epoch 62, Val Loss: 69.35950
Epoch 63, Val Loss: 73.29356
Epoch 64, Val Loss: 70.88786
Epoch 65, Val Loss: 69.10924
Epoch 66, Val Loss: 69.91492
Epoch 67, Val Loss: 74.31763
Epoch 68, Val Loss: 77.65625
Epoch 69, Val Loss: 69.47767
Epoch 70, Val Loss: 71.30552
Epoch 71, Val Loss: 69.65099
Epoch 72, Val Loss: 72.21762
Epoch 73, Val Loss: 69.76274
Epoch 74, Val Loss: 101.66725
Epoch 75, Val Loss: 72.24947
Epoch 76, Val Loss: 75.82075
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.85897738380662, 'MSE - std': 7.766510579356484, 'R2 - mean': 0.505220888934025, 'R2 - std': 0.022712511013110233} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 973.66687
Epoch 1, Val Loss: 442.25574
Epoch 2, Val Loss: 164.26846
Epoch 3, Val Loss: 171.48050
Epoch 4, Val Loss: 158.84937
Epoch 5, Val Loss: 130.28197
Epoch 6, Val Loss: 128.73607
Epoch 7, Val Loss: 128.14778
Epoch 8, Val Loss: 107.27470
Epoch 9, Val Loss: 99.36510
Epoch 10, Val Loss: 101.83959
Epoch 11, Val Loss: 99.61648
Epoch 12, Val Loss: 91.89175
Epoch 13, Val Loss: 95.62717
Epoch 14, Val Loss: 93.30019
Epoch 15, Val Loss: 98.17594
Epoch 16, Val Loss: 90.76815
Epoch 17, Val Loss: 108.92513
Epoch 18, Val Loss: 100.88046
Epoch 19, Val Loss: 93.09734
Epoch 20, Val Loss: 103.89619
Epoch 21, Val Loss: 89.61138
Epoch 22, Val Loss: 88.89333
Epoch 23, Val Loss: 88.83534
Epoch 24, Val Loss: 85.54851
Epoch 25, Val Loss: 88.70598
Epoch 26, Val Loss: 103.91874
Epoch 27, Val Loss: 91.43529
Epoch 28, Val Loss: 93.18278
Epoch 29, Val Loss: 87.05445
Epoch 30, Val Loss: 86.11911
Epoch 31, Val Loss: 88.36165
Epoch 32, Val Loss: 83.69432
Epoch 33, Val Loss: 88.87192
Epoch 34, Val Loss: 89.21137
Epoch 35, Val Loss: 86.87887
Epoch 36, Val Loss: 89.37624
Epoch 37, Val Loss: 84.70515
Epoch 38, Val Loss: 85.86777
Epoch 39, Val Loss: 84.72229
Epoch 40, Val Loss: 87.90648
Epoch 41, Val Loss: 87.47765
Epoch 42, Val Loss: 92.84512
Epoch 43, Val Loss: 84.41312
Epoch 44, Val Loss: 84.97005
Epoch 45, Val Loss: 82.86463
Epoch 46, Val Loss: 84.74207
Epoch 47, Val Loss: 81.27348
Epoch 48, Val Loss: 83.77180
Epoch 49, Val Loss: 87.06258
Epoch 50, Val Loss: 87.78349
Epoch 51, Val Loss: 81.70818
Epoch 52, Val Loss: 81.41038
Epoch 53, Val Loss: 82.76210
Epoch 54, Val Loss: 85.02539
Epoch 55, Val Loss: 83.64231
Epoch 56, Val Loss: 91.06790
Epoch 57, Val Loss: 92.63245
Epoch 58, Val Loss: 79.42965
Epoch 59, Val Loss: 78.68044
Epoch 60, Val Loss: 82.20712
Epoch 61, Val Loss: 87.04790
Epoch 62, Val Loss: 84.52859
Epoch 63, Val Loss: 81.66795
Epoch 64, Val Loss: 84.61289
Epoch 65, Val Loss: 89.76898
Epoch 66, Val Loss: 83.98388
Epoch 67, Val Loss: 83.85222
Epoch 68, Val Loss: 100.42083
Epoch 69, Val Loss: 96.12846
Epoch 70, Val Loss: 80.49712
Epoch 71, Val Loss: 79.96220
Epoch 72, Val Loss: 79.00832
Epoch 73, Val Loss: 82.05655
Epoch 74, Val Loss: 84.09871
Epoch 75, Val Loss: 80.63546
Epoch 76, Val Loss: 84.28748
Epoch 77, Val Loss: 80.92691
Epoch 78, Val Loss: 82.57607
Epoch 79, Val Loss: 84.18797
Epoch 80, Val Loss: 82.51976
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.40679091257971, 'MSE - std': 8.044443813380736, 'R2 - mean': 0.49550311818605114, 'R2 - std': 0.0258881985144007} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1403.42432
Epoch 1, Val Loss: 470.19861
Epoch 2, Val Loss: 163.55870
Epoch 3, Val Loss: 157.99820
Epoch 4, Val Loss: 154.47914
Epoch 5, Val Loss: 123.35593
Epoch 6, Val Loss: 121.08935
Epoch 7, Val Loss: 117.18074
Epoch 8, Val Loss: 103.47115
Epoch 9, Val Loss: 115.59834
Epoch 10, Val Loss: 119.58819
Epoch 11, Val Loss: 111.07331
Epoch 12, Val Loss: 114.76001
Epoch 13, Val Loss: 107.73795
Epoch 14, Val Loss: 105.63929
Epoch 15, Val Loss: 111.68138
Epoch 16, Val Loss: 98.10258
Epoch 17, Val Loss: 106.10207
Epoch 18, Val Loss: 102.71920
Epoch 19, Val Loss: 98.09431
Epoch 20, Val Loss: 86.59351
Epoch 21, Val Loss: 95.03864
Epoch 22, Val Loss: 85.29866
Epoch 23, Val Loss: 92.10948
Epoch 24, Val Loss: 88.53529
Epoch 25, Val Loss: 83.05305
Epoch 26, Val Loss: 93.61507
Epoch 27, Val Loss: 84.67256
Epoch 28, Val Loss: 105.73031
Epoch 29, Val Loss: 105.83987
Epoch 30, Val Loss: 92.75696
Epoch 31, Val Loss: 80.30134
Epoch 32, Val Loss: 82.41565
Epoch 33, Val Loss: 102.78245
Epoch 34, Val Loss: 87.21195
Epoch 35, Val Loss: 83.25156
Epoch 36, Val Loss: 80.62379
Epoch 37, Val Loss: 79.53862
Epoch 38, Val Loss: 84.19189
Epoch 39, Val Loss: 82.94722
Epoch 40, Val Loss: 78.46162
Epoch 41, Val Loss: 80.28410
Epoch 42, Val Loss: 83.75328
Epoch 43, Val Loss: 90.99220
Epoch 44, Val Loss: 77.73847
Epoch 45, Val Loss: 79.43389
Epoch 46, Val Loss: 79.10928
Epoch 47, Val Loss: 77.04057
Epoch 48, Val Loss: 81.50547
Epoch 49, Val Loss: 77.56302
Epoch 50, Val Loss: 81.40973
Epoch 51, Val Loss: 75.97949
Epoch 52, Val Loss: 74.21920
Epoch 53, Val Loss: 81.28040
Epoch 54, Val Loss: 74.61352
Epoch 55, Val Loss: 88.36672
Epoch 56, Val Loss: 85.16771
Epoch 57, Val Loss: 79.01755
Epoch 58, Val Loss: 79.43148
Epoch 59, Val Loss: 92.71521
Epoch 60, Val Loss: 79.38955
Epoch 61, Val Loss: 86.47633
Epoch 62, Val Loss: 80.51093
Epoch 63, Val Loss: 80.17983
Epoch 64, Val Loss: 83.46957
Epoch 65, Val Loss: 78.24023
Epoch 66, Val Loss: 79.60265
Epoch 67, Val Loss: 91.87097
Epoch 68, Val Loss: 78.33114
Epoch 69, Val Loss: 88.10435
Epoch 70, Val Loss: 74.86509
Epoch 71, Val Loss: 77.11781
Epoch 72, Val Loss: 75.43607
Epoch 73, Val Loss: 78.06967
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.14669083488573, 'MSE - std': 7.623770054017189, 'R2 - mean': 0.502196370155518, 'R2 - std': 0.026746168801604117} 
 

Results After CV: {'MSE - mean': 80.14669083488573, 'MSE - std': 7.623770054017189, 'R2 - mean': 0.502196370155518, 'R2 - std': 0.026746168801604117}
Train time: 2491.2141042756034
Inference time: 0.18774099239963107
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 79 finished with value: 80.14669083488573 and parameters: {'p_m': 0.27906908432729105, 'alpha': 8.580248246628077, 'K': 15, 'beta': 8.741824509905467}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1905.60645
Epoch 1, Val Loss: 373.30115
Epoch 2, Val Loss: 190.61571
Epoch 3, Val Loss: 162.17784
Epoch 4, Val Loss: 151.41040
Epoch 5, Val Loss: 135.04980
Epoch 6, Val Loss: 124.46924
Epoch 7, Val Loss: 123.95074
Epoch 8, Val Loss: 110.74390
Epoch 9, Val Loss: 106.26884
Epoch 10, Val Loss: 112.28156
Epoch 11, Val Loss: 101.27345
Epoch 12, Val Loss: 102.73391
Epoch 13, Val Loss: 103.78999
Epoch 14, Val Loss: 103.69365
Epoch 15, Val Loss: 98.80499
Epoch 16, Val Loss: 102.26225
Epoch 17, Val Loss: 105.21307
Epoch 18, Val Loss: 99.30695
Epoch 19, Val Loss: 100.03751
Epoch 20, Val Loss: 98.75259
Epoch 21, Val Loss: 99.13344
Epoch 22, Val Loss: 101.95782
Epoch 23, Val Loss: 100.79685
Epoch 24, Val Loss: 98.66391
Epoch 25, Val Loss: 103.38583
Epoch 26, Val Loss: 109.73891
Epoch 27, Val Loss: 97.96555
Epoch 28, Val Loss: 96.33583
Epoch 29, Val Loss: 94.18364
Epoch 30, Val Loss: 96.95868
Epoch 31, Val Loss: 108.56804
Epoch 32, Val Loss: 95.05575
Epoch 33, Val Loss: 103.13860
Epoch 34, Val Loss: 97.59558
Epoch 35, Val Loss: 97.35435
Epoch 36, Val Loss: 100.59991
Epoch 37, Val Loss: 96.70459
Epoch 38, Val Loss: 103.46124
Epoch 39, Val Loss: 99.47058
Epoch 40, Val Loss: 91.38245
Epoch 41, Val Loss: 94.50682
Epoch 42, Val Loss: 95.51522
Epoch 43, Val Loss: 99.16543
Epoch 44, Val Loss: 101.92635
Epoch 45, Val Loss: 94.99547
Epoch 46, Val Loss: 99.45621
Epoch 47, Val Loss: 101.45073
Epoch 48, Val Loss: 109.82291
Epoch 49, Val Loss: 100.02458
Epoch 50, Val Loss: 108.39862
Epoch 51, Val Loss: 97.45966
Epoch 52, Val Loss: 96.61633
Epoch 53, Val Loss: 99.44237
Epoch 54, Val Loss: 99.51704
Epoch 55, Val Loss: 95.33070
Epoch 56, Val Loss: 111.07413
Epoch 57, Val Loss: 94.79652
Epoch 58, Val Loss: 93.33540
Epoch 59, Val Loss: 104.22848
Epoch 60, Val Loss: 102.73392
Epoch 61, Val Loss: 103.10904
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 94.81265725358651, 'MSE - std': 0.0, 'R2 - mean': 0.4474951052212769, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 2170.04297
Epoch 1, Val Loss: 285.71222
Epoch 2, Val Loss: 144.39519
Epoch 3, Val Loss: 128.45181
Epoch 4, Val Loss: 112.49521
Epoch 5, Val Loss: 104.80916
Epoch 6, Val Loss: 97.90292
Epoch 7, Val Loss: 94.81951
Epoch 8, Val Loss: 92.83495
Epoch 9, Val Loss: 96.87058
Epoch 10, Val Loss: 92.47987
Epoch 11, Val Loss: 95.11159
Epoch 12, Val Loss: 86.14219
Epoch 13, Val Loss: 89.68972
Epoch 14, Val Loss: 87.47868
Epoch 15, Val Loss: 86.29684
Epoch 16, Val Loss: 83.98410
Epoch 17, Val Loss: 86.07077
Epoch 18, Val Loss: 82.41474
Epoch 19, Val Loss: 86.62982
Epoch 20, Val Loss: 84.05742
Epoch 21, Val Loss: 83.77795
Epoch 22, Val Loss: 79.69560
Epoch 23, Val Loss: 80.68398
Epoch 24, Val Loss: 81.93209
Epoch 25, Val Loss: 94.49598
Epoch 26, Val Loss: 80.90384
Epoch 27, Val Loss: 83.30872
Epoch 28, Val Loss: 82.77430
Epoch 29, Val Loss: 86.32121
Epoch 30, Val Loss: 81.04951
Epoch 31, Val Loss: 89.91579
Epoch 32, Val Loss: 79.81678
Epoch 33, Val Loss: 81.38880
Epoch 34, Val Loss: 79.35509
Epoch 35, Val Loss: 86.78170
Epoch 36, Val Loss: 80.02962
Epoch 37, Val Loss: 79.29090
Epoch 38, Val Loss: 83.66467
Epoch 39, Val Loss: 81.01858
Epoch 40, Val Loss: 78.84642
Epoch 41, Val Loss: 81.63146
Epoch 42, Val Loss: 84.49970
Epoch 43, Val Loss: 82.29332
Epoch 44, Val Loss: 85.50478
Epoch 45, Val Loss: 79.57380
Epoch 46, Val Loss: 81.57626
Epoch 47, Val Loss: 76.99512
Epoch 48, Val Loss: 81.17857
Epoch 49, Val Loss: 76.93435
Epoch 50, Val Loss: 79.64475
Epoch 51, Val Loss: 82.97737
Epoch 52, Val Loss: 80.19339
Epoch 53, Val Loss: 84.87531
Epoch 54, Val Loss: 84.81229
Epoch 55, Val Loss: 94.35167
Epoch 56, Val Loss: 76.31580
Epoch 57, Val Loss: 76.70926
Epoch 58, Val Loss: 81.59129
Epoch 59, Val Loss: 77.06723
Epoch 60, Val Loss: 84.46339
Epoch 61, Val Loss: 80.72694
Epoch 62, Val Loss: 81.76984
Epoch 63, Val Loss: 97.08123
Epoch 64, Val Loss: 81.70331
Epoch 65, Val Loss: 74.66122
Epoch 66, Val Loss: 80.26117
Epoch 67, Val Loss: 78.86456
Epoch 68, Val Loss: 78.65326
Epoch 69, Val Loss: 75.26345
Epoch 70, Val Loss: 92.03891
Epoch 71, Val Loss: 81.63992
Epoch 72, Val Loss: 89.74802
Epoch 73, Val Loss: 79.12192
Epoch 74, Val Loss: 73.75919
Epoch 75, Val Loss: 73.57565
Epoch 76, Val Loss: 83.78078
Epoch 77, Val Loss: 75.21263
Epoch 78, Val Loss: 78.50562
Epoch 79, Val Loss: 79.45927
Epoch 80, Val Loss: 79.30179
Epoch 81, Val Loss: 75.60854
Epoch 82, Val Loss: 77.93108
Epoch 83, Val Loss: 81.14397
Epoch 84, Val Loss: 78.78058
Epoch 85, Val Loss: 73.50843
Epoch 86, Val Loss: 79.43703
Epoch 87, Val Loss: 80.08611
Epoch 88, Val Loss: 85.19030
Epoch 89, Val Loss: 75.87969
Epoch 90, Val Loss: 80.81637
Epoch 91, Val Loss: 79.80676
Epoch 92, Val Loss: 72.63041
Epoch 93, Val Loss: 82.19103
Epoch 94, Val Loss: 74.73336
Epoch 95, Val Loss: 74.05977
Epoch 96, Val Loss: 74.35564
Epoch 97, Val Loss: 79.15955
Epoch 98, Val Loss: 75.62157
Epoch 99, Val Loss: 86.49088
DID NOT SAVE RESULTS
{'MSE - mean': 88.04105997354, 'MSE - std': 6.771597280046507, 'R2 - mean': 0.464498755762171, 'R2 - std': 0.01700365054089409} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 2301.57788
Epoch 1, Val Loss: 275.35556
Epoch 2, Val Loss: 147.81076
Epoch 3, Val Loss: 132.47774
Epoch 4, Val Loss: 111.80289
Epoch 5, Val Loss: 101.36401
Epoch 6, Val Loss: 94.12649
Epoch 7, Val Loss: 93.37420
Epoch 8, Val Loss: 88.73528
Epoch 9, Val Loss: 83.62444
Epoch 10, Val Loss: 79.74420
Epoch 11, Val Loss: 79.22350
Epoch 12, Val Loss: 82.55460
Epoch 13, Val Loss: 84.13141
Epoch 14, Val Loss: 80.42666
Epoch 15, Val Loss: 75.95834
Epoch 16, Val Loss: 77.23402
Epoch 17, Val Loss: 80.12901
Epoch 18, Val Loss: 75.60426
Epoch 19, Val Loss: 77.41804
Epoch 20, Val Loss: 73.31886
Epoch 21, Val Loss: 78.99053
Epoch 22, Val Loss: 79.90829
Epoch 23, Val Loss: 79.26882
Epoch 24, Val Loss: 78.39413
Epoch 25, Val Loss: 80.59599
Epoch 26, Val Loss: 77.11456
Epoch 27, Val Loss: 85.18879
Epoch 28, Val Loss: 83.05005
Epoch 29, Val Loss: 95.17636
Epoch 30, Val Loss: 84.86659
Epoch 31, Val Loss: 78.37726
Epoch 32, Val Loss: 82.11181
Epoch 33, Val Loss: 77.63151
Epoch 34, Val Loss: 77.63066
Epoch 35, Val Loss: 76.37357
Epoch 36, Val Loss: 91.77092
Epoch 37, Val Loss: 76.60490
Epoch 38, Val Loss: 95.20767
Epoch 39, Val Loss: 77.46652
Epoch 40, Val Loss: 78.22308
Epoch 41, Val Loss: 82.80525
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.49870864847547, 'MSE - std': 8.47558833372172, 'R2 - mean': 0.4762840631994609, 'R2 - std': 0.02169185017299006} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 822.78479
Epoch 1, Val Loss: 304.73367
Epoch 2, Val Loss: 150.15291
Epoch 3, Val Loss: 132.95580
Epoch 4, Val Loss: 128.94917
Epoch 5, Val Loss: 113.95390
Epoch 6, Val Loss: 113.80885
Epoch 7, Val Loss: 116.04008
Epoch 8, Val Loss: 99.42623
Epoch 9, Val Loss: 98.95251
Epoch 10, Val Loss: 97.26492
Epoch 11, Val Loss: 98.39749
Epoch 12, Val Loss: 95.39931
Epoch 13, Val Loss: 92.57459
Epoch 14, Val Loss: 96.63853
Epoch 15, Val Loss: 98.11114
Epoch 16, Val Loss: 98.78657
Epoch 17, Val Loss: 91.56207
Epoch 18, Val Loss: 99.28346
Epoch 19, Val Loss: 102.05052
Epoch 20, Val Loss: 91.79188
Epoch 21, Val Loss: 96.67229
Epoch 22, Val Loss: 87.11607
Epoch 23, Val Loss: 87.34559
Epoch 24, Val Loss: 96.03568
Epoch 25, Val Loss: 89.81897
Epoch 26, Val Loss: 87.98238
Epoch 27, Val Loss: 95.36604
Epoch 28, Val Loss: 85.06245
Epoch 29, Val Loss: 89.14134
Epoch 30, Val Loss: 90.55493
Epoch 31, Val Loss: 92.28572
Epoch 32, Val Loss: 87.96312
Epoch 33, Val Loss: 92.73831
Epoch 34, Val Loss: 89.32542
Epoch 35, Val Loss: 83.71796
Epoch 36, Val Loss: 86.03922
Epoch 37, Val Loss: 87.47456
Epoch 38, Val Loss: 86.65591
Epoch 39, Val Loss: 90.52482
Epoch 40, Val Loss: 85.22096
Epoch 41, Val Loss: 86.77184
Epoch 42, Val Loss: 89.95564
Epoch 43, Val Loss: 88.75429
Epoch 44, Val Loss: 87.33410
Epoch 45, Val Loss: 85.91457
Epoch 46, Val Loss: 88.78127
Epoch 47, Val Loss: 100.47662
Epoch 48, Val Loss: 86.85344
Epoch 49, Val Loss: 82.79871
Epoch 50, Val Loss: 90.88194
Epoch 51, Val Loss: 86.23190
Epoch 52, Val Loss: 83.72505
Epoch 53, Val Loss: 84.68652
Epoch 54, Val Loss: 85.43645
Epoch 55, Val Loss: 85.36898
Epoch 56, Val Loss: 88.10295
Epoch 57, Val Loss: 83.57032
Epoch 58, Val Loss: 87.51274
Epoch 59, Val Loss: 89.80010
Epoch 60, Val Loss: 90.66843
Epoch 61, Val Loss: 83.00066
Epoch 62, Val Loss: 81.71089
Epoch 63, Val Loss: 82.71115
Epoch 64, Val Loss: 82.76305
Epoch 65, Val Loss: 98.86606
Epoch 66, Val Loss: 83.89681
Epoch 67, Val Loss: 85.03243
Epoch 68, Val Loss: 89.88919
Epoch 69, Val Loss: 88.09914
Epoch 70, Val Loss: 83.60327
Epoch 71, Val Loss: 87.93983
Epoch 72, Val Loss: 96.86127
Epoch 73, Val Loss: 82.12796
Epoch 74, Val Loss: 84.78645
Epoch 75, Val Loss: 89.42466
Epoch 76, Val Loss: 85.67098
Epoch 77, Val Loss: 78.79148
Epoch 78, Val Loss: 80.26511
Epoch 79, Val Loss: 83.33601
Epoch 80, Val Loss: 87.62751
Epoch 81, Val Loss: 84.40474
Epoch 82, Val Loss: 94.10828
Epoch 83, Val Loss: 82.06348
Epoch 84, Val Loss: 84.25678
Epoch 85, Val Loss: 98.03857
Epoch 86, Val Loss: 99.59609
Epoch 87, Val Loss: 78.95239
Epoch 88, Val Loss: 89.30417
Epoch 89, Val Loss: 79.47904
Epoch 90, Val Loss: 82.03226
Epoch 91, Val Loss: 82.16863
Epoch 92, Val Loss: 79.90628
Epoch 93, Val Loss: 84.27805
Epoch 94, Val Loss: 85.67674
Epoch 95, Val Loss: 89.15939
Epoch 96, Val Loss: 84.20704
Epoch 97, Val Loss: 80.75440
Epoch 98, Val Loss: 80.39426
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.31964413552141, 'MSE - std': 7.988999708723833, 'R2 - mean': 0.4712053370250437, 'R2 - std': 0.020743255569213786} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1984.36670
Epoch 1, Val Loss: 290.83582
Epoch 2, Val Loss: 150.30147
Epoch 3, Val Loss: 127.74095
Epoch 4, Val Loss: 110.58031
Epoch 5, Val Loss: 105.89124
Epoch 6, Val Loss: 99.70941
Epoch 7, Val Loss: 92.00639
Epoch 8, Val Loss: 90.91635
Epoch 9, Val Loss: 91.33557
Epoch 10, Val Loss: 85.54668
Epoch 11, Val Loss: 86.52654
Epoch 12, Val Loss: 88.72742
Epoch 13, Val Loss: 90.07307
Epoch 14, Val Loss: 96.80157
Epoch 15, Val Loss: 86.59474
Epoch 16, Val Loss: 86.08291
Epoch 17, Val Loss: 85.51135
Epoch 18, Val Loss: 85.54582
Epoch 19, Val Loss: 84.95085
Epoch 20, Val Loss: 81.28978
Epoch 21, Val Loss: 82.66412
Epoch 22, Val Loss: 87.72007
Epoch 23, Val Loss: 83.13556
Epoch 24, Val Loss: 82.35341
Epoch 25, Val Loss: 85.67519
Epoch 26, Val Loss: 83.16068
Epoch 27, Val Loss: 87.65432
Epoch 28, Val Loss: 86.12093
Epoch 29, Val Loss: 87.15498
Epoch 30, Val Loss: 85.50362
Epoch 31, Val Loss: 88.02441
Epoch 32, Val Loss: 84.36900
Epoch 33, Val Loss: 87.93066
Epoch 34, Val Loss: 80.83409
Epoch 35, Val Loss: 81.93103
Epoch 36, Val Loss: 90.10462
Epoch 37, Val Loss: 88.64859
Epoch 38, Val Loss: 86.19095
Epoch 39, Val Loss: 86.60997
Epoch 40, Val Loss: 107.80598
Epoch 41, Val Loss: 81.06860
Epoch 42, Val Loss: 83.94296
Epoch 43, Val Loss: 87.54727
Epoch 44, Val Loss: 88.27966
Epoch 45, Val Loss: 87.05685
Epoch 46, Val Loss: 82.41792
Epoch 47, Val Loss: 83.11860
Epoch 48, Val Loss: 87.72300
Epoch 49, Val Loss: 87.35612
Epoch 50, Val Loss: 88.96720
Epoch 51, Val Loss: 87.39865
Epoch 52, Val Loss: 87.27785
Epoch 53, Val Loss: 88.02626
Epoch 54, Val Loss: 89.70436
Epoch 55, Val Loss: 81.31088
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 84.35968174952265, 'MSE - std': 7.399013732040325, 'R2 - mean': 0.47596791797025634, 'R2 - std': 0.020855570726465027} 
 

Results After CV: {'MSE - mean': 84.35968174952265, 'MSE - std': 7.399013732040325, 'R2 - mean': 0.47596791797025634, 'R2 - std': 0.020855570726465027}
Train time: 335.5894473977969
Inference time: 0.1967502115992829
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 80 finished with value: 84.35968174952265 and parameters: {'p_m': 0.33884544747968337, 'alpha': 6.793120202231729, 'K': 2, 'beta': 1.3909422929781394}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 663.96655
Epoch 1, Val Loss: 388.05469
Epoch 2, Val Loss: 167.45415
Epoch 3, Val Loss: 146.68475
Epoch 4, Val Loss: 138.85294
Epoch 5, Val Loss: 124.47632
Epoch 6, Val Loss: 123.99422
Epoch 7, Val Loss: 121.11298
Epoch 8, Val Loss: 114.42130
Epoch 9, Val Loss: 118.34641
Epoch 10, Val Loss: 109.66119
Epoch 11, Val Loss: 117.83138
Epoch 12, Val Loss: 117.15321
Epoch 13, Val Loss: 111.95747
Epoch 14, Val Loss: 105.08871
Epoch 15, Val Loss: 106.12829
Epoch 16, Val Loss: 98.21860
Epoch 17, Val Loss: 104.38983
Epoch 18, Val Loss: 103.51944
Epoch 19, Val Loss: 102.04094
Epoch 20, Val Loss: 101.03873
Epoch 21, Val Loss: 102.75938
Epoch 22, Val Loss: 125.26455
Epoch 23, Val Loss: 115.13107
Epoch 24, Val Loss: 98.57342
Epoch 25, Val Loss: 103.83208
Epoch 26, Val Loss: 102.51080
Epoch 27, Val Loss: 99.29099
Epoch 28, Val Loss: 104.99292
Epoch 29, Val Loss: 101.15199
Epoch 30, Val Loss: 98.02030
Epoch 31, Val Loss: 99.18394
Epoch 32, Val Loss: 97.38636
Epoch 33, Val Loss: 101.84457
Epoch 34, Val Loss: 122.88171
Epoch 35, Val Loss: 97.03812
Epoch 36, Val Loss: 95.25346
Epoch 37, Val Loss: 104.87481
Epoch 38, Val Loss: 96.48647
Epoch 39, Val Loss: 92.39966
Epoch 40, Val Loss: 106.24313
Epoch 41, Val Loss: 92.13004
Epoch 42, Val Loss: 92.01691
Epoch 43, Val Loss: 102.34740
Epoch 44, Val Loss: 92.99355
Epoch 45, Val Loss: 97.74817
Epoch 46, Val Loss: 96.79567
Epoch 47, Val Loss: 100.50618
Epoch 48, Val Loss: 94.64843
Epoch 49, Val Loss: 93.73177
Epoch 50, Val Loss: 90.00532
Epoch 51, Val Loss: 90.03432
Epoch 52, Val Loss: 91.98010
Epoch 53, Val Loss: 95.86263
Epoch 54, Val Loss: 89.52448
Epoch 55, Val Loss: 101.64993
Epoch 56, Val Loss: 88.23662
Epoch 57, Val Loss: 90.27399
Epoch 58, Val Loss: 86.26945
Epoch 59, Val Loss: 90.44606
Epoch 60, Val Loss: 89.70896
Epoch 61, Val Loss: 91.56966
Epoch 62, Val Loss: 85.87111
Epoch 63, Val Loss: 92.05322
Epoch 64, Val Loss: 89.72642
Epoch 65, Val Loss: 97.87486
Epoch 66, Val Loss: 86.41037
Epoch 67, Val Loss: 89.19785
Epoch 68, Val Loss: 91.21849
Epoch 69, Val Loss: 88.70547
Epoch 70, Val Loss: 88.22024
Epoch 71, Val Loss: 90.67224
Epoch 72, Val Loss: 85.41028
Epoch 73, Val Loss: 86.33970
Epoch 74, Val Loss: 87.59395
Epoch 75, Val Loss: 87.71349
Epoch 76, Val Loss: 98.08009
Epoch 77, Val Loss: 86.45543
Epoch 78, Val Loss: 89.09575
Epoch 79, Val Loss: 85.08715
Epoch 80, Val Loss: 85.98058
Epoch 81, Val Loss: 90.51959
Epoch 82, Val Loss: 93.18224
Epoch 83, Val Loss: 93.26144
Epoch 84, Val Loss: 88.32980
Epoch 85, Val Loss: 98.43610
Epoch 86, Val Loss: 85.92553
Epoch 87, Val Loss: 84.46436
Epoch 88, Val Loss: 87.28271
Epoch 89, Val Loss: 84.49290
Epoch 90, Val Loss: 83.83028
Epoch 91, Val Loss: 94.23055
Epoch 92, Val Loss: 86.46430
Epoch 93, Val Loss: 103.61893
Epoch 94, Val Loss: 101.92017
Epoch 95, Val Loss: 85.67013
Epoch 96, Val Loss: 86.65749
Epoch 97, Val Loss: 82.53586
Epoch 98, Val Loss: 87.71820
Epoch 99, Val Loss: 98.93929
DID NOT SAVE RESULTS
{'MSE - mean': 85.55778900148674, 'MSE - std': 0.0, 'R2 - mean': 0.501426301307693, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1155.08948
Epoch 1, Val Loss: 365.91083
Epoch 2, Val Loss: 168.02736
Epoch 3, Val Loss: 141.22583
Epoch 4, Val Loss: 127.23476
Epoch 5, Val Loss: 123.83842
Epoch 6, Val Loss: 117.99306
Epoch 7, Val Loss: 108.30835
Epoch 8, Val Loss: 101.25620
Epoch 9, Val Loss: 100.09669
Epoch 10, Val Loss: 95.24628
Epoch 11, Val Loss: 101.19338
Epoch 12, Val Loss: 92.43318
Epoch 13, Val Loss: 107.11073
Epoch 14, Val Loss: 94.96941
Epoch 15, Val Loss: 94.38829
Epoch 16, Val Loss: 89.11327
Epoch 17, Val Loss: 100.51044
Epoch 18, Val Loss: 84.24641
Epoch 19, Val Loss: 99.88164
Epoch 20, Val Loss: 88.81963
Epoch 21, Val Loss: 80.64511
Epoch 22, Val Loss: 86.18572
Epoch 23, Val Loss: 85.92377
Epoch 24, Val Loss: 82.63560
Epoch 25, Val Loss: 83.61427
Epoch 26, Val Loss: 95.42599
Epoch 27, Val Loss: 97.68793
Epoch 28, Val Loss: 89.05460
Epoch 29, Val Loss: 88.33888
Epoch 30, Val Loss: 97.01530
Epoch 31, Val Loss: 89.80156
Epoch 32, Val Loss: 78.96072
Epoch 33, Val Loss: 84.83775
Epoch 34, Val Loss: 80.19550
Epoch 35, Val Loss: 85.13464
Epoch 36, Val Loss: 79.89143
Epoch 37, Val Loss: 81.70278
Epoch 38, Val Loss: 78.95594
Epoch 39, Val Loss: 79.14575
Epoch 40, Val Loss: 79.82539
Epoch 41, Val Loss: 103.92818
Epoch 42, Val Loss: 108.81077
Epoch 43, Val Loss: 81.03157
Epoch 44, Val Loss: 84.39674
Epoch 45, Val Loss: 81.00245
Epoch 46, Val Loss: 75.95586
Epoch 47, Val Loss: 81.60291
Epoch 48, Val Loss: 77.18577
Epoch 49, Val Loss: 75.15252
Epoch 50, Val Loss: 75.21570
Epoch 51, Val Loss: 74.29510
Epoch 52, Val Loss: 75.67190
Epoch 53, Val Loss: 91.01027
Epoch 54, Val Loss: 77.93973
Epoch 55, Val Loss: 70.46616
Epoch 56, Val Loss: 76.04738
Epoch 57, Val Loss: 79.30556
Epoch 58, Val Loss: 74.95295
Epoch 59, Val Loss: 77.68407
Epoch 60, Val Loss: 82.59786
Epoch 61, Val Loss: 74.80631
Epoch 62, Val Loss: 75.05031
Epoch 63, Val Loss: 76.01652
Epoch 64, Val Loss: 87.56878
Epoch 65, Val Loss: 71.53947
Epoch 66, Val Loss: 74.18194
Epoch 67, Val Loss: 71.94003
Epoch 68, Val Loss: 75.58817
Epoch 69, Val Loss: 72.99409
Epoch 70, Val Loss: 76.67665
Epoch 71, Val Loss: 68.47496
Epoch 72, Val Loss: 74.03922
Epoch 73, Val Loss: 70.23959
Epoch 74, Val Loss: 74.55650
Epoch 75, Val Loss: 79.41743
Epoch 76, Val Loss: 78.31979
Epoch 77, Val Loss: 69.76218
Epoch 78, Val Loss: 72.15444
Epoch 79, Val Loss: 67.86116
Epoch 80, Val Loss: 66.33767
Epoch 81, Val Loss: 77.97997
Epoch 82, Val Loss: 67.22997
Epoch 83, Val Loss: 69.00522
Epoch 84, Val Loss: 67.39017
Epoch 85, Val Loss: 83.55311
Epoch 86, Val Loss: 68.43438
Epoch 87, Val Loss: 70.03595
Epoch 88, Val Loss: 69.60956
Epoch 89, Val Loss: 72.44390
Epoch 90, Val Loss: 79.21259
Epoch 91, Val Loss: 70.62201
Epoch 92, Val Loss: 69.86380
Epoch 93, Val Loss: 67.19321
Epoch 94, Val Loss: 80.44968
Epoch 95, Val Loss: 66.97970
Epoch 96, Val Loss: 69.48531
Epoch 97, Val Loss: 78.76846
Epoch 98, Val Loss: 67.62981
Epoch 99, Val Loss: 76.30891
DID NOT SAVE RESULTS
{'MSE - mean': 80.01913204276666, 'MSE - std': 5.5386569587200825, 'R2 - mean': 0.5131211583570003, 'R2 - std': 0.011694857049307339} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 800.13281
Epoch 1, Val Loss: 479.52835
Epoch 2, Val Loss: 174.44885
Epoch 3, Val Loss: 116.99830
Epoch 4, Val Loss: 111.40025
Epoch 5, Val Loss: 93.61953
Epoch 6, Val Loss: 96.28717
Epoch 7, Val Loss: 110.13813
Epoch 8, Val Loss: 96.75197
Epoch 9, Val Loss: 85.42888
Epoch 10, Val Loss: 89.26245
Epoch 11, Val Loss: 80.99207
Epoch 12, Val Loss: 87.00822
Epoch 13, Val Loss: 82.08017
Epoch 14, Val Loss: 81.49274
Epoch 15, Val Loss: 79.95506
Epoch 16, Val Loss: 87.04046
Epoch 17, Val Loss: 99.86610
Epoch 18, Val Loss: 82.45140
Epoch 19, Val Loss: 91.23077
Epoch 20, Val Loss: 73.81964
Epoch 21, Val Loss: 79.39304
Epoch 22, Val Loss: 92.36687
Epoch 23, Val Loss: 75.53123
Epoch 24, Val Loss: 81.55789
Epoch 25, Val Loss: 80.20457
Epoch 26, Val Loss: 78.90384
Epoch 27, Val Loss: 83.40792
Epoch 28, Val Loss: 83.85820
Epoch 29, Val Loss: 77.58525
Epoch 30, Val Loss: 78.54342
Epoch 31, Val Loss: 80.40225
Epoch 32, Val Loss: 90.77322
Epoch 33, Val Loss: 76.43229
Epoch 34, Val Loss: 75.05477
Epoch 35, Val Loss: 90.11739
Epoch 36, Val Loss: 95.78171
Epoch 37, Val Loss: 75.43661
Epoch 38, Val Loss: 76.52010
Epoch 39, Val Loss: 82.43416
Epoch 40, Val Loss: 78.30343
Epoch 41, Val Loss: 82.05972
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.54680126193966, 'MSE - std': 4.9786206048724155, 'R2 - mean': 0.5060371359565411, 'R2 - std': 0.013840033755121597} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 877.70215
Epoch 1, Val Loss: 442.35913
Epoch 2, Val Loss: 158.65916
Epoch 3, Val Loss: 149.10129
Epoch 4, Val Loss: 126.01652
Epoch 5, Val Loss: 137.65123
Epoch 6, Val Loss: 117.23042
Epoch 7, Val Loss: 107.48247
Epoch 8, Val Loss: 106.00031
Epoch 9, Val Loss: 124.68602
Epoch 10, Val Loss: 102.30523
Epoch 11, Val Loss: 97.54806
Epoch 12, Val Loss: 97.56959
Epoch 13, Val Loss: 91.02237
Epoch 14, Val Loss: 95.84898
Epoch 15, Val Loss: 94.71876
Epoch 16, Val Loss: 105.56348
Epoch 17, Val Loss: 101.92288
Epoch 18, Val Loss: 113.70145
Epoch 19, Val Loss: 98.30292
Epoch 20, Val Loss: 103.26986
Epoch 21, Val Loss: 93.24300
Epoch 22, Val Loss: 92.49730
Epoch 23, Val Loss: 99.43747
Epoch 24, Val Loss: 93.32491
Epoch 25, Val Loss: 89.91832
Epoch 26, Val Loss: 98.18484
Epoch 27, Val Loss: 92.91003
Epoch 28, Val Loss: 90.49555
Epoch 29, Val Loss: 97.63202
Epoch 30, Val Loss: 92.07840
Epoch 31, Val Loss: 94.80901
Epoch 32, Val Loss: 95.17406
Epoch 33, Val Loss: 90.33857
Epoch 34, Val Loss: 88.00408
Epoch 35, Val Loss: 93.97544
Epoch 36, Val Loss: 98.76485
Epoch 37, Val Loss: 94.38686
Epoch 38, Val Loss: 127.81206
Epoch 39, Val Loss: 89.22556
Epoch 40, Val Loss: 87.14841
Epoch 41, Val Loss: 88.93951
Epoch 42, Val Loss: 84.08910
Epoch 43, Val Loss: 92.02716
Epoch 44, Val Loss: 87.44073
Epoch 45, Val Loss: 93.04709
Epoch 46, Val Loss: 86.92053
Epoch 47, Val Loss: 91.54593
Epoch 48, Val Loss: 86.19140
Epoch 49, Val Loss: 86.14886
Epoch 50, Val Loss: 83.01810
Epoch 51, Val Loss: 85.38757
Epoch 52, Val Loss: 102.55019
Epoch 53, Val Loss: 82.34929
Epoch 54, Val Loss: 83.65484
Epoch 55, Val Loss: 88.87719
Epoch 56, Val Loss: 86.18994
Epoch 57, Val Loss: 80.10218
Epoch 58, Val Loss: 83.00033
Epoch 59, Val Loss: 78.70049
Epoch 60, Val Loss: 81.39654
Epoch 61, Val Loss: 79.11967
Epoch 62, Val Loss: 85.06635
Epoch 63, Val Loss: 82.44595
Epoch 64, Val Loss: 78.50589
Epoch 65, Val Loss: 81.09347
Epoch 66, Val Loss: 76.24911
Epoch 67, Val Loss: 78.80384
Epoch 68, Val Loss: 83.14520
Epoch 69, Val Loss: 81.60654
Epoch 70, Val Loss: 79.73996
Epoch 71, Val Loss: 77.22605
Epoch 72, Val Loss: 80.00275
Epoch 73, Val Loss: 79.43812
Epoch 74, Val Loss: 77.51225
Epoch 75, Val Loss: 81.99625
Epoch 76, Val Loss: 78.14375
Epoch 77, Val Loss: 81.76248
Epoch 78, Val Loss: 84.28432
Epoch 79, Val Loss: 78.43840
Epoch 80, Val Loss: 79.94907
Epoch 81, Val Loss: 77.07193
Epoch 82, Val Loss: 83.22099
Epoch 83, Val Loss: 76.54926
Epoch 84, Val Loss: 79.68729
Epoch 85, Val Loss: 78.70804
Epoch 86, Val Loss: 77.82647
Epoch 87, Val Loss: 79.62916
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.81929089597719, 'MSE - std': 5.838032610038185, 'R2 - mean': 0.49823292694120913, 'R2 - std': 0.018065905341890412} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1096.86206
Epoch 1, Val Loss: 349.95200
Epoch 2, Val Loss: 152.84555
Epoch 3, Val Loss: 129.99178
Epoch 4, Val Loss: 130.83766
Epoch 5, Val Loss: 127.38980
Epoch 6, Val Loss: 99.47247
Epoch 7, Val Loss: 116.21247
Epoch 8, Val Loss: 97.79504
Epoch 9, Val Loss: 107.30856
Epoch 10, Val Loss: 104.30386
Epoch 11, Val Loss: 100.63921
Epoch 12, Val Loss: 107.38202
Epoch 13, Val Loss: 100.45491
Epoch 14, Val Loss: 109.26547
Epoch 15, Val Loss: 97.47182
Epoch 16, Val Loss: 98.51550
Epoch 17, Val Loss: 91.92692
Epoch 18, Val Loss: 104.45599
Epoch 19, Val Loss: 102.88475
Epoch 20, Val Loss: 102.72261
Epoch 21, Val Loss: 108.18872
Epoch 22, Val Loss: 101.84555
Epoch 23, Val Loss: 98.50971
Epoch 24, Val Loss: 104.76112
Epoch 25, Val Loss: 94.32899
Epoch 26, Val Loss: 93.92338
Epoch 27, Val Loss: 101.16074
Epoch 28, Val Loss: 97.46561
Epoch 29, Val Loss: 92.79164
Epoch 30, Val Loss: 92.30620
Epoch 31, Val Loss: 89.63255
Epoch 32, Val Loss: 84.34499
Epoch 33, Val Loss: 102.95767
Epoch 34, Val Loss: 88.59422
Epoch 35, Val Loss: 93.97385
Epoch 36, Val Loss: 94.55617
Epoch 37, Val Loss: 84.17779
Epoch 38, Val Loss: 87.73198
Epoch 39, Val Loss: 86.30286
Epoch 40, Val Loss: 90.05859
Epoch 41, Val Loss: 82.20962
Epoch 42, Val Loss: 92.54969
Epoch 43, Val Loss: 87.92403
Epoch 44, Val Loss: 86.05421
Epoch 45, Val Loss: 83.23766
Epoch 46, Val Loss: 85.84998
Epoch 47, Val Loss: 85.47687
Epoch 48, Val Loss: 87.68645
Epoch 49, Val Loss: 93.67668
Epoch 50, Val Loss: 82.37917
Epoch 51, Val Loss: 83.40460
Epoch 52, Val Loss: 83.77063
Epoch 53, Val Loss: 82.25366
Epoch 54, Val Loss: 104.26049
Epoch 55, Val Loss: 77.26552
Epoch 56, Val Loss: 78.43422
Epoch 57, Val Loss: 89.35766
Epoch 58, Val Loss: 85.03233
Epoch 59, Val Loss: 83.76115
Epoch 60, Val Loss: 104.99297
Epoch 61, Val Loss: 94.05313
Epoch 62, Val Loss: 82.59676
Epoch 63, Val Loss: 83.51028
Epoch 64, Val Loss: 82.10548
Epoch 65, Val Loss: 76.07191
Epoch 66, Val Loss: 80.79854
Epoch 67, Val Loss: 93.78314
Epoch 68, Val Loss: 78.58549
Epoch 69, Val Loss: 80.37926
Epoch 70, Val Loss: 80.85052
Epoch 71, Val Loss: 80.09954
Epoch 72, Val Loss: 89.35251
Epoch 73, Val Loss: 88.88365
Epoch 74, Val Loss: 81.07952
Epoch 75, Val Loss: 75.26759
Epoch 76, Val Loss: 77.12651
Epoch 77, Val Loss: 79.33331
Epoch 78, Val Loss: 78.85423
Epoch 79, Val Loss: 77.95531
Epoch 80, Val Loss: 75.15651
Epoch 81, Val Loss: 83.13246
Epoch 82, Val Loss: 87.04858
Epoch 83, Val Loss: 78.27224
Epoch 84, Val Loss: 79.81118
Epoch 85, Val Loss: 82.65925
Epoch 86, Val Loss: 75.55532
Epoch 87, Val Loss: 75.73484
Epoch 88, Val Loss: 87.56951
Epoch 89, Val Loss: 77.51741
Epoch 90, Val Loss: 96.56862
Epoch 91, Val Loss: 76.94485
Epoch 92, Val Loss: 78.09760
Epoch 93, Val Loss: 76.95927
Epoch 94, Val Loss: 78.98965
Epoch 95, Val Loss: 72.83083
Epoch 96, Val Loss: 76.49374
Epoch 97, Val Loss: 82.08203
Epoch 98, Val Loss: 82.70065
Epoch 99, Val Loss: 76.32721
DID NOT SAVE RESULTS
{'MSE - mean': 79.19629972427, 'MSE - std': 6.148373864563962, 'R2 - mean': 0.5073929996547628, 'R2 - std': 0.024428042842767318} 
 

Results After CV: {'MSE - mean': 79.19629972427, 'MSE - std': 6.148373864563962, 'R2 - mean': 0.5073929996547628, 'R2 - std': 0.024428042842767318}
Train time: 398.5295402163989
Inference time: 0.20908379881875588
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 81 finished with value: 79.19629972427 and parameters: {'p_m': 0.1513281011232179, 'alpha': 9.43086006599853, 'K': 2, 'beta': 5.918739086413522}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 904.03271
Epoch 1, Val Loss: 397.73901
Epoch 2, Val Loss: 174.34499
Epoch 3, Val Loss: 170.80075
Epoch 4, Val Loss: 162.44652
Epoch 5, Val Loss: 141.87643
Epoch 6, Val Loss: 132.36584
Epoch 7, Val Loss: 142.99438
Epoch 8, Val Loss: 114.00515
Epoch 9, Val Loss: 117.96877
Epoch 10, Val Loss: 120.83584
Epoch 11, Val Loss: 111.39612
Epoch 12, Val Loss: 110.71826
Epoch 13, Val Loss: 97.96425
Epoch 14, Val Loss: 113.46609
Epoch 15, Val Loss: 104.57688
Epoch 16, Val Loss: 105.78848
Epoch 17, Val Loss: 101.14314
Epoch 18, Val Loss: 104.81066
Epoch 19, Val Loss: 112.05878
Epoch 20, Val Loss: 101.84045
Epoch 21, Val Loss: 100.06860
Epoch 22, Val Loss: 97.81070
Epoch 23, Val Loss: 104.90523
Epoch 24, Val Loss: 99.19270
Epoch 25, Val Loss: 108.37479
Epoch 26, Val Loss: 98.10934
Epoch 27, Val Loss: 105.23445
Epoch 28, Val Loss: 112.74257
Epoch 29, Val Loss: 105.37888
Epoch 30, Val Loss: 96.29625
Epoch 31, Val Loss: 92.33553
Epoch 32, Val Loss: 104.90643
Epoch 33, Val Loss: 92.33665
Epoch 34, Val Loss: 99.17681
Epoch 35, Val Loss: 98.22140
Epoch 36, Val Loss: 94.99004
Epoch 37, Val Loss: 92.63554
Epoch 38, Val Loss: 99.48204
Epoch 39, Val Loss: 96.33658
Epoch 40, Val Loss: 109.25954
Epoch 41, Val Loss: 96.79248
Epoch 42, Val Loss: 87.51620
Epoch 43, Val Loss: 91.82729
Epoch 44, Val Loss: 92.31673
Epoch 45, Val Loss: 90.89266
Epoch 46, Val Loss: 104.13408
Epoch 47, Val Loss: 90.25369
Epoch 48, Val Loss: 92.75446
Epoch 49, Val Loss: 91.06622
Epoch 50, Val Loss: 88.19497
Epoch 51, Val Loss: 87.73090
Epoch 52, Val Loss: 92.97353
Epoch 53, Val Loss: 89.63103
Epoch 54, Val Loss: 91.20757
Epoch 55, Val Loss: 90.71673
Epoch 56, Val Loss: 101.90576
Epoch 57, Val Loss: 85.41914
Epoch 58, Val Loss: 89.37951
Epoch 59, Val Loss: 90.51371
Epoch 60, Val Loss: 86.00834
Epoch 61, Val Loss: 87.41644
Epoch 62, Val Loss: 88.31390
Epoch 63, Val Loss: 87.05022
Epoch 64, Val Loss: 88.02843
Epoch 65, Val Loss: 83.76283
Epoch 66, Val Loss: 87.00439
Epoch 67, Val Loss: 87.07686
Epoch 68, Val Loss: 88.88635
Epoch 69, Val Loss: 89.12221
Epoch 70, Val Loss: 83.77500
Epoch 71, Val Loss: 84.51340
Epoch 72, Val Loss: 93.29202
Epoch 73, Val Loss: 83.41901
Epoch 74, Val Loss: 83.74110
Epoch 75, Val Loss: 87.82683
Epoch 76, Val Loss: 84.74590
Epoch 77, Val Loss: 93.30901
Epoch 78, Val Loss: 85.04464
Epoch 79, Val Loss: 83.96791
Epoch 80, Val Loss: 96.51440
Epoch 81, Val Loss: 88.56367
Epoch 82, Val Loss: 89.14062
Epoch 83, Val Loss: 85.43562
Epoch 84, Val Loss: 99.50524
Epoch 85, Val Loss: 85.83685
Epoch 86, Val Loss: 89.00530
Epoch 87, Val Loss: 91.15840
Epoch 88, Val Loss: 84.92476
Epoch 89, Val Loss: 89.45651
Epoch 90, Val Loss: 87.22237
Epoch 91, Val Loss: 84.70428
Epoch 92, Val Loss: 96.20340
Epoch 93, Val Loss: 86.86942
Epoch 94, Val Loss: 89.28462
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 87.1526772184726, 'MSE - std': 0.0, 'R2 - mean': 0.49213235710198644, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1061.75098
Epoch 1, Val Loss: 416.74933
Epoch 2, Val Loss: 155.02992
Epoch 3, Val Loss: 160.86728
Epoch 4, Val Loss: 160.64253
Epoch 5, Val Loss: 127.60359
Epoch 6, Val Loss: 115.14837
Epoch 7, Val Loss: 110.38754
Epoch 8, Val Loss: 120.44539
Epoch 9, Val Loss: 120.09615
Epoch 10, Val Loss: 109.81640
Epoch 11, Val Loss: 119.31790
Epoch 12, Val Loss: 102.33008
Epoch 13, Val Loss: 99.70546
Epoch 14, Val Loss: 102.62394
Epoch 15, Val Loss: 104.61298
Epoch 16, Val Loss: 97.96748
Epoch 17, Val Loss: 96.14395
Epoch 18, Val Loss: 99.92383
Epoch 19, Val Loss: 92.41799
Epoch 20, Val Loss: 95.13535
Epoch 21, Val Loss: 89.89199
Epoch 22, Val Loss: 94.17437
Epoch 23, Val Loss: 87.35219
Epoch 24, Val Loss: 111.21141
Epoch 25, Val Loss: 97.23772
Epoch 26, Val Loss: 88.14333
Epoch 27, Val Loss: 89.29470
Epoch 28, Val Loss: 93.95024
Epoch 29, Val Loss: 85.70158
Epoch 30, Val Loss: 82.81517
Epoch 31, Val Loss: 81.81107
Epoch 32, Val Loss: 86.24581
Epoch 33, Val Loss: 86.33694
Epoch 34, Val Loss: 85.68445
Epoch 35, Val Loss: 75.24117
Epoch 36, Val Loss: 81.81111
Epoch 37, Val Loss: 80.91612
Epoch 38, Val Loss: 78.44364
Epoch 39, Val Loss: 78.13825
Epoch 40, Val Loss: 86.87540
Epoch 41, Val Loss: 76.76252
Epoch 42, Val Loss: 79.19251
Epoch 43, Val Loss: 76.76641
Epoch 44, Val Loss: 82.96861
Epoch 45, Val Loss: 85.98688
Epoch 46, Val Loss: 78.25652
Epoch 47, Val Loss: 73.48766
Epoch 48, Val Loss: 86.66436
Epoch 49, Val Loss: 80.03436
Epoch 50, Val Loss: 77.79868
Epoch 51, Val Loss: 75.62503
Epoch 52, Val Loss: 75.22887
Epoch 53, Val Loss: 107.96657
Epoch 54, Val Loss: 79.69694
Epoch 55, Val Loss: 74.05559
Epoch 56, Val Loss: 74.17638
Epoch 57, Val Loss: 86.16005
Epoch 58, Val Loss: 84.71050
Epoch 59, Val Loss: 73.06856
Epoch 60, Val Loss: 75.69868
Epoch 61, Val Loss: 77.77001
Epoch 62, Val Loss: 71.21348
Epoch 63, Val Loss: 80.28599
Epoch 64, Val Loss: 75.54333
Epoch 65, Val Loss: 79.10054
Epoch 66, Val Loss: 80.89841
Epoch 67, Val Loss: 74.15241
Epoch 68, Val Loss: 71.62650
Epoch 69, Val Loss: 77.13551
Epoch 70, Val Loss: 77.77234
Epoch 71, Val Loss: 74.52831
Epoch 72, Val Loss: 74.37939
Epoch 73, Val Loss: 73.37032
Epoch 74, Val Loss: 75.22816
Epoch 75, Val Loss: 73.19933
Epoch 76, Val Loss: 73.59952
Epoch 77, Val Loss: 73.72102
Epoch 78, Val Loss: 70.28015
Epoch 79, Val Loss: 71.64099
Epoch 80, Val Loss: 76.64453
Epoch 81, Val Loss: 74.34251
Epoch 82, Val Loss: 74.73319
Epoch 83, Val Loss: 69.61772
Epoch 84, Val Loss: 76.62618
Epoch 85, Val Loss: 72.41565
Epoch 86, Val Loss: 71.88026
Epoch 87, Val Loss: 70.06358
Epoch 88, Val Loss: 70.09565
Epoch 89, Val Loss: 79.12479
Epoch 90, Val Loss: 69.13493
Epoch 91, Val Loss: 69.26051
Epoch 92, Val Loss: 75.02073
Epoch 93, Val Loss: 73.24649
Epoch 94, Val Loss: 68.56750
Epoch 95, Val Loss: 69.79428
Epoch 96, Val Loss: 70.35310
Epoch 97, Val Loss: 69.45448
Epoch 98, Val Loss: 73.38432
Epoch 99, Val Loss: 82.69378
DID NOT SAVE RESULTS
{'MSE - mean': 81.24272286327314, 'MSE - std': 5.909954355199467, 'R2 - mean': 0.5057553785074511, 'R2 - std': 0.013623021405464675} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1148.05078
Epoch 1, Val Loss: 514.60828
Epoch 2, Val Loss: 160.36847
Epoch 3, Val Loss: 135.13855
Epoch 4, Val Loss: 146.38486
Epoch 5, Val Loss: 128.87000
Epoch 6, Val Loss: 123.33281
Epoch 7, Val Loss: 116.22446
Epoch 8, Val Loss: 112.55782
Epoch 9, Val Loss: 92.65646
Epoch 10, Val Loss: 112.34121
Epoch 11, Val Loss: 95.00949
Epoch 12, Val Loss: 91.37930
Epoch 13, Val Loss: 93.30811
Epoch 14, Val Loss: 88.91991
Epoch 15, Val Loss: 80.92680
Epoch 16, Val Loss: 78.31555
Epoch 17, Val Loss: 80.09212
Epoch 18, Val Loss: 85.38664
Epoch 19, Val Loss: 107.02085
Epoch 20, Val Loss: 86.29665
Epoch 21, Val Loss: 84.41779
Epoch 22, Val Loss: 84.45267
Epoch 23, Val Loss: 82.73772
Epoch 24, Val Loss: 101.12981
Epoch 25, Val Loss: 87.67815
Epoch 26, Val Loss: 78.86652
Epoch 27, Val Loss: 81.77623
Epoch 28, Val Loss: 86.52441
Epoch 29, Val Loss: 92.65442
Epoch 30, Val Loss: 84.05807
Epoch 31, Val Loss: 83.60903
Epoch 32, Val Loss: 80.46848
Epoch 33, Val Loss: 82.45179
Epoch 34, Val Loss: 109.57100
Epoch 35, Val Loss: 94.19601
Epoch 36, Val Loss: 74.05965
Epoch 37, Val Loss: 76.11610
Epoch 38, Val Loss: 78.85866
Epoch 39, Val Loss: 75.47922
Epoch 40, Val Loss: 85.72566
Epoch 41, Val Loss: 90.58398
Epoch 42, Val Loss: 71.21962
Epoch 43, Val Loss: 71.36103
Epoch 44, Val Loss: 68.73950
Epoch 45, Val Loss: 74.85140
Epoch 46, Val Loss: 70.74179
Epoch 47, Val Loss: 86.42084
Epoch 48, Val Loss: 81.06260
Epoch 49, Val Loss: 71.43619
Epoch 50, Val Loss: 82.57727
Epoch 51, Val Loss: 75.60761
Epoch 52, Val Loss: 76.59972
Epoch 53, Val Loss: 68.81869
Epoch 54, Val Loss: 70.48342
Epoch 55, Val Loss: 72.53690
Epoch 56, Val Loss: 73.76808
Epoch 57, Val Loss: 71.24118
Epoch 58, Val Loss: 71.99356
Epoch 59, Val Loss: 87.61262
Epoch 60, Val Loss: 68.55505
Epoch 61, Val Loss: 73.64991
Epoch 62, Val Loss: 75.93609
Epoch 63, Val Loss: 76.71513
Epoch 64, Val Loss: 72.86790
Epoch 65, Val Loss: 77.76665
Epoch 66, Val Loss: 74.56915
Epoch 67, Val Loss: 70.37109
Epoch 68, Val Loss: 72.36531
Epoch 69, Val Loss: 79.25667
Epoch 70, Val Loss: 76.27579
Epoch 71, Val Loss: 69.83928
Epoch 72, Val Loss: 66.81004
Epoch 73, Val Loss: 70.61792
Epoch 74, Val Loss: 68.58557
Epoch 75, Val Loss: 79.49467
Epoch 76, Val Loss: 67.40665
Epoch 77, Val Loss: 69.63223
Epoch 78, Val Loss: 76.32713
Epoch 79, Val Loss: 67.09827
Epoch 80, Val Loss: 73.26428
Epoch 81, Val Loss: 69.69978
Epoch 82, Val Loss: 71.06087
Epoch 83, Val Loss: 76.16048
Epoch 84, Val Loss: 68.86997
Epoch 85, Val Loss: 79.84129
Epoch 86, Val Loss: 70.10860
Epoch 87, Val Loss: 68.07249
Epoch 88, Val Loss: 67.67548
Epoch 89, Val Loss: 73.03296
Epoch 90, Val Loss: 75.12535
Epoch 91, Val Loss: 78.76900
Epoch 92, Val Loss: 74.43431
Epoch 93, Val Loss: 68.98161
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.49698417265161, 'MSE - std': 8.266142495728296, 'R2 - mean': 0.5203862777115091, 'R2 - std': 0.023491506930117895} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 993.23560
Epoch 1, Val Loss: 362.88281
Epoch 2, Val Loss: 164.79111
Epoch 3, Val Loss: 152.31984
Epoch 4, Val Loss: 144.25476
Epoch 5, Val Loss: 138.59229
Epoch 6, Val Loss: 126.43004
Epoch 7, Val Loss: 128.81406
Epoch 8, Val Loss: 122.75543
Epoch 9, Val Loss: 124.22993
Epoch 10, Val Loss: 102.22409
Epoch 11, Val Loss: 104.88411
Epoch 12, Val Loss: 105.14645
Epoch 13, Val Loss: 98.61273
Epoch 14, Val Loss: 105.36637
Epoch 15, Val Loss: 111.25485
Epoch 16, Val Loss: 95.97961
Epoch 17, Val Loss: 104.44762
Epoch 18, Val Loss: 99.79600
Epoch 19, Val Loss: 100.03467
Epoch 20, Val Loss: 97.07753
Epoch 21, Val Loss: 100.92247
Epoch 22, Val Loss: 100.14797
Epoch 23, Val Loss: 86.63483
Epoch 24, Val Loss: 89.98743
Epoch 25, Val Loss: 93.84618
Epoch 26, Val Loss: 95.61971
Epoch 27, Val Loss: 93.34303
Epoch 28, Val Loss: 91.86684
Epoch 29, Val Loss: 96.30447
Epoch 30, Val Loss: 113.42909
Epoch 31, Val Loss: 99.10642
Epoch 32, Val Loss: 85.42403
Epoch 33, Val Loss: 86.74337
Epoch 34, Val Loss: 99.11296
Epoch 35, Val Loss: 103.73307
Epoch 36, Val Loss: 89.47314
Epoch 37, Val Loss: 83.53281
Epoch 38, Val Loss: 90.42120
Epoch 39, Val Loss: 86.27378
Epoch 40, Val Loss: 93.06763
Epoch 41, Val Loss: 90.24522
Epoch 42, Val Loss: 84.02840
Epoch 43, Val Loss: 80.41769
Epoch 44, Val Loss: 86.08344
Epoch 45, Val Loss: 89.11164
Epoch 46, Val Loss: 83.85006
Epoch 47, Val Loss: 95.27574
Epoch 48, Val Loss: 88.34088
Epoch 49, Val Loss: 80.64647
Epoch 50, Val Loss: 84.10790
Epoch 51, Val Loss: 82.38378
Epoch 52, Val Loss: 88.76611
Epoch 53, Val Loss: 78.83546
Epoch 54, Val Loss: 84.86436
Epoch 55, Val Loss: 80.47997
Epoch 56, Val Loss: 76.46851
Epoch 57, Val Loss: 78.84683
Epoch 58, Val Loss: 80.28642
Epoch 59, Val Loss: 80.20380
Epoch 60, Val Loss: 79.98473
Epoch 61, Val Loss: 80.81332
Epoch 62, Val Loss: 93.71815
Epoch 63, Val Loss: 78.12560
Epoch 64, Val Loss: 82.41324
Epoch 65, Val Loss: 79.02421
Epoch 66, Val Loss: 78.14901
Epoch 67, Val Loss: 77.35217
Epoch 68, Val Loss: 80.62096
Epoch 69, Val Loss: 82.64590
Epoch 70, Val Loss: 84.48234
Epoch 71, Val Loss: 76.44855
Epoch 72, Val Loss: 76.54713
Epoch 73, Val Loss: 78.93901
Epoch 74, Val Loss: 83.26842
Epoch 75, Val Loss: 87.12872
Epoch 76, Val Loss: 78.67898
Epoch 77, Val Loss: 77.74292
Epoch 78, Val Loss: 81.94547
Epoch 79, Val Loss: 81.75911
Epoch 80, Val Loss: 79.68445
Epoch 81, Val Loss: 83.33264
Epoch 82, Val Loss: 78.78457
Epoch 83, Val Loss: 76.04129
Epoch 84, Val Loss: 79.47578
Epoch 85, Val Loss: 88.97882
Epoch 86, Val Loss: 78.98403
Epoch 87, Val Loss: 75.92699
Epoch 88, Val Loss: 77.28600
Epoch 89, Val Loss: 75.27871
Epoch 90, Val Loss: 75.76167
Epoch 91, Val Loss: 77.53044
Epoch 92, Val Loss: 75.49255
Epoch 93, Val Loss: 77.71530
Epoch 94, Val Loss: 82.09740
Epoch 95, Val Loss: 80.91129
Epoch 96, Val Loss: 79.59922
Epoch 97, Val Loss: 80.33263
Epoch 98, Val Loss: 80.52992
Epoch 99, Val Loss: 80.41351
DID NOT SAVE RESULTS
{'MSE - mean': 78.86508136798767, 'MSE - std': 8.250484034251539, 'R2 - mean': 0.5114928152612354, 'R2 - std': 0.025518017094772874} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1206.73804
Epoch 1, Val Loss: 441.42502
Epoch 2, Val Loss: 195.29745
Epoch 3, Val Loss: 163.09856
Epoch 4, Val Loss: 137.84547
Epoch 5, Val Loss: 119.80687
Epoch 6, Val Loss: 137.44939
Epoch 7, Val Loss: 114.11217
Epoch 8, Val Loss: 122.06706
Epoch 9, Val Loss: 106.57500
Epoch 10, Val Loss: 119.85246
Epoch 11, Val Loss: 114.27072
Epoch 12, Val Loss: 108.57127
Epoch 13, Val Loss: 116.01418
Epoch 14, Val Loss: 105.90609
Epoch 15, Val Loss: 111.35597
Epoch 16, Val Loss: 101.63483
Epoch 17, Val Loss: 116.69813
Epoch 18, Val Loss: 97.61749
Epoch 19, Val Loss: 115.69223
Epoch 20, Val Loss: 102.80052
Epoch 21, Val Loss: 96.47751
Epoch 22, Val Loss: 100.93111
Epoch 23, Val Loss: 97.67740
Epoch 24, Val Loss: 87.85664
Epoch 25, Val Loss: 105.76994
Epoch 26, Val Loss: 103.87550
Epoch 27, Val Loss: 109.26656
Epoch 28, Val Loss: 108.04264
Epoch 29, Val Loss: 99.99193
Epoch 30, Val Loss: 93.82679
Epoch 31, Val Loss: 90.12267
Epoch 32, Val Loss: 93.74799
Epoch 33, Val Loss: 86.79335
Epoch 34, Val Loss: 83.07807
Epoch 35, Val Loss: 96.15807
Epoch 36, Val Loss: 82.84083
Epoch 37, Val Loss: 91.87137
Epoch 38, Val Loss: 102.10991
Epoch 39, Val Loss: 90.62739
Epoch 40, Val Loss: 83.50867
Epoch 41, Val Loss: 91.07220
Epoch 42, Val Loss: 81.35545
Epoch 43, Val Loss: 82.03232
Epoch 44, Val Loss: 79.66895
Epoch 45, Val Loss: 80.98793
Epoch 46, Val Loss: 81.52867
Epoch 47, Val Loss: 89.31897
Epoch 48, Val Loss: 108.49386
Epoch 49, Val Loss: 117.47834
Epoch 50, Val Loss: 78.47324
Epoch 51, Val Loss: 85.03174
Epoch 52, Val Loss: 76.99706
Epoch 53, Val Loss: 77.51678
Epoch 54, Val Loss: 77.07207
Epoch 55, Val Loss: 80.05591
Epoch 56, Val Loss: 81.08852
Epoch 57, Val Loss: 81.09522
Epoch 58, Val Loss: 86.73169
Epoch 59, Val Loss: 81.80161
Epoch 60, Val Loss: 78.95456
Epoch 61, Val Loss: 78.70186
Epoch 62, Val Loss: 82.23696
Epoch 63, Val Loss: 77.38055
Epoch 64, Val Loss: 79.86114
Epoch 65, Val Loss: 75.00546
Epoch 66, Val Loss: 77.27106
Epoch 67, Val Loss: 88.80221
Epoch 68, Val Loss: 81.27661
Epoch 69, Val Loss: 77.11443
Epoch 70, Val Loss: 78.58509
Epoch 71, Val Loss: 77.24741
Epoch 72, Val Loss: 83.15615
Epoch 73, Val Loss: 76.09732
Epoch 74, Val Loss: 79.67036
Epoch 75, Val Loss: 78.95122
Epoch 76, Val Loss: 78.03992
Epoch 77, Val Loss: 77.73840
Epoch 78, Val Loss: 96.30566
Epoch 79, Val Loss: 75.21674
Epoch 80, Val Loss: 75.13398
Epoch 81, Val Loss: 71.71727
Epoch 82, Val Loss: 74.23139
Epoch 83, Val Loss: 75.46875
Epoch 84, Val Loss: 73.64551
Epoch 85, Val Loss: 73.83488
Epoch 86, Val Loss: 79.97593
Epoch 87, Val Loss: 81.39983
Epoch 88, Val Loss: 79.69206
Epoch 89, Val Loss: 75.83277
Epoch 90, Val Loss: 76.24839
Epoch 91, Val Loss: 76.36166
Epoch 92, Val Loss: 71.80915
Epoch 93, Val Loss: 80.12061
Epoch 94, Val Loss: 76.71915
Epoch 95, Val Loss: 75.06341
Epoch 96, Val Loss: 82.01878
Epoch 97, Val Loss: 77.65952
Epoch 98, Val Loss: 75.04798
Epoch 99, Val Loss: 72.14346
DID NOT SAVE RESULTS
{'MSE - mean': 77.74003409605997, 'MSE - std': 7.7148762074215735, 'R2 - mean': 0.5173292179853983, 'R2 - std': 0.025635712281771403} 
 

Results After CV: {'MSE - mean': 77.74003409605997, 'MSE - std': 7.7148762074215735, 'R2 - mean': 0.5173292179853983, 'R2 - std': 0.025635712281771403}
Train time: 465.250637016003
Inference time: 0.17847786139464006
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 82 finished with value: 77.74003409605997 and parameters: {'p_m': 0.2158140860960735, 'alpha': 9.680756976113194, 'K': 2, 'beta': 7.114427106451592}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1264.19312
Epoch 1, Val Loss: 470.99356
Epoch 2, Val Loss: 185.03134
Epoch 3, Val Loss: 170.97714
Epoch 4, Val Loss: 146.47250
Epoch 5, Val Loss: 143.12912
Epoch 6, Val Loss: 130.36441
Epoch 7, Val Loss: 121.99606
Epoch 8, Val Loss: 110.68537
Epoch 9, Val Loss: 116.31990
Epoch 10, Val Loss: 112.07232
Epoch 11, Val Loss: 107.97064
Epoch 12, Val Loss: 105.32562
Epoch 13, Val Loss: 115.13028
Epoch 14, Val Loss: 103.62162
Epoch 15, Val Loss: 102.07642
Epoch 16, Val Loss: 105.12774
Epoch 17, Val Loss: 113.49956
Epoch 18, Val Loss: 103.68288
Epoch 19, Val Loss: 99.17666
Epoch 20, Val Loss: 104.58124
Epoch 21, Val Loss: 97.24232
Epoch 22, Val Loss: 101.32786
Epoch 23, Val Loss: 113.90128
Epoch 24, Val Loss: 110.60409
Epoch 25, Val Loss: 103.27164
Epoch 26, Val Loss: 103.70933
Epoch 27, Val Loss: 103.01684
Epoch 28, Val Loss: 107.37858
Epoch 29, Val Loss: 106.81305
Epoch 30, Val Loss: 96.64920
Epoch 31, Val Loss: 100.19136
Epoch 32, Val Loss: 109.97231
Epoch 33, Val Loss: 98.69514
Epoch 34, Val Loss: 96.82005
Epoch 35, Val Loss: 107.08066
Epoch 36, Val Loss: 103.44496
Epoch 37, Val Loss: 95.21590
Epoch 38, Val Loss: 91.04351
Epoch 39, Val Loss: 102.57388
Epoch 40, Val Loss: 98.70901
Epoch 41, Val Loss: 87.54102
Epoch 42, Val Loss: 93.45106
Epoch 43, Val Loss: 95.74660
Epoch 44, Val Loss: 109.15138
Epoch 45, Val Loss: 93.46797
Epoch 46, Val Loss: 123.86829
Epoch 47, Val Loss: 94.27434
Epoch 48, Val Loss: 88.99001
Epoch 49, Val Loss: 86.81606
Epoch 50, Val Loss: 91.23958
Epoch 51, Val Loss: 88.15144
Epoch 52, Val Loss: 93.56210
Epoch 53, Val Loss: 93.44032
Epoch 54, Val Loss: 94.11855
Epoch 55, Val Loss: 94.23538
Epoch 56, Val Loss: 97.84795
Epoch 57, Val Loss: 87.72337
Epoch 58, Val Loss: 87.61774
Epoch 59, Val Loss: 90.20504
Epoch 60, Val Loss: 87.02924
Epoch 61, Val Loss: 90.12019
Epoch 62, Val Loss: 91.99120
Epoch 63, Val Loss: 87.13767
Epoch 64, Val Loss: 85.86903
Epoch 65, Val Loss: 105.38650
Epoch 66, Val Loss: 104.98281
Epoch 67, Val Loss: 91.41048
Epoch 68, Val Loss: 87.06432
Epoch 69, Val Loss: 89.58230
Epoch 70, Val Loss: 93.32589
Epoch 71, Val Loss: 91.46074
Epoch 72, Val Loss: 86.83202
Epoch 73, Val Loss: 90.43829
Epoch 74, Val Loss: 96.49030
Epoch 75, Val Loss: 94.97164
Epoch 76, Val Loss: 90.07336
Epoch 77, Val Loss: 82.85117
Epoch 78, Val Loss: 92.74638
Epoch 79, Val Loss: 87.66629
Epoch 80, Val Loss: 88.36414
Epoch 81, Val Loss: 86.04742
Epoch 82, Val Loss: 102.50858
Epoch 83, Val Loss: 89.44998
Epoch 84, Val Loss: 89.30872
Epoch 85, Val Loss: 87.43739
Epoch 86, Val Loss: 88.98888
Epoch 87, Val Loss: 85.11704
Epoch 88, Val Loss: 89.80613
Epoch 89, Val Loss: 85.93282
Epoch 90, Val Loss: 89.14566
Epoch 91, Val Loss: 95.11477
Epoch 92, Val Loss: 85.68690
Epoch 93, Val Loss: 88.55421
Epoch 94, Val Loss: 87.87570
Epoch 95, Val Loss: 90.86755
Epoch 96, Val Loss: 95.11925
Epoch 97, Val Loss: 85.68059
Epoch 98, Val Loss: 93.00601
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 86.14321943482065, 'MSE - std': 0.0, 'R2 - mean': 0.49801480341976534, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 607.70050
Epoch 1, Val Loss: 353.87256
Epoch 2, Val Loss: 162.10631
Epoch 3, Val Loss: 140.36156
Epoch 4, Val Loss: 115.26907
Epoch 5, Val Loss: 105.71817
Epoch 6, Val Loss: 101.49567
Epoch 7, Val Loss: 111.81592
Epoch 8, Val Loss: 101.82710
Epoch 9, Val Loss: 114.79572
Epoch 10, Val Loss: 95.21411
Epoch 11, Val Loss: 92.43514
Epoch 12, Val Loss: 91.73702
Epoch 13, Val Loss: 99.52861
Epoch 14, Val Loss: 85.59866
Epoch 15, Val Loss: 94.68048
Epoch 16, Val Loss: 92.29617
Epoch 17, Val Loss: 83.09512
Epoch 18, Val Loss: 91.86049
Epoch 19, Val Loss: 89.89920
Epoch 20, Val Loss: 97.40694
Epoch 21, Val Loss: 88.42303
Epoch 22, Val Loss: 85.46230
Epoch 23, Val Loss: 89.24949
Epoch 24, Val Loss: 81.85559
Epoch 25, Val Loss: 77.89467
Epoch 26, Val Loss: 86.20537
Epoch 27, Val Loss: 83.46130
Epoch 28, Val Loss: 85.79018
Epoch 29, Val Loss: 94.59624
Epoch 30, Val Loss: 87.11651
Epoch 31, Val Loss: 93.63828
Epoch 32, Val Loss: 81.74303
Epoch 33, Val Loss: 90.65766
Epoch 34, Val Loss: 87.78314
Epoch 35, Val Loss: 85.93771
Epoch 36, Val Loss: 80.30170
Epoch 37, Val Loss: 86.05019
Epoch 38, Val Loss: 80.31197
Epoch 39, Val Loss: 79.22703
Epoch 40, Val Loss: 76.52747
Epoch 41, Val Loss: 78.98737
Epoch 42, Val Loss: 92.94716
Epoch 43, Val Loss: 78.17546
Epoch 44, Val Loss: 78.01163
Epoch 45, Val Loss: 73.70665
Epoch 46, Val Loss: 79.32816
Epoch 47, Val Loss: 78.31046
Epoch 48, Val Loss: 86.54662
Epoch 49, Val Loss: 74.38367
Epoch 50, Val Loss: 73.79751
Epoch 51, Val Loss: 79.04790
Epoch 52, Val Loss: 79.42140
Epoch 53, Val Loss: 73.67409
Epoch 54, Val Loss: 78.53098
Epoch 55, Val Loss: 72.99778
Epoch 56, Val Loss: 74.08999
Epoch 57, Val Loss: 79.12220
Epoch 58, Val Loss: 84.93491
Epoch 59, Val Loss: 80.19135
Epoch 60, Val Loss: 74.21538
Epoch 61, Val Loss: 72.40710
Epoch 62, Val Loss: 72.12109
Epoch 63, Val Loss: 76.90465
Epoch 64, Val Loss: 75.55199
Epoch 65, Val Loss: 75.55403
Epoch 66, Val Loss: 72.61622
Epoch 67, Val Loss: 74.85025
Epoch 68, Val Loss: 70.98716
Epoch 69, Val Loss: 75.26717
Epoch 70, Val Loss: 75.28915
Epoch 71, Val Loss: 73.10471
Epoch 72, Val Loss: 76.97949
Epoch 73, Val Loss: 72.76686
Epoch 74, Val Loss: 71.63340
Epoch 75, Val Loss: 75.30654
Epoch 76, Val Loss: 76.58403
Epoch 77, Val Loss: 70.97304
Epoch 78, Val Loss: 72.64670
Epoch 79, Val Loss: 74.57025
Epoch 80, Val Loss: 73.40501
Epoch 81, Val Loss: 74.99211
Epoch 82, Val Loss: 94.91515
Epoch 83, Val Loss: 76.84099
Epoch 84, Val Loss: 74.44336
Epoch 85, Val Loss: 72.83403
Epoch 86, Val Loss: 73.52432
Epoch 87, Val Loss: 69.29696
Epoch 88, Val Loss: 72.55534
Epoch 89, Val Loss: 72.59856
Epoch 90, Val Loss: 78.17583
Epoch 91, Val Loss: 71.26150
Epoch 92, Val Loss: 88.72163
Epoch 93, Val Loss: 72.59446
Epoch 94, Val Loss: 75.93755
Epoch 95, Val Loss: 74.76698
Epoch 96, Val Loss: 73.59972
Epoch 97, Val Loss: 72.45409
Epoch 98, Val Loss: 70.51342
Epoch 99, Val Loss: 90.66017
DID NOT SAVE RESULTS
{'MSE - mean': 81.41492022556474, 'MSE - std': 4.728299209255901, 'R2 - mean': 0.5043778253112663, 'R2 - std': 0.006363021891500953} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 492.48016
Epoch 1, Val Loss: 376.15558
Epoch 2, Val Loss: 159.01874
Epoch 3, Val Loss: 130.14186
Epoch 4, Val Loss: 110.69695
Epoch 5, Val Loss: 113.83836
Epoch 6, Val Loss: 118.14064
Epoch 7, Val Loss: 87.76283
Epoch 8, Val Loss: 94.16518
Epoch 9, Val Loss: 87.52741
Epoch 10, Val Loss: 95.88298
Epoch 11, Val Loss: 91.70172
Epoch 12, Val Loss: 84.80492
Epoch 13, Val Loss: 88.56264
Epoch 14, Val Loss: 84.63672
Epoch 15, Val Loss: 78.06664
Epoch 16, Val Loss: 81.84650
Epoch 17, Val Loss: 89.96056
Epoch 18, Val Loss: 82.65816
Epoch 19, Val Loss: 82.63286
Epoch 20, Val Loss: 96.78476
Epoch 21, Val Loss: 79.74783
Epoch 22, Val Loss: 83.98668
Epoch 23, Val Loss: 91.28101
Epoch 24, Val Loss: 82.17525
Epoch 25, Val Loss: 80.90330
Epoch 26, Val Loss: 81.71886
Epoch 27, Val Loss: 76.04333
Epoch 28, Val Loss: 73.95955
Epoch 29, Val Loss: 84.85507
Epoch 30, Val Loss: 83.05775
Epoch 31, Val Loss: 78.83408
Epoch 32, Val Loss: 76.78499
Epoch 33, Val Loss: 79.64958
Epoch 34, Val Loss: 101.13094
Epoch 35, Val Loss: 91.45741
Epoch 36, Val Loss: 71.32236
Epoch 37, Val Loss: 78.15436
Epoch 38, Val Loss: 77.69985
Epoch 39, Val Loss: 73.73149
Epoch 40, Val Loss: 74.55418
Epoch 41, Val Loss: 82.05042
Epoch 42, Val Loss: 73.81583
Epoch 43, Val Loss: 87.24570
Epoch 44, Val Loss: 74.19003
Epoch 45, Val Loss: 86.28262
Epoch 46, Val Loss: 84.65900
Epoch 47, Val Loss: 71.67886
Epoch 48, Val Loss: 75.55812
Epoch 49, Val Loss: 74.10358
Epoch 50, Val Loss: 73.59996
Epoch 51, Val Loss: 73.86707
Epoch 52, Val Loss: 73.01043
Epoch 53, Val Loss: 75.19592
Epoch 54, Val Loss: 73.18010
Epoch 55, Val Loss: 70.73036
Epoch 56, Val Loss: 76.36206
Epoch 57, Val Loss: 69.65802
Epoch 58, Val Loss: 69.38271
Epoch 59, Val Loss: 71.40253
Epoch 60, Val Loss: 95.25477
Epoch 61, Val Loss: 75.01548
Epoch 62, Val Loss: 73.00262
Epoch 63, Val Loss: 76.23814
Epoch 64, Val Loss: 80.80263
Epoch 65, Val Loss: 70.59432
Epoch 66, Val Loss: 69.67827
Epoch 67, Val Loss: 70.72181
Epoch 68, Val Loss: 67.23258
Epoch 69, Val Loss: 73.77962
Epoch 70, Val Loss: 75.41933
Epoch 71, Val Loss: 67.53761
Epoch 72, Val Loss: 69.74202
Epoch 73, Val Loss: 70.15432
Epoch 74, Val Loss: 71.48689
Epoch 75, Val Loss: 69.31158
Epoch 76, Val Loss: 67.47687
Epoch 77, Val Loss: 73.65778
Epoch 78, Val Loss: 71.16390
Epoch 79, Val Loss: 76.23621
Epoch 80, Val Loss: 94.40858
Epoch 81, Val Loss: 76.54439
Epoch 82, Val Loss: 72.86292
Epoch 83, Val Loss: 69.08331
Epoch 84, Val Loss: 68.63946
Epoch 85, Val Loss: 70.35871
Epoch 86, Val Loss: 67.58729
Epoch 87, Val Loss: 70.74538
Epoch 88, Val Loss: 70.35628
Epoch 89, Val Loss: 72.42471
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.86814286289975, 'MSE - std': 7.500060736162008, 'R2 - mean': 0.5177448800643868, 'R2 - std': 0.01960480393356833} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 464.31033
Epoch 1, Val Loss: 367.12033
Epoch 2, Val Loss: 167.28790
Epoch 3, Val Loss: 163.80544
Epoch 4, Val Loss: 141.98949
Epoch 5, Val Loss: 130.01674
Epoch 6, Val Loss: 113.19063
Epoch 7, Val Loss: 115.93472
Epoch 8, Val Loss: 116.76741
Epoch 9, Val Loss: 107.59460
Epoch 10, Val Loss: 104.65320
Epoch 11, Val Loss: 107.03905
Epoch 12, Val Loss: 98.40361
Epoch 13, Val Loss: 98.87939
Epoch 14, Val Loss: 105.38370
Epoch 15, Val Loss: 94.60052
Epoch 16, Val Loss: 97.62559
Epoch 17, Val Loss: 94.76157
Epoch 18, Val Loss: 89.90787
Epoch 19, Val Loss: 86.61882
Epoch 20, Val Loss: 95.59131
Epoch 21, Val Loss: 91.04895
Epoch 22, Val Loss: 89.84570
Epoch 23, Val Loss: 87.71409
Epoch 24, Val Loss: 90.33621
Epoch 25, Val Loss: 96.04526
Epoch 26, Val Loss: 92.52728
Epoch 27, Val Loss: 91.86375
Epoch 28, Val Loss: 83.56644
Epoch 29, Val Loss: 93.50045
Epoch 30, Val Loss: 85.11771
Epoch 31, Val Loss: 88.76377
Epoch 32, Val Loss: 90.28267
Epoch 33, Val Loss: 86.38148
Epoch 34, Val Loss: 91.14093
Epoch 35, Val Loss: 88.79581
Epoch 36, Val Loss: 115.02300
Epoch 37, Val Loss: 87.08875
Epoch 38, Val Loss: 90.81157
Epoch 39, Val Loss: 87.83109
Epoch 40, Val Loss: 89.17817
Epoch 41, Val Loss: 95.73012
Epoch 42, Val Loss: 80.70425
Epoch 43, Val Loss: 87.07601
Epoch 44, Val Loss: 86.46844
Epoch 45, Val Loss: 85.09996
Epoch 46, Val Loss: 100.69032
Epoch 47, Val Loss: 80.86462
Epoch 48, Val Loss: 91.09448
Epoch 49, Val Loss: 86.61772
Epoch 50, Val Loss: 80.22234
Epoch 51, Val Loss: 79.90141
Epoch 52, Val Loss: 78.08516
Epoch 53, Val Loss: 83.12236
Epoch 54, Val Loss: 82.89834
Epoch 55, Val Loss: 82.02752
Epoch 56, Val Loss: 80.82307
Epoch 57, Val Loss: 84.77780
Epoch 58, Val Loss: 81.40392
Epoch 59, Val Loss: 89.44051
Epoch 60, Val Loss: 83.61107
Epoch 61, Val Loss: 78.25188
Epoch 62, Val Loss: 86.16936
Epoch 63, Val Loss: 87.18218
Epoch 64, Val Loss: 78.51998
Epoch 65, Val Loss: 78.75243
Epoch 66, Val Loss: 83.81954
Epoch 67, Val Loss: 79.22266
Epoch 68, Val Loss: 87.95802
Epoch 69, Val Loss: 91.71796
Epoch 70, Val Loss: 79.67507
Epoch 71, Val Loss: 83.38699
Epoch 72, Val Loss: 80.22514
Epoch 73, Val Loss: 81.71103
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.60994170652268, 'MSE - std': 8.046152246960355, 'R2 - mean': 0.5067162303977784, 'R2 - std': 0.025556889352219586} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 466.14481
Epoch 1, Val Loss: 378.30777
Epoch 2, Val Loss: 177.28023
Epoch 3, Val Loss: 148.75865
Epoch 4, Val Loss: 120.85262
Epoch 5, Val Loss: 122.63049
Epoch 6, Val Loss: 130.07674
Epoch 7, Val Loss: 109.83241
Epoch 8, Val Loss: 108.34912
Epoch 9, Val Loss: 114.71132
Epoch 10, Val Loss: 105.01141
Epoch 11, Val Loss: 106.96112
Epoch 12, Val Loss: 103.08354
Epoch 13, Val Loss: 94.44167
Epoch 14, Val Loss: 87.89565
Epoch 15, Val Loss: 106.22800
Epoch 16, Val Loss: 96.61160
Epoch 17, Val Loss: 99.19336
Epoch 18, Val Loss: 111.45584
Epoch 19, Val Loss: 101.63920
Epoch 20, Val Loss: 108.51217
Epoch 21, Val Loss: 95.27536
Epoch 22, Val Loss: 115.65124
Epoch 23, Val Loss: 93.67239
Epoch 24, Val Loss: 97.40921
Epoch 25, Val Loss: 100.69876
Epoch 26, Val Loss: 92.06827
Epoch 27, Val Loss: 90.14735
Epoch 28, Val Loss: 91.44276
Epoch 29, Val Loss: 105.32670
Epoch 30, Val Loss: 100.71057
Epoch 31, Val Loss: 85.27347
Epoch 32, Val Loss: 85.08308
Epoch 33, Val Loss: 93.30508
Epoch 34, Val Loss: 86.93601
Epoch 35, Val Loss: 83.97644
Epoch 36, Val Loss: 88.76141
Epoch 37, Val Loss: 100.97504
Epoch 38, Val Loss: 82.36194
Epoch 39, Val Loss: 85.57909
Epoch 40, Val Loss: 87.82938
Epoch 41, Val Loss: 87.00875
Epoch 42, Val Loss: 95.05235
Epoch 43, Val Loss: 86.12755
Epoch 44, Val Loss: 86.77229
Epoch 45, Val Loss: 88.36368
Epoch 46, Val Loss: 83.37468
Epoch 47, Val Loss: 84.32394
Epoch 48, Val Loss: 81.61012
Epoch 49, Val Loss: 86.65678
Epoch 50, Val Loss: 89.40160
Epoch 51, Val Loss: 95.78751
Epoch 52, Val Loss: 83.64304
Epoch 53, Val Loss: 77.36220
Epoch 54, Val Loss: 93.80988
Epoch 55, Val Loss: 75.46025
Epoch 56, Val Loss: 77.21822
Epoch 57, Val Loss: 82.75349
Epoch 58, Val Loss: 84.64159
Epoch 59, Val Loss: 82.68384
Epoch 60, Val Loss: 84.16212
Epoch 61, Val Loss: 83.09313
Epoch 62, Val Loss: 79.07528
Epoch 63, Val Loss: 78.70838
Epoch 64, Val Loss: 81.59776
Epoch 65, Val Loss: 83.49557
Epoch 66, Val Loss: 83.34704
Epoch 67, Val Loss: 76.59586
Epoch 68, Val Loss: 77.82227
Epoch 69, Val Loss: 80.21846
Epoch 70, Val Loss: 78.64079
Epoch 71, Val Loss: 81.29571
Epoch 72, Val Loss: 74.20296
Epoch 73, Val Loss: 76.65227
Epoch 74, Val Loss: 79.55407
Epoch 75, Val Loss: 84.96808
Epoch 76, Val Loss: 76.28606
Epoch 77, Val Loss: 78.87421
Epoch 78, Val Loss: 80.87914
Epoch 79, Val Loss: 80.45897
Epoch 80, Val Loss: 86.29485
Epoch 81, Val Loss: 77.60206
Epoch 82, Val Loss: 85.98042
Epoch 83, Val Loss: 76.22238
Epoch 84, Val Loss: 79.47364
Epoch 85, Val Loss: 73.81705
Epoch 86, Val Loss: 78.01932
Epoch 87, Val Loss: 77.06265
Epoch 88, Val Loss: 75.69412
Epoch 89, Val Loss: 84.59145
Epoch 90, Val Loss: 76.42477
Epoch 91, Val Loss: 75.99811
Epoch 92, Val Loss: 82.73413
Epoch 93, Val Loss: 76.63896
Epoch 94, Val Loss: 75.01837
Epoch 95, Val Loss: 77.52238
Epoch 96, Val Loss: 75.59240
Epoch 97, Val Loss: 79.15798
Epoch 98, Val Loss: 74.09181
Epoch 99, Val Loss: 85.52836
DID NOT SAVE RESULTS
{'MSE - mean': 78.68161505648582, 'MSE - std': 7.4323357204641045, 'R2 - mean': 0.5113399313913483, 'R2 - std': 0.02465842894835421} 
 

Results After CV: {'MSE - mean': 78.68161505648582, 'MSE - std': 7.4323357204641045, 'R2 - mean': 0.5113399313913483, 'R2 - std': 0.02465842894835421}
Train time: 433.279744939215
Inference time: 0.20771677359007298
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 83 finished with value: 78.68161505648582 and parameters: {'p_m': 0.21984002414938758, 'alpha': 9.229314247660161, 'K': 2, 'beta': 5.552903518750264}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 637.49591
Epoch 1, Val Loss: 468.53018
Epoch 2, Val Loss: 207.36707
Epoch 3, Val Loss: 173.88000
Epoch 4, Val Loss: 164.28563
Epoch 5, Val Loss: 156.21556
Epoch 6, Val Loss: 140.55551
Epoch 7, Val Loss: 126.54702
Epoch 8, Val Loss: 151.18721
Epoch 9, Val Loss: 126.77635
Epoch 10, Val Loss: 144.40747
Epoch 11, Val Loss: 116.96288
Epoch 12, Val Loss: 126.46888
Epoch 13, Val Loss: 109.55578
Epoch 14, Val Loss: 101.09142
Epoch 15, Val Loss: 101.99157
Epoch 16, Val Loss: 102.38539
Epoch 17, Val Loss: 101.18257
Epoch 18, Val Loss: 100.38378
Epoch 19, Val Loss: 104.81197
Epoch 20, Val Loss: 112.53691
Epoch 21, Val Loss: 110.29111
Epoch 22, Val Loss: 96.99670
Epoch 23, Val Loss: 105.36028
Epoch 24, Val Loss: 111.81053
Epoch 25, Val Loss: 98.35065
Epoch 26, Val Loss: 103.80544
Epoch 27, Val Loss: 111.53104
Epoch 28, Val Loss: 99.76103
Epoch 29, Val Loss: 98.74802
Epoch 30, Val Loss: 100.45872
Epoch 31, Val Loss: 97.44659
Epoch 32, Val Loss: 91.18955
Epoch 33, Val Loss: 100.02657
Epoch 34, Val Loss: 101.79289
Epoch 35, Val Loss: 96.88933
Epoch 36, Val Loss: 92.86137
Epoch 37, Val Loss: 101.29704
Epoch 38, Val Loss: 95.33534
Epoch 39, Val Loss: 96.53976
Epoch 40, Val Loss: 95.45759
Epoch 41, Val Loss: 92.58089
Epoch 42, Val Loss: 83.90515
Epoch 43, Val Loss: 89.67012
Epoch 44, Val Loss: 100.62894
Epoch 45, Val Loss: 86.87929
Epoch 46, Val Loss: 97.30696
Epoch 47, Val Loss: 85.66959
Epoch 48, Val Loss: 88.25539
Epoch 49, Val Loss: 89.07230
Epoch 50, Val Loss: 88.08939
Epoch 51, Val Loss: 83.36160
Epoch 52, Val Loss: 85.24215
Epoch 53, Val Loss: 87.37735
Epoch 54, Val Loss: 85.94505
Epoch 55, Val Loss: 84.89395
Epoch 56, Val Loss: 87.17326
Epoch 57, Val Loss: 86.76945
Epoch 58, Val Loss: 90.17639
Epoch 59, Val Loss: 80.80061
Epoch 60, Val Loss: 84.42519
Epoch 61, Val Loss: 86.80045
Epoch 62, Val Loss: 87.04538
Epoch 63, Val Loss: 86.50948
Epoch 64, Val Loss: 91.35241
Epoch 65, Val Loss: 84.27689
Epoch 66, Val Loss: 85.48396
Epoch 67, Val Loss: 84.06306
Epoch 68, Val Loss: 80.48184
Epoch 69, Val Loss: 84.18227
Epoch 70, Val Loss: 86.81421
Epoch 71, Val Loss: 84.35797
Epoch 72, Val Loss: 88.97849
Epoch 73, Val Loss: 83.32454
Epoch 74, Val Loss: 87.62172
Epoch 75, Val Loss: 86.39931
Epoch 76, Val Loss: 88.15787
Epoch 77, Val Loss: 86.05807
Epoch 78, Val Loss: 83.35984
Epoch 79, Val Loss: 84.69795
Epoch 80, Val Loss: 89.98888
Epoch 81, Val Loss: 84.02393
Epoch 82, Val Loss: 89.65855
Epoch 83, Val Loss: 83.69176
Epoch 84, Val Loss: 84.90672
Epoch 85, Val Loss: 83.46249
Epoch 86, Val Loss: 80.81418
Epoch 87, Val Loss: 83.31802
Epoch 88, Val Loss: 82.69194
Epoch 89, Val Loss: 94.79624
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 85.59371258957847, 'MSE - std': 0.0, 'R2 - mean': 0.5012169626093205, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1043.17004
Epoch 1, Val Loss: 451.14581
Epoch 2, Val Loss: 152.85590
Epoch 3, Val Loss: 155.68770
Epoch 4, Val Loss: 139.79025
Epoch 5, Val Loss: 126.44489
Epoch 6, Val Loss: 111.52257
Epoch 7, Val Loss: 117.22263
Epoch 8, Val Loss: 104.91222
Epoch 9, Val Loss: 119.86776
Epoch 10, Val Loss: 101.77687
Epoch 11, Val Loss: 104.98605
Epoch 12, Val Loss: 94.13251
Epoch 13, Val Loss: 89.50253
Epoch 14, Val Loss: 92.15386
Epoch 15, Val Loss: 94.39435
Epoch 16, Val Loss: 99.85127
Epoch 17, Val Loss: 92.48065
Epoch 18, Val Loss: 84.79350
Epoch 19, Val Loss: 96.75928
Epoch 20, Val Loss: 89.17435
Epoch 21, Val Loss: 90.94032
Epoch 22, Val Loss: 89.08908
Epoch 23, Val Loss: 88.76712
Epoch 24, Val Loss: 86.75513
Epoch 25, Val Loss: 84.09235
Epoch 26, Val Loss: 95.96661
Epoch 27, Val Loss: 92.87003
Epoch 28, Val Loss: 82.75380
Epoch 29, Val Loss: 93.57722
Epoch 30, Val Loss: 87.04542
Epoch 31, Val Loss: 84.17752
Epoch 32, Val Loss: 90.79683
Epoch 33, Val Loss: 84.86311
Epoch 34, Val Loss: 78.92710
Epoch 35, Val Loss: 93.24651
Epoch 36, Val Loss: 81.29218
Epoch 37, Val Loss: 83.78291
Epoch 38, Val Loss: 87.59631
Epoch 39, Val Loss: 77.53965
Epoch 40, Val Loss: 79.53140
Epoch 41, Val Loss: 80.49738
Epoch 42, Val Loss: 84.38856
Epoch 43, Val Loss: 74.69836
Epoch 44, Val Loss: 74.24658
Epoch 45, Val Loss: 83.83154
Epoch 46, Val Loss: 72.94959
Epoch 47, Val Loss: 79.93648
Epoch 48, Val Loss: 83.32046
Epoch 49, Val Loss: 79.79873
Epoch 50, Val Loss: 72.53806
Epoch 51, Val Loss: 78.56461
Epoch 52, Val Loss: 78.59686
Epoch 53, Val Loss: 79.89627
Epoch 54, Val Loss: 92.47399
Epoch 55, Val Loss: 79.32497
Epoch 56, Val Loss: 79.24996
Epoch 57, Val Loss: 71.63524
Epoch 58, Val Loss: 85.74910
Epoch 59, Val Loss: 73.53933
Epoch 60, Val Loss: 76.33286
Epoch 61, Val Loss: 68.92107
Epoch 62, Val Loss: 70.87778
Epoch 63, Val Loss: 75.46711
Epoch 64, Val Loss: 76.87524
Epoch 65, Val Loss: 71.87359
Epoch 66, Val Loss: 75.42753
Epoch 67, Val Loss: 79.84696
Epoch 68, Val Loss: 73.00761
Epoch 69, Val Loss: 71.05884
Epoch 70, Val Loss: 71.64516
Epoch 71, Val Loss: 71.40613
Epoch 72, Val Loss: 73.92496
Epoch 73, Val Loss: 69.82029
Epoch 74, Val Loss: 74.73997
Epoch 75, Val Loss: 71.22218
Epoch 76, Val Loss: 79.00024
Epoch 77, Val Loss: 71.10278
Epoch 78, Val Loss: 71.71246
Epoch 79, Val Loss: 77.96894
Epoch 80, Val Loss: 76.31892
Epoch 81, Val Loss: 71.75342
Epoch 82, Val Loss: 69.30636
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.11141729447868, 'MSE - std': 4.482295295099782, 'R2 - mean': 0.5061623262117227, 'R2 - std': 0.00494536360240222} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1404.59253
Epoch 1, Val Loss: 419.42526
Epoch 2, Val Loss: 155.59401
Epoch 3, Val Loss: 135.18938
Epoch 4, Val Loss: 141.13023
Epoch 5, Val Loss: 126.53606
Epoch 6, Val Loss: 116.04654
Epoch 7, Val Loss: 112.55019
Epoch 8, Val Loss: 119.87997
Epoch 9, Val Loss: 86.89330
Epoch 10, Val Loss: 98.10246
Epoch 11, Val Loss: 96.87454
Epoch 12, Val Loss: 104.93933
Epoch 13, Val Loss: 96.21046
Epoch 14, Val Loss: 93.99078
Epoch 15, Val Loss: 92.20420
Epoch 16, Val Loss: 90.68471
Epoch 17, Val Loss: 79.59849
Epoch 18, Val Loss: 80.87924
Epoch 19, Val Loss: 91.83157
Epoch 20, Val Loss: 100.70427
Epoch 21, Val Loss: 92.91690
Epoch 22, Val Loss: 82.17074
Epoch 23, Val Loss: 88.82856
Epoch 24, Val Loss: 86.46342
Epoch 25, Val Loss: 81.82687
Epoch 26, Val Loss: 82.85518
Epoch 27, Val Loss: 78.00161
Epoch 28, Val Loss: 72.45409
Epoch 29, Val Loss: 73.57334
Epoch 30, Val Loss: 89.83894
Epoch 31, Val Loss: 77.94402
Epoch 32, Val Loss: 77.93394
Epoch 33, Val Loss: 90.44969
Epoch 34, Val Loss: 77.39485
Epoch 35, Val Loss: 82.81036
Epoch 36, Val Loss: 84.35079
Epoch 37, Val Loss: 79.31830
Epoch 38, Val Loss: 76.65781
Epoch 39, Val Loss: 73.21736
Epoch 40, Val Loss: 75.96053
Epoch 41, Val Loss: 73.32107
Epoch 42, Val Loss: 89.60990
Epoch 43, Val Loss: 85.17305
Epoch 44, Val Loss: 71.55178
Epoch 45, Val Loss: 75.00083
Epoch 46, Val Loss: 89.73593
Epoch 47, Val Loss: 73.66962
Epoch 48, Val Loss: 73.59071
Epoch 49, Val Loss: 74.35023
Epoch 50, Val Loss: 72.87687
Epoch 51, Val Loss: 81.68946
Epoch 52, Val Loss: 68.83459
Epoch 53, Val Loss: 74.81093
Epoch 54, Val Loss: 79.60494
Epoch 55, Val Loss: 71.72636
Epoch 56, Val Loss: 67.81177
Epoch 57, Val Loss: 76.93539
Epoch 58, Val Loss: 71.28467
Epoch 59, Val Loss: 71.34410
Epoch 60, Val Loss: 69.68723
Epoch 61, Val Loss: 71.91000
Epoch 62, Val Loss: 69.54552
Epoch 63, Val Loss: 74.88762
Epoch 64, Val Loss: 75.85910
Epoch 65, Val Loss: 67.81663
Epoch 66, Val Loss: 79.60316
Epoch 67, Val Loss: 71.08481
Epoch 68, Val Loss: 82.23951
Epoch 69, Val Loss: 77.68353
Epoch 70, Val Loss: 75.92139
Epoch 71, Val Loss: 70.06863
Epoch 72, Val Loss: 73.91359
Epoch 73, Val Loss: 70.91885
Epoch 74, Val Loss: 79.19664
Epoch 75, Val Loss: 78.86073
Epoch 76, Val Loss: 78.52072
Epoch 77, Val Loss: 68.46042
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 76.99677793915536, 'MSE - std': 6.874190482551397, 'R2 - mean': 0.5167100564327288, 'R2 - std': 0.015453596336675013} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 548.51245
Epoch 1, Val Loss: 346.39252
Epoch 2, Val Loss: 188.76093
Epoch 3, Val Loss: 146.04288
Epoch 4, Val Loss: 136.07661
Epoch 5, Val Loss: 133.93221
Epoch 6, Val Loss: 115.02207
Epoch 7, Val Loss: 123.18666
Epoch 8, Val Loss: 108.31749
Epoch 9, Val Loss: 125.15893
Epoch 10, Val Loss: 107.99463
Epoch 11, Val Loss: 105.54071
Epoch 12, Val Loss: 110.57864
Epoch 13, Val Loss: 107.37466
Epoch 14, Val Loss: 102.76642
Epoch 15, Val Loss: 100.78248
Epoch 16, Val Loss: 112.18784
Epoch 17, Val Loss: 116.96978
Epoch 18, Val Loss: 95.42312
Epoch 19, Val Loss: 96.73540
Epoch 20, Val Loss: 99.12756
Epoch 21, Val Loss: 95.60199
Epoch 22, Val Loss: 106.96483
Epoch 23, Val Loss: 93.87624
Epoch 24, Val Loss: 101.33987
Epoch 25, Val Loss: 95.48122
Epoch 26, Val Loss: 90.64196
Epoch 27, Val Loss: 92.84153
Epoch 28, Val Loss: 99.29378
Epoch 29, Val Loss: 133.25812
Epoch 30, Val Loss: 90.00156
Epoch 31, Val Loss: 91.95187
Epoch 32, Val Loss: 90.54758
Epoch 33, Val Loss: 89.75905
Epoch 34, Val Loss: 95.26923
Epoch 35, Val Loss: 91.54872
Epoch 36, Val Loss: 83.14434
Epoch 37, Val Loss: 78.98577
Epoch 38, Val Loss: 90.01527
Epoch 39, Val Loss: 91.95074
Epoch 40, Val Loss: 107.79422
Epoch 41, Val Loss: 85.54774
Epoch 42, Val Loss: 89.66814
Epoch 43, Val Loss: 82.47493
Epoch 44, Val Loss: 90.78079
Epoch 45, Val Loss: 85.66837
Epoch 46, Val Loss: 94.53107
Epoch 47, Val Loss: 89.73716
Epoch 48, Val Loss: 83.97966
Epoch 49, Val Loss: 78.09415
Epoch 50, Val Loss: 82.03333
Epoch 51, Val Loss: 80.65228
Epoch 52, Val Loss: 89.38948
Epoch 53, Val Loss: 84.21290
Epoch 54, Val Loss: 82.54548
Epoch 55, Val Loss: 84.55477
Epoch 56, Val Loss: 83.10534
Epoch 57, Val Loss: 78.79716
Epoch 58, Val Loss: 90.44736
Epoch 59, Val Loss: 79.37059
Epoch 60, Val Loss: 88.03183
Epoch 61, Val Loss: 83.47554
Epoch 62, Val Loss: 80.42241
Epoch 63, Val Loss: 94.62091
Epoch 64, Val Loss: 82.33461
Epoch 65, Val Loss: 80.92763
Epoch 66, Val Loss: 77.88102
Epoch 67, Val Loss: 77.54770
Epoch 68, Val Loss: 98.81513
Epoch 69, Val Loss: 79.81528
Epoch 70, Val Loss: 88.42712
Epoch 71, Val Loss: 84.19178
Epoch 72, Val Loss: 80.52947
Epoch 73, Val Loss: 80.66955
Epoch 74, Val Loss: 98.12631
Epoch 75, Val Loss: 78.87373
Epoch 76, Val Loss: 83.59164
Epoch 77, Val Loss: 84.16728
Epoch 78, Val Loss: 82.69173
Epoch 79, Val Loss: 81.80689
Epoch 80, Val Loss: 79.90890
Epoch 81, Val Loss: 77.87903
Epoch 82, Val Loss: 78.86312
Epoch 83, Val Loss: 79.25990
Epoch 84, Val Loss: 78.16143
Epoch 85, Val Loss: 77.26731
Epoch 86, Val Loss: 81.30297
Epoch 87, Val Loss: 76.52132
Epoch 88, Val Loss: 78.13007
Epoch 89, Val Loss: 93.17216
Epoch 90, Val Loss: 81.18987
Epoch 91, Val Loss: 83.29996
Epoch 92, Val Loss: 79.05038
Epoch 93, Val Loss: 77.26176
Epoch 94, Val Loss: 98.76103
Epoch 95, Val Loss: 100.55185
Epoch 96, Val Loss: 80.79099
Epoch 97, Val Loss: 79.43177
Epoch 98, Val Loss: 84.12888
Epoch 99, Val Loss: 78.38122
DID NOT SAVE RESULTS
{'MSE - mean': 79.77853954610252, 'MSE - std': 7.658685527324902, 'R2 - mean': 0.5055079108806553, 'R2 - std': 0.023570626311411273} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 648.82568
Epoch 1, Val Loss: 502.64642
Epoch 2, Val Loss: 164.06076
Epoch 3, Val Loss: 159.06541
Epoch 4, Val Loss: 157.14316
Epoch 5, Val Loss: 131.49867
Epoch 6, Val Loss: 114.88895
Epoch 7, Val Loss: 124.29768
Epoch 8, Val Loss: 127.58482
Epoch 9, Val Loss: 111.40400
Epoch 10, Val Loss: 119.50434
Epoch 11, Val Loss: 103.74805
Epoch 12, Val Loss: 119.95831
Epoch 13, Val Loss: 102.95084
Epoch 14, Val Loss: 97.38048
Epoch 15, Val Loss: 105.90486
Epoch 16, Val Loss: 92.66119
Epoch 17, Val Loss: 99.02686
Epoch 18, Val Loss: 116.00515
Epoch 19, Val Loss: 98.55086
Epoch 20, Val Loss: 106.22445
Epoch 21, Val Loss: 119.62569
Epoch 22, Val Loss: 94.77228
Epoch 23, Val Loss: 89.32555
Epoch 24, Val Loss: 100.47099
Epoch 25, Val Loss: 92.45739
Epoch 26, Val Loss: 86.80304
Epoch 27, Val Loss: 103.65694
Epoch 28, Val Loss: 87.03536
Epoch 29, Val Loss: 84.85420
Epoch 30, Val Loss: 90.90202
Epoch 31, Val Loss: 91.22681
Epoch 32, Val Loss: 79.70164
Epoch 33, Val Loss: 98.80499
Epoch 34, Val Loss: 85.45843
Epoch 35, Val Loss: 81.23618
Epoch 36, Val Loss: 80.71516
Epoch 37, Val Loss: 83.52673
Epoch 38, Val Loss: 81.89363
Epoch 39, Val Loss: 88.11314
Epoch 40, Val Loss: 81.75775
Epoch 41, Val Loss: 79.75232
Epoch 42, Val Loss: 81.79540
Epoch 43, Val Loss: 92.56303
Epoch 44, Val Loss: 84.17985
Epoch 45, Val Loss: 78.38448
Epoch 46, Val Loss: 92.79894
Epoch 47, Val Loss: 75.53963
Epoch 48, Val Loss: 84.57877
Epoch 49, Val Loss: 78.70873
Epoch 50, Val Loss: 76.91441
Epoch 51, Val Loss: 78.81700
Epoch 52, Val Loss: 78.70277
Epoch 53, Val Loss: 92.49057
Epoch 54, Val Loss: 77.30538
Epoch 55, Val Loss: 81.28898
Epoch 56, Val Loss: 74.28751
Epoch 57, Val Loss: 78.09415
Epoch 58, Val Loss: 78.54001
Epoch 59, Val Loss: 71.78601
Epoch 60, Val Loss: 76.48550
Epoch 61, Val Loss: 75.87459
Epoch 62, Val Loss: 79.72102
Epoch 63, Val Loss: 77.64867
Epoch 64, Val Loss: 77.53535
Epoch 65, Val Loss: 77.12608
Epoch 66, Val Loss: 78.09708
Epoch 67, Val Loss: 83.71550
Epoch 68, Val Loss: 79.71827
Epoch 69, Val Loss: 74.56538
Epoch 70, Val Loss: 73.73318
Epoch 71, Val Loss: 73.83271
Epoch 72, Val Loss: 80.70342
Epoch 73, Val Loss: 72.10248
Epoch 74, Val Loss: 78.55891
Epoch 75, Val Loss: 76.91804
Epoch 76, Val Loss: 76.71163
Epoch 77, Val Loss: 71.78327
Epoch 78, Val Loss: 72.92433
Epoch 79, Val Loss: 78.12017
Epoch 80, Val Loss: 83.35487
Epoch 81, Val Loss: 71.74300
Epoch 82, Val Loss: 80.06249
Epoch 83, Val Loss: 77.25696
Epoch 84, Val Loss: 75.66631
Epoch 85, Val Loss: 73.19469
Epoch 86, Val Loss: 76.27409
Epoch 87, Val Loss: 82.65491
Epoch 88, Val Loss: 76.37923
Epoch 89, Val Loss: 72.22369
Epoch 90, Val Loss: 79.56937
Epoch 91, Val Loss: 69.31809
Epoch 92, Val Loss: 72.24266
Epoch 93, Val Loss: 72.92132
Epoch 94, Val Loss: 76.14571
Epoch 95, Val Loss: 69.95027
Epoch 96, Val Loss: 70.41745
Epoch 97, Val Loss: 79.87627
Epoch 98, Val Loss: 72.38391
Epoch 99, Val Loss: 71.76333
DID NOT SAVE RESULTS
{'MSE - mean': 77.72926040740285, 'MSE - std': 7.982640613130683, 'R2 - mean': 0.5171918790571923, 'R2 - std': 0.031472527530706465} 
 

Results After CV: {'MSE - mean': 77.72926040740285, 'MSE - std': 7.982640613130683, 'R2 - mean': 0.5171918790571923, 'R2 - std': 0.031472527530706465}
Train time: 418.69381449217906
Inference time: 0.1880081915995106
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 84 finished with value: 77.72926040740285 and parameters: {'p_m': 0.18812106745118518, 'alpha': 3.000682641233104, 'K': 2, 'beta': 8.634089454365835}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 666.73187
Epoch 1, Val Loss: 275.70355
Epoch 2, Val Loss: 207.97557
Epoch 3, Val Loss: 151.47964
Epoch 4, Val Loss: 156.81242
Epoch 5, Val Loss: 129.91119
Epoch 6, Val Loss: 134.52789
Epoch 7, Val Loss: 118.01949
Epoch 8, Val Loss: 122.63332
Epoch 9, Val Loss: 114.66029
Epoch 10, Val Loss: 104.64287
Epoch 11, Val Loss: 120.05754
Epoch 12, Val Loss: 127.72967
Epoch 13, Val Loss: 106.18508
Epoch 14, Val Loss: 111.85362
Epoch 15, Val Loss: 158.23251
Epoch 16, Val Loss: 118.78793
Epoch 17, Val Loss: 108.10151
Epoch 18, Val Loss: 103.20090
Epoch 19, Val Loss: 114.78672
Epoch 20, Val Loss: 98.96787
Epoch 21, Val Loss: 105.73228
Epoch 22, Val Loss: 111.48688
Epoch 23, Val Loss: 101.04784
Epoch 24, Val Loss: 103.31970
Epoch 25, Val Loss: 102.57539
Epoch 26, Val Loss: 100.53470
Epoch 27, Val Loss: 111.78435
Epoch 28, Val Loss: 93.17581
Epoch 29, Val Loss: 102.57796
Epoch 30, Val Loss: 90.11852
Epoch 31, Val Loss: 98.00188
Epoch 32, Val Loss: 95.20885
Epoch 33, Val Loss: 89.23662
Epoch 34, Val Loss: 89.96927
Epoch 35, Val Loss: 88.17609
Epoch 36, Val Loss: 93.02866
Epoch 37, Val Loss: 91.52002
Epoch 38, Val Loss: 90.35204
Epoch 39, Val Loss: 87.51410
Epoch 40, Val Loss: 91.71798
Epoch 41, Val Loss: 87.82349
Epoch 42, Val Loss: 97.76452
Epoch 43, Val Loss: 86.78246
Epoch 44, Val Loss: 89.32541
Epoch 45, Val Loss: 91.30353
Epoch 46, Val Loss: 88.63376
Epoch 47, Val Loss: 89.48499
Epoch 48, Val Loss: 95.58707
Epoch 49, Val Loss: 94.36262
Epoch 50, Val Loss: 90.53505
Epoch 51, Val Loss: 87.24321
Epoch 52, Val Loss: 84.93876
Epoch 53, Val Loss: 86.63974
Epoch 54, Val Loss: 89.60769
Epoch 55, Val Loss: 89.29124
Epoch 56, Val Loss: 91.25354
Epoch 57, Val Loss: 89.85379
Epoch 58, Val Loss: 87.01392
Epoch 59, Val Loss: 88.50105
Epoch 60, Val Loss: 89.01426
Epoch 61, Val Loss: 87.75250
Epoch 62, Val Loss: 87.66139
Epoch 63, Val Loss: 85.84654
Epoch 64, Val Loss: 90.09055
Epoch 65, Val Loss: 85.77362
Epoch 66, Val Loss: 86.37109
Epoch 67, Val Loss: 85.31371
Epoch 68, Val Loss: 88.87459
Epoch 69, Val Loss: 88.55361
Epoch 70, Val Loss: 87.43478
Epoch 71, Val Loss: 84.09315
Epoch 72, Val Loss: 91.16839
Epoch 73, Val Loss: 86.36510
Epoch 74, Val Loss: 86.77516
Epoch 75, Val Loss: 83.94691
Epoch 76, Val Loss: 94.59396
Epoch 77, Val Loss: 83.91360
Epoch 78, Val Loss: 89.06505
Epoch 79, Val Loss: 86.24380
Epoch 80, Val Loss: 90.03709
Epoch 81, Val Loss: 88.95963
Epoch 82, Val Loss: 89.11863
Epoch 83, Val Loss: 89.71464
Epoch 84, Val Loss: 87.68407
Epoch 85, Val Loss: 92.39006
Epoch 86, Val Loss: 92.02686
Epoch 87, Val Loss: 91.43374
Epoch 88, Val Loss: 87.59428
Epoch 89, Val Loss: 89.07013
Epoch 90, Val Loss: 95.88593
Epoch 91, Val Loss: 92.98579
Epoch 92, Val Loss: 87.23175
Epoch 93, Val Loss: 85.74974
Epoch 94, Val Loss: 87.89008
Epoch 95, Val Loss: 88.41344
Epoch 96, Val Loss: 85.42374
Epoch 97, Val Loss: 89.72835
Epoch 98, Val Loss: 97.37294
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 88.90585289327477, 'MSE - std': 0.0, 'R2 - mean': 0.48191601922270455, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 478.02420
Epoch 1, Val Loss: 301.81985
Epoch 2, Val Loss: 198.35748
Epoch 3, Val Loss: 152.07312
Epoch 4, Val Loss: 137.40453
Epoch 5, Val Loss: 126.27467
Epoch 6, Val Loss: 130.79109
Epoch 7, Val Loss: 101.25989
Epoch 8, Val Loss: 103.77864
Epoch 9, Val Loss: 96.67947
Epoch 10, Val Loss: 110.50329
Epoch 11, Val Loss: 95.41389
Epoch 12, Val Loss: 102.53088
Epoch 13, Val Loss: 85.64250
Epoch 14, Val Loss: 86.66976
Epoch 15, Val Loss: 86.18836
Epoch 16, Val Loss: 89.43703
Epoch 17, Val Loss: 82.66547
Epoch 18, Val Loss: 85.61855
Epoch 19, Val Loss: 83.07147
Epoch 20, Val Loss: 86.97985
Epoch 21, Val Loss: 86.11711
Epoch 22, Val Loss: 91.99436
Epoch 23, Val Loss: 80.28809
Epoch 24, Val Loss: 83.42939
Epoch 25, Val Loss: 82.67521
Epoch 26, Val Loss: 99.92307
Epoch 27, Val Loss: 88.63294
Epoch 28, Val Loss: 76.31260
Epoch 29, Val Loss: 78.48907
Epoch 30, Val Loss: 73.09702
Epoch 31, Val Loss: 74.94096
Epoch 32, Val Loss: 84.59659
Epoch 33, Val Loss: 80.32764
Epoch 34, Val Loss: 73.27615
Epoch 35, Val Loss: 76.68736
Epoch 36, Val Loss: 70.58614
Epoch 37, Val Loss: 69.27806
Epoch 38, Val Loss: 74.59311
Epoch 39, Val Loss: 73.85554
Epoch 40, Val Loss: 77.62289
Epoch 41, Val Loss: 77.53165
Epoch 42, Val Loss: 80.15907
Epoch 43, Val Loss: 76.46542
Epoch 44, Val Loss: 85.24274
Epoch 45, Val Loss: 77.24908
Epoch 46, Val Loss: 70.15936
Epoch 47, Val Loss: 70.90559
Epoch 48, Val Loss: 74.84416
Epoch 49, Val Loss: 70.06237
Epoch 50, Val Loss: 75.49206
Epoch 51, Val Loss: 74.89892
Epoch 52, Val Loss: 79.00017
Epoch 53, Val Loss: 78.04411
Epoch 54, Val Loss: 73.40781
Epoch 55, Val Loss: 77.34621
Epoch 56, Val Loss: 74.53422
Epoch 57, Val Loss: 79.22440
Epoch 58, Val Loss: 71.28555
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 83.54207013678925, 'MSE - std': 5.363782756485527, 'R2 - mean': 0.4915700319959901, 'R2 - std': 0.009654012773285536} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 861.16260
Epoch 1, Val Loss: 373.95703
Epoch 2, Val Loss: 165.28818
Epoch 3, Val Loss: 157.32716
Epoch 4, Val Loss: 139.36150
Epoch 5, Val Loss: 106.72183
Epoch 6, Val Loss: 123.21834
Epoch 7, Val Loss: 91.41907
Epoch 8, Val Loss: 89.62726
Epoch 9, Val Loss: 99.27570
Epoch 10, Val Loss: 95.51945
Epoch 11, Val Loss: 85.57297
Epoch 12, Val Loss: 95.96741
Epoch 13, Val Loss: 87.06619
Epoch 14, Val Loss: 83.70790
Epoch 15, Val Loss: 85.26237
Epoch 16, Val Loss: 89.92853
Epoch 17, Val Loss: 78.67046
Epoch 18, Val Loss: 92.53152
Epoch 19, Val Loss: 93.74288
Epoch 20, Val Loss: 85.63388
Epoch 21, Val Loss: 80.68643
Epoch 22, Val Loss: 85.71912
Epoch 23, Val Loss: 89.85133
Epoch 24, Val Loss: 84.01967
Epoch 25, Val Loss: 79.81140
Epoch 26, Val Loss: 82.27211
Epoch 27, Val Loss: 85.93994
Epoch 28, Val Loss: 89.43777
Epoch 29, Val Loss: 82.58430
Epoch 30, Val Loss: 79.44772
Epoch 31, Val Loss: 78.78465
Epoch 32, Val Loss: 78.22927
Epoch 33, Val Loss: 75.78386
Epoch 34, Val Loss: 71.44998
Epoch 35, Val Loss: 76.29719
Epoch 36, Val Loss: 73.85254
Epoch 37, Val Loss: 75.07729
Epoch 38, Val Loss: 73.21503
Epoch 39, Val Loss: 75.35191
Epoch 40, Val Loss: 71.52840
Epoch 41, Val Loss: 71.27263
Epoch 42, Val Loss: 76.20096
Epoch 43, Val Loss: 76.75888
Epoch 44, Val Loss: 75.79565
Epoch 45, Val Loss: 76.89445
Epoch 46, Val Loss: 73.09468
Epoch 47, Val Loss: 100.38365
Epoch 48, Val Loss: 79.93969
Epoch 49, Val Loss: 75.79781
Epoch 50, Val Loss: 75.98224
Epoch 51, Val Loss: 79.36426
Epoch 52, Val Loss: 73.76077
Epoch 53, Val Loss: 71.98245
Epoch 54, Val Loss: 72.69978
Epoch 55, Val Loss: 68.92467
Epoch 56, Val Loss: 70.92959
Epoch 57, Val Loss: 91.39440
Epoch 58, Val Loss: 67.51218
Epoch 59, Val Loss: 77.82596
Epoch 60, Val Loss: 80.88538
Epoch 61, Val Loss: 68.13399
Epoch 62, Val Loss: 72.38335
Epoch 63, Val Loss: 72.04947
Epoch 64, Val Loss: 75.95615
Epoch 65, Val Loss: 71.74938
Epoch 66, Val Loss: 72.66628
Epoch 67, Val Loss: 73.16705
Epoch 68, Val Loss: 67.96002
Epoch 69, Val Loss: 71.33142
Epoch 70, Val Loss: 69.30460
Epoch 71, Val Loss: 75.32025
Epoch 72, Val Loss: 82.77608
Epoch 73, Val Loss: 76.94781
Epoch 74, Val Loss: 69.78894
Epoch 75, Val Loss: 69.55493
Epoch 76, Val Loss: 72.76833
Epoch 77, Val Loss: 88.42757
Epoch 78, Val Loss: 75.06666
Epoch 79, Val Loss: 74.21223
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.52531228079084, 'MSE - std': 8.337615311184072, 'R2 - mean': 0.5075995370002057, 'R2 - std': 0.024000486865440648} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 506.19244
Epoch 1, Val Loss: 357.54907
Epoch 2, Val Loss: 214.02274
Epoch 3, Val Loss: 166.56761
Epoch 4, Val Loss: 141.16202
Epoch 5, Val Loss: 141.28848
Epoch 6, Val Loss: 123.07063
Epoch 7, Val Loss: 117.41237
Epoch 8, Val Loss: 107.38432
Epoch 9, Val Loss: 109.72466
Epoch 10, Val Loss: 132.20221
Epoch 11, Val Loss: 102.80620
Epoch 12, Val Loss: 104.94635
Epoch 13, Val Loss: 97.81471
Epoch 14, Val Loss: 96.79829
Epoch 15, Val Loss: 96.86228
Epoch 16, Val Loss: 89.68996
Epoch 17, Val Loss: 93.59729
Epoch 18, Val Loss: 99.49985
Epoch 19, Val Loss: 99.65750
Epoch 20, Val Loss: 101.44849
Epoch 21, Val Loss: 89.47631
Epoch 22, Val Loss: 93.52231
Epoch 23, Val Loss: 91.14022
Epoch 24, Val Loss: 103.55347
Epoch 25, Val Loss: 92.12169
Epoch 26, Val Loss: 107.95864
Epoch 27, Val Loss: 96.52168
Epoch 28, Val Loss: 90.80264
Epoch 29, Val Loss: 86.80694
Epoch 30, Val Loss: 88.42974
Epoch 31, Val Loss: 95.45186
Epoch 32, Val Loss: 87.50552
Epoch 33, Val Loss: 81.80125
Epoch 34, Val Loss: 83.16830
Epoch 35, Val Loss: 84.81858
Epoch 36, Val Loss: 83.23866
Epoch 37, Val Loss: 83.28248
Epoch 38, Val Loss: 86.33579
Epoch 39, Val Loss: 89.66462
Epoch 40, Val Loss: 82.32978
Epoch 41, Val Loss: 78.60934
Epoch 42, Val Loss: 81.07279
Epoch 43, Val Loss: 87.50462
Epoch 44, Val Loss: 85.11945
Epoch 45, Val Loss: 84.71972
Epoch 46, Val Loss: 82.94714
Epoch 47, Val Loss: 90.16005
Epoch 48, Val Loss: 84.48946
Epoch 49, Val Loss: 82.32068
Epoch 50, Val Loss: 86.28574
Epoch 51, Val Loss: 83.58659
Epoch 52, Val Loss: 83.25695
Epoch 53, Val Loss: 87.72484
Epoch 54, Val Loss: 80.57423
Epoch 55, Val Loss: 85.17467
Epoch 56, Val Loss: 86.12186
Epoch 57, Val Loss: 87.66357
Epoch 58, Val Loss: 82.27222
Epoch 59, Val Loss: 80.47463
Epoch 60, Val Loss: 86.33452
Epoch 61, Val Loss: 86.62848
Epoch 62, Val Loss: 82.28886
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.40251675240721, 'MSE - std': 8.773356742002228, 'R2 - mean': 0.4958130549646619, 'R2 - std': 0.029133846358766903} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 428.93823
Epoch 1, Val Loss: 395.77542
Epoch 2, Val Loss: 194.05801
Epoch 3, Val Loss: 185.38889
Epoch 4, Val Loss: 143.40370
Epoch 5, Val Loss: 139.25914
Epoch 6, Val Loss: 130.35439
Epoch 7, Val Loss: 110.45757
Epoch 8, Val Loss: 117.75031
Epoch 9, Val Loss: 112.25231
Epoch 10, Val Loss: 96.02117
Epoch 11, Val Loss: 103.29879
Epoch 12, Val Loss: 105.85431
Epoch 13, Val Loss: 104.29553
Epoch 14, Val Loss: 96.49367
Epoch 15, Val Loss: 121.82578
Epoch 16, Val Loss: 104.47874
Epoch 17, Val Loss: 99.79149
Epoch 18, Val Loss: 111.89262
Epoch 19, Val Loss: 99.09166
Epoch 20, Val Loss: 101.81433
Epoch 21, Val Loss: 115.04381
Epoch 22, Val Loss: 103.67683
Epoch 23, Val Loss: 101.29373
Epoch 24, Val Loss: 90.02831
Epoch 25, Val Loss: 93.53494
Epoch 26, Val Loss: 91.14117
Epoch 27, Val Loss: 103.84936
Epoch 28, Val Loss: 90.73204
Epoch 29, Val Loss: 92.50047
Epoch 30, Val Loss: 85.61588
Epoch 31, Val Loss: 103.60075
Epoch 32, Val Loss: 90.97867
Epoch 33, Val Loss: 80.17548
Epoch 34, Val Loss: 82.85045
Epoch 35, Val Loss: 81.15617
Epoch 36, Val Loss: 77.64219
Epoch 37, Val Loss: 96.59337
Epoch 38, Val Loss: 78.39137
Epoch 39, Val Loss: 78.52446
Epoch 40, Val Loss: 85.30202
Epoch 41, Val Loss: 95.75749
Epoch 42, Val Loss: 78.17294
Epoch 43, Val Loss: 77.41261
Epoch 44, Val Loss: 85.94246
Epoch 45, Val Loss: 86.44131
Epoch 46, Val Loss: 77.67386
Epoch 47, Val Loss: 81.52913
Epoch 48, Val Loss: 80.53212
Epoch 49, Val Loss: 79.34795
Epoch 50, Val Loss: 77.64883
Epoch 51, Val Loss: 77.25961
Epoch 52, Val Loss: 78.60202
Epoch 53, Val Loss: 80.25793
Epoch 54, Val Loss: 81.99166
Epoch 55, Val Loss: 78.52719
Epoch 56, Val Loss: 76.46686
Epoch 57, Val Loss: 75.45837
Epoch 58, Val Loss: 81.96052
Epoch 59, Val Loss: 76.38806
Epoch 60, Val Loss: 81.13084
Epoch 61, Val Loss: 75.39491
Epoch 62, Val Loss: 80.94720
Epoch 63, Val Loss: 77.42258
Epoch 64, Val Loss: 81.44505
Epoch 65, Val Loss: 76.05622
Epoch 66, Val Loss: 80.97342
Epoch 67, Val Loss: 78.97308
Epoch 68, Val Loss: 77.53336
Epoch 69, Val Loss: 78.35277
Epoch 70, Val Loss: 79.43384
Epoch 71, Val Loss: 71.88786
Epoch 72, Val Loss: 84.80112
Epoch 73, Val Loss: 75.23528
Epoch 74, Val Loss: 75.64867
Epoch 75, Val Loss: 80.17371
Epoch 76, Val Loss: 76.52626
Epoch 77, Val Loss: 76.92844
Epoch 78, Val Loss: 81.83885
Epoch 79, Val Loss: 82.80114
Epoch 80, Val Loss: 80.04457
Epoch 81, Val Loss: 76.52013
Epoch 82, Val Loss: 72.22614
Epoch 83, Val Loss: 74.67538
Epoch 84, Val Loss: 89.05566
Epoch 85, Val Loss: 77.34030
Epoch 86, Val Loss: 76.46951
Epoch 87, Val Loss: 74.94061
Epoch 88, Val Loss: 81.29955
Epoch 89, Val Loss: 78.04290
Epoch 90, Val Loss: 83.82345
Epoch 91, Val Loss: 79.15299
Epoch 92, Val Loss: 73.59053
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 79.89989709155284, 'MSE - std': 8.402909864963043, 'R2 - mean': 0.5039706471517702, 'R2 - std': 0.03074426847543573} 
 

Results After CV: {'MSE - mean': 79.89989709155284, 'MSE - std': 8.402909864963043, 'R2 - mean': 0.5039706471517702, 'R2 - std': 0.03074426847543573}
Train time: 881.3914965777774
Inference time: 0.21236585220322013
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 85 finished with value: 79.89989709155284 and parameters: {'p_m': 0.24379974591504056, 'alpha': 3.205055963993749, 'K': 5, 'beta': 9.036515242935494}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1698.85645
Epoch 1, Val Loss: 415.24658
Epoch 2, Val Loss: 200.18689
Epoch 3, Val Loss: 175.46426
Epoch 4, Val Loss: 155.32797
Epoch 5, Val Loss: 142.97798
Epoch 6, Val Loss: 125.09433
Epoch 7, Val Loss: 130.02983
Epoch 8, Val Loss: 126.76017
Epoch 9, Val Loss: 124.50468
Epoch 10, Val Loss: 110.36703
Epoch 11, Val Loss: 137.12868
Epoch 12, Val Loss: 118.96344
Epoch 13, Val Loss: 109.25826
Epoch 14, Val Loss: 125.31491
Epoch 15, Val Loss: 113.22960
Epoch 16, Val Loss: 125.87708
Epoch 17, Val Loss: 112.44591
Epoch 18, Val Loss: 116.37791
Epoch 19, Val Loss: 109.19759
Epoch 20, Val Loss: 101.98721
Epoch 21, Val Loss: 105.96644
Epoch 22, Val Loss: 107.77683
Epoch 23, Val Loss: 115.55200
Epoch 24, Val Loss: 104.12482
Epoch 25, Val Loss: 100.51705
Epoch 26, Val Loss: 100.85960
Epoch 27, Val Loss: 100.22555
Epoch 28, Val Loss: 103.67554
Epoch 29, Val Loss: 109.73345
Epoch 30, Val Loss: 109.32465
Epoch 31, Val Loss: 105.47600
Epoch 32, Val Loss: 122.11702
Epoch 33, Val Loss: 102.59995
Epoch 34, Val Loss: 106.66408
Epoch 35, Val Loss: 104.91743
Epoch 36, Val Loss: 107.65282
Epoch 37, Val Loss: 103.41371
Epoch 38, Val Loss: 105.26170
Epoch 39, Val Loss: 104.79486
Epoch 40, Val Loss: 95.44791
Epoch 41, Val Loss: 96.75772
Epoch 42, Val Loss: 98.21313
Epoch 43, Val Loss: 101.73666
Epoch 44, Val Loss: 97.67072
Epoch 45, Val Loss: 96.50188
Epoch 46, Val Loss: 99.29619
Epoch 47, Val Loss: 92.48924
Epoch 48, Val Loss: 94.77271
Epoch 49, Val Loss: 93.05874
Epoch 50, Val Loss: 119.29661
Epoch 51, Val Loss: 98.70812
Epoch 52, Val Loss: 92.36816
Epoch 53, Val Loss: 99.63802
Epoch 54, Val Loss: 95.36388
Epoch 55, Val Loss: 100.25585
Epoch 56, Val Loss: 98.77636
Epoch 57, Val Loss: 92.23299
Epoch 58, Val Loss: 102.38090
Epoch 59, Val Loss: 91.23091
Epoch 60, Val Loss: 90.77571
Epoch 61, Val Loss: 91.11012
Epoch 62, Val Loss: 92.09451
Epoch 63, Val Loss: 88.95362
Epoch 64, Val Loss: 91.94035
Epoch 65, Val Loss: 86.60172
Epoch 66, Val Loss: 96.46926
Epoch 67, Val Loss: 94.14685
Epoch 68, Val Loss: 87.73814
Epoch 69, Val Loss: 85.49726
Epoch 70, Val Loss: 85.21565
Epoch 71, Val Loss: 89.54476
Epoch 72, Val Loss: 93.83500
Epoch 73, Val Loss: 85.96128
Epoch 74, Val Loss: 88.72321
Epoch 75, Val Loss: 88.02002
Epoch 76, Val Loss: 84.94807
Epoch 77, Val Loss: 87.88634
Epoch 78, Val Loss: 84.56770
Epoch 79, Val Loss: 95.52968
Epoch 80, Val Loss: 93.78967
Epoch 81, Val Loss: 90.00526
Epoch 82, Val Loss: 92.62714
Epoch 83, Val Loss: 88.37579
Epoch 84, Val Loss: 89.50832
Epoch 85, Val Loss: 87.10863
Epoch 86, Val Loss: 86.47287
Epoch 87, Val Loss: 86.02727
Epoch 88, Val Loss: 89.38882
Epoch 89, Val Loss: 97.60269
Epoch 90, Val Loss: 87.37298
Epoch 91, Val Loss: 83.16245
Epoch 92, Val Loss: 87.72796
Epoch 93, Val Loss: 87.01742
Epoch 94, Val Loss: 87.91431
Epoch 95, Val Loss: 86.31430
Epoch 96, Val Loss: 85.97253
Epoch 97, Val Loss: 85.58432
Epoch 98, Val Loss: 85.43168
Epoch 99, Val Loss: 84.72359
DID NOT SAVE RESULTS
{'MSE - mean': 86.77169733615779, 'MSE - std': 0.0, 'R2 - mean': 0.4943524536153473, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1142.76379
Epoch 1, Val Loss: 413.60663
Epoch 2, Val Loss: 151.01219
Epoch 3, Val Loss: 130.26015
Epoch 4, Val Loss: 122.85285
Epoch 5, Val Loss: 111.80093
Epoch 6, Val Loss: 115.75343
Epoch 7, Val Loss: 110.42130
Epoch 8, Val Loss: 110.89982
Epoch 9, Val Loss: 99.25349
Epoch 10, Val Loss: 87.89309
Epoch 11, Val Loss: 93.74142
Epoch 12, Val Loss: 92.27238
Epoch 13, Val Loss: 95.87282
Epoch 14, Val Loss: 97.26451
Epoch 15, Val Loss: 104.76923
Epoch 16, Val Loss: 99.53669
Epoch 17, Val Loss: 88.50130
Epoch 18, Val Loss: 85.86653
Epoch 19, Val Loss: 88.87450
Epoch 20, Val Loss: 76.01489
Epoch 21, Val Loss: 80.86885
Epoch 22, Val Loss: 90.63588
Epoch 23, Val Loss: 80.78841
Epoch 24, Val Loss: 84.97840
Epoch 25, Val Loss: 81.76441
Epoch 26, Val Loss: 82.86582
Epoch 27, Val Loss: 87.97526
Epoch 28, Val Loss: 81.26369
Epoch 29, Val Loss: 85.45242
Epoch 30, Val Loss: 79.95390
Epoch 31, Val Loss: 79.39835
Epoch 32, Val Loss: 75.30133
Epoch 33, Val Loss: 83.48696
Epoch 34, Val Loss: 93.35017
Epoch 35, Val Loss: 83.61409
Epoch 36, Val Loss: 93.55687
Epoch 37, Val Loss: 79.32040
Epoch 38, Val Loss: 80.21857
Epoch 39, Val Loss: 89.70453
Epoch 40, Val Loss: 77.46227
Epoch 41, Val Loss: 82.95203
Epoch 42, Val Loss: 75.53574
Epoch 43, Val Loss: 81.80006
Epoch 44, Val Loss: 80.64805
Epoch 45, Val Loss: 83.29855
Epoch 46, Val Loss: 74.74954
Epoch 47, Val Loss: 79.44733
Epoch 48, Val Loss: 76.95105
Epoch 49, Val Loss: 76.95013
Epoch 50, Val Loss: 76.15695
Epoch 51, Val Loss: 78.00005
Epoch 52, Val Loss: 75.84553
Epoch 53, Val Loss: 76.76997
Epoch 54, Val Loss: 69.04564
Epoch 55, Val Loss: 76.04131
Epoch 56, Val Loss: 73.58667
Epoch 57, Val Loss: 74.26742
Epoch 58, Val Loss: 72.68194
Epoch 59, Val Loss: 90.72922
Epoch 60, Val Loss: 82.56333
Epoch 61, Val Loss: 72.16328
Epoch 62, Val Loss: 94.58327
Epoch 63, Val Loss: 70.64339
Epoch 64, Val Loss: 74.88059
Epoch 65, Val Loss: 69.88864
Epoch 66, Val Loss: 73.65143
Epoch 67, Val Loss: 72.72599
Epoch 68, Val Loss: 77.32429
Epoch 69, Val Loss: 71.48236
Epoch 70, Val Loss: 75.21247
Epoch 71, Val Loss: 71.98431
Epoch 72, Val Loss: 73.71674
Epoch 73, Val Loss: 69.62701
Epoch 74, Val Loss: 69.85304
Epoch 75, Val Loss: 75.32185
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 81.30944978498715, 'MSE - std': 5.462247551170634, 'R2 - mean': 0.5052243881742728, 'R2 - std': 0.010871934558925489} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1230.88232
Epoch 1, Val Loss: 449.45493
Epoch 2, Val Loss: 143.69176
Epoch 3, Val Loss: 120.87971
Epoch 4, Val Loss: 112.27503
Epoch 5, Val Loss: 103.12781
Epoch 6, Val Loss: 96.78191
Epoch 7, Val Loss: 92.68275
Epoch 8, Val Loss: 94.34544
Epoch 9, Val Loss: 85.48429
Epoch 10, Val Loss: 96.63240
Epoch 11, Val Loss: 86.92460
Epoch 12, Val Loss: 90.49525
Epoch 13, Val Loss: 86.24718
Epoch 14, Val Loss: 84.16849
Epoch 15, Val Loss: 94.60152
Epoch 16, Val Loss: 99.34810
Epoch 17, Val Loss: 94.51375
Epoch 18, Val Loss: 87.30017
Epoch 19, Val Loss: 83.80109
Epoch 20, Val Loss: 97.71258
Epoch 21, Val Loss: 79.58622
Epoch 22, Val Loss: 85.69523
Epoch 23, Val Loss: 98.69565
Epoch 24, Val Loss: 92.54816
Epoch 25, Val Loss: 83.20935
Epoch 26, Val Loss: 81.05568
Epoch 27, Val Loss: 90.57213
Epoch 28, Val Loss: 84.02833
Epoch 29, Val Loss: 78.80450
Epoch 30, Val Loss: 76.65988
Epoch 31, Val Loss: 81.97061
Epoch 32, Val Loss: 86.93375
Epoch 33, Val Loss: 87.25117
Epoch 34, Val Loss: 79.70607
Epoch 35, Val Loss: 85.05750
Epoch 36, Val Loss: 82.01661
Epoch 37, Val Loss: 86.87904
Epoch 38, Val Loss: 78.44673
Epoch 39, Val Loss: 90.85929
Epoch 40, Val Loss: 103.27895
Epoch 41, Val Loss: 77.49314
Epoch 42, Val Loss: 82.94888
Epoch 43, Val Loss: 79.32674
Epoch 44, Val Loss: 77.78897
Epoch 45, Val Loss: 78.63844
Epoch 46, Val Loss: 82.27252
Epoch 47, Val Loss: 78.20395
Epoch 48, Val Loss: 75.59030
Epoch 49, Val Loss: 75.60323
Epoch 50, Val Loss: 74.36932
Epoch 51, Val Loss: 72.66885
Epoch 52, Val Loss: 75.32639
Epoch 53, Val Loss: 84.79350
Epoch 54, Val Loss: 79.05379
Epoch 55, Val Loss: 81.89737
Epoch 56, Val Loss: 77.19965
Epoch 57, Val Loss: 77.41664
Epoch 58, Val Loss: 81.32926
Epoch 59, Val Loss: 83.00660
Epoch 60, Val Loss: 72.57330
Epoch 61, Val Loss: 76.78208
Epoch 62, Val Loss: 82.69437
Epoch 63, Val Loss: 72.26915
Epoch 64, Val Loss: 75.84698
Epoch 65, Val Loss: 76.50815
Epoch 66, Val Loss: 72.59686
Epoch 67, Val Loss: 74.77460
Epoch 68, Val Loss: 74.34451
Epoch 69, Val Loss: 70.67940
Epoch 70, Val Loss: 92.89284
Epoch 71, Val Loss: 79.96265
Epoch 72, Val Loss: 73.10529
Epoch 73, Val Loss: 74.41236
Epoch 74, Val Loss: 72.08110
Epoch 75, Val Loss: 71.54147
Epoch 76, Val Loss: 77.38296
Epoch 77, Val Loss: 71.23566
Epoch 78, Val Loss: 68.20927
Epoch 79, Val Loss: 83.47012
Epoch 80, Val Loss: 77.67024
Epoch 81, Val Loss: 70.66072
Epoch 82, Val Loss: 71.92758
Epoch 83, Val Loss: 77.93207
Epoch 84, Val Loss: 71.06461
Epoch 85, Val Loss: 101.14536
Epoch 86, Val Loss: 71.44418
Epoch 87, Val Loss: 69.92041
Epoch 88, Val Loss: 74.98364
Epoch 89, Val Loss: 68.92485
Epoch 90, Val Loss: 70.14499
Epoch 91, Val Loss: 70.51589
Epoch 92, Val Loss: 73.64867
Epoch 93, Val Loss: 68.87986
Epoch 94, Val Loss: 72.19493
Epoch 95, Val Loss: 72.72471
Epoch 96, Val Loss: 72.91267
Epoch 97, Val Loss: 69.09627
Epoch 98, Val Loss: 76.16440
Epoch 99, Val Loss: 70.89134
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 77.1722821937163, 'MSE - std': 7.356838784199601, 'R2 - mean': 0.5157925127571011, 'R2 - std': 0.01738303258253291} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1536.77173
Epoch 1, Val Loss: 351.41611
Epoch 2, Val Loss: 148.23178
Epoch 3, Val Loss: 140.50815
Epoch 4, Val Loss: 128.14653
Epoch 5, Val Loss: 118.55148
Epoch 6, Val Loss: 117.95891
Epoch 7, Val Loss: 103.88937
Epoch 8, Val Loss: 102.85047
Epoch 9, Val Loss: 101.80170
Epoch 10, Val Loss: 105.02242
Epoch 11, Val Loss: 102.48100
Epoch 12, Val Loss: 104.22307
Epoch 13, Val Loss: 103.85233
Epoch 14, Val Loss: 98.68114
Epoch 15, Val Loss: 94.04116
Epoch 16, Val Loss: 96.17519
Epoch 17, Val Loss: 101.21083
Epoch 18, Val Loss: 99.23202
Epoch 19, Val Loss: 100.51555
Epoch 20, Val Loss: 94.51440
Epoch 21, Val Loss: 97.82294
Epoch 22, Val Loss: 92.59032
Epoch 23, Val Loss: 99.68214
Epoch 24, Val Loss: 91.54340
Epoch 25, Val Loss: 91.42281
Epoch 26, Val Loss: 88.25380
Epoch 27, Val Loss: 87.93696
Epoch 28, Val Loss: 95.17278
Epoch 29, Val Loss: 88.71080
Epoch 30, Val Loss: 87.46952
Epoch 31, Val Loss: 92.28740
Epoch 32, Val Loss: 90.04023
Epoch 33, Val Loss: 93.34933
Epoch 34, Val Loss: 91.03222
Epoch 35, Val Loss: 101.68142
Epoch 36, Val Loss: 86.67239
Epoch 37, Val Loss: 87.79267
Epoch 38, Val Loss: 89.34322
Epoch 39, Val Loss: 83.99631
Epoch 40, Val Loss: 86.46185
Epoch 41, Val Loss: 90.48839
Epoch 42, Val Loss: 97.24196
Epoch 43, Val Loss: 86.34660
Epoch 44, Val Loss: 85.84070
Epoch 45, Val Loss: 90.04720
Epoch 46, Val Loss: 83.97353
Epoch 47, Val Loss: 88.37119
Epoch 48, Val Loss: 81.26775
Epoch 49, Val Loss: 101.36972
Epoch 50, Val Loss: 86.31364
Epoch 51, Val Loss: 81.12450
Epoch 52, Val Loss: 87.56408
Epoch 53, Val Loss: 88.47224
Epoch 54, Val Loss: 84.59560
Epoch 55, Val Loss: 93.00786
Epoch 56, Val Loss: 84.64344
Epoch 57, Val Loss: 81.74281
Epoch 58, Val Loss: 79.61066
Epoch 59, Val Loss: 86.47001
Epoch 60, Val Loss: 81.70056
Epoch 61, Val Loss: 78.99272
Epoch 62, Val Loss: 83.19518
Epoch 63, Val Loss: 81.59857
Epoch 64, Val Loss: 83.11905
Epoch 65, Val Loss: 81.45981
Epoch 66, Val Loss: 78.24064
Epoch 67, Val Loss: 82.64159
Epoch 68, Val Loss: 89.22287
Epoch 69, Val Loss: 80.90263
Epoch 70, Val Loss: 89.47367
Epoch 71, Val Loss: 82.83913
Epoch 72, Val Loss: 84.92787
Epoch 73, Val Loss: 98.16507
Epoch 74, Val Loss: 87.08936
Epoch 75, Val Loss: 93.40472
Epoch 76, Val Loss: 83.38577
Epoch 77, Val Loss: 83.67143
Epoch 78, Val Loss: 79.03448
Epoch 79, Val Loss: 80.02763
Epoch 80, Val Loss: 80.89494
Epoch 81, Val Loss: 80.30542
Epoch 82, Val Loss: 78.46750
Epoch 83, Val Loss: 81.46102
Epoch 84, Val Loss: 81.56154
Epoch 85, Val Loss: 79.67219
Epoch 86, Val Loss: 79.47308
Epoch 87, Val Loss: 85.83947
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.01570090577468, 'MSE - std': 8.052788187254066, 'R2 - mean': 0.5041873258406383, 'R2 - std': 0.025113113236358675} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1388.99927
Epoch 1, Val Loss: 390.24915
Epoch 2, Val Loss: 176.45139
Epoch 3, Val Loss: 135.12271
Epoch 4, Val Loss: 142.15274
Epoch 5, Val Loss: 113.95337
Epoch 6, Val Loss: 123.75835
Epoch 7, Val Loss: 106.17878
Epoch 8, Val Loss: 107.81283
Epoch 9, Val Loss: 103.71239
Epoch 10, Val Loss: 104.92665
Epoch 11, Val Loss: 97.90898
Epoch 12, Val Loss: 93.66704
Epoch 13, Val Loss: 95.22638
Epoch 14, Val Loss: 97.82786
Epoch 15, Val Loss: 88.79871
Epoch 16, Val Loss: 114.78150
Epoch 17, Val Loss: 101.48262
Epoch 18, Val Loss: 93.11684
Epoch 19, Val Loss: 109.29788
Epoch 20, Val Loss: 98.30135
Epoch 21, Val Loss: 92.25777
Epoch 22, Val Loss: 97.01724
Epoch 23, Val Loss: 98.50795
Epoch 24, Val Loss: 89.08286
Epoch 25, Val Loss: 107.22882
Epoch 26, Val Loss: 90.87943
Epoch 27, Val Loss: 100.96465
Epoch 28, Val Loss: 91.25761
Epoch 29, Val Loss: 96.45257
Epoch 30, Val Loss: 95.73631
Epoch 31, Val Loss: 97.69664
Epoch 32, Val Loss: 89.84746
Epoch 33, Val Loss: 91.48331
Epoch 34, Val Loss: 84.61052
Epoch 35, Val Loss: 89.29614
Epoch 36, Val Loss: 88.95734
Epoch 37, Val Loss: 86.29437
Epoch 38, Val Loss: 92.68174
Epoch 39, Val Loss: 90.60403
Epoch 40, Val Loss: 81.17146
Epoch 41, Val Loss: 86.81759
Epoch 42, Val Loss: 81.35922
Epoch 43, Val Loss: 79.80991
Epoch 44, Val Loss: 81.47771
Epoch 45, Val Loss: 83.63021
Epoch 46, Val Loss: 80.80809
Epoch 47, Val Loss: 80.19363
Epoch 48, Val Loss: 88.92772
Epoch 49, Val Loss: 79.62217
Epoch 50, Val Loss: 89.04797
Epoch 51, Val Loss: 90.78654
Epoch 52, Val Loss: 78.20065
Epoch 53, Val Loss: 75.57231
Epoch 54, Val Loss: 89.40053
Epoch 55, Val Loss: 92.87848
Epoch 56, Val Loss: 78.89303
Epoch 57, Val Loss: 80.17772
Epoch 58, Val Loss: 88.95211
Epoch 59, Val Loss: 81.29662
Epoch 60, Val Loss: 84.26966
Epoch 61, Val Loss: 81.54948
Epoch 62, Val Loss: 77.16194
Epoch 63, Val Loss: 84.12674
Epoch 64, Val Loss: 82.28294
Epoch 65, Val Loss: 74.25895
Epoch 66, Val Loss: 76.08427
Epoch 67, Val Loss: 78.28412
Epoch 68, Val Loss: 80.75495
Epoch 69, Val Loss: 77.09697
Epoch 70, Val Loss: 80.13342
Epoch 71, Val Loss: 72.30080
Epoch 72, Val Loss: 92.20889
Epoch 73, Val Loss: 76.34800
Epoch 74, Val Loss: 86.29807
Epoch 75, Val Loss: 75.27647
Epoch 76, Val Loss: 77.55139
Epoch 77, Val Loss: 77.74030
Epoch 78, Val Loss: 75.21654
Epoch 79, Val Loss: 75.89570
Epoch 80, Val Loss: 76.68501
Epoch 81, Val Loss: 90.65411
Epoch 82, Val Loss: 74.28034
Epoch 83, Val Loss: 79.93088
Epoch 84, Val Loss: 87.37211
Epoch 85, Val Loss: 76.36586
Epoch 86, Val Loss: 82.97855
Epoch 87, Val Loss: 78.27187
Epoch 88, Val Loss: 90.64900
Epoch 89, Val Loss: 81.29391
Epoch 90, Val Loss: 83.47438
Epoch 91, Val Loss: 86.87633
Epoch 92, Val Loss: 78.48805
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 78.71558350393569, 'MSE - std': 7.65761967619711, 'R2 - mean': 0.5111395555675431, 'R2 - std': 0.026417205715979383} 
 

Results After CV: {'MSE - mean': 78.71558350393569, 'MSE - std': 7.65761967619711, 'R2 - mean': 0.5111395555675431, 'R2 - std': 0.026417205715979383}
Train time: 430.8019823596231
Inference time: 0.18271656660363078
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 86 finished with value: 78.71558350393569 and parameters: {'p_m': 0.2133112828626138, 'alpha': 1.6521478063152955, 'K': 2, 'beta': 4.957134525149405}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1383.50232
Epoch 1, Val Loss: 340.35718
Epoch 2, Val Loss: 191.30820
Epoch 3, Val Loss: 166.01691
Epoch 4, Val Loss: 128.64722
Epoch 5, Val Loss: 131.01871
Epoch 6, Val Loss: 130.90306
Epoch 7, Val Loss: 133.59268
Epoch 8, Val Loss: 112.16578
Epoch 9, Val Loss: 106.92479
Epoch 10, Val Loss: 119.65263
Epoch 11, Val Loss: 115.32949
Epoch 12, Val Loss: 109.06725
Epoch 13, Val Loss: 105.47116
Epoch 14, Val Loss: 100.07756
Epoch 15, Val Loss: 103.11248
Epoch 16, Val Loss: 101.35625
Epoch 17, Val Loss: 103.28586
Epoch 18, Val Loss: 109.70895
Epoch 19, Val Loss: 97.25668
Epoch 20, Val Loss: 111.02545
Epoch 21, Val Loss: 106.17806
Epoch 22, Val Loss: 104.27248
Epoch 23, Val Loss: 115.14622
Epoch 24, Val Loss: 97.33768
Epoch 25, Val Loss: 101.67311
Epoch 26, Val Loss: 102.12994
Epoch 27, Val Loss: 93.06693
Epoch 28, Val Loss: 105.44320
Epoch 29, Val Loss: 104.97981
Epoch 30, Val Loss: 99.70035
Epoch 31, Val Loss: 98.18079
Epoch 32, Val Loss: 103.35413
Epoch 33, Val Loss: 102.60248
Epoch 34, Val Loss: 100.10448
Epoch 35, Val Loss: 96.15883
Epoch 36, Val Loss: 107.16113
Epoch 37, Val Loss: 95.25510
Epoch 38, Val Loss: 102.09634
Epoch 39, Val Loss: 93.82775
Epoch 40, Val Loss: 97.88477
Epoch 41, Val Loss: 91.82294
Epoch 42, Val Loss: 100.31575
Epoch 43, Val Loss: 111.65460
Epoch 44, Val Loss: 94.66795
Epoch 45, Val Loss: 90.74112
Epoch 46, Val Loss: 90.06898
Epoch 47, Val Loss: 91.43230
Epoch 48, Val Loss: 90.84436
Epoch 49, Val Loss: 92.73187
Epoch 50, Val Loss: 88.25999
Epoch 51, Val Loss: 92.57965
Epoch 52, Val Loss: 87.94392
Epoch 53, Val Loss: 92.57906
Epoch 54, Val Loss: 94.52238
Epoch 55, Val Loss: 97.74877
Epoch 56, Val Loss: 92.57938
Epoch 57, Val Loss: 92.55084
Epoch 58, Val Loss: 88.21594
Epoch 59, Val Loss: 93.63501
Epoch 60, Val Loss: 95.98572
Epoch 61, Val Loss: 96.04205
Epoch 62, Val Loss: 89.14436
Epoch 63, Val Loss: 97.88407
Epoch 64, Val Loss: 99.50116
Epoch 65, Val Loss: 90.32727
Epoch 66, Val Loss: 86.31737
Epoch 67, Val Loss: 98.41119
Epoch 68, Val Loss: 91.18729
Epoch 69, Val Loss: 86.81228
Epoch 70, Val Loss: 98.26009
Epoch 71, Val Loss: 90.65758
Epoch 72, Val Loss: 91.09886
Epoch 73, Val Loss: 93.34118
Epoch 74, Val Loss: 86.48900
Epoch 75, Val Loss: 84.73143
Epoch 76, Val Loss: 87.27764
Epoch 77, Val Loss: 96.01414
Epoch 78, Val Loss: 90.05233
Epoch 79, Val Loss: 89.51086
Epoch 80, Val Loss: 87.52573
Epoch 81, Val Loss: 94.91764
Epoch 82, Val Loss: 85.91772
Epoch 83, Val Loss: 91.63129
Epoch 84, Val Loss: 86.64729
Epoch 85, Val Loss: 91.87350
Epoch 86, Val Loss: 90.31210
Epoch 87, Val Loss: 89.91383
Epoch 88, Val Loss: 91.17003
Epoch 89, Val Loss: 91.17015
Epoch 90, Val Loss: 92.61889
Epoch 91, Val Loss: 85.53490
Epoch 92, Val Loss: 83.71622
Epoch 93, Val Loss: 95.73161
Epoch 94, Val Loss: 86.37480
Epoch 95, Val Loss: 89.63503
Epoch 96, Val Loss: 86.95284
Epoch 97, Val Loss: 121.74387
Epoch 98, Val Loss: 84.55315
Epoch 99, Val Loss: 87.00296
DID NOT SAVE RESULTS
{'MSE - mean': 88.70656796491826, 'MSE - std': 0.0, 'R2 - mean': 0.4830773187955887, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1437.52856
Epoch 1, Val Loss: 393.19669
Epoch 2, Val Loss: 163.23180
Epoch 3, Val Loss: 133.33722
Epoch 4, Val Loss: 131.36560
Epoch 5, Val Loss: 111.59645
Epoch 6, Val Loss: 95.62354
Epoch 7, Val Loss: 93.26155
Epoch 8, Val Loss: 92.30791
Epoch 9, Val Loss: 97.87331
Epoch 10, Val Loss: 89.95559
Epoch 11, Val Loss: 88.16603
Epoch 12, Val Loss: 87.08784
Epoch 13, Val Loss: 91.71342
Epoch 14, Val Loss: 82.93959
Epoch 15, Val Loss: 81.48723
Epoch 16, Val Loss: 90.60757
Epoch 17, Val Loss: 81.35807
Epoch 18, Val Loss: 82.98437
Epoch 19, Val Loss: 90.16217
Epoch 20, Val Loss: 90.16562
Epoch 21, Val Loss: 90.80540
Epoch 22, Val Loss: 85.03127
Epoch 23, Val Loss: 87.60873
Epoch 24, Val Loss: 83.60743
Epoch 25, Val Loss: 79.57166
Epoch 26, Val Loss: 81.44641
Epoch 27, Val Loss: 78.73103
Epoch 28, Val Loss: 98.94867
Epoch 29, Val Loss: 83.78232
Epoch 30, Val Loss: 94.94982
Epoch 31, Val Loss: 76.93494
Epoch 32, Val Loss: 81.17314
Epoch 33, Val Loss: 79.45042
Epoch 34, Val Loss: 92.05702
Epoch 35, Val Loss: 80.63988
Epoch 36, Val Loss: 76.64304
Epoch 37, Val Loss: 97.79140
Epoch 38, Val Loss: 83.59188
Epoch 39, Val Loss: 83.00940
Epoch 40, Val Loss: 77.99640
Epoch 41, Val Loss: 71.42877
Epoch 42, Val Loss: 77.64713
Epoch 43, Val Loss: 87.44168
Epoch 44, Val Loss: 74.29247
Epoch 45, Val Loss: 92.86275
Epoch 46, Val Loss: 77.59815
Epoch 47, Val Loss: 81.22085
Epoch 48, Val Loss: 82.38101
Epoch 49, Val Loss: 81.84076
Epoch 50, Val Loss: 75.73363
Epoch 51, Val Loss: 71.16821
Epoch 52, Val Loss: 81.50562
Epoch 53, Val Loss: 89.31133
Epoch 54, Val Loss: 83.06301
Epoch 55, Val Loss: 75.68855
Epoch 56, Val Loss: 72.61111
Epoch 57, Val Loss: 71.49200
Epoch 58, Val Loss: 75.44720
Epoch 59, Val Loss: 81.24948
Epoch 60, Val Loss: 68.78794
Epoch 61, Val Loss: 72.19628
Epoch 62, Val Loss: 69.52115
Epoch 63, Val Loss: 76.16353
Epoch 64, Val Loss: 71.66663
Epoch 65, Val Loss: 70.89108
Epoch 66, Val Loss: 71.26962
Epoch 67, Val Loss: 90.10326
Epoch 68, Val Loss: 69.43795
Epoch 69, Val Loss: 69.12068
Epoch 70, Val Loss: 67.35707
Epoch 71, Val Loss: 72.48996
Epoch 72, Val Loss: 67.14722
Epoch 73, Val Loss: 66.83442
Epoch 74, Val Loss: 84.17670
Epoch 75, Val Loss: 69.85765
Epoch 76, Val Loss: 66.01127
Epoch 77, Val Loss: 72.75172
Epoch 78, Val Loss: 67.78689
Epoch 79, Val Loss: 66.26339
Epoch 80, Val Loss: 68.39619
Epoch 81, Val Loss: 70.37897
Epoch 82, Val Loss: 66.27242
Epoch 83, Val Loss: 64.66412
Epoch 84, Val Loss: 71.37542
Epoch 85, Val Loss: 68.98116
Epoch 86, Val Loss: 69.26462
Epoch 87, Val Loss: 68.97569
Epoch 88, Val Loss: 73.07018
Epoch 89, Val Loss: 69.94583
Epoch 90, Val Loss: 75.90720
Epoch 91, Val Loss: 69.32635
Epoch 92, Val Loss: 65.74235
Epoch 93, Val Loss: 69.29433
Epoch 94, Val Loss: 74.71591
Epoch 95, Val Loss: 71.26631
Epoch 96, Val Loss: 67.70399
Epoch 97, Val Loss: 66.23521
Epoch 98, Val Loss: 71.40032
Epoch 99, Val Loss: 70.71806
DID NOT SAVE RESULTS
{'MSE - mean': 80.42200537105894, 'MSE - std': 8.28456259385932, 'R2 - mean': 0.5114209174084476, 'R2 - std': 0.0283435986128589} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 644.36261
Epoch 1, Val Loss: 312.97345
Epoch 2, Val Loss: 184.15753
Epoch 3, Val Loss: 135.72203
Epoch 4, Val Loss: 107.22421
Epoch 5, Val Loss: 99.57981
Epoch 6, Val Loss: 113.10761
Epoch 7, Val Loss: 90.98070
Epoch 8, Val Loss: 81.43678
Epoch 9, Val Loss: 88.73858
Epoch 10, Val Loss: 95.20712
Epoch 11, Val Loss: 93.69076
Epoch 12, Val Loss: 86.33766
Epoch 13, Val Loss: 95.68040
Epoch 14, Val Loss: 101.50996
Epoch 15, Val Loss: 100.36483
Epoch 16, Val Loss: 81.03211
Epoch 17, Val Loss: 88.03510
Epoch 18, Val Loss: 80.64492
Epoch 19, Val Loss: 91.66364
Epoch 20, Val Loss: 89.88518
Epoch 21, Val Loss: 92.33147
Epoch 22, Val Loss: 82.58518
Epoch 23, Val Loss: 84.91216
Epoch 24, Val Loss: 81.38213
Epoch 25, Val Loss: 96.02180
Epoch 26, Val Loss: 86.76225
Epoch 27, Val Loss: 82.46661
Epoch 28, Val Loss: 84.32939
Epoch 29, Val Loss: 86.82372
Epoch 30, Val Loss: 80.05006
Epoch 31, Val Loss: 85.00529
Epoch 32, Val Loss: 86.01871
Epoch 33, Val Loss: 85.05180
Epoch 34, Val Loss: 81.83781
Epoch 35, Val Loss: 82.50964
Epoch 36, Val Loss: 84.22090
Epoch 37, Val Loss: 82.68465
Epoch 38, Val Loss: 77.78789
Epoch 39, Val Loss: 87.11782
Epoch 40, Val Loss: 87.26950
Epoch 41, Val Loss: 87.93199
Epoch 42, Val Loss: 84.52731
Epoch 43, Val Loss: 85.54385
Epoch 44, Val Loss: 85.14804
Epoch 45, Val Loss: 72.97324
Epoch 46, Val Loss: 74.48112
Epoch 47, Val Loss: 80.10800
Epoch 48, Val Loss: 76.11241
Epoch 49, Val Loss: 87.40196
Epoch 50, Val Loss: 79.44037
Epoch 51, Val Loss: 94.97413
Epoch 52, Val Loss: 75.55106
Epoch 53, Val Loss: 86.62838
Epoch 54, Val Loss: 74.10928
Epoch 55, Val Loss: 74.01994
Epoch 56, Val Loss: 72.60596
Epoch 57, Val Loss: 75.97958
Epoch 58, Val Loss: 73.67038
Epoch 59, Val Loss: 75.09866
Epoch 60, Val Loss: 72.83146
Epoch 61, Val Loss: 69.75806
Epoch 62, Val Loss: 69.25865
Epoch 63, Val Loss: 70.39015
Epoch 64, Val Loss: 69.57811
Epoch 65, Val Loss: 76.71529
Epoch 66, Val Loss: 82.71037
Epoch 67, Val Loss: 70.32245
Epoch 68, Val Loss: 71.12958
Epoch 69, Val Loss: 72.28574
Epoch 70, Val Loss: 72.58089
Epoch 71, Val Loss: 83.46356
Epoch 72, Val Loss: 71.81972
Epoch 73, Val Loss: 72.58006
Epoch 74, Val Loss: 70.99299
Epoch 75, Val Loss: 68.62324
Epoch 76, Val Loss: 71.21251
Epoch 77, Val Loss: 79.48757
Epoch 78, Val Loss: 90.92692
Epoch 79, Val Loss: 84.68294
Epoch 80, Val Loss: 69.43936
Epoch 81, Val Loss: 82.44703
Epoch 82, Val Loss: 73.89267
Epoch 83, Val Loss: 68.68439
Epoch 84, Val Loss: 81.47356
Epoch 85, Val Loss: 67.88890
Epoch 86, Val Loss: 68.46335
Epoch 87, Val Loss: 69.53145
Epoch 88, Val Loss: 67.98290
Epoch 89, Val Loss: 67.47743
Epoch 90, Val Loss: 72.28594
Epoch 91, Val Loss: 68.20145
Epoch 92, Val Loss: 75.26743
Epoch 93, Val Loss: 70.03581
Epoch 94, Val Loss: 68.79131
Epoch 95, Val Loss: 70.70116
Epoch 96, Val Loss: 68.61896
Epoch 97, Val Loss: 68.08624
Epoch 98, Val Loss: 68.10751
Epoch 99, Val Loss: 75.01936
DID NOT SAVE RESULTS
{'MSE - mean': 76.34413775679518, 'MSE - std': 8.88898157683458, 'R2 - mean': 0.5215131763333205, 'R2 - std': 0.027189711938487397} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 517.03735
Epoch 1, Val Loss: 374.30148
Epoch 2, Val Loss: 173.43231
Epoch 3, Val Loss: 150.80931
Epoch 4, Val Loss: 125.99932
Epoch 5, Val Loss: 124.43404
Epoch 6, Val Loss: 112.63340
Epoch 7, Val Loss: 109.69438
Epoch 8, Val Loss: 104.09879
Epoch 9, Val Loss: 101.46851
Epoch 10, Val Loss: 108.11529
Epoch 11, Val Loss: 103.87067
Epoch 12, Val Loss: 100.65685
Epoch 13, Val Loss: 100.62281
Epoch 14, Val Loss: 97.65644
Epoch 15, Val Loss: 95.58754
Epoch 16, Val Loss: 90.73940
Epoch 17, Val Loss: 98.27821
Epoch 18, Val Loss: 97.61710
Epoch 19, Val Loss: 90.68502
Epoch 20, Val Loss: 94.19936
Epoch 21, Val Loss: 91.06223
Epoch 22, Val Loss: 92.98630
Epoch 23, Val Loss: 96.10935
Epoch 24, Val Loss: 86.17994
Epoch 25, Val Loss: 93.91388
Epoch 26, Val Loss: 92.86240
Epoch 27, Val Loss: 95.88632
Epoch 28, Val Loss: 85.96018
Epoch 29, Val Loss: 86.85480
Epoch 30, Val Loss: 91.65558
Epoch 31, Val Loss: 88.71490
Epoch 32, Val Loss: 99.50582
Epoch 33, Val Loss: 88.89675
Epoch 34, Val Loss: 86.96043
Epoch 35, Val Loss: 88.16954
Epoch 36, Val Loss: 85.61270
Epoch 37, Val Loss: 86.35526
Epoch 38, Val Loss: 106.65202
Epoch 39, Val Loss: 89.02678
Epoch 40, Val Loss: 97.29321
Epoch 41, Val Loss: 101.99899
Epoch 42, Val Loss: 85.71446
Epoch 43, Val Loss: 91.37424
Epoch 44, Val Loss: 92.35020
Epoch 45, Val Loss: 82.58397
Epoch 46, Val Loss: 89.62257
Epoch 47, Val Loss: 89.05098
Epoch 48, Val Loss: 95.20821
Epoch 49, Val Loss: 84.03389
Epoch 50, Val Loss: 86.78815
Epoch 51, Val Loss: 93.31568
Epoch 52, Val Loss: 86.40607
Epoch 53, Val Loss: 95.67085
Epoch 54, Val Loss: 96.11177
Epoch 55, Val Loss: 83.91660
Epoch 56, Val Loss: 84.97085
Epoch 57, Val Loss: 79.86456
Epoch 58, Val Loss: 80.15252
Epoch 59, Val Loss: 97.69772
Epoch 60, Val Loss: 84.45017
Epoch 61, Val Loss: 91.02299
Epoch 62, Val Loss: 82.20800
Epoch 63, Val Loss: 86.06464
Epoch 64, Val Loss: 84.39117
Epoch 65, Val Loss: 81.38536
Epoch 66, Val Loss: 80.75912
Epoch 67, Val Loss: 91.10047
Epoch 68, Val Loss: 83.46241
Epoch 69, Val Loss: 80.04897
Epoch 70, Val Loss: 88.41398
Epoch 71, Val Loss: 80.68295
Epoch 72, Val Loss: 94.77153
Epoch 73, Val Loss: 78.84071
Epoch 74, Val Loss: 86.24323
Epoch 75, Val Loss: 92.56678
Epoch 76, Val Loss: 82.23152
Epoch 77, Val Loss: 89.28275
Epoch 78, Val Loss: 79.12377
Epoch 79, Val Loss: 81.22240
Epoch 80, Val Loss: 80.67380
Epoch 81, Val Loss: 78.70155
Epoch 82, Val Loss: 79.13311
Epoch 83, Val Loss: 86.60574
Epoch 84, Val Loss: 76.56587
Epoch 85, Val Loss: 79.07685
Epoch 86, Val Loss: 77.79482
Epoch 87, Val Loss: 87.81609
Epoch 88, Val Loss: 76.79008
Epoch 89, Val Loss: 94.02620
Epoch 90, Val Loss: 77.31889
Epoch 91, Val Loss: 80.62283
Epoch 92, Val Loss: 79.50536
Epoch 93, Val Loss: 81.51004
Epoch 94, Val Loss: 79.37502
Epoch 95, Val Loss: 78.03543
Epoch 96, Val Loss: 87.28120
Epoch 97, Val Loss: 78.44513
Epoch 98, Val Loss: 81.02427
Epoch 99, Val Loss: 88.45741
DID NOT SAVE RESULTS
{'MSE - mean': 79.23128801841122, 'MSE - std': 9.179727937386124, 'R2 - mean': 0.5094564566885222, 'R2 - std': 0.03147306455134666} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 1038.67224
Epoch 1, Val Loss: 485.15738
Epoch 2, Val Loss: 178.21974
Epoch 3, Val Loss: 153.57407
Epoch 4, Val Loss: 122.89864
Epoch 5, Val Loss: 115.24423
Epoch 6, Val Loss: 120.25210
Epoch 7, Val Loss: 102.95715
Epoch 8, Val Loss: 103.05457
Epoch 9, Val Loss: 94.69350
Epoch 10, Val Loss: 93.04085
Epoch 11, Val Loss: 90.98587
Epoch 12, Val Loss: 89.86234
Epoch 13, Val Loss: 106.45673
Epoch 14, Val Loss: 92.15942
Epoch 15, Val Loss: 86.81755
Epoch 16, Val Loss: 92.39267
Epoch 17, Val Loss: 102.33159
Epoch 18, Val Loss: 92.99916
Epoch 19, Val Loss: 93.09320
Epoch 20, Val Loss: 94.25018
Epoch 21, Val Loss: 95.06197
Epoch 22, Val Loss: 98.62952
Epoch 23, Val Loss: 103.76617
Epoch 24, Val Loss: 104.17549
Epoch 25, Val Loss: 89.94279
Epoch 26, Val Loss: 93.25639
Epoch 27, Val Loss: 91.45623
Epoch 28, Val Loss: 91.90197
Epoch 29, Val Loss: 90.93147
Epoch 30, Val Loss: 87.95966
Epoch 31, Val Loss: 92.29396
Epoch 32, Val Loss: 100.57742
Epoch 33, Val Loss: 91.42401
Epoch 34, Val Loss: 110.25906
Epoch 35, Val Loss: 90.51052
Epoch 36, Val Loss: 97.26550
Early stopping applies.
DID NOT SAVE RESULTS
{'MSE - mean': 80.57717721425152, 'MSE - std': 8.64057838998411, 'R2 - mean': 0.499744268546962, 'R2 - std': 0.03420159978408665} 
 

Results After CV: {'MSE - mean': 80.57717721425152, 'MSE - std': 8.64057838998411, 'R2 - mean': 0.499744268546962, 'R2 - std': 0.03420159978408665}
Train time: 949.4175057720043
Inference time: 0.1772880356060341
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 87 finished with value: 80.57717721425152 and parameters: {'p_m': 0.12261457613145083, 'alpha': 4.354779793262104, 'K': 5, 'beta': 7.855907154538738}. Best is trial 56 with value: 77.02717411419609.
In get_device
On Device: cuda
In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 723.61755
Epoch 1, Val Loss: 457.05841
Epoch 2, Val Loss: 212.00061
Epoch 3, Val Loss: 174.84554
Epoch 4, Val Loss: 141.31482
Epoch 5, Val Loss: 150.27711
Epoch 6, Val Loss: 121.62421
Epoch 7, Val Loss: 124.65173
Epoch 8, Val Loss: 129.04817
Epoch 9, Val Loss: 108.82256
Epoch 10, Val Loss: 110.17572
Epoch 11, Val Loss: 119.02261
Epoch 12, Val Loss: 105.68219
Epoch 13, Val Loss: 127.63504
Epoch 14, Val Loss: 112.85039
Epoch 15, Val Loss: 107.01337
Epoch 16, Val Loss: 110.24881
Epoch 17, Val Loss: 97.73870
Epoch 18, Val Loss: 111.85271
Epoch 19, Val Loss: 104.42375
Epoch 20, Val Loss: 99.33549
Epoch 21, Val Loss: 97.07746
Epoch 22, Val Loss: 106.63309
Epoch 23, Val Loss: 100.92534
Epoch 24, Val Loss: 113.21412
Epoch 25, Val Loss: 103.04883
Epoch 26, Val Loss: 94.37563
Epoch 27, Val Loss: 98.33794
Epoch 28, Val Loss: 99.68172
Epoch 29, Val Loss: 109.52985
Epoch 30, Val Loss: 98.37131
Epoch 31, Val Loss: 97.07841
Epoch 32, Val Loss: 105.55898
Epoch 33, Val Loss: 92.76524
Epoch 34, Val Loss: 100.24845
Epoch 35, Val Loss: 90.81302
Epoch 36, Val Loss: 90.94779
Epoch 37, Val Loss: 88.13632
Epoch 38, Val Loss: 91.76358
Epoch 39, Val Loss: 93.87858
Epoch 40, Val Loss: 101.81983
Epoch 41, Val Loss: 86.89182
Epoch 42, Val Loss: 95.77347
Epoch 43, Val Loss: 89.01961
Epoch 44, Val Loss: 86.65875
Epoch 45, Val Loss: 92.86109
Epoch 46, Val Loss: 89.96172
Epoch 47, Val Loss: 86.40182
Epoch 48, Val Loss: 90.89265
Epoch 49, Val Loss: 88.61783
Epoch 50, Val Loss: 90.24036
Epoch 51, Val Loss: 89.18578
Epoch 52, Val Loss: 99.19835
Epoch 53, Val Loss: 96.06772
Epoch 54, Val Loss: 90.26470
Epoch 55, Val Loss: 90.08384
Epoch 56, Val Loss: 87.45309
Epoch 57, Val Loss: 89.78870
Epoch 58, Val Loss: 88.53685
Epoch 59, Val Loss: 94.81310
Epoch 60, Val Loss: 89.74502
Epoch 61, Val Loss: 91.28513
Epoch 62, Val Loss: 97.54042
Epoch 63, Val Loss: 85.65726
Epoch 64, Val Loss: 85.98636
Epoch 65, Val Loss: 86.93520
Epoch 66, Val Loss: 86.11919
Epoch 67, Val Loss: 95.98067
Epoch 68, Val Loss: 93.98723
Epoch 69, Val Loss: 85.29436
Epoch 70, Val Loss: 90.85747
Epoch 71, Val Loss: 85.03554
Epoch 72, Val Loss: 88.08276
Epoch 73, Val Loss: 85.21424
Epoch 74, Val Loss: 85.87217
Epoch 75, Val Loss: 87.26403
Epoch 76, Val Loss: 83.54596
Epoch 77, Val Loss: 89.34372
Epoch 78, Val Loss: 91.62291
Epoch 79, Val Loss: 90.89798
Epoch 80, Val Loss: 86.24352
Epoch 81, Val Loss: 89.97853
Epoch 82, Val Loss: 84.90377
Epoch 83, Val Loss: 88.08994
Epoch 84, Val Loss: 83.59928
Epoch 85, Val Loss: 82.98013
Epoch 86, Val Loss: 83.90007
Epoch 87, Val Loss: 83.68077
Epoch 88, Val Loss: 89.57966
Epoch 89, Val Loss: 91.77705
Epoch 90, Val Loss: 83.81714
Epoch 91, Val Loss: 84.89198
Epoch 92, Val Loss: 83.99502
Epoch 93, Val Loss: 84.96858
Epoch 94, Val Loss: 88.00935
Epoch 95, Val Loss: 88.63537
Epoch 96, Val Loss: 89.27917
Epoch 97, Val Loss: 87.68044
Epoch 98, Val Loss: 82.45236
Epoch 99, Val Loss: 84.15263
DID NOT SAVE RESULTS
{'MSE - mean': 86.87358974146369, 'MSE - std': 0.0, 'R2 - mean': 0.49375869267347516, 'R2 - std': 0.0} 
 

In get_device
On Device: cuda
Fitted encoder
Epoch 0, Val Loss: 671.22766
Epoch 1, Val Loss: 415.42755
Epoch 2, Val Loss: 152.88922
Epoch 3, Val Loss: 148.79500
Epoch 4, Val Loss: 126.40210
Epoch 5, Val Loss: 115.28352
Epoch 6, Val Loss: 122.35367
Epoch 7, Val Loss: 115.68385
Epoch 8, Val Loss: 107.16212
Epoch 9, Val Loss: 107.40976
Epoch 10, Val Loss: 98.64616
Epoch 11, Val Loss: 95.93327
Epoch 12, Val Loss: 92.97839
Epoch 13, Val Loss: 102.06236
Epoch 14, Val Loss: 86.55018
Epoch 15, Val Loss: 83.48294
Epoch 16, Val Loss: 83.92773
Epoch 17, Val Loss: 85.35224
Epoch 18, Val Loss: 88.92008
Epoch 19, Val Loss: 90.92745
Epoch 20, Val Loss: 85.36626
Epoch 21, Val Loss: 84.14260
Epoch 22, Val Loss: 91.39281
