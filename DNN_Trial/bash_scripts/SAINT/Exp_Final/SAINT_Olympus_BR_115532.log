

----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/boston.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/boston.yml', data_parallel=False, dataset='Boston', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[3], num_bins=10, num_classes=1, num_features=13, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset Boston...
Dataset loaded! 

(506, 13)
A new study created in RDB with name: SAINT_Boston
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (404, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43225825  0.28085326 -1.26935664]
 [ 1.          0.         -0.42951432 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42951694 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42885285 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42405785 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42918228 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42154269  0.04424437 -0.45586512]
 [ 1.          0.         -0.41418809  0.04424437 -0.45586512]
 [ 1.          0.         -0.40547001  0.04424437 -0.45586512]
 [ 1.          0.         -0.40368561  0.04424437 -0.45586512]] 
 
 
Val : (404, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.00000000e+00  0.00000000e+00 -4.32258247e-01  2.80853261e-01
  -1.26935664e+00 -1.33314879e-01  4.00328643e-01 -1.16382568e-01
   1.25618120e-01 -9.71860731e-01 -6.57926849e-01 -1.43057295e+00
   4.19508769e-01 -1.05567454e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29514322e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.83324680e-01  3.76165405e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   4.19508769e-01 -4.65019751e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.29516937e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.25988980e+00 -2.63787436e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   3.73404289e-01 -1.19055965e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.28852852e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  9.96384984e-01 -8.13859260e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.93794477e-01 -1.34532257e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.24057847e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.20634336e+00 -5.11859043e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   4.19508769e-01 -1.00598003e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29182280e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.96006730e-01 -3.50073213e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.88017257e-01 -1.02301815e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.21542692e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -3.93004027e-01 -6.60491988e-02
   8.11929717e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.04782522e-01  2.10867810e-03]
 [ 1.00000000e+00  0.00000000e+00 -4.14188085e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -1.67545364e-01  9.94546802e-01
   9.93950473e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.19508769e-01  9.56243343e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.05470014e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -9.29877468e-01  1.13476119e+00
   1.05537081e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.03171419e-01  2.48683437e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.03685613e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01  1.21323548e-01  9.29832470e-01
   1.17886489e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.69892645e-01  1.14082297e+00]] 
 
 
Val : (404, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8815395832061768
Epoch 1 loss 1.8112646341323853
Epoch 2 loss 1.7376004457473755
Epoch 3 loss 1.6659311056137085
Epoch 4 loss 1.5970418453216553
Epoch 5 loss 1.526479959487915
Epoch 6 loss 1.4563323259353638
Epoch 7 loss 1.3929555416107178
Epoch 8 loss 1.340855360031128
Epoch 9 loss 1.28289794921875
Epoch 10 loss 1.2450512647628784
Epoch 11 loss 1.2068020105361938
Epoch 12 loss 1.1871534585952759
Epoch 13 loss 1.1807332038879395
Epoch 14 loss 1.1625479459762573
Epoch 15 loss 1.1350104808807373
Epoch 16 loss 1.139955759048462
Epoch 17 loss 1.132705569267273
Epoch 18 loss 1.1291383504867554
Epoch 19 loss 1.1210205554962158
Epoch 20 loss 1.1300212144851685
Epoch 21 loss 1.0905381441116333
Epoch 22 loss 1.1447513103485107
Epoch 23 loss 1.0963462591171265
Epoch 24 loss 1.1229528188705444
Epoch 25 loss 1.1139708757400513
Epoch 26 loss 1.1313556432724
Epoch 27 loss 1.0923926830291748
Epoch 28 loss 1.0984907150268555
Epoch 29 loss 1.1251097917556763
Epoch 30 loss 1.147612452507019
Epoch 31 loss 1.0864348411560059
Epoch 32 loss 1.092286229133606
Epoch 33 loss 1.121799349784851
Epoch 34 loss 1.120413064956665
Epoch 35 loss 1.113720178604126
Epoch 36 loss 1.1145002841949463
Epoch 37 loss 1.1196386814117432
Epoch 38 loss 1.1301722526550293
Epoch 39 loss 1.0981876850128174
Epoch 40 loss 1.1157180070877075
Epoch 41 loss 1.1436270475387573
Epoch 42 loss 1.0996631383895874
Epoch 43 loss 1.1162680387496948
Epoch 44 loss 1.1323952674865723
Epoch 45 loss 1.1338390111923218
Epoch 46 loss 1.1151646375656128
Epoch 47 loss 1.0974634885787964
Epoch 48 loss 1.1302447319030762
Epoch 49 loss 1.1488847732543945
Epoch 50 loss 1.113462209701538
Epoch 51 loss 1.1262383460998535
Epoch 52 loss 1.1355746984481812
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (102,)
Probabilities shape : (102, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0864, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601 ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601  -0.14644097
   0.43321145 -0.11061159  0.14775275 -0.99688337 -0.67131018 -1.47837754
   0.4487374  -1.08196   ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622 -0.73733458
   0.2147811   0.37093288  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.4487374  -0.50980847]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622 -0.73733458
   1.29842261 -0.25472344  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.40426039 -1.2126196 ]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363 -0.83153501
   1.03318575 -0.79250669  1.10373099 -0.76961753 -1.10524957  0.11340123
   0.42393081 -1.36253431]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363 -0.83153501
   0.22754651 -0.3390816   1.10373099 -0.76961753 -1.10524957  0.11340123
   0.41835752 -1.05032662]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834 -0.26633243
  -0.36533589 -0.06140267  0.86054354 -0.54235169 -0.58334949 -1.52519456
   0.43453098 -0.05731364]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834 -0.26633243
  -0.13839526  0.97549967  1.049587   -0.54235169 -0.58334949 -1.52519456
   0.4487374   0.86693114]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834 -0.26633243
  -0.90573827  1.11258167  1.11337705 -0.54235169 -0.58334949 -1.52519456
   0.33650671  2.3495738 ]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834 -0.26633243
  -0.37668292  0.6169775   1.36058773 -0.54235169 -0.58334949 -1.52519456
   0.33738095  0.58498147]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834 -0.26633243
   0.15237242  0.91223105  1.24163577 -0.54235169 -0.58334949 -1.52519456
   0.4008727   1.04572849]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8837552070617676
Epoch 1 loss 1.8000789880752563
Epoch 2 loss 1.724217176437378
Epoch 3 loss 1.6466624736785889
Epoch 4 loss 1.5740593671798706
Epoch 5 loss 1.498358130455017
Epoch 6 loss 1.4270886182785034
Epoch 7 loss 1.3505992889404297
Epoch 8 loss 1.2917691469192505
Epoch 9 loss 1.250176191329956
Epoch 10 loss 1.2233240604400635
Epoch 11 loss 1.1889921426773071
Epoch 12 loss 1.1651089191436768
Epoch 13 loss 1.1385380029678345
Epoch 14 loss 1.1262773275375366
Epoch 15 loss 1.1783469915390015
Epoch 16 loss 1.1027525663375854
Epoch 17 loss 1.1356457471847534
Epoch 18 loss 1.1195460557937622
Epoch 19 loss 1.1337953805923462
Epoch 20 loss 1.099051594734192
Epoch 21 loss 1.1473844051361084
Epoch 22 loss 1.0784752368927002
Epoch 23 loss 1.1501129865646362
Epoch 24 loss 1.102128028869629
Epoch 25 loss 1.1060878038406372
Epoch 26 loss 1.1179866790771484
Epoch 27 loss 1.111122965812683
Epoch 28 loss 1.1274183988571167
Epoch 29 loss 1.068135142326355
Epoch 30 loss 1.1755050420761108
Epoch 31 loss 1.0954128503799438
Epoch 32 loss 1.1278611421585083
Epoch 33 loss 1.1002918481826782
Epoch 34 loss 1.1195933818817139
Epoch 35 loss 1.1270159482955933
Epoch 36 loss 1.1255656480789185
Epoch 37 loss 1.124125599861145
Epoch 38 loss 1.1448026895523071
Epoch 39 loss 1.092928409576416
Epoch 40 loss 1.1992194652557373
Epoch 41 loss 1.0913435220718384
Epoch 42 loss 1.296149730682373
Epoch 43 loss 1.1055508852005005
Epoch 44 loss 1.1674418449401855
Epoch 45 loss 1.129996657371521
Epoch 46 loss 1.1696174144744873
Epoch 47 loss 1.131799578666687
Epoch 48 loss 1.1712385416030884
Epoch 49 loss 1.17619788646698
Epoch 50 loss 1.170060396194458
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.07725, 'Log Loss - std': 0.009149999999999991} 
 

Fold 3
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492 -0.74392033
   0.23876567  0.35529727  0.55426555 -0.87364684 -1.00997446 -0.31587901
   0.45531939 -0.528203  ]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369 -0.83699472
   1.30685234 -0.52159414  1.06231866 -0.76085533 -1.12764816  0.09576882
   0.45531939 -1.06900562]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189 -0.27854836
  -0.37472213  0.60380901  1.3081568  -0.53527231 -0.6040002  -1.50508385
   0.3472664   0.60166285]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189 -0.27854836
   0.17403314  0.90202309  1.19430763 -0.53527231 -0.6040002  -1.50508385
   0.40887463  1.07717172]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189 -0.27854836
  -0.54390941 -1.06121963  0.77871637 -0.53527231 -0.6040002  -1.50508385
   0.3874549   0.40436216]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012 -0.16009005
  -0.45563779 -0.2517814   0.43382852 -0.64806382 -0.62753494  1.14775772
   0.45531939 -0.65311279]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012 -0.16009005
  -0.62482507 -0.43994028  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.44174649 -0.62330477]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012 -0.16009005
  -0.4762345  -1.40558589  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.34875094 -0.89157694]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012 -0.16009005
  -0.39531884  0.45470197  0.22524421 -0.64806382 -0.62753494  1.14775772
   0.34769055  0.25674149]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012 -0.16009005
  -1.18093631 -1.14642365  0.01118548 -0.64806382 -0.62753494  1.14775772
  -0.68893948 -0.16624848]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8753708600997925
Epoch 1 loss 1.8160350322723389
Epoch 2 loss 1.749187707901001
Epoch 3 loss 1.6797391176223755
Epoch 4 loss 1.6235064268112183
Epoch 5 loss 1.5511294603347778
Epoch 6 loss 1.4733021259307861
Epoch 7 loss 1.4096637964248657
Epoch 8 loss 1.3654248714447021
Epoch 9 loss 1.2845485210418701
Epoch 10 loss 1.2192871570587158
Epoch 11 loss 1.1813348531723022
Epoch 12 loss 1.1544727087020874
Epoch 13 loss 1.1229088306427002
Epoch 14 loss 1.0891575813293457
Epoch 15 loss 1.096213936805725
Epoch 16 loss 1.0919468402862549
Epoch 17 loss 1.07301926612854
Epoch 18 loss 1.0696684122085571
Epoch 19 loss 1.1042391061782837
Epoch 20 loss 1.1007648706436157
Epoch 21 loss 1.0670791864395142
Epoch 22 loss 1.072675347328186
Epoch 23 loss 1.06305730342865
Epoch 24 loss 1.094522476196289
Epoch 25 loss 1.088562250137329
Epoch 26 loss 1.0830965042114258
Epoch 27 loss 1.0784313678741455
Epoch 28 loss 1.0663402080535889
Epoch 29 loss 1.082848072052002
Epoch 30 loss 1.086847186088562
Epoch 31 loss 1.0806362628936768
Epoch 32 loss 1.0778272151947021
Epoch 33 loss 1.0768345594406128
Epoch 34 loss 1.075706124305725
Epoch 35 loss 1.0717633962631226
Epoch 36 loss 1.0908063650131226
Epoch 37 loss 1.1015069484710693
Epoch 38 loss 1.0676690340042114
Epoch 39 loss 1.0843896865844727
Epoch 40 loss 1.0963398218154907
Epoch 41 loss 1.0861579179763794
Epoch 42 loss 1.0869179964065552
Epoch 43 loss 1.0928038358688354
Epoch 44 loss 1.079248309135437
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0725333333333333, 'Log Loss - std': 0.010015432536285661} 
 

Fold 4
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395 -0.14778782
   0.37199413 -0.12658697  0.14599729 -0.98899287 -0.67900701 -1.4532496
   0.43873734 -1.05010173]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753 -0.75071501
   1.24288869 -0.27245627  0.56534951 -0.87386148 -0.99912348 -0.30460384
   0.39343964 -1.18278002]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279 -0.84683384
   0.97590954 -0.8167978   1.08893019 -0.75873009 -1.11768514  0.10890864
   0.41347302 -1.33501091]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279 -0.84683384
   1.18863624 -0.51794363  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.43873734 -1.00122025]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279 -0.84683384
   0.16497821 -0.35784318  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.4077969  -1.01797961]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242 -0.27012088
  -0.43179873 -0.07677794  0.84906129 -0.5284673  -0.59008576 -1.49919543
   0.42426879 -0.00962456]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242 -0.27012088
  -0.20336736  0.97276947  1.03552505 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.9288998 ]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242 -0.27012088
  -0.9757509   1.11152319  1.09844462 -0.5284673  -0.59008576 -1.49919543
   0.32443578  2.43444931]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242 -0.27012088
  -0.44322029  0.60987511  1.34228185 -0.5284673  -0.59008576 -1.49919543
   0.32532615  0.64259401]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242 -0.27012088
  -0.43608181  0.50314147  1.16757965 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.10769098]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8783265352249146
Epoch 1 loss 1.8055516481399536
Epoch 2 loss 1.7194697856903076
Epoch 3 loss 1.6409837007522583
Epoch 4 loss 1.5620545148849487
Epoch 5 loss 1.5000699758529663
Epoch 6 loss 1.415635347366333
Epoch 7 loss 1.3534150123596191
Epoch 8 loss 1.2832809686660767
Epoch 9 loss 1.248154878616333
Epoch 10 loss 1.2331151962280273
Epoch 11 loss 1.1954584121704102
Epoch 12 loss 1.1759947538375854
Epoch 13 loss 1.1536129713058472
Epoch 14 loss 1.1436855792999268
Epoch 15 loss 1.1346559524536133
Epoch 16 loss 1.1207669973373413
Epoch 17 loss 1.1176527738571167
Epoch 18 loss 1.1072570085525513
Epoch 19 loss 1.1013180017471313
Epoch 20 loss 1.0985040664672852
Epoch 21 loss 1.093239188194275
Epoch 22 loss 1.0821725130081177
Epoch 23 loss 1.093621015548706
Epoch 24 loss 1.0940250158309937
Epoch 25 loss 1.1149940490722656
Epoch 26 loss 1.0793429613113403
Epoch 27 loss 1.0960545539855957
Epoch 28 loss 1.0815316438674927
Epoch 29 loss 1.0906957387924194
Epoch 30 loss 1.0788320302963257
Epoch 31 loss 1.0863858461380005
Epoch 32 loss 1.074288249015808
Epoch 33 loss 1.084160566329956
Epoch 34 loss 1.0867427587509155
Epoch 35 loss 1.1063140630722046
Epoch 36 loss 1.1185966730117798
Epoch 37 loss 1.0914517641067505
Epoch 38 loss 1.1360129117965698
Epoch 39 loss 1.0884058475494385
Epoch 40 loss 1.1227288246154785
Epoch 41 loss 1.103588342666626
Epoch 42 loss 1.114223837852478
Epoch 43 loss 1.1420276165008545
Epoch 44 loss 1.1087234020233154
Epoch 45 loss 1.155056357383728
Epoch 46 loss 1.1246532201766968
Epoch 47 loss 1.1365423202514648
Epoch 48 loss 1.1592538356781006
Epoch 49 loss 1.1477243900299072
Epoch 50 loss 1.1610485315322876
Epoch 51 loss 1.1406550407409668
Epoch 52 loss 1.175475001335144
Epoch 53 loss 1.1626687049865723
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.072975, 'Log Loss - std': 0.008707288613569694} 
 

Fold 5
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722 -0.13302913
   0.40034384 -0.11547912  0.13462698 -0.97126473 -0.63313291 -1.47540215
   0.44270655 -1.07367538]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593 -0.72934599
   0.18434892  0.37281223  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.44270655 -0.49078942]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593 -0.72934599
   1.25590816 -0.26161011  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.39839877 -1.20678636]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074 -0.82441099
   0.99362861 -0.8069282   1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41799435 -1.35951369]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074 -0.82441099
   1.20261071 -0.50753788  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.44270655 -1.0246345 ]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074 -0.82441099
   0.196972   -0.34715021  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41244227 -1.04144852]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118 -0.25402095
  -0.38929995 -0.06558074  0.84730135 -0.50684653 -0.54347597 -1.52256379
   0.42855419 -0.0298051 ]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118 -0.25402095
  -0.16488963  0.98584956  1.03631394 -0.50684653 -0.54347597 -1.52256379
   0.44270655  0.91177992]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118 -0.25402095
  -0.923677    1.12485221  1.10009357 -0.50684653 -0.54347597 -1.52256379
   0.3309029   2.4222392 ]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118 -0.25402095
  -0.40052046  0.62230417  1.34726387 -0.50684653 -0.54347597 -1.52256379
   0.33177381  0.62454044]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.874148964881897
Epoch 1 loss 1.781211495399475
Epoch 2 loss 1.7017605304718018
Epoch 3 loss 1.6246665716171265
Epoch 4 loss 1.5338935852050781
Epoch 5 loss 1.4506562948226929
Epoch 6 loss 1.391552209854126
Epoch 7 loss 1.3153098821640015
Epoch 8 loss 1.2640917301177979
Epoch 9 loss 1.1926631927490234
Epoch 10 loss 1.1438037157058716
Epoch 11 loss 1.118515968322754
Epoch 12 loss 1.0934062004089355
Epoch 13 loss 1.0660353899002075
Epoch 14 loss 1.0652554035186768
Epoch 15 loss 1.0288103818893433
Epoch 16 loss 1.0516620874404907
Epoch 17 loss 1.0373919010162354
Epoch 18 loss 1.039935827255249
Epoch 19 loss 1.0008978843688965
Epoch 20 loss 1.0363242626190186
Epoch 21 loss 1.0186415910720825
Epoch 22 loss 0.9927318096160889
Epoch 23 loss 1.0483133792877197
Epoch 24 loss 0.9831991195678711
Epoch 25 loss 1.034579873085022
Epoch 26 loss 1.0133633613586426
Epoch 27 loss 1.0275362730026245
Epoch 28 loss 1.0128382444381714
Epoch 29 loss 1.0109573602676392
Epoch 30 loss 1.0327502489089966
Epoch 31 loss 1.025513768196106
Epoch 32 loss 1.0139973163604736
Epoch 33 loss 1.0249462127685547
Epoch 34 loss 1.029874324798584
Epoch 35 loss 1.0250296592712402
Epoch 36 loss 1.0456863641738892
Epoch 37 loss 1.0710474252700806
Epoch 38 loss 1.0351296663284302
Epoch 39 loss 1.0592536926269531
Epoch 40 loss 1.0559362173080444
Epoch 41 loss 1.082129716873169
Epoch 42 loss 1.0276401042938232
Epoch 43 loss 1.1023290157318115
Epoch 44 loss 1.0520992279052734
Epoch 45 loss 1.0788190364837646
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.05502, 'Log Loss - std': 0.03674481732163057} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 1.05502 and parameters: {'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}. Best is trial 0 with value: 1.05502.
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (404, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43225825  0.28085326 -1.26935664]
 [ 1.          0.         -0.42951432 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42951694 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42885285 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42405785 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42918228 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42154269  0.04424437 -0.45586512]
 [ 1.          0.         -0.41418809  0.04424437 -0.45586512]
 [ 1.          0.         -0.40547001  0.04424437 -0.45586512]
 [ 1.          0.         -0.40368561  0.04424437 -0.45586512]] 
 
 
Val : (404, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.00000000e+00  0.00000000e+00 -4.32258247e-01  2.80853261e-01
  -1.26935664e+00 -1.33314879e-01  4.00328643e-01 -1.16382568e-01
   1.25618120e-01 -9.71860731e-01 -6.57926849e-01 -1.43057295e+00
   4.19508769e-01 -1.05567454e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29514322e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.83324680e-01  3.76165405e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   4.19508769e-01 -4.65019751e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.29516937e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.25988980e+00 -2.63787436e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   3.73404289e-01 -1.19055965e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.28852852e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  9.96384984e-01 -8.13859260e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.93794477e-01 -1.34532257e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.24057847e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.20634336e+00 -5.11859043e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   4.19508769e-01 -1.00598003e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29182280e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.96006730e-01 -3.50073213e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.88017257e-01 -1.02301815e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.21542692e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -3.93004027e-01 -6.60491988e-02
   8.11929717e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.04782522e-01  2.10867810e-03]
 [ 1.00000000e+00  0.00000000e+00 -4.14188085e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -1.67545364e-01  9.94546802e-01
   9.93950473e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.19508769e-01  9.56243343e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.05470014e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -9.29877468e-01  1.13476119e+00
   1.05537081e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.03171419e-01  2.48683437e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.03685613e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01  1.21323548e-01  9.29832470e-01
   1.17886489e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.69892645e-01  1.14082297e+00]] 
 
 
Val : (404, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}
Epoch 0 loss 1.761887788772583
Epoch 1 loss 1.5946019887924194
Epoch 2 loss 1.433385968208313
Epoch 3 loss 1.320127010345459
Epoch 4 loss 1.2352858781814575
Epoch 5 loss 1.2135636806488037
Epoch 6 loss 1.1365269422531128
Epoch 7 loss 1.1073495149612427
Epoch 8 loss 1.1246768236160278
Epoch 9 loss 1.2101266384124756
Epoch 10 loss 1.1442739963531494
Epoch 11 loss 1.29293692111969
Epoch 12 loss 1.1070811748504639
Epoch 13 loss 1.1810510158538818
Epoch 14 loss 1.1786139011383057
Epoch 15 loss 1.107845664024353
Epoch 16 loss 1.108299732208252
Epoch 17 loss 1.0775548219680786
Epoch 18 loss 1.0957015752792358
Epoch 19 loss 1.063202977180481
Epoch 20 loss 1.070466160774231
Epoch 21 loss 1.0728638172149658
Epoch 22 loss 1.0477097034454346
Epoch 23 loss 1.1869854927062988
Epoch 24 loss 1.107458472251892
Epoch 25 loss 1.19632089138031
Epoch 26 loss 1.1462777853012085
Epoch 27 loss 1.1493984460830688
Epoch 28 loss 1.1469398736953735
Epoch 29 loss 1.2727303504943848
Epoch 30 loss 1.2526012659072876
Epoch 31 loss 1.337664246559143
Epoch 32 loss 1.303365707397461
Epoch 33 loss 1.3229364156723022
Epoch 34 loss 1.2760169506072998
Epoch 35 loss 1.4059051275253296
Epoch 36 loss 1.4592711925506592
Epoch 37 loss 1.4067999124526978
Epoch 38 loss 1.5643056631088257
Epoch 39 loss 1.5690765380859375
Epoch 40 loss 1.6658101081848145
Epoch 41 loss 1.5808809995651245
Epoch 42 loss 1.6184866428375244
Epoch 43 loss 1.5839743614196777
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (102,)
Probabilities shape : (102, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0477, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601 ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601  -0.14644097
   0.43321145 -0.11061159  0.14775275 -0.99688337 -0.67131018 -1.47837754
   0.4487374  -1.08196   ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622 -0.73733458
   0.2147811   0.37093288  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.4487374  -0.50980847]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622 -0.73733458
   1.29842261 -0.25472344  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.40426039 -1.2126196 ]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363 -0.83153501
   1.03318575 -0.79250669  1.10373099 -0.76961753 -1.10524957  0.11340123
   0.42393081 -1.36253431]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363 -0.83153501
   0.22754651 -0.3390816   1.10373099 -0.76961753 -1.10524957  0.11340123
   0.41835752 -1.05032662]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834 -0.26633243
  -0.36533589 -0.06140267  0.86054354 -0.54235169 -0.58334949 -1.52519456
   0.43453098 -0.05731364]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834 -0.26633243
  -0.13839526  0.97549967  1.049587   -0.54235169 -0.58334949 -1.52519456
   0.4487374   0.86693114]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834 -0.26633243
  -0.90573827  1.11258167  1.11337705 -0.54235169 -0.58334949 -1.52519456
   0.33650671  2.3495738 ]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834 -0.26633243
  -0.37668292  0.6169775   1.36058773 -0.54235169 -0.58334949 -1.52519456
   0.33738095  0.58498147]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834 -0.26633243
   0.15237242  0.91223105  1.24163577 -0.54235169 -0.58334949 -1.52519456
   0.4008727   1.04572849]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}
Epoch 0 loss 1.874068260192871
Epoch 1 loss 1.67817223072052
Epoch 2 loss 1.4590176343917847
Epoch 3 loss 1.3177762031555176
Epoch 4 loss 1.1939347982406616
Epoch 5 loss 1.1815191507339478
Epoch 6 loss 1.1013926267623901
Epoch 7 loss 1.0129339694976807
Epoch 8 loss 1.0037881135940552
Epoch 9 loss 0.9980034232139587
Epoch 10 loss 1.0630265474319458
Epoch 11 loss 1.0355478525161743
Epoch 12 loss 1.0995824337005615
Epoch 13 loss 0.9922946095466614
Epoch 14 loss 1.0824021100997925
Epoch 15 loss 1.1909282207489014
Epoch 16 loss 1.107908844947815
Epoch 17 loss 1.026543140411377
Epoch 18 loss 1.08515465259552
Epoch 19 loss 1.1263507604599
Epoch 20 loss 1.3756386041641235
Epoch 21 loss 1.1203358173370361
Epoch 22 loss 1.162567377090454
Epoch 23 loss 1.3079133033752441
Epoch 24 loss 1.251304268836975
Epoch 25 loss 1.2390708923339844
Epoch 26 loss 1.7194653749465942
Epoch 27 loss 1.173984169960022
Epoch 28 loss 1.2918894290924072
Epoch 29 loss 1.372291922569275
Epoch 30 loss 1.3804243803024292
Epoch 31 loss 1.4010411500930786
Epoch 32 loss 1.3934417963027954
Epoch 33 loss 1.613742470741272
Epoch 34 loss 1.6769307851791382
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.02, 'Log Loss - std': 0.027700000000000058} 
 

Fold 3
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492 -0.74392033
   0.23876567  0.35529727  0.55426555 -0.87364684 -1.00997446 -0.31587901
   0.45531939 -0.528203  ]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369 -0.83699472
   1.30685234 -0.52159414  1.06231866 -0.76085533 -1.12764816  0.09576882
   0.45531939 -1.06900562]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189 -0.27854836
  -0.37472213  0.60380901  1.3081568  -0.53527231 -0.6040002  -1.50508385
   0.3472664   0.60166285]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189 -0.27854836
   0.17403314  0.90202309  1.19430763 -0.53527231 -0.6040002  -1.50508385
   0.40887463  1.07717172]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189 -0.27854836
  -0.54390941 -1.06121963  0.77871637 -0.53527231 -0.6040002  -1.50508385
   0.3874549   0.40436216]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012 -0.16009005
  -0.45563779 -0.2517814   0.43382852 -0.64806382 -0.62753494  1.14775772
   0.45531939 -0.65311279]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012 -0.16009005
  -0.62482507 -0.43994028  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.44174649 -0.62330477]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012 -0.16009005
  -0.4762345  -1.40558589  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.34875094 -0.89157694]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012 -0.16009005
  -0.39531884  0.45470197  0.22524421 -0.64806382 -0.62753494  1.14775772
   0.34769055  0.25674149]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012 -0.16009005
  -1.18093631 -1.14642365  0.01118548 -0.64806382 -0.62753494  1.14775772
  -0.68893948 -0.16624848]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}
Epoch 0 loss 1.905885100364685
Epoch 1 loss 1.6255090236663818
Epoch 2 loss 1.463316798210144
Epoch 3 loss 1.3395357131958008
Epoch 4 loss 1.2566413879394531
Epoch 5 loss 1.1753026247024536
Epoch 6 loss 1.2601388692855835
Epoch 7 loss 1.1591945886611938
Epoch 8 loss 1.156406044960022
Epoch 9 loss 1.1071600914001465
Epoch 10 loss 1.2267755270004272
Epoch 11 loss 1.1328450441360474
Epoch 12 loss 1.122156023979187
Epoch 13 loss 1.1388556957244873
Epoch 14 loss 1.3537245988845825
Epoch 15 loss 1.175941824913025
Epoch 16 loss 1.1484178304672241
Epoch 17 loss 1.164901614189148
Epoch 18 loss 1.2676674127578735
Epoch 19 loss 1.2006311416625977
Epoch 20 loss 1.2186847925186157
Epoch 21 loss 1.1226799488067627
Epoch 22 loss 1.1422200202941895
Epoch 23 loss 1.1277225017547607
Epoch 24 loss 1.2496217489242554
Epoch 25 loss 1.2090888023376465
Epoch 26 loss 1.1558856964111328
Epoch 27 loss 1.2196506261825562
Epoch 28 loss 1.2746690511703491
Epoch 29 loss 1.2309482097625732
Epoch 30 loss 1.3624272346496582
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0490666666666666, 'Log Loss - std': 0.04691768204940317} 
 

Fold 4
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395 -0.14778782
   0.37199413 -0.12658697  0.14599729 -0.98899287 -0.67900701 -1.4532496
   0.43873734 -1.05010173]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753 -0.75071501
   1.24288869 -0.27245627  0.56534951 -0.87386148 -0.99912348 -0.30460384
   0.39343964 -1.18278002]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279 -0.84683384
   0.97590954 -0.8167978   1.08893019 -0.75873009 -1.11768514  0.10890864
   0.41347302 -1.33501091]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279 -0.84683384
   1.18863624 -0.51794363  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.43873734 -1.00122025]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279 -0.84683384
   0.16497821 -0.35784318  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.4077969  -1.01797961]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242 -0.27012088
  -0.43179873 -0.07677794  0.84906129 -0.5284673  -0.59008576 -1.49919543
   0.42426879 -0.00962456]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242 -0.27012088
  -0.20336736  0.97276947  1.03552505 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.9288998 ]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242 -0.27012088
  -0.9757509   1.11152319  1.09844462 -0.5284673  -0.59008576 -1.49919543
   0.32443578  2.43444931]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242 -0.27012088
  -0.44322029  0.60987511  1.34228185 -0.5284673  -0.59008576 -1.49919543
   0.32532615  0.64259401]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242 -0.27012088
  -0.43608181  0.50314147  1.16757965 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.10769098]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}
Epoch 0 loss 1.7947055101394653
Epoch 1 loss 1.5936057567596436
Epoch 2 loss 1.485053300857544
Epoch 3 loss 1.3714792728424072
Epoch 4 loss 1.2606817483901978
Epoch 5 loss 1.1994825601577759
Epoch 6 loss 1.1696377992630005
Epoch 7 loss 1.1244897842407227
Epoch 8 loss 1.085647702217102
Epoch 9 loss 1.116178035736084
Epoch 10 loss 1.0792841911315918
Epoch 11 loss 1.0887641906738281
Epoch 12 loss 1.0811964273452759
Epoch 13 loss 1.1299400329589844
Epoch 14 loss 1.1204911470413208
Epoch 15 loss 1.1268230676651
Epoch 16 loss 1.182727575302124
Epoch 17 loss 1.1844463348388672
Epoch 18 loss 1.1970142126083374
Epoch 19 loss 1.226730227470398
Epoch 20 loss 1.20348060131073
Epoch 21 loss 1.2338619232177734
Epoch 22 loss 1.2455884218215942
Epoch 23 loss 1.3483461141586304
Epoch 24 loss 1.3143004179000854
Epoch 25 loss 1.324516773223877
Epoch 26 loss 1.267578125
Epoch 27 loss 1.3050402402877808
Epoch 28 loss 1.3938164710998535
Epoch 29 loss 1.4462857246398926
Epoch 30 loss 1.5111942291259766
Epoch 31 loss 1.4641733169555664
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.056625, 'Log Loss - std': 0.042688837826766836} 
 

Fold 5
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722 -0.13302913
   0.40034384 -0.11547912  0.13462698 -0.97126473 -0.63313291 -1.47540215
   0.44270655 -1.07367538]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593 -0.72934599
   0.18434892  0.37281223  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.44270655 -0.49078942]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593 -0.72934599
   1.25590816 -0.26161011  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.39839877 -1.20678636]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074 -0.82441099
   0.99362861 -0.8069282   1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41799435 -1.35951369]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074 -0.82441099
   1.20261071 -0.50753788  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.44270655 -1.0246345 ]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074 -0.82441099
   0.196972   -0.34715021  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41244227 -1.04144852]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118 -0.25402095
  -0.38929995 -0.06558074  0.84730135 -0.50684653 -0.54347597 -1.52256379
   0.42855419 -0.0298051 ]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118 -0.25402095
  -0.16488963  0.98584956  1.03631394 -0.50684653 -0.54347597 -1.52256379
   0.44270655  0.91177992]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118 -0.25402095
  -0.923677    1.12485221  1.10009357 -0.50684653 -0.54347597 -1.52256379
   0.3309029   2.4222392 ]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118 -0.25402095
  -0.40052046  0.62230417  1.34726387 -0.50684653 -0.54347597 -1.52256379
   0.33177381  0.62454044]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}
Epoch 0 loss 1.743588924407959
Epoch 1 loss 1.5096056461334229
Epoch 2 loss 1.363340973854065
Epoch 3 loss 1.1930569410324097
Epoch 4 loss 1.1579921245574951
Epoch 5 loss 1.1156132221221924
Epoch 6 loss 1.1736888885498047
Epoch 7 loss 1.0909405946731567
Epoch 8 loss 1.132775902748108
Epoch 9 loss 1.0387741327285767
Epoch 10 loss 1.1122369766235352
Epoch 11 loss 1.0387248992919922
Epoch 12 loss 1.1193842887878418
Epoch 13 loss 1.118889570236206
Epoch 14 loss 1.1447932720184326
Epoch 15 loss 1.1365543603897095
Epoch 16 loss 1.11173677444458
Epoch 17 loss 1.2045674324035645
Epoch 18 loss 1.3161977529525757
Epoch 19 loss 1.067404866218567
Epoch 20 loss 1.179923176765442
Epoch 21 loss 1.2328490018844604
Epoch 22 loss 1.1713707447052002
Epoch 23 loss 1.145749568939209
Epoch 24 loss 1.130780816078186
Epoch 25 loss 1.2833826541900635
Epoch 26 loss 1.2479537725448608
Epoch 27 loss 1.296507716178894
Epoch 28 loss 1.3121662139892578
Epoch 29 loss 1.3514550924301147
Epoch 30 loss 1.3193937540054321
Epoch 31 loss 1.4385883808135986
Epoch 32 loss 1.4511264562606812
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.05304, 'Log Loss - std': 0.03884943242828651} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 1.05304 and parameters: {'dim': 64, 'depth': 12, 'heads': 8, 'dropout': 0.3}. Best is trial 0 with value: 1.05502.
Best parameters After Trials: {'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Parameters saved to YAML file!!!
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (404, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43225825  0.28085326 -1.26935664]
 [ 1.          0.         -0.42951432 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42951694 -0.4935031  -0.57291426]
 [ 1.          0.         -0.42885285 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42405785 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42918228 -0.4935031  -1.28837713]
 [ 1.          0.         -0.42154269  0.04424437 -0.45586512]
 [ 1.          0.         -0.41418809  0.04424437 -0.45586512]
 [ 1.          0.         -0.40547001  0.04424437 -0.45586512]
 [ 1.          0.         -0.40368561  0.04424437 -0.45586512]] 
 
 
Val : (404, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.00000000e+00  0.00000000e+00 -4.32258247e-01  2.80853261e-01
  -1.26935664e+00 -1.33314879e-01  4.00328643e-01 -1.16382568e-01
   1.25618120e-01 -9.71860731e-01 -6.57926849e-01 -1.43057295e+00
   4.19508769e-01 -1.05567454e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29514322e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.83324680e-01  3.76165405e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   4.19508769e-01 -4.65019751e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.29516937e-01 -4.93503105e-01
  -5.72914258e-01 -7.40690027e-01  1.25988980e+00 -2.63787436e-01
   5.34978135e-01 -8.54376669e-01 -9.85150361e-01 -2.90809064e-01
   3.73404289e-01 -1.19055965e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.28852852e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  9.96384984e-01 -8.13859260e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.93794477e-01 -1.34532257e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.24057847e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.20634336e+00 -5.11859043e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   4.19508769e-01 -1.00598003e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.29182280e-01 -4.93503105e-01
  -1.28837713e+00 -8.37517949e-01  1.96006730e-01 -3.50073213e-01
   1.04608309e+00 -7.36892607e-01 -1.10634425e+00  1.19505936e-01
   3.88017257e-01 -1.02301815e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.21542692e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -3.93004027e-01 -6.60491988e-02
   8.11929717e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.04782522e-01  2.10867810e-03]
 [ 1.00000000e+00  0.00000000e+00 -4.14188085e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -1.67545364e-01  9.94546802e-01
   9.93950473e-01 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   4.19508769e-01  9.56243343e-01]
 [ 1.00000000e+00  0.00000000e+00 -4.05470014e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01 -9.29877468e-01  1.13476119e+00
   1.05537081e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.03171419e-01  2.48683437e+00]
 [ 1.00000000e+00  0.00000000e+00 -4.03685613e-01  4.42443716e-02
  -4.55865117e-01 -2.56550417e-01  1.21323548e-01  9.29832470e-01
   1.17886489e+00 -5.01924483e-01 -5.67031429e-01 -1.47616351e+00
   3.69892645e-01  1.14082297e+00]] 
 
 
Val : (404, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.901815414428711
Epoch 1 loss 1.8189774751663208
Epoch 2 loss 1.7468948364257812
Epoch 3 loss 1.6710556745529175
Epoch 4 loss 1.5846974849700928
Epoch 5 loss 1.5054214000701904
Epoch 6 loss 1.4309765100479126
Epoch 7 loss 1.3690720796585083
Epoch 8 loss 1.3111505508422852
Epoch 9 loss 1.2777734994888306
Epoch 10 loss 1.2403644323349
Epoch 11 loss 1.206688404083252
Epoch 12 loss 1.1809028387069702
Epoch 13 loss 1.1698416471481323
Epoch 14 loss 1.1648179292678833
Epoch 15 loss 1.1334271430969238
Epoch 16 loss 1.1416946649551392
Epoch 17 loss 1.14534330368042
Epoch 18 loss 1.1216249465942383
Epoch 19 loss 1.1182416677474976
Epoch 20 loss 1.1160746812820435
Epoch 21 loss 1.1341304779052734
Epoch 22 loss 1.100671648979187
Epoch 23 loss 1.0992001295089722
Epoch 24 loss 1.0947506427764893
Epoch 25 loss 1.131005048751831
Epoch 26 loss 1.1025887727737427
Epoch 27 loss 1.1054348945617676
Epoch 28 loss 1.1194943189620972
Epoch 29 loss 1.1193580627441406
Epoch 30 loss 1.1345767974853516
Epoch 31 loss 1.109988808631897
Epoch 32 loss 1.1002718210220337
Epoch 33 loss 1.1080700159072876
Epoch 34 loss 1.1412278413772583
Epoch 35 loss 1.09906005859375
Epoch 36 loss 1.1082617044448853
Epoch 37 loss 1.126882791519165
Epoch 38 loss 1.1310616731643677
Epoch 39 loss 1.102715015411377
Epoch 40 loss 1.1182546615600586
Epoch 41 loss 1.1591968536376953
Epoch 42 loss 1.0962224006652832
Epoch 43 loss 1.1257264614105225
Epoch 44 loss 1.1568838357925415
Epoch 45 loss 1.1130157709121704
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Boston/logging/loss_0.txt
File name : output/SAINT/Boston/logging/loss_0.txt . The file was saved
Log file exists at: output/SAINT/Boston/logging/val_loss_0.txt
File name : output/SAINT/Boston/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (102,)
Probabilities shape : (102, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0948, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601 ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.4187734   0.27873242 -1.3111601  -0.14644097
   0.43321145 -0.11061159  0.14775275 -0.99688337 -0.67131018 -1.47837754
   0.4487374  -1.08196   ]
 [ 1.          0.         -0.41648614 -0.49094914 -0.60984622 -0.73733458
   0.2147811   0.37093288  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.4487374  -0.50980847]
 [ 1.          0.         -0.41648832 -0.49094914 -0.60984622 -0.73733458
   1.29842261 -0.25472344  0.57290665 -0.88325045 -0.98796866 -0.30795197
   0.40426039 -1.2126196 ]
 [ 1.          0.         -0.41593476 -0.49094914 -1.33031363 -0.83153501
   1.03318575 -0.79250669  1.10373099 -0.76961753 -1.10524957  0.11340123
   0.42393081 -1.36253431]
 [ 1.          0.         -0.41620936 -0.49094914 -1.33031363 -0.83153501
   0.22754651 -0.3390816   1.10373099 -0.76961753 -1.10524957  0.11340123
   0.41835752 -1.05032662]
 [ 1.          0.         -0.40984121  0.04355194 -0.49197834 -0.26633243
  -0.36533589 -0.06140267  0.86054354 -0.54235169 -0.58334949 -1.52519456
   0.43453098 -0.05731364]
 [ 1.          0.         -0.40371062  0.04355194 -0.49197834 -0.26633243
  -0.13839526  0.97549967  1.049587   -0.54235169 -0.58334949 -1.52519456
   0.4487374   0.86693114]
 [ 1.          0.         -0.39644348  0.04355194 -0.49197834 -0.26633243
  -0.90573827  1.11258167  1.11337705 -0.54235169 -0.58334949 -1.52519456
   0.33650671  2.3495738 ]
 [ 1.          0.         -0.400933    0.04355194 -0.49197834 -0.26633243
  -0.37668292  0.6169775   1.36058773 -0.54235169 -0.58334949 -1.52519456
   0.33738095  0.58498147]
 [ 1.          0.         -0.39495605  0.04355194 -0.49197834 -0.26633243
   0.15237242  0.91223105  1.24163577 -0.54235169 -0.58334949 -1.52519456
   0.4008727   1.04572849]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.883664846420288
Epoch 1 loss 1.820746898651123
Epoch 2 loss 1.757936716079712
Epoch 3 loss 1.6798044443130493
Epoch 4 loss 1.5890427827835083
Epoch 5 loss 1.5174446105957031
Epoch 6 loss 1.4518941640853882
Epoch 7 loss 1.3680261373519897
Epoch 8 loss 1.309066653251648
Epoch 9 loss 1.2527891397476196
Epoch 10 loss 1.2248440980911255
Epoch 11 loss 1.194741129875183
Epoch 12 loss 1.171980857849121
Epoch 13 loss 1.16132652759552
Epoch 14 loss 1.1207566261291504
Epoch 15 loss 1.1289210319519043
Epoch 16 loss 1.1490440368652344
Epoch 17 loss 1.13182532787323
Epoch 18 loss 1.126011848449707
Epoch 19 loss 1.1133121252059937
Epoch 20 loss 1.1179311275482178
Epoch 21 loss 1.0995216369628906
Epoch 22 loss 1.1518521308898926
Epoch 23 loss 1.083303451538086
Epoch 24 loss 1.1346503496170044
Epoch 25 loss 1.08908212184906
Epoch 26 loss 1.1482281684875488
Epoch 27 loss 1.1294167041778564
Epoch 28 loss 1.0758047103881836
Epoch 29 loss 1.1321401596069336
Epoch 30 loss 1.113099455833435
Epoch 31 loss 1.1300219297409058
Epoch 32 loss 1.10847008228302
Epoch 33 loss 1.1698178052902222
Epoch 34 loss 1.1088353395462036
Epoch 35 loss 1.1525529623031616
Epoch 36 loss 1.116304636001587
Epoch 37 loss 1.130387544631958
Epoch 38 loss 1.1218657493591309
Epoch 39 loss 1.108636498451233
Epoch 40 loss 1.1620981693267822
Epoch 41 loss 1.1346243619918823
Epoch 42 loss 1.1421184539794922
Epoch 43 loss 1.161601185798645
Epoch 44 loss 1.1013565063476562
Epoch 45 loss 1.1980018615722656
Epoch 46 loss 1.128936529159546
Epoch 47 loss 1.1790858507156372
Epoch 48 loss 1.1775742769241333
Epoch 49 loss 1.1619598865509033
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Boston/logging/loss_1.txt
File name : output/SAINT/Boston/logging/loss_1.txt . The file was saved
Log file exists at: output/SAINT/Boston/logging/val_loss_1.txt
File name : output/SAINT/Boston/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0853000000000002, 'Log Loss - std': 0.009499999999999953} 
 

Fold 3
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.42056938 -0.4888212  -0.60741492 -0.74392033
   0.23876567  0.35529727  0.55426555 -0.87364684 -1.00997446 -0.31587901
   0.45531939 -0.528203  ]
 [ 1.          0.         -0.41596666 -0.4888212  -1.31758369 -0.83699472
   1.30685234 -0.52159414  1.06231866 -0.76085533 -1.12764816  0.09576882
   0.45531939 -1.06900562]
 [ 1.          0.         -0.40483039  0.03480498 -0.49123189 -0.27854836
  -0.37472213  0.60380901  1.3081568  -0.53527231 -0.6040002  -1.50508385
   0.3472664   0.60166285]
 [ 1.          0.         -0.39878202  0.03480498 -0.49123189 -0.27854836
   0.17403314  0.90202309  1.19430763 -0.53527231 -0.6040002  -1.50508385
   0.40887463  1.07717172]
 [ 1.          0.         -0.41323966  0.03480498 -0.49123189 -0.27854836
  -0.54390941 -1.06121963  0.77871637 -0.53527231 -0.6040002  -1.50508385
   0.3874549   0.40436216]
 [ 1.          0.         -0.35413658 -0.4888212  -0.45202012 -0.16009005
  -0.45563779 -0.2517814   0.43382852 -0.64806382 -0.62753494  1.14775772
   0.45531939 -0.65311279]
 [ 1.          0.         -0.35439792 -0.4888212  -0.45202012 -0.16009005
  -0.62482507 -0.43994028  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.44174649 -0.62330477]
 [ 1.          0.         -0.30736291 -0.4888212  -0.45202012 -0.16009005
  -0.4762345  -1.40558589  0.3369129  -0.64806382 -0.62753494  1.14775772
   0.34875094 -0.89157694]
 [ 1.          0.         -0.33710632 -0.4888212  -0.45202012 -0.16009005
  -0.39531884  0.45470197  0.22524421 -0.64806382 -0.62753494  1.14775772
   0.34769055  0.25674149]
 [ 1.          0.         -0.3350652  -0.4888212  -0.45202012 -0.16009005
  -1.18093631 -1.14642365  0.01118548 -0.64806382 -0.62753494  1.14775772
  -0.68893948 -0.16624848]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8802229166030884
Epoch 1 loss 1.8357212543487549
Epoch 2 loss 1.7696702480316162
Epoch 3 loss 1.7012157440185547
Epoch 4 loss 1.6301292181015015
Epoch 5 loss 1.5622230768203735
Epoch 6 loss 1.4899940490722656
Epoch 7 loss 1.4359714984893799
Epoch 8 loss 1.376928687095642
Epoch 9 loss 1.3222401142120361
Epoch 10 loss 1.2754175662994385
Epoch 11 loss 1.2250720262527466
Epoch 12 loss 1.1868115663528442
Epoch 13 loss 1.1754878759384155
Epoch 14 loss 1.1840440034866333
Epoch 15 loss 1.146972894668579
Epoch 16 loss 1.125779151916504
Epoch 17 loss 1.1269102096557617
Epoch 18 loss 1.139372706413269
Epoch 19 loss 1.1373164653778076
Epoch 20 loss 1.1095463037490845
Epoch 21 loss 1.1384732723236084
Epoch 22 loss 1.151740550994873
Epoch 23 loss 1.1149959564208984
Epoch 24 loss 1.1287510395050049
Epoch 25 loss 1.1367064714431763
Epoch 26 loss 1.14893639087677
Epoch 27 loss 1.1391925811767578
Epoch 28 loss 1.1458226442337036
Epoch 29 loss 1.1549655199050903
Epoch 30 loss 1.1525899171829224
Epoch 31 loss 1.132744312286377
Epoch 32 loss 1.1218805313110352
Epoch 33 loss 1.1581053733825684
Epoch 34 loss 1.140458345413208
Epoch 35 loss 1.1345795392990112
Epoch 36 loss 1.1626018285751343
Epoch 37 loss 1.1744917631149292
Epoch 38 loss 1.1689832210540771
Epoch 39 loss 1.165867567062378
Epoch 40 loss 1.1721004247665405
Epoch 41 loss 1.149640679359436
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Boston/logging/loss_2.txt
File name : output/SAINT/Boston/logging/loss_2.txt . The file was saved
Log file exists at: output/SAINT/Boston/logging/val_loss_2.txt
File name : output/SAINT/Boston/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0933666666666666, 'Log Loss - std': 0.013795248779521416} 
 

Fold 4
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.40199982  0.30903267 -1.27877395 -0.14778782
   0.37199413 -0.12658697  0.14599729 -0.98899287 -0.67900701 -1.4532496
   0.43873734 -1.05010173]
 [ 1.          0.         -0.39968202 -0.48478275 -0.59044753 -0.75071501
   1.24288869 -0.27245627  0.56534951 -0.87386148 -0.99912348 -0.30460384
   0.39343964 -1.18278002]
 [ 1.          0.         -0.39912053 -0.48478275 -1.29757279 -0.84683384
   0.97590954 -0.8167978   1.08893019 -0.75873009 -1.11768514  0.10890864
   0.41347302 -1.33501091]
 [ 1.          0.         -0.39506632 -0.48478275 -1.29757279 -0.84683384
   1.18863624 -0.51794363  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.43873734 -1.00122025]
 [ 1.          0.         -0.39939907 -0.48478275 -1.29757279 -0.84683384
   0.16497821 -0.35784318  1.08893019 -0.75873009 -1.11768514  0.10890864
   0.4077969  -1.01797961]
 [ 1.          0.         -0.39293974  0.06647796 -0.47476242 -0.27012088
  -0.43179873 -0.07677794  0.84906129 -0.5284673  -0.59008576 -1.49919543
   0.42426879 -0.00962456]
 [ 1.          0.         -0.38672137  0.06647796 -0.47476242 -0.27012088
  -0.20336736  0.97276947  1.03552505 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.9288998 ]
 [ 1.          0.         -0.37935017  0.06647796 -0.47476242 -0.27012088
  -0.9757509   1.11152319  1.09844462 -0.5284673  -0.59008576 -1.49919543
   0.32443578  2.43444931]
 [ 1.          0.         -0.38390398  0.06647796 -0.47476242 -0.27012088
  -0.44322029  0.60987511  1.34228185 -0.5284673  -0.59008576 -1.49919543
   0.32532615  0.64259401]
 [ 1.          0.         -0.3897145   0.06647796 -0.47476242 -0.27012088
  -0.43608181  0.50314147  1.16757965 -0.5284673  -0.59008576 -1.49919543
   0.43873734  0.10769098]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8781590461730957
Epoch 1 loss 1.8141824007034302
Epoch 2 loss 1.741426706314087
Epoch 3 loss 1.6590945720672607
Epoch 4 loss 1.5811280012130737
Epoch 5 loss 1.4902938604354858
Epoch 6 loss 1.402047038078308
Epoch 7 loss 1.3497563600540161
Epoch 8 loss 1.2696049213409424
Epoch 9 loss 1.230680227279663
Epoch 10 loss 1.2266870737075806
Epoch 11 loss 1.160854697227478
Epoch 12 loss 1.1748859882354736
Epoch 13 loss 1.1479476690292358
Epoch 14 loss 1.1347712278366089
Epoch 15 loss 1.1169523000717163
Epoch 16 loss 1.120805263519287
Epoch 17 loss 1.1152052879333496
Epoch 18 loss 1.1214725971221924
Epoch 19 loss 1.098713755607605
Epoch 20 loss 1.1088935136795044
Epoch 21 loss 1.085357666015625
Epoch 22 loss 1.0732413530349731
Epoch 23 loss 1.0978223085403442
Epoch 24 loss 1.0834072828292847
Epoch 25 loss 1.1018791198730469
Epoch 26 loss 1.0649842023849487
Epoch 27 loss 1.1074177026748657
Epoch 28 loss 1.0616786479949951
Epoch 29 loss 1.0772135257720947
Epoch 30 loss 1.0982035398483276
Epoch 31 loss 1.055592656135559
Epoch 32 loss 1.0840116739273071
Epoch 33 loss 1.0615590810775757
Epoch 34 loss 1.0870635509490967
Epoch 35 loss 1.0756800174713135
Epoch 36 loss 1.0766948461532593
Epoch 37 loss 1.0846666097640991
Epoch 38 loss 1.083651065826416
Epoch 39 loss 1.0720183849334717
Epoch 40 loss 1.0933430194854736
Epoch 41 loss 1.0835739374160767
Epoch 42 loss 1.0942375659942627
Epoch 43 loss 1.0872669219970703
Epoch 44 loss 1.0852680206298828
Epoch 45 loss 1.0907447338104248
Epoch 46 loss 1.1053670644760132
Epoch 47 loss 1.1007425785064697
Epoch 48 loss 1.1288609504699707
Epoch 49 loss 1.1159387826919556
Epoch 50 loss 1.1660897731781006
Epoch 51 loss 1.1306052207946777
Epoch 52 loss 1.1552610397338867
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Boston/logging/loss_3.txt
File name : output/SAINT/Boston/logging/loss_3.txt . The file was saved
Log file exists at: output/SAINT/Boston/logging/val_loss_3.txt
File name : output/SAINT/Boston/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.083925, 'Log Loss - std': 0.02025257699652065} 
 

Fold 5
num_features : 13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :13
num_classes : 1
cat_idx : [0]
nominal_idx : [3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (405, 13)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]
Cat Dims V1 : []
Cat Idx V1 : [3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118]] 
 
 
Val : (405, 14) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] 


OHE Idx : [0, 1]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[ 1.          0.         -0.43317572  0.29173066 -1.28244722 -0.13302913
   0.40034384 -0.11547912  0.13462698 -0.97126473 -0.63313291 -1.47540215
   0.44270655 -1.07367538]
 [ 1.          0.         -0.43051216 -0.48091839 -0.58662593 -0.72934599
   0.18434892  0.37281223  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.44270655 -0.49078942]
 [ 1.          0.         -0.4305147  -0.48091839 -0.58662593 -0.72934599
   1.25590816 -0.26161011  0.55971144 -0.85516018 -0.95589786 -0.29636136
   0.39839877 -1.20678636]
 [ 1.          0.         -0.42987006 -0.48091839 -1.30145074 -0.82441099
   0.99362861 -0.8069282   1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41799435 -1.35951369]
 [ 1.          0.         -0.4252155  -0.48091839 -1.30145074 -0.82441099
   1.20261071 -0.50753788  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.44270655 -1.0246345 ]
 [ 1.          0.         -0.43018984 -0.48091839 -1.30145074 -0.82441099
   0.196972   -0.34715021  1.09044908 -0.73905563 -1.07544044  0.12809332
   0.41244227 -1.04144852]
 [ 1.          0.         -0.42277401  0.05564345 -0.46968118 -0.25402095
  -0.38929995 -0.06558074  0.84730135 -0.50684653 -0.54347597 -1.52256379
   0.42855419 -0.0298051 ]
 [ 1.          0.         -0.41563481  0.05564345 -0.46968118 -0.25402095
  -0.16488963  0.98584956  1.03631394 -0.50684653 -0.54347597 -1.52256379
   0.44270655  0.91177992]
 [ 1.          0.         -0.40717208  0.05564345 -0.46968118 -0.25402095
  -0.923677    1.12485221  1.10009357 -0.50684653 -0.54347597 -1.52256379
   0.3309029   2.4222392 ]
 [ 1.          0.         -0.41240021  0.05564345 -0.46968118 -0.25402095
  -0.40052046  0.62230417  1.34726387 -0.50684653 -0.54347597 -1.52256379
   0.33177381  0.62454044]] 
 
 
Val : (405, 14) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6.]), 7)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6], Length : 7
Test after shift : [0 1 2 3 4 5 6], Length : 7
Number of Classes After Bin Verifier: 7
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 1, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 1.8632574081420898
Epoch 1 loss 1.7901111841201782
Epoch 2 loss 1.6960923671722412
Epoch 3 loss 1.5999326705932617
Epoch 4 loss 1.5249038934707642
Epoch 5 loss 1.460808515548706
Epoch 6 loss 1.3943480253219604
Epoch 7 loss 1.3250856399536133
Epoch 8 loss 1.2789757251739502
Epoch 9 loss 1.207836389541626
Epoch 10 loss 1.1941224336624146
Epoch 11 loss 1.1331121921539307
Epoch 12 loss 1.143204927444458
Epoch 13 loss 1.0735349655151367
Epoch 14 loss 1.1043058633804321
Epoch 15 loss 1.0521371364593506
Epoch 16 loss 1.052038550376892
Epoch 17 loss 1.076850175857544
Epoch 18 loss 1.0484654903411865
Epoch 19 loss 1.089414119720459
Epoch 20 loss 1.0374404191970825
Epoch 21 loss 1.0572657585144043
Epoch 22 loss 1.0389963388442993
Epoch 23 loss 1.0363234281539917
Epoch 24 loss 1.0240871906280518
Epoch 25 loss 1.0586016178131104
Epoch 26 loss 1.0260016918182373
Epoch 27 loss 1.0452513694763184
Epoch 28 loss 1.0948119163513184
Epoch 29 loss 1.0072667598724365
Epoch 30 loss 1.0446754693984985
Epoch 31 loss 1.023741602897644
Epoch 32 loss 1.0293926000595093
Epoch 33 loss 1.0404975414276123
Epoch 34 loss 1.0209401845932007
Epoch 35 loss 1.0419751405715942
Epoch 36 loss 1.0490518808364868
Epoch 37 loss 1.0398650169372559
Epoch 38 loss 1.0180647373199463
Epoch 39 loss 1.0441818237304688
Epoch 40 loss 1.0883607864379883
Epoch 41 loss 1.035703420639038
Epoch 42 loss 1.030329704284668
Epoch 43 loss 1.0481699705123901
Epoch 44 loss 1.0594913959503174
Epoch 45 loss 1.0597809553146362
Epoch 46 loss 1.054010033607483
Epoch 47 loss 1.069486141204834
Epoch 48 loss 1.0682685375213623
Epoch 49 loss 1.1003546714782715
Epoch 50 loss 1.0449857711791992
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Boston/logging/loss_4.txt
File name : output/SAINT/Boston/logging/loss_4.txt . The file was saved
Log file exists at: output/SAINT/Boston/logging/val_loss_4.txt
File name : output/SAINT/Boston/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 7
Class label len :7
Class labels : [0, 1, 2, 3, 4, 5, 6]
Unique y_true : [0 1 2 3 4 5 6] 

Prediction shape : (101,)
Probabilities shape : (101, 7) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0686, 'Log Loss - std': 0.03560275270256496} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 1.0686, 'Log Loss - std': 0.03560275270256496}
Train time: 56.76279984919999
Inference time: 0.17441438020000533
Finished cross validation
Loss path :output/SAINT/Boston/logging/
Plots saved successfully!


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/socmob.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/socmob.yml', data_parallel=False, dataset='Socmob', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[0, 1, 2, 3], num_bins=10, num_classes=1, num_features=5, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='skewed')
Start hyperparameter optimization
Loading dataset Socmob...
Dataset loaded! 

(1156, 5)
A new study created in RDB with name: SAINT_Socmob
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 5
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :5
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (924, 5)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [4]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [4] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (924, 39) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [4] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 0.1479241496870315]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 1.944725440775985]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 0.030261855045462985]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 -0.34478670912453685]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 0.13566766066186808]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 1.0 -0.27369907277858924]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 -0.24673479692322972]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 -0.17809845838231475]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 -0.2173192232628376]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 1.0 -0.3545919003446676]] 
 
 
Val : (924, 39) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 88
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.,
       52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63., 64.,
       65., 66.]), 67)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 13.,
       14., 15., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,
       28., 30., 31., 32., 33., 35., 36., 37., 38., 39., 40., 41., 42.,
       43., 44., 45., 46., 47., 48., 49., 51., 52., 53., 54., 55., 56.,
       57., 58., 59., 60., 61., 62., 63., 64., 65., 66.]), 62)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66], Length: 67
Final Test Labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 17 18 19 20 21 22 23 24 25
 26 27 28 30 31 32 33 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 51 52
 53 54 55 56 57 58 59 60 61 62 63 64 65 66], Length: 62
Final Num Classes: 67
Final Bin Labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66], Length : 67
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 17 18 19 20 21 22 23 24 25
 26 27 28 30 31 32 33 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 51 52
 53 54 55 56 57 58 59 60 61 62 63 64 65 66], Length : 62
Number of Classes After Bin Verifier: 67
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 12, 'heads': 8, 'dropout': 0.6}
Trial 0 failed with parameters: {'dim': 128, 'depth': 12, 'heads': 8, 'dropout': 0.6} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 800.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 378.44 MiB is free. Including non-PyTorch memory, this process has 7.41 GiB memory in use. Of the allocated memory 7.32 GiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 416, in __call__
    sc, time = cross_validation(model, self.X, self.y, args_cp, visual=False, save_model=False)#Dont save model during HPT
  File "train.py", line 307, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 75, in fit
    self.model.to(self.device)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1160, in to
    return self._apply(convert)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 810, in _apply
    module._apply(fn)
  [Previous line repeated 5 more times]
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 833, in _apply
    param_applied = fn(param)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1158, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 800.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 378.44 MiB is free. Including non-PyTorch memory, this process has 7.41 GiB memory in use. Of the allocated memory 7.32 GiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/sensory.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/sensory.yml', data_parallel=False, dataset='Sensory', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], num_bins=10, num_classes=1, num_features=11, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=False, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset Sensory...
Dataset loaded! 

(576, 11)
A new study created in RDB with name: SAINT_Sensory
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (460, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (460, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]] 
 
 
Val : (460, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}
Epoch 0 loss 1.7638798952102661
Epoch 1 loss 1.7077981233596802
Epoch 2 loss 1.713786005973816
Epoch 3 loss 1.7499035596847534
Epoch 4 loss 1.6914724111557007
Epoch 5 loss 1.699777364730835
Epoch 6 loss 1.7117013931274414
Epoch 7 loss 1.733486533164978
Epoch 8 loss 1.7474210262298584
Epoch 9 loss 1.7386764287948608
Epoch 10 loss 1.6681941747665405
Epoch 11 loss 1.7234517335891724
Epoch 12 loss 1.7179147005081177
Epoch 13 loss 1.6794259548187256
Epoch 14 loss 1.8482712507247925
Epoch 15 loss 1.680675745010376
Epoch 16 loss 1.7362977266311646
Epoch 17 loss 1.7156612873077393
Epoch 18 loss 1.8340665102005005
Epoch 19 loss 1.7515326738357544
Epoch 20 loss 1.7548755407333374
Epoch 21 loss 1.8946601152420044
Epoch 22 loss 1.7048283815383911
Epoch 23 loss 1.7448866367340088
Epoch 24 loss 1.726720929145813
Epoch 25 loss 1.7581156492233276
Epoch 26 loss 1.7874361276626587
Epoch 27 loss 1.8140588998794556
Epoch 28 loss 1.7401833534240723
Epoch 29 loss 1.8297615051269531
Epoch 30 loss 1.7494944334030151
Epoch 31 loss 1.8740968704223633
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 6
Class label len :6
Class labels : [0, 1, 2, 3, 4, 5]
Unique y_true : [0 1 2 3 4 5] 

Prediction shape : (116,)
Probabilities shape : (116, 6) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.6682, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (461, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (461, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]] 
 
 
Val : (461, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}
Epoch 0 loss 1.7215770483016968
Epoch 1 loss 1.6858363151550293
Epoch 2 loss 1.742058277130127
Epoch 3 loss 1.666861653327942
Epoch 4 loss 1.7147529125213623
Epoch 5 loss 1.7392668724060059
Epoch 6 loss 1.6431113481521606
Epoch 7 loss 1.62188720703125
Epoch 8 loss 1.6867568492889404
Epoch 9 loss 1.652605414390564
Epoch 10 loss 1.642716646194458
Epoch 11 loss 1.604190707206726
Epoch 12 loss 1.6596776247024536
Epoch 13 loss 1.6917988061904907
Epoch 14 loss 1.6238669157028198
Epoch 15 loss 1.686755657196045
Epoch 16 loss 1.7457894086837769
Epoch 17 loss 1.628029227256775
Epoch 18 loss 1.6945693492889404
Epoch 19 loss 1.657039999961853
Epoch 20 loss 1.7188001871109009
Epoch 21 loss 1.6389398574829102
Epoch 22 loss 1.6676398515701294
Epoch 23 loss 1.6123868227005005
Epoch 24 loss 1.5986512899398804
Epoch 25 loss 1.6238576173782349
Epoch 26 loss 1.612601399421692
Epoch 27 loss 1.748732328414917
Epoch 28 loss 1.6517817974090576
Epoch 29 loss 1.6907384395599365
Epoch 30 loss 1.662156105041504
Epoch 31 loss 1.624418020248413
Epoch 32 loss 1.669132947921753
Epoch 33 loss 1.6316219568252563
Epoch 34 loss 1.797213077545166
Epoch 35 loss 1.7331129312515259
Epoch 36 loss 1.7346001863479614
Epoch 37 loss 1.717176914215088
Epoch 38 loss 1.784171223640442
Epoch 39 loss 1.7688225507736206
Epoch 40 loss 1.735595703125
Epoch 41 loss 1.773598313331604
Epoch 42 loss 1.8358144760131836
Epoch 43 loss 1.8408735990524292
Epoch 44 loss 1.9022661447525024
Epoch 45 loss 1.7672796249389648
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 6
Class label len :6
Class labels : [0, 1, 2, 3, 4, 5]
Unique y_true : [0 1 2 3 4 5] 

Prediction shape : (115,)
Probabilities shape : (115, 6) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.6334499999999998, 'Log Loss - std': 0.03474999999999995} 
 

Fold 3
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (461, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (461, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]] 
 
 
Val : (461, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}
Epoch 0 loss 1.746151089668274
Epoch 1 loss 1.7111179828643799
Epoch 2 loss 1.707102656364441
Epoch 3 loss 1.7637877464294434
Epoch 4 loss 1.715401530265808
Epoch 5 loss 1.7359620332717896
Epoch 6 loss 1.8516982793807983
Epoch 7 loss 1.7966111898422241
Epoch 8 loss 1.8801501989364624
Epoch 9 loss 1.84251070022583
Epoch 10 loss 1.8342456817626953
Epoch 11 loss 1.813820242881775
Epoch 12 loss 1.835326910018921
Epoch 13 loss 1.810133934020996
Epoch 14 loss 1.9084177017211914
Epoch 15 loss 1.824002742767334
Epoch 16 loss 1.8266693353652954
Epoch 17 loss 1.8369237184524536
Epoch 18 loss 1.798768401145935
Epoch 19 loss 1.819257140159607
Epoch 20 loss 1.8215891122817993
Epoch 21 loss 1.8541276454925537
Epoch 22 loss 1.8724559545516968
Epoch 23 loss 1.8654841184616089
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 6
Class label len :6
Class labels : [0, 1, 2, 3, 4, 5]
Unique y_true : [0 1 2 3 4 5] 

Prediction shape : (115,)
Probabilities shape : (115, 6) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.6580000000000001, 'Log Loss - std': 0.04483800471326381} 
 

Fold 4
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (461, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (461, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]] 
 
 
Val : (461, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}
Epoch 0 loss 1.7226567268371582
Epoch 1 loss 1.687144160270691
Epoch 2 loss 1.6783488988876343
Epoch 3 loss 1.6884620189666748
Epoch 4 loss 1.669293999671936
Epoch 5 loss 1.69132399559021
Epoch 6 loss 1.6682389974594116
Epoch 7 loss 1.667907953262329
Epoch 8 loss 1.7294085025787354
Epoch 9 loss 1.7448644638061523
Epoch 10 loss 1.7101163864135742
Epoch 11 loss 1.6810334920883179
Epoch 12 loss 1.6721603870391846
Epoch 13 loss 1.7356433868408203
Epoch 14 loss 1.7053027153015137
Epoch 15 loss 1.6736806631088257
Epoch 16 loss 1.735758900642395
Epoch 17 loss 1.7306761741638184
Epoch 18 loss 1.697581171989441
Epoch 19 loss 1.7335827350616455
Epoch 20 loss 1.694103479385376
Epoch 21 loss 1.7191945314407349
Epoch 22 loss 1.7149524688720703
Epoch 23 loss 1.8094947338104248
Epoch 24 loss 1.7321155071258545
Epoch 25 loss 1.8193587064743042
Epoch 26 loss 1.7286725044250488
Epoch 27 loss 1.7749946117401123
Epoch 28 loss 1.7315582036972046
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 6
Class label len :6
Class labels : [0, 1, 2, 3, 4, 5]
Unique y_true : [0 1 2 3 4 5] 

Prediction shape : (115,)
Probabilities shape : (115, 6) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.660475, 'Log Loss - std': 0.03906676176751793} 
 

Fold 5
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (461, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (461, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]] 
 
 
Val : (461, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}
Epoch 0 loss 1.6829864978790283
Epoch 1 loss 1.6655699014663696
Epoch 2 loss 1.6605510711669922
Epoch 3 loss 1.6661560535430908
Epoch 4 loss 1.6592789888381958
Epoch 5 loss 1.6545714139938354
Epoch 6 loss 1.6951972246170044
Epoch 7 loss 1.6773148775100708
Epoch 8 loss 1.640297770500183
Epoch 9 loss 1.6988246440887451
Epoch 10 loss 1.6652249097824097
Epoch 11 loss 1.662672996520996
Epoch 12 loss 1.685807704925537
Epoch 13 loss 1.6702380180358887
Epoch 14 loss 1.659550428390503
Epoch 15 loss 1.6682590246200562
Epoch 16 loss 1.6760295629501343
Epoch 17 loss 1.8197500705718994
Epoch 18 loss 1.6472892761230469
Epoch 19 loss 1.722035527229309
Epoch 20 loss 1.731885552406311
Epoch 21 loss 1.665512204170227
Epoch 22 loss 1.6882109642028809
Epoch 23 loss 1.6680505275726318
Epoch 24 loss 1.711700201034546
Epoch 25 loss 1.6934419870376587
Epoch 26 loss 1.6472240686416626
Epoch 27 loss 1.6532206535339355
Epoch 28 loss 1.7590088844299316
Epoch 29 loss 1.6751155853271484
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 6
Class label len :6
Class labels : [0, 1, 2, 3, 4, 5]
Unique y_true : [0 1 2 3 4 5] 

Prediction shape : (115,)
Probabilities shape : (115, 6) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.65644, 'Log Loss - std': 0.035862158328801116} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 1.65644 and parameters: {'dim': 128, 'depth': 1, 'heads': 2, 'dropout': 0.5}. Best is trial 0 with value: 1.65644.
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :11
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (460, 11)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0.]] 
 
 
Val : (460, 36) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
  1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
  0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]] 
 
 
Val : (460, 36) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 7
Unique values in y_train: (array([0., 1., 2., 3., 4., 5.]), 6)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5.]), 6)
WE ARE IN THE GUTTERS!!!!!
Final Train Labels: [0 1 2 3 4 5], Length: 6
Final Test Labels: [0 1 2 3 4 5], Length: 6
Final Num Classes: 6
Final Bin Labels: [0, 1, 2, 3, 4, 5]
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5], Length : 6
Test after shift : [0 1 2 3 4 5], Length : 6
Number of Classes After Bin Verifier: 6
In get_device
Using dim 64 and batch size 64
{'dim': 64, 'depth': 12, 'heads': 2, 'dropout': 0.8}
Trial 1 failed with parameters: {'dim': 64, 'depth': 12, 'heads': 2, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 7.76 GiB memory in use. Of the allocated memory 7.46 GiB is allocated by PyTorch, and 167.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 416, in __call__
    sc, time = cross_validation(model, self.X, self.y, args_cp, visual=False, save_model=False)#Dont save model during HPT
  File "train.py", line 307, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 132, in fit
    optimizer.step()
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/adamw.py", line 173, in step
    self._init_group(
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/adamw.py", line 125, in _init_group
    state["exp_avg_sq"] = torch.zeros_like(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 28.44 MiB is free. Including non-PyTorch memory, this process has 7.76 GiB memory in use. Of the allocated memory 7.46 GiB is allocated by PyTorch, and 167.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Trial 1 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/moneyball.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/moneyball.yml', data_parallel=False, dataset='Moneyball', direction='maximize', dropna_idx=[9, 10, 12, 13], early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[0, 1, 8], num_bins=10, num_classes=1, num_features=14, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset Moneyball...
Dataset loaded! 

(1232, 10)
A new study created in RDB with name: SAINT_Moneyball
In get_device
Using dim 32 and batch size 64
Fold 1
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (985, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (985, 49) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 -0.2932461762834204
  0.005101287982464569 0.11257683392679009 0.6073689431980099
  -0.017330738916979668 0.15210539120410443]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.54401046003895 -1.2331085745177286
  1.1511011584291242 -0.42311486374418245 -0.2622798719624465
  -0.9484640752747441 0.15210539120410443]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 0.9670238577125837
  -1.0527447462759905 -0.757922174788545 0.5174052726641695
  0.06026370577950071 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 0.46505189501926003
  -1.757975435781627 -1.6284211835038873 -0.592146663919865
  -1.4916251881501068 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 -0.42140923058809876
  0.35771663273528287 -0.5570377881619274 0.7273205039097973
  -0.32770851770290116 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.54401046003895 -1.361271628822407
  1.4155626669937378 -0.757922174788545 0.39745371195238216
  -0.6380862964888226 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 1.8641652378453324
  -1.4935139272170133 0.24649975834454252 1.147150966401053
  1.1465859315302174 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 1.0 1.54401046003895 -0.485490757740438
  0.6221781412998967 0.581307069388905 0.7273205039097973
  0.6810192633513437 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 0.3262085861891918
  -0.7882832377113766 -0.6239992503708 0.06758691999496864
  0.4482359292619026 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 -0.17576337650413187
  0.7103319774881012 0.3804226827622875 1.0571872958672126
  1.1465859315302174 0.15210539120410443]] 
 
 
Val : (985, 49) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 32 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}
Epoch 0 loss 1.908731460571289
Epoch 1 loss 1.4864118099212646
Epoch 2 loss 1.2546920776367188
Epoch 3 loss 1.122117519378662
Epoch 4 loss 1.0461927652359009
Epoch 5 loss 1.1179176568984985
Epoch 6 loss 0.970954179763794
Epoch 7 loss 0.9448007345199585
Epoch 8 loss 0.9567464590072632
Epoch 9 loss 1.0192711353302002
Epoch 10 loss 0.995821475982666
Epoch 11 loss 0.9559780359268188
Epoch 12 loss 0.9475436210632324
Epoch 13 loss 1.0015766620635986
Epoch 14 loss 0.9592508673667908
Epoch 15 loss 0.947447657585144
Epoch 16 loss 1.0143274068832397
Epoch 17 loss 0.957470178604126
Epoch 18 loss 0.958389163017273
Epoch 19 loss 0.9464243650436401
Epoch 20 loss 0.9620571136474609
Epoch 21 loss 1.006566047668457
Epoch 22 loss 1.0437469482421875
Epoch 23 loss 1.0323294401168823
Epoch 24 loss 1.0437970161437988
Epoch 25 loss 1.108215570449829
Epoch 26 loss 1.041177749633789
Epoch 27 loss 1.1196537017822266
Epoch 28 loss 1.1511995792388916
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (247,)
Probabilities shape : (247, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9461, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (985, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (985, 50) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5518309595756514 -0.2984739322018782
  0.03428077988573539 0.124993940297029 0.6192431259002107
  -0.016467038676321873 0.12620928561553893]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.5518309595756514 -1.225908705762921
  1.154090439163381 -0.4008748528373132 -0.24374559885655983
  -0.9433260727437409 0.12620928561553893]
 [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5518309595756514 -0.11931039640031312
  1.0679512346035622 -0.9924772451134565 0.5894848940120462
  -0.9433260727437409 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5518309595756514 0.4497973055575995
  -1.6885033113106425 -1.5840796373895998 -0.5710861496263733
  -1.4839938426164019 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5518309595756514 -0.42494231041474767
  0.378837598125011 -0.5323420511209006 0.738276053452869
  -0.3254200500321282 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.5518309595756514 -1.3523770839757905
  1.4125080528428378 -0.7295428485462817 0.4109355026830588
  -0.6343730613879346 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5518309595756514 1.356154016083164
  -1.0855288793919102 -0.13794045627013848 -0.4818114539618763
  -0.6343730613879346 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5518309595756514 -0.48817649952118236
  0.6372552118044676 0.5851291342895921 0.738276053452869
  0.6786772368742424 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5518309595756514 0.8186634086784688
  -2.205338538669556 -1.5840796373895998 -0.7793937728435218
  -1.7929468539722082 0.12620928561553893]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5518309595756514 -0.18254458550674785
  0.7233944163642866 0.3879283368642111 1.0656166042226791
  1.1421067539079433 0.12620928561553893]] 
 
 
Val : (985, 50) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}
Epoch 0 loss 2.059488296508789
Epoch 1 loss 2.0184810161590576
Epoch 2 loss 1.8772436380386353
Epoch 3 loss 1.6907446384429932
Epoch 4 loss 1.517322063446045
Epoch 5 loss 1.3801610469818115
Epoch 6 loss 1.2851793766021729
Epoch 7 loss 1.180879831314087
Epoch 8 loss 1.117870569229126
Epoch 9 loss 1.0862293243408203
Epoch 10 loss 1.0847883224487305
Epoch 11 loss 1.0033048391342163
Epoch 12 loss 1.007059931755066
Epoch 13 loss 0.9765235185623169
Epoch 14 loss 0.9901818633079529
Epoch 15 loss 0.9267838597297668
Epoch 16 loss 0.9504057168960571
Epoch 17 loss 0.9028490781784058
Epoch 18 loss 0.9509838819503784
Epoch 19 loss 0.8977806568145752
Epoch 20 loss 0.9064857363700867
Epoch 21 loss 0.9033200740814209
Epoch 22 loss 0.8837203979492188
Epoch 23 loss 0.9309967160224915
Epoch 24 loss 0.8736011981964111
Epoch 25 loss 0.9568896293640137
Epoch 26 loss 0.9667879939079285
Epoch 27 loss 0.8650139570236206
Epoch 28 loss 0.8853209614753723
Epoch 29 loss 0.9316363334655762
Epoch 30 loss 0.8648725748062134
Epoch 31 loss 0.8820284605026245
Epoch 32 loss 0.873239278793335
Epoch 33 loss 0.8615551590919495
Epoch 34 loss 0.9078863859176636
Epoch 35 loss 0.8567841053009033
Epoch 36 loss 0.8675755262374878
Epoch 37 loss 0.8880699872970581
Epoch 38 loss 0.8693026304244995
Epoch 39 loss 0.8813704252243042
Epoch 40 loss 0.8808351755142212
Epoch 41 loss 0.8762412071228027
Epoch 42 loss 0.868094801902771
Epoch 43 loss 0.8741641044616699
Epoch 44 loss 0.8839350938796997
Epoch 45 loss 0.8963825702667236
Epoch 46 loss 0.9171911478042603
Epoch 47 loss 0.9088176488876343
Epoch 48 loss 0.9435106515884399
Epoch 49 loss 0.9338191747665405
Epoch 50 loss 0.9061802625656128
Epoch 51 loss 0.8686631917953491
Epoch 52 loss 0.9113655686378479
Epoch 53 loss 0.9182254076004028
Epoch 54 loss 0.9404211044311523
Epoch 55 loss 0.963627278804779
Epoch 56 loss 0.954704761505127
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (247,)
Probabilities shape : (247, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.89865, 'Log Loss - std': 0.04745000000000005} 
 

Fold 3
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (986, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (986, 50) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5511319556733212 -0.29955527895669254
  0.006058531598584041 0.10159790047279765 0.6382535614917421
  -0.02166551570739544 0.1324923812219859]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.5511319556733212 -1.2648248019081667
  1.1480917379316513 -0.44025756871546906 -0.24974869314502668
  -0.9675931240096076 0.1324923812219859]
 [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5511319556733212 -0.11308275747743048
  1.0602430297521845 -1.0498449715522775 0.6076327940904741
  -0.9675931240096076 0.1324923812219859]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5511319556733212 0.9947833995464206
  -1.0481259665550164 -0.7789172369581404 0.5463912592879382
  0.05716178498445557 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5511319556733212 0.4792417225155196
  -1.7509156319907502 -1.659432374389086 -0.5865771345589774
  -1.5193842288525647 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.5511319556733212 -1.3964524641288223
  1.4116378624700514 -0.7789172369581404 0.4239081896828664
  -0.6522839212422036 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5511319556733212 1.4225733017635511
  -1.1359746747344832 -0.16932983412133193 -0.4947148323551702
  -0.6522839212422036 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5511319556733212 1.9161770350910097
  -1.48736950745235 0.23706176776987373 1.189427374714565
  1.160743994670361 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5511319556733212 -0.4969967722876759
  0.620999488854851 0.5757214360125451 0.7607366310968138
  0.6877801905192638 0.1324923812219859]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5511319556733212 0.863155737325765
  -2.2780078810675506 -1.659432374389086 -0.8009225063678497
  -1.8346934316199688 0.1324923812219859]] 
 
 
Val : (986, 50) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}
Epoch 0 loss 2.0699853897094727
Epoch 1 loss 2.022752285003662
Epoch 2 loss 1.8779864311218262
Epoch 3 loss 1.6315293312072754
Epoch 4 loss 1.4200547933578491
Epoch 5 loss 1.271834373474121
Epoch 6 loss 1.152394413948059
Epoch 7 loss 1.0886359214782715
Epoch 8 loss 1.0704808235168457
Epoch 9 loss 1.0183608531951904
Epoch 10 loss 1.0169326066970825
Epoch 11 loss 1.0047320127487183
Epoch 12 loss 0.9709503650665283
Epoch 13 loss 0.9387315511703491
Epoch 14 loss 1.0170648097991943
Epoch 15 loss 0.9119035601615906
Epoch 16 loss 0.9412115812301636
Epoch 17 loss 0.9087204933166504
Epoch 18 loss 0.9430191516876221
Epoch 19 loss 0.8897688388824463
Epoch 20 loss 0.9357189536094666
Epoch 21 loss 0.9231293201446533
Epoch 22 loss 0.8932634592056274
Epoch 23 loss 0.9157345294952393
Epoch 24 loss 0.9123597741127014
Epoch 25 loss 0.9074211120605469
Epoch 26 loss 0.9105733633041382
Epoch 27 loss 0.9035567045211792
Epoch 28 loss 0.9012534618377686
Epoch 29 loss 0.9387713670730591
Epoch 30 loss 0.8842166066169739
Epoch 31 loss 0.9299365878105164
Epoch 32 loss 0.9259841442108154
Epoch 33 loss 0.8941065073013306
Epoch 34 loss 0.9174339771270752
Epoch 35 loss 0.9173704385757446
Epoch 36 loss 0.9325881004333496
Epoch 37 loss 0.9237571954727173
Epoch 38 loss 0.925926148891449
Epoch 39 loss 0.9289244413375854
Epoch 40 loss 0.9296493530273438
Epoch 41 loss 0.9640219211578369
Epoch 42 loss 0.9300130009651184
Epoch 43 loss 0.9690171480178833
Epoch 44 loss 0.9414190053939819
Epoch 45 loss 0.947006106376648
Epoch 46 loss 0.9540321826934814
Epoch 47 loss 0.9886546730995178
Epoch 48 loss 0.9552099704742432
Epoch 49 loss 0.9584976434707642
Epoch 50 loss 1.0078201293945312
Epoch 51 loss 0.9872312545776367
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (246,)
Probabilities shape : (246, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.8934333333333333, 'Log Loss - std': 0.039438926061556134} 
 

Fold 4
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (986, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (986, 49) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.5866258884921898 -0.2544455216877482
  -0.020989786171218102 0.11353605845597158 0.6341337701362169
  -0.013054365583245546 0.12105516374115395]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.5866258884921898 -1.2041069560392008
  1.1047302102416192 -0.4163884558048092 -0.23640351073540256
  -0.9324546845174484 0.12105516374115395]
 [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 1.0 1.5866258884921898 -0.07098819914258123
  1.0181363643637087 -1.012553534348196 0.6041152432096092
  -0.9324546845174484 0.12105516374115395]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.5866258884921898 1.0189641289198814
  -1.060115936706145 -0.7475912772178018 0.544078189356394
  0.06356232766127136 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.5866258884921898 -0.383944808190219
  0.32538559734042416 -0.5488695843700062 0.7542078778426473
  -0.31952113856131314 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.5866258884921898 -1.3336062425416715
  1.364511747875351 -0.7475912772178018 0.4240040816499635
  -0.6259879115393808 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.5866258884921898 1.4398368100529115
  -1.1467097825840555 -0.15142619867441515 -0.4765517261482635
  -0.6259879115393808 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.5866258884921898 1.925459134437177
  -1.4930851660956979 0.24601718702117598 1.174467254815154
  1.1361960330844996 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.5866258884921898 0.8894648424174105
  -2.272429778996893 -1.6087186128915825 -0.7767369954143398
  -1.7752383102071343 0.12105516374115395]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.5866258884921898 0.37146769640752736
  -0.8003343990724132 -0.6151101486526048 0.0938002854572813
  0.4466457938838559 0.12105516374115395]] 
 
 
Val : (986, 49) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 32 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}
Epoch 0 loss 1.9012278318405151
Epoch 1 loss 1.518700361251831
Epoch 2 loss 1.2829580307006836
Epoch 3 loss 1.081984281539917
Epoch 4 loss 1.0243422985076904
Epoch 5 loss 1.0138894319534302
Epoch 6 loss 1.0338265895843506
Epoch 7 loss 1.0106146335601807
Epoch 8 loss 0.997918963432312
Epoch 9 loss 1.137956142425537
Epoch 10 loss 1.0789592266082764
Epoch 11 loss 1.08770751953125
Epoch 12 loss 1.026986837387085
Epoch 13 loss 1.0241060256958008
Epoch 14 loss 1.0606305599212646
Epoch 15 loss 1.0917178392410278
Epoch 16 loss 1.0607328414916992
Epoch 17 loss 1.1815848350524902
Epoch 18 loss 1.0863027572631836
Epoch 19 loss 1.1232316493988037
Epoch 20 loss 1.0821456909179688
Epoch 21 loss 1.0980216264724731
Epoch 22 loss 1.118672251701355
Epoch 23 loss 1.074214220046997
Epoch 24 loss 1.14853835105896
Epoch 25 loss 1.1415600776672363
Epoch 26 loss 1.1377662420272827
Epoch 27 loss 1.157780408859253
Epoch 28 loss 1.1086621284484863
Epoch 29 loss 1.2121319770812988
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (246,)
Probabilities shape : (246, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.92065, 'Log Loss - std': 0.058213507882621196} 
 

Fold 5
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (986, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (986, 50) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5453194098373437 -0.12666570459245366
  1.07260090432717 -1.0288571925021945 0.5778518225514135
  -0.9651510526932938 0.1189606070994637]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5453194098373437 0.9624493754925159
  -1.0379951209512384 -0.7625266091976093 0.5178453036429677
  0.040074119438229035 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5453194098373437 0.4556334471361439
  -1.7415271293773744 -1.628101004937511 -0.5922752961632846
  -1.5064261453794985 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5453194098373437 -0.4393819157059598
  0.3690688959010339 -0.5627786717191704 0.7278681198225285
  -0.3465509467662028 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5453194098373437 1.3829987628520586
  -1.1259366220045053 -0.16328279676229265 -0.5022655178006122
  -0.6558509997297483 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5453194098373437 1.8682480559592232
  -1.4777026262175734 0.23621307819458515 1.1479137521816503
  1.1226243048106297 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 1.0 1.5453194098373437 -0.5040818214535817
  0.632893399060835 0.5691263073253167 0.7278681198225285
  0.65867422536532 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.5453194098373437 0.8330495639972719
  -2.2691761356969766 -1.628101004937511 -0.8022981123428422
  -1.815726198343044 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5453194098373437 0.31545031801629636
  -0.7741706177914373 -0.6293613175453168 0.06779641182962447
  0.4266991856426609 0.1189606070994637]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.5453194098373437 -0.19136561034007563
  0.720834900114102 0.3693783698468777 1.0579039738189815
  1.1226243048106297 0.1189606070994637]] 
 
 
Val : (986, 50) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}
Epoch 0 loss 2.0605738162994385
Epoch 1 loss 2.0192346572875977
Epoch 2 loss 1.8879096508026123
Epoch 3 loss 1.648890495300293
Epoch 4 loss 1.450763463973999
Epoch 5 loss 1.306020975112915
Epoch 6 loss 1.208674430847168
Epoch 7 loss 1.0564554929733276
Epoch 8 loss 1.0151348114013672
Epoch 9 loss 1.0061044692993164
Epoch 10 loss 0.9961299896240234
Epoch 11 loss 0.9374853372573853
Epoch 12 loss 0.9718081951141357
Epoch 13 loss 0.938143253326416
Epoch 14 loss 0.9076770544052124
Epoch 15 loss 0.9080023765563965
Epoch 16 loss 0.938244104385376
Epoch 17 loss 0.928046703338623
Epoch 18 loss 0.8988034725189209
Epoch 19 loss 0.9429404139518738
Epoch 20 loss 0.9088079929351807
Epoch 21 loss 0.8996062278747559
Epoch 22 loss 0.8820378184318542
Epoch 23 loss 0.8929674625396729
Epoch 24 loss 0.9293827414512634
Epoch 25 loss 0.9080836772918701
Epoch 26 loss 0.9505867958068848
Epoch 27 loss 0.9322143793106079
Epoch 28 loss 0.8838603496551514
Epoch 29 loss 0.9187932014465332
Epoch 30 loss 0.905559778213501
Epoch 31 loss 0.8945306539535522
Epoch 32 loss 0.9150041341781616
Epoch 33 loss 0.9025313854217529
Epoch 34 loss 0.9143214821815491
Epoch 35 loss 0.9183804988861084
Epoch 36 loss 0.9097493886947632
Epoch 37 loss 0.9582180976867676
Epoch 38 loss 0.937302827835083
Epoch 39 loss 0.9207854270935059
Epoch 40 loss 0.9446298480033875
Epoch 41 loss 0.9203003644943237
Epoch 42 loss 0.9314830899238586
Epoch 43 loss 0.9451038837432861
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (246,)
Probabilities shape : (246, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.91304, 'Log Loss - std': 0.05424664413583572} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 0.91304 and parameters: {'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0}. Best is trial 0 with value: 0.91304.
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :10
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 1, 8]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (985, 10)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [2, 3, 4, 5, 6, 7, 9]
Cat Dims V1 : []
Cat Idx V1 : [0, 1, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (985, 49) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [2, 3, 4, 5, 6, 7, 9] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 -0.2932461762834204
  0.005101287982464569 0.11257683392679009 0.6073689431980099
  -0.017330738916979668 0.15210539120410443]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.54401046003895 -1.2331085745177286
  1.1511011584291242 -0.42311486374418245 -0.2622798719624465
  -0.9484640752747441 0.15210539120410443]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 0.9670238577125837
  -1.0527447462759905 -0.757922174788545 0.5174052726641695
  0.06026370577950071 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 0.46505189501926003
  -1.757975435781627 -1.6284211835038873 -0.592146663919865
  -1.4916251881501068 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 -0.42140923058809876
  0.35771663273528287 -0.5570377881619274 0.7273205039097973
  -0.32770851770290116 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 1.0 1.54401046003895 -1.361271628822407
  1.4155626669937378 -0.757922174788545 0.39745371195238216
  -0.6380862964888226 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 1.0 0.0 1.54401046003895 1.8641652378453324
  -1.4935139272170133 0.24649975834454252 1.147150966401053
  1.1465859315302174 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 1.0 1.54401046003895 -0.485490757740438
  0.6221781412998967 0.581307069388905 0.7273205039097973
  0.6810192633513437 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 0.3262085861891918
  -0.7882832377113766 -0.6239992503708 0.06758691999496864
  0.4482359292619026 0.15210539120410443]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 1.0 0.0 1.54401046003895 -0.17576337650413187
  0.7103319774881012 0.3804226827622875 1.0571872958672126
  1.1465859315302174 0.15210539120410443]] 
 
 
Val : (985, 49) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 1, 'heads': 8, 'dropout': 0.2}
Trial 1 failed with parameters: {'dim': 128, 'depth': 1, 'heads': 8, 'dropout': 0.2} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 594.44 MiB is free. Including non-PyTorch memory, this process has 7.20 GiB memory in use. Of the allocated memory 7.00 GiB is allocated by PyTorch, and 75.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 416, in __call__
    sc, time = cross_validation(model, self.X, self.y, args_cp, visual=False, save_model=False)#Dont save model during HPT
  File "train.py", line 307, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 132, in fit
    optimizer.step()
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/adamw.py", line 173, in step
    self._init_group(
  File "/home/mburu/anaconda3/envs/TabSurvey/lib/python3.8/site-packages/torch/optim/adamw.py", line 121, in _init_group
    state["exp_avg"] = torch.zeros_like(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 626.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 594.44 MiB is free. Including non-PyTorch memory, this process has 7.20 GiB memory in use. Of the allocated memory 7.00 GiB is allocated by PyTorch, and 75.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Trial 1 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/black_friday.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/black_friday.yml', data_parallel=False, dataset='Black_Friday', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[0, 2, 3, 4, 5, 6, 7, 8], num_bins=10, num_classes=1, num_features=9, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[1], scale=False, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='bimodial')
Start hyperparameter optimization
Loading dataset Black_Friday...
Dataset loaded! 

(166821, 9)
A new study created in RDB with name: SAINT_Black_Friday
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133456, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133456, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]] 
 
 
Val : (133456, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.1903605461120605
Epoch 1 loss 2.172804355621338
Epoch 2 loss 2.1614887714385986
Epoch 3 loss 2.1679275035858154
Epoch 4 loss 2.148488759994507
Epoch 5 loss 2.1493775844573975
Epoch 6 loss 2.146859645843506
Epoch 7 loss 2.1456830501556396
Epoch 8 loss 2.147036552429199
Epoch 9 loss 2.143486976623535
Epoch 10 loss 2.143254041671753
Epoch 11 loss 2.1496176719665527
Epoch 12 loss 2.156080961227417
Epoch 13 loss 2.1595683097839355
Epoch 14 loss 2.170161008834839
Epoch 15 loss 2.1797432899475098
Epoch 16 loss 2.1965415477752686
Epoch 17 loss 2.2290120124816895
Epoch 18 loss 2.256251335144043
Epoch 19 loss 2.2775321006774902
Epoch 20 loss 2.3169138431549072
Epoch 21 loss 2.358102321624756
Epoch 22 loss 2.4103524684906006
Epoch 23 loss 2.4292566776275635
Epoch 24 loss 2.5210845470428467
Epoch 25 loss 2.567013740539551
Epoch 26 loss 2.6154496669769287
Epoch 27 loss 2.675171136856079
Epoch 28 loss 2.7201199531555176
Epoch 29 loss 2.8535614013671875
Epoch 30 loss 2.8441731929779053
Epoch 31 loss 2.9327690601348877
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33365,)
Probabilities shape : (33365, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1433, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.1792702674865723
Epoch 1 loss 2.1602604389190674
Epoch 2 loss 2.1559786796569824
Epoch 3 loss 2.1427454948425293
Epoch 4 loss 2.1386308670043945
Epoch 5 loss 2.1416189670562744
Epoch 6 loss 2.138139009475708
Epoch 7 loss 2.136396646499634
Epoch 8 loss 2.1342341899871826
Epoch 9 loss 2.13439679145813
Epoch 10 loss 2.13161563873291
Epoch 11 loss 2.140256404876709
Epoch 12 loss 2.14249849319458
Epoch 13 loss 2.1452620029449463
Epoch 14 loss 2.160526990890503
Epoch 15 loss 2.1775379180908203
Epoch 16 loss 2.1887803077697754
Epoch 17 loss 2.2156431674957275
Epoch 18 loss 2.241848945617676
Epoch 19 loss 2.27771258354187
Epoch 20 loss 2.3005964756011963
Epoch 21 loss 2.333148956298828
Epoch 22 loss 2.3856394290924072
Epoch 23 loss 2.449223279953003
Epoch 24 loss 2.478492498397827
Epoch 25 loss 2.5355327129364014
Epoch 26 loss 2.59274959564209
Epoch 27 loss 2.658521890640259
Epoch 28 loss 2.742657423019409
Epoch 29 loss 2.7843315601348877
Epoch 30 loss 2.8357388973236084
Epoch 31 loss 2.9210376739501953
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.13755, 'Log Loss - std': 0.005749999999999922} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.185123920440674
Epoch 1 loss 2.1657609939575195
Epoch 2 loss 2.155985116958618
Epoch 3 loss 2.1499040126800537
Epoch 4 loss 2.1470134258270264
Epoch 5 loss 2.1458306312561035
Epoch 6 loss 2.145796775817871
Epoch 7 loss 2.140610933303833
Epoch 8 loss 2.1434106826782227
Epoch 9 loss 2.1432480812072754
Epoch 10 loss 2.1449508666992188
Epoch 11 loss 2.15236234664917
Epoch 12 loss 2.158123016357422
Epoch 13 loss 2.1661553382873535
Epoch 14 loss 2.1733062267303467
Epoch 15 loss 2.188632011413574
Epoch 16 loss 2.2050695419311523
Epoch 17 loss 2.2381067276000977
Epoch 18 loss 2.2575247287750244
Epoch 19 loss 2.2881264686584473
Epoch 20 loss 2.327174425125122
Epoch 21 loss 2.3602843284606934
Epoch 22 loss 2.424058675765991
Epoch 23 loss 2.464946985244751
Epoch 24 loss 2.5180563926696777
Epoch 25 loss 2.576348066329956
Epoch 26 loss 2.65144681930542
Epoch 27 loss 2.7084648609161377
Epoch 28 loss 2.786329746246338
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1385666666666667, 'Log Loss - std': 0.0049100803342601515} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.1899607181549072
Epoch 1 loss 2.1667842864990234
Epoch 2 loss 2.1582143306732178
Epoch 3 loss 2.157203435897827
Epoch 4 loss 2.1541247367858887
Epoch 5 loss 2.1552155017852783
Epoch 6 loss 2.1546950340270996
Epoch 7 loss 2.1451058387756348
Epoch 8 loss 2.1497082710266113
Epoch 9 loss 2.1510801315307617
Epoch 10 loss 2.151125431060791
Epoch 11 loss 2.1521072387695312
Epoch 12 loss 2.1591529846191406
Epoch 13 loss 2.1627275943756104
Epoch 14 loss 2.1757171154022217
Epoch 15 loss 2.1916592121124268
Epoch 16 loss 2.2077181339263916
Epoch 17 loss 2.230665445327759
Epoch 18 loss 2.260618209838867
Epoch 19 loss 2.288090467453003
Epoch 20 loss 2.326979160308838
Epoch 21 loss 2.369493246078491
Epoch 22 loss 2.4140849113464355
Epoch 23 loss 2.463244676589966
Epoch 24 loss 2.5133862495422363
Epoch 25 loss 2.589719295501709
Epoch 26 loss 2.628882884979248
Epoch 27 loss 2.7047135829925537
Epoch 28 loss 2.759817600250244
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.140325, 'Log Loss - std': 0.005230380005315031} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.1791529655456543
Epoch 1 loss 2.1579630374908447
Epoch 2 loss 2.1519036293029785
Epoch 3 loss 2.1456594467163086
Epoch 4 loss 2.142461061477661
Epoch 5 loss 2.1425371170043945
Epoch 6 loss 2.1386501789093018
Epoch 7 loss 2.139878749847412
Epoch 8 loss 2.1406314373016357
Epoch 9 loss 2.1442084312438965
Epoch 10 loss 2.1394033432006836
Epoch 11 loss 2.1422536373138428
Epoch 12 loss 2.149573564529419
Epoch 13 loss 2.1544148921966553
Epoch 14 loss 2.1638104915618896
Epoch 15 loss 2.178739547729492
Epoch 16 loss 2.1820356845855713
Epoch 17 loss 2.2079825401306152
Epoch 18 loss 2.241368532180786
Epoch 19 loss 2.2691712379455566
Epoch 20 loss 2.3040647506713867
Epoch 21 loss 2.34114408493042
Epoch 22 loss 2.3895153999328613
Epoch 23 loss 2.426405191421509
Epoch 24 loss 2.4664294719696045
Epoch 25 loss 2.5337843894958496
Epoch 26 loss 2.5749402046203613
Epoch 27 loss 2.651434898376465
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1400599999999996, 'Log Loss - std': 0.004708120644163604} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 2.1400599999999996 and parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}. Best is trial 0 with value: 2.1400599999999996.
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133456, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133456, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]] 
 
 
Val : (133456, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.227416753768921
Epoch 1 loss 2.197471857070923
Epoch 2 loss 2.1828322410583496
Epoch 3 loss 2.1750049591064453
Epoch 4 loss 2.176123857498169
Epoch 5 loss 2.1584062576293945
Epoch 6 loss 2.161212682723999
Epoch 7 loss 2.1566309928894043
Epoch 8 loss 2.158299684524536
Epoch 9 loss 2.1528563499450684
Epoch 10 loss 2.153040647506714
Epoch 11 loss 2.1545917987823486
Epoch 12 loss 2.1504018306732178
Epoch 13 loss 2.153553009033203
Epoch 14 loss 2.146609306335449
Epoch 15 loss 2.148388385772705
Epoch 16 loss 2.1510443687438965
Epoch 17 loss 2.1436078548431396
Epoch 18 loss 2.1452364921569824
Epoch 19 loss 2.1435630321502686
Epoch 20 loss 2.1451938152313232
Epoch 21 loss 2.1457200050354004
Epoch 22 loss 2.145998477935791
Epoch 23 loss 2.143887519836426
Epoch 24 loss 2.1442911624908447
Epoch 25 loss 2.142533540725708
Epoch 26 loss 2.141411542892456
Epoch 27 loss 2.14149808883667
Epoch 28 loss 2.1398468017578125
Epoch 29 loss 2.1404857635498047
Epoch 30 loss 2.1372928619384766
Epoch 31 loss 2.1405811309814453
Epoch 32 loss 2.141172170639038
Epoch 33 loss 2.142886161804199
Epoch 34 loss 2.1401255130767822
Epoch 35 loss 2.1380958557128906
Epoch 36 loss 2.138956069946289
Epoch 37 loss 2.1404569149017334
Epoch 38 loss 2.1384780406951904
Epoch 39 loss 2.1412906646728516
Epoch 40 loss 2.13991117477417
Epoch 41 loss 2.146358013153076
Epoch 42 loss 2.1418004035949707
Epoch 43 loss 2.141056537628174
Epoch 44 loss 2.138723134994507
Epoch 45 loss 2.1402101516723633
Epoch 46 loss 2.1389458179473877
Epoch 47 loss 2.140446662902832
Epoch 48 loss 2.1428117752075195
Epoch 49 loss 2.142155408859253
Epoch 50 loss 2.143378257751465
Epoch 51 loss 2.1438958644866943
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33365,)
Probabilities shape : (33365, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1376, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.2299845218658447
Epoch 1 loss 2.1954257488250732
Epoch 2 loss 2.1752188205718994
Epoch 3 loss 2.168618679046631
Epoch 4 loss 2.1720707416534424
Epoch 5 loss 2.152928113937378
Epoch 6 loss 2.153132915496826
Epoch 7 loss 2.1537623405456543
Epoch 8 loss 2.150604248046875
Epoch 9 loss 2.1462433338165283
Epoch 10 loss 2.143259048461914
Epoch 11 loss 2.1438398361206055
Epoch 12 loss 2.1397972106933594
Epoch 13 loss 2.136399984359741
Epoch 14 loss 2.1379871368408203
Epoch 15 loss 2.1356844902038574
Epoch 16 loss 2.13826847076416
Epoch 17 loss 2.136526346206665
Epoch 18 loss 2.133450746536255
Epoch 19 loss 2.132572650909424
Epoch 20 loss 2.1358227729797363
Epoch 21 loss 2.132477283477783
Epoch 22 loss 2.1330454349517822
Epoch 23 loss 2.136599063873291
Epoch 24 loss 2.137835741043091
Epoch 25 loss 2.1302430629730225
Epoch 26 loss 2.131237745285034
Epoch 27 loss 2.129068374633789
Epoch 28 loss 2.1317758560180664
Epoch 29 loss 2.132564067840576
Epoch 30 loss 2.1280248165130615
Epoch 31 loss 2.1365771293640137
Epoch 32 loss 2.130296230316162
Epoch 33 loss 2.130852222442627
Epoch 34 loss 2.1303513050079346
Epoch 35 loss 2.131598711013794
Epoch 36 loss 2.1307928562164307
Epoch 37 loss 2.1323049068450928
Epoch 38 loss 2.130985975265503
Epoch 39 loss 2.1279680728912354
Epoch 40 loss 2.1337010860443115
Epoch 41 loss 2.131519317626953
Epoch 42 loss 2.1276137828826904
Epoch 43 loss 2.130215644836426
Epoch 44 loss 2.1314873695373535
Epoch 45 loss 2.132521867752075
Epoch 46 loss 2.127622604370117
Epoch 47 loss 2.1346428394317627
Epoch 48 loss 2.1325886249542236
Epoch 49 loss 2.1309900283813477
Epoch 50 loss 2.1334502696990967
Epoch 51 loss 2.131304979324341
Epoch 52 loss 2.129511594772339
Epoch 53 loss 2.132558822631836
Epoch 54 loss 2.133012533187866
Epoch 55 loss 2.1319468021392822
Epoch 56 loss 2.1341123580932617
Epoch 57 loss 2.1317038536071777
Epoch 58 loss 2.1388282775878906
Epoch 59 loss 2.1361911296844482
Epoch 60 loss 2.1391916275024414
Epoch 61 loss 2.132999897003174
Epoch 62 loss 2.1330463886260986
Epoch 63 loss 2.1351358890533447
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1327, 'Log Loss - std': 0.004899999999999904} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.2210869789123535
Epoch 1 loss 2.1921186447143555
Epoch 2 loss 2.1857481002807617
Epoch 3 loss 2.1697027683258057
Epoch 4 loss 2.166898012161255
Epoch 5 loss 2.1625170707702637
Epoch 6 loss 2.1582934856414795
Epoch 7 loss 2.155529737472534
Epoch 8 loss 2.161102056503296
Epoch 9 loss 2.1471517086029053
Epoch 10 loss 2.1492300033569336
Epoch 11 loss 2.1450304985046387
Epoch 12 loss 2.1435928344726562
Epoch 13 loss 2.1458632946014404
Epoch 14 loss 2.1474320888519287
Epoch 15 loss 2.143264055252075
Epoch 16 loss 2.1431519985198975
Epoch 17 loss 2.1479170322418213
Epoch 18 loss 2.145477056503296
Epoch 19 loss 2.143583297729492
Epoch 20 loss 2.142051935195923
Epoch 21 loss 2.14074969291687
Epoch 22 loss 2.141206741333008
Epoch 23 loss 2.1378419399261475
Epoch 24 loss 2.1396923065185547
Epoch 25 loss 2.142385482788086
Epoch 26 loss 2.1404314041137695
Epoch 27 loss 2.138521432876587
Epoch 28 loss 2.1406030654907227
Epoch 29 loss 2.136950731277466
Epoch 30 loss 2.1357762813568115
Epoch 31 loss 2.139247417449951
Epoch 32 loss 2.140050172805786
Epoch 33 loss 2.139467716217041
Epoch 34 loss 2.1391310691833496
Epoch 35 loss 2.1373002529144287
Epoch 36 loss 2.136486053466797
Epoch 37 loss 2.1363213062286377
Epoch 38 loss 2.1386470794677734
Epoch 39 loss 2.135881185531616
Epoch 40 loss 2.1379013061523438
Epoch 41 loss 2.1379024982452393
Epoch 42 loss 2.138749599456787
Epoch 43 loss 2.1364541053771973
Epoch 44 loss 2.1380817890167236
Epoch 45 loss 2.1343326568603516
Epoch 46 loss 2.1386828422546387
Epoch 47 loss 2.1369667053222656
Epoch 48 loss 2.13618540763855
Epoch 49 loss 2.135641098022461
Epoch 50 loss 2.1384146213531494
Epoch 51 loss 2.140078544616699
Epoch 52 loss 2.136495351791382
Epoch 53 loss 2.134531259536743
Epoch 54 loss 2.138030529022217
Epoch 55 loss 2.1403777599334717
Epoch 56 loss 2.144956111907959
Epoch 57 loss 2.139599323272705
Epoch 58 loss 2.1421637535095215
Epoch 59 loss 2.148650884628296
Epoch 60 loss 2.1389071941375732
Epoch 61 loss 2.143489122390747
Epoch 62 loss 2.145082712173462
Epoch 63 loss 2.141228675842285
Epoch 64 loss 2.1460843086242676
Epoch 65 loss 2.1439409255981445
Epoch 66 loss 2.147289276123047
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1333333333333333, 'Log Loss - std': 0.004099864496405715} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.229757785797119
Epoch 1 loss 2.2031352519989014
Epoch 2 loss 2.1899006366729736
Epoch 3 loss 2.184549331665039
Epoch 4 loss 2.1736066341400146
Epoch 5 loss 2.168558120727539
Epoch 6 loss 2.171264886856079
Epoch 7 loss 2.164569139480591
Epoch 8 loss 2.1575398445129395
Epoch 9 loss 2.1651611328125
Epoch 10 loss 2.1563549041748047
Epoch 11 loss 2.1547720432281494
Epoch 12 loss 2.1553096771240234
Epoch 13 loss 2.155364990234375
Epoch 14 loss 2.1491525173187256
Epoch 15 loss 2.1503260135650635
Epoch 16 loss 2.1503310203552246
Epoch 17 loss 2.1522703170776367
Epoch 18 loss 2.1500790119171143
Epoch 19 loss 2.150566577911377
Epoch 20 loss 2.1472344398498535
Epoch 21 loss 2.1504275798797607
Epoch 22 loss 2.147021770477295
Epoch 23 loss 2.1481709480285645
Epoch 24 loss 2.1473567485809326
Epoch 25 loss 2.143920421600342
Epoch 26 loss 2.1426758766174316
Epoch 27 loss 2.145463228225708
Epoch 28 loss 2.14438796043396
Epoch 29 loss 2.1469247341156006
Epoch 30 loss 2.142995834350586
Epoch 31 loss 2.1400184631347656
Epoch 32 loss 2.140155553817749
Epoch 33 loss 2.1426808834075928
Epoch 34 loss 2.142960786819458
Epoch 35 loss 2.141742706298828
Epoch 36 loss 2.1402623653411865
Epoch 37 loss 2.1400482654571533
Epoch 38 loss 2.1398348808288574
Epoch 39 loss 2.14216685295105
Epoch 40 loss 2.142491102218628
Epoch 41 loss 2.142599105834961
Epoch 42 loss 2.1401453018188477
Epoch 43 loss 2.1423301696777344
Epoch 44 loss 2.145707845687866
Epoch 45 loss 2.1424660682678223
Epoch 46 loss 2.1455628871917725
Epoch 47 loss 2.1407997608184814
Epoch 48 loss 2.1437315940856934
Epoch 49 loss 2.143613338470459
Epoch 50 loss 2.1417860984802246
Epoch 51 loss 2.146217107772827
Epoch 52 loss 2.143864631652832
Epoch 53 loss 2.145861864089966
Epoch 54 loss 2.148359775543213
Epoch 55 loss 2.1484830379486084
Epoch 56 loss 2.144954204559326
Epoch 57 loss 2.146663188934326
Epoch 58 loss 2.147865056991577
Epoch 59 loss 2.148027181625366
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1350249999999997, 'Log Loss - std': 0.004603463370115939} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.2452754974365234
Epoch 1 loss 2.2005865573883057
Epoch 2 loss 2.182511329650879
Epoch 3 loss 2.186727285385132
Epoch 4 loss 2.166710376739502
Epoch 5 loss 2.1612322330474854
Epoch 6 loss 2.1595234870910645
Epoch 7 loss 2.159390687942505
Epoch 8 loss 2.1622633934020996
Epoch 9 loss 2.1498360633850098
Epoch 10 loss 2.1447391510009766
Epoch 11 loss 2.148061752319336
Epoch 12 loss 2.1442275047302246
Epoch 13 loss 2.1425952911376953
Epoch 14 loss 2.144554853439331
Epoch 15 loss 2.145145893096924
Epoch 16 loss 2.14264178276062
Epoch 17 loss 2.1387646198272705
Epoch 18 loss 2.1368260383605957
Epoch 19 loss 2.139460563659668
Epoch 20 loss 2.1377696990966797
Epoch 21 loss 2.1343321800231934
Epoch 22 loss 2.1365158557891846
Epoch 23 loss 2.136650562286377
Epoch 24 loss 2.135032892227173
Epoch 25 loss 2.136488914489746
Epoch 26 loss 2.1335575580596924
Epoch 27 loss 2.1345858573913574
Epoch 28 loss 2.132017135620117
Epoch 29 loss 2.1340749263763428
Epoch 30 loss 2.1324782371520996
Epoch 31 loss 2.132676601409912
Epoch 32 loss 2.1304845809936523
Epoch 33 loss 2.12947416305542
Epoch 34 loss 2.130516529083252
Epoch 35 loss 2.1342713832855225
Epoch 36 loss 2.1292362213134766
Epoch 37 loss 2.1301486492156982
Epoch 38 loss 2.133495807647705
Epoch 39 loss 2.132847547531128
Epoch 40 loss 2.130025863647461
Epoch 41 loss 2.133678436279297
Epoch 42 loss 2.1305477619171143
Epoch 43 loss 2.1312813758850098
Epoch 44 loss 2.132906198501587
Epoch 45 loss 2.1302361488342285
Epoch 46 loss 2.1316118240356445
Epoch 47 loss 2.130573272705078
Epoch 48 loss 2.133873462677002
Epoch 49 loss 2.1350860595703125
Epoch 50 loss 2.132197618484497
Epoch 51 loss 2.1337404251098633
Epoch 52 loss 2.1319236755371094
Epoch 53 loss 2.135741949081421
Epoch 54 loss 2.131667137145996
Epoch 55 loss 2.1370911598205566
Epoch 56 loss 2.1345651149749756
Epoch 57 loss 2.1405129432678223
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1339799999999998, 'Log Loss - std': 0.004617531808228225} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 2.1339799999999998 and parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.8}. Best is trial 0 with value: 2.1400599999999996.
Best parameters After Trials: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Parameters saved to YAML file!!!
In get_device
Using dim 64 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133456, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133456, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]] 
 
 
Val : (133456, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.189704418182373
Epoch 1 loss 2.164027690887451
Epoch 2 loss 2.154841899871826
Epoch 3 loss 2.1511144638061523
Epoch 4 loss 2.1510744094848633
Epoch 5 loss 2.1486992835998535
Epoch 6 loss 2.1441547870635986
Epoch 7 loss 2.1470813751220703
Epoch 8 loss 2.1464693546295166
Epoch 9 loss 2.1433093547821045
Epoch 10 loss 2.143214225769043
Epoch 11 loss 2.1493136882781982
Epoch 12 loss 2.1532113552093506
Epoch 13 loss 2.1667420864105225
Epoch 14 loss 2.1716866493225098
Epoch 15 loss 2.191497325897217
Epoch 16 loss 2.20131516456604
Epoch 17 loss 2.2260959148406982
Epoch 18 loss 2.2559258937835693
Epoch 19 loss 2.3002007007598877
Epoch 20 loss 2.3160452842712402
Epoch 21 loss 2.3718130588531494
Epoch 22 loss 2.4256935119628906
Epoch 23 loss 2.4817709922790527
Epoch 24 loss 2.516047477722168
Epoch 25 loss 2.551640510559082
Epoch 26 loss 2.632974147796631
Epoch 27 loss 2.691396713256836
Epoch 28 loss 2.744434118270874
Epoch 29 loss 2.823390245437622
Epoch 30 loss 2.8383982181549072
Epoch 31 loss 2.942030429840088
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Black_Friday/logging/loss_0.txt
File name : output/SAINT/Black_Friday/logging/loss_0.txt . The file was saved
Log file exists at: output/SAINT/Black_Friday/logging/val_loss_0.txt
File name : output/SAINT/Black_Friday/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33365,)
Probabilities shape : (33365, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1437, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.181241273880005
Epoch 1 loss 2.164663314819336
Epoch 2 loss 2.147184371948242
Epoch 3 loss 2.1421988010406494
Epoch 4 loss 2.1393256187438965
Epoch 5 loss 2.1418659687042236
Epoch 6 loss 2.133594274520874
Epoch 7 loss 2.1375107765197754
Epoch 8 loss 2.1370859146118164
Epoch 9 loss 2.13499116897583
Epoch 10 loss 2.1362645626068115
Epoch 11 loss 2.1407244205474854
Epoch 12 loss 2.144981861114502
Epoch 13 loss 2.156172513961792
Epoch 14 loss 2.1659836769104004
Epoch 15 loss 2.1822216510772705
Epoch 16 loss 2.1974940299987793
Epoch 17 loss 2.224626302719116
Epoch 18 loss 2.256371021270752
Epoch 19 loss 2.2988028526306152
Epoch 20 loss 2.3273377418518066
Epoch 21 loss 2.362595558166504
Epoch 22 loss 2.423039436340332
Epoch 23 loss 2.4669618606567383
Epoch 24 loss 2.517571210861206
Epoch 25 loss 2.5628323554992676
Epoch 26 loss 2.6271679401397705
Epoch 27 loss 2.6737468242645264
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Black_Friday/logging/loss_1.txt
File name : output/SAINT/Black_Friday/logging/loss_1.txt . The file was saved
Log file exists at: output/SAINT/Black_Friday/logging/val_loss_1.txt
File name : output/SAINT/Black_Friday/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1388, 'Log Loss - std': 0.004899999999999904} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.2058186531066895
Epoch 1 loss 2.1607019901275635
Epoch 2 loss 2.1552419662475586
Epoch 3 loss 2.1532199382781982
Epoch 4 loss 2.1493031978607178
Epoch 5 loss 2.1446287631988525
Epoch 6 loss 2.1422293186187744
Epoch 7 loss 2.1429781913757324
Epoch 8 loss 2.142585277557373
Epoch 9 loss 2.143444299697876
Epoch 10 loss 2.1434593200683594
Epoch 11 loss 2.1470470428466797
Epoch 12 loss 2.1502039432525635
Epoch 13 loss 2.161022424697876
Epoch 14 loss 2.170288562774658
Epoch 15 loss 2.1849100589752197
Epoch 16 loss 2.2145824432373047
Epoch 17 loss 2.2311830520629883
Epoch 18 loss 2.261776924133301
Epoch 19 loss 2.3076846599578857
Epoch 20 loss 2.34218430519104
Epoch 21 loss 2.3805880546569824
Epoch 22 loss 2.440478563308716
Epoch 23 loss 2.489353656768799
Epoch 24 loss 2.534912109375
Epoch 25 loss 2.6151785850524902
Epoch 26 loss 2.6950275897979736
Epoch 27 loss 2.7202651500701904
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Black_Friday/logging/loss_2.txt
File name : output/SAINT/Black_Friday/logging/loss_2.txt . The file was saved
Log file exists at: output/SAINT/Black_Friday/logging/val_loss_2.txt
File name : output/SAINT/Black_Friday/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1401, 'Log Loss - std': 0.004403029260255497} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['36-45' 0.0 1.0 0.0 1.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  1.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.1917240619659424
Epoch 1 loss 2.177495241165161
Epoch 2 loss 2.159533977508545
Epoch 3 loss 2.1623594760894775
Epoch 4 loss 2.1544580459594727
Epoch 5 loss 2.1538567543029785
Epoch 6 loss 2.1529927253723145
Epoch 7 loss 2.1513681411743164
Epoch 8 loss 2.149595260620117
Epoch 9 loss 2.1498804092407227
Epoch 10 loss 2.150038957595825
Epoch 11 loss 2.1521124839782715
Epoch 12 loss 2.1640188694000244
Epoch 13 loss 2.178433895111084
Epoch 14 loss 2.185188055038452
Epoch 15 loss 2.1997711658477783
Epoch 16 loss 2.2187907695770264
Epoch 17 loss 2.2371976375579834
Epoch 18 loss 2.2703545093536377
Epoch 19 loss 2.3112902641296387
Epoch 20 loss 2.3529765605926514
Epoch 21 loss 2.386373996734619
Epoch 22 loss 2.4586565494537354
Epoch 23 loss 2.491042137145996
Epoch 24 loss 2.5473365783691406
Epoch 25 loss 2.611424207687378
Epoch 26 loss 2.666332721710205
Epoch 27 loss 2.746464490890503
Epoch 28 loss 2.790327787399292
Epoch 29 loss 2.8608789443969727
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Black_Friday/logging/loss_3.txt
File name : output/SAINT/Black_Friday/logging/loss_3.txt . The file was saved
Log file exists at: output/SAINT/Black_Friday/logging/val_loss_3.txt
File name : output/SAINT/Black_Friday/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.1426499999999997, 'Log Loss - std': 0.0058350235646482} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : [0, 2, 3, 4, 5, 6, 7, 8]
ordinal_idx : [1]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (133457, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : []
Cat Dims V1 : [8]
Cat Idx V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [['0-17' 1.0 0.0 0.0 0.0]
 ['46-50' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['51-55' 1.0 0.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['26-35' 0.0 1.0 0.0 0.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]
 ['36-45' 1.0 0.0 0.0 1.0]] 
 
 
Val : (133457, 75) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [] 


OHE Idx : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]


Ordinal Idx V2: [0]


Cat Dims V2 : [8]
Cat Idx V2 : [0] 
 

Train: [[1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [5.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 1.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [6.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0]
 [3.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0]
 [4.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0]] 
 
 
Val : (133457, 75) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 46
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,
       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,
       39., 40., 41., 42., 43., 44., 45.]), 46)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45], Length : 46
Number of Classes After Bin Verifier: 46
In get_device
Using dim 8 and batch size 64
{'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.1}
Epoch 0 loss 2.182749032974243
Epoch 1 loss 2.160186529159546
Epoch 2 loss 2.1545956134796143
Epoch 3 loss 2.1471753120422363
Epoch 4 loss 2.140105724334717
Epoch 5 loss 2.1457042694091797
Epoch 6 loss 2.142941951751709
Epoch 7 loss 2.1386971473693848
Epoch 8 loss 2.138768196105957
Epoch 9 loss 2.1372780799865723
Epoch 10 loss 2.142463445663452
Epoch 11 loss 2.1437275409698486
Epoch 12 loss 2.1455609798431396
Epoch 13 loss 2.1517183780670166
Epoch 14 loss 2.1648342609405518
Epoch 15 loss 2.1773486137390137
Epoch 16 loss 2.2034149169921875
Epoch 17 loss 2.2182328701019287
Epoch 18 loss 2.24918532371521
Epoch 19 loss 2.275399684906006
Epoch 20 loss 2.314016819000244
Epoch 21 loss 2.3535797595977783
Epoch 22 loss 2.402918815612793
Epoch 23 loss 2.448988199234009
Epoch 24 loss 2.4719526767730713
Epoch 25 loss 2.5521602630615234
Epoch 26 loss 2.6113033294677734
Epoch 27 loss 2.6884686946868896
Epoch 28 loss 2.7445147037506104
Epoch 29 loss 2.758847951889038
Epoch 30 loss 2.8335378170013428
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Black_Friday/logging/loss_4.txt
File name : output/SAINT/Black_Friday/logging/loss_4.txt . The file was saved
Log file exists at: output/SAINT/Black_Friday/logging/val_loss_4.txt
File name : output/SAINT/Black_Friday/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 46
Class label len :46
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 

Prediction shape : (33364,)
Probabilities shape : (33364, 46) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 2.14168, 'Log Loss - std': 0.005567908045217704} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 2.14168, 'Log Loss - std': 0.005567908045217704}
Train time: 10686.488403788604
Inference time: 5.7235478146001695
Finished cross validation
Loss path :output/SAINT/Black_Friday/logging/
Plots saved successfully!
