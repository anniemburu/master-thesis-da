

----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/sat11.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/sat11.yml', data_parallel=False, dataset='SAT11', direction='maximize', dropna_idx=[116], early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=[115], num_bins=10, num_classes=1, num_features=117, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='bimodial')
Start hyperparameter optimization
Loading dataset SAT11...
Dataset loaded! 

(1725, 116)
A new study created in RDB with name: SAINT_SAT11
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [1.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 ...
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}
Epoch 0 loss 0.7688256502151489
Epoch 1 loss 0.6243898272514343
Epoch 2 loss 0.535976231098175
Epoch 3 loss 0.5126067399978638
Epoch 4 loss 0.5076308250427246
Epoch 5 loss 0.4919451177120209
Epoch 6 loss 0.5067131519317627
Epoch 7 loss 0.48130425810813904
Epoch 8 loss 0.4712566137313843
Epoch 9 loss 0.4755583703517914
Epoch 10 loss 0.46700519323349
Epoch 11 loss 0.47482961416244507
Epoch 12 loss 0.48022592067718506
Epoch 13 loss 0.4571930170059204
Epoch 14 loss 0.4680784344673157
Epoch 15 loss 0.46454358100891113
Epoch 16 loss 0.4738837480545044
Epoch 17 loss 0.4380234181880951
Epoch 18 loss 0.4485921263694763
Epoch 19 loss 0.42914843559265137
Epoch 20 loss 0.4429149031639099
Epoch 21 loss 0.42139309644699097
Epoch 22 loss 0.39959537982940674
Epoch 23 loss 0.3980677127838135
Epoch 24 loss 0.4255611300468445
Epoch 25 loss 0.38339972496032715
Epoch 26 loss 0.40795859694480896
Epoch 27 loss 0.3648490309715271
Epoch 28 loss 0.382294237613678
Epoch 29 loss 0.33185726404190063
Epoch 30 loss 0.36509841680526733
Epoch 31 loss 0.3614949584007263
Epoch 32 loss 0.3674444556236267
Epoch 33 loss 0.34927332401275635
Epoch 34 loss 0.3388281762599945
Epoch 35 loss 0.33709728717803955
Epoch 36 loss 0.36653774976730347
Epoch 37 loss 0.35261261463165283
Epoch 38 loss 0.332790732383728
Epoch 39 loss 0.30636611580848694
Epoch 40 loss 0.34996840357780457
Epoch 41 loss 0.3204331398010254
Epoch 42 loss 0.3489590883255005
Epoch 43 loss 0.32471972703933716
Epoch 44 loss 0.3319418430328369
Epoch 45 loss 0.3520589768886566
Epoch 46 loss 0.385424941778183
Epoch 47 loss 0.31567761301994324
Epoch 48 loss 0.36419469118118286
Epoch 49 loss 0.3626405596733093
Epoch 50 loss 0.3381229341030121
Epoch 51 loss 0.32401323318481445
Epoch 52 loss 0.3484798073768616
Epoch 53 loss 0.3545108437538147
Epoch 54 loss 0.3476029634475708
Epoch 55 loss 0.3396899700164795
Epoch 56 loss 0.37322038412094116
Epoch 57 loss 0.32642075419425964
Epoch 58 loss 0.39187952876091003
Epoch 59 loss 0.38069948554039
Epoch 60 loss 0.3886476457118988
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.315, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 ...
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}
Epoch 0 loss 0.8490402102470398
Epoch 1 loss 0.7742366194725037
Epoch 2 loss 0.6280490159988403
Epoch 3 loss 0.6158749461174011
Epoch 4 loss 0.5854966640472412
Epoch 5 loss 0.5988704562187195
Epoch 6 loss 0.5961448550224304
Epoch 7 loss 0.6117358803749084
Epoch 8 loss 0.5757063627243042
Epoch 9 loss 0.558927059173584
Epoch 10 loss 0.5631706714630127
Epoch 11 loss 0.5675692558288574
Epoch 12 loss 0.5564653873443604
Epoch 13 loss 0.5538400411605835
Epoch 14 loss 0.5526317358016968
Epoch 15 loss 0.5672470331192017
Epoch 16 loss 0.5522772073745728
Epoch 17 loss 0.5451908111572266
Epoch 18 loss 0.5681247115135193
Epoch 19 loss 0.5389745235443115
Epoch 20 loss 0.5183172225952148
Epoch 21 loss 0.556565523147583
Epoch 22 loss 0.54329913854599
Epoch 23 loss 0.5112554430961609
Epoch 24 loss 0.5207127928733826
Epoch 25 loss 0.4764974117279053
Epoch 26 loss 0.4828578233718872
Epoch 27 loss 0.49297699332237244
Epoch 28 loss 0.4865458011627197
Epoch 29 loss 0.5109743475914001
Epoch 30 loss 0.43791183829307556
Epoch 31 loss 0.43727123737335205
Epoch 32 loss 0.4567670226097107
Epoch 33 loss 0.45591291785240173
Epoch 34 loss 0.4627940356731415
Epoch 35 loss 0.5385247468948364
Epoch 36 loss 0.555306077003479
Epoch 37 loss 0.45635005831718445
Epoch 38 loss 0.4433410167694092
Epoch 39 loss 0.4528213441371918
Epoch 40 loss 0.4797569513320923
Epoch 41 loss 0.4645361602306366
Epoch 42 loss 0.5143770575523376
Epoch 43 loss 0.4674389958381653
Epoch 44 loss 0.48886868357658386
Epoch 45 loss 0.4539961814880371
Epoch 46 loss 0.6647285223007202
Epoch 47 loss 0.5089923143386841
Epoch 48 loss 0.4776964783668518
Epoch 49 loss 0.49361881613731384
Epoch 50 loss 0.5098799467086792
Epoch 51 loss 0.595404863357544
Epoch 52 loss 0.5284780859947205
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3695, 'Log Loss - std': 0.05449999999999999} 
 

Fold 3
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 ...
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}
Epoch 0 loss 0.6774826049804688
Epoch 1 loss 0.5638100504875183
Epoch 2 loss 0.5409495830535889
Epoch 3 loss 0.5219313502311707
Epoch 4 loss 0.5041897892951965
Epoch 5 loss 0.4991299510002136
Epoch 6 loss 0.5079910159111023
Epoch 7 loss 0.47017011046409607
Epoch 8 loss 0.534583330154419
Epoch 9 loss 0.46766623854637146
Epoch 10 loss 0.47485050559043884
Epoch 11 loss 0.4437728822231293
Epoch 12 loss 0.461023211479187
Epoch 13 loss 0.4442863464355469
Epoch 14 loss 0.4438265264034271
Epoch 15 loss 0.45444726943969727
Epoch 16 loss 0.4754350781440735
Epoch 17 loss 0.42866915464401245
Epoch 18 loss 0.4375929832458496
Epoch 19 loss 0.4647258520126343
Epoch 20 loss 0.41322728991508484
Epoch 21 loss 0.41555628180503845
Epoch 22 loss 0.42122209072113037
Epoch 23 loss 0.4492794871330261
Epoch 24 loss 0.43581530451774597
Epoch 25 loss 0.403652548789978
Epoch 26 loss 0.39228570461273193
Epoch 27 loss 0.38968586921691895
Epoch 28 loss 0.3670145869255066
Epoch 29 loss 0.38537949323654175
Epoch 30 loss 0.39662274718284607
Epoch 31 loss 0.34308284521102905
Epoch 32 loss 0.3366940915584564
Epoch 33 loss 0.35399001836776733
Epoch 34 loss 0.31514638662338257
Epoch 35 loss 0.3485066592693329
Epoch 36 loss 0.30620694160461426
Epoch 37 loss 0.3219858705997467
Epoch 38 loss 0.3310362696647644
Epoch 39 loss 0.33722400665283203
Epoch 40 loss 0.35860246419906616
Epoch 41 loss 0.30037182569503784
Epoch 42 loss 0.31425559520721436
Epoch 43 loss 0.3117532730102539
Epoch 44 loss 0.30756065249443054
Epoch 45 loss 0.3236686587333679
Epoch 46 loss 0.30571720004081726
Epoch 47 loss 0.30066031217575073
Epoch 48 loss 0.3091725707054138
Epoch 49 loss 0.31961262226104736
Epoch 50 loss 0.33553194999694824
Epoch 51 loss 0.29766446352005005
Epoch 52 loss 0.35624533891677856
Epoch 53 loss 0.3173413872718811
Epoch 54 loss 0.32893702387809753
Epoch 55 loss 0.31650662422180176
Epoch 56 loss 0.30447137355804443
Epoch 57 loss 0.2968766391277313
Epoch 58 loss 0.32940158247947693
Epoch 59 loss 0.33000338077545166
Epoch 60 loss 0.36702340841293335
Epoch 61 loss 0.33818361163139343
Epoch 62 loss 0.3541705310344696
Epoch 63 loss 0.3398563861846924
Epoch 64 loss 0.3654717803001404
Epoch 65 loss 0.3341911733150482
Epoch 66 loss 0.3453516364097595
Epoch 67 loss 0.3566027581691742
Epoch 68 loss 0.3351430892944336
Epoch 69 loss 0.3481380343437195
Epoch 70 loss 0.37310880422592163
Epoch 71 loss 0.3610045611858368
Epoch 72 loss 0.3900320529937744
Epoch 73 loss 0.4057328402996063
Epoch 74 loss 0.40185174345970154
Epoch 75 loss 0.3887622356414795
Epoch 76 loss 0.3516073226928711
Epoch 77 loss 0.35227128863334656
Epoch 78 loss 0.38139960169792175
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3488, 'Log Loss - std': 0.05326487272740512} 
 

Fold 4
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 ...
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}
Epoch 0 loss 0.7550705671310425
Epoch 1 loss 0.6621066331863403
Epoch 2 loss 0.6501786112785339
Epoch 3 loss 0.5426708459854126
Epoch 4 loss 0.550826907157898
Epoch 5 loss 0.508208692073822
Epoch 6 loss 0.533078670501709
Epoch 7 loss 0.494312047958374
Epoch 8 loss 0.5217987895011902
Epoch 9 loss 0.5188714861869812
Epoch 10 loss 0.551677405834198
Epoch 11 loss 0.502465546131134
Epoch 12 loss 0.48428553342819214
Epoch 13 loss 0.5756509304046631
Epoch 14 loss 0.49242478609085083
Epoch 15 loss 0.5381146669387817
Epoch 16 loss 0.5232288837432861
Epoch 17 loss 0.47876009345054626
Epoch 18 loss 0.5200369954109192
Epoch 19 loss 0.5063568949699402
Epoch 20 loss 0.5007534623146057
Epoch 21 loss 0.496885746717453
Epoch 22 loss 0.483222097158432
Epoch 23 loss 0.4808046221733093
Epoch 24 loss 0.5178642272949219
Epoch 25 loss 0.4717923104763031
Epoch 26 loss 0.48614010214805603
Epoch 27 loss 0.44531044363975525
Epoch 28 loss 0.45829662680625916
Epoch 29 loss 0.45264238119125366
Epoch 30 loss 0.42729660868644714
Epoch 31 loss 0.4664899706840515
Epoch 32 loss 0.421627938747406
Epoch 33 loss 0.436704158782959
Epoch 34 loss 0.41034647822380066
Epoch 35 loss 0.4036939740180969
Epoch 36 loss 0.3925672769546509
Epoch 37 loss 0.3957490622997284
Epoch 38 loss 0.49813467264175415
Epoch 39 loss 0.4044008255004883
Epoch 40 loss 0.4431416690349579
Epoch 41 loss 0.45884329080581665
Epoch 42 loss 0.40623340010643005
Epoch 43 loss 0.49683675169944763
Epoch 44 loss 0.46338915824890137
Epoch 45 loss 0.38720381259918213
Epoch 46 loss 0.4403414726257324
Epoch 47 loss 0.46413499116897583
Epoch 48 loss 0.42351531982421875
Epoch 49 loss 0.45952877402305603
Epoch 50 loss 0.46552419662475586
Epoch 51 loss 0.437843918800354
Epoch 52 loss 0.4857991635799408
Epoch 53 loss 0.43917036056518555
Epoch 54 loss 0.4777142405509949
Epoch 55 loss 0.48527616262435913
Epoch 56 loss 0.4854108691215515
Epoch 57 loss 0.5035158395767212
Epoch 58 loss 0.47081851959228516
Epoch 59 loss 0.5887000560760498
Epoch 60 loss 0.562358558177948
Epoch 61 loss 0.6017922163009644
Epoch 62 loss 0.5378285646438599
Epoch 63 loss 0.5638124346733093
Epoch 64 loss 0.5445549488067627
Epoch 65 loss 0.6053481698036194
Epoch 66 loss 0.5891371965408325
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.362875, 'Log Loss - std': 0.05217448490402181} 
 

Fold 5
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [1.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 1.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 ...
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}
Epoch 0 loss 0.7062587141990662
Epoch 1 loss 0.6299823522567749
Epoch 2 loss 0.506070077419281
Epoch 3 loss 0.46834540367126465
Epoch 4 loss 0.47782742977142334
Epoch 5 loss 0.4277185797691345
Epoch 6 loss 0.441447913646698
Epoch 7 loss 0.410093754529953
Epoch 8 loss 0.420784056186676
Epoch 9 loss 0.4061434268951416
Epoch 10 loss 0.39107590913772583
Epoch 11 loss 0.4039561152458191
Epoch 12 loss 0.4134882390499115
Epoch 13 loss 0.41210174560546875
Epoch 14 loss 0.38294416666030884
Epoch 15 loss 0.3761170506477356
Epoch 16 loss 0.4851529002189636
Epoch 17 loss 0.37432777881622314
Epoch 18 loss 0.3644527196884155
Epoch 19 loss 0.3846956193447113
Epoch 20 loss 0.3428581953048706
Epoch 21 loss 0.34949278831481934
Epoch 22 loss 0.33630675077438354
Epoch 23 loss 0.33314043283462524
Epoch 24 loss 0.28516384959220886
Epoch 25 loss 0.3373013436794281
Epoch 26 loss 0.30564647912979126
Epoch 27 loss 0.3015255928039551
Epoch 28 loss 0.2732347846031189
Epoch 29 loss 0.2522609233856201
Epoch 30 loss 0.27382662892341614
Epoch 31 loss 0.28099367022514343
Epoch 32 loss 0.27842482924461365
Epoch 33 loss 0.23608122766017914
Epoch 34 loss 0.2788267135620117
Epoch 35 loss 0.22836801409721375
Epoch 36 loss 0.2730489671230316
Epoch 37 loss 0.24230211973190308
Epoch 38 loss 0.24270270764827728
Epoch 39 loss 0.2478996366262436
Epoch 40 loss 0.2755817174911499
Epoch 41 loss 0.2399175465106964
Epoch 42 loss 0.2235998809337616
Epoch 43 loss 0.23057475686073303
Epoch 44 loss 0.2620030641555786
Epoch 45 loss 0.26181334257125854
Epoch 46 loss 0.24256114661693573
Epoch 47 loss 0.23492197692394257
Epoch 48 loss 0.23693454265594482
Epoch 49 loss 0.23423020541667938
Epoch 50 loss 0.21580784022808075
Epoch 51 loss 0.2368730753660202
Epoch 52 loss 0.25670358538627625
Epoch 53 loss 0.22970670461654663
Epoch 54 loss 0.2599259316921234
Epoch 55 loss 0.23498663306236267
Epoch 56 loss 0.2631608843803406
Epoch 57 loss 0.24932247400283813
Epoch 58 loss 0.2713008522987366
Epoch 59 loss 0.2585863769054413
Epoch 60 loss 0.2680387794971466
Epoch 61 loss 0.27781176567077637
Epoch 62 loss 0.24383342266082764
Epoch 63 loss 0.25183236598968506
Epoch 64 loss 0.3182043135166168
Epoch 65 loss 0.31918400526046753
Epoch 66 loss 0.28050723671913147
Epoch 67 loss 0.2691532373428345
Epoch 68 loss 0.27015259861946106
Epoch 69 loss 0.2867733836174011
Epoch 70 loss 0.3366202712059021
Epoch 71 loss 0.3386996388435364
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3335, 'Log Loss - std': 0.07502868784671633} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 0.3335 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'dropout': 0.4}. Best is trial 0 with value: 0.3335.
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [1.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 ...
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7236733436584473
Epoch 1 loss 0.5780894160270691
Epoch 2 loss 0.5234076380729675
Epoch 3 loss 0.5167466402053833
Epoch 4 loss 0.49395066499710083
Epoch 5 loss 0.5036638975143433
Epoch 6 loss 0.5040179491043091
Epoch 7 loss 0.4963037371635437
Epoch 8 loss 0.4796864986419678
Epoch 9 loss 0.4790928065776825
Epoch 10 loss 0.4659312963485718
Epoch 11 loss 0.46085989475250244
Epoch 12 loss 0.48367685079574585
Epoch 13 loss 0.48611778020858765
Epoch 14 loss 0.501613974571228
Epoch 15 loss 0.4938780665397644
Epoch 16 loss 0.4806424081325531
Epoch 17 loss 0.47386687994003296
Epoch 18 loss 0.46200546622276306
Epoch 19 loss 0.4890611171722412
Epoch 20 loss 0.4526861608028412
Epoch 21 loss 0.47469982504844666
Epoch 22 loss 0.4552837610244751
Epoch 23 loss 0.4657655954360962
Epoch 24 loss 0.5363259315490723
Epoch 25 loss 0.4634760320186615
Epoch 26 loss 0.45128506422042847
Epoch 27 loss 0.4421203136444092
Epoch 28 loss 0.4402303695678711
Epoch 29 loss 0.4500017762184143
Epoch 30 loss 0.4488410949707031
Epoch 31 loss 0.424007773399353
Epoch 32 loss 0.4219488799571991
Epoch 33 loss 0.4137372374534607
Epoch 34 loss 0.3999747633934021
Epoch 35 loss 0.4215075671672821
Epoch 36 loss 0.43251657485961914
Epoch 37 loss 0.40048083662986755
Epoch 38 loss 0.400789737701416
Epoch 39 loss 0.3779899477958679
Epoch 40 loss 0.3668353259563446
Epoch 41 loss 0.4133242070674896
Epoch 42 loss 0.4293222427368164
Epoch 43 loss 0.3626604676246643
Epoch 44 loss 0.3746163249015808
Epoch 45 loss 0.35351940989494324
Epoch 46 loss 0.37071847915649414
Epoch 47 loss 0.38115832209587097
Epoch 48 loss 0.38902008533477783
Epoch 49 loss 0.3554336428642273
Epoch 50 loss 0.35484203696250916
Epoch 51 loss 0.35246965289115906
Epoch 52 loss 0.35808882117271423
Epoch 53 loss 0.3407914638519287
Epoch 54 loss 0.3438040018081665
Epoch 55 loss 0.3531051576137543
Epoch 56 loss 0.3888937830924988
Epoch 57 loss 0.3532654643058777
Epoch 58 loss 0.3484615087509155
Epoch 59 loss 0.3454734981060028
Epoch 60 loss 0.35393819212913513
Epoch 61 loss 0.34002166986465454
Epoch 62 loss 0.34512418508529663
Epoch 63 loss 0.36694639921188354
Epoch 64 loss 0.3526228070259094
Epoch 65 loss 0.348399817943573
Epoch 66 loss 0.36177951097488403
Epoch 67 loss 0.33544355630874634
Epoch 68 loss 0.37775230407714844
Epoch 69 loss 0.3333173394203186
Epoch 70 loss 0.3532618284225464
Epoch 71 loss 0.36170753836631775
Epoch 72 loss 0.36209604144096375
Epoch 73 loss 0.37494349479675293
Epoch 74 loss 0.3555334806442261
Epoch 75 loss 0.349001944065094
Epoch 76 loss 0.3515101671218872
Epoch 77 loss 0.3846322298049927
Epoch 78 loss 0.37313616275787354
Epoch 79 loss 0.38167113065719604
Epoch 80 loss 0.41181421279907227
Epoch 81 loss 0.354567289352417
Epoch 82 loss 0.3814466893672943
Epoch 83 loss 0.37680530548095703
Epoch 84 loss 0.3486332893371582
Epoch 85 loss 0.37331122159957886
Epoch 86 loss 0.3515143394470215
Epoch 87 loss 0.3774900436401367
Epoch 88 loss 0.4002797603607178
Epoch 89 loss 0.3948414921760559
Epoch 90 loss 0.4310459494590759
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3303, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 ...
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7747477293014526
Epoch 1 loss 0.7518097162246704
Epoch 2 loss 0.6460651159286499
Epoch 3 loss 0.61112380027771
Epoch 4 loss 0.6238337159156799
Epoch 5 loss 0.5957911610603333
Epoch 6 loss 0.617090106010437
Epoch 7 loss 0.5644971132278442
Epoch 8 loss 0.5887916684150696
Epoch 9 loss 0.5882242918014526
Epoch 10 loss 0.6042754650115967
Epoch 11 loss 0.576654314994812
Epoch 12 loss 0.6086554527282715
Epoch 13 loss 0.5894874334335327
Epoch 14 loss 0.581200361251831
Epoch 15 loss 0.5880775451660156
Epoch 16 loss 0.5900799632072449
Epoch 17 loss 0.5702874660491943
Epoch 18 loss 0.5624019503593445
Epoch 19 loss 0.5831496119499207
Epoch 20 loss 0.5728445649147034
Epoch 21 loss 0.5829522609710693
Epoch 22 loss 0.5754444599151611
Epoch 23 loss 0.5664666295051575
Epoch 24 loss 0.592240571975708
Epoch 25 loss 0.5808988809585571
Epoch 26 loss 0.582901656627655
Epoch 27 loss 0.5945836901664734
Epoch 28 loss 0.6058920621871948
Epoch 29 loss 0.5537769198417664
Epoch 30 loss 0.5572904348373413
Epoch 31 loss 0.5723880529403687
Epoch 32 loss 0.5708363652229309
Epoch 33 loss 0.5810614824295044
Epoch 34 loss 0.584479570388794
Epoch 35 loss 0.5496320128440857
Epoch 36 loss 0.5625947713851929
Epoch 37 loss 0.6094615459442139
Epoch 38 loss 0.5334987044334412
Epoch 39 loss 0.5420792102813721
Epoch 40 loss 0.5334267020225525
Epoch 41 loss 0.527364194393158
Epoch 42 loss 0.5460649728775024
Epoch 43 loss 0.5238887071609497
Epoch 44 loss 0.5391400456428528
Epoch 45 loss 0.518500566482544
Epoch 46 loss 0.5102869868278503
Epoch 47 loss 0.4934850335121155
Epoch 48 loss 0.480823278427124
Epoch 49 loss 0.4998038411140442
Epoch 50 loss 0.5016783475875854
Epoch 51 loss 0.505969762802124
Epoch 52 loss 0.49854326248168945
Epoch 53 loss 0.500712513923645
Epoch 54 loss 0.5565274953842163
Epoch 55 loss 0.508833110332489
Epoch 56 loss 0.46550798416137695
Epoch 57 loss 0.46392568945884705
Epoch 58 loss 0.5050052404403687
Epoch 59 loss 0.5040088891983032
Epoch 60 loss 0.5601441264152527
Epoch 61 loss 0.4584468603134155
Epoch 62 loss 0.46958690881729126
Epoch 63 loss 0.5219472646713257
Epoch 64 loss 0.4649295210838318
Epoch 65 loss 0.4974777102470398
Epoch 66 loss 0.5093385577201843
Epoch 67 loss 0.4796554446220398
Epoch 68 loss 0.5099160671234131
Epoch 69 loss 0.4869573712348938
Epoch 70 loss 0.5513705015182495
Epoch 71 loss 0.5166049003601074
Epoch 72 loss 0.5041617155075073
Epoch 73 loss 0.5214037895202637
Epoch 74 loss 0.5475172996520996
Epoch 75 loss 0.5239701271057129
Epoch 76 loss 0.5085340738296509
Epoch 77 loss 0.5312657356262207
Epoch 78 loss 0.5886150002479553
Epoch 79 loss 0.5264080166816711
Epoch 80 loss 0.5318629145622253
Epoch 81 loss 0.5327668786048889
Epoch 82 loss 0.5558899641036987
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.40785, 'Log Loss - std': 0.07755000000000001} 
 

Fold 3
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 ...
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7853209972381592
Epoch 1 loss 0.6660830974578857
Epoch 2 loss 0.5996851325035095
Epoch 3 loss 0.5585966110229492
Epoch 4 loss 0.5326899290084839
Epoch 5 loss 0.5102252960205078
Epoch 6 loss 0.4982028603553772
Epoch 7 loss 0.501844584941864
Epoch 8 loss 0.5200706720352173
Epoch 9 loss 0.49157947301864624
Epoch 10 loss 0.48655399680137634
Epoch 11 loss 0.45880040526390076
Epoch 12 loss 0.4691579341888428
Epoch 13 loss 0.47745174169540405
Epoch 14 loss 0.48842787742614746
Epoch 15 loss 0.4716378152370453
Epoch 16 loss 0.44527238607406616
Epoch 17 loss 0.4597123861312866
Epoch 18 loss 0.4578140377998352
Epoch 19 loss 0.45429691672325134
Epoch 20 loss 0.45594680309295654
Epoch 21 loss 0.45175206661224365
Epoch 22 loss 0.43178123235702515
Epoch 23 loss 0.45964106917381287
Epoch 24 loss 0.439050555229187
Epoch 25 loss 0.4691029191017151
Epoch 26 loss 0.4337129294872284
Epoch 27 loss 0.44460225105285645
Epoch 28 loss 0.4284457564353943
Epoch 29 loss 0.45268183946609497
Epoch 30 loss 0.4162113666534424
Epoch 31 loss 0.4121183753013611
Epoch 32 loss 0.4037492871284485
Epoch 33 loss 0.3954014480113983
Epoch 34 loss 0.38582414388656616
Epoch 35 loss 0.38234269618988037
Epoch 36 loss 0.39619168639183044
Epoch 37 loss 0.36990565061569214
Epoch 38 loss 0.37260493636131287
Epoch 39 loss 0.338839054107666
Epoch 40 loss 0.34219714999198914
Epoch 41 loss 0.3452078700065613
Epoch 42 loss 0.3403392732143402
Epoch 43 loss 0.36303529143333435
Epoch 44 loss 0.31874924898147583
Epoch 45 loss 0.39497822523117065
Epoch 46 loss 0.3966773450374603
Epoch 47 loss 0.4113874137401581
Epoch 48 loss 0.3314785361289978
Epoch 49 loss 0.37927550077438354
Epoch 50 loss 0.35499870777130127
Epoch 51 loss 0.32405880093574524
Epoch 52 loss 0.33466464281082153
Epoch 53 loss 0.31249698996543884
Epoch 54 loss 0.3628685176372528
Epoch 55 loss 0.35026511549949646
Epoch 56 loss 0.30530887842178345
Epoch 57 loss 0.34848082065582275
Epoch 58 loss 0.3306436538696289
Epoch 59 loss 0.3095707893371582
Epoch 60 loss 0.31705009937286377
Epoch 61 loss 0.3215961754322052
Epoch 62 loss 0.30953675508499146
Epoch 63 loss 0.29318752884864807
Epoch 64 loss 0.3519246578216553
Epoch 65 loss 0.32750558853149414
Epoch 66 loss 0.39503535628318787
Epoch 67 loss 0.3327885866165161
Epoch 68 loss 0.3919224441051483
Epoch 69 loss 0.3843058943748474
Epoch 70 loss 0.3194800019264221
Epoch 71 loss 0.36635297536849976
Epoch 72 loss 0.31656721234321594
Epoch 73 loss 0.2806215286254883
Epoch 74 loss 0.29911524057388306
Epoch 75 loss 0.3216927647590637
Epoch 76 loss 0.35647866129875183
Epoch 77 loss 0.31723231077194214
Epoch 78 loss 0.35735392570495605
Epoch 79 loss 0.3154199719429016
Epoch 80 loss 0.30703413486480713
Epoch 81 loss 0.35544317960739136
Epoch 82 loss 0.33178040385246277
Epoch 83 loss 0.4305533766746521
Epoch 84 loss 0.3398938775062561
Epoch 85 loss 0.3261328637599945
Epoch 86 loss 0.35241997241973877
Epoch 87 loss 0.3652791976928711
Epoch 88 loss 0.3503984808921814
Epoch 89 loss 0.35627663135528564
Epoch 90 loss 0.3722185492515564
Epoch 91 loss 0.36318469047546387
Epoch 92 loss 0.36290162801742554
Epoch 93 loss 0.3570488393306732
Epoch 94 loss 0.43768832087516785
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3806333333333333, 'Log Loss - std': 0.074100127455281} 
 

Fold 4
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 ...
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7530537843704224
Epoch 1 loss 0.6586058139801025
Epoch 2 loss 0.6174594759941101
Epoch 3 loss 0.5679482221603394
Epoch 4 loss 0.5500954985618591
Epoch 5 loss 0.5511825084686279
Epoch 6 loss 0.5169269442558289
Epoch 7 loss 0.5384572744369507
Epoch 8 loss 0.5439307689666748
Epoch 9 loss 0.5211015939712524
Epoch 10 loss 0.5533521175384521
Epoch 11 loss 0.5358320474624634
Epoch 12 loss 0.5307702422142029
Epoch 13 loss 0.5141761302947998
Epoch 14 loss 0.5052971839904785
Epoch 15 loss 0.5072801113128662
Epoch 16 loss 0.5017175674438477
Epoch 17 loss 0.5160086750984192
Epoch 18 loss 0.520736575126648
Epoch 19 loss 0.5056244134902954
Epoch 20 loss 0.5018552541732788
Epoch 21 loss 0.491912841796875
Epoch 22 loss 0.4941825270652771
Epoch 23 loss 0.4787719249725342
Epoch 24 loss 0.5056310892105103
Epoch 25 loss 0.49147844314575195
Epoch 26 loss 0.4743530750274658
Epoch 27 loss 0.46920716762542725
Epoch 28 loss 0.47804200649261475
Epoch 29 loss 0.4587791860103607
Epoch 30 loss 0.49664807319641113
Epoch 31 loss 0.4588542878627777
Epoch 32 loss 0.46246129274368286
Epoch 33 loss 0.5144966840744019
Epoch 34 loss 0.4500541687011719
Epoch 35 loss 0.463855504989624
Epoch 36 loss 0.4202496409416199
Epoch 37 loss 0.4749854505062103
Epoch 38 loss 0.43774378299713135
Epoch 39 loss 0.48450741171836853
Epoch 40 loss 0.45650142431259155
Epoch 41 loss 0.4134219288825989
Epoch 42 loss 0.4328920245170593
Epoch 43 loss 0.39993032813072205
Epoch 44 loss 0.416562020778656
Epoch 45 loss 0.4135972857475281
Epoch 46 loss 0.4259220063686371
Epoch 47 loss 0.40646791458129883
Epoch 48 loss 0.42081114649772644
Epoch 49 loss 0.41497087478637695
Epoch 50 loss 0.448442667722702
Epoch 51 loss 0.3885898292064667
Epoch 52 loss 0.4242311716079712
Epoch 53 loss 0.39425283670425415
Epoch 54 loss 0.3764454126358032
Epoch 55 loss 0.41409263014793396
Epoch 56 loss 0.4307003915309906
Epoch 57 loss 0.41922950744628906
Epoch 58 loss 0.38919270038604736
Epoch 59 loss 0.4356645941734314
Epoch 60 loss 0.4490134119987488
Epoch 61 loss 0.3898977041244507
Epoch 62 loss 0.39594408869743347
Epoch 63 loss 0.4636056423187256
Epoch 64 loss 0.4081181287765503
Epoch 65 loss 0.3849111497402191
Epoch 66 loss 0.4819011688232422
Epoch 67 loss 0.4146415591239929
Epoch 68 loss 0.39903414249420166
Epoch 69 loss 0.4533337950706482
Epoch 70 loss 0.4303908348083496
Epoch 71 loss 0.5025845766067505
Epoch 72 loss 0.4247530698776245
Epoch 73 loss 0.4285268783569336
Epoch 74 loss 0.4444901645183563
Epoch 75 loss 0.4274193048477173
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3867, 'Log Loss - std': 0.0650271866222121} 
 

Fold 5
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [1.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 1.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 ...
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7075837850570679
Epoch 1 loss 0.6145836710929871
Epoch 2 loss 0.520771861076355
Epoch 3 loss 0.49967700242996216
Epoch 4 loss 0.45987066626548767
Epoch 5 loss 0.45445966720581055
Epoch 6 loss 0.45187899470329285
Epoch 7 loss 0.4413295388221741
Epoch 8 loss 0.4225383698940277
Epoch 9 loss 0.41463780403137207
Epoch 10 loss 0.4159265458583832
Epoch 11 loss 0.4116126298904419
Epoch 12 loss 0.4154431223869324
Epoch 13 loss 0.41734597086906433
Epoch 14 loss 0.422987699508667
Epoch 15 loss 0.423434853553772
Epoch 16 loss 0.4249441623687744
Epoch 17 loss 0.3972315490245819
Epoch 18 loss 0.4162842929363251
Epoch 19 loss 0.4058135747909546
Epoch 20 loss 0.4067150354385376
Epoch 21 loss 0.4044818580150604
Epoch 22 loss 0.4352589547634125
Epoch 23 loss 0.3823949694633484
Epoch 24 loss 0.38979053497314453
Epoch 25 loss 0.372750461101532
Epoch 26 loss 0.39265620708465576
Epoch 27 loss 0.3642429709434509
Epoch 28 loss 0.36803680658340454
Epoch 29 loss 0.3693830966949463
Epoch 30 loss 0.35136157274246216
Epoch 31 loss 0.3524145483970642
Epoch 32 loss 0.3482522666454315
Epoch 33 loss 0.33834129571914673
Epoch 34 loss 0.3499234616756439
Epoch 35 loss 0.33320051431655884
Epoch 36 loss 0.3468054234981537
Epoch 37 loss 0.31564122438430786
Epoch 38 loss 0.30938920378685
Epoch 39 loss 0.28014522790908813
Epoch 40 loss 0.35388824343681335
Epoch 41 loss 0.2954566478729248
Epoch 42 loss 0.2749421000480652
Epoch 43 loss 0.30072829127311707
Epoch 44 loss 0.275312602519989
Epoch 45 loss 0.2868000268936157
Epoch 46 loss 0.2680361270904541
Epoch 47 loss 0.26679128408432007
Epoch 48 loss 0.28901407122612
Epoch 49 loss 0.2444310486316681
Epoch 50 loss 0.24992159008979797
Epoch 51 loss 0.24839642643928528
Epoch 52 loss 0.24170666933059692
Epoch 53 loss 0.2522716224193573
Epoch 54 loss 0.26402515172958374
Epoch 55 loss 0.2525004744529724
Epoch 56 loss 0.2724657654762268
Epoch 57 loss 0.26410970091819763
Epoch 58 loss 0.23757529258728027
Epoch 59 loss 0.2552110552787781
Epoch 60 loss 0.25682806968688965
Epoch 61 loss 0.23093760013580322
Epoch 62 loss 0.2598147392272949
Epoch 63 loss 0.22404739260673523
Epoch 64 loss 0.23888061940670013
Epoch 65 loss 0.23535004258155823
Epoch 66 loss 0.2454650104045868
Epoch 67 loss 0.2578273415565491
Epoch 68 loss 0.2686084508895874
Epoch 69 loss 0.23829802870750427
Epoch 70 loss 0.24966375529766083
Epoch 71 loss 0.24155589938163757
Epoch 72 loss 0.26631125807762146
Epoch 73 loss 0.24239718914031982
Epoch 74 loss 0.29269012808799744
Epoch 75 loss 0.23409530520439148
Epoch 76 loss 0.24874906241893768
Epoch 77 loss 0.2993449866771698
Epoch 78 loss 0.24798214435577393
Epoch 79 loss 0.2532540261745453
Epoch 80 loss 0.26639121770858765
Epoch 81 loss 0.23675066232681274
Epoch 82 loss 0.2821851372718811
Epoch 83 loss 0.248927503824234
Epoch 84 loss 0.29429373145103455
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.35736, 'Log Loss - std': 0.08262064148867401} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 0.35736 and parameters: {'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}. Best is trial 1 with value: 0.35736.
Best parameters After Trials: {'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Parameters saved to YAML file!!!
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [1.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 ...
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]
 [0.0 0.0 0.0 ... 2.579169386727153 1.2837928753303054 0.9948004955077808]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7397204637527466
Epoch 1 loss 0.6235436201095581
Epoch 2 loss 0.6110126972198486
Epoch 3 loss 0.5361710786819458
Epoch 4 loss 0.5106548070907593
Epoch 5 loss 0.5841740369796753
Epoch 6 loss 0.4758479595184326
Epoch 7 loss 0.5034260749816895
Epoch 8 loss 0.47920531034469604
Epoch 9 loss 0.46532368659973145
Epoch 10 loss 0.4681207537651062
Epoch 11 loss 0.4769909083843231
Epoch 12 loss 0.4639335572719574
Epoch 13 loss 0.48533517122268677
Epoch 14 loss 0.5047598481178284
Epoch 15 loss 0.4779230058193207
Epoch 16 loss 0.46410197019577026
Epoch 17 loss 0.45939379930496216
Epoch 18 loss 0.4813471734523773
Epoch 19 loss 0.46456965804100037
Epoch 20 loss 0.4756713807582855
Epoch 21 loss 0.478144109249115
Epoch 22 loss 0.4745599627494812
Epoch 23 loss 0.46466612815856934
Epoch 24 loss 0.4541133642196655
Epoch 25 loss 0.4420158863067627
Epoch 26 loss 0.4562499225139618
Epoch 27 loss 0.43449923396110535
Epoch 28 loss 0.42620715498924255
Epoch 29 loss 0.4550562798976898
Epoch 30 loss 0.4047192931175232
Epoch 31 loss 0.40939196944236755
Epoch 32 loss 0.42887991666793823
Epoch 33 loss 0.4318412244319916
Epoch 34 loss 0.3870980441570282
Epoch 35 loss 0.3838704228401184
Epoch 36 loss 0.3853529393672943
Epoch 37 loss 0.3693983256816864
Epoch 38 loss 0.3849810063838959
Epoch 39 loss 0.35749325156211853
Epoch 40 loss 0.35451802611351013
Epoch 41 loss 0.36440905928611755
Epoch 42 loss 0.36942625045776367
Epoch 43 loss 0.3439216613769531
Epoch 44 loss 0.3596509099006653
Epoch 45 loss 0.3651648461818695
Epoch 46 loss 0.367095410823822
Epoch 47 loss 0.3380795419216156
Epoch 48 loss 0.35373902320861816
Epoch 49 loss 0.35396668314933777
Epoch 50 loss 0.3756101131439209
Epoch 51 loss 0.3514288365840912
Epoch 52 loss 0.36057329177856445
Epoch 53 loss 0.33707770705223083
Epoch 54 loss 0.34935709834098816
Epoch 55 loss 0.36752963066101074
Epoch 56 loss 0.32560545206069946
Epoch 57 loss 0.38704532384872437
Epoch 58 loss 0.3874078691005707
Epoch 59 loss 0.3979538381099701
Epoch 60 loss 0.32799074053764343
Epoch 61 loss 0.34026896953582764
Epoch 62 loss 0.3561208248138428
Epoch 63 loss 0.3526592254638672
Epoch 64 loss 0.3642575740814209
Epoch 65 loss 0.40111374855041504
Epoch 66 loss 0.3696426749229431
Epoch 67 loss 0.380237340927124
Epoch 68 loss 0.3656681180000305
Epoch 69 loss 0.3973935544490814
Epoch 70 loss 0.3657853305339813
Epoch 71 loss 0.37116727232933044
Epoch 72 loss 0.387871116399765
Epoch 73 loss 0.3700006902217865
Epoch 74 loss 0.38495978713035583
Epoch 75 loss 0.3639141321182251
Epoch 76 loss 0.36493200063705444
Epoch 77 loss 0.3794334828853607
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/SAT11/logging/loss_0.txt
File name : output/SAINT/SAT11/logging/loss_0.txt . The file was saved
Log file exists at: output/SAINT/SAT11/logging/val_loss_0.txt
File name : output/SAINT/SAT11/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3421, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 ...
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]
 [0.0 0.0 0.0 ... 2.5554593677083233 1.2724838377231176
  0.9898050177516838]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7803845405578613
Epoch 1 loss 0.6745214462280273
Epoch 2 loss 0.6540576815605164
Epoch 3 loss 0.6210489869117737
Epoch 4 loss 0.6048783659934998
Epoch 5 loss 0.5792707204818726
Epoch 6 loss 0.6281493902206421
Epoch 7 loss 0.5857731103897095
Epoch 8 loss 0.5733083486557007
Epoch 9 loss 0.587549090385437
Epoch 10 loss 0.5735453367233276
Epoch 11 loss 0.5824460387229919
Epoch 12 loss 0.603200376033783
Epoch 13 loss 0.5665408372879028
Epoch 14 loss 0.5402969121932983
Epoch 15 loss 0.5690041184425354
Epoch 16 loss 0.5717103481292725
Epoch 17 loss 0.561944842338562
Epoch 18 loss 0.578170657157898
Epoch 19 loss 0.5886420011520386
Epoch 20 loss 0.5877907276153564
Epoch 21 loss 0.5643026828765869
Epoch 22 loss 0.568306565284729
Epoch 23 loss 0.5835086703300476
Epoch 24 loss 0.5653610825538635
Epoch 25 loss 0.5521182417869568
Epoch 26 loss 0.565424382686615
Epoch 27 loss 0.5748295783996582
Epoch 28 loss 0.55191969871521
Epoch 29 loss 0.5409257411956787
Epoch 30 loss 0.5408832430839539
Epoch 31 loss 0.5367593169212341
Epoch 32 loss 0.5190962553024292
Epoch 33 loss 0.5660573840141296
Epoch 34 loss 0.524429202079773
Epoch 35 loss 0.5143454074859619
Epoch 36 loss 0.5220910310745239
Epoch 37 loss 0.5321256518363953
Epoch 38 loss 0.4978834092617035
Epoch 39 loss 0.5318031311035156
Epoch 40 loss 0.5019523501396179
Epoch 41 loss 0.5140619874000549
Epoch 42 loss 0.4799496531486511
Epoch 43 loss 0.5022789239883423
Epoch 44 loss 0.4447541832923889
Epoch 45 loss 0.46046876907348633
Epoch 46 loss 0.45899730920791626
Epoch 47 loss 0.4654166102409363
Epoch 48 loss 0.45532354712486267
Epoch 49 loss 0.48603248596191406
Epoch 50 loss 0.4528982639312744
Epoch 51 loss 0.45794376730918884
Epoch 52 loss 0.5033788681030273
Epoch 53 loss 0.4570286273956299
Epoch 54 loss 0.4596669375896454
Epoch 55 loss 0.4549899101257324
Epoch 56 loss 0.4815414845943451
Epoch 57 loss 0.4332045912742615
Epoch 58 loss 0.43051859736442566
Epoch 59 loss 0.4561172425746918
Epoch 60 loss 0.44079896807670593
Epoch 61 loss 0.46677708625793457
Epoch 62 loss 0.4542407989501953
Epoch 63 loss 0.4648577570915222
Epoch 64 loss 0.4693242907524109
Epoch 65 loss 0.44978123903274536
Epoch 66 loss 0.40717315673828125
Epoch 67 loss 0.4851948618888855
Epoch 68 loss 0.4869470000267029
Epoch 69 loss 0.43879565596580505
Epoch 70 loss 0.4793015122413635
Epoch 71 loss 0.4797985255718231
Epoch 72 loss 0.4519280195236206
Epoch 73 loss 0.46875566244125366
Epoch 74 loss 0.4856606721878052
Epoch 75 loss 0.47239482402801514
Epoch 76 loss 0.5188774466514587
Epoch 77 loss 0.4875301718711853
Epoch 78 loss 0.47548922896385193
Epoch 79 loss 0.47692057490348816
Epoch 80 loss 0.5222722887992859
Epoch 81 loss 0.4780980944633484
Epoch 82 loss 0.48277243971824646
Epoch 83 loss 0.5493327975273132
Epoch 84 loss 0.5363427996635437
Epoch 85 loss 0.48099884390830994
Epoch 86 loss 0.5372859835624695
Epoch 87 loss 0.5567667484283447
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/SAT11/logging/loss_1.txt
File name : output/SAINT/SAT11/logging/loss_1.txt . The file was saved
Log file exists at: output/SAINT/SAT11/logging/val_loss_1.txt
File name : output/SAINT/SAT11/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.38185, 'Log Loss - std': 0.03974999999999998} 
 

Fold 3
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 ...
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]
 [0.0 0.0 0.0 ... 2.572681656950333 1.2836416330199947 0.9931480745530373]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7367855310440063
Epoch 1 loss 0.6038073301315308
Epoch 2 loss 0.5449188351631165
Epoch 3 loss 0.5334281921386719
Epoch 4 loss 0.499003142118454
Epoch 5 loss 0.5084115862846375
Epoch 6 loss 0.4928959310054779
Epoch 7 loss 0.4733310341835022
Epoch 8 loss 0.48599833250045776
Epoch 9 loss 0.4701334834098816
Epoch 10 loss 0.4752574861049652
Epoch 11 loss 0.47159573435783386
Epoch 12 loss 0.4599219262599945
Epoch 13 loss 0.45977991819381714
Epoch 14 loss 0.45124053955078125
Epoch 15 loss 0.4597019553184509
Epoch 16 loss 0.45867180824279785
Epoch 17 loss 0.44903773069381714
Epoch 18 loss 0.45392274856567383
Epoch 19 loss 0.444711297750473
Epoch 20 loss 0.4358426332473755
Epoch 21 loss 0.44192707538604736
Epoch 22 loss 0.43502283096313477
Epoch 23 loss 0.4227849245071411
Epoch 24 loss 0.4338362216949463
Epoch 25 loss 0.4278145432472229
Epoch 26 loss 0.4464882016181946
Epoch 27 loss 0.41099119186401367
Epoch 28 loss 0.42804455757141113
Epoch 29 loss 0.39927101135253906
Epoch 30 loss 0.4028185307979584
Epoch 31 loss 0.4005621671676636
Epoch 32 loss 0.39857006072998047
Epoch 33 loss 0.390299528837204
Epoch 34 loss 0.38451823592185974
Epoch 35 loss 0.3806799650192261
Epoch 36 loss 0.37849053740501404
Epoch 37 loss 0.37712937593460083
Epoch 38 loss 0.36982688307762146
Epoch 39 loss 0.38927900791168213
Epoch 40 loss 0.3631133437156677
Epoch 41 loss 0.3743133544921875
Epoch 42 loss 0.3302598297595978
Epoch 43 loss 0.3627479076385498
Epoch 44 loss 0.3528793752193451
Epoch 45 loss 0.3523590564727783
Epoch 46 loss 0.33972734212875366
Epoch 47 loss 0.3504495322704315
Epoch 48 loss 0.3357359766960144
Epoch 49 loss 0.3665045499801636
Epoch 50 loss 0.327617347240448
Epoch 51 loss 0.3306264281272888
Epoch 52 loss 0.32661008834838867
Epoch 53 loss 0.32556888461112976
Epoch 54 loss 0.3702114224433899
Epoch 55 loss 0.3190940320491791
Epoch 56 loss 0.3065221905708313
Epoch 57 loss 0.34072670340538025
Epoch 58 loss 0.3321426808834076
Epoch 59 loss 0.305495023727417
Epoch 60 loss 0.3406669497489929
Epoch 61 loss 0.32954490184783936
Epoch 62 loss 0.3141418695449829
Epoch 63 loss 0.3066990077495575
Epoch 64 loss 0.3249870538711548
Epoch 65 loss 0.3560064733028412
Epoch 66 loss 0.3220270276069641
Epoch 67 loss 0.30692780017852783
Epoch 68 loss 0.30818089842796326
Epoch 69 loss 0.3175402581691742
Epoch 70 loss 0.34693264961242676
Epoch 71 loss 0.3187843859195709
Epoch 72 loss 0.3423037528991699
Epoch 73 loss 0.36538493633270264
Epoch 74 loss 0.3369515836238861
Epoch 75 loss 0.3254477381706238
Epoch 76 loss 0.3512769639492035
Epoch 77 loss 0.30292075872421265
Epoch 78 loss 0.3429703712463379
Epoch 79 loss 0.31820642948150635
Epoch 80 loss 0.38515740633010864
Epoch 81 loss 0.3417391777038574
Epoch 82 loss 0.3829762637615204
Epoch 83 loss 0.3236367106437683
Epoch 84 loss 0.36601412296295166
Epoch 85 loss 0.3573013246059418
Epoch 86 loss 0.373959481716156
Epoch 87 loss 0.33026620745658875
Epoch 88 loss 0.36883509159088135
Epoch 89 loss 0.41706615686416626
Epoch 90 loss 0.3417139947414398
Epoch 91 loss 0.3904462456703186
Epoch 92 loss 0.37923693656921387
Epoch 93 loss 0.3624880909919739
Epoch 94 loss 0.36127930879592896
Epoch 95 loss 0.38517141342163086
Epoch 96 loss 0.4587484300136566
Epoch 97 loss 0.42831704020500183
Epoch 98 loss 0.3562079071998596
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/SAT11/logging/loss_2.txt
File name : output/SAINT/SAT11/logging/loss_2.txt . The file was saved
Log file exists at: output/SAINT/SAT11/logging/val_loss_2.txt
File name : output/SAINT/SAT11/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.3650333333333333, 'Log Loss - std': 0.0402364953189956} 
 

Fold 4
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 1.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 ...
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]
 [0.0 0.0 0.0 ... 2.5776931347039733 1.2593157823662984
  0.9810282088831183]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7333042025566101
Epoch 1 loss 0.653099536895752
Epoch 2 loss 0.6230305433273315
Epoch 3 loss 0.6133502721786499
Epoch 4 loss 0.5392234325408936
Epoch 5 loss 0.5538319945335388
Epoch 6 loss 0.5215723514556885
Epoch 7 loss 0.5146795511245728
Epoch 8 loss 0.5232595205307007
Epoch 9 loss 0.5686216354370117
Epoch 10 loss 0.5247161984443665
Epoch 11 loss 0.5528127551078796
Epoch 12 loss 0.5358965396881104
Epoch 13 loss 0.5145372152328491
Epoch 14 loss 0.5248690843582153
Epoch 15 loss 0.5113641023635864
Epoch 16 loss 0.5360094308853149
Epoch 17 loss 0.5259700417518616
Epoch 18 loss 0.5013141632080078
Epoch 19 loss 0.5396606922149658
Epoch 20 loss 0.5293803811073303
Epoch 21 loss 0.5791758894920349
Epoch 22 loss 0.5039368867874146
Epoch 23 loss 0.5149056911468506
Epoch 24 loss 0.5139895081520081
Epoch 25 loss 0.4861181378364563
Epoch 26 loss 0.49177107214927673
Epoch 27 loss 0.49657902121543884
Epoch 28 loss 0.5153550505638123
Epoch 29 loss 0.5098044872283936
Epoch 30 loss 0.48068270087242126
Epoch 31 loss 0.5058465003967285
Epoch 32 loss 0.5236110687255859
Epoch 33 loss 0.4583204984664917
Epoch 34 loss 0.4836391806602478
Epoch 35 loss 0.5042897462844849
Epoch 36 loss 0.47801852226257324
Epoch 37 loss 0.45962581038475037
Epoch 38 loss 0.4519515633583069
Epoch 39 loss 0.4701147675514221
Epoch 40 loss 0.49804505705833435
Epoch 41 loss 0.4513254165649414
Epoch 42 loss 0.4872865080833435
Epoch 43 loss 0.499109148979187
Epoch 44 loss 0.45100027322769165
Epoch 45 loss 0.4548909366130829
Epoch 46 loss 0.40960824489593506
Epoch 47 loss 0.426214337348938
Epoch 48 loss 0.39503762125968933
Epoch 49 loss 0.4156965911388397
Epoch 50 loss 0.4126322269439697
Epoch 51 loss 0.4171578884124756
Epoch 52 loss 0.39605042338371277
Epoch 53 loss 0.4182392358779907
Epoch 54 loss 0.40840062499046326
Epoch 55 loss 0.4887392520904541
Epoch 56 loss 0.42811259627342224
Epoch 57 loss 0.4430874288082123
Epoch 58 loss 0.41894370317459106
Epoch 59 loss 0.4573058485984802
Epoch 60 loss 0.4105369448661804
Epoch 61 loss 0.46799370646476746
Epoch 62 loss 0.43515580892562866
Epoch 63 loss 0.46699652075767517
Epoch 64 loss 0.5544933080673218
Epoch 65 loss 0.47052618861198425
Epoch 66 loss 0.4463874101638794
Epoch 67 loss 0.44083595275878906
Epoch 68 loss 0.4412086606025696
Epoch 69 loss 0.4406234920024872
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/SAT11/logging/loss_3.txt
File name : output/SAINT/SAT11/logging/loss_3.txt . The file was saved
Log file exists at: output/SAINT/SAT11/logging/val_loss_3.txt
File name : output/SAINT/SAT11/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.378175, 'Log Loss - std': 0.04162141125670777} 
 

Fold 5
num_features : 116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :116
num_classes : 1
cat_idx : [0]
nominal_idx : [115]
ordinal_idx : None
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1380, 116)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
Cat Dims V1 : []
Cat Idx V1 : [115] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 1.0 0.0]
 [1.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 1.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 1.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]
 [0.0 0.0 0.0 0.0 0.0]] 
 
 
Val : (1380, 130) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114] 


OHE Idx : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]


Ordinal Idx V2: None


Cat Dims V2 : []
Cat Idx V2 : None 
 

Train: [[0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [1.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 1.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 ...
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]
 [0.0 0.0 0.0 ... 2.6560947038188796 1.2792309188622057
  0.9870369058550037]] 
 
 
Val : (1380, 130) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 3
Unique values in y_train: (array([0., 1., 2.]), 3)
Unique values in y_test: (array([0., 1., 2.]), 3)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2], Length : 3
Test after shift : [0 1 2], Length : 3
Number of Classes After Bin Verifier: 3
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 2, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7318600416183472
Epoch 1 loss 0.6338305473327637
Epoch 2 loss 0.5222365856170654
Epoch 3 loss 0.4684546887874603
Epoch 4 loss 0.4652861952781677
Epoch 5 loss 0.5189658403396606
Epoch 6 loss 0.4483048915863037
Epoch 7 loss 0.4232890009880066
Epoch 8 loss 0.44262319803237915
Epoch 9 loss 0.41731947660446167
Epoch 10 loss 0.4121537208557129
Epoch 11 loss 0.41544443368911743
Epoch 12 loss 0.4307079017162323
Epoch 13 loss 0.4024495482444763
Epoch 14 loss 0.41194507479667664
Epoch 15 loss 0.3842695653438568
Epoch 16 loss 0.38700222969055176
Epoch 17 loss 0.40186434984207153
Epoch 18 loss 0.3907763659954071
Epoch 19 loss 0.4055938720703125
Epoch 20 loss 0.38822731375694275
Epoch 21 loss 0.38392528891563416
Epoch 22 loss 0.3951033055782318
Epoch 23 loss 0.3726883828639984
Epoch 24 loss 0.36557984352111816
Epoch 25 loss 0.3715493679046631
Epoch 26 loss 0.36830997467041016
Epoch 27 loss 0.3973264694213867
Epoch 28 loss 0.3890474736690521
Epoch 29 loss 0.3612714409828186
Epoch 30 loss 0.37059077620506287
Epoch 31 loss 0.35847848653793335
Epoch 32 loss 0.355316162109375
Epoch 33 loss 0.34067922830581665
Epoch 34 loss 0.362201064825058
Epoch 35 loss 0.3361744284629822
Epoch 36 loss 0.32386481761932373
Epoch 37 loss 0.3201781213283539
Epoch 38 loss 0.3214312195777893
Epoch 39 loss 0.3274586796760559
Epoch 40 loss 0.3337671458721161
Epoch 41 loss 0.3240363299846649
Epoch 42 loss 0.30388304591178894
Epoch 43 loss 0.3018156886100769
Epoch 44 loss 0.3125378489494324
Epoch 45 loss 0.2982761263847351
Epoch 46 loss 0.2907487750053406
Epoch 47 loss 0.28120213747024536
Epoch 48 loss 0.30807700753211975
Epoch 49 loss 0.27875417470932007
Epoch 50 loss 0.30008384585380554
Epoch 51 loss 0.2661346197128296
Epoch 52 loss 0.2636430859565735
Epoch 53 loss 0.2696138322353363
Epoch 54 loss 0.2589312791824341
Epoch 55 loss 0.26718565821647644
Epoch 56 loss 0.25075891613960266
Epoch 57 loss 0.24732516705989838
Epoch 58 loss 0.26180553436279297
Epoch 59 loss 0.26972824335098267
Epoch 60 loss 0.2489728182554245
Epoch 61 loss 0.28436946868896484
Epoch 62 loss 0.25323405861854553
Epoch 63 loss 0.2316712737083435
Epoch 64 loss 0.253196656703949
Epoch 65 loss 0.2513847351074219
Epoch 66 loss 0.24818575382232666
Epoch 67 loss 0.2315378189086914
Epoch 68 loss 0.22717249393463135
Epoch 69 loss 0.24081718921661377
Epoch 70 loss 0.2608633041381836
Epoch 71 loss 0.2595526874065399
Epoch 72 loss 0.24939942359924316
Epoch 73 loss 0.23885419964790344
Epoch 74 loss 0.23479752242565155
Epoch 75 loss 0.25000327825546265
Epoch 76 loss 0.23302368819713593
Epoch 77 loss 0.23701739311218262
Epoch 78 loss 0.2422991693019867
Epoch 79 loss 0.26301154494285583
Epoch 80 loss 0.22890430688858032
Epoch 81 loss 0.22232608497142792
Epoch 82 loss 0.2625313401222229
Epoch 83 loss 0.2465353012084961
Epoch 84 loss 0.23079797625541687
Epoch 85 loss 0.24881523847579956
Epoch 86 loss 0.26721125841140747
Epoch 87 loss 0.24385160207748413
Epoch 88 loss 0.2488490343093872
Epoch 89 loss 0.23894000053405762
Epoch 90 loss 0.2468349039554596
Epoch 91 loss 0.2864072322845459
Epoch 92 loss 0.24997186660766602
Epoch 93 loss 0.27198511362075806
Epoch 94 loss 0.2772207260131836
Epoch 95 loss 0.265421986579895
Epoch 96 loss 0.26311326026916504
Epoch 97 loss 0.2536751627922058
Epoch 98 loss 0.2657915949821472
Epoch 99 loss 0.2717211842536926
State of save is True b4 loss saving
Log file exists at: output/SAINT/SAT11/logging/loss_4.txt
File name : output/SAINT/SAT11/logging/loss_4.txt . The file was saved
Log file exists at: output/SAINT/SAT11/logging/val_loss_4.txt
File name : output/SAINT/SAT11/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 3
Class label len :3
Class labels : [0, 1, 2]
Unique y_true : [0 1 2] 

Prediction shape : (345,)
Probabilities shape : (345, 3) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.34642, 'Log Loss - std': 0.07361653075227058} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 0.34642, 'Log Loss - std': 0.07361653075227058}
Train time: 431.2714955677998
Inference time: 0.22801503039972887
Finished cross validation
Loss path :output/SAINT/SAT11/logging/
Plots saved successfully!


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/diamonds.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/diamonds.yml', data_parallel=False, dataset='Diamonds', direction='maximize', dropna_idx=None, early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=2, nominal_idx=None, num_bins=10, num_classes=1, num_features=9, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=False, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[1, 2, 3], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset Diamonds...
Dataset loaded! 

(53940, 9)
A new study created in RDB with name: SAINT_Diamonds
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 'Ideal' 'E' 'SI2' -0.17767576091934348]
 [-1.236976378485391 'Premium' 'E' 'SI1' -1.3637394355688461]
 [-1.069224675734413 'Premium' 'I' 'VS2' 0.45024030213039123]
 [-1.1740694899537742 'Very Good' 'J' 'VVS2' 0.7293141079302727]
 [-1.1740694899537742 'Very Good' 'I' 'VVS1' 0.3804718506804196]
 [-1.1321315642660297 'Very Good' 'H' 'SI1' 0.10139804488053805]
 [-1.2160074156415188 'Fair' 'E' 'VS2' 2.3339884912795954]
 [-1.1950384527976465 'Very Good' 'H' 'VS1' -1.6428132413687278]
 [-1.0482557128905408 'Good' 'J' 'SI1' 1.5665355253299222]
 [-1.1950384527976465 'Ideal' 'J' 'VS1' 0.7293141079302727]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 5 6 2 -0.17767576091934348 -1.0997679290240274
  -1.5847483029459433 -1.5624470539339794 -1.5635817068251905]
 [-1.236976378485391 4 6 3 -1.3637394355688461 1.5843835902987453
  -1.6380368496537203 -1.6869504169773575 -1.7324417222907198]
 [-1.069224675734413 4 2 4 0.45024030213039123 0.24230783063735892
  -1.3627126916635395 -1.3401196199279468 -1.2821483477159754]
 [-1.1740694899537742 3 1 6 0.7293141079302727 -0.20505075591643654
  -1.5936297273972397 -1.580233248654462 -1.493223367047887]
 [-1.1740694899537742 3 2 7 0.3804718506804196 -0.20505075591643654
  -1.5847483029459433 -1.5624470539339794 -1.5072950350033474]
 [-1.1321315642660297 3 3 3 0.10139804488053805 -1.0997679290240274
  -1.4781712095303894 -1.4468367882508424 -1.4228650272705832]
 [-1.2160074156415188 1 6 4 2.3339884912795954 1.5843835902987453
  -1.6557996985563126 -1.7403090011388052 -1.4791516990924258]
 [-1.1950384527976465 3 3 5 -1.6428132413687278 1.5843835902987453
  -1.5403411806894627 -1.5001953724122905 -1.6198683786470336]
 [-1.0482557128905408 2 1 3 1.5665355253299222 -1.0997679290240274
  -1.318305569407059 -1.2956541331267404 -1.1414316681613677]
 [-1.1950384527976465 5 1 5 0.7293141079302727 -0.652409342470232
  -1.6025111518485355 -1.6335918328159098 -1.5213667029588085]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7551032900810242
Epoch 1 loss 0.696894645690918
Epoch 2 loss 0.7025978565216064
Epoch 3 loss 0.6698234677314758
Epoch 4 loss 0.6815442442893982
Epoch 5 loss 0.6664653420448303
Epoch 6 loss 0.7016732692718506
Epoch 7 loss 0.6552090048789978
Epoch 8 loss 0.6614634394645691
Epoch 9 loss 0.6393417716026306
Epoch 10 loss 0.632640540599823
Epoch 11 loss 0.6191393136978149
Epoch 12 loss 0.6206772327423096
Epoch 13 loss 0.5815843343734741
Epoch 14 loss 0.5825156569480896
Epoch 15 loss 0.5970444083213806
Epoch 16 loss 0.5726274847984314
Epoch 17 loss 0.5794382691383362
Epoch 18 loss 0.5716468691825867
Epoch 19 loss 0.5787168145179749
Epoch 20 loss 0.5832251310348511
Epoch 21 loss 0.5715174078941345
Epoch 22 loss 0.5854452848434448
Epoch 23 loss 0.5887871980667114
Epoch 24 loss 0.5755510926246643
Epoch 25 loss 0.5758541822433472
Epoch 26 loss 0.5816498398780823
Epoch 27 loss 0.5935392379760742
Epoch 28 loss 0.5961433053016663
Epoch 29 loss 0.5850059390068054
Epoch 30 loss 0.6032295823097229
Epoch 31 loss 0.6025196313858032
Epoch 32 loss 0.6065508127212524
Epoch 33 loss 0.5944281816482544
Epoch 34 loss 0.6096773743629456
Epoch 35 loss 0.6072163581848145
Epoch 36 loss 0.626851499080658
Epoch 37 loss 0.6682162880897522
Epoch 38 loss 0.6246867775917053
Epoch 39 loss 0.6270495653152466
Epoch 40 loss 0.6343321800231934
Epoch 41 loss 0.6506635546684265
Epoch 42 loss 0.6484361290931702
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6558, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 'Premium' 'E' 'SI1' -1.3617245236890496]
 [-1.1991826034964022 'Good' 'E' 'VS1' -3.3871902928108906]
 [-1.0725306248271413 'Premium' 'I' 'VS2' 0.4542103037994991]
 [-1.0303132986040544 'Good' 'J' 'SI2' 1.08280312869938]
 [-1.1780739403848586 'Very Good' 'J' 'VVS2' 0.73358489264389]
 [-1.1780739403848586 'Very Good' 'I' 'VVS1' 0.38436665658840014]
 [-1.1358566141617716 'Very Good' 'H' 'SI1' 0.10499206774400914]
 [-1.2202912666079455 'Fair' 'E' 'VS2' 2.339988778499142]
 [-1.1991826034964022 'Very Good' 'H' 'VS1' -1.6410991125334407]
 [-1.051421961715598 'Good' 'J' 'SI1' 1.571708659177068]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 4 6 3 -1.3617245236890496 1.5949518123380095
  -1.6437879201752599 -1.6514473425787888 -1.7685832176092422]
 [-1.1991826034964022 2 6 5 -3.3871902928108906 3.3941876961159525
  -1.5010019420077028 -1.4510608771835314 -1.7685832176092422]
 [-1.0725306248271413 4 2 4 0.4542103037994991 0.24552489950455236
  -1.3671400874756174 -1.3116615969085696 -1.307955447116008]
 [-1.0303132986040544 2 1 2 1.08280312869938 0.24552489950455236
  -1.242202356579005 -1.2071121367023494 -1.135220033181045]
 [-1.1780739403848586 3 1 6 0.73358489264389 -0.20428407143993338
  -1.5991673019978982 -1.5468978823725676 -1.5238747145347116]
 [-1.1780739403848586 3 2 7 0.38436665658840014 -0.20428407143993338
  -1.5902431783624258 -1.5294729723381975 -1.5382693323626249]
 [-1.1358566141617716 3 3 3 0.10499206774400914 -1.1039020133289048
  -1.4831536947367576 -1.416211057114791 -1.4519016253951438]
 [-1.2202912666079455 1 6 4 2.339988778499142 1.5949518123380095
  -1.6616361674462046 -1.7037220726818993 -1.5094800967067976]
 [-1.1991826034964022 3 3 5 -1.6410991125334407 1.5949518123380095
  -1.5456225601850642 -1.4684857872179018 -1.6534262749859334]
 [-1.051421961715598 2 1 3 1.571708659177068 -1.1039020133289048
  -1.3225194692982558 -1.2680993218226444 -1.164009268836872]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7534130215644836
Epoch 1 loss 0.7422053813934326
Epoch 2 loss 0.7016710042953491
Epoch 3 loss 0.6793166995048523
Epoch 4 loss 0.717926561832428
Epoch 5 loss 0.6587111949920654
Epoch 6 loss 0.6715801358222961
Epoch 7 loss 0.6675752401351929
Epoch 8 loss 0.6643276810646057
Epoch 9 loss 0.6563353538513184
Epoch 10 loss 0.6509053707122803
Epoch 11 loss 0.6519457697868347
Epoch 12 loss 0.6466994285583496
Epoch 13 loss 0.648860514163971
Epoch 14 loss 0.6189444661140442
Epoch 15 loss 0.6152098774909973
Epoch 16 loss 0.600584089756012
Epoch 17 loss 0.5858261585235596
Epoch 18 loss 0.6015123724937439
Epoch 19 loss 0.5996014475822449
Epoch 20 loss 0.585742712020874
Epoch 21 loss 0.5885555744171143
Epoch 22 loss 0.5880562663078308
Epoch 23 loss 0.5873505473136902
Epoch 24 loss 0.5875977277755737
Epoch 25 loss 0.5958156585693359
Epoch 26 loss 0.5999933481216431
Epoch 27 loss 0.5976411700248718
Epoch 28 loss 0.6261274814605713
Epoch 29 loss 0.6157089471817017
Epoch 30 loss 0.6118537187576294
Epoch 31 loss 0.6179293990135193
Epoch 32 loss 0.6081526875495911
Epoch 33 loss 0.6321783661842346
Epoch 34 loss 0.6233781576156616
Epoch 35 loss 0.6349563002586365
Epoch 36 loss 0.6449538469314575
Epoch 37 loss 0.6622242331504822
Epoch 38 loss 0.6419184803962708
Epoch 39 loss 0.6504865884780884
Epoch 40 loss 0.663388192653656
Epoch 41 loss 0.6617985963821411
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.667, 'Log Loss - std': 0.011199999999999988} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 'Ideal' 'E' 'SI2' -0.17299106375200937]
 [-1.2431374791872112 'Premium' 'E' 'SI1' -1.358384470113667]
 [-1.2007760315615899 'Good' 'E' 'VS1' -3.380526163318843]
 [-1.0736916886847254 'Premium' 'I' 'VS2' 0.45457015138063084]
 [-1.031330241059104 'Good' 'J' 'SI2' 1.082131366513271]
 [-1.179595307748779 'Very Good' 'J' 'VVS2' 0.733486246995137]
 [-1.179595307748779 'Very Good' 'I' 'VVS1' 0.38484112747700305]
 [-1.2219567553744004 'Fair' 'E' 'VS2' 2.3372537967785516]
 [-1.2007760315615899 'Very Good' 'H' 'VS1' -1.6373005657281732]
 [-1.0525109648719149 'Good' 'J' 'SI1' 1.5702345338386605]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 5 6 2 -0.17299106375200937 -1.0991811176282293
  -1.5887751661204468 -1.52741996295235 -1.5654913782973074]
 [-1.2431374791872112 4 6 3 -1.358384470113667 1.580885495554982
  -1.642349354189251 -1.6494018572095064 -1.7351080246385664]
 [-1.2007760315615899 2 6 5 -3.380526163318843 3.367596571010456
  -1.4994848526724398 -1.449003030929892 -1.7351080246385664]
 [-1.0736916886847254 4 2 4 0.45457015138063084 0.2408521889633763
  -1.3655493825004286 -1.309595151778856 -1.282796967728543]
 [-1.031330241059104 2 1 2 1.082131366513271 0.2408521889633763
  -1.2405429436732185 -1.2050392424155796 -1.113180321387284]
 [-1.179595307748779 3 1 6 0.733486246995137 -0.20582557990049227
  -1.5977041974652477 -1.5448459478462293 -1.4948177756551164]
 [-1.179595307748779 3 2 7 0.38484112747700305 -0.20582557990049227
  -1.5887751661204468 -1.52741996295235 -1.5089524961835543]
 [-1.2219567553744004 1 6 4 2.3372537967785516 1.580885495554982
  -1.6602074168788525 -1.701679811891145 -1.4806830551266779]
 [-1.2007760315615899 3 3 5 -1.6373005657281732 1.580885495554982
  -1.5441300093964432 -1.4664290158237718 -1.6220302604110604]
 [-1.0525109648719149 2 1 3 1.5702345338386605 -1.0991811176282293
  -1.320904225776425 -1.2660301895441572 -1.1414497624441604]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7689686417579651
Epoch 1 loss 0.8750631809234619
Epoch 2 loss 0.7388982772827148
Epoch 3 loss 0.6765177249908447
Epoch 4 loss 0.6814894676208496
Epoch 5 loss 0.6842713952064514
Epoch 6 loss 0.6887168884277344
Epoch 7 loss 0.6567444205284119
Epoch 8 loss 0.6755107045173645
Epoch 9 loss 0.6610996723175049
Epoch 10 loss 0.6743373274803162
Epoch 11 loss 0.6574325561523438
Epoch 12 loss 0.6252540946006775
Epoch 13 loss 0.6346094012260437
Epoch 14 loss 0.6111355423927307
Epoch 15 loss 0.618005096912384
Epoch 16 loss 0.6123967170715332
Epoch 17 loss 0.6132723093032837
Epoch 18 loss 0.6045840978622437
Epoch 19 loss 0.6005775332450867
Epoch 20 loss 0.5984814167022705
Epoch 21 loss 0.6088925004005432
Epoch 22 loss 0.6219478249549866
Epoch 23 loss 0.6163665652275085
Epoch 24 loss 0.6274374127388
Epoch 25 loss 0.6094557642936707
Epoch 26 loss 0.6116269826889038
Epoch 27 loss 0.637154221534729
Epoch 28 loss 0.6177379488945007
Epoch 29 loss 0.6301880478858948
Epoch 30 loss 0.6246694326400757
Epoch 31 loss 0.6281087398529053
Epoch 32 loss 0.6612627506256104
Epoch 33 loss 0.6306275129318237
Epoch 34 loss 0.6690861582756042
Epoch 35 loss 0.6665858626365662
Epoch 36 loss 0.6572676301002502
Epoch 37 loss 0.6844543218612671
Epoch 38 loss 0.6795994639396667
Epoch 39 loss 0.6706945896148682
Epoch 40 loss 0.695076048374176
Epoch 41 loss 0.7176584005355835
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6658333333333334, 'Log Loss - std': 0.00929241028414527} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 'Ideal' 'E' 'SI2' -0.17623676016550302]
 [-1.2007693433003284 'Good' 'E' 'VS1' -3.3952118794129094]
 [-1.0318275851408616 'Good' 'J' 'SI2' 1.0833621995400016]
 [-1.1796516235303949 'Very Good' 'J' 'VVS2' 0.7334735996218053]
 [-1.1374161839905281 'Very Good' 'H' 'SI1' 0.10367411976905298]
 [-1.2007693433003284 'Very Good' 'H' 'VS1' -1.6457688798219283]
 [-1.0529453049107949 'Good' 'J' 'SI1' 1.5732062394254782]
 [-1.2007693433003284 'Ideal' 'J' 'VS1' 0.7334735996218053]
 [-1.2218870630702616 'Premium' 'F' 'SI1' -0.9459916799855358]
 [-1.2641225026101284 'Premium' 'E' 'SI2' -1.0859471199528112]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 5 6 2 -0.17623676016550302 -1.1001014896248056
  -1.5915444854651115 -1.5301186577850108 -1.5696115327877844]
 [-1.2007693433003284 2 6 5 -3.3952118794129094 3.3772680777522917
  -1.5023022126050385 -1.4517413942698225 -1.739235168570439]
 [-1.0318275851408616 2 1 2 1.0833621995400016 0.2431093805883235
  -1.2434996213108258 -1.2079010188892378 -1.1172818373673723]
 [-1.1796516235303949 3 1 6 0.7334735996218053 -0.20462757614938623
  -1.600468712751119 -1.5475358274550528 -1.4989350178783452]
 [-1.1374161839905281 3 3 3 0.10367411976905298 -1.1001014896248056
  -1.4844537580330235 -1.416907054929739 -1.428258502968906]
 [-1.2007693433003284 3 3 5 -1.6457688798219283 1.5863202508014527
  -1.5469233490350751 -1.4691585639398648 -1.6261527447153359]
 [-1.0529453049107949 2 1 3 1.5732062394254782 -1.1001014896248056
  -1.3238176668848918 -1.2688611127343836 -1.1455524433311481]
 [-1.2007693433003284 5 1 5 0.7334735996218053 -0.652364532887096
  -1.6093929400371263 -1.5997873364651782 -1.527205623842121]
 [-1.2218870630702616 4 5 3 -0.9459916799855358 1.5863202508014527
  -1.6540140764671631 -1.6520388454753037 -1.7109645626066634]
 [-1.2641225026101284 4 6 2 -1.0859471199528112 2.0340572075391625
  -1.7343321220412289 -1.7304161089904915 -1.7957763804979907]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7634873390197754
Epoch 1 loss 0.7334754467010498
Epoch 2 loss 0.7105589509010315
Epoch 3 loss 0.7032845616340637
Epoch 4 loss 0.6525904536247253
Epoch 5 loss 0.6812866926193237
Epoch 6 loss 0.6652485728263855
Epoch 7 loss 0.6621764898300171
Epoch 8 loss 0.6603639125823975
Epoch 9 loss 0.6532023549079895
Epoch 10 loss 0.6368280053138733
Epoch 11 loss 0.641818642616272
Epoch 12 loss 0.6318818926811218
Epoch 13 loss 0.6342127919197083
Epoch 14 loss 0.6004950404167175
Epoch 15 loss 0.5958384275436401
Epoch 16 loss 0.6039308309555054
Epoch 17 loss 0.5990096926689148
Epoch 18 loss 0.5842742323875427
Epoch 19 loss 0.6110769510269165
Epoch 20 loss 0.614539623260498
Epoch 21 loss 0.5899477601051331
Epoch 22 loss 0.6038392782211304
Epoch 23 loss 0.6042509078979492
Epoch 24 loss 0.5895503759384155
Epoch 25 loss 0.5931435227394104
Epoch 26 loss 0.5960351228713989
Epoch 27 loss 0.599549412727356
Epoch 28 loss 0.6241528391838074
Epoch 29 loss 0.608306348323822
Epoch 30 loss 0.6102511882781982
Epoch 31 loss 0.6211704015731812
Epoch 32 loss 0.6349759101867676
Epoch 33 loss 0.6470370888710022
Epoch 34 loss 0.6541131734848022
Epoch 35 loss 0.6569466590881348
Epoch 36 loss 0.6651182770729065
Epoch 37 loss 0.670641303062439
Epoch 38 loss 0.6730501055717468
Epoch 39 loss 0.6731336116790771
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.66755, 'Log Loss - std': 0.008579189938449888} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 'Ideal' 'E' 'SI2' -0.16918805719128635]
 [-1.2373782800036142 'Premium' 'E' 'SI1' -1.354043921120755]
 [-1.1951587568816937 'Good' 'E' 'VS1' -3.375268630176903]
 [-1.0685001875159332 'Premium' 'I' 'VS2' 0.4580885766537244]
 [-1.0262806643940128 'Good' 'J' 'SI2' 1.085365210498735]
 [-1.1740489953207336 'Very Good' 'I' 'VVS1' 0.3883911728931665]
 [-1.1318294721988134 'Very Good' 'H' 'SI1' 0.10960155785094007]
 [-1.2162685184426538 'Fair' 'E' 'VS2' 2.3399184781887565]
 [-1.1951587568816937 'Ideal' 'J' 'VS1' 0.7368781916959508]
 [-1.2162685184426538 'Premium' 'F' 'SI1' -0.9358594985574128]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 5 6 2 -0.16918805719128635 -1.095468028782346
  -1.5839349366235063 -1.5322976251522233 -1.56187701865597]
 [-1.2373782800036142 4 6 3 -1.354043921120755 1.5812091849357435
  -1.6374236122792667 -1.6548711768767947 -1.731354397531372]
 [-1.1951587568816937 2 6 5 -3.375268630176903 3.3656606607478032
  -1.4947871438639058 -1.4535003419007129 -1.731354397531372]
 [-1.0685001875159332 4 2 4 0.4580885766537244 0.24287057807669882
  -1.3610654547245045 -1.313416282786917 -1.2794147205303008]
 [-1.0262806643940128 2 1 2 1.085365210498735 0.24287057807669882
  -1.236258544861064 -1.2083532384515707 -1.1099373416548988]
 [-1.1740489953207336 3 2 7 0.3883911728931665 -0.2032422908763161
  -1.5839349366235063 -1.5322976251522233 -1.5053845590308361]
 [-1.1318294721988134 3 3 3 0.10960155785094007 -1.095468028782346
  -1.4769575853119854 -1.418479327122264 -1.4206458695931359]
 [-1.2162685184426538 1 6 4 2.3399184781887565 1.5812091849357435
  -1.6552531708311868 -1.7074026990444682 -1.4771383292182692]
 [-1.1951587568816937 5 1 5 0.7368781916959508 -0.649355159829331
  -1.6017644951754264 -1.602339654709121 -1.51950767393712]
 [-1.2162685184426538 4 5 3 -0.9358594985574128 1.5812091849357435
  -1.646338391555227 -1.6548711768767947 -1.7031081677188051]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7318795919418335
Epoch 1 loss 0.7094264030456543
Epoch 2 loss 0.7220171093940735
Epoch 3 loss 0.6705803871154785
Epoch 4 loss 0.6764250993728638
Epoch 5 loss 0.6884047389030457
Epoch 6 loss 0.6537583470344543
Epoch 7 loss 0.664745032787323
Epoch 8 loss 0.6481021642684937
Epoch 9 loss 0.6657571792602539
Epoch 10 loss 0.6319769024848938
Epoch 11 loss 0.6515449285507202
Epoch 12 loss 0.6384028792381287
Epoch 13 loss 0.6341627836227417
Epoch 14 loss 0.627390444278717
Epoch 15 loss 0.593309760093689
Epoch 16 loss 0.597180962562561
Epoch 17 loss 0.5931302309036255
Epoch 18 loss 0.5912993550300598
Epoch 19 loss 0.6048904657363892
Epoch 20 loss 0.6020476222038269
Epoch 21 loss 0.5927411913871765
Epoch 22 loss 0.603618860244751
Epoch 23 loss 0.5942654013633728
Epoch 24 loss 0.5890910029411316
Epoch 25 loss 0.6024957299232483
Epoch 26 loss 0.6018547415733337
Epoch 27 loss 0.6092441082000732
Epoch 28 loss 0.6206454038619995
Epoch 29 loss 0.6230043172836304
Epoch 30 loss 0.6062129735946655
Epoch 31 loss 0.6183857917785645
Epoch 32 loss 0.6261583566665649
Epoch 33 loss 0.6415651440620422
Epoch 34 loss 0.6497491598129272
Epoch 35 loss 0.6397849917411804
Epoch 36 loss 0.6448521018028259
Epoch 37 loss 0.6560507416725159
Epoch 38 loss 0.6452363729476929
Epoch 39 loss 0.670291543006897
Epoch 40 loss 0.6868911385536194
Epoch 41 loss 0.7129839658737183
Epoch 42 loss 0.698912501335144
Epoch 43 loss 0.7076842784881592
Epoch 44 loss 0.7026404738426208
Epoch 45 loss 0.716010332107544
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.68326, 'Log Loss - std': 0.032343444467155924} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 0.68326 and parameters: {'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}. Best is trial 0 with value: 0.68326.
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 'Ideal' 'E' 'SI2' -0.17767576091934348]
 [-1.236976378485391 'Premium' 'E' 'SI1' -1.3637394355688461]
 [-1.069224675734413 'Premium' 'I' 'VS2' 0.45024030213039123]
 [-1.1740694899537742 'Very Good' 'J' 'VVS2' 0.7293141079302727]
 [-1.1740694899537742 'Very Good' 'I' 'VVS1' 0.3804718506804196]
 [-1.1321315642660297 'Very Good' 'H' 'SI1' 0.10139804488053805]
 [-1.2160074156415188 'Fair' 'E' 'VS2' 2.3339884912795954]
 [-1.1950384527976465 'Very Good' 'H' 'VS1' -1.6428132413687278]
 [-1.0482557128905408 'Good' 'J' 'SI1' 1.5665355253299222]
 [-1.1950384527976465 'Ideal' 'J' 'VS1' 0.7293141079302727]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 5 6 2 -0.17767576091934348 -1.0997679290240274
  -1.5847483029459433 -1.5624470539339794 -1.5635817068251905]
 [-1.236976378485391 4 6 3 -1.3637394355688461 1.5843835902987453
  -1.6380368496537203 -1.6869504169773575 -1.7324417222907198]
 [-1.069224675734413 4 2 4 0.45024030213039123 0.24230783063735892
  -1.3627126916635395 -1.3401196199279468 -1.2821483477159754]
 [-1.1740694899537742 3 1 6 0.7293141079302727 -0.20505075591643654
  -1.5936297273972397 -1.580233248654462 -1.493223367047887]
 [-1.1740694899537742 3 2 7 0.3804718506804196 -0.20505075591643654
  -1.5847483029459433 -1.5624470539339794 -1.5072950350033474]
 [-1.1321315642660297 3 3 3 0.10139804488053805 -1.0997679290240274
  -1.4781712095303894 -1.4468367882508424 -1.4228650272705832]
 [-1.2160074156415188 1 6 4 2.3339884912795954 1.5843835902987453
  -1.6557996985563126 -1.7403090011388052 -1.4791516990924258]
 [-1.1950384527976465 3 3 5 -1.6428132413687278 1.5843835902987453
  -1.5403411806894627 -1.5001953724122905 -1.6198683786470336]
 [-1.0482557128905408 2 1 3 1.5665355253299222 -1.0997679290240274
  -1.318305569407059 -1.2956541331267404 -1.1414316681613677]
 [-1.1950384527976465 5 1 5 0.7293141079302727 -0.652409342470232
  -1.6025111518485355 -1.6335918328159098 -1.5213667029588085]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 0.7299381494522095
Epoch 1 loss 0.6915866136550903
Epoch 2 loss 0.700895369052887
Epoch 3 loss 0.6582748293876648
Epoch 4 loss 0.6491146683692932
Epoch 5 loss 0.6579355001449585
Epoch 6 loss 0.6331232786178589
Epoch 7 loss 0.6332942247390747
Epoch 8 loss 0.6362934708595276
Epoch 9 loss 0.6121881008148193
Epoch 10 loss 0.5835225582122803
Epoch 11 loss 0.5853894948959351
Epoch 12 loss 0.5881101489067078
Epoch 13 loss 0.5747565031051636
Epoch 14 loss 0.5902775526046753
Epoch 15 loss 0.5743883848190308
Epoch 16 loss 0.5947826504707336
Epoch 17 loss 0.6111310720443726
Epoch 18 loss 0.6080196499824524
Epoch 19 loss 0.6159388422966003
Epoch 20 loss 0.6167340278625488
Epoch 21 loss 0.6471307873725891
Epoch 22 loss 0.6695664525032043
Epoch 23 loss 0.6660028696060181
Epoch 24 loss 0.6594637632369995
Epoch 25 loss 0.6772491931915283
Epoch 26 loss 0.7089118957519531
Epoch 27 loss 0.7171501517295837
Epoch 28 loss 0.7480174899101257
Epoch 29 loss 0.7500078678131104
Epoch 30 loss 0.8155635595321655
Epoch 31 loss 0.8212170004844666
Epoch 32 loss 0.8156466484069824
Epoch 33 loss 0.841424286365509
Epoch 34 loss 0.8441210985183716
Epoch 35 loss 0.8936701416969299
Epoch 36 loss 0.9303585290908813
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6322, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 'Premium' 'E' 'SI1' -1.3617245236890496]
 [-1.1991826034964022 'Good' 'E' 'VS1' -3.3871902928108906]
 [-1.0725306248271413 'Premium' 'I' 'VS2' 0.4542103037994991]
 [-1.0303132986040544 'Good' 'J' 'SI2' 1.08280312869938]
 [-1.1780739403848586 'Very Good' 'J' 'VVS2' 0.73358489264389]
 [-1.1780739403848586 'Very Good' 'I' 'VVS1' 0.38436665658840014]
 [-1.1358566141617716 'Very Good' 'H' 'SI1' 0.10499206774400914]
 [-1.2202912666079455 'Fair' 'E' 'VS2' 2.339988778499142]
 [-1.1991826034964022 'Very Good' 'H' 'VS1' -1.6410991125334407]
 [-1.051421961715598 'Good' 'J' 'SI1' 1.571708659177068]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 4 6 3 -1.3617245236890496 1.5949518123380095
  -1.6437879201752599 -1.6514473425787888 -1.7685832176092422]
 [-1.1991826034964022 2 6 5 -3.3871902928108906 3.3941876961159525
  -1.5010019420077028 -1.4510608771835314 -1.7685832176092422]
 [-1.0725306248271413 4 2 4 0.4542103037994991 0.24552489950455236
  -1.3671400874756174 -1.3116615969085696 -1.307955447116008]
 [-1.0303132986040544 2 1 2 1.08280312869938 0.24552489950455236
  -1.242202356579005 -1.2071121367023494 -1.135220033181045]
 [-1.1780739403848586 3 1 6 0.73358489264389 -0.20428407143993338
  -1.5991673019978982 -1.5468978823725676 -1.5238747145347116]
 [-1.1780739403848586 3 2 7 0.38436665658840014 -0.20428407143993338
  -1.5902431783624258 -1.5294729723381975 -1.5382693323626249]
 [-1.1358566141617716 3 3 3 0.10499206774400914 -1.1039020133289048
  -1.4831536947367576 -1.416211057114791 -1.4519016253951438]
 [-1.2202912666079455 1 6 4 2.339988778499142 1.5949518123380095
  -1.6616361674462046 -1.7037220726818993 -1.5094800967067976]
 [-1.1991826034964022 3 3 5 -1.6410991125334407 1.5949518123380095
  -1.5456225601850642 -1.4684857872179018 -1.6534262749859334]
 [-1.051421961715598 2 1 3 1.571708659177068 -1.1039020133289048
  -1.3225194692982558 -1.2680993218226444 -1.164009268836872]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 0.7361031174659729
Epoch 1 loss 0.7058805227279663
Epoch 2 loss 0.6855201125144958
Epoch 3 loss 0.6670282483100891
Epoch 4 loss 0.6700512766838074
Epoch 5 loss 0.6682590246200562
Epoch 6 loss 0.6509097218513489
Epoch 7 loss 0.6269514560699463
Epoch 8 loss 0.6247531175613403
Epoch 9 loss 0.6114868521690369
Epoch 10 loss 0.5917525291442871
Epoch 11 loss 0.5833425521850586
Epoch 12 loss 0.5895378589630127
Epoch 13 loss 0.6196690201759338
Epoch 14 loss 0.5891264081001282
Epoch 15 loss 0.615995466709137
Epoch 16 loss 0.6057811379432678
Epoch 17 loss 0.615062415599823
Epoch 18 loss 0.6284358501434326
Epoch 19 loss 0.6840378642082214
Epoch 20 loss 0.655708372592926
Epoch 21 loss 0.6763449907302856
Epoch 22 loss 0.6788793206214905
Epoch 23 loss 0.7231277823448181
Epoch 24 loss 0.7312531471252441
Epoch 25 loss 0.7322894334793091
Epoch 26 loss 0.8015794157981873
Epoch 27 loss 0.8123136758804321
Epoch 28 loss 0.8394808769226074
Epoch 29 loss 0.8578354120254517
Epoch 30 loss 0.8843312859535217
Epoch 31 loss 0.8829997777938843
Epoch 32 loss 0.8968603014945984
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6451, 'Log Loss - std': 0.012900000000000023} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 'Ideal' 'E' 'SI2' -0.17299106375200937]
 [-1.2431374791872112 'Premium' 'E' 'SI1' -1.358384470113667]
 [-1.2007760315615899 'Good' 'E' 'VS1' -3.380526163318843]
 [-1.0736916886847254 'Premium' 'I' 'VS2' 0.45457015138063084]
 [-1.031330241059104 'Good' 'J' 'SI2' 1.082131366513271]
 [-1.179595307748779 'Very Good' 'J' 'VVS2' 0.733486246995137]
 [-1.179595307748779 'Very Good' 'I' 'VVS1' 0.38484112747700305]
 [-1.2219567553744004 'Fair' 'E' 'VS2' 2.3372537967785516]
 [-1.2007760315615899 'Very Good' 'H' 'VS1' -1.6373005657281732]
 [-1.0525109648719149 'Good' 'J' 'SI1' 1.5702345338386605]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 5 6 2 -0.17299106375200937 -1.0991811176282293
  -1.5887751661204468 -1.52741996295235 -1.5654913782973074]
 [-1.2431374791872112 4 6 3 -1.358384470113667 1.580885495554982
  -1.642349354189251 -1.6494018572095064 -1.7351080246385664]
 [-1.2007760315615899 2 6 5 -3.380526163318843 3.367596571010456
  -1.4994848526724398 -1.449003030929892 -1.7351080246385664]
 [-1.0736916886847254 4 2 4 0.45457015138063084 0.2408521889633763
  -1.3655493825004286 -1.309595151778856 -1.282796967728543]
 [-1.031330241059104 2 1 2 1.082131366513271 0.2408521889633763
  -1.2405429436732185 -1.2050392424155796 -1.113180321387284]
 [-1.179595307748779 3 1 6 0.733486246995137 -0.20582557990049227
  -1.5977041974652477 -1.5448459478462293 -1.4948177756551164]
 [-1.179595307748779 3 2 7 0.38484112747700305 -0.20582557990049227
  -1.5887751661204468 -1.52741996295235 -1.5089524961835543]
 [-1.2219567553744004 1 6 4 2.3372537967785516 1.580885495554982
  -1.6602074168788525 -1.701679811891145 -1.4806830551266779]
 [-1.2007760315615899 3 3 5 -1.6373005657281732 1.580885495554982
  -1.5441300093964432 -1.4664290158237718 -1.6220302604110604]
 [-1.0525109648719149 2 1 3 1.5702345338386605 -1.0991811176282293
  -1.320904225776425 -1.2660301895441572 -1.1414497624441604]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 0.8474164605140686
Epoch 1 loss 0.7189804911613464
Epoch 2 loss 0.6860489249229431
Epoch 3 loss 0.6988105177879333
Epoch 4 loss 0.6974981427192688
Epoch 5 loss 0.6918392181396484
Epoch 6 loss 0.6854461431503296
Epoch 7 loss 0.6476574540138245
Epoch 8 loss 0.6457177400588989
Epoch 9 loss 0.6176908016204834
Epoch 10 loss 0.6077562570571899
Epoch 11 loss 0.5941511988639832
Epoch 12 loss 0.6232782602310181
Epoch 13 loss 0.601886510848999
Epoch 14 loss 0.6087742447853088
Epoch 15 loss 0.6095112562179565
Epoch 16 loss 0.639697253704071
Epoch 17 loss 0.6321870684623718
Epoch 18 loss 0.6360587477684021
Epoch 19 loss 0.6523009538650513
Epoch 20 loss 0.6636161804199219
Epoch 21 loss 0.6864985823631287
Epoch 22 loss 0.6917212009429932
Epoch 23 loss 0.6982269883155823
Epoch 24 loss 0.7236083745956421
Epoch 25 loss 0.7388058304786682
Epoch 26 loss 0.7613614201545715
Epoch 27 loss 0.8228069543838501
Epoch 28 loss 0.7976071834564209
Epoch 29 loss 0.8271567225456238
Epoch 30 loss 0.8639720678329468
Epoch 31 loss 0.9028182029724121
Epoch 32 loss 0.8993051052093506
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.652, 'Log Loss - std': 0.014358272876638049} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 'Ideal' 'E' 'SI2' -0.17623676016550302]
 [-1.2007693433003284 'Good' 'E' 'VS1' -3.3952118794129094]
 [-1.0318275851408616 'Good' 'J' 'SI2' 1.0833621995400016]
 [-1.1796516235303949 'Very Good' 'J' 'VVS2' 0.7334735996218053]
 [-1.1374161839905281 'Very Good' 'H' 'SI1' 0.10367411976905298]
 [-1.2007693433003284 'Very Good' 'H' 'VS1' -1.6457688798219283]
 [-1.0529453049107949 'Good' 'J' 'SI1' 1.5732062394254782]
 [-1.2007693433003284 'Ideal' 'J' 'VS1' 0.7334735996218053]
 [-1.2218870630702616 'Premium' 'F' 'SI1' -0.9459916799855358]
 [-1.2641225026101284 'Premium' 'E' 'SI2' -1.0859471199528112]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 5 6 2 -0.17623676016550302 -1.1001014896248056
  -1.5915444854651115 -1.5301186577850108 -1.5696115327877844]
 [-1.2007693433003284 2 6 5 -3.3952118794129094 3.3772680777522917
  -1.5023022126050385 -1.4517413942698225 -1.739235168570439]
 [-1.0318275851408616 2 1 2 1.0833621995400016 0.2431093805883235
  -1.2434996213108258 -1.2079010188892378 -1.1172818373673723]
 [-1.1796516235303949 3 1 6 0.7334735996218053 -0.20462757614938623
  -1.600468712751119 -1.5475358274550528 -1.4989350178783452]
 [-1.1374161839905281 3 3 3 0.10367411976905298 -1.1001014896248056
  -1.4844537580330235 -1.416907054929739 -1.428258502968906]
 [-1.2007693433003284 3 3 5 -1.6457688798219283 1.5863202508014527
  -1.5469233490350751 -1.4691585639398648 -1.6261527447153359]
 [-1.0529453049107949 2 1 3 1.5732062394254782 -1.1001014896248056
  -1.3238176668848918 -1.2688611127343836 -1.1455524433311481]
 [-1.2007693433003284 5 1 5 0.7334735996218053 -0.652364532887096
  -1.6093929400371263 -1.5997873364651782 -1.527205623842121]
 [-1.2218870630702616 4 5 3 -0.9459916799855358 1.5863202508014527
  -1.6540140764671631 -1.6520388454753037 -1.7109645626066634]
 [-1.2641225026101284 4 6 2 -1.0859471199528112 2.0340572075391625
  -1.7343321220412289 -1.7304161089904915 -1.7957763804979907]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 0.7584556341171265
Epoch 1 loss 0.6896101236343384
Epoch 2 loss 0.6734952926635742
Epoch 3 loss 0.6728830337524414
Epoch 4 loss 0.6512556076049805
Epoch 5 loss 0.6548015475273132
Epoch 6 loss 0.6273393630981445
Epoch 7 loss 0.629152774810791
Epoch 8 loss 0.587770402431488
Epoch 9 loss 0.5980830192565918
Epoch 10 loss 0.5848868489265442
Epoch 11 loss 0.5931820869445801
Epoch 12 loss 0.5932286381721497
Epoch 13 loss 0.5983489155769348
Epoch 14 loss 0.6070002913475037
Epoch 15 loss 0.625971257686615
Epoch 16 loss 0.6181567311286926
Epoch 17 loss 0.6271695494651794
Epoch 18 loss 0.6300433278083801
Epoch 19 loss 0.6521851420402527
Epoch 20 loss 0.6676011085510254
Epoch 21 loss 0.6847217679023743
Epoch 22 loss 0.6862680912017822
Epoch 23 loss 0.7149275541305542
Epoch 24 loss 0.7130086421966553
Epoch 25 loss 0.7873271703720093
Epoch 26 loss 0.7751979231834412
Epoch 27 loss 0.8228256106376648
Epoch 28 loss 0.7897322177886963
Epoch 29 loss 0.8797731399536133
Epoch 30 loss 0.872289776802063
Epoch 31 loss 0.8951488137245178
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.65195, 'Log Loss - std': 0.01243493063913104} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 'Ideal' 'E' 'SI2' -0.16918805719128635]
 [-1.2373782800036142 'Premium' 'E' 'SI1' -1.354043921120755]
 [-1.1951587568816937 'Good' 'E' 'VS1' -3.375268630176903]
 [-1.0685001875159332 'Premium' 'I' 'VS2' 0.4580885766537244]
 [-1.0262806643940128 'Good' 'J' 'SI2' 1.085365210498735]
 [-1.1740489953207336 'Very Good' 'I' 'VVS1' 0.3883911728931665]
 [-1.1318294721988134 'Very Good' 'H' 'SI1' 0.10960155785094007]
 [-1.2162685184426538 'Fair' 'E' 'VS2' 2.3399184781887565]
 [-1.1951587568816937 'Ideal' 'J' 'VS1' 0.7368781916959508]
 [-1.2162685184426538 'Premium' 'F' 'SI1' -0.9358594985574128]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 5 6 2 -0.16918805719128635 -1.095468028782346
  -1.5839349366235063 -1.5322976251522233 -1.56187701865597]
 [-1.2373782800036142 4 6 3 -1.354043921120755 1.5812091849357435
  -1.6374236122792667 -1.6548711768767947 -1.731354397531372]
 [-1.1951587568816937 2 6 5 -3.375268630176903 3.3656606607478032
  -1.4947871438639058 -1.4535003419007129 -1.731354397531372]
 [-1.0685001875159332 4 2 4 0.4580885766537244 0.24287057807669882
  -1.3610654547245045 -1.313416282786917 -1.2794147205303008]
 [-1.0262806643940128 2 1 2 1.085365210498735 0.24287057807669882
  -1.236258544861064 -1.2083532384515707 -1.1099373416548988]
 [-1.1740489953207336 3 2 7 0.3883911728931665 -0.2032422908763161
  -1.5839349366235063 -1.5322976251522233 -1.5053845590308361]
 [-1.1318294721988134 3 3 3 0.10960155785094007 -1.095468028782346
  -1.4769575853119854 -1.418479327122264 -1.4206458695931359]
 [-1.2162685184426538 1 6 4 2.3399184781887565 1.5812091849357435
  -1.6552531708311868 -1.7074026990444682 -1.4771383292182692]
 [-1.1951587568816937 5 1 5 0.7368781916959508 -0.649355159829331
  -1.6017644951754264 -1.602339654709121 -1.51950767393712]
 [-1.2162685184426538 4 5 3 -0.9358594985574128 1.5812091849357435
  -1.646338391555227 -1.6548711768767947 -1.7031081677188051]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}
Epoch 0 loss 0.7872899174690247
Epoch 1 loss 0.7148604393005371
Epoch 2 loss 0.7092944979667664
Epoch 3 loss 0.6722293496131897
Epoch 4 loss 0.6610399484634399
Epoch 5 loss 0.6707148551940918
Epoch 6 loss 0.6556307077407837
Epoch 7 loss 0.6150487661361694
Epoch 8 loss 0.6021360754966736
Epoch 9 loss 0.5957257151603699
Epoch 10 loss 0.5897608995437622
Epoch 11 loss 0.5882533192634583
Epoch 12 loss 0.6119678616523743
Epoch 13 loss 0.6024882793426514
Epoch 14 loss 0.6158337593078613
Epoch 15 loss 0.6227681636810303
Epoch 16 loss 0.6315701603889465
Epoch 17 loss 0.613528311252594
Epoch 18 loss 0.6293298602104187
Epoch 19 loss 0.6669244170188904
Epoch 20 loss 0.6580888032913208
Epoch 21 loss 0.6919762492179871
Epoch 22 loss 0.6872883439064026
Epoch 23 loss 0.7118557691574097
Epoch 24 loss 0.7744365334510803
Epoch 25 loss 0.7797014117240906
Epoch 26 loss 0.7855424880981445
Epoch 27 loss 0.8054143786430359
Epoch 28 loss 0.8394120931625366
Epoch 29 loss 0.8378673791885376
Epoch 30 loss 0.8829271197319031
Epoch 31 loss 0.9023887515068054
Epoch 32 loss 0.9093164801597595
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6529200000000001, 'Log Loss - std': 0.011290066430274004} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 0.6529200000000001 and parameters: {'dim': 128, 'depth': 6, 'heads': 4, 'dropout': 0.2}. Best is trial 0 with value: 0.68326.
Best parameters After Trials: {'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Parameters saved to YAML file!!!
In get_device
Using dim 128 and batch size 64
Fold 1
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 'Ideal' 'E' 'SI2' -0.17767576091934348]
 [-1.236976378485391 'Premium' 'E' 'SI1' -1.3637394355688461]
 [-1.069224675734413 'Premium' 'I' 'VS2' 0.45024030213039123]
 [-1.1740694899537742 'Very Good' 'J' 'VVS2' 0.7293141079302727]
 [-1.1740694899537742 'Very Good' 'I' 'VVS1' 0.3804718506804196]
 [-1.1321315642660297 'Very Good' 'H' 'SI1' 0.10139804488053805]
 [-1.2160074156415188 'Fair' 'E' 'VS2' 2.3339884912795954]
 [-1.1950384527976465 'Very Good' 'H' 'VS1' -1.6428132413687278]
 [-1.0482557128905408 'Good' 'J' 'SI1' 1.5665355253299222]
 [-1.1950384527976465 'Ideal' 'J' 'VS1' 0.7293141079302727]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1950384527976465 5 6 2 -0.17767576091934348 -1.0997679290240274
  -1.5847483029459433 -1.5624470539339794 -1.5635817068251905]
 [-1.236976378485391 4 6 3 -1.3637394355688461 1.5843835902987453
  -1.6380368496537203 -1.6869504169773575 -1.7324417222907198]
 [-1.069224675734413 4 2 4 0.45024030213039123 0.24230783063735892
  -1.3627126916635395 -1.3401196199279468 -1.2821483477159754]
 [-1.1740694899537742 3 1 6 0.7293141079302727 -0.20505075591643654
  -1.5936297273972397 -1.580233248654462 -1.493223367047887]
 [-1.1740694899537742 3 2 7 0.3804718506804196 -0.20505075591643654
  -1.5847483029459433 -1.5624470539339794 -1.5072950350033474]
 [-1.1321315642660297 3 3 3 0.10139804488053805 -1.0997679290240274
  -1.4781712095303894 -1.4468367882508424 -1.4228650272705832]
 [-1.2160074156415188 1 6 4 2.3339884912795954 1.5843835902987453
  -1.6557996985563126 -1.7403090011388052 -1.4791516990924258]
 [-1.1950384527976465 3 3 5 -1.6428132413687278 1.5843835902987453
  -1.5403411806894627 -1.5001953724122905 -1.6198683786470336]
 [-1.0482557128905408 2 1 3 1.5665355253299222 -1.0997679290240274
  -1.318305569407059 -1.2956541331267404 -1.1414316681613677]
 [-1.1950384527976465 5 1 5 0.7293141079302727 -0.652409342470232
  -1.6025111518485355 -1.6335918328159098 -1.5213667029588085]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7993372678756714
Epoch 1 loss 0.7152008414268494
Epoch 2 loss 0.6865347623825073
Epoch 3 loss 0.6922330856323242
Epoch 4 loss 0.6936758160591125
Epoch 5 loss 0.7290731072425842
Epoch 6 loss 0.6742970943450928
Epoch 7 loss 0.6909441947937012
Epoch 8 loss 0.6509535908699036
Epoch 9 loss 0.6566548347473145
Epoch 10 loss 0.6616606116294861
Epoch 11 loss 0.6824683547019958
Epoch 12 loss 0.6394851207733154
Epoch 13 loss 0.6441259384155273
Epoch 14 loss 0.6404356956481934
Epoch 15 loss 0.6041991114616394
Epoch 16 loss 0.5889853835105896
Epoch 17 loss 0.5764742493629456
Epoch 18 loss 0.5780824422836304
Epoch 19 loss 0.5709760189056396
Epoch 20 loss 0.5699171423912048
Epoch 21 loss 0.5722400546073914
Epoch 22 loss 0.570545494556427
Epoch 23 loss 0.589597225189209
Epoch 24 loss 0.5954039096832275
Epoch 25 loss 0.5810980200767517
Epoch 26 loss 0.5703163743019104
Epoch 27 loss 0.5961262583732605
Epoch 28 loss 0.5822609663009644
Epoch 29 loss 0.6080594062805176
Epoch 30 loss 0.5951585173606873
Epoch 31 loss 0.6144320964813232
Epoch 32 loss 0.6037766933441162
Epoch 33 loss 0.6006787419319153
Epoch 34 loss 0.607307493686676
Epoch 35 loss 0.6110698580741882
Epoch 36 loss 0.6179692149162292
Epoch 37 loss 0.6300933361053467
Epoch 38 loss 0.6395982503890991
Epoch 39 loss 0.6390029788017273
Epoch 40 loss 0.646940290927887
Epoch 41 loss 0.643578290939331
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Diamonds/logging/loss_0.txt
File name : output/SAINT/Diamonds/logging/loss_0.txt . The file was saved
Log file exists at: output/SAINT/Diamonds/logging/val_loss_0.txt
File name : output/SAINT/Diamonds/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6734, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 'Premium' 'E' 'SI1' -1.3617245236890496]
 [-1.1991826034964022 'Good' 'E' 'VS1' -3.3871902928108906]
 [-1.0725306248271413 'Premium' 'I' 'VS2' 0.4542103037994991]
 [-1.0303132986040544 'Good' 'J' 'SI2' 1.08280312869938]
 [-1.1780739403848586 'Very Good' 'J' 'VVS2' 0.73358489264389]
 [-1.1780739403848586 'Very Good' 'I' 'VVS1' 0.38436665658840014]
 [-1.1358566141617716 'Very Good' 'H' 'SI1' 0.10499206774400914]
 [-1.2202912666079455 'Fair' 'E' 'VS2' 2.339988778499142]
 [-1.1991826034964022 'Very Good' 'H' 'VS1' -1.6410991125334407]
 [-1.051421961715598 'Good' 'J' 'SI1' 1.571708659177068]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.241399929719489 4 6 3 -1.3617245236890496 1.5949518123380095
  -1.6437879201752599 -1.6514473425787888 -1.7685832176092422]
 [-1.1991826034964022 2 6 5 -3.3871902928108906 3.3941876961159525
  -1.5010019420077028 -1.4510608771835314 -1.7685832176092422]
 [-1.0725306248271413 4 2 4 0.4542103037994991 0.24552489950455236
  -1.3671400874756174 -1.3116615969085696 -1.307955447116008]
 [-1.0303132986040544 2 1 2 1.08280312869938 0.24552489950455236
  -1.242202356579005 -1.2071121367023494 -1.135220033181045]
 [-1.1780739403848586 3 1 6 0.73358489264389 -0.20428407143993338
  -1.5991673019978982 -1.5468978823725676 -1.5238747145347116]
 [-1.1780739403848586 3 2 7 0.38436665658840014 -0.20428407143993338
  -1.5902431783624258 -1.5294729723381975 -1.5382693323626249]
 [-1.1358566141617716 3 3 3 0.10499206774400914 -1.1039020133289048
  -1.4831536947367576 -1.416211057114791 -1.4519016253951438]
 [-1.2202912666079455 1 6 4 2.339988778499142 1.5949518123380095
  -1.6616361674462046 -1.7037220726818993 -1.5094800967067976]
 [-1.1991826034964022 3 3 5 -1.6410991125334407 1.5949518123380095
  -1.5456225601850642 -1.4684857872179018 -1.6534262749859334]
 [-1.051421961715598 2 1 3 1.571708659177068 -1.1039020133289048
  -1.3225194692982558 -1.2680993218226444 -1.164009268836872]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.8381292819976807
Epoch 1 loss 0.7502981424331665
Epoch 2 loss 0.6973736882209778
Epoch 3 loss 0.715375542640686
Epoch 4 loss 0.7032161355018616
Epoch 5 loss 0.6838952302932739
Epoch 6 loss 0.6834604144096375
Epoch 7 loss 0.6588005423545837
Epoch 8 loss 0.6610948443412781
Epoch 9 loss 0.6724182367324829
Epoch 10 loss 0.6407628059387207
Epoch 11 loss 0.6436814665794373
Epoch 12 loss 0.640651524066925
Epoch 13 loss 0.6042217016220093
Epoch 14 loss 0.5917271971702576
Epoch 15 loss 0.604595422744751
Epoch 16 loss 0.591842532157898
Epoch 17 loss 0.6023423075675964
Epoch 18 loss 0.5938947796821594
Epoch 19 loss 0.5829756259918213
Epoch 20 loss 0.6010554432868958
Epoch 21 loss 0.5840614438056946
Epoch 22 loss 0.5738710165023804
Epoch 23 loss 0.5884405970573425
Epoch 24 loss 0.5970807075500488
Epoch 25 loss 0.5924764275550842
Epoch 26 loss 0.6035284996032715
Epoch 27 loss 0.6126646399497986
Epoch 28 loss 0.5898373126983643
Epoch 29 loss 0.6009395122528076
Epoch 30 loss 0.6057079434394836
Epoch 31 loss 0.5995709896087646
Epoch 32 loss 0.600273072719574
Epoch 33 loss 0.6081498265266418
Epoch 34 loss 0.6280802488327026
Epoch 35 loss 0.6302101612091064
Epoch 36 loss 0.6229060888290405
Epoch 37 loss 0.6421725153923035
Epoch 38 loss 0.6544739007949829
Epoch 39 loss 0.6618014574050903
Epoch 40 loss 0.6552091240882874
Epoch 41 loss 0.6686835289001465
Epoch 42 loss 0.6704649925231934
Epoch 43 loss 0.6929740905761719
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Diamonds/logging/loss_1.txt
File name : output/SAINT/Diamonds/logging/loss_1.txt . The file was saved
Log file exists at: output/SAINT/Diamonds/logging/val_loss_1.txt
File name : output/SAINT/Diamonds/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.68885, 'Log Loss - std': 0.01545000000000002} 
 

Fold 3
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 'Ideal' 'E' 'SI2' -0.17299106375200937]
 [-1.2431374791872112 'Premium' 'E' 'SI1' -1.358384470113667]
 [-1.2007760315615899 'Good' 'E' 'VS1' -3.380526163318843]
 [-1.0736916886847254 'Premium' 'I' 'VS2' 0.45457015138063084]
 [-1.031330241059104 'Good' 'J' 'SI2' 1.082131366513271]
 [-1.179595307748779 'Very Good' 'J' 'VVS2' 0.733486246995137]
 [-1.179595307748779 'Very Good' 'I' 'VVS1' 0.38484112747700305]
 [-1.2219567553744004 'Fair' 'E' 'VS2' 2.3372537967785516]
 [-1.2007760315615899 'Very Good' 'H' 'VS1' -1.6373005657281732]
 [-1.0525109648719149 'Good' 'J' 'SI1' 1.5702345338386605]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007760315615899 5 6 2 -0.17299106375200937 -1.0991811176282293
  -1.5887751661204468 -1.52741996295235 -1.5654913782973074]
 [-1.2431374791872112 4 6 3 -1.358384470113667 1.580885495554982
  -1.642349354189251 -1.6494018572095064 -1.7351080246385664]
 [-1.2007760315615899 2 6 5 -3.380526163318843 3.367596571010456
  -1.4994848526724398 -1.449003030929892 -1.7351080246385664]
 [-1.0736916886847254 4 2 4 0.45457015138063084 0.2408521889633763
  -1.3655493825004286 -1.309595151778856 -1.282796967728543]
 [-1.031330241059104 2 1 2 1.082131366513271 0.2408521889633763
  -1.2405429436732185 -1.2050392424155796 -1.113180321387284]
 [-1.179595307748779 3 1 6 0.733486246995137 -0.20582557990049227
  -1.5977041974652477 -1.5448459478462293 -1.4948177756551164]
 [-1.179595307748779 3 2 7 0.38484112747700305 -0.20582557990049227
  -1.5887751661204468 -1.52741996295235 -1.5089524961835543]
 [-1.2219567553744004 1 6 4 2.3372537967785516 1.580885495554982
  -1.6602074168788525 -1.701679811891145 -1.4806830551266779]
 [-1.2007760315615899 3 3 5 -1.6373005657281732 1.580885495554982
  -1.5441300093964432 -1.4664290158237718 -1.6220302604110604]
 [-1.0525109648719149 2 1 3 1.5702345338386605 -1.0991811176282293
  -1.320904225776425 -1.2660301895441572 -1.1414497624441604]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7815374135971069
Epoch 1 loss 0.7071403861045837
Epoch 2 loss 0.7257258892059326
Epoch 3 loss 0.7180836796760559
Epoch 4 loss 0.7170005440711975
Epoch 5 loss 0.6781206727027893
Epoch 6 loss 0.6714847683906555
Epoch 7 loss 0.6946673393249512
Epoch 8 loss 0.6703476309776306
Epoch 9 loss 0.6641715168952942
Epoch 10 loss 0.6578565239906311
Epoch 11 loss 0.6577868461608887
Epoch 12 loss 0.6684049963951111
Epoch 13 loss 0.6486928462982178
Epoch 14 loss 0.6264524459838867
Epoch 15 loss 0.6265352964401245
Epoch 16 loss 0.6181837320327759
Epoch 17 loss 0.6285979151725769
Epoch 18 loss 0.612698495388031
Epoch 19 loss 0.6112971901893616
Epoch 20 loss 0.6014761924743652
Epoch 21 loss 0.6117779016494751
Epoch 22 loss 0.6245987415313721
Epoch 23 loss 0.6066245436668396
Epoch 24 loss 0.6143595576286316
Epoch 25 loss 0.6373661160469055
Epoch 26 loss 0.6159226298332214
Epoch 27 loss 0.6409590840339661
Epoch 28 loss 0.6424954533576965
Epoch 29 loss 0.6348462700843811
Epoch 30 loss 0.6280405521392822
Epoch 31 loss 0.6466692686080933
Epoch 32 loss 0.6537693738937378
Epoch 33 loss 0.658787190914154
Epoch 34 loss 0.6551098227500916
Epoch 35 loss 0.67493736743927
Epoch 36 loss 0.6897667050361633
Epoch 37 loss 0.681052565574646
Epoch 38 loss 0.6991564035415649
Epoch 39 loss 0.6968632340431213
Epoch 40 loss 0.7177141904830933
Epoch 41 loss 0.7194942831993103
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Diamonds/logging/loss_2.txt
File name : output/SAINT/Diamonds/logging/loss_2.txt . The file was saved
Log file exists at: output/SAINT/Diamonds/logging/val_loss_2.txt
File name : output/SAINT/Diamonds/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6952333333333334, 'Log Loss - std': 0.015512217407220955} 
 

Fold 4
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 'Ideal' 'E' 'SI2' -0.17623676016550302]
 [-1.2007693433003284 'Good' 'E' 'VS1' -3.3952118794129094]
 [-1.0318275851408616 'Good' 'J' 'SI2' 1.0833621995400016]
 [-1.1796516235303949 'Very Good' 'J' 'VVS2' 0.7334735996218053]
 [-1.1374161839905281 'Very Good' 'H' 'SI1' 0.10367411976905298]
 [-1.2007693433003284 'Very Good' 'H' 'VS1' -1.6457688798219283]
 [-1.0529453049107949 'Good' 'J' 'SI1' 1.5732062394254782]
 [-1.2007693433003284 'Ideal' 'J' 'VS1' 0.7334735996218053]
 [-1.2218870630702616 'Premium' 'F' 'SI1' -0.9459916799855358]
 [-1.2641225026101284 'Premium' 'E' 'SI2' -1.0859471199528112]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.2007693433003284 5 6 2 -0.17623676016550302 -1.1001014896248056
  -1.5915444854651115 -1.5301186577850108 -1.5696115327877844]
 [-1.2007693433003284 2 6 5 -3.3952118794129094 3.3772680777522917
  -1.5023022126050385 -1.4517413942698225 -1.739235168570439]
 [-1.0318275851408616 2 1 2 1.0833621995400016 0.2431093805883235
  -1.2434996213108258 -1.2079010188892378 -1.1172818373673723]
 [-1.1796516235303949 3 1 6 0.7334735996218053 -0.20462757614938623
  -1.600468712751119 -1.5475358274550528 -1.4989350178783452]
 [-1.1374161839905281 3 3 3 0.10367411976905298 -1.1001014896248056
  -1.4844537580330235 -1.416907054929739 -1.428258502968906]
 [-1.2007693433003284 3 3 5 -1.6457688798219283 1.5863202508014527
  -1.5469233490350751 -1.4691585639398648 -1.6261527447153359]
 [-1.0529453049107949 2 1 3 1.5732062394254782 -1.1001014896248056
  -1.3238176668848918 -1.2688611127343836 -1.1455524433311481]
 [-1.2007693433003284 5 1 5 0.7334735996218053 -0.652364532887096
  -1.6093929400371263 -1.5997873364651782 -1.527205623842121]
 [-1.2218870630702616 4 5 3 -0.9459916799855358 1.5863202508014527
  -1.6540140764671631 -1.6520388454753037 -1.7109645626066634]
 [-1.2641225026101284 4 6 2 -1.0859471199528112 2.0340572075391625
  -1.7343321220412289 -1.7304161089904915 -1.7957763804979907]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 1.008728265762329
Epoch 1 loss 0.7321671843528748
Epoch 2 loss 0.7471149563789368
Epoch 3 loss 0.7476986646652222
Epoch 4 loss 0.6903859376907349
Epoch 5 loss 0.6898906230926514
Epoch 6 loss 0.656843364238739
Epoch 7 loss 0.6679410934448242
Epoch 8 loss 0.6605225205421448
Epoch 9 loss 0.6477685570716858
Epoch 10 loss 0.6470169425010681
Epoch 11 loss 0.6585016846656799
Epoch 12 loss 0.6801255941390991
Epoch 13 loss 0.6281654238700867
Epoch 14 loss 0.5971166491508484
Epoch 15 loss 0.5805220603942871
Epoch 16 loss 0.6016941666603088
Epoch 17 loss 0.6174242496490479
Epoch 18 loss 0.5814620852470398
Epoch 19 loss 0.5677495002746582
Epoch 20 loss 0.5790413618087769
Epoch 21 loss 0.5668433904647827
Epoch 22 loss 0.5886085033416748
Epoch 23 loss 0.5839473605155945
Epoch 24 loss 0.5692576766014099
Epoch 25 loss 0.5888863801956177
Epoch 26 loss 0.588075578212738
Epoch 27 loss 0.57833331823349
Epoch 28 loss 0.5954604148864746
Epoch 29 loss 0.6094096899032593
Epoch 30 loss 0.6137548089027405
Epoch 31 loss 0.6131758689880371
Epoch 32 loss 0.6170092225074768
Epoch 33 loss 0.6228429079055786
Epoch 34 loss 0.6245189309120178
Epoch 35 loss 0.6280904412269592
Epoch 36 loss 0.6498202085494995
Epoch 37 loss 0.6382327675819397
Epoch 38 loss 0.6385780572891235
Epoch 39 loss 0.6495956182479858
Epoch 40 loss 0.672295868396759
Epoch 41 loss 0.6662386059761047
Epoch 42 loss 0.6572609543800354
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Diamonds/logging/loss_3.txt
File name : output/SAINT/Diamonds/logging/loss_3.txt . The file was saved
Log file exists at: output/SAINT/Diamonds/logging/val_loss_3.txt
File name : output/SAINT/Diamonds/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.687825, 'Log Loss - std': 0.0185774560960321} 
 

Fold 5
num_features : 9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :9
num_classes : 1
cat_idx : [0]
nominal_idx : None
ordinal_idx : [1, 2, 3]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (43152, 9)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 4, 5, 6, 7, 8]
Cat Dims V1 : [6, 8, 9]
Cat Idx V1 : [1, 2, 3] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 'Ideal' 'E' 'SI2' -0.16918805719128635]
 [-1.2373782800036142 'Premium' 'E' 'SI1' -1.354043921120755]
 [-1.1951587568816937 'Good' 'E' 'VS1' -3.375268630176903]
 [-1.0685001875159332 'Premium' 'I' 'VS2' 0.4580885766537244]
 [-1.0262806643940128 'Good' 'J' 'SI2' 1.085365210498735]
 [-1.1740489953207336 'Very Good' 'I' 'VVS1' 0.3883911728931665]
 [-1.1318294721988134 'Very Good' 'H' 'SI1' 0.10960155785094007]
 [-1.2162685184426538 'Fair' 'E' 'VS2' 2.3399184781887565]
 [-1.1951587568816937 'Ideal' 'J' 'VS1' 0.7368781916959508]
 [-1.2162685184426538 'Premium' 'F' 'SI1' -0.9358594985574128]] 
 
 
Val : (43152, 9) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 4, 5, 6, 7, 8] 


OHE Idx : None


Ordinal Idx V2: [1, 2, 3]


Cat Dims V2 : [6, 8, 9]
Cat Idx V2 : [1, 2, 3] 
 

Train: [[-1.1951587568816937 5 6 2 -0.16918805719128635 -1.095468028782346
  -1.5839349366235063 -1.5322976251522233 -1.56187701865597]
 [-1.2373782800036142 4 6 3 -1.354043921120755 1.5812091849357435
  -1.6374236122792667 -1.6548711768767947 -1.731354397531372]
 [-1.1951587568816937 2 6 5 -3.375268630176903 3.3656606607478032
  -1.4947871438639058 -1.4535003419007129 -1.731354397531372]
 [-1.0685001875159332 4 2 4 0.4580885766537244 0.24287057807669882
  -1.3610654547245045 -1.313416282786917 -1.2794147205303008]
 [-1.0262806643940128 2 1 2 1.085365210498735 0.24287057807669882
  -1.236258544861064 -1.2083532384515707 -1.1099373416548988]
 [-1.1740489953207336 3 2 7 0.3883911728931665 -0.2032422908763161
  -1.5839349366235063 -1.5322976251522233 -1.5053845590308361]
 [-1.1318294721988134 3 3 3 0.10960155785094007 -1.095468028782346
  -1.4769575853119854 -1.418479327122264 -1.4206458695931359]
 [-1.2162685184426538 1 6 4 2.3399184781887565 1.5812091849357435
  -1.6552531708311868 -1.7074026990444682 -1.4771383292182692]
 [-1.1951587568816937 5 1 5 0.7368781916959508 -0.649355159829331
  -1.6017644951754264 -1.602339654709121 -1.51950767393712]
 [-1.2162685184426538 4 5 3 -0.9358594985574128 1.5812091849357435
  -1.646338391555227 -1.6548711768767947 -1.7031081677188051]] 
 
 
Val : (43152, 9) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 14
Unique values in y_train: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
Unique values in y_test: (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,
       13.]), 14)
No need to shift labels.
VERIFY SHIFT
Train after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Test after shift : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13], Length : 14
Number of Classes After Bin Verifier: 14
In get_device
Using dim 128 and batch size 64
{'dim': 128, 'depth': 6, 'heads': 2, 'dropout': 0.6}
Epoch 0 loss 0.7501576542854309
Epoch 1 loss 0.7816263437271118
Epoch 2 loss 0.7427436709403992
Epoch 3 loss 0.6903173923492432
Epoch 4 loss 0.6897903084754944
Epoch 5 loss 0.6699416041374207
Epoch 6 loss 0.668526828289032
Epoch 7 loss 0.676223874092102
Epoch 8 loss 0.6696264743804932
Epoch 9 loss 0.6632115840911865
Epoch 10 loss 0.6579298973083496
Epoch 11 loss 0.6332383751869202
Epoch 12 loss 0.6194936633110046
Epoch 13 loss 0.622550368309021
Epoch 14 loss 0.5995298027992249
Epoch 15 loss 0.6166383028030396
Epoch 16 loss 0.5922216176986694
Epoch 17 loss 0.5832942724227905
Epoch 18 loss 0.6222648024559021
Epoch 19 loss 0.5881685018539429
Epoch 20 loss 0.5763400197029114
Epoch 21 loss 0.6093400716781616
Epoch 22 loss 0.5892350077629089
Epoch 23 loss 0.5937247276306152
Epoch 24 loss 0.5892316102981567
Epoch 25 loss 0.5985383987426758
Epoch 26 loss 0.6141394972801208
Epoch 27 loss 0.6238662600517273
Epoch 28 loss 0.5996648073196411
Epoch 29 loss 0.6207166314125061
Epoch 30 loss 0.6361147165298462
Epoch 31 loss 0.6259410381317139
Epoch 32 loss 0.6214756965637207
Epoch 33 loss 0.6395940780639648
Epoch 34 loss 0.6246248483657837
Epoch 35 loss 0.6475988030433655
Epoch 36 loss 0.6384574770927429
Epoch 37 loss 0.663158655166626
Epoch 38 loss 0.6739281415939331
Epoch 39 loss 0.6489059329032898
Epoch 40 loss 0.6872907280921936
Epoch 41 loss 0.7045857906341553
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/Diamonds/logging/loss_4.txt
File name : output/SAINT/Diamonds/logging/loss_4.txt . The file was saved
Log file exists at: output/SAINT/Diamonds/logging/val_loss_4.txt
File name : output/SAINT/Diamonds/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 14
Class label len :14
Class labels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
Unique y_true : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] 

Prediction shape : (10788,)
Probabilities shape : (10788, 14) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.6968, 'Log Loss - std': 0.02446017170830983} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 0.6968, 'Log Loss - std': 0.02446017170830983}
Train time: 4090.0659230562
Inference time: 1.1823778922014754
Finished cross validation
Loss path :output/SAINT/Diamonds/logging/
Plots saved successfully!


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/house_prices_nominal.yml 



----------------------------------------------------------------------------
Namespace(batch_size=64, bin_alt=None, cat_dims=[2], cat_idx=[0], config='config/house_prices_nominal.yml', data_parallel=False, dataset='House_Prices_Nominal', direction='maximize', dropna_idx=[0], early_stopping_rounds=20, epochs=100, frequency_reg=False, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=[6, 25, 30, 31, 32, 33, 35, 42, 57, 58, 60, 63, 64, 72, 73, 74], miss_num_idx=[3, 26, 59], model_name='SAINT', n_trials=2, nominal_idx=[2, 7, 12], num_bins=10, num_classes=1, num_features=80, num_idx=None, num_splits=5, objective='probabilistic_regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 39, 40, 41, 42, 53, 55, 57, 58, 60, 63, 64, 65, 72, 73, 74, 78, 79], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=128, y_distribution='normal')
Start hyperparameter optimization
Loading dataset House_Prices_Nominal...
Dataset loaded! 

(1460, 79)
A new study created in RDB with name: SAINT_House_Prices_Nominal
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08549072883692027 -1.6038865594520038 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -0.4812300464036975 -0.6383658556335169]
 [2 0 4 ... -0.08549072883692027 -1.6038865594520038 -1.389990169524665]
 ...
 [2 0 4 ... -0.08549072883692027 -0.8554488840864662 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -1.9781053971347726 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 0.2672076289618401 -1.389990169524665]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.975378394126892
Epoch 1 loss 1.789343237876892
Epoch 2 loss 1.6793222427368164
Epoch 3 loss 1.5248045921325684
Epoch 4 loss 1.4364349842071533
Epoch 5 loss 1.3203023672103882
Epoch 6 loss 1.1312326192855835
Epoch 7 loss 1.197371006011963
Epoch 8 loss 1.1632107496261597
Epoch 9 loss 1.1753218173980713
Epoch 10 loss 1.078511357307434
Epoch 11 loss 1.012967586517334
Epoch 12 loss 0.9977645874023438
Epoch 13 loss 1.0909727811813354
Epoch 14 loss 0.973627507686615
Epoch 15 loss 1.024024486541748
Epoch 16 loss 1.0312292575836182
Epoch 17 loss 1.0715864896774292
Epoch 18 loss 0.9360479116439819
Epoch 19 loss 1.0642755031585693
Epoch 20 loss 0.9676487445831299
Epoch 21 loss 1.0815680027008057
Epoch 22 loss 1.084804892539978
Epoch 23 loss 1.0494484901428223
Epoch 24 loss 0.9388357400894165
Epoch 25 loss 0.9692746996879578
Epoch 26 loss 0.9602221250534058
Epoch 27 loss 1.060210943222046
Epoch 28 loss 1.0537521839141846
Epoch 29 loss 0.9606412649154663
Epoch 30 loss 1.0114312171936035
Epoch 31 loss 1.016039490699768
Epoch 32 loss 1.0089547634124756
Epoch 33 loss 1.1057116985321045
Epoch 34 loss 1.0305285453796387
Epoch 35 loss 1.0909994840621948
Epoch 36 loss 0.9980175495147705
Epoch 37 loss 1.103412389755249
Epoch 38 loss 1.0934470891952515
Epoch 39 loss 1.095214605331421
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9719, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08520364902762013 -1.5988030922284444 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 -0.4931772711965776 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 ...
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 0.6124485498352892 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.24390660949133355 -0.5890737346279431]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9945847988128662
Epoch 1 loss 1.8321651220321655
Epoch 2 loss 1.6679332256317139
Epoch 3 loss 1.5431759357452393
Epoch 4 loss 1.4053444862365723
Epoch 5 loss 1.3295818567276
Epoch 6 loss 1.2197115421295166
Epoch 7 loss 1.230149745941162
Epoch 8 loss 1.1412794589996338
Epoch 9 loss 1.0998939275741577
Epoch 10 loss 1.0696452856063843
Epoch 11 loss 1.0292956829071045
Epoch 12 loss 1.0616981983184814
Epoch 13 loss 1.0056346654891968
Epoch 14 loss 0.9786922931671143
Epoch 15 loss 1.0394752025604248
Epoch 16 loss 1.1629421710968018
Epoch 17 loss 1.1369826793670654
Epoch 18 loss 0.9881234169006348
Epoch 19 loss 1.139656901359558
Epoch 20 loss 1.074756383895874
Epoch 21 loss 1.0796349048614502
Epoch 22 loss 1.0050535202026367
Epoch 23 loss 1.0173594951629639
Epoch 24 loss 1.0283775329589844
Epoch 25 loss 1.0146039724349976
Epoch 26 loss 1.1490232944488525
Epoch 27 loss 1.0722298622131348
Epoch 28 loss 0.9928674101829529
Epoch 29 loss 1.1382710933685303
Epoch 30 loss 1.1128121614456177
Epoch 31 loss 1.0223535299301147
Epoch 32 loss 1.0839093923568726
Epoch 33 loss 1.2131538391113281
Epoch 34 loss 1.132902979850769
Epoch 35 loss 1.0815284252166748
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 1.0042499999999999, 'Log Loss - std': 0.03234999999999999} 
 

Fold 3
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -0.48114920966458397 -0.6162456233646283]
 [2 0 4 ... -0.0941079206995686 0.9938698897795997 0.13744535892851478]
 ...
 [2 0 4 ... -0.0941079206995686 -0.8499039845256299 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.9561683091087676 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.010591506958008
Epoch 1 loss 1.9113452434539795
Epoch 2 loss 1.7579271793365479
Epoch 3 loss 1.633392095565796
Epoch 4 loss 1.50022292137146
Epoch 5 loss 1.3899401426315308
Epoch 6 loss 1.3010549545288086
Epoch 7 loss 1.25532865524292
Epoch 8 loss 1.1825380325317383
Epoch 9 loss 1.1033742427825928
Epoch 10 loss 1.0605424642562866
Epoch 11 loss 1.0056405067443848
Epoch 12 loss 1.0043619871139526
Epoch 13 loss 0.9851752519607544
Epoch 14 loss 1.0555356740951538
Epoch 15 loss 0.9472591280937195
Epoch 16 loss 1.0442146062850952
Epoch 17 loss 0.9163033366203308
Epoch 18 loss 0.9618498682975769
Epoch 19 loss 1.0513014793395996
Epoch 20 loss 0.9725971221923828
Epoch 21 loss 0.9553130865097046
Epoch 22 loss 0.9834958910942078
Epoch 23 loss 0.9559726119041443
Epoch 24 loss 1.0288176536560059
Epoch 25 loss 1.1141834259033203
Epoch 26 loss 0.9783906936645508
Epoch 27 loss 0.9588069915771484
Epoch 28 loss 0.9855839014053345
Epoch 29 loss 0.9663339853286743
Epoch 30 loss 0.9827537536621094
Epoch 31 loss 1.061143398284912
Epoch 32 loss 1.1184996366500854
Epoch 33 loss 1.1353180408477783
Epoch 34 loss 1.0674970149993896
Epoch 35 loss 0.9842504262924194
Epoch 36 loss 1.037600040435791
Epoch 37 loss 1.0809099674224854
Epoch 38 loss 1.1675539016723633
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9903333333333332, 'Log Loss - std': 0.03293977669761724} 
 

Fold 4
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -0.49206674869507705 -0.6244852981715446]
 [2 0 4 ... -0.08629838735429034 0.9882525364970667 0.12515378534790741]
 ...
 [2 0 4 ... 0.5549707577802916 1.7284121790931386 0.8747928688673595]
 [2 0 4 ... -0.08629838735429034 -0.862146569993113 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9719493389129639
Epoch 1 loss 1.7921626567840576
Epoch 2 loss 1.6203516721725464
Epoch 3 loss 1.4788602590560913
Epoch 4 loss 1.3910826444625854
Epoch 5 loss 1.2895556688308716
Epoch 6 loss 1.2096776962280273
Epoch 7 loss 1.146640658378601
Epoch 8 loss 1.1082733869552612
Epoch 9 loss 1.158803939819336
Epoch 10 loss 1.03817880153656
Epoch 11 loss 0.9799565076828003
Epoch 12 loss 0.9610989093780518
Epoch 13 loss 0.8877501487731934
Epoch 14 loss 0.9356860518455505
Epoch 15 loss 0.8853898048400879
Epoch 16 loss 0.8701719641685486
Epoch 17 loss 1.035771369934082
Epoch 18 loss 0.8777758479118347
Epoch 19 loss 0.8843040466308594
Epoch 20 loss 1.0543797016143799
Epoch 21 loss 1.0155892372131348
Epoch 22 loss 1.154248595237732
Epoch 23 loss 1.1052521467208862
Epoch 24 loss 0.9441698789596558
Epoch 25 loss 0.8901082277297974
Epoch 26 loss 1.0565129518508911
Epoch 27 loss 0.9322978258132935
Epoch 28 loss 0.9593191146850586
Epoch 29 loss 1.051390528678894
Epoch 30 loss 1.011492133140564
Epoch 31 loss 1.076472282409668
Epoch 32 loss 1.0081379413604736
Epoch 33 loss 1.0936596393585205
Epoch 34 loss 1.0967928171157837
Epoch 35 loss 1.0739290714263916
Epoch 36 loss 0.9899412989616394
Epoch 37 loss 1.1043180227279663
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9708749999999999, 'Log Loss - std': 0.04415486241627302} 
 

Fold 5
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 109) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 2.0820453273934776 0.148179267290661]
 ...
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 0.148179267290661]
 [2 0 4 ... -0.139514558791527 0.23919223373207887 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]] 
 
 
Val : (1168, 109) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9628591537475586
Epoch 1 loss 1.7836030721664429
Epoch 2 loss 1.6265456676483154
Epoch 3 loss 1.5070856809616089
Epoch 4 loss 1.3746827840805054
Epoch 5 loss 1.2869064807891846
Epoch 6 loss 1.243072748184204
Epoch 7 loss 1.1581237316131592
Epoch 8 loss 1.1349655389785767
Epoch 9 loss 1.1318844556808472
Epoch 10 loss 1.1253905296325684
Epoch 11 loss 1.0399550199508667
Epoch 12 loss 1.062606692314148
Epoch 13 loss 1.0279583930969238
Epoch 14 loss 0.9607684016227722
Epoch 15 loss 0.9394990801811218
Epoch 16 loss 0.906563937664032
Epoch 17 loss 1.1500015258789062
Epoch 18 loss 1.056169033050537
Epoch 19 loss 1.017363429069519
Epoch 20 loss 0.9642877578735352
Epoch 21 loss 1.0218253135681152
Epoch 22 loss 1.0152111053466797
Epoch 23 loss 1.0027875900268555
Epoch 24 loss 1.2185381650924683
Epoch 25 loss 1.067618727684021
Epoch 26 loss 0.990430474281311
Epoch 27 loss 1.0663588047027588
Epoch 28 loss 0.9998699426651001
Epoch 29 loss 0.9276067018508911
Epoch 30 loss 1.050551414489746
Epoch 31 loss 1.1263041496276855
Epoch 32 loss 0.9680368900299072
Epoch 33 loss 1.032067060470581
Epoch 34 loss 1.080804705619812
Epoch 35 loss 1.109105110168457
Epoch 36 loss 1.071567416191101
Epoch 37 loss 1.1651328802108765
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9680199999999999, 'Log Loss - std': 0.0399039546912333} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 0 finished with value: 0.9680199999999999 and parameters: {'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}. Best is trial 0 with value: 0.9680199999999999.
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08549072883692027 -1.6038865594520038 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -0.4812300464036975 -0.6383658556335169]
 [2 0 4 ... -0.08549072883692027 -1.6038865594520038 -1.389990169524665]
 ...
 [2 0 4 ... -0.08549072883692027 -0.8554488840864662 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -1.9781053971347726 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 0.2672076289618401 -1.389990169524665]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}
Epoch 0 loss 2.036414384841919
Epoch 1 loss 1.9665449857711792
Epoch 2 loss 1.8302114009857178
Epoch 3 loss 1.6743278503417969
Epoch 4 loss 1.4612987041473389
Epoch 5 loss 1.2911940813064575
Epoch 6 loss 1.2479541301727295
Epoch 7 loss 1.1313940286636353
Epoch 8 loss 1.082088828086853
Epoch 9 loss 1.0686273574829102
Epoch 10 loss 1.0098352432250977
Epoch 11 loss 1.1842067241668701
Epoch 12 loss 0.9986580610275269
Epoch 13 loss 0.9696690440177917
Epoch 14 loss 0.9850956797599792
Epoch 15 loss 0.9632242918014526
Epoch 16 loss 0.8462115526199341
Epoch 17 loss 0.9853380918502808
Epoch 18 loss 0.9917232394218445
Epoch 19 loss 0.8997637629508972
Epoch 20 loss 1.0350682735443115
Epoch 21 loss 0.9665629267692566
Epoch 22 loss 0.9022932052612305
Epoch 23 loss 0.9068452715873718
Epoch 24 loss 0.9210301637649536
Epoch 25 loss 0.8627251982688904
Epoch 26 loss 0.995123565196991
Epoch 27 loss 0.8887977004051208
Epoch 28 loss 0.8937349319458008
Epoch 29 loss 0.8649184107780457
Epoch 30 loss 0.8705326318740845
Epoch 31 loss 0.8893864154815674
Epoch 32 loss 0.8727492094039917
Epoch 33 loss 0.8692737817764282
Epoch 34 loss 0.9960604906082153
Epoch 35 loss 0.9508152008056641
Epoch 36 loss 0.8989705443382263
Epoch 37 loss 0.9294654726982117
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9541, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08520364902762013 -1.5988030922284444 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 -0.4931772711965776 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 ...
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 0.6124485498352892 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.24390660949133355 -0.5890737346279431]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}
Epoch 0 loss 2.052997589111328
Epoch 1 loss 1.9927914142608643
Epoch 2 loss 1.8601818084716797
Epoch 3 loss 1.6560090780258179
Epoch 4 loss 1.43513822555542
Epoch 5 loss 1.2942904233932495
Epoch 6 loss 1.1805075407028198
Epoch 7 loss 1.1304326057434082
Epoch 8 loss 1.0553584098815918
Epoch 9 loss 1.0442454814910889
Epoch 10 loss 1.0277599096298218
Epoch 11 loss 1.0573793649673462
Epoch 12 loss 0.9773086309432983
Epoch 13 loss 0.9664196968078613
Epoch 14 loss 1.0471307039260864
Epoch 15 loss 0.911698043346405
Epoch 16 loss 0.981450080871582
Epoch 17 loss 0.9518622159957886
Epoch 18 loss 0.973005473613739
Epoch 19 loss 0.9814175367355347
Epoch 20 loss 0.8726057410240173
Epoch 21 loss 0.8873803019523621
Epoch 22 loss 0.9457348585128784
Epoch 23 loss 1.0742566585540771
Epoch 24 loss 0.9258382320404053
Epoch 25 loss 0.9157885313034058
Epoch 26 loss 0.9753441214561462
Epoch 27 loss 0.9259909391403198
Epoch 28 loss 0.8985006809234619
Epoch 29 loss 0.9101652503013611
Epoch 30 loss 0.9139494895935059
Epoch 31 loss 1.0080177783966064
Epoch 32 loss 0.8896098136901855
Epoch 33 loss 0.9390575289726257
Epoch 34 loss 0.9766084551811218
Epoch 35 loss 0.9540255069732666
Epoch 36 loss 0.9121540784835815
Epoch 37 loss 0.9341686964035034
Epoch 38 loss 1.026068091392517
Epoch 39 loss 0.8840042948722839
Epoch 40 loss 0.9017853140830994
Epoch 41 loss 0.975339412689209
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.94035, 'Log Loss - std': 0.013749999999999984} 
 

Fold 3
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -0.48114920966458397 -0.6162456233646283]
 [2 0 4 ... -0.0941079206995686 0.9938698897795997 0.13744535892851478]
 ...
 [2 0 4 ... -0.0941079206995686 -0.8499039845256299 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.9561683091087676 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}
Epoch 0 loss 1.9993693828582764
Epoch 1 loss 1.870190978050232
Epoch 2 loss 1.6991904973983765
Epoch 3 loss 1.5417520999908447
Epoch 4 loss 1.364574909210205
Epoch 5 loss 1.3027379512786865
Epoch 6 loss 1.1853727102279663
Epoch 7 loss 1.171589732170105
Epoch 8 loss 1.0987801551818848
Epoch 9 loss 1.0816391706466675
Epoch 10 loss 0.9964642524719238
Epoch 11 loss 1.0193397998809814
Epoch 12 loss 0.9732334613800049
Epoch 13 loss 0.9548880457878113
Epoch 14 loss 0.9818638563156128
Epoch 15 loss 0.9224473834037781
Epoch 16 loss 0.9602357745170593
Epoch 17 loss 0.9125643968582153
Epoch 18 loss 0.9369813203811646
Epoch 19 loss 0.9779285788536072
Epoch 20 loss 0.9028847217559814
Epoch 21 loss 1.0183897018432617
Epoch 22 loss 0.9022533297538757
Epoch 23 loss 0.9565863609313965
Epoch 24 loss 0.8911087512969971
Epoch 25 loss 0.9097811579704285
Epoch 26 loss 0.9371869564056396
Epoch 27 loss 0.990710973739624
Epoch 28 loss 0.8975653648376465
Epoch 29 loss 1.0678133964538574
Epoch 30 loss 1.0163555145263672
Epoch 31 loss 0.9788421392440796
Epoch 32 loss 1.0176790952682495
Epoch 33 loss 0.9379138946533203
Epoch 34 loss 1.004654884338379
Epoch 35 loss 0.9269270896911621
Epoch 36 loss 1.0317473411560059
Epoch 37 loss 0.9679142832756042
Epoch 38 loss 0.969697892665863
Epoch 39 loss 0.8834239840507507
Epoch 40 loss 0.8329232931137085
Epoch 41 loss 0.9368872046470642
Epoch 42 loss 0.9901298880577087
Epoch 43 loss 0.8800105452537537
Epoch 44 loss 0.9047813415527344
Epoch 45 loss 0.8836641311645508
Epoch 46 loss 0.9014396667480469
Epoch 47 loss 0.9832577705383301
Epoch 48 loss 0.907536506652832
Epoch 49 loss 1.0175608396530151
Epoch 50 loss 1.0007174015045166
Epoch 51 loss 0.9230402708053589
Epoch 52 loss 1.0376152992248535
Epoch 53 loss 0.9106022715568542
Epoch 54 loss 0.8773548007011414
Epoch 55 loss 0.9307000041007996
Epoch 56 loss 1.0548384189605713
Epoch 57 loss 1.0163028240203857
Epoch 58 loss 0.9362825751304626
Epoch 59 loss 0.9766407012939453
Epoch 60 loss 0.9575812220573425
Epoch 61 loss 0.9656695127487183
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9323333333333333, 'Log Loss - std': 0.015955424016789864} 
 

Fold 4
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -0.49206674869507705 -0.6244852981715446]
 [2 0 4 ... -0.08629838735429034 0.9882525364970667 0.12515378534790741]
 ...
 [2 0 4 ... 0.5549707577802916 1.7284121790931386 0.8747928688673595]
 [2 0 4 ... -0.08629838735429034 -0.862146569993113 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}
Epoch 0 loss 2.026643753051758
Epoch 1 loss 1.9392518997192383
Epoch 2 loss 1.787418246269226
Epoch 3 loss 1.5882881879806519
Epoch 4 loss 1.3944549560546875
Epoch 5 loss 1.3047178983688354
Epoch 6 loss 1.1949524879455566
Epoch 7 loss 1.1630975008010864
Epoch 8 loss 1.0944498777389526
Epoch 9 loss 1.0632624626159668
Epoch 10 loss 1.0210204124450684
Epoch 11 loss 0.9734421968460083
Epoch 12 loss 1.0145310163497925
Epoch 13 loss 1.029271125793457
Epoch 14 loss 0.9622723460197449
Epoch 15 loss 0.9473934173583984
Epoch 16 loss 0.9394674301147461
Epoch 17 loss 1.0031102895736694
Epoch 18 loss 0.9080435037612915
Epoch 19 loss 0.9129047393798828
Epoch 20 loss 1.0063295364379883
Epoch 21 loss 0.8706164360046387
Epoch 22 loss 0.9376758337020874
Epoch 23 loss 0.9446014165878296
Epoch 24 loss 0.8922611474990845
Epoch 25 loss 0.8917372226715088
Epoch 26 loss 0.8613815307617188
Epoch 27 loss 0.9044740200042725
Epoch 28 loss 0.9100698232650757
Epoch 29 loss 0.9597915410995483
Epoch 30 loss 0.8671676516532898
Epoch 31 loss 0.9144178628921509
Epoch 32 loss 0.8743916749954224
Epoch 33 loss 0.8394463062286377
Epoch 34 loss 0.8856241106987
Epoch 35 loss 0.8559109568595886
Epoch 36 loss 0.8479703664779663
Epoch 37 loss 0.851320743560791
Epoch 38 loss 0.8558872938156128
Epoch 39 loss 0.8343371748924255
Epoch 40 loss 0.8527342081069946
Epoch 41 loss 0.9230473041534424
Epoch 42 loss 0.9024378657341003
Epoch 43 loss 0.8912872076034546
Epoch 44 loss 0.8742725849151611
Epoch 45 loss 0.8468834757804871
Epoch 46 loss 0.8767701983451843
Epoch 47 loss 0.8472839593887329
Epoch 48 loss 0.8380961418151855
Epoch 49 loss 0.9799439311027527
Epoch 50 loss 0.9370858073234558
Epoch 51 loss 0.9182853102684021
Epoch 52 loss 0.8380341529846191
Epoch 53 loss 0.8097453117370605
Epoch 54 loss 0.9705238342285156
Epoch 55 loss 0.8468029499053955
Epoch 56 loss 0.8845305442810059
Epoch 57 loss 0.8908448219299316
Epoch 58 loss 0.8278917670249939
Epoch 59 loss 0.7845752239227295
Epoch 60 loss 0.9199618101119995
Epoch 61 loss 0.8477858901023865
Epoch 62 loss 0.8495597839355469
Epoch 63 loss 0.8597626090049744
Epoch 64 loss 0.8978235125541687
Epoch 65 loss 0.8834882974624634
Epoch 66 loss 0.9252910017967224
Epoch 67 loss 0.8720275163650513
Epoch 68 loss 0.9897592067718506
Epoch 69 loss 0.9286785125732422
Epoch 70 loss 0.847719669342041
Epoch 71 loss 0.9084075689315796
Epoch 72 loss 0.9574465155601501
Epoch 73 loss 0.9130768179893494
Epoch 74 loss 0.8944158554077148
Epoch 75 loss 0.8908385038375854
Epoch 76 loss 0.8434256315231323
Epoch 77 loss 0.939660906791687
Epoch 78 loss 1.0483791828155518
Epoch 79 loss 0.966808021068573
Epoch 80 loss 0.8675929307937622
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9121750000000001, 'Log Loss - std': 0.03755005825561391} 
 

Fold 5
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 109) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 2.0820453273934776 0.148179267290661]
 ...
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 0.148179267290661]
 [2 0 4 ... -0.139514558791527 0.23919223373207887 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]] 
 
 
Val : (1168, 109) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}
Epoch 0 loss 2.0140633583068848
Epoch 1 loss 1.9305518865585327
Epoch 2 loss 1.777003526687622
Epoch 3 loss 1.6525367498397827
Epoch 4 loss 1.5315736532211304
Epoch 5 loss 1.3976154327392578
Epoch 6 loss 1.2581183910369873
Epoch 7 loss 1.1889317035675049
Epoch 8 loss 1.1643859148025513
Epoch 9 loss 1.1211336851119995
Epoch 10 loss 1.1111421585083008
Epoch 11 loss 1.0821512937545776
Epoch 12 loss 1.0518052577972412
Epoch 13 loss 1.0247668027877808
Epoch 14 loss 1.069387674331665
Epoch 15 loss 1.036520004272461
Epoch 16 loss 0.9359328746795654
Epoch 17 loss 1.00897216796875
Epoch 18 loss 0.9748777747154236
Epoch 19 loss 1.0232865810394287
Epoch 20 loss 0.9910337924957275
Epoch 21 loss 1.0135033130645752
Epoch 22 loss 1.0077755451202393
Epoch 23 loss 0.9976203441619873
Epoch 24 loss 1.009063959121704
Epoch 25 loss 0.9816642999649048
Epoch 26 loss 0.9721572399139404
Epoch 27 loss 0.9874261617660522
Epoch 28 loss 0.9611692428588867
Epoch 29 loss 0.9603948593139648
Epoch 30 loss 0.9551569819450378
Epoch 31 loss 0.9808435440063477
Epoch 32 loss 0.9283051490783691
Epoch 33 loss 0.9742587804794312
Epoch 34 loss 0.9410371780395508
Epoch 35 loss 0.9425241947174072
Epoch 36 loss 1.016026496887207
Epoch 37 loss 0.9354981184005737
Epoch 38 loss 0.9454085230827332
Epoch 39 loss 0.959697425365448
Epoch 40 loss 0.9798714518547058
Epoch 41 loss 1.0294208526611328
Epoch 42 loss 1.0187782049179077
Epoch 43 loss 0.9433803558349609
Epoch 44 loss 0.9823058843612671
Epoch 45 loss 1.0406804084777832
Epoch 46 loss 1.0822181701660156
Epoch 47 loss 1.0828804969787598
Epoch 48 loss 0.9999227523803711
Epoch 49 loss 1.038023829460144
Epoch 50 loss 0.933079719543457
Epoch 51 loss 1.011849284172058
Epoch 52 loss 1.0426485538482666
Epoch 53 loss 1.0637426376342773
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is False b4 loss saving
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.92538, 'Log Loss - std': 0.04272579548703567} 
 

Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 0.92538 and parameters: {'dim': 32, 'depth': 1, 'heads': 8, 'dropout': 0.8}. Best is trial 0 with value: 0.9680199999999999.
Best parameters After Trials: {'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Parameters saved to YAML file!!!
In get_device
Using dim 8 and batch size 64
Fold 1
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 8, 15, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 4, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08549072883692027 -1.6038865594520038 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -0.4812300464036975 -0.6383658556335169]
 [2 0 4 ... -0.08549072883692027 -1.6038865594520038 -1.389990169524665]
 ...
 [2 0 4 ... -0.08549072883692027 -0.8554488840864662 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 -1.9781053971347726 0.11325845825763112]
 [2 0 4 ... -0.08549072883692027 0.2672076289618401 -1.389990169524665]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9999797344207764
Epoch 1 loss 1.8321876525878906
Epoch 2 loss 1.7060928344726562
Epoch 3 loss 1.569968581199646
Epoch 4 loss 1.3910554647445679
Epoch 5 loss 1.2871044874191284
Epoch 6 loss 1.213110327720642
Epoch 7 loss 1.1337213516235352
Epoch 8 loss 1.0605123043060303
Epoch 9 loss 1.0928568840026855
Epoch 10 loss 1.0165388584136963
Epoch 11 loss 1.0324410200119019
Epoch 12 loss 1.0128339529037476
Epoch 13 loss 0.934646487236023
Epoch 14 loss 0.945583701133728
Epoch 15 loss 0.9838109016418457
Epoch 16 loss 1.0713419914245605
Epoch 17 loss 0.9631533622741699
Epoch 18 loss 0.9347878694534302
Epoch 19 loss 0.9845677614212036
Epoch 20 loss 0.902786910533905
Epoch 21 loss 0.8881489634513855
Epoch 22 loss 1.0717730522155762
Epoch 23 loss 1.000764012336731
Epoch 24 loss 1.0595824718475342
Epoch 25 loss 1.0281022787094116
Epoch 26 loss 1.0474107265472412
Epoch 27 loss 0.8825997710227966
Epoch 28 loss 0.945819079875946
Epoch 29 loss 0.9539191126823425
Epoch 30 loss 0.9500626921653748
Epoch 31 loss 0.9495220184326172
Epoch 32 loss 0.8967750072479248
Epoch 33 loss 0.9454883933067322
Epoch 34 loss 0.8914284706115723
Epoch 35 loss 0.9899484515190125
Epoch 36 loss 1.0808480978012085
Epoch 37 loss 1.0586328506469727
Epoch 38 loss 1.2322559356689453
Epoch 39 loss 1.013243317604065
Epoch 40 loss 0.9616128206253052
Epoch 41 loss 1.009418249130249
Epoch 42 loss 0.9379914999008179
Epoch 43 loss 0.9370599985122681
Epoch 44 loss 1.0982863903045654
Epoch 45 loss 0.8921071290969849
Epoch 46 loss 0.9750038981437683
Epoch 47 loss 0.9868857860565186
Epoch 48 loss 1.0752346515655518
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/House_Prices_Nominal/logging/loss_0.txt
File name : output/SAINT/House_Prices_Nominal/logging/loss_0.txt . The file was saved
Log file exists at: output/SAINT/House_Prices_Nominal/logging/val_loss_0.txt
File name : output/SAINT/House_Prices_Nominal/logging/val_loss_0.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9151, 'Log Loss - std': 0.0} 
 

Fold 2
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 9, 6, 9, 7, 7, 14, 16, 4, 5, 5, 7, 5, 5, 5, 7, 7, 6, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08520364902762013 -1.5988030922284444 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 -0.4931772711965776 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 ...
 [2 0 4 ... -0.08520364902762013 0.9809904901792448 0.1703502411395687]
 [2 0 4 ... -0.08520364902762013 0.6124485498352892 -0.5890737346279431]
 [2 0 4 ... -0.08520364902762013 0.24390660949133355 -0.5890737346279431]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.0080831050872803
Epoch 1 loss 1.8632110357284546
Epoch 2 loss 1.7335232496261597
Epoch 3 loss 1.5722978115081787
Epoch 4 loss 1.4133625030517578
Epoch 5 loss 1.2862814664840698
Epoch 6 loss 1.22959566116333
Epoch 7 loss 1.1224913597106934
Epoch 8 loss 1.0860854387283325
Epoch 9 loss 1.0671067237854004
Epoch 10 loss 1.1128867864608765
Epoch 11 loss 1.1993930339813232
Epoch 12 loss 1.0992982387542725
Epoch 13 loss 1.173171043395996
Epoch 14 loss 1.0344105958938599
Epoch 15 loss 1.190317153930664
Epoch 16 loss 1.039686679840088
Epoch 17 loss 1.1245596408843994
Epoch 18 loss 1.0792744159698486
Epoch 19 loss 0.9781111478805542
Epoch 20 loss 1.0544540882110596
Epoch 21 loss 1.0168970823287964
Epoch 22 loss 1.083425760269165
Epoch 23 loss 1.107935905456543
Epoch 24 loss 0.9994475841522217
Epoch 25 loss 1.0508368015289307
Epoch 26 loss 1.2004936933517456
Epoch 27 loss 0.9788941740989685
Epoch 28 loss 1.0779993534088135
Epoch 29 loss 1.0381635427474976
Epoch 30 loss 1.037184476852417
Epoch 31 loss 1.0254008769989014
Epoch 32 loss 1.1616873741149902
Epoch 33 loss 1.091432809829712
Epoch 34 loss 1.1530588865280151
Epoch 35 loss 1.121152400970459
Epoch 36 loss 1.0420520305633545
Epoch 37 loss 1.2051973342895508
Epoch 38 loss 1.191532015800476
Epoch 39 loss 1.2691880464553833
Epoch 40 loss 1.1616920232772827
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/House_Prices_Nominal/logging/loss_1.txt
File name : output/SAINT/House_Prices_Nominal/logging/loss_1.txt . The file was saved
Log file exists at: output/SAINT/House_Prices_Nominal/logging/val_loss_1.txt
File name : output/SAINT/House_Prices_Nominal/logging/val_loss_1.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9646, 'Log Loss - std': 0.04949999999999999} 
 

Fold 3
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 3, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -0.48114920966458397 -0.6162456233646283]
 [2 0 4 ... -0.0941079206995686 0.9938698897795997 0.13744535892851478]
 ...
 [2 0 4 ... -0.0941079206995686 -0.8499039845256299 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.9561683091087676 0.13744535892851478]
 [2 0 4 ... -0.0941079206995686 -1.5874135342477218 0.13744535892851478]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 2.0502514839172363
Epoch 1 loss 1.9552409648895264
Epoch 2 loss 1.7918494939804077
Epoch 3 loss 1.6304388046264648
Epoch 4 loss 1.43244206905365
Epoch 5 loss 1.3276865482330322
Epoch 6 loss 1.2186260223388672
Epoch 7 loss 1.157253623008728
Epoch 8 loss 1.0570347309112549
Epoch 9 loss 0.9905802607536316
Epoch 10 loss 1.0850529670715332
Epoch 11 loss 0.9960212111473083
Epoch 12 loss 0.911655843257904
Epoch 13 loss 1.0434749126434326
Epoch 14 loss 0.9685262441635132
Epoch 15 loss 1.0013387203216553
Epoch 16 loss 1.098860502243042
Epoch 17 loss 0.9705151319503784
Epoch 18 loss 0.9296779632568359
Epoch 19 loss 0.9403600692749023
Epoch 20 loss 1.084216833114624
Epoch 21 loss 1.0277360677719116
Epoch 22 loss 0.9991707801818848
Epoch 23 loss 0.9920309782028198
Epoch 24 loss 0.9554466009140015
Epoch 25 loss 1.0661009550094604
Epoch 26 loss 0.943610668182373
Epoch 27 loss 1.0787341594696045
Epoch 28 loss 0.9997982382774353
Epoch 29 loss 0.9517934322357178
Epoch 30 loss 1.1376993656158447
Epoch 31 loss 0.9946383833885193
Epoch 32 loss 1.0973913669586182
Epoch 33 loss 1.0857717990875244
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/House_Prices_Nominal/logging/loss_2.txt
File name : output/SAINT/House_Prices_Nominal/logging/loss_2.txt . The file was saved
Log file exists at: output/SAINT/House_Prices_Nominal/logging/val_loss_2.txt
File name : output/SAINT/House_Prices_Nominal/logging/val_loss_2.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9641666666666667, 'Log Loss - std': 0.0404212265468968} 
 

Fold 4
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 110) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 3, 6, 4, 10, 8, 6, 9, 7, 9, 15, 16, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 5, 3, 5, 5, 7, 6, 7, 4, 6, 6, 4, 4, 5, 5, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -0.49206674869507705 -0.6244852981715446]
 [2 0 4 ... -0.08629838735429034 0.9882525364970667 0.12515378534790741]
 ...
 [2 0 4 ... 0.5549707577802916 1.7284121790931386 0.8747928688673595]
 [2 0 4 ... -0.08629838735429034 -0.862146569993113 0.12515378534790741]
 [2 0 4 ... -0.08629838735429034 -1.602306212589185 0.12515378534790741]] 
 
 
Val : (1168, 110) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9737961292266846
Epoch 1 loss 1.820732831954956
Epoch 2 loss 1.6785879135131836
Epoch 3 loss 1.5423340797424316
Epoch 4 loss 1.44864821434021
Epoch 5 loss 1.3467886447906494
Epoch 6 loss 1.2268917560577393
Epoch 7 loss 1.162043571472168
Epoch 8 loss 1.0884127616882324
Epoch 9 loss 1.091036081314087
Epoch 10 loss 1.1039788722991943
Epoch 11 loss 1.0073705911636353
Epoch 12 loss 0.9179368019104004
Epoch 13 loss 1.1995996236801147
Epoch 14 loss 1.066917896270752
Epoch 15 loss 0.9898585677146912
Epoch 16 loss 0.9573420286178589
Epoch 17 loss 0.9769134521484375
Epoch 18 loss 0.9545723795890808
Epoch 19 loss 1.0331659317016602
Epoch 20 loss 1.1535841226577759
Epoch 21 loss 0.9944949150085449
Epoch 22 loss 0.9358944892883301
Epoch 23 loss 0.9791013598442078
Epoch 24 loss 1.0267672538757324
Epoch 25 loss 0.9058272242546082
Epoch 26 loss 0.9408296942710876
Epoch 27 loss 0.9746016263961792
Epoch 28 loss 1.0421326160430908
Epoch 29 loss 0.9304894804954529
Epoch 30 loss 0.9034494757652283
Epoch 31 loss 0.9216283559799194
Epoch 32 loss 0.9264134764671326
Epoch 33 loss 0.9742447137832642
Epoch 34 loss 0.9916026592254639
Epoch 35 loss 0.9413992762565613
Epoch 36 loss 1.040761947631836
Epoch 37 loss 0.9364969730377197
Epoch 38 loss 1.0529234409332275
Epoch 39 loss 1.0594031810760498
Epoch 40 loss 1.0170693397521973
Epoch 41 loss 0.9037021994590759
Epoch 42 loss 0.9116758704185486
Epoch 43 loss 1.0612492561340332
Epoch 44 loss 0.9687594175338745
Epoch 45 loss 1.0539608001708984
Epoch 46 loss 0.931759238243103
Epoch 47 loss 1.0716875791549683
Epoch 48 loss 0.9441978335380554
Epoch 49 loss 1.065861463546753
Epoch 50 loss 1.066414713859558
Epoch 51 loss 0.9003928899765015
Epoch 52 loss 1.1361337900161743
Epoch 53 loss 1.1170059442520142
Epoch 54 loss 1.0125809907913208
Epoch 55 loss 1.0048688650131226
Epoch 56 loss 1.0488101243972778
Epoch 57 loss 1.2693462371826172
Epoch 58 loss 1.0972445011138916
Epoch 59 loss 1.3064627647399902
Epoch 60 loss 0.9810198545455933
Epoch 61 loss 1.002228856086731
Epoch 62 loss 1.0606772899627686
Epoch 63 loss 1.263007402420044
Epoch 64 loss 1.230850100517273
Epoch 65 loss 1.2715033292770386
Epoch 66 loss 1.1513497829437256
Epoch 67 loss 1.1573386192321777
Epoch 68 loss 1.3049535751342773
Epoch 69 loss 1.1912634372711182
Epoch 70 loss 1.1924853324890137
Epoch 71 loss 1.2676695585250854
Epoch 72 loss 1.1357595920562744
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/House_Prices_Nominal/logging/loss_3.txt
File name : output/SAINT/House_Prices_Nominal/logging/loss_3.txt . The file was saved
Log file exists at: output/SAINT/House_Prices_Nominal/logging/val_loss_3.txt
File name : output/SAINT/House_Prices_Nominal/logging/val_loss_3.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.976225, 'Log Loss - std': 0.04076293506360893} 
 

Fold 5
num_features : 79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BEFORE ANY ENCODING
num_features :79
num_classes : 1
cat_idx : [0]
nominal_idx : [1, 6, 11]
ordinal_idx : [4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78]
num_idx : None
cat_dims : [2]
bin_alt : None 


X shape : (1168, 79)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


AFTER SEPARATING CATEGORICALS AND NUMERICALS
Numerical Index V1 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76]
Cat Dims V1 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V1 : [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 41, 52, 54, 56, 57, 59, 62, 63, 64, 71, 72, 73, 77, 78] 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 


Scaling the data...
One Hot Encoding...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After OHE
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'FR2']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Corner']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']
 ['Pave' 'None' 'Lvl' 'AllPub' 'Inside']] 
 
 
Val : (1168, 109) 
 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
After ORDINAL
Numerical Index V2 : [0, 2, 3, 16, 17, 18, 19, 25, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 74, 75, 76] 


OHE Idx : [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]


Ordinal Idx V2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]


Cat Dims V2 : [3, 3, 5, 2, 6, 4, 10, 8, 6, 9, 7, 8, 16, 17, 4, 5, 6, 7, 5, 5, 5, 7, 7, 7, 6, 3, 6, 5, 8, 6, 7, 4, 6, 6, 4, 4, 5, 3, 10, 7]
Cat Idx V2 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 
 

Train: [[2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 2.0820453273934776 0.148179267290661]
 ...
 [2 0 4 ... -0.139514558791527 -1.6036608599293196 0.148179267290661]
 [2 0 4 ... -0.139514558791527 0.23919223373207887 -1.3568066822346665]
 [2 0 4 ... -0.139514558791527 0.9763334711966383 0.148179267290661]] 
 
 
Val : (1168, 109) 
 

FINISHED ENCODING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Number of Classes B4 Bin Verifier: 8
Unique values in y_train: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
Unique values in y_test: (array([0., 1., 2., 3., 4., 5., 6., 7.]), 8)
No need to shift labels.
VERIFY SHIFT
Train after shift : [0 1 2 3 4 5 6 7], Length : 8
Test after shift : [0 1 2 3 4 5 6 7], Length : 8
Number of Classes After Bin Verifier: 8
In get_device
Using dim 8 and batch size 64
{'dim': 256, 'depth': 6, 'heads': 2, 'dropout': 0.8}
Epoch 0 loss 1.9426153898239136
Epoch 1 loss 1.8071587085723877
Epoch 2 loss 1.6826136112213135
Epoch 3 loss 1.5063599348068237
Epoch 4 loss 1.3912229537963867
Epoch 5 loss 1.2827352285385132
Epoch 6 loss 1.2300952672958374
Epoch 7 loss 1.1888312101364136
Epoch 8 loss 1.1962594985961914
Epoch 9 loss 1.066604495048523
Epoch 10 loss 1.0641530752182007
Epoch 11 loss 1.075167179107666
Epoch 12 loss 1.0743772983551025
Epoch 13 loss 1.0164564847946167
Epoch 14 loss 1.1028679609298706
Epoch 15 loss 1.0627541542053223
Epoch 16 loss 1.1267883777618408
Epoch 17 loss 0.9558852910995483
Epoch 18 loss 0.934867262840271
Epoch 19 loss 0.9619030356407166
Epoch 20 loss 1.0090818405151367
Epoch 21 loss 1.2015151977539062
Epoch 22 loss 1.011870265007019
Epoch 23 loss 0.9692916870117188
Epoch 24 loss 1.0082682371139526
Epoch 25 loss 1.0371674299240112
Epoch 26 loss 1.100442886352539
Epoch 27 loss 1.0373576879501343
Epoch 28 loss 1.219162940979004
Epoch 29 loss 1.0301326513290405
Epoch 30 loss 0.9687580466270447
Epoch 31 loss 1.1259840726852417
Epoch 32 loss 0.985966145992279
Epoch 33 loss 1.0906965732574463
Epoch 34 loss 1.0573654174804688
Epoch 35 loss 1.0795916318893433
Epoch 36 loss 1.0609767436981201
Epoch 37 loss 1.017159342765808
Epoch 38 loss 1.1489803791046143
Epoch 39 loss 1.1489601135253906
Validation loss has not improved for 20 steps!
Early stopping applies.
State of save is True b4 loss saving
Log file exists at: output/SAINT/House_Prices_Nominal/logging/loss_4.txt
File name : output/SAINT/House_Prices_Nominal/logging/loss_4.txt . The file was saved
Log file exists at: output/SAINT/House_Prices_Nominal/logging/val_loss_4.txt
File name : output/SAINT/House_Prices_Nominal/logging/val_loss_4.txt . The file was saved
Saved Losses and Regularization
±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

B4 Evaluation
Number of classes : 8
Class label len :8
Class labels : [0, 1, 2, 3, 4, 5, 6, 7]
Unique y_true : [0 1 2 3 4 5 6 7] 

Prediction shape : (292,)
Probabilities shape : (292, 8) 

±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±±± 

After Evaluation
{'Log Loss - mean': 0.9766600000000001, 'Log Loss - std': 0.03646985604578114} 
 

Saving model.....
Results After CV: {'Log Loss - mean': 0.9766600000000001, 'Log Loss - std': 0.03646985604578114}
Train time: 163.1439820823999
Inference time: 0.22330185060009172
Finished cross validation
Loss path :output/SAINT/House_Prices_Nominal/logging/
Plots saved successfully!
