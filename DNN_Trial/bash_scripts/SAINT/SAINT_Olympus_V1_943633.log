

----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/boston.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/boston.yml', data_parallel=False, dataset='Boston', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=30, nominal_idx=[3], num_classes=1, num_features=13, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Boston...
Dataset loaded!
(506, 13)
Scaling the data...
args.num_features: 14
args.cat_idx: []
New Shape: (506, 14)
A new study created in RDB with name: SAINT_Boston
In get_device
Using dim 128 and batch size 128
In get_device
Using dim 128 and batch size 128
Epoch 0 loss 439.39263916015625
Epoch 1 loss 371.0314636230469
Epoch 2 loss 298.7507019042969
Epoch 3 loss 209.47579956054688
Epoch 4 loss 118.81161499023438
Epoch 5 loss 69.02766418457031
Epoch 6 loss 89.02914428710938
Epoch 7 loss 55.21660614013672
Epoch 8 loss 46.84686279296875
Epoch 9 loss 44.61890411376953
Epoch 10 loss 32.539710998535156
Epoch 11 loss 30.970869064331055
Epoch 12 loss 27.469785690307617
Epoch 13 loss 24.864059448242188
Epoch 14 loss 25.19695281982422
Epoch 15 loss 23.408422470092773
Epoch 16 loss 21.4408016204834
Epoch 17 loss 24.893896102905273
Epoch 18 loss 20.557167053222656
Epoch 19 loss 19.757915496826172
Epoch 20 loss 22.23468017578125
Epoch 21 loss 21.385038375854492
Epoch 22 loss 24.224475860595703
Epoch 23 loss 19.042381286621094
Epoch 24 loss 22.944278717041016
Epoch 25 loss 16.27631378173828
Epoch 26 loss 16.6082763671875
Epoch 27 loss 15.631889343261719
Epoch 28 loss 17.136674880981445
Epoch 29 loss 15.85165023803711
Epoch 30 loss 17.27488136291504
Epoch 31 loss 15.924700736999512
Epoch 32 loss 18.44270896911621
Epoch 33 loss 15.115592956542969
Epoch 34 loss 14.702985763549805
Epoch 35 loss 14.745134353637695
Epoch 36 loss 15.279620170593262
Epoch 37 loss 14.253040313720703
Epoch 38 loss 15.13237476348877
Epoch 39 loss 14.777434349060059
Epoch 40 loss 14.705377578735352
Epoch 41 loss 14.085258483886719
Epoch 42 loss 14.348556518554688
Epoch 43 loss 15.903191566467285
Epoch 44 loss 14.005677223205566
Epoch 45 loss 14.40014934539795
Epoch 46 loss 13.69048023223877
Epoch 47 loss 13.315116882324219
Epoch 48 loss 15.028895378112793
Epoch 49 loss 14.739636421203613
Epoch 50 loss 14.044663429260254
Epoch 51 loss 14.66135311126709
Epoch 52 loss 14.89682674407959
Epoch 53 loss 14.089550018310547
Epoch 54 loss 16.90742301940918
Epoch 55 loss 13.259405136108398
Epoch 56 loss 12.746026992797852
Epoch 57 loss 18.478538513183594
Epoch 58 loss 13.542244911193848
Epoch 59 loss 14.806323051452637
Epoch 60 loss 15.450186729431152
Epoch 61 loss 12.913773536682129
Epoch 62 loss 12.242430686950684
Epoch 63 loss 13.192178726196289
Epoch 64 loss 11.828644752502441
Epoch 65 loss 11.749868392944336
Epoch 66 loss 13.662397384643555
Epoch 67 loss 15.546712875366211
Epoch 68 loss 12.683539390563965
Epoch 69 loss 12.594640731811523
Epoch 70 loss 11.022455215454102
Epoch 71 loss 11.12822437286377
Epoch 72 loss 13.092808723449707
Epoch 73 loss 13.334217071533203
Epoch 74 loss 14.14072322845459
Epoch 75 loss 14.01169490814209
Epoch 76 loss 12.661699295043945
Epoch 77 loss 12.027877807617188
Epoch 78 loss 13.120898246765137
Epoch 79 loss 11.105860710144043
Epoch 80 loss 12.13053035736084
Epoch 81 loss 14.492879867553711
Epoch 82 loss 12.065309524536133
Epoch 83 loss 13.047327995300293
Epoch 84 loss 12.937193870544434
Epoch 85 loss 12.638274192810059
Epoch 86 loss 13.141138076782227
Epoch 87 loss 11.598458290100098
Epoch 88 loss 12.556036949157715
Epoch 89 loss 13.347573280334473
Epoch 90 loss 12.151803970336914
Epoch 91 loss 15.883322715759277
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 11.022456665817135, 'MSE - std': 0.0, 'R2 - mean': 0.8523810144648326, 'R2 - std': 0.0} 
 

In get_device
Using dim 128 and batch size 128
Epoch 0 loss 525.14013671875
Epoch 1 loss 450.8569641113281
Epoch 2 loss 374.9831237792969
Epoch 3 loss 279.1837158203125
Epoch 4 loss 174.3684844970703
Epoch 5 loss 90.45480346679688
Epoch 6 loss 82.65601348876953
Epoch 7 loss 66.87984466552734
Epoch 8 loss 73.60819244384766
Epoch 9 loss 51.715511322021484
Epoch 10 loss 43.06690979003906
Epoch 11 loss 38.75956726074219
Epoch 12 loss 32.23088073730469
Epoch 13 loss 26.516983032226562
Epoch 14 loss 22.650358200073242
Epoch 15 loss 23.395734786987305
Epoch 16 loss 19.414758682250977
Epoch 17 loss 17.2210750579834
Epoch 18 loss 14.903726577758789
Epoch 19 loss 14.56446647644043
Epoch 20 loss 15.373380661010742
Epoch 21 loss 18.291629791259766
Epoch 22 loss 15.69072437286377
Epoch 23 loss 15.815375328063965
Epoch 24 loss 19.218212127685547
Epoch 25 loss 16.997411727905273
Epoch 26 loss 18.330759048461914
Epoch 27 loss 23.344802856445312
Epoch 28 loss 16.346895217895508
Epoch 29 loss 17.75543212890625
Epoch 30 loss 15.177410125732422
Epoch 31 loss 14.997139930725098
Epoch 32 loss 15.38017463684082
Epoch 33 loss 16.21546173095703
Epoch 34 loss 14.7206392288208
Epoch 35 loss 14.291522026062012
Epoch 36 loss 14.057171821594238
Epoch 37 loss 13.955694198608398
Epoch 38 loss 14.337389945983887
Epoch 39 loss 14.245393753051758
Epoch 40 loss 14.561290740966797
Epoch 41 loss 19.945730209350586
Epoch 42 loss 18.409700393676758
Epoch 43 loss 17.84650230407715
Epoch 44 loss 16.898008346557617
Epoch 45 loss 16.65128517150879
Epoch 46 loss 16.216083526611328
Epoch 47 loss 17.419876098632812
Epoch 48 loss 14.293498039245605
Epoch 49 loss 17.031970977783203
Epoch 50 loss 13.584569931030273
Epoch 51 loss 14.895408630371094
Epoch 52 loss 13.390042304992676
Epoch 53 loss 13.047409057617188
Epoch 54 loss 13.410419464111328
Epoch 55 loss 13.248001098632812
Epoch 56 loss 13.920995712280273
Epoch 57 loss 13.487211227416992
Epoch 58 loss 14.295827865600586
Epoch 59 loss 13.135174751281738
Epoch 60 loss 14.01591682434082
Epoch 61 loss 13.537169456481934
Epoch 62 loss 13.816815376281738
Epoch 63 loss 13.489313125610352
Epoch 64 loss 14.018954277038574
Epoch 65 loss 12.74651050567627
Epoch 66 loss 14.25903034210205
Epoch 67 loss 13.027501106262207
Epoch 68 loss 13.944482803344727
Epoch 69 loss 13.591978073120117
Epoch 70 loss 15.842679023742676
Epoch 71 loss 14.123248100280762
Epoch 72 loss 16.39175033569336
Epoch 73 loss 13.03363037109375
Epoch 74 loss 14.189762115478516
Epoch 75 loss 12.755549430847168
Epoch 76 loss 12.652755737304688
Epoch 77 loss 12.560598373413086
Epoch 78 loss 13.060981750488281
Epoch 79 loss 12.841947555541992
Epoch 80 loss 12.661704063415527
Epoch 81 loss 12.962313652038574
Epoch 82 loss 12.466508865356445
Epoch 83 loss 12.393930435180664
Epoch 84 loss 12.681144714355469
Epoch 85 loss 12.017484664916992
Epoch 86 loss 12.17957878112793
Epoch 87 loss 12.331869125366211
Epoch 88 loss 12.460893630981445
Epoch 89 loss 13.935855865478516
Epoch 90 loss 12.720657348632812
Epoch 91 loss 13.17348575592041
Epoch 92 loss 12.400141716003418
Epoch 93 loss 12.760231018066406
Epoch 94 loss 13.488000869750977
Epoch 95 loss 13.188702583312988
Epoch 96 loss 16.377126693725586
Epoch 97 loss 13.384003639221191
Epoch 98 loss 12.855414390563965
Epoch 99 loss 12.326193809509277
Saved Losses
{'MSE - mean': 11.519972103135196, 'MSE - std': 0.4975154373180608, 'R2 - mean': 0.851584911237683, 'R2 - std': 0.0007961032271496804} 
 

In get_device
Using dim 128 and batch size 128
Epoch 0 loss 561.5865478515625
Epoch 1 loss 485.1536865234375
Epoch 2 loss 398.24786376953125
Epoch 3 loss 293.6546936035156
Epoch 4 loss 182.26507568359375
Epoch 5 loss 100.11712646484375
Epoch 6 loss 85.61571502685547
Epoch 7 loss 81.07012939453125
Epoch 8 loss 64.11201477050781
Epoch 9 loss 51.07990264892578
Epoch 10 loss 44.80760192871094
Epoch 11 loss 33.211734771728516
Epoch 12 loss 26.804149627685547
Epoch 13 loss 19.467529296875
Epoch 14 loss 15.113536834716797
Epoch 15 loss 13.701900482177734
Epoch 16 loss 20.652618408203125
Epoch 17 loss 13.695585250854492
Epoch 18 loss 12.70061206817627
Epoch 19 loss 10.640583992004395
Epoch 20 loss 12.741334915161133
Epoch 21 loss 12.143614768981934
Epoch 22 loss 13.910969734191895
Epoch 23 loss 12.755517959594727
Epoch 24 loss 9.79587173461914
Epoch 25 loss 9.03796100616455
Epoch 26 loss 9.179242134094238
Epoch 27 loss 12.69918441772461
Epoch 28 loss 15.422237396240234
Epoch 29 loss 12.385300636291504
Epoch 30 loss 10.752291679382324
Epoch 31 loss 9.684545516967773
Epoch 32 loss 13.23157787322998
Epoch 33 loss 10.5159912109375
Epoch 34 loss 9.542724609375
Epoch 35 loss 9.294275283813477
Epoch 36 loss 9.294736862182617
Epoch 37 loss 10.30636978149414
Epoch 38 loss 11.227222442626953
Epoch 39 loss 8.787952423095703
Epoch 40 loss 8.302340507507324
Epoch 41 loss 9.500378608703613
Epoch 42 loss 7.754208087921143
Epoch 43 loss 9.564269065856934
Epoch 44 loss 8.61091136932373
Epoch 45 loss 10.010627746582031
Epoch 46 loss 12.269320487976074
Epoch 47 loss 8.97350788116455
Epoch 48 loss 8.283736228942871
Epoch 49 loss 15.062188148498535
Epoch 50 loss 11.087709426879883
Epoch 51 loss 12.638379096984863
Epoch 52 loss 8.755889892578125
Epoch 53 loss 8.397977828979492
Epoch 54 loss 9.077448844909668
Epoch 55 loss 8.109060287475586
Epoch 56 loss 7.3266987800598145
Epoch 57 loss 7.217560768127441
Epoch 58 loss 7.807003498077393
Epoch 59 loss 8.675819396972656
Epoch 60 loss 7.947950839996338
Epoch 61 loss 8.388275146484375
Epoch 62 loss 9.07661247253418
Epoch 63 loss 7.667065620422363
Epoch 64 loss 7.5206193923950195
Epoch 65 loss 7.637205600738525
Epoch 66 loss 8.023600578308105
Epoch 67 loss 7.965943336486816
Epoch 68 loss 8.653681755065918
Epoch 69 loss 8.242392539978027
Epoch 70 loss 8.583752632141113
Epoch 71 loss 8.397643089294434
Epoch 72 loss 8.216721534729004
Epoch 73 loss 8.009797096252441
Epoch 74 loss 7.613123893737793
Epoch 75 loss 7.65750789642334
Epoch 76 loss 7.503337860107422
Epoch 77 loss 7.379326820373535
Epoch 78 loss 7.43890380859375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 10.08583475624589, 'MSE - std': 2.0684569771688706, 'R2 - mean': 0.8758469372920624, 'R2 - std': 0.03431784283370637} 
 

In get_device
Using dim 128 and batch size 128
Epoch 0 loss 435.0096740722656
Epoch 1 loss 369.4428405761719
Epoch 2 loss 297.3643493652344
Epoch 3 loss 209.0649871826172
Epoch 4 loss 119.4836654663086
Epoch 5 loss 71.04232025146484
Epoch 6 loss 96.67790985107422
Epoch 7 loss 58.4312629699707
Epoch 8 loss 50.31990432739258
Epoch 9 loss 52.445701599121094
Epoch 10 loss 40.766483306884766
Epoch 11 loss 39.6900634765625
Epoch 12 loss 28.159971237182617
Epoch 13 loss 22.5117130279541
Epoch 14 loss 20.023422241210938
Epoch 15 loss 19.518535614013672
Epoch 16 loss 16.848697662353516
Epoch 17 loss 17.062957763671875
Epoch 18 loss 15.326835632324219
Epoch 19 loss 12.541617393493652
Epoch 20 loss 12.06567096710205
Epoch 21 loss 12.054221153259277
Epoch 22 loss 14.439046859741211
Epoch 23 loss 13.108695983886719
Epoch 24 loss 12.252193450927734
Epoch 25 loss 11.57820987701416
Epoch 26 loss 11.42202377319336
Epoch 27 loss 12.47315788269043
Epoch 28 loss 15.693840026855469
Epoch 29 loss 12.647101402282715
Epoch 30 loss 11.514861106872559
Epoch 31 loss 11.437490463256836
Epoch 32 loss 12.032151222229004
Epoch 33 loss 14.660844802856445
Epoch 34 loss 10.667655944824219
Epoch 35 loss 10.8191556930542
Epoch 36 loss 9.791255950927734
Epoch 37 loss 12.556768417358398
Epoch 38 loss 9.00784969329834
Epoch 39 loss 8.983996391296387
Epoch 40 loss 14.080883026123047
Epoch 41 loss 9.030755996704102
Epoch 42 loss 9.55946159362793
Epoch 43 loss 11.07878589630127
Epoch 44 loss 10.617639541625977
Epoch 45 loss 9.442793846130371
Epoch 46 loss 9.248966217041016
Epoch 47 loss 7.698924541473389
Epoch 48 loss 7.238261699676514
Epoch 49 loss 8.035799026489258
Epoch 50 loss 7.43386173248291
Epoch 51 loss 7.167512893676758
Epoch 52 loss 8.596169471740723
Epoch 53 loss 7.09054708480835
Epoch 54 loss 7.77166748046875
Epoch 55 loss 7.377041816711426
Epoch 56 loss 8.2988862991333
Epoch 57 loss 7.751247406005859
Epoch 58 loss 7.277375221252441
Epoch 59 loss 7.014100074768066
Epoch 60 loss 7.13696813583374
Epoch 61 loss 6.633234024047852
Epoch 62 loss 7.561985015869141
Epoch 63 loss 6.764755725860596
Epoch 64 loss 8.41781997680664
Epoch 65 loss 6.736904621124268
Epoch 66 loss 8.536177635192871
Epoch 67 loss 7.660959720611572
Epoch 68 loss 7.184981346130371
Epoch 69 loss 8.810896873474121
Epoch 70 loss 7.052509307861328
Epoch 71 loss 7.803772449493408
Epoch 72 loss 7.479766845703125
Epoch 73 loss 6.668927192687988
Epoch 74 loss 7.223887920379639
Epoch 75 loss 6.876955509185791
Epoch 76 loss 10.057696342468262
Epoch 77 loss 6.659487247467041
Epoch 78 loss 6.365859508514404
Epoch 79 loss 8.434643745422363
Epoch 80 loss 7.703378677368164
Epoch 81 loss 7.137362957000732
Epoch 82 loss 10.433744430541992
Epoch 83 loss 7.701292514801025
Epoch 84 loss 8.1049222946167
Epoch 85 loss 7.930096626281738
Epoch 86 loss 7.2790751457214355
Epoch 87 loss 8.357118606567383
Epoch 88 loss 6.930359363555908
Epoch 89 loss 8.01644229888916
Epoch 90 loss 7.0812835693359375
Epoch 91 loss 8.115198135375977
Epoch 92 loss 6.85584831237793
Epoch 93 loss 7.310391426086426
Epoch 94 loss 9.549107551574707
Epoch 95 loss 7.006924152374268
Epoch 96 loss 8.658913612365723
Epoch 97 loss 8.063555717468262
Epoch 98 loss 6.9297661781311035
Epoch 99 loss 7.098382472991943
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 9.155841212062121, 'MSE - std': 2.4090557644997346, 'R2 - mean': 0.8857937801612781, 'R2 - std': 0.034352653489415165} 
 

In get_device
Using dim 128 and batch size 128
Epoch 0 loss 474.5007019042969
Epoch 1 loss 398.507568359375
Epoch 2 loss 324.8783874511719
Epoch 3 loss 234.16363525390625
Epoch 4 loss 141.49549865722656
Epoch 5 loss 88.04644775390625
Epoch 6 loss 103.78173065185547
Epoch 7 loss 73.83649444580078
Epoch 8 loss 63.224937438964844
Epoch 9 loss 54.90663528442383
Epoch 10 loss 45.963539123535156
Epoch 11 loss 39.56488800048828
Epoch 12 loss 32.07268142700195
Epoch 13 loss 28.23274040222168
Epoch 14 loss 31.133644104003906
Epoch 15 loss 24.0299015045166
Epoch 16 loss 21.454051971435547
Epoch 17 loss 19.490575790405273
Epoch 18 loss 16.885583877563477
Epoch 19 loss 16.399913787841797
Epoch 20 loss 13.855084419250488
Epoch 21 loss 13.79522705078125
Epoch 22 loss 13.52851390838623
Epoch 23 loss 13.090752601623535
Epoch 24 loss 15.183902740478516
Epoch 25 loss 13.291790962219238
Epoch 26 loss 13.60981559753418
Epoch 27 loss 12.476506233215332
Epoch 28 loss 12.608880043029785
Epoch 29 loss 11.511691093444824
Epoch 30 loss 12.4447603225708
Epoch 31 loss 18.314611434936523
Epoch 32 loss 15.114145278930664
Epoch 33 loss 24.659406661987305
Epoch 34 loss 16.7930965423584
Epoch 35 loss 16.79094696044922
Epoch 36 loss 12.265236854553223
Epoch 37 loss 12.602937698364258
Epoch 38 loss 12.024901390075684
Epoch 39 loss 12.298269271850586
Epoch 40 loss 12.077290534973145
Epoch 41 loss 15.13096809387207
Epoch 42 loss 12.096385955810547
Epoch 43 loss 14.32562255859375
Epoch 44 loss 12.376382827758789
Epoch 45 loss 12.100329399108887
Epoch 46 loss 12.942102432250977
Epoch 47 loss 12.096919059753418
Epoch 48 loss 15.393918991088867
Epoch 49 loss 11.691225051879883
Epoch 50 loss 13.912339210510254
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 9.6270111888625, 'MSE - std': 2.3517747190850984, 'R2 - mean': 0.8834112316265579, 'R2 - std': 0.03109324671841542} 
 

Results After CV: {'MSE - mean': 9.6270111888625, 'MSE - std': 2.3517747190850984, 'R2 - mean': 0.8834112316265579, 'R2 - std': 0.03109324671841542}
Train time: 122.7027054528
Inference time: 0.17389987059998474
Finished cross validation
Trial 0 finished with value: 9.6270111888625 and parameters: {'dim': 128, 'depth': 3, 'heads': 2, 'dropout': 0.1}. Best is trial 0 with value: 9.6270111888625.
In get_device
Using dim 256 and batch size 128
In get_device
Using dim 256 and batch size 128
Trial 1 failed with parameters: {'dim': 256, 'depth': 6, 'heads': 4, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 140.44 MiB is free. Including non-PyTorch memory, this process has 7.65 GiB memory in use. Of the allocated memory 7.23 GiB is allocated by PyTorch, and 293.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 131, in fit
    loss.backward()
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 140.44 MiB is free. Including non-PyTorch memory, this process has 7.65 GiB memory in use. Of the allocated memory 7.23 GiB is allocated by PyTorch, and 293.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Trial 1 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/socmob.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/socmob.yml', data_parallel=False, dataset='Socmob', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=30, nominal_idx=[0, 1, 2, 3], num_classes=1, num_features=5, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Socmob...
Dataset loaded!
(1156, 5)
Scaling the data...
args.num_features: 39
args.cat_idx: []
New Shape: (1156, 39)
A new study created in RDB with name: SAINT_Socmob
In get_device
Using dim 32 and batch size 128
In get_device
Using dim 32 and batch size 128
Epoch 0 loss 1167.2520751953125
Epoch 1 loss 1113.7501220703125
Epoch 2 loss 1065.1234130859375
Epoch 3 loss 1029.6468505859375
Epoch 4 loss 1026.632080078125
Epoch 5 loss 1041.1168212890625
Epoch 6 loss 1035.7451171875
Epoch 7 loss 973.9453125
Epoch 8 loss 770.0870361328125
Epoch 9 loss 648.83447265625
Epoch 10 loss 575.0533447265625
Epoch 11 loss 500.1458740234375
Epoch 12 loss 407.8463439941406
Epoch 13 loss 297.6308288574219
Epoch 14 loss 345.1822509765625
Epoch 15 loss 240.25511169433594
Epoch 16 loss 265.2943420410156
Epoch 17 loss 577.3289184570312
Epoch 18 loss 467.02001953125
Epoch 19 loss 332.3491516113281
Epoch 20 loss 290.24346923828125
Epoch 21 loss 181.59149169921875
Epoch 22 loss 192.1576690673828
Epoch 23 loss 389.69793701171875
Epoch 24 loss 233.43052673339844
Epoch 25 loss 319.5426940917969
Epoch 26 loss 210.56146240234375
Epoch 27 loss 342.1963806152344
Epoch 28 loss 204.6193084716797
Epoch 29 loss 278.239501953125
Epoch 30 loss 181.6021728515625
Epoch 31 loss 303.4277038574219
Epoch 32 loss 283.0740966796875
Epoch 33 loss 316.029296875
Epoch 34 loss 237.45755004882812
Epoch 35 loss 269.33526611328125
Epoch 36 loss 202.3853759765625
Epoch 37 loss 212.90057373046875
Epoch 38 loss 302.89825439453125
Epoch 39 loss 147.9897918701172
Epoch 40 loss 234.08523559570312
Epoch 41 loss 190.5545196533203
Epoch 42 loss 230.5287628173828
Epoch 43 loss 229.5200653076172
Epoch 44 loss 271.9880065917969
Epoch 45 loss 245.05751037597656
Epoch 46 loss 308.7124938964844
Epoch 47 loss 283.89068603515625
Epoch 48 loss 165.0941162109375
Epoch 49 loss 227.38197326660156
Epoch 50 loss 391.54486083984375
Epoch 51 loss 214.3236083984375
Epoch 52 loss 202.37530517578125
Epoch 53 loss 205.20681762695312
Epoch 54 loss 300.821533203125
Epoch 55 loss 219.86143493652344
Epoch 56 loss 185.58367919921875
Epoch 57 loss 259.67291259765625
Epoch 58 loss 150.0941162109375
Epoch 59 loss 264.1849365234375
Epoch 60 loss 206.94015502929688
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 147.98982142525415, 'MSE - std': 0.0, 'R2 - mean': 0.8554417758480639, 'R2 - std': 0.0} 
 

In get_device
Using dim 32 and batch size 128
Epoch 0 loss 1186.529541015625
Epoch 1 loss 1130.9891357421875
Epoch 2 loss 1082.5762939453125
Epoch 3 loss 1052.51904296875
Epoch 4 loss 1054.2298583984375
Epoch 5 loss 1060.15234375
Epoch 6 loss 990.52587890625
Epoch 7 loss 792.806396484375
Epoch 8 loss 663.988525390625
Epoch 9 loss 550.0236206054688
Epoch 10 loss 465.8760681152344
Epoch 11 loss 486.4344482421875
Epoch 12 loss 297.1733703613281
Epoch 13 loss 691.3705444335938
Epoch 14 loss 477.14306640625
Epoch 15 loss 709.6163330078125
Epoch 16 loss 263.8127746582031
Epoch 17 loss 230.57362365722656
Epoch 18 loss 205.21250915527344
Epoch 19 loss 294.5264587402344
Epoch 20 loss 317.8349304199219
Epoch 21 loss 234.75003051757812
Epoch 22 loss 233.97010803222656
Epoch 23 loss 182.49603271484375
Epoch 24 loss 131.54737854003906
Epoch 25 loss 206.32388305664062
Epoch 26 loss 670.8980102539062
Epoch 27 loss 150.37705993652344
Epoch 28 loss 209.31057739257812
Epoch 29 loss 165.09103393554688
Epoch 30 loss 257.9495849609375
Epoch 31 loss 214.40135192871094
Epoch 32 loss 296.6383056640625
Epoch 33 loss 307.7555847167969
Epoch 34 loss 159.84400939941406
Epoch 35 loss 268.85333251953125
Epoch 36 loss 180.11790466308594
Epoch 37 loss 267.77301025390625
Epoch 38 loss 132.9428253173828
Epoch 39 loss 436.5887145996094
Epoch 40 loss 137.41346740722656
Epoch 41 loss 345.3641662597656
Epoch 42 loss 94.96321868896484
Epoch 43 loss 165.62741088867188
Epoch 44 loss 113.84274291992188
Epoch 45 loss 235.69244384765625
Epoch 46 loss 236.53488159179688
Epoch 47 loss 148.1459503173828
Epoch 48 loss 155.89292907714844
Epoch 49 loss 108.07513427734375
Epoch 50 loss 81.81326293945312
Epoch 51 loss 130.90560913085938
Epoch 52 loss 135.3219757080078
Epoch 53 loss 100.87334442138672
Epoch 54 loss 100.1028823852539
Epoch 55 loss 169.0771484375
Epoch 56 loss 169.5393829345703
Epoch 57 loss 224.82376098632812
Epoch 58 loss 109.36454010009766
Epoch 59 loss 233.6807861328125
Epoch 60 loss 87.66743469238281
Epoch 61 loss 101.66993713378906
Epoch 62 loss 219.61740112304688
Epoch 63 loss 111.5867691040039
Epoch 64 loss 115.39280700683594
Epoch 65 loss 178.54917907714844
Epoch 66 loss 360.9877624511719
Epoch 67 loss 142.91453552246094
Epoch 68 loss 124.0763931274414
Epoch 69 loss 135.72854614257812
Epoch 70 loss 97.74272155761719
Epoch 71 loss 96.66783142089844
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 114.90154302674276, 'MSE - std': 33.088278398511385, 'R2 - mean': 0.8887650422122987, 'R2 - std': 0.03332326636423477} 
 

In get_device
Using dim 32 and batch size 128
Epoch 0 loss 2694.019775390625
Epoch 1 loss 2624.7802734375
Epoch 2 loss 2551.843505859375
Epoch 3 loss 2484.9033203125
Epoch 4 loss 2451.233154296875
Epoch 5 loss 2442.53271484375
Epoch 6 loss 2381.9384765625
Epoch 7 loss 2120.698974609375
Epoch 8 loss 1841.29296875
Epoch 9 loss 1508.799560546875
Epoch 10 loss 1257.983642578125
Epoch 11 loss 1073.966064453125
Epoch 12 loss 1048.2686767578125
Epoch 13 loss 903.5808715820312
Epoch 14 loss 759.9188232421875
Epoch 15 loss 783.7141723632812
Epoch 16 loss 694.698486328125
Epoch 17 loss 713.5206909179688
Epoch 18 loss 484.5353088378906
Epoch 19 loss 666.0503540039062
Epoch 20 loss 532.915283203125
Epoch 21 loss 615.6271362304688
Epoch 22 loss 522.66943359375
Epoch 23 loss 455.6765441894531
Epoch 24 loss 375.5383605957031
Epoch 25 loss 505.6439514160156
Epoch 26 loss 389.6920166015625
Epoch 27 loss 469.29290771484375
Epoch 28 loss 332.46923828125
Epoch 29 loss 537.2264404296875
Epoch 30 loss 570.277587890625
Epoch 31 loss 698.98388671875
Epoch 32 loss 316.9344482421875
Epoch 33 loss 366.31878662109375
Epoch 34 loss 372.182373046875
Epoch 35 loss 885.5216674804688
Epoch 36 loss 640.6214599609375
Epoch 37 loss 427.31072998046875
Epoch 38 loss 717.8532104492188
Epoch 39 loss 659.7874755859375
Epoch 40 loss 499.33489990234375
Epoch 41 loss 450.6656188964844
Epoch 42 loss 835.6279907226562
Epoch 43 loss 543.0044555664062
Epoch 44 loss 400.1535339355469
Epoch 45 loss 509.58135986328125
Epoch 46 loss 378.4147033691406
Epoch 47 loss 339.9834289550781
Epoch 48 loss 340.2493896484375
Epoch 49 loss 476.2838134765625
Epoch 50 loss 368.0240173339844
Epoch 51 loss 242.183349609375
Epoch 52 loss 312.1472473144531
Epoch 53 loss 571.632568359375
Epoch 54 loss 319.8526916503906
Epoch 55 loss 361.935546875
Epoch 56 loss 500.73101806640625
Epoch 57 loss 259.6509094238281
Epoch 58 loss 490.6190490722656
Epoch 59 loss 320.1354064941406
Epoch 60 loss 215.80323791503906
Epoch 61 loss 218.277587890625
Epoch 62 loss 478.2769470214844
Epoch 63 loss 281.440185546875
Epoch 64 loss 393.63739013671875
Epoch 65 loss 323.4671936035156
Epoch 66 loss 349.2040100097656
Epoch 67 loss 433.44976806640625
Epoch 68 loss 389.83660888671875
Epoch 69 loss 302.9823913574219
Epoch 70 loss 229.4384765625
Epoch 71 loss 295.341796875
Epoch 72 loss 304.01397705078125
Epoch 73 loss 212.5703582763672
Epoch 74 loss 312.402099609375
Epoch 75 loss 197.86993408203125
Epoch 76 loss 537.6573486328125
Epoch 77 loss 167.96766662597656
Epoch 78 loss 396.26544189453125
Epoch 79 loss 332.2741394042969
Epoch 80 loss 263.9877624511719
Epoch 81 loss 263.6595153808594
Epoch 82 loss 318.56011962890625
Epoch 83 loss 309.9347839355469
Epoch 84 loss 209.5014190673828
Epoch 85 loss 315.2438049316406
Epoch 86 loss 272.7743225097656
Epoch 87 loss 181.3241729736328
Epoch 88 loss 289.0805969238281
Epoch 89 loss 226.62400817871094
Epoch 90 loss 228.9775390625
Epoch 91 loss 333.2759704589844
Epoch 92 loss 283.93597412109375
Epoch 93 loss 250.0576171875
Epoch 94 loss 239.5354766845703
Epoch 95 loss 315.3209228515625
Epoch 96 loss 304.1747741699219
Epoch 97 loss 245.31573486328125
Epoch 98 loss 241.83262634277344
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 132.59026199723016, 'MSE - std': 36.81943783590433, 'R2 - mean': 0.9029900948084677, 'R2 - std': 0.0338378136140922} 
 

In get_device
Using dim 32 and batch size 128
Epoch 0 loss 1969.7261962890625
Epoch 1 loss 1892.8551025390625
Epoch 2 loss 1814.60205078125
Epoch 3 loss 1753.6014404296875
Epoch 4 loss 1722.3148193359375
Epoch 5 loss 1667.100341796875
Epoch 6 loss 1531.3055419921875
Epoch 7 loss 1359.0245361328125
Epoch 8 loss 1055.9271240234375
Epoch 9 loss 838.5466918945312
Epoch 10 loss 936.4775390625
Epoch 11 loss 704.641357421875
Epoch 12 loss 574.6976928710938
Epoch 13 loss 613.8323364257812
Epoch 14 loss 713.9782104492188
Epoch 15 loss 771.4608764648438
Epoch 16 loss 536.69873046875
Epoch 17 loss 568.8106079101562
Epoch 18 loss 861.7483520507812
Epoch 19 loss 935.9883422851562
Epoch 20 loss 502.8882141113281
Epoch 21 loss 346.612060546875
Epoch 22 loss 460.6898193359375
Epoch 23 loss 495.0155944824219
Epoch 24 loss 427.5447998046875
Epoch 25 loss 295.2552795410156
Epoch 26 loss 422.8385009765625
Epoch 27 loss 506.1990966796875
Epoch 28 loss 273.7348937988281
Epoch 29 loss 294.8741149902344
Epoch 30 loss 335.5703430175781
Epoch 31 loss 396.6578674316406
Epoch 32 loss 298.4027404785156
Epoch 33 loss 235.2635955810547
Epoch 34 loss 478.9585266113281
Epoch 35 loss 269.40460205078125
Epoch 36 loss 436.66815185546875
Epoch 37 loss 307.07275390625
Epoch 38 loss 286.14605712890625
Epoch 39 loss 595.3807373046875
Epoch 40 loss 198.2137451171875
Epoch 41 loss 243.36917114257812
Epoch 42 loss 198.1131591796875
Epoch 43 loss 247.4912109375
Epoch 44 loss 283.44873046875
Epoch 45 loss 201.27294921875
Epoch 46 loss 269.20257568359375
Epoch 47 loss 248.36863708496094
Epoch 48 loss 173.5576934814453
Epoch 49 loss 137.40379333496094
Epoch 50 loss 180.71896362304688
Epoch 51 loss 372.4071350097656
Epoch 52 loss 285.315673828125
Epoch 53 loss 284.2193603515625
Epoch 54 loss 208.01593017578125
Epoch 55 loss 199.8767852783203
Epoch 56 loss 181.2425994873047
Epoch 57 loss 168.26136779785156
Epoch 58 loss 138.97161865234375
Epoch 59 loss 273.6106872558594
Epoch 60 loss 224.8994140625
Epoch 61 loss 206.2852783203125
Epoch 62 loss 142.66470336914062
Epoch 63 loss 318.2397766113281
Epoch 64 loss 702.184326171875
Epoch 65 loss 187.25772094726562
Epoch 66 loss 274.09454345703125
Epoch 67 loss 190.59133911132812
Epoch 68 loss 205.73504638671875
Epoch 69 loss 331.64813232421875
Epoch 70 loss 190.32525634765625
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 133.79365001339738, 'MSE - std': 31.9546190724656, 'R2 - mean': 0.9073104500768554, 'R2 - std': 0.03024474552003682} 
 

In get_device
Using dim 32 and batch size 128
Epoch 0 loss 2401.2109375
Epoch 1 loss 2335.671630859375
Epoch 2 loss 2264.30810546875
Epoch 3 loss 2193.19189453125
Epoch 4 loss 2147.044189453125
Epoch 5 loss 2137.9130859375
Epoch 6 loss 2132.282958984375
Epoch 7 loss 2061.519775390625
Epoch 8 loss 1784.819091796875
Epoch 9 loss 1526.001953125
Epoch 10 loss 1237.6688232421875
Epoch 11 loss 951.2380981445312
Epoch 12 loss 860.1021118164062
Epoch 13 loss 796.0244750976562
Epoch 14 loss 781.8037109375
Epoch 15 loss 1054.7667236328125
Epoch 16 loss 750.4137573242188
Epoch 17 loss 624.6730346679688
Epoch 18 loss 643.1780395507812
Epoch 19 loss 517.4550170898438
Epoch 20 loss 611.882568359375
Epoch 21 loss 733.7265014648438
Epoch 22 loss 480.5015563964844
Epoch 23 loss 517.1339111328125
Epoch 24 loss 708.0751953125
Epoch 25 loss 482.654296875
Epoch 26 loss 399.0299987792969
Epoch 27 loss 346.5441589355469
Epoch 28 loss 441.4357604980469
Epoch 29 loss 383.30029296875
Epoch 30 loss 382.55950927734375
Epoch 31 loss 375.0752868652344
Epoch 32 loss 347.37164306640625
Epoch 33 loss 466.8476257324219
Epoch 34 loss 450.789794921875
Epoch 35 loss 685.2398681640625
Epoch 36 loss 352.7764892578125
Epoch 37 loss 373.3177185058594
Epoch 38 loss 372.8485107421875
Epoch 39 loss 276.3260192871094
Epoch 40 loss 292.8513488769531
Epoch 41 loss 305.1891174316406
Epoch 42 loss 284.6695861816406
Epoch 43 loss 364.4397888183594
Epoch 44 loss 379.66217041015625
Epoch 45 loss 317.7283020019531
Epoch 46 loss 556.9745483398438
Epoch 47 loss 365.2782287597656
Epoch 48 loss 391.92449951171875
Epoch 49 loss 403.3860168457031
Epoch 50 loss 304.8854064941406
Epoch 51 loss 332.6872863769531
Epoch 52 loss 282.1288146972656
Epoch 53 loss 271.5529479980469
Epoch 54 loss 256.91619873046875
Epoch 55 loss 420.2580871582031
Epoch 56 loss 337.35028076171875
Epoch 57 loss 371.6390686035156
Epoch 58 loss 285.27447509765625
Epoch 59 loss 412.2268371582031
Epoch 60 loss 289.8535461425781
Epoch 61 loss 316.2484130859375
Epoch 62 loss 393.1817932128906
Epoch 63 loss 261.0429382324219
Epoch 64 loss 232.00279235839844
Epoch 65 loss 288.33685302734375
Epoch 66 loss 286.2808837890625
Epoch 67 loss 296.1446228027344
Epoch 68 loss 552.5191040039062
Epoch 69 loss 393.4429016113281
Epoch 70 loss 341.7100830078125
Epoch 71 loss 331.7356872558594
Epoch 72 loss 269.1053466796875
Epoch 73 loss 256.2027893066406
Epoch 74 loss 370.0610046386719
Epoch 75 loss 574.5305786132812
Epoch 76 loss 188.71109008789062
Epoch 77 loss 340.59124755859375
Epoch 78 loss 205.9982147216797
Epoch 79 loss 232.90963745117188
Epoch 80 loss 171.1616973876953
Epoch 81 loss 179.0572509765625
Epoch 82 loss 176.62115478515625
Epoch 83 loss 348.9665222167969
Epoch 84 loss 185.75926208496094
Epoch 85 loss 255.35450744628906
Epoch 86 loss 211.55116271972656
Epoch 87 loss 258.10064697265625
Epoch 88 loss 223.7814178466797
Epoch 89 loss 171.44410705566406
Epoch 90 loss 186.7355194091797
Epoch 91 loss 269.8221740722656
Epoch 92 loss 148.95547485351562
Epoch 93 loss 340.2516174316406
Epoch 94 loss 185.88064575195312
Epoch 95 loss 295.91851806640625
Epoch 96 loss 157.4956512451172
Epoch 97 loss 196.9361114501953
Epoch 98 loss 183.75083923339844
Epoch 99 loss 151.40560913085938
Saved Losses
{'MSE - mean': 136.82602464325637, 'MSE - std': 29.2174490268462, 'R2 - mean': 0.9119212890250281, 'R2 - std': 0.028580326248686862} 
 

Results After CV: {'MSE - mean': 136.82602464325637, 'MSE - std': 29.2174490268462, 'R2 - mean': 0.9119212890250281, 'R2 - std': 0.028580326248686862}
Train time: 225.97902930419997
Inference time: 0.251741309199997
Finished cross validation
Trial 0 finished with value: 136.82602464325637 and parameters: {'dim': 32, 'depth': 12, 'heads': 4, 'dropout': 0.7}. Best is trial 0 with value: 136.82602464325637.
In get_device
Using dim 128 and batch size 128
In get_device
Using dim 128 and batch size 128
Trial 1 failed with parameters: {'dim': 128, 'depth': 2, 'heads': 4, 'dropout': 0} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 4.44 MiB is free. Including non-PyTorch memory, this process has 7.78 GiB memory in use. Of the allocated memory 7.61 GiB is allocated by PyTorch, and 37.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 132, in fit
    optimizer.step()
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/optim/adamw.py", line 216, in step
    has_complex = self._init_group(
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/optim/adamw.py", line 155, in _init_group
    state["exp_avg"] = torch.zeros_like(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 4.44 MiB is free. Including non-PyTorch memory, this process has 7.78 GiB memory in use. Of the allocated memory 7.61 GiB is allocated by PyTorch, and 37.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Trial 1 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/sensory.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/sensory.yml', data_parallel=False, dataset='Sensory', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=30, nominal_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], num_classes=1, num_features=11, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=False, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Sensory...
Dataset loaded!
(576, 11)
args.num_features: 36
args.cat_idx: []
New Shape: (576, 36)
A new study created in RDB with name: SAINT_Sensory
In get_device
Using dim 256 and batch size 128
In get_device
Using dim 256 and batch size 128
Trial 0 failed with parameters: {'dim': 256, 'depth': 2, 'heads': 4, 'dropout': 0.3} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 7.79 GiB of which 920.44 MiB is free. Including non-PyTorch memory, this process has 6.88 GiB memory in use. Of the allocated memory 6.77 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 75, in fit
    self.model.to(self.device)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1174, in to
    return self._apply(convert)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 780, in _apply
    module._apply(fn)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 780, in _apply
    module._apply(fn)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 780, in _apply
    module._apply(fn)
  [Previous line repeated 5 more times]
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 805, in _apply
    param_applied = fn(param)
  File "/home/mburu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1160, in convert
    return t.to(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 7.79 GiB of which 920.44 MiB is free. Including non-PyTorch memory, this process has 6.88 GiB memory in use. Of the allocated memory 6.77 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/moneyball.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/moneyball.yml', data_parallel=False, dataset='Moneyball', direction='minimize', dropna_idx=[9, 10, 12, 13], early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=30, nominal_idx=[0, 1, 8], num_classes=1, num_features=14, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Moneyball...
Dataset loaded!
(1232, 10)
Scaling the data...
args.num_features: 50
args.cat_idx: []
New Shape: (1232, 50)
A new study created in RDB with name: SAINT_Moneyball
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514343.0
Epoch 1 loss 511902.65625
Epoch 2 loss 508453.53125
Epoch 3 loss 502882.8125
Epoch 4 loss 493706.84375
Epoch 5 loss 477350.5
Epoch 6 loss 447065.1875
Epoch 7 loss 395362.09375
Epoch 8 loss 319284.46875
Epoch 9 loss 222317.28125
Epoch 10 loss 120302.9609375
Epoch 11 loss 42486.3125
Epoch 12 loss 11129.3017578125
Epoch 13 loss 8850.302734375
Epoch 14 loss 8938.9052734375
Epoch 15 loss 8559.3994140625
Epoch 16 loss 8537.1640625
Epoch 17 loss 8511.888671875
Epoch 18 loss 8318.4130859375
Epoch 19 loss 6156.048828125
Epoch 20 loss 3967.075927734375
Epoch 21 loss 2678.74609375
Epoch 22 loss 2177.0986328125
Epoch 23 loss 2433.212646484375
Epoch 24 loss 1938.8363037109375
Epoch 25 loss 1703.715087890625
Epoch 26 loss 1704.025146484375
Epoch 27 loss 1898.827880859375
Epoch 28 loss 1767.852783203125
Epoch 29 loss 1387.458251953125
Epoch 30 loss 1805.2100830078125
Epoch 31 loss 1312.3538818359375
Epoch 32 loss 1223.889404296875
Epoch 33 loss 1135.8876953125
Epoch 34 loss 1709.8690185546875
Epoch 35 loss 1153.9921875
Epoch 36 loss 1509.39453125
Epoch 37 loss 1573.1766357421875
Epoch 38 loss 1006.6622924804688
Epoch 39 loss 1228.4627685546875
Epoch 40 loss 967.3870849609375
Epoch 41 loss 1010.7683715820312
Epoch 42 loss 953.1100463867188
Epoch 43 loss 1367.8441162109375
Epoch 44 loss 1098.493896484375
Epoch 45 loss 888.4697875976562
Epoch 46 loss 926.3322143554688
Epoch 47 loss 984.7857666015625
Epoch 48 loss 851.641845703125
Epoch 49 loss 830.7443237304688
Epoch 50 loss 917.096923828125
Epoch 51 loss 822.8060913085938
Epoch 52 loss 812.2714233398438
Epoch 53 loss 913.7692260742188
Epoch 54 loss 805.1981201171875
Epoch 55 loss 865.996337890625
Epoch 56 loss 841.7263793945312
Epoch 57 loss 843.4622192382812
Epoch 58 loss 849.4237670898438
Epoch 59 loss 937.80859375
Epoch 60 loss 985.078369140625
Epoch 61 loss 1254.8408203125
Epoch 62 loss 885.3207397460938
Epoch 63 loss 720.3676147460938
Epoch 64 loss 1069.42041015625
Epoch 65 loss 776.2100219726562
Epoch 66 loss 777.4161376953125
Epoch 67 loss 790.940673828125
Epoch 68 loss 1095.9395751953125
Epoch 69 loss 980.950439453125
Epoch 70 loss 781.7131958007812
Epoch 71 loss 709.3593139648438
Epoch 72 loss 760.0145874023438
Epoch 73 loss 763.9842529296875
Epoch 74 loss 840.6367797851562
Epoch 75 loss 938.1058959960938
Epoch 76 loss 843.766357421875
Epoch 77 loss 761.1285400390625
Epoch 78 loss 789.2030029296875
Epoch 79 loss 667.5140991210938
Epoch 80 loss 658.1823120117188
Epoch 81 loss 671.927978515625
Epoch 82 loss 661.5686645507812
Epoch 83 loss 810.1940307617188
Epoch 84 loss 1052.650146484375
Epoch 85 loss 1579.4759521484375
Epoch 86 loss 778.09375
Epoch 87 loss 988.1534423828125
Epoch 88 loss 797.148193359375
Epoch 89 loss 698.2369384765625
Epoch 90 loss 737.6767578125
Epoch 91 loss 662.7985229492188
Epoch 92 loss 745.9678344726562
Epoch 93 loss 654.5262451171875
Epoch 94 loss 682.2205810546875
Epoch 95 loss 638.798095703125
Epoch 96 loss 653.1163940429688
Epoch 97 loss 751.1485595703125
Epoch 98 loss 900.4683837890625
Epoch 99 loss 1004.5325927734375
Saved Losses
{'MSE - mean': 638.7981298494074, 'MSE - std': 0.0, 'R2 - mean': 0.9257263305101475, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 521874.96875
Epoch 1 loss 519529.71875
Epoch 2 loss 516046.0625
Epoch 3 loss 510549.125
Epoch 4 loss 501372.40625
Epoch 5 loss 484487.5625
Epoch 6 loss 452948.5
Epoch 7 loss 399880.34375
Epoch 8 loss 321044.34375
Epoch 9 loss 221389.515625
Epoch 10 loss 117695.0625
Epoch 11 loss 40247.90234375
Epoch 12 loss 10099.87109375
Epoch 13 loss 7743.552734375
Epoch 14 loss 7799.56103515625
Epoch 15 loss 7631.62890625
Epoch 16 loss 7611.4970703125
Epoch 17 loss 7576.0791015625
Epoch 18 loss 7269.65185546875
Epoch 19 loss 6438.37548828125
Epoch 20 loss 5713.85693359375
Epoch 21 loss 4879.94189453125
Epoch 22 loss 3211.146728515625
Epoch 23 loss 2331.002685546875
Epoch 24 loss 1992.7947998046875
Epoch 25 loss 1702.73095703125
Epoch 26 loss 1435.199951171875
Epoch 27 loss 1999.5087890625
Epoch 28 loss 1763.1680908203125
Epoch 29 loss 1549.92236328125
Epoch 30 loss 1105.498046875
Epoch 31 loss 2264.832763671875
Epoch 32 loss 1808.3033447265625
Epoch 33 loss 1192.4444580078125
Epoch 34 loss 1090.041015625
Epoch 35 loss 863.9179077148438
Epoch 36 loss 1254.5657958984375
Epoch 37 loss 1023.5362548828125
Epoch 38 loss 901.8944091796875
Epoch 39 loss 1278.98681640625
Epoch 40 loss 881.8684692382812
Epoch 41 loss 819.8145751953125
Epoch 42 loss 954.1925659179688
Epoch 43 loss 884.0224609375
Epoch 44 loss 657.9442749023438
Epoch 45 loss 825.37841796875
Epoch 46 loss 760.438720703125
Epoch 47 loss 800.1303100585938
Epoch 48 loss 687.510009765625
Epoch 49 loss 1403.18212890625
Epoch 50 loss 768.2576293945312
Epoch 51 loss 627.2981567382812
Epoch 52 loss 1054.4439697265625
Epoch 53 loss 671.909912109375
Epoch 54 loss 841.6034545898438
Epoch 55 loss 946.5186157226562
Epoch 56 loss 1415.3172607421875
Epoch 57 loss 977.3649291992188
Epoch 58 loss 1021.90380859375
Epoch 59 loss 624.2039794921875
Epoch 60 loss 664.0260009765625
Epoch 61 loss 638.838134765625
Epoch 62 loss 705.6512451171875
Epoch 63 loss 793.923828125
Epoch 64 loss 720.6341552734375
Epoch 65 loss 683.721923828125
Epoch 66 loss 757.703857421875
Epoch 67 loss 777.4479370117188
Epoch 68 loss 567.8274536132812
Epoch 69 loss 586.4978637695312
Epoch 70 loss 581.4700927734375
Epoch 71 loss 580.8457641601562
Epoch 72 loss 589.0813598632812
Epoch 73 loss 686.7294311523438
Epoch 74 loss 671.9291381835938
Epoch 75 loss 701.5169677734375
Epoch 76 loss 710.1883544921875
Epoch 77 loss 603.4036254882812
Epoch 78 loss 618.81005859375
Epoch 79 loss 565.7775268554688
Epoch 80 loss 572.859130859375
Epoch 81 loss 851.8746337890625
Epoch 82 loss 588.1303100585938
Epoch 83 loss 646.1688842773438
Epoch 84 loss 532.8013916015625
Epoch 85 loss 819.095947265625
Epoch 86 loss 744.1726684570312
Epoch 87 loss 692.87841796875
Epoch 88 loss 601.7521362304688
Epoch 89 loss 632.9786987304688
Epoch 90 loss 853.5283813476562
Epoch 91 loss 553.2793579101562
Epoch 92 loss 602.3131713867188
Epoch 93 loss 625.8392333984375
Epoch 94 loss 825.6576538085938
Epoch 95 loss 590.7621459960938
Epoch 96 loss 607.3942260742188
Epoch 97 loss 521.982421875
Epoch 98 loss 633.4038696289062
Epoch 99 loss 797.3641967773438
Saved Losses
{'MSE - mean': 580.3902467401238, 'MSE - std': 58.407883109283546, 'R2 - mean': 0.9287041413760795, 'R2 - std': 0.002977810865932018} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516029.5
Epoch 1 loss 513904.84375
Epoch 2 loss 510600.03125
Epoch 3 loss 505203.8125
Epoch 4 loss 496241.8125
Epoch 5 loss 480114.53125
Epoch 6 loss 450261.375
Epoch 7 loss 399598.9375
Epoch 8 loss 324407.84375
Epoch 9 loss 227682.171875
Epoch 10 loss 125164.3671875
Epoch 11 loss 45666.21875
Epoch 12 loss 12454.2255859375
Epoch 13 loss 9510.708984375
Epoch 14 loss 9723.6103515625
Epoch 15 loss 9310.6484375
Epoch 16 loss 9330.0966796875
Epoch 17 loss 9294.798828125
Epoch 18 loss 9277.25
Epoch 19 loss 8847.8212890625
Epoch 20 loss 7399.2548828125
Epoch 21 loss 6619.9560546875
Epoch 22 loss 5757.56884765625
Epoch 23 loss 4305.7041015625
Epoch 24 loss 2518.364990234375
Epoch 25 loss 2091.261474609375
Epoch 26 loss 2656.406982421875
Epoch 27 loss 1529.995361328125
Epoch 28 loss 1631.5577392578125
Epoch 29 loss 1804.7642822265625
Epoch 30 loss 1185.769287109375
Epoch 31 loss 1214.467529296875
Epoch 32 loss 1194.5050048828125
Epoch 33 loss 1045.6796875
Epoch 34 loss 1182.0743408203125
Epoch 35 loss 1146.31884765625
Epoch 36 loss 1295.779296875
Epoch 37 loss 1240.1724853515625
Epoch 38 loss 1375.7005615234375
Epoch 39 loss 1685.1243896484375
Epoch 40 loss 858.8622436523438
Epoch 41 loss 1009.6148071289062
Epoch 42 loss 925.537109375
Epoch 43 loss 872.318359375
Epoch 44 loss 1186.2806396484375
Epoch 45 loss 1313.73779296875
Epoch 46 loss 1371.174072265625
Epoch 47 loss 934.8798828125
Epoch 48 loss 1288.762939453125
Epoch 49 loss 1160.2984619140625
Epoch 50 loss 2769.27587890625
Epoch 51 loss 1267.7850341796875
Epoch 52 loss 1222.244873046875
Epoch 53 loss 1020.8861694335938
Epoch 54 loss 859.17822265625
Epoch 55 loss 1362.727294921875
Epoch 56 loss 867.42919921875
Epoch 57 loss 692.2098999023438
Epoch 58 loss 995.1770629882812
Epoch 59 loss 1012.4451904296875
Epoch 60 loss 686.1070556640625
Epoch 61 loss 645.6171264648438
Epoch 62 loss 1045.623779296875
Epoch 63 loss 984.1248779296875
Epoch 64 loss 1101.039306640625
Epoch 65 loss 947.56396484375
Epoch 66 loss 830.9371948242188
Epoch 67 loss 938.7998657226562
Epoch 68 loss 794.986083984375
Epoch 69 loss 1417.6614990234375
Epoch 70 loss 646.9238891601562
Epoch 71 loss 878.0120239257812
Epoch 72 loss 706.919921875
Epoch 73 loss 783.3517456054688
Epoch 74 loss 810.0419921875
Epoch 75 loss 798.4471435546875
Epoch 76 loss 682.7803344726562
Epoch 77 loss 691.6389770507812
Epoch 78 loss 779.02587890625
Epoch 79 loss 619.138916015625
Epoch 80 loss 865.1989135742188
Epoch 81 loss 875.7117309570312
Epoch 82 loss 1160.0478515625
Epoch 83 loss 791.2929077148438
Epoch 84 loss 631.872314453125
Epoch 85 loss 739.3485717773438
Epoch 86 loss 885.4960327148438
Epoch 87 loss 962.0042114257812
Epoch 88 loss 577.67236328125
Epoch 89 loss 545.2489624023438
Epoch 90 loss 785.9142456054688
Epoch 91 loss 607.1127319335938
Epoch 92 loss 798.1536865234375
Epoch 93 loss 578.3810424804688
Epoch 94 loss 592.644775390625
Epoch 95 loss 632.463623046875
Epoch 96 loss 1010.91650390625
Epoch 97 loss 736.517333984375
Epoch 98 loss 988.4495239257812
Epoch 99 loss 956.8385009765625
Saved Losses
{'MSE - mean': 568.6764760149532, 'MSE - std': 50.48510066090996, 'R2 - mean': 0.9329441616073595, 'R2 - std': 0.006470480262353108} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520094.59375
Epoch 1 loss 518634.1875
Epoch 2 loss 516375.125
Epoch 3 loss 512472.21875
Epoch 4 loss 505622.625
Epoch 5 loss 493146.71875
Epoch 6 loss 469222.15625
Epoch 7 loss 426224.3125
Epoch 8 loss 358299.25
Epoch 9 loss 265534.28125
Epoch 10 loss 158756.9375
Epoch 11 loss 65612.046875
Epoch 12 loss 16600.875
Epoch 13 loss 8304.5546875
Epoch 14 loss 8740.3251953125
Epoch 15 loss 8300.2294921875
Epoch 16 loss 8287.6806640625
Epoch 17 loss 8275.580078125
Epoch 18 loss 8247.216796875
Epoch 19 loss 8183.255859375
Epoch 20 loss 7478.48974609375
Epoch 21 loss 5708.1064453125
Epoch 22 loss 3094.85546875
Epoch 23 loss 2720.40869140625
Epoch 24 loss 2295.233154296875
Epoch 25 loss 2146.460693359375
Epoch 26 loss 2037.98681640625
Epoch 27 loss 2138.108154296875
Epoch 28 loss 1600.1064453125
Epoch 29 loss 1898.86376953125
Epoch 30 loss 1375.598388671875
Epoch 31 loss 1920.0364990234375
Epoch 32 loss 1457.9957275390625
Epoch 33 loss 1676.8673095703125
Epoch 34 loss 1198.463134765625
Epoch 35 loss 1268.19970703125
Epoch 36 loss 1938.6307373046875
Epoch 37 loss 969.0464477539062
Epoch 38 loss 1016.582763671875
Epoch 39 loss 962.7137451171875
Epoch 40 loss 932.8530883789062
Epoch 41 loss 1402.1751708984375
Epoch 42 loss 1014.38916015625
Epoch 43 loss 1015.1145629882812
Epoch 44 loss 1065.7916259765625
Epoch 45 loss 929.51318359375
Epoch 46 loss 823.96240234375
Epoch 47 loss 790.0025634765625
Epoch 48 loss 914.1004638671875
Epoch 49 loss 1059.5345458984375
Epoch 50 loss 855.5835571289062
Epoch 51 loss 951.693115234375
Epoch 52 loss 881.68359375
Epoch 53 loss 770.361572265625
Epoch 54 loss 910.810791015625
Epoch 55 loss 702.767822265625
Epoch 56 loss 701.6624755859375
Epoch 57 loss 950.0993041992188
Epoch 58 loss 1151.3685302734375
Epoch 59 loss 954.91015625
Epoch 60 loss 1043.0345458984375
Epoch 61 loss 979.3118896484375
Epoch 62 loss 667.8973999023438
Epoch 63 loss 698.48486328125
Epoch 64 loss 773.1648559570312
Epoch 65 loss 768.0186157226562
Epoch 66 loss 818.8658447265625
Epoch 67 loss 828.6663818359375
Epoch 68 loss 901.5968017578125
Epoch 69 loss 843.690673828125
Epoch 70 loss 839.8525390625
Epoch 71 loss 717.8348388671875
Epoch 72 loss 641.6016235351562
Epoch 73 loss 640.2485961914062
Epoch 74 loss 740.043701171875
Epoch 75 loss 841.098388671875
Epoch 76 loss 1015.7175903320312
Epoch 77 loss 669.3081665039062
Epoch 78 loss 634.0086059570312
Epoch 79 loss 708.962646484375
Epoch 80 loss 723.6436767578125
Epoch 81 loss 1126.295654296875
Epoch 82 loss 649.7005615234375
Epoch 83 loss 792.9545288085938
Epoch 84 loss 663.8321533203125
Epoch 85 loss 635.24072265625
Epoch 86 loss 761.0293579101562
Epoch 87 loss 753.8705444335938
Epoch 88 loss 785.9808959960938
Epoch 89 loss 669.331787109375
Epoch 90 loss 607.3082275390625
Epoch 91 loss 792.9804077148438
Epoch 92 loss 668.18115234375
Epoch 93 loss 619.362548828125
Epoch 94 loss 651.1267700195312
Epoch 95 loss 756.6348876953125
Epoch 96 loss 673.9376220703125
Epoch 97 loss 644.6043701171875
Epoch 98 loss 702.0523071289062
Epoch 99 loss 706.8646850585938
Saved Losses
{'MSE - mean': 578.3344163124797, 'MSE - std': 46.81224705062139, 'R2 - mean': 0.9314278507186091, 'R2 - std': 0.006188532318179699} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515223.21875
Epoch 1 loss 513010.625
Epoch 2 loss 509580.09375
Epoch 3 loss 504043.40625
Epoch 4 loss 494670.6875
Epoch 5 loss 477530.3125
Epoch 6 loss 445638.25
Epoch 7 loss 392281.75
Epoch 8 loss 314112.5625
Epoch 9 loss 215922.359375
Epoch 10 loss 114674.1640625
Epoch 11 loss 39368.80078125
Epoch 12 loss 10208.0302734375
Epoch 13 loss 8218.6044921875
Epoch 14 loss 8236.703125
Epoch 15 loss 7973.5126953125
Epoch 16 loss 7930.93896484375
Epoch 17 loss 7911.36962890625
Epoch 18 loss 7556.2099609375
Epoch 19 loss 6266.98974609375
Epoch 20 loss 5118.080078125
Epoch 21 loss 3744.610595703125
Epoch 22 loss 3016.48193359375
Epoch 23 loss 2825.025390625
Epoch 24 loss 1919.9149169921875
Epoch 25 loss 2209.166015625
Epoch 26 loss 1533.091796875
Epoch 27 loss 1591.8831787109375
Epoch 28 loss 1492.0367431640625
Epoch 29 loss 1652.4097900390625
Epoch 30 loss 1395.5911865234375
Epoch 31 loss 1348.1630859375
Epoch 32 loss 1165.6492919921875
Epoch 33 loss 973.7720947265625
Epoch 34 loss 1024.188720703125
Epoch 35 loss 955.764892578125
Epoch 36 loss 890.4266967773438
Epoch 37 loss 1192.52734375
Epoch 38 loss 823.0459594726562
Epoch 39 loss 946.5894165039062
Epoch 40 loss 1209.6578369140625
Epoch 41 loss 984.5175170898438
Epoch 42 loss 874.9541015625
Epoch 43 loss 883.3202514648438
Epoch 44 loss 915.9229736328125
Epoch 45 loss 1202.6085205078125
Epoch 46 loss 906.9600830078125
Epoch 47 loss 750.6566162109375
Epoch 48 loss 706.6783447265625
Epoch 49 loss 818.7664794921875
Epoch 50 loss 824.0075073242188
Epoch 51 loss 702.119140625
Epoch 52 loss 699.8175659179688
Epoch 53 loss 622.03662109375
Epoch 54 loss 1182.320068359375
Epoch 55 loss 696.8118286132812
Epoch 56 loss 653.1213989257812
Epoch 57 loss 631.6113891601562
Epoch 58 loss 636.072509765625
Epoch 59 loss 608.244140625
Epoch 60 loss 644.1795654296875
Epoch 61 loss 590.75439453125
Epoch 62 loss 709.63671875
Epoch 63 loss 629.6709594726562
Epoch 64 loss 832.4524536132812
Epoch 65 loss 733.4815063476562
Epoch 66 loss 571.9014282226562
Epoch 67 loss 596.0465087890625
Epoch 68 loss 690.3345947265625
Epoch 69 loss 648.9609985351562
Epoch 70 loss 693.4401245117188
Epoch 71 loss 822.4322509765625
Epoch 72 loss 616.7918701171875
Epoch 73 loss 591.978271484375
Epoch 74 loss 609.385009765625
Epoch 75 loss 602.3564453125
Epoch 76 loss 547.8699951171875
Epoch 77 loss 548.8327026367188
Epoch 78 loss 531.1632690429688
Epoch 79 loss 533.201904296875
Epoch 80 loss 550.2588500976562
Epoch 81 loss 519.0184326171875
Epoch 82 loss 762.8961791992188
Epoch 83 loss 656.6959228515625
Epoch 84 loss 651.1056518554688
Epoch 85 loss 705.710693359375
Epoch 86 loss 525.5631103515625
Epoch 87 loss 603.1842041015625
Epoch 88 loss 619.4493408203125
Epoch 89 loss 500.4207763671875
Epoch 90 loss 603.7789306640625
Epoch 91 loss 501.1081237792969
Epoch 92 loss 700.188720703125
Epoch 93 loss 537.40380859375
Epoch 94 loss 531.0743408203125
Epoch 95 loss 577.869873046875
Epoch 96 loss 545.5617065429688
Epoch 97 loss 524.8501586914062
Epoch 98 loss 514.34521484375
Epoch 99 loss 686.7689208984375
Saved Losses
{'MSE - mean': 562.7517657923996, 'MSE - std': 52.19564319046693, 'R2 - mean': 0.9325973114829933, 'R2 - std': 0.006009068124115422} 
 

Results After CV: {'MSE - mean': 562.7517657923996, 'MSE - std': 52.19564319046693, 'R2 - mean': 0.9325973114829933, 'R2 - std': 0.006009068124115422}
Train time: 123.63310909420002
Inference time: 0.1400604391999991
Finished cross validation
Trial 0 finished with value: 562.7517657923996 and parameters: {'dim': 64, 'depth': 6, 'heads': 2, 'dropout': 0.8}. Best is trial 0 with value: 562.7517657923996.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 512502.03125
Epoch 1 loss 509308.1875
Epoch 2 loss 504848.59375
Epoch 3 loss 498357.59375
Epoch 4 loss 488012.46875
Epoch 5 loss 467842.46875
Epoch 6 loss 430666.59375
Epoch 7 loss 371400.4375
Epoch 8 loss 288367.375
Epoch 9 loss 188229.5
Epoch 10 loss 91451.859375
Epoch 11 loss 27949.5234375
Epoch 12 loss 9061.345703125
Epoch 13 loss 9072.1923828125
Epoch 14 loss 8583.9091796875
Epoch 15 loss 8548.169921875
Epoch 16 loss 8507.1005859375
Epoch 17 loss 4119.8330078125
Epoch 18 loss 2635.4541015625
Epoch 19 loss 1887.1336669921875
Epoch 20 loss 1438.820068359375
Epoch 21 loss 1232.8887939453125
Epoch 22 loss 1101.4256591796875
Epoch 23 loss 948.1636352539062
Epoch 24 loss 988.1738891601562
Epoch 25 loss 996.8662719726562
Epoch 26 loss 1310.519287109375
Epoch 27 loss 799.7687377929688
Epoch 28 loss 780.5602416992188
Epoch 29 loss 734.891357421875
Epoch 30 loss 700.7896118164062
Epoch 31 loss 679.7288818359375
Epoch 32 loss 814.580078125
Epoch 33 loss 867.0698852539062
Epoch 34 loss 657.1671142578125
Epoch 35 loss 638.0406494140625
Epoch 36 loss 628.812744140625
Epoch 37 loss 702.4016723632812
Epoch 38 loss 667.2646484375
Epoch 39 loss 730.1156616210938
Epoch 40 loss 633.2603759765625
Epoch 41 loss 677.714599609375
Epoch 42 loss 673.1316528320312
Epoch 43 loss 692.45068359375
Epoch 44 loss 604.9140014648438
Epoch 45 loss 662.0573120117188
Epoch 46 loss 720.3314819335938
Epoch 47 loss 704.0984497070312
Epoch 48 loss 582.232421875
Epoch 49 loss 602.8179321289062
Epoch 50 loss 591.1051635742188
Epoch 51 loss 607.21728515625
Epoch 52 loss 606.937255859375
Epoch 53 loss 578.8291015625
Epoch 54 loss 577.2220458984375
Epoch 55 loss 582.4194946289062
Epoch 56 loss 574.5701293945312
Epoch 57 loss 614.8864135742188
Epoch 58 loss 747.7112426757812
Epoch 59 loss 658.8536376953125
Epoch 60 loss 597.9019775390625
Epoch 61 loss 575.8074340820312
Epoch 62 loss 608.5836181640625
Epoch 63 loss 626.5805053710938
Epoch 64 loss 656.5409545898438
Epoch 65 loss 609.6091918945312
Epoch 66 loss 648.7376098632812
Epoch 67 loss 596.1051635742188
Epoch 68 loss 574.4004516601562
Epoch 69 loss 647.330078125
Epoch 70 loss 752.8074340820312
Epoch 71 loss 610.5571899414062
Epoch 72 loss 656.7888793945312
Epoch 73 loss 703.0653686523438
Epoch 74 loss 570.3538208007812
Epoch 75 loss 628.6057739257812
Epoch 76 loss 687.451904296875
Epoch 77 loss 665.3692016601562
Epoch 78 loss 634.35107421875
Epoch 79 loss 733.2682495117188
Epoch 80 loss 604.3748779296875
Epoch 81 loss 592.6892700195312
Epoch 82 loss 702.8468017578125
Epoch 83 loss 705.9415893554688
Epoch 84 loss 613.6932983398438
Epoch 85 loss 610.3824462890625
Epoch 86 loss 614.459716796875
Epoch 87 loss 609.1039428710938
Epoch 88 loss 612.351318359375
Epoch 89 loss 597.8255615234375
Epoch 90 loss 669.4718017578125
Epoch 91 loss 633.3756713867188
Epoch 92 loss 627.7234497070312
Epoch 93 loss 619.1823120117188
Epoch 94 loss 631.704345703125
Epoch 95 loss 767.2845458984375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 570.3536710277057, 'MSE - std': 0.0, 'R2 - mean': 0.9336844331960983, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523548.71875
Epoch 1 loss 521921.5
Epoch 2 loss 519204.6875
Epoch 3 loss 514535.40625
Epoch 4 loss 506602.1875
Epoch 5 loss 492154.25
Epoch 6 loss 464968.8125
Epoch 7 loss 419484.5625
Epoch 8 loss 351096.65625
Epoch 9 loss 260082.5
Epoch 10 loss 156650.5
Epoch 11 loss 65997.3359375
Epoch 12 loss 17165.544921875
Epoch 13 loss 7659.25244140625
Epoch 14 loss 7638.9091796875
Epoch 15 loss 7709.70849609375
Epoch 16 loss 7519.9296875
Epoch 17 loss 6166.41259765625
Epoch 18 loss 2865.48681640625
Epoch 19 loss 1936.74853515625
Epoch 20 loss 1733.4912109375
Epoch 21 loss 1432.8507080078125
Epoch 22 loss 1158.34619140625
Epoch 23 loss 1019.6866455078125
Epoch 24 loss 796.6773681640625
Epoch 25 loss 906.3287963867188
Epoch 26 loss 724.2534790039062
Epoch 27 loss 670.5155639648438
Epoch 28 loss 671.2507934570312
Epoch 29 loss 745.1231079101562
Epoch 30 loss 592.90283203125
Epoch 31 loss 700.3421020507812
Epoch 32 loss 616.714111328125
Epoch 33 loss 572.4547729492188
Epoch 34 loss 596.860595703125
Epoch 35 loss 593.6928100585938
Epoch 36 loss 500.4781188964844
Epoch 37 loss 478.7330627441406
Epoch 38 loss 511.4197082519531
Epoch 39 loss 670.2166748046875
Epoch 40 loss 499.7479553222656
Epoch 41 loss 609.297607421875
Epoch 42 loss 506.67291259765625
Epoch 43 loss 557.6776733398438
Epoch 44 loss 591.1664428710938
Epoch 45 loss 514.8626708984375
Epoch 46 loss 491.1379089355469
Epoch 47 loss 485.0627746582031
Epoch 48 loss 475.4521789550781
Epoch 49 loss 439.41632080078125
Epoch 50 loss 479.7192687988281
Epoch 51 loss 502.9516906738281
Epoch 52 loss 487.39105224609375
Epoch 53 loss 746.4635620117188
Epoch 54 loss 501.951171875
Epoch 55 loss 488.0310974121094
Epoch 56 loss 458.3653869628906
Epoch 57 loss 480.3640441894531
Epoch 58 loss 466.573486328125
Epoch 59 loss 529.5875244140625
Epoch 60 loss 441.07080078125
Epoch 61 loss 446.5128479003906
Epoch 62 loss 468.9540100097656
Epoch 63 loss 497.45465087890625
Epoch 64 loss 435.1766052246094
Epoch 65 loss 483.9709777832031
Epoch 66 loss 461.8699951171875
Epoch 67 loss 446.0943298339844
Epoch 68 loss 442.5165100097656
Epoch 69 loss 448.4953918457031
Epoch 70 loss 454.6878967285156
Epoch 71 loss 484.58758544921875
Epoch 72 loss 473.8722839355469
Epoch 73 loss 499.9289855957031
Epoch 74 loss 454.4397277832031
Epoch 75 loss 459.04815673828125
Epoch 76 loss 424.65130615234375
Epoch 77 loss 511.0314636230469
Epoch 78 loss 428.3809509277344
Epoch 79 loss 535.44873046875
Epoch 80 loss 460.3607482910156
Epoch 81 loss 447.68353271484375
Epoch 82 loss 490.5771179199219
Epoch 83 loss 571.682373046875
Epoch 84 loss 461.50341796875
Epoch 85 loss 434.265380859375
Epoch 86 loss 439.5039978027344
Epoch 87 loss 563.9046630859375
Epoch 88 loss 493.2096252441406
Epoch 89 loss 477.5328674316406
Epoch 90 loss 451.79248046875
Epoch 91 loss 460.6514892578125
Epoch 92 loss 451.9232177734375
Epoch 93 loss 471.53582763671875
Epoch 94 loss 509.2599182128906
Epoch 95 loss 491.2100830078125
Epoch 96 loss 495.6162414550781
Epoch 97 loss 433.3823547363281
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 497.5023090527732, 'MSE - std': 72.85136197493244, 'R2 - mean': 0.9390526534783874, 'R2 - std': 0.005368220282289116} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514366.3125
Epoch 1 loss 511401.1875
Epoch 2 loss 507079.78125
Epoch 3 loss 500164.0
Epoch 4 loss 488741.90625
Epoch 5 loss 467131.65625
Epoch 6 loss 427952.5625
Epoch 7 loss 366015.78125
Epoch 8 loss 280291.8125
Epoch 9 loss 178336.796875
Epoch 10 loss 83108.46875
Epoch 11 loss 24385.0234375
Epoch 12 loss 9461.6298828125
Epoch 13 loss 9712.240234375
Epoch 14 loss 9258.833984375
Epoch 15 loss 8927.998046875
Epoch 16 loss 3804.597900390625
Epoch 17 loss 3275.159912109375
Epoch 18 loss 1774.6617431640625
Epoch 19 loss 1368.9539794921875
Epoch 20 loss 1139.508544921875
Epoch 21 loss 960.1815185546875
Epoch 22 loss 856.80078125
Epoch 23 loss 803.2424926757812
Epoch 24 loss 824.662841796875
Epoch 25 loss 677.3685302734375
Epoch 26 loss 775.0962524414062
Epoch 27 loss 718.4647827148438
Epoch 28 loss 705.88525390625
Epoch 29 loss 641.9860229492188
Epoch 30 loss 599.0588989257812
Epoch 31 loss 695.1448974609375
Epoch 32 loss 714.5662841796875
Epoch 33 loss 1415.8426513671875
Epoch 34 loss 773.9193725585938
Epoch 35 loss 704.806396484375
Epoch 36 loss 630.7653198242188
Epoch 37 loss 567.9625854492188
Epoch 38 loss 727.8466186523438
Epoch 39 loss 596.9820556640625
Epoch 40 loss 552.4263916015625
Epoch 41 loss 525.0499877929688
Epoch 42 loss 841.9671020507812
Epoch 43 loss 630.831298828125
Epoch 44 loss 615.5739135742188
Epoch 45 loss 605.2374267578125
Epoch 46 loss 572.9996948242188
Epoch 47 loss 489.1015625
Epoch 48 loss 550.6302490234375
Epoch 49 loss 560.6187744140625
Epoch 50 loss 586.2567138671875
Epoch 51 loss 532.8743286132812
Epoch 52 loss 534.758056640625
Epoch 53 loss 530.3789672851562
Epoch 54 loss 520.1143188476562
Epoch 55 loss 564.1357421875
Epoch 56 loss 579.5994873046875
Epoch 57 loss 584.1798706054688
Epoch 58 loss 494.90142822265625
Epoch 59 loss 488.7146301269531
Epoch 60 loss 555.2976684570312
Epoch 61 loss 507.80487060546875
Epoch 62 loss 491.98760986328125
Epoch 63 loss 529.0603637695312
Epoch 64 loss 691.4658203125
Epoch 65 loss 515.8753662109375
Epoch 66 loss 550.2549438476562
Epoch 67 loss 522.4111328125
Epoch 68 loss 688.3654174804688
Epoch 69 loss 494.80364990234375
Epoch 70 loss 564.0904541015625
Epoch 71 loss 629.5911865234375
Epoch 72 loss 552.5728759765625
Epoch 73 loss 501.1521301269531
Epoch 74 loss 510.99444580078125
Epoch 75 loss 495.63134765625
Epoch 76 loss 554.5582885742188
Epoch 77 loss 567.3240356445312
Epoch 78 loss 555.0244750976562
Epoch 79 loss 489.23004150390625
Epoch 80 loss 548.2376708984375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 494.5732234228619, 'MSE - std': 59.62694899391658, 'R2 - mean': 0.9418676378049105, 'R2 - std': 0.00592115975548106} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517493.125
Epoch 1 loss 514860.3125
Epoch 2 loss 511091.84375
Epoch 3 loss 505403.5
Epoch 4 loss 496329.90625
Epoch 5 loss 479511.625
Epoch 6 loss 448265.9375
Epoch 7 loss 396994.59375
Epoch 8 loss 323212.15625
Epoch 9 loss 229652.890625
Epoch 10 loss 129677.0625
Epoch 11 loss 49814.91015625
Epoch 12 loss 13110.4296875
Epoch 13 loss 8350.3759765625
Epoch 14 loss 8309.6982421875
Epoch 15 loss 8277.2890625
Epoch 16 loss 8112.494140625
Epoch 17 loss 3954.7666015625
Epoch 18 loss 3468.548095703125
Epoch 19 loss 1957.927734375
Epoch 20 loss 1599.7484130859375
Epoch 21 loss 1644.7528076171875
Epoch 22 loss 1107.9544677734375
Epoch 23 loss 984.5304565429688
Epoch 24 loss 996.7200927734375
Epoch 25 loss 836.0086669921875
Epoch 26 loss 791.8394775390625
Epoch 27 loss 703.7078857421875
Epoch 28 loss 912.55517578125
Epoch 29 loss 994.5848999023438
Epoch 30 loss 738.8335571289062
Epoch 31 loss 682.2080078125
Epoch 32 loss 678.7891235351562
Epoch 33 loss 659.5
Epoch 34 loss 636.1732788085938
Epoch 35 loss 714.066650390625
Epoch 36 loss 695.2492065429688
Epoch 37 loss 599.8453979492188
Epoch 38 loss 613.5983276367188
Epoch 39 loss 585.9168701171875
Epoch 40 loss 614.8682250976562
Epoch 41 loss 592.5755615234375
Epoch 42 loss 649.885009765625
Epoch 43 loss 626.7518310546875
Epoch 44 loss 638.216552734375
Epoch 45 loss 592.7057495117188
Epoch 46 loss 578.8734130859375
Epoch 47 loss 675.3978881835938
Epoch 48 loss 562.3671875
Epoch 49 loss 627.3775024414062
Epoch 50 loss 607.0709838867188
Epoch 51 loss 722.2645874023438
Epoch 52 loss 587.794677734375
Epoch 53 loss 579.5098876953125
Epoch 54 loss 571.6729125976562
Epoch 55 loss 582.266845703125
Epoch 56 loss 711.925048828125
Epoch 57 loss 566.7291259765625
Epoch 58 loss 562.2662353515625
Epoch 59 loss 629.8931884765625
Epoch 60 loss 582.1113891601562
Epoch 61 loss 585.6812744140625
Epoch 62 loss 552.159912109375
Epoch 63 loss 596.2039794921875
Epoch 64 loss 640.5352783203125
Epoch 65 loss 615.7556762695312
Epoch 66 loss 587.9949340820312
Epoch 67 loss 766.5715942382812
Epoch 68 loss 679.2894897460938
Epoch 69 loss 673.4934692382812
Epoch 70 loss 608.3280639648438
Epoch 71 loss 635.97607421875
Epoch 72 loss 596.2850341796875
Epoch 73 loss 586.7284545898438
Epoch 74 loss 556.3915405273438
Epoch 75 loss 795.5853271484375
Epoch 76 loss 864.794921875
Epoch 77 loss 593.8258056640625
Epoch 78 loss 581.0462036132812
Epoch 79 loss 710.95703125
Epoch 80 loss 617.99609375
Epoch 81 loss 566.7277221679688
Epoch 82 loss 618.3767700195312
Epoch 83 loss 584.9073486328125
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 508.96981426818206, 'MSE - std': 57.34383374561751, 'R2 - mean': 0.9397804588095496, 'R2 - std': 0.006274077471108625} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515519.25
Epoch 1 loss 513348.15625
Epoch 2 loss 509935.59375
Epoch 3 loss 504334.09375
Epoch 4 loss 495156.625
Epoch 5 loss 477382.96875
Epoch 6 loss 443613.4375
Epoch 7 loss 388319.875
Epoch 8 loss 308191.34375
Epoch 9 loss 208175.828125
Epoch 10 loss 106473.5234375
Epoch 11 loss 34059.3984375
Epoch 12 loss 9228.8349609375
Epoch 13 loss 8301.2998046875
Epoch 14 loss 7956.69873046875
Epoch 15 loss 7868.70166015625
Epoch 16 loss 4625.2578125
Epoch 17 loss 3198.190185546875
Epoch 18 loss 1783.23193359375
Epoch 19 loss 1408.5120849609375
Epoch 20 loss 1320.3616943359375
Epoch 21 loss 1022.9129028320312
Epoch 22 loss 1002.48486328125
Epoch 23 loss 767.225830078125
Epoch 24 loss 911.342041015625
Epoch 25 loss 724.626708984375
Epoch 26 loss 713.2965698242188
Epoch 27 loss 717.1273803710938
Epoch 28 loss 637.2553100585938
Epoch 29 loss 678.291748046875
Epoch 30 loss 585.8056640625
Epoch 31 loss 674.3867797851562
Epoch 32 loss 618.1724243164062
Epoch 33 loss 624.456787109375
Epoch 34 loss 584.62841796875
Epoch 35 loss 657.4814453125
Epoch 36 loss 553.3212280273438
Epoch 37 loss 508.8720703125
Epoch 38 loss 607.568603515625
Epoch 39 loss 616.7576293945312
Epoch 40 loss 522.3744506835938
Epoch 41 loss 505.5963439941406
Epoch 42 loss 562.3230590820312
Epoch 43 loss 524.6569213867188
Epoch 44 loss 587.654296875
Epoch 45 loss 601.1425170898438
Epoch 46 loss 492.481689453125
Epoch 47 loss 489.2408142089844
Epoch 48 loss 551.6983642578125
Epoch 49 loss 523.9672241210938
Epoch 50 loss 485.8790283203125
Epoch 51 loss 615.072021484375
Epoch 52 loss 569.1422729492188
Epoch 53 loss 558.6433715820312
Epoch 54 loss 471.48480224609375
Epoch 55 loss 627.3705444335938
Epoch 56 loss 541.822265625
Epoch 57 loss 462.8689880371094
Epoch 58 loss 540.972900390625
Epoch 59 loss 504.45196533203125
Epoch 60 loss 489.44989013671875
Epoch 61 loss 482.11468505859375
Epoch 62 loss 476.7156982421875
Epoch 63 loss 494.1175231933594
Epoch 64 loss 515.03857421875
Epoch 65 loss 534.3165893554688
Epoch 66 loss 560.5381469726562
Epoch 67 loss 602.234375
Epoch 68 loss 606.3897094726562
Epoch 69 loss 542.9368286132812
Epoch 70 loss 523.6005859375
Epoch 71 loss 498.8079833984375
Epoch 72 loss 639.0778198242188
Epoch 73 loss 543.154052734375
Epoch 74 loss 587.3621215820312
Epoch 75 loss 470.09588623046875
Epoch 76 loss 600.5416259765625
Epoch 77 loss 478.4754333496094
Epoch 78 loss 484.4078369140625
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 499.74968577106966, 'MSE - std': 54.5040851031285, 'R2 - mean': 0.9402207821582035, 'R2 - std': 0.005680385294701184} 
 

Results After CV: {'MSE - mean': 499.74968577106966, 'MSE - std': 54.5040851031285, 'R2 - mean': 0.9402207821582035, 'R2 - std': 0.005680385294701184}
Train time: 146.69870083339998
Inference time: 0.16066449359998386
Finished cross validation
Trial 1 finished with value: 499.74968577106966 and parameters: {'dim': 64, 'depth': 12, 'heads': 2, 'dropout': 0.2}. Best is trial 1 with value: 499.74968577106966.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 511553.5
Epoch 1 loss 507623.125
Epoch 2 loss 502816.75
Epoch 3 loss 498862.46875
Epoch 4 loss 492005.375
Epoch 5 loss 477305.40625
Epoch 6 loss 448541.75
Epoch 7 loss 399553.8125
Epoch 8 loss 326098.03125
Epoch 9 loss 230692.203125
Epoch 10 loss 128127.0859375
Epoch 11 loss 47200.21875
Epoch 12 loss 12122.7744140625
Epoch 13 loss 8788.638671875
Epoch 14 loss 8606.93359375
Epoch 15 loss 8819.4736328125
Epoch 16 loss 8567.8544921875
Epoch 17 loss 8054.630859375
Epoch 18 loss 4068.48486328125
Epoch 19 loss 2799.861328125
Epoch 20 loss 1965.2515869140625
Epoch 21 loss 1684.4244384765625
Epoch 22 loss 1240.875732421875
Epoch 23 loss 1950.9986572265625
Epoch 24 loss 1086.060302734375
Epoch 25 loss 1022.735595703125
Epoch 26 loss 904.2966918945312
Epoch 27 loss 1099.355712890625
Epoch 28 loss 820.5
Epoch 29 loss 841.5335693359375
Epoch 30 loss 825.611572265625
Epoch 31 loss 763.7623291015625
Epoch 32 loss 833.187744140625
Epoch 33 loss 1070.2164306640625
Epoch 34 loss 850.8423461914062
Epoch 35 loss 775.7908935546875
Epoch 36 loss 996.9873657226562
Epoch 37 loss 723.1403198242188
Epoch 38 loss 693.0534057617188
Epoch 39 loss 832.5748291015625
Epoch 40 loss 808.7825317382812
Epoch 41 loss 735.635498046875
Epoch 42 loss 766.0873413085938
Epoch 43 loss 669.380859375
Epoch 44 loss 690.6204833984375
Epoch 45 loss 785.3677368164062
Epoch 46 loss 694.6873779296875
Epoch 47 loss 649.2411499023438
Epoch 48 loss 620.1989135742188
Epoch 49 loss 676.6060791015625
Epoch 50 loss 671.4953002929688
Epoch 51 loss 655.8614501953125
Epoch 52 loss 643.4854125976562
Epoch 53 loss 639.4683837890625
Epoch 54 loss 584.2348022460938
Epoch 55 loss 580.9370727539062
Epoch 56 loss 619.3634033203125
Epoch 57 loss 600.1375122070312
Epoch 58 loss 684.4244995117188
Epoch 59 loss 651.8048095703125
Epoch 60 loss 632.3645629882812
Epoch 61 loss 713.284912109375
Epoch 62 loss 724.8381958007812
Epoch 63 loss 661.180419921875
Epoch 64 loss 648.6759643554688
Epoch 65 loss 723.2278442382812
Epoch 66 loss 660.2855224609375
Epoch 67 loss 622.6947021484375
Epoch 68 loss 805.1647338867188
Epoch 69 loss 697.1968383789062
Epoch 70 loss 625.3427734375
Epoch 71 loss 634.3070068359375
Epoch 72 loss 718.3168334960938
Epoch 73 loss 664.0303955078125
Epoch 74 loss 754.11474609375
Epoch 75 loss 651.9844970703125
Epoch 76 loss 688.4537353515625
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 580.9370911510639, 'MSE - std': 0.0, 'R2 - mean': 0.9324538888166088, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520105.59375
Epoch 1 loss 516112.5625
Epoch 2 loss 510993.71875
Epoch 3 loss 506113.84375
Epoch 4 loss 496824.4375
Epoch 5 loss 477183.3125
Epoch 6 loss 441153.4375
Epoch 7 loss 383404.125
Epoch 8 loss 301310.40625
Epoch 9 loss 200675.59375
Epoch 10 loss 101144.21875
Epoch 11 loss 32130.19921875
Epoch 12 loss 8873.8603515625
Epoch 13 loss 7753.212890625
Epoch 14 loss 7639.2734375
Epoch 15 loss 7702.25732421875
Epoch 16 loss 6831.248046875
Epoch 17 loss 4641.7177734375
Epoch 18 loss 3865.866455078125
Epoch 19 loss 2098.9482421875
Epoch 20 loss 1515.470703125
Epoch 21 loss 2043.3477783203125
Epoch 22 loss 1145.50830078125
Epoch 23 loss 1106.7655029296875
Epoch 24 loss 946.3545532226562
Epoch 25 loss 1085.766357421875
Epoch 26 loss 810.3317260742188
Epoch 27 loss 809.0360717773438
Epoch 28 loss 692.0200805664062
Epoch 29 loss 640.7215576171875
Epoch 30 loss 832.4367065429688
Epoch 31 loss 663.4497680664062
Epoch 32 loss 625.7079467773438
Epoch 33 loss 823.5353393554688
Epoch 34 loss 598.3659057617188
Epoch 35 loss 671.3682861328125
Epoch 36 loss 877.0518188476562
Epoch 37 loss 878.7586059570312
Epoch 38 loss 656.97216796875
Epoch 39 loss 613.4774780273438
Epoch 40 loss 675.5454711914062
Epoch 41 loss 518.066162109375
Epoch 42 loss 575.006103515625
Epoch 43 loss 556.0467529296875
Epoch 44 loss 562.3663330078125
Epoch 45 loss 549.601318359375
Epoch 46 loss 500.11932373046875
Epoch 47 loss 558.2779541015625
Epoch 48 loss 519.0355224609375
Epoch 49 loss 635.9164428710938
Epoch 50 loss 535.5272216796875
Epoch 51 loss 604.6575317382812
Epoch 52 loss 517.1231079101562
Epoch 53 loss 541.162109375
Epoch 54 loss 638.95947265625
Epoch 55 loss 489.97283935546875
Epoch 56 loss 554.3900756835938
Epoch 57 loss 532.7708740234375
Epoch 58 loss 520.0087280273438
Epoch 59 loss 514.145751953125
Epoch 60 loss 673.913330078125
Epoch 61 loss 541.4063720703125
Epoch 62 loss 534.114501953125
Epoch 63 loss 494.9854431152344
Epoch 64 loss 492.55596923828125
Epoch 65 loss 576.8314819335938
Epoch 66 loss 554.8607788085938
Epoch 67 loss 534.672607421875
Epoch 68 loss 518.9049682617188
Epoch 69 loss 466.28582763671875
Epoch 70 loss 689.6931762695312
Epoch 71 loss 467.33270263671875
Epoch 72 loss 516.13818359375
Epoch 73 loss 570.999267578125
Epoch 74 loss 575.790771484375
Epoch 75 loss 725.85400390625
Epoch 76 loss 775.0103149414062
Epoch 77 loss 474.0920715332031
Epoch 78 loss 521.5526123046875
Epoch 79 loss 643.4017333984375
Epoch 80 loss 643.4927978515625
Epoch 81 loss 510.2636413574219
Epoch 82 loss 517.7103881835938
Epoch 83 loss 497.8704528808594
Epoch 84 loss 453.5606689453125
Epoch 85 loss 541.2718505859375
Epoch 86 loss 480.5063781738281
Epoch 87 loss 523.408447265625
Epoch 88 loss 493.0852966308594
Epoch 89 loss 470.310791015625
Epoch 90 loss 516.5
Epoch 91 loss 497.2532958984375
Epoch 92 loss 548.2312622070312
Epoch 93 loss 723.2930908203125
Epoch 94 loss 488.62847900390625
Epoch 95 loss 476.3430480957031
Epoch 96 loss 549.8098754882812
Epoch 97 loss 473.8615417480469
Epoch 98 loss 522.0314331054688
Epoch 99 loss 490.0946350097656
Saved Losses
{'MSE - mean': 517.2489258434232, 'MSE - std': 63.68816530764076, 'R2 - mean': 0.9365454955142307, 'R2 - std': 0.00409160669762193} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516236.5
Epoch 1 loss 513816.6875
Epoch 2 loss 510199.34375
Epoch 3 loss 506386.71875
Epoch 4 loss 499289.125
Epoch 5 loss 484293.0
Epoch 6 loss 455724.125
Epoch 7 loss 407327.5
Epoch 8 loss 334648.40625
Epoch 9 loss 239179.953125
Epoch 10 loss 135207.9375
Epoch 11 loss 51556.109375
Epoch 12 loss 13775.1357421875
Epoch 13 loss 9416.4140625
Epoch 14 loss 9345.474609375
Epoch 15 loss 9408.177734375
Epoch 16 loss 9278.8798828125
Epoch 17 loss 8047.029296875
Epoch 18 loss 4704.69140625
Epoch 19 loss 3353.169189453125
Epoch 20 loss 2256.92626953125
Epoch 21 loss 1883.3485107421875
Epoch 22 loss 2153.009765625
Epoch 23 loss 1179.26904296875
Epoch 24 loss 961.1701049804688
Epoch 25 loss 945.353759765625
Epoch 26 loss 807.5150756835938
Epoch 27 loss 699.0576171875
Epoch 28 loss 771.2901000976562
Epoch 29 loss 891.535400390625
Epoch 30 loss 863.9172973632812
Epoch 31 loss 841.5831909179688
Epoch 32 loss 839.4337768554688
Epoch 33 loss 611.794921875
Epoch 34 loss 796.09716796875
Epoch 35 loss 691.6801147460938
Epoch 36 loss 707.5361328125
Epoch 37 loss 862.9764404296875
Epoch 38 loss 675.9988403320312
Epoch 39 loss 624.9022827148438
Epoch 40 loss 714.6019287109375
Epoch 41 loss 590.5230102539062
Epoch 42 loss 667.2288818359375
Epoch 43 loss 696.8131103515625
Epoch 44 loss 924.1843872070312
Epoch 45 loss 575.40771484375
Epoch 46 loss 553.5140991210938
Epoch 47 loss 816.0059204101562
Epoch 48 loss 577.0679931640625
Epoch 49 loss 501.46368408203125
Epoch 50 loss 489.61297607421875
Epoch 51 loss 583.177490234375
Epoch 52 loss 553.11962890625
Epoch 53 loss 634.8746948242188
Epoch 54 loss 617.9843139648438
Epoch 55 loss 488.04925537109375
Epoch 56 loss 576.7582397460938
Epoch 57 loss 491.9581604003906
Epoch 58 loss 525.6640625
Epoch 59 loss 634.6553344726562
Epoch 60 loss 611.6464233398438
Epoch 61 loss 607.9437255859375
Epoch 62 loss 545.2308349609375
Epoch 63 loss 491.7652282714844
Epoch 64 loss 478.91259765625
Epoch 65 loss 615.0840454101562
Epoch 66 loss 560.8818359375
Epoch 67 loss 612.9047241210938
Epoch 68 loss 575.915771484375
Epoch 69 loss 556.2276000976562
Epoch 70 loss 521.173583984375
Epoch 71 loss 645.7039794921875
Epoch 72 loss 514.455810546875
Epoch 73 loss 581.7079467773438
Epoch 74 loss 549.2682495117188
Epoch 75 loss 536.8758544921875
Epoch 76 loss 579.6943359375
Epoch 77 loss 589.0555419921875
Epoch 78 loss 549.9542236328125
Epoch 79 loss 664.867431640625
Epoch 80 loss 549.5014038085938
Epoch 81 loss 501.6210021972656
Epoch 82 loss 581.0880126953125
Epoch 83 loss 499.6493835449219
Epoch 84 loss 508.0870666503906
Epoch 85 loss 513.7244873046875
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 504.47009359881355, 'MSE - std': 55.05196370013213, 'R2 - mean': 0.9405472293251614, 'R2 - std': 0.006571801673243119} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518353.5625
Epoch 1 loss 515636.53125
Epoch 2 loss 511500.84375
Epoch 3 loss 507278.875
Epoch 4 loss 500260.5
Epoch 5 loss 484885.0
Epoch 6 loss 455398.03125
Epoch 7 loss 405734.96875
Epoch 8 loss 331150.65625
Epoch 9 loss 233788.71875
Epoch 10 loss 128739.7421875
Epoch 11 loss 46066.36328125
Epoch 12 loss 11568.4248046875
Epoch 13 loss 8433.1962890625
Epoch 14 loss 8333.76171875
Epoch 15 loss 8262.30078125
Epoch 16 loss 7054.4833984375
Epoch 17 loss 4958.10205078125
Epoch 18 loss 3006.4384765625
Epoch 19 loss 2582.51708984375
Epoch 20 loss 1868.121826171875
Epoch 21 loss 1603.3118896484375
Epoch 22 loss 1426.0003662109375
Epoch 23 loss 1761.8995361328125
Epoch 24 loss 1076.0413818359375
Epoch 25 loss 1159.959228515625
Epoch 26 loss 1011.4354248046875
Epoch 27 loss 893.1737670898438
Epoch 28 loss 836.5244750976562
Epoch 29 loss 1166.751708984375
Epoch 30 loss 1069.4498291015625
Epoch 31 loss 1301.4114990234375
Epoch 32 loss 883.9451293945312
Epoch 33 loss 733.8856201171875
Epoch 34 loss 779.5006713867188
Epoch 35 loss 660.6294555664062
Epoch 36 loss 704.4813232421875
Epoch 37 loss 921.9967651367188
Epoch 38 loss 942.7528076171875
Epoch 39 loss 749.6510620117188
Epoch 40 loss 690.3169555664062
Epoch 41 loss 671.0496215820312
Epoch 42 loss 758.3518676757812
Epoch 43 loss 828.8373413085938
Epoch 44 loss 775.773681640625
Epoch 45 loss 628.5247192382812
Epoch 46 loss 621.2452392578125
Epoch 47 loss 628.8531494140625
Epoch 48 loss 595.5824584960938
Epoch 49 loss 584.431396484375
Epoch 50 loss 656.48486328125
Epoch 51 loss 620.9596557617188
Epoch 52 loss 594.3221435546875
Epoch 53 loss 666.7324829101562
Epoch 54 loss 735.0973510742188
Epoch 55 loss 570.74365234375
Epoch 56 loss 733.1246948242188
Epoch 57 loss 734.591064453125
Epoch 58 loss 731.7125854492188
Epoch 59 loss 594.8610229492188
Epoch 60 loss 570.6507568359375
Epoch 61 loss 572.0343017578125
Epoch 62 loss 829.91943359375
Epoch 63 loss 574.4899291992188
Epoch 64 loss 665.7352294921875
Epoch 65 loss 613.2877807617188
Epoch 66 loss 550.7918701171875
Epoch 67 loss 600.3707885742188
Epoch 68 loss 629.7564697265625
Epoch 69 loss 662.8333740234375
Epoch 70 loss 643.6500854492188
Epoch 71 loss 612.1675415039062
Epoch 72 loss 568.0014038085938
Epoch 73 loss 953.3118896484375
Epoch 74 loss 615.7485961914062
Epoch 75 loss 687.1002197265625
Epoch 76 loss 614.8215942382812
Epoch 77 loss 615.4662475585938
Epoch 78 loss 586.7313232421875
Epoch 79 loss 567.741455078125
Epoch 80 loss 604.4081420898438
Epoch 81 loss 589.8519287109375
Epoch 82 loss 623.58740234375
Epoch 83 loss 634.9317626953125
Epoch 84 loss 587.45751953125
Epoch 85 loss 580.5740966796875
Epoch 86 loss 582.3857421875
Epoch 87 loss 660.0911865234375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 516.0505278546841, 'MSE - std': 51.72386686138345, 'R2 - mean': 0.9388313225696746, 'R2 - std': 0.006420626208159646} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513049.46875
Epoch 1 loss 509269.34375
Epoch 2 loss 504195.9375
Epoch 3 loss 499669.5
Epoch 4 loss 491675.15625
Epoch 5 loss 474755.5625
Epoch 6 loss 442649.8125
Epoch 7 loss 389767.40625
Epoch 8 loss 312674.84375
Epoch 9 loss 215360.09375
Epoch 10 loss 114472.3046875
Epoch 11 loss 39564.6640625
Epoch 12 loss 10278.8125
Epoch 13 loss 8190.4296875
Epoch 14 loss 7977.04931640625
Epoch 15 loss 8065.3232421875
Epoch 16 loss 8021.607421875
Epoch 17 loss 7837.61767578125
Epoch 18 loss 4908.0263671875
Epoch 19 loss 3109.035400390625
Epoch 20 loss 2289.7568359375
Epoch 21 loss 1589.75830078125
Epoch 22 loss 1262.0364990234375
Epoch 23 loss 1306.6842041015625
Epoch 24 loss 1095.8614501953125
Epoch 25 loss 1068.177734375
Epoch 26 loss 1054.0498046875
Epoch 27 loss 959.5879516601562
Epoch 28 loss 846.4303588867188
Epoch 29 loss 752.7696533203125
Epoch 30 loss 666.39697265625
Epoch 31 loss 834.7236938476562
Epoch 32 loss 670.4739990234375
Epoch 33 loss 606.6526489257812
Epoch 34 loss 627.2468872070312
Epoch 35 loss 765.632568359375
Epoch 36 loss 564.137939453125
Epoch 37 loss 610.2449340820312
Epoch 38 loss 763.5457153320312
Epoch 39 loss 931.2405395507812
Epoch 40 loss 585.2911376953125
Epoch 41 loss 693.2144165039062
Epoch 42 loss 534.1869506835938
Epoch 43 loss 541.8361206054688
Epoch 44 loss 609.7427978515625
Epoch 45 loss 684.74169921875
Epoch 46 loss 557.60302734375
Epoch 47 loss 564.2239379882812
Epoch 48 loss 602.1065673828125
Epoch 49 loss 719.9088745117188
Epoch 50 loss 529.982177734375
Epoch 51 loss 527.2090454101562
Epoch 52 loss 574.491455078125
Epoch 53 loss 562.2843017578125
Epoch 54 loss 508.9698791503906
Epoch 55 loss 760.0779418945312
Epoch 56 loss 805.8737182617188
Epoch 57 loss 672.1277465820312
Epoch 58 loss 648.6102294921875
Epoch 59 loss 491.7171325683594
Epoch 60 loss 531.7085571289062
Epoch 61 loss 523.9364624023438
Epoch 62 loss 526.5578002929688
Epoch 63 loss 546.0598754882812
Epoch 64 loss 495.29559326171875
Epoch 65 loss 497.1098937988281
Epoch 66 loss 494.2328186035156
Epoch 67 loss 551.563720703125
Epoch 68 loss 566.9302368164062
Epoch 69 loss 619.0008544921875
Epoch 70 loss 939.5826416015625
Epoch 71 loss 553.4246215820312
Epoch 72 loss 540.975830078125
Epoch 73 loss 598.162841796875
Epoch 74 loss 543.856201171875
Epoch 75 loss 573.9381103515625
Epoch 76 loss 634.8936767578125
Epoch 77 loss 530.513671875
Epoch 78 loss 493.1724548339844
Epoch 79 loss 558.91357421875
Epoch 80 loss 545.6674194335938
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 511.18386460065256, 'MSE - std': 47.27604432889727, 'R2 - mean': 0.9387382867906673, 'R2 - std': 0.0057457963198000025} 
 

Results After CV: {'MSE - mean': 511.18386460065256, 'MSE - std': 47.27604432889727, 'R2 - mean': 0.9387382867906673, 'R2 - std': 0.0057457963198000025}
Train time: 150.697908595
Inference time: 0.16208371799989435
Finished cross validation
Trial 2 finished with value: 511.18386460065256 and parameters: {'dim': 256, 'depth': 12, 'heads': 8, 'dropout': 0.3}. Best is trial 1 with value: 499.74968577106966.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515048.1875
Epoch 1 loss 512825.71875
Epoch 2 loss 509310.96875
Epoch 3 loss 503528.84375
Epoch 4 loss 494336.25
Epoch 5 loss 476970.03125
Epoch 6 loss 444563.0
Epoch 7 loss 391549.78125
Epoch 8 loss 315345.34375
Epoch 9 loss 219411.796875
Epoch 10 loss 119576.265625
Epoch 11 loss 43536.4609375
Epoch 12 loss 11670.705078125
Epoch 13 loss 8697.064453125
Epoch 14 loss 8413.16796875
Epoch 15 loss 8177.11279296875
Epoch 16 loss 7241.86572265625
Epoch 17 loss 4666.412109375
Epoch 18 loss 3138.155517578125
Epoch 19 loss 2289.900634765625
Epoch 20 loss 1782.0030517578125
Epoch 21 loss 1539.3143310546875
Epoch 22 loss 1394.283447265625
Epoch 23 loss 1475.1240234375
Epoch 24 loss 1175.8707275390625
Epoch 25 loss 1167.3079833984375
Epoch 26 loss 1078.8626708984375
Epoch 27 loss 1106.7113037109375
Epoch 28 loss 986.5375366210938
Epoch 29 loss 1095.9581298828125
Epoch 30 loss 993.0347290039062
Epoch 31 loss 963.5755004882812
Epoch 32 loss 807.916748046875
Epoch 33 loss 877.6273193359375
Epoch 34 loss 765.6748046875
Epoch 35 loss 874.23828125
Epoch 36 loss 1043.800537109375
Epoch 37 loss 733.8041381835938
Epoch 38 loss 776.434814453125
Epoch 39 loss 767.8146362304688
Epoch 40 loss 707.5535888671875
Epoch 41 loss 721.850341796875
Epoch 42 loss 700.681640625
Epoch 43 loss 767.6624145507812
Epoch 44 loss 677.3213500976562
Epoch 45 loss 663.9243774414062
Epoch 46 loss 674.557861328125
Epoch 47 loss 698.98388671875
Epoch 48 loss 719.9928588867188
Epoch 49 loss 691.5565795898438
Epoch 50 loss 655.2259521484375
Epoch 51 loss 656.1800537109375
Epoch 52 loss 754.2767944335938
Epoch 53 loss 663.4742431640625
Epoch 54 loss 667.392333984375
Epoch 55 loss 653.9666137695312
Epoch 56 loss 704.2153930664062
Epoch 57 loss 625.0286254882812
Epoch 58 loss 668.6777954101562
Epoch 59 loss 627.833251953125
Epoch 60 loss 618.26220703125
Epoch 61 loss 629.5322875976562
Epoch 62 loss 671.4243774414062
Epoch 63 loss 623.1217041015625
Epoch 64 loss 651.9638061523438
Epoch 65 loss 619.565673828125
Epoch 66 loss 710.751220703125
Epoch 67 loss 651.1581420898438
Epoch 68 loss 687.30615234375
Epoch 69 loss 609.172607421875
Epoch 70 loss 648.70458984375
Epoch 71 loss 602.8373413085938
Epoch 72 loss 611.2206420898438
Epoch 73 loss 614.2442016601562
Epoch 74 loss 682.2709350585938
Epoch 75 loss 741.353759765625
Epoch 76 loss 619.4166870117188
Epoch 77 loss 626.4450073242188
Epoch 78 loss 612.6589965820312
Epoch 79 loss 593.6950073242188
Epoch 80 loss 612.1372680664062
Epoch 81 loss 587.177001953125
Epoch 82 loss 607.0413818359375
Epoch 83 loss 609.8829956054688
Epoch 84 loss 629.0440063476562
Epoch 85 loss 593.1292724609375
Epoch 86 loss 585.287841796875
Epoch 87 loss 639.0928955078125
Epoch 88 loss 578.6301879882812
Epoch 89 loss 589.700927734375
Epoch 90 loss 593.5888061523438
Epoch 91 loss 602.145751953125
Epoch 92 loss 623.6459350585938
Epoch 93 loss 588.8482666015625
Epoch 94 loss 633.5040893554688
Epoch 95 loss 583.6124877929688
Epoch 96 loss 601.2739868164062
Epoch 97 loss 586.16943359375
Epoch 98 loss 577.8790893554688
Epoch 99 loss 609.7242431640625
Saved Losses
{'MSE - mean': 577.8788788213814, 'MSE - std': 0.0, 'R2 - mean': 0.932809470088987, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523384.625
Epoch 1 loss 521343.4375
Epoch 2 loss 517969.6875
Epoch 3 loss 512489.125
Epoch 4 loss 503908.09375
Epoch 5 loss 486948.65625
Epoch 6 loss 454490.71875
Epoch 7 loss 400512.78125
Epoch 8 loss 321461.125
Epoch 9 loss 220919.765625
Epoch 10 loss 116882.578125
Epoch 11 loss 39616.84375
Epoch 12 loss 10096.115234375
Epoch 13 loss 7668.8701171875
Epoch 14 loss 7451.93017578125
Epoch 15 loss 7055.45703125
Epoch 16 loss 5546.32421875
Epoch 17 loss 3218.492431640625
Epoch 18 loss 2113.00341796875
Epoch 19 loss 1599.81787109375
Epoch 20 loss 1337.740966796875
Epoch 21 loss 1201.6044921875
Epoch 22 loss 1301.3626708984375
Epoch 23 loss 1120.3785400390625
Epoch 24 loss 933.755615234375
Epoch 25 loss 872.1832885742188
Epoch 26 loss 833.0458374023438
Epoch 27 loss 813.610107421875
Epoch 28 loss 694.5956420898438
Epoch 29 loss 766.33203125
Epoch 30 loss 636.0765380859375
Epoch 31 loss 666.8005981445312
Epoch 32 loss 608.3856201171875
Epoch 33 loss 633.8419799804688
Epoch 34 loss 659.6595458984375
Epoch 35 loss 552.5809936523438
Epoch 36 loss 548.53515625
Epoch 37 loss 536.87744140625
Epoch 38 loss 526.829345703125
Epoch 39 loss 528.71728515625
Epoch 40 loss 505.608154296875
Epoch 41 loss 529.6436767578125
Epoch 42 loss 521.7509765625
Epoch 43 loss 638.9188842773438
Epoch 44 loss 503.3490905761719
Epoch 45 loss 537.093994140625
Epoch 46 loss 495.9476623535156
Epoch 47 loss 536.8102416992188
Epoch 48 loss 481.196044921875
Epoch 49 loss 772.94970703125
Epoch 50 loss 540.80859375
Epoch 51 loss 471.3819580078125
Epoch 52 loss 507.2678527832031
Epoch 53 loss 464.3597717285156
Epoch 54 loss 470.6501159667969
Epoch 55 loss 489.94580078125
Epoch 56 loss 488.3442077636719
Epoch 57 loss 474.9675598144531
Epoch 58 loss 456.6234436035156
Epoch 59 loss 544.2514038085938
Epoch 60 loss 461.9288330078125
Epoch 61 loss 455.3595275878906
Epoch 62 loss 523.1592407226562
Epoch 63 loss 448.1466369628906
Epoch 64 loss 502.7703552246094
Epoch 65 loss 447.8253479003906
Epoch 66 loss 489.8830871582031
Epoch 67 loss 464.0079040527344
Epoch 68 loss 454.50018310546875
Epoch 69 loss 463.8677978515625
Epoch 70 loss 477.5732116699219
Epoch 71 loss 444.3519287109375
Epoch 72 loss 447.3660888671875
Epoch 73 loss 456.82177734375
Epoch 74 loss 460.5798645019531
Epoch 75 loss 545.3031616210938
Epoch 76 loss 441.869384765625
Epoch 77 loss 447.4118957519531
Epoch 78 loss 453.3399353027344
Epoch 79 loss 479.98504638671875
Epoch 80 loss 442.0707092285156
Epoch 81 loss 443.9122619628906
Epoch 82 loss 474.28485107421875
Epoch 83 loss 480.6836242675781
Epoch 84 loss 453.3204040527344
Epoch 85 loss 458.4821472167969
Epoch 86 loss 534.690185546875
Epoch 87 loss 468.06805419921875
Epoch 88 loss 470.855224609375
Epoch 89 loss 450.8382873535156
Epoch 90 loss 447.4049987792969
Epoch 91 loss 446.9991149902344
Epoch 92 loss 532.8604736328125
Epoch 93 loss 454.6768798828125
Epoch 94 loss 512.0108642578125
Epoch 95 loss 454.5434265136719
Epoch 96 loss 446.5263366699219
Epoch 97 loss 447.7735900878906
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 509.8740123342044, 'MSE - std': 68.00486648717694, 'R2 - mean': 0.937488396570165, 'R2 - std': 0.004678926481178014} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516956.03125
Epoch 1 loss 515238.9375
Epoch 2 loss 512147.5
Epoch 3 loss 506844.9375
Epoch 4 loss 498355.8125
Epoch 5 loss 482784.46875
Epoch 6 loss 453582.21875
Epoch 7 loss 405483.09375
Epoch 8 loss 334456.0
Epoch 9 loss 242201.515625
Epoch 10 loss 141242.828125
Epoch 11 loss 57560.3125
Epoch 12 loss 16018.912109375
Epoch 13 loss 9294.951171875
Epoch 14 loss 9374.6318359375
Epoch 15 loss 8965.26171875
Epoch 16 loss 8454.1533203125
Epoch 17 loss 6050.11962890625
Epoch 18 loss 3775.53125
Epoch 19 loss 2545.794189453125
Epoch 20 loss 1950.03125
Epoch 21 loss 1698.070068359375
Epoch 22 loss 1415.4632568359375
Epoch 23 loss 1272.1092529296875
Epoch 24 loss 1482.0308837890625
Epoch 25 loss 1187.3104248046875
Epoch 26 loss 1061.6776123046875
Epoch 27 loss 1088.8966064453125
Epoch 28 loss 906.9815673828125
Epoch 29 loss 844.806396484375
Epoch 30 loss 845.7855834960938
Epoch 31 loss 789.6516723632812
Epoch 32 loss 810.1726684570312
Epoch 33 loss 959.0462036132812
Epoch 34 loss 743.1663208007812
Epoch 35 loss 727.2022094726562
Epoch 36 loss 774.3944091796875
Epoch 37 loss 993.004638671875
Epoch 38 loss 675.6458129882812
Epoch 39 loss 692.56591796875
Epoch 40 loss 661.01318359375
Epoch 41 loss 610.0782470703125
Epoch 42 loss 741.3284301757812
Epoch 43 loss 741.6044921875
Epoch 44 loss 738.4259643554688
Epoch 45 loss 608.1064453125
Epoch 46 loss 572.9677124023438
Epoch 47 loss 574.5257568359375
Epoch 48 loss 735.6231689453125
Epoch 49 loss 567.5538330078125
Epoch 50 loss 588.3609619140625
Epoch 51 loss 597.1019287109375
Epoch 52 loss 519.4785766601562
Epoch 53 loss 666.5397338867188
Epoch 54 loss 515.6051025390625
Epoch 55 loss 561.9114379882812
Epoch 56 loss 572.9522094726562
Epoch 57 loss 519.2655029296875
Epoch 58 loss 513.89404296875
Epoch 59 loss 852.6402587890625
Epoch 60 loss 506.80230712890625
Epoch 61 loss 570.9893188476562
Epoch 62 loss 575.8229370117188
Epoch 63 loss 636.7052612304688
Epoch 64 loss 540.2302856445312
Epoch 65 loss 507.96630859375
Epoch 66 loss 483.6387023925781
Epoch 67 loss 601.6265258789062
Epoch 68 loss 472.0169372558594
Epoch 69 loss 535.6544799804688
Epoch 70 loss 569.26171875
Epoch 71 loss 475.3714599609375
Epoch 72 loss 512.2332763671875
Epoch 73 loss 498.8076477050781
Epoch 74 loss 473.43475341796875
Epoch 75 loss 497.45477294921875
Epoch 76 loss 511.6906433105469
Epoch 77 loss 530.6884765625
Epoch 78 loss 454.9083251953125
Epoch 79 loss 479.3092041015625
Epoch 80 loss 816.704833984375
Epoch 81 loss 563.7689819335938
Epoch 82 loss 597.3565063476562
Epoch 83 loss 479.3671569824219
Epoch 84 loss 535.9932250976562
Epoch 85 loss 522.1902465820312
Epoch 86 loss 580.2406005859375
Epoch 87 loss 668.0770263671875
Epoch 88 loss 476.28460693359375
Epoch 89 loss 595.3462524414062
Epoch 90 loss 462.74090576171875
Epoch 91 loss 449.79827880859375
Epoch 92 loss 557.3827514648438
Epoch 93 loss 552.3955688476562
Epoch 94 loss 454.315673828125
Epoch 95 loss 490.4493713378906
Epoch 96 loss 460.1686706542969
Epoch 97 loss 519.8084106445312
Epoch 98 loss 478.6950378417969
Epoch 99 loss 448.18939208984375
Saved Losses
{'MSE - mean': 489.31245441555615, 'MSE - std': 62.67904944006169, 'R2 - mean': 0.9422760183581959, 'R2 - std': 0.007774158911502983} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519409.71875
Epoch 1 loss 517332.28125
Epoch 2 loss 513864.4375
Epoch 3 loss 508398.5
Epoch 4 loss 500059.0625
Epoch 5 loss 483866.46875
Epoch 6 loss 452542.84375
Epoch 7 loss 400239.25
Epoch 8 loss 323589.53125
Epoch 9 loss 225673.0625
Epoch 10 loss 122542.7890625
Epoch 11 loss 43607.14453125
Epoch 12 loss 11399.2646484375
Epoch 13 loss 8399.779296875
Epoch 14 loss 8128.36572265625
Epoch 15 loss 7879.9072265625
Epoch 16 loss 7211.84521484375
Epoch 17 loss 4266.42431640625
Epoch 18 loss 2920.563232421875
Epoch 19 loss 2014.5274658203125
Epoch 20 loss 1622.291015625
Epoch 21 loss 1495.149169921875
Epoch 22 loss 1311.6888427734375
Epoch 23 loss 1071.1339111328125
Epoch 24 loss 1170.1680908203125
Epoch 25 loss 1054.5767822265625
Epoch 26 loss 960.834716796875
Epoch 27 loss 1289.0233154296875
Epoch 28 loss 866.1455688476562
Epoch 29 loss 777.5701904296875
Epoch 30 loss 865.947265625
Epoch 31 loss 795.8274536132812
Epoch 32 loss 697.697509765625
Epoch 33 loss 687.3805541992188
Epoch 34 loss 828.3638916015625
Epoch 35 loss 724.5285034179688
Epoch 36 loss 678.9403686523438
Epoch 37 loss 772.05126953125
Epoch 38 loss 631.9712524414062
Epoch 39 loss 614.9987182617188
Epoch 40 loss 669.7281494140625
Epoch 41 loss 610.9219360351562
Epoch 42 loss 649.7703247070312
Epoch 43 loss 631.719970703125
Epoch 44 loss 634.184326171875
Epoch 45 loss 587.4514770507812
Epoch 46 loss 679.7879028320312
Epoch 47 loss 570.67822265625
Epoch 48 loss 575.3002319335938
Epoch 49 loss 575.2901611328125
Epoch 50 loss 599.1539306640625
Epoch 51 loss 585.7367553710938
Epoch 52 loss 539.962890625
Epoch 53 loss 764.209228515625
Epoch 54 loss 542.4321899414062
Epoch 55 loss 561.02294921875
Epoch 56 loss 535.6181030273438
Epoch 57 loss 575.82275390625
Epoch 58 loss 692.9349365234375
Epoch 59 loss 526.7050170898438
Epoch 60 loss 657.9299926757812
Epoch 61 loss 613.346923828125
Epoch 62 loss 543.834716796875
Epoch 63 loss 590.3326416015625
Epoch 64 loss 567.2777709960938
Epoch 65 loss 598.284423828125
Epoch 66 loss 667.692626953125
Epoch 67 loss 532.3640747070312
Epoch 68 loss 638.9083862304688
Epoch 69 loss 511.1754150390625
Epoch 70 loss 701.2007446289062
Epoch 71 loss 507.1143798828125
Epoch 72 loss 651.4364624023438
Epoch 73 loss 530.7055053710938
Epoch 74 loss 567.678955078125
Epoch 75 loss 515.252685546875
Epoch 76 loss 668.169921875
Epoch 77 loss 547.5169677734375
Epoch 78 loss 525.5037841796875
Epoch 79 loss 515.3636474609375
Epoch 80 loss 501.51611328125
Epoch 81 loss 539.3685302734375
Epoch 82 loss 539.1240844726562
Epoch 83 loss 492.80328369140625
Epoch 84 loss 601.4398803710938
Epoch 85 loss 513.68212890625
Epoch 86 loss 528.8681030273438
Epoch 87 loss 527.8232421875
Epoch 88 loss 587.318603515625
Epoch 89 loss 508.2276916503906
Epoch 90 loss 503.73681640625
Epoch 91 loss 575.9196166992188
Epoch 92 loss 507.23291015625
Epoch 93 loss 577.77880859375
Epoch 94 loss 495.24700927734375
Epoch 95 loss 561.66552734375
Epoch 96 loss 524.4940185546875
Epoch 97 loss 786.3482055664062
Epoch 98 loss 563.8578491210938
Epoch 99 loss 793.934814453125
Saved Losses
{'MSE - mean': 490.18517539811876, 'MSE - std': 54.30269196616765, 'R2 - mean': 0.9418733958956654, 'R2 - std': 0.006768639052865652} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516655.34375
Epoch 1 loss 514239.46875
Epoch 2 loss 510149.0
Epoch 3 loss 503647.0
Epoch 4 loss 493217.25
Epoch 5 loss 472797.96875
Epoch 6 loss 434915.375
Epoch 7 loss 374347.625
Epoch 8 loss 289059.65625
Epoch 9 loss 185935.140625
Epoch 10 loss 87136.7421875
Epoch 11 loss 24796.83984375
Epoch 12 loss 8199.6650390625
Epoch 13 loss 8183.87353515625
Epoch 14 loss 7745.94580078125
Epoch 15 loss 7437.89990234375
Epoch 16 loss 6196.15771484375
Epoch 17 loss 3415.96484375
Epoch 18 loss 2190.945068359375
Epoch 19 loss 1952.438720703125
Epoch 20 loss 1483.28857421875
Epoch 21 loss 1240.583740234375
Epoch 22 loss 1217.4847412109375
Epoch 23 loss 1033.7452392578125
Epoch 24 loss 949.0967407226562
Epoch 25 loss 1013.0238647460938
Epoch 26 loss 870.0400390625
Epoch 27 loss 874.4571533203125
Epoch 28 loss 797.3991088867188
Epoch 29 loss 813.8811645507812
Epoch 30 loss 852.2173461914062
Epoch 31 loss 719.9393920898438
Epoch 32 loss 751.007080078125
Epoch 33 loss 756.7556762695312
Epoch 34 loss 679.6238403320312
Epoch 35 loss 709.1240844726562
Epoch 36 loss 670.212646484375
Epoch 37 loss 650.7601318359375
Epoch 38 loss 660.9860229492188
Epoch 39 loss 689.8751220703125
Epoch 40 loss 624.72998046875
Epoch 41 loss 644.3441162109375
Epoch 42 loss 648.2124633789062
Epoch 43 loss 621.4166259765625
Epoch 44 loss 584.1503295898438
Epoch 45 loss 682.5055541992188
Epoch 46 loss 604.8357543945312
Epoch 47 loss 571.2395629882812
Epoch 48 loss 587.0167236328125
Epoch 49 loss 574.6552124023438
Epoch 50 loss 668.0941162109375
Epoch 51 loss 639.0527954101562
Epoch 52 loss 566.8750610351562
Epoch 53 loss 558.8048095703125
Epoch 54 loss 538.2691650390625
Epoch 55 loss 535.0316162109375
Epoch 56 loss 531.3056030273438
Epoch 57 loss 532.1062622070312
Epoch 58 loss 531.9677124023438
Epoch 59 loss 610.186279296875
Epoch 60 loss 522.9575805664062
Epoch 61 loss 519.4077758789062
Epoch 62 loss 510.26800537109375
Epoch 63 loss 520.147216796875
Epoch 64 loss 520.31005859375
Epoch 65 loss 528.398681640625
Epoch 66 loss 529.5657348632812
Epoch 67 loss 502.9960021972656
Epoch 68 loss 502.8436584472656
Epoch 69 loss 506.5037841796875
Epoch 70 loss 570.733154296875
Epoch 71 loss 534.8517456054688
Epoch 72 loss 512.3867797851562
Epoch 73 loss 503.4151916503906
Epoch 74 loss 538.8643798828125
Epoch 75 loss 521.9083251953125
Epoch 76 loss 530.7328491210938
Epoch 77 loss 540.3157348632812
Epoch 78 loss 488.2687683105469
Epoch 79 loss 553.5083618164062
Epoch 80 loss 523.298828125
Epoch 81 loss 526.7940063476562
Epoch 82 loss 530.9581909179688
Epoch 83 loss 605.4199829101562
Epoch 84 loss 492.8301696777344
Epoch 85 loss 483.5807189941406
Epoch 86 loss 477.4695129394531
Epoch 87 loss 488.1814880371094
Epoch 88 loss 515.3428955078125
Epoch 89 loss 477.3728332519531
Epoch 90 loss 482.4706726074219
Epoch 91 loss 497.9796447753906
Epoch 92 loss 518.6566162109375
Epoch 93 loss 487.2998962402344
Epoch 94 loss 480.4855041503906
Epoch 95 loss 539.1029663085938
Epoch 96 loss 488.3472900390625
Epoch 97 loss 523.2362060546875
Epoch 98 loss 509.3147277832031
Epoch 99 loss 467.95654296875
Saved Losses
{'MSE - mean': 485.7394580560655, 'MSE - std': 49.37695307083786, 'R2 - mean': 0.9417675962781192, 'R2 - std': 0.00605775155801838} 
 

Results After CV: {'MSE - mean': 485.7394580560655, 'MSE - std': 49.37695307083786, 'R2 - mean': 0.9417675962781192, 'R2 - std': 0.00605775155801838}
Train time: 97.38426179099997
Inference time: 0.13869773359992904
Finished cross validation
Trial 3 finished with value: 485.7394580560655 and parameters: {'dim': 256, 'depth': 2, 'heads': 4, 'dropout': 0.2}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515859.34375
Epoch 1 loss 514059.6875
Epoch 2 loss 510439.03125
Epoch 3 loss 503631.15625
Epoch 4 loss 492447.34375
Epoch 5 loss 471645.625
Epoch 6 loss 433796.875
Epoch 7 loss 373485.28125
Epoch 8 loss 288838.03125
Epoch 9 loss 186914.15625
Epoch 10 loss 89388.2109375
Epoch 11 loss 26643.349609375
Epoch 12 loss 8963.658203125
Epoch 13 loss 8633.32421875
Epoch 14 loss 7944.298828125
Epoch 15 loss 7637.0810546875
Epoch 16 loss 7254.89208984375
Epoch 17 loss 6678.248046875
Epoch 18 loss 5933.98193359375
Epoch 19 loss 4933.31884765625
Epoch 20 loss 3723.572509765625
Epoch 21 loss 2611.447998046875
Epoch 22 loss 2034.32373046875
Epoch 23 loss 1585.1629638671875
Epoch 24 loss 1550.887939453125
Epoch 25 loss 1538.642333984375
Epoch 26 loss 1299.4559326171875
Epoch 27 loss 1260.4188232421875
Epoch 28 loss 1177.5235595703125
Epoch 29 loss 1126.347900390625
Epoch 30 loss 1089.2896728515625
Epoch 31 loss 1059.3204345703125
Epoch 32 loss 1023.6670532226562
Epoch 33 loss 993.5391235351562
Epoch 34 loss 974.43603515625
Epoch 35 loss 934.4728393554688
Epoch 36 loss 924.644775390625
Epoch 37 loss 920.4699096679688
Epoch 38 loss 914.124755859375
Epoch 39 loss 873.6345825195312
Epoch 40 loss 861.5838012695312
Epoch 41 loss 888.0135498046875
Epoch 42 loss 830.2452392578125
Epoch 43 loss 820.1819458007812
Epoch 44 loss 856.3807373046875
Epoch 45 loss 802.3139038085938
Epoch 46 loss 795.0586547851562
Epoch 47 loss 793.3802490234375
Epoch 48 loss 776.929931640625
Epoch 49 loss 773.533203125
Epoch 50 loss 782.1377563476562
Epoch 51 loss 886.065673828125
Epoch 52 loss 762.2498168945312
Epoch 53 loss 751.9873657226562
Epoch 54 loss 753.3258666992188
Epoch 55 loss 751.3826293945312
Epoch 56 loss 749.1005249023438
Epoch 57 loss 729.8875732421875
Epoch 58 loss 717.4171752929688
Epoch 59 loss 722.4273681640625
Epoch 60 loss 711.5997314453125
Epoch 61 loss 753.779052734375
Epoch 62 loss 703.0626220703125
Epoch 63 loss 791.2314453125
Epoch 64 loss 708.2208251953125
Epoch 65 loss 690.1716918945312
Epoch 66 loss 731.6825561523438
Epoch 67 loss 694.2195434570312
Epoch 68 loss 724.8906860351562
Epoch 69 loss 686.3402099609375
Epoch 70 loss 692.63916015625
Epoch 71 loss 689.9588012695312
Epoch 72 loss 674.8242797851562
Epoch 73 loss 665.4874267578125
Epoch 74 loss 657.5167846679688
Epoch 75 loss 705.9467163085938
Epoch 76 loss 653.4577026367188
Epoch 77 loss 735.7997436523438
Epoch 78 loss 648.2379760742188
Epoch 79 loss 691.1603393554688
Epoch 80 loss 687.0886840820312
Epoch 81 loss 735.856689453125
Epoch 82 loss 663.0
Epoch 83 loss 647.850341796875
Epoch 84 loss 632.2346801757812
Epoch 85 loss 649.6605834960938
Epoch 86 loss 680.3003540039062
Epoch 87 loss 631.1900634765625
Epoch 88 loss 665.7102661132812
Epoch 89 loss 664.3451538085938
Epoch 90 loss 625.132080078125
Epoch 91 loss 629.8501586914062
Epoch 92 loss 670.8308715820312
Epoch 93 loss 636.087158203125
Epoch 94 loss 622.7568969726562
Epoch 95 loss 621.9524536132812
Epoch 96 loss 721.533935546875
Epoch 97 loss 613.4070434570312
Epoch 98 loss 623.4988403320312
Epoch 99 loss 617.7002563476562
Saved Losses
{'MSE - mean': 613.4071669836759, 'MSE - std': 0.0, 'R2 - mean': 0.9286785620458958, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523560.875
Epoch 1 loss 521393.65625
Epoch 2 loss 517609.5625
Epoch 3 loss 511858.625
Epoch 4 loss 502863.9375
Epoch 5 loss 485076.21875
Epoch 6 loss 452534.0625
Epoch 7 loss 399527.40625
Epoch 8 loss 323223.90625
Epoch 9 loss 226893.6875
Epoch 10 loss 125704.296875
Epoch 11 loss 46897.06640625
Epoch 12 loss 12010.6328125
Epoch 13 loss 7497.52197265625
Epoch 14 loss 7188.44384765625
Epoch 15 loss 7050.79736328125
Epoch 16 loss 6518.0693359375
Epoch 17 loss 6025.15185546875
Epoch 18 loss 5183.22705078125
Epoch 19 loss 4158.859375
Epoch 20 loss 2860.25048828125
Epoch 21 loss 1921.720458984375
Epoch 22 loss 1398.8546142578125
Epoch 23 loss 1230.344482421875
Epoch 24 loss 1149.88232421875
Epoch 25 loss 1093.19580078125
Epoch 26 loss 1024.2281494140625
Epoch 27 loss 991.4202880859375
Epoch 28 loss 962.1841430664062
Epoch 29 loss 951.0670776367188
Epoch 30 loss 893.2244873046875
Epoch 31 loss 855.9937133789062
Epoch 32 loss 834.6809692382812
Epoch 33 loss 813.8422241210938
Epoch 34 loss 845.4549560546875
Epoch 35 loss 826.3837890625
Epoch 36 loss 760.8102416992188
Epoch 37 loss 730.4276733398438
Epoch 38 loss 730.3943481445312
Epoch 39 loss 712.502685546875
Epoch 40 loss 685.7962036132812
Epoch 41 loss 673.0426635742188
Epoch 42 loss 671.0853881835938
Epoch 43 loss 665.9489135742188
Epoch 44 loss 673.2511596679688
Epoch 45 loss 639.198974609375
Epoch 46 loss 616.4016723632812
Epoch 47 loss 648.6376342773438
Epoch 48 loss 599.2567138671875
Epoch 49 loss 589.3176879882812
Epoch 50 loss 577.7847290039062
Epoch 51 loss 572.499267578125
Epoch 52 loss 570.7544555664062
Epoch 53 loss 558.4144287109375
Epoch 54 loss 555.3018798828125
Epoch 55 loss 563.2806396484375
Epoch 56 loss 561.43017578125
Epoch 57 loss 536.2091064453125
Epoch 58 loss 534.1161499023438
Epoch 59 loss 552.9633178710938
Epoch 60 loss 523.466064453125
Epoch 61 loss 540.8101806640625
Epoch 62 loss 527.8499145507812
Epoch 63 loss 515.9508666992188
Epoch 64 loss 519.6398315429688
Epoch 65 loss 508.8695068359375
Epoch 66 loss 518.5208129882812
Epoch 67 loss 505.7264404296875
Epoch 68 loss 526.7188720703125
Epoch 69 loss 500.8016357421875
Epoch 70 loss 535.6909790039062
Epoch 71 loss 498.3357238769531
Epoch 72 loss 563.5208129882812
Epoch 73 loss 506.2837219238281
Epoch 74 loss 499.2882080078125
Epoch 75 loss 587.3551635742188
Epoch 76 loss 506.72705078125
Epoch 77 loss 486.0462341308594
Epoch 78 loss 553.9617309570312
Epoch 79 loss 490.4137268066406
Epoch 80 loss 519.4826049804688
Epoch 81 loss 517.51806640625
Epoch 82 loss 561.2144775390625
Epoch 83 loss 548.6580810546875
Epoch 84 loss 484.08099365234375
Epoch 85 loss 485.2396240234375
Epoch 86 loss 488.1988220214844
Epoch 87 loss 494.6199035644531
Epoch 88 loss 499.18231201171875
Epoch 89 loss 482.5470886230469
Epoch 90 loss 492.8359069824219
Epoch 91 loss 484.6802062988281
Epoch 92 loss 493.4845275878906
Epoch 93 loss 481.3197326660156
Epoch 94 loss 530.9771118164062
Epoch 95 loss 521.2649536132812
Epoch 96 loss 487.5149230957031
Epoch 97 loss 535.8705444335938
Epoch 98 loss 558.9325561523438
Epoch 99 loss 490.45404052734375
Saved Losses
{'MSE - mean': 547.3635096587543, 'MSE - std': 66.04365732492164, 'R2 - mean': 0.9328412506777441, 'R2 - std': 0.004162688631848377} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516214.875
Epoch 1 loss 513445.8125
Epoch 2 loss 508671.96875
Epoch 3 loss 501300.09375
Epoch 4 loss 489524.71875
Epoch 5 loss 466789.90625
Epoch 6 loss 426682.25
Epoch 7 loss 364171.5625
Epoch 8 loss 278552.0
Epoch 9 loss 177771.796875
Epoch 10 loss 83532.09375
Epoch 11 loss 25136.294921875
Epoch 12 loss 9551.6748046875
Epoch 13 loss 9330.5390625
Epoch 14 loss 8723.466796875
Epoch 15 loss 8401.185546875
Epoch 16 loss 7951.15380859375
Epoch 17 loss 7341.52197265625
Epoch 18 loss 6520.72705078125
Epoch 19 loss 5458.99951171875
Epoch 20 loss 4143.76904296875
Epoch 21 loss 2845.519775390625
Epoch 22 loss 1923.3353271484375
Epoch 23 loss 1562.93994140625
Epoch 24 loss 1440.0570068359375
Epoch 25 loss 1413.2772216796875
Epoch 26 loss 1355.1572265625
Epoch 27 loss 1295.2591552734375
Epoch 28 loss 1259.5411376953125
Epoch 29 loss 1203.0977783203125
Epoch 30 loss 1136.130126953125
Epoch 31 loss 1098.2550048828125
Epoch 32 loss 1058.04296875
Epoch 33 loss 1019.878173828125
Epoch 34 loss 1019.6307983398438
Epoch 35 loss 969.3411254882812
Epoch 36 loss 956.747802734375
Epoch 37 loss 917.6666870117188
Epoch 38 loss 902.7538452148438
Epoch 39 loss 851.2808837890625
Epoch 40 loss 851.49072265625
Epoch 41 loss 817.3109741210938
Epoch 42 loss 793.0712890625
Epoch 43 loss 778.7396240234375
Epoch 44 loss 777.8742065429688
Epoch 45 loss 777.3154907226562
Epoch 46 loss 736.1589965820312
Epoch 47 loss 710.9939575195312
Epoch 48 loss 712.2935180664062
Epoch 49 loss 695.0774536132812
Epoch 50 loss 674.3720703125
Epoch 51 loss 666.0402221679688
Epoch 52 loss 665.4866943359375
Epoch 53 loss 653.083740234375
Epoch 54 loss 636.0115966796875
Epoch 55 loss 629.9276733398438
Epoch 56 loss 644.2276611328125
Epoch 57 loss 619.6053466796875
Epoch 58 loss 610.0692138671875
Epoch 59 loss 636.1536254882812
Epoch 60 loss 596.6751708984375
Epoch 61 loss 666.5767822265625
Epoch 62 loss 581.9276733398438
Epoch 63 loss 574.74169921875
Epoch 64 loss 572.62646484375
Epoch 65 loss 587.59716796875
Epoch 66 loss 567.4600830078125
Epoch 67 loss 630.5238647460938
Epoch 68 loss 636.8408203125
Epoch 69 loss 547.9929809570312
Epoch 70 loss 577.022216796875
Epoch 71 loss 550.0525512695312
Epoch 72 loss 597.6499633789062
Epoch 73 loss 537.8462524414062
Epoch 74 loss 534.0051879882812
Epoch 75 loss 540.8509521484375
Epoch 76 loss 612.052978515625
Epoch 77 loss 533.558837890625
Epoch 78 loss 533.9400024414062
Epoch 79 loss 517.3961181640625
Epoch 80 loss 519.8782348632812
Epoch 81 loss 542.33203125
Epoch 82 loss 541.0780029296875
Epoch 83 loss 516.9816284179688
Epoch 84 loss 515.1617431640625
Epoch 85 loss 539.6441040039062
Epoch 86 loss 511.9124755859375
Epoch 87 loss 532.5379028320312
Epoch 88 loss 499.2715759277344
Epoch 89 loss 543.747802734375
Epoch 90 loss 505.473876953125
Epoch 91 loss 693.0458374023438
Epoch 92 loss 569.851806640625
Epoch 93 loss 563.2118530273438
Epoch 94 loss 512.7794799804688
Epoch 95 loss 504.48199462890625
Epoch 96 loss 486.7008972167969
Epoch 97 loss 515.5685424804688
Epoch 98 loss 490.8998718261719
Epoch 99 loss 605.27880859375
Saved Losses
{'MSE - mean': 527.1426140722001, 'MSE - std': 61.03779445457631, 'R2 - mean': 0.9377988317910303, 'R2 - std': 0.0077914828768406936} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520644.375
Epoch 1 loss 519363.3125
Epoch 2 loss 516668.46875
Epoch 3 loss 511642.4375
Epoch 4 loss 503752.90625
Epoch 5 loss 489185.28125
Epoch 6 loss 461075.75
Epoch 7 loss 413932.1875
Epoch 8 loss 343769.6875
Epoch 9 loss 251710.453125
Epoch 10 loss 149156.640625
Epoch 11 loss 61533.55859375
Epoch 12 loss 16150.21484375
Epoch 13 loss 8243.80859375
Epoch 14 loss 8197.9306640625
Epoch 15 loss 7853.4189453125
Epoch 16 loss 7523.4111328125
Epoch 17 loss 7102.037109375
Epoch 18 loss 6455.634765625
Epoch 19 loss 5566.8173828125
Epoch 20 loss 4388.658203125
Epoch 21 loss 3017.698974609375
Epoch 22 loss 1982.482177734375
Epoch 23 loss 1820.611083984375
Epoch 24 loss 1467.0455322265625
Epoch 25 loss 1484.420166015625
Epoch 26 loss 1278.609375
Epoch 27 loss 1400.0345458984375
Epoch 28 loss 1165.7305908203125
Epoch 29 loss 1117.61279296875
Epoch 30 loss 1290.6519775390625
Epoch 31 loss 1124.9259033203125
Epoch 32 loss 1021.5698852539062
Epoch 33 loss 1032.405517578125
Epoch 34 loss 972.1152954101562
Epoch 35 loss 982.0952758789062
Epoch 36 loss 899.6007690429688
Epoch 37 loss 902.9780883789062
Epoch 38 loss 911.2507934570312
Epoch 39 loss 825.039306640625
Epoch 40 loss 806.46728515625
Epoch 41 loss 782.118896484375
Epoch 42 loss 770.069580078125
Epoch 43 loss 743.4407958984375
Epoch 44 loss 818.8787841796875
Epoch 45 loss 825.0301513671875
Epoch 46 loss 699.4614868164062
Epoch 47 loss 704.6048583984375
Epoch 48 loss 753.9082641601562
Epoch 49 loss 660.991943359375
Epoch 50 loss 667.8941040039062
Epoch 51 loss 752.0060424804688
Epoch 52 loss 626.4581298828125
Epoch 53 loss 690.4371337890625
Epoch 54 loss 679.2225952148438
Epoch 55 loss 653.46728515625
Epoch 56 loss 597.1243286132812
Epoch 57 loss 637.3704833984375
Epoch 58 loss 721.6560668945312
Epoch 59 loss 599.3228759765625
Epoch 60 loss 625.1371459960938
Epoch 61 loss 571.28564453125
Epoch 62 loss 576.837646484375
Epoch 63 loss 577.3477783203125
Epoch 64 loss 566.2410888671875
Epoch 65 loss 562.7762451171875
Epoch 66 loss 558.33056640625
Epoch 67 loss 566.7457275390625
Epoch 68 loss 567.8213500976562
Epoch 69 loss 563.8953857421875
Epoch 70 loss 575.6702270507812
Epoch 71 loss 537.1422729492188
Epoch 72 loss 552.4766845703125
Epoch 73 loss 542.1788940429688
Epoch 74 loss 533.1248779296875
Epoch 75 loss 572.7112426757812
Epoch 76 loss 534.7520751953125
Epoch 77 loss 551.2628173828125
Epoch 78 loss 532.3079223632812
Epoch 79 loss 545.3461303710938
Epoch 80 loss 528.1001586914062
Epoch 81 loss 527.0174560546875
Epoch 82 loss 528.4518432617188
Epoch 83 loss 535.1624755859375
Epoch 84 loss 519.786376953125
Epoch 85 loss 525.6797485351562
Epoch 86 loss 590.009765625
Epoch 87 loss 588.2330932617188
Epoch 88 loss 508.96026611328125
Epoch 89 loss 520.3878173828125
Epoch 90 loss 516.7002563476562
Epoch 91 loss 519.060791015625
Epoch 92 loss 513.13037109375
Epoch 93 loss 542.1043090820312
Epoch 94 loss 513.84765625
Epoch 95 loss 499.5654296875
Epoch 96 loss 496.5269775390625
Epoch 97 loss 497.4080810546875
Epoch 98 loss 495.13629150390625
Epoch 99 loss 549.6776123046875
Saved Losses
{'MSE - mean': 519.1410345946707, 'MSE - std': 54.64691287085654, 'R2 - mean': 0.93844528281621, 'R2 - std': 0.006839890412056614} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516406.5
Epoch 1 loss 513752.6875
Epoch 2 loss 508871.71875
Epoch 3 loss 500983.96875
Epoch 4 loss 488862.75
Epoch 5 loss 466240.53125
Epoch 6 loss 426399.5625
Epoch 7 loss 364450.96875
Epoch 8 loss 279524.21875
Epoch 9 loss 179135.890625
Epoch 10 loss 84248.03125
Epoch 11 loss 24615.318359375
Epoch 12 loss 8236.87890625
Epoch 13 loss 7867.46630859375
Epoch 14 loss 7246.0654296875
Epoch 15 loss 6913.3115234375
Epoch 16 loss 6474.69921875
Epoch 17 loss 5905.11669921875
Epoch 18 loss 5128.30908203125
Epoch 19 loss 4158.45703125
Epoch 20 loss 3142.5859375
Epoch 21 loss 1995.4814453125
Epoch 22 loss 1484.002197265625
Epoch 23 loss 1281.78125
Epoch 24 loss 1178.720458984375
Epoch 25 loss 1129.7364501953125
Epoch 26 loss 1097.4822998046875
Epoch 27 loss 1020.0095825195312
Epoch 28 loss 1021.6707153320312
Epoch 29 loss 951.7398071289062
Epoch 30 loss 919.4315185546875
Epoch 31 loss 885.0454711914062
Epoch 32 loss 869.410400390625
Epoch 33 loss 897.515380859375
Epoch 34 loss 799.7103271484375
Epoch 35 loss 772.48486328125
Epoch 36 loss 764.2518920898438
Epoch 37 loss 934.6153564453125
Epoch 38 loss 708.9487915039062
Epoch 39 loss 690.6974487304688
Epoch 40 loss 713.1109008789062
Epoch 41 loss 657.3062744140625
Epoch 42 loss 680.2584838867188
Epoch 43 loss 628.1689453125
Epoch 44 loss 824.5775146484375
Epoch 45 loss 611.5050659179688
Epoch 46 loss 705.9388427734375
Epoch 47 loss 599.9786376953125
Epoch 48 loss 567.8400268554688
Epoch 49 loss 559.645263671875
Epoch 50 loss 554.9249267578125
Epoch 51 loss 557.713623046875
Epoch 52 loss 526.241455078125
Epoch 53 loss 521.7155151367188
Epoch 54 loss 514.322021484375
Epoch 55 loss 538.42578125
Epoch 56 loss 511.50042724609375
Epoch 57 loss 500.1441650390625
Epoch 58 loss 499.4145202636719
Epoch 59 loss 496.1370544433594
Epoch 60 loss 491.9024963378906
Epoch 61 loss 682.8956909179688
Epoch 62 loss 496.30377197265625
Epoch 63 loss 497.8861389160156
Epoch 64 loss 492.6239318847656
Epoch 65 loss 532.4391479492188
Epoch 66 loss 481.71270751953125
Epoch 67 loss 509.40386962890625
Epoch 68 loss 471.7372131347656
Epoch 69 loss 479.3756408691406
Epoch 70 loss 469.27984619140625
Epoch 71 loss 690.4645385742188
Epoch 72 loss 504.8789367675781
Epoch 73 loss 467.6023254394531
Epoch 74 loss 548.9021606445312
Epoch 75 loss 498.93463134765625
Epoch 76 loss 470.86883544921875
Epoch 77 loss 538.0335083007812
Epoch 78 loss 470.8979187011719
Epoch 79 loss 458.4070129394531
Epoch 80 loss 476.77825927734375
Epoch 81 loss 470.4445495605469
Epoch 82 loss 461.4614562988281
Epoch 83 loss 454.3778381347656
Epoch 84 loss 460.33197021484375
Epoch 85 loss 489.3758850097656
Epoch 86 loss 455.50164794921875
Epoch 87 loss 474.12371826171875
Epoch 88 loss 551.5797729492188
Epoch 89 loss 458.2303161621094
Epoch 90 loss 453.9881896972656
Epoch 91 loss 505.006591796875
Epoch 92 loss 449.0721740722656
Epoch 93 loss 510.7457275390625
Epoch 94 loss 499.8475036621094
Epoch 95 loss 457.4233093261719
Epoch 96 loss 456.04693603515625
Epoch 97 loss 451.3966979980469
Epoch 98 loss 452.48309326171875
Epoch 99 loss 475.2366638183594
Saved Losses
{'MSE - mean': 505.1272779584764, 'MSE - std': 56.34331876350481, 'R2 - mean': 0.9394985139047879, 'R2 - std': 0.0064702753869478975} 
 

Results After CV: {'MSE - mean': 505.1272779584764, 'MSE - std': 56.34331876350481, 'R2 - mean': 0.9394985139047879, 'R2 - std': 0.0064702753869478975}
Train time: 90.4975141506
Inference time: 0.1389875134000249
Finished cross validation
Trial 4 finished with value: 505.1272779584764 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'dropout': 0}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 511988.625
Epoch 1 loss 508212.625
Epoch 2 loss 503259.15625
Epoch 3 loss 498575.40625
Epoch 4 loss 490020.75
Epoch 5 loss 472250.25
Epoch 6 loss 439299.40625
Epoch 7 loss 385254.9375
Epoch 8 loss 306970.65625
Epoch 9 loss 208843.40625
Epoch 10 loss 108556.2109375
Epoch 11 loss 36159.7265625
Epoch 12 loss 10134.02734375
Epoch 13 loss 8922.6865234375
Epoch 14 loss 8533.533203125
Epoch 15 loss 8108.8759765625
Epoch 16 loss 4097.23828125
Epoch 17 loss 2936.912109375
Epoch 18 loss 1760.643798828125
Epoch 19 loss 1488.5235595703125
Epoch 20 loss 1506.0999755859375
Epoch 21 loss 1168.40869140625
Epoch 22 loss 1023.4180297851562
Epoch 23 loss 959.485107421875
Epoch 24 loss 1020.3699951171875
Epoch 25 loss 925.7304077148438
Epoch 26 loss 951.8809814453125
Epoch 27 loss 851.5880737304688
Epoch 28 loss 873.8543701171875
Epoch 29 loss 857.5912475585938
Epoch 30 loss 725.3878173828125
Epoch 31 loss 763.7914428710938
Epoch 32 loss 797.0313110351562
Epoch 33 loss 814.60791015625
Epoch 34 loss 661.9569702148438
Epoch 35 loss 720.2693481445312
Epoch 36 loss 1040.548095703125
Epoch 37 loss 809.938232421875
Epoch 38 loss 675.3529052734375
Epoch 39 loss 716.7623291015625
Epoch 40 loss 684.8592529296875
Epoch 41 loss 634.0657958984375
Epoch 42 loss 607.844482421875
Epoch 43 loss 629.9701538085938
Epoch 44 loss 596.7578735351562
Epoch 45 loss 668.2924194335938
Epoch 46 loss 884.5811157226562
Epoch 47 loss 706.5028076171875
Epoch 48 loss 624.354248046875
Epoch 49 loss 599.6588134765625
Epoch 50 loss 860.3365478515625
Epoch 51 loss 581.3232421875
Epoch 52 loss 748.9618530273438
Epoch 53 loss 586.805419921875
Epoch 54 loss 600.466064453125
Epoch 55 loss 577.9568481445312
Epoch 56 loss 590.8136596679688
Epoch 57 loss 725.9552612304688
Epoch 58 loss 621.0775146484375
Epoch 59 loss 573.1952514648438
Epoch 60 loss 567.7755737304688
Epoch 61 loss 580.6866455078125
Epoch 62 loss 583.374755859375
Epoch 63 loss 755.2758178710938
Epoch 64 loss 581.1864013671875
Epoch 65 loss 585.6530151367188
Epoch 66 loss 610.3914794921875
Epoch 67 loss 632.8924560546875
Epoch 68 loss 586.0714721679688
Epoch 69 loss 585.7208862304688
Epoch 70 loss 687.2525634765625
Epoch 71 loss 583.8220825195312
Epoch 72 loss 585.04443359375
Epoch 73 loss 571.5867309570312
Epoch 74 loss 632.1546020507812
Epoch 75 loss 635.1478271484375
Epoch 76 loss 625.728759765625
Epoch 77 loss 666.6751708984375
Epoch 78 loss 577.6280517578125
Epoch 79 loss 580.3584594726562
Epoch 80 loss 625.0128784179688
Epoch 81 loss 643.3932495117188
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 567.7757207397145, 'MSE - std': 0.0, 'R2 - mean': 0.9339841739415771, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522892.125
Epoch 1 loss 520143.09375
Epoch 2 loss 515951.125
Epoch 3 loss 511739.875
Epoch 4 loss 505809.5
Epoch 5 loss 493482.6875
Epoch 6 loss 469210.125
Epoch 7 loss 427022.25
Epoch 8 loss 362180.9375
Epoch 9 loss 273664.375
Epoch 10 loss 170832.53125
Epoch 11 loss 77047.0546875
Epoch 12 loss 21659.689453125
Epoch 13 loss 7907.7802734375
Epoch 14 loss 7703.47021484375
Epoch 15 loss 7553.1865234375
Epoch 16 loss 5914.6005859375
Epoch 17 loss 3142.222412109375
Epoch 18 loss 2077.375
Epoch 19 loss 1505.071044921875
Epoch 20 loss 1358.6287841796875
Epoch 21 loss 1066.8203125
Epoch 22 loss 1018.2525634765625
Epoch 23 loss 894.2144165039062
Epoch 24 loss 768.9863891601562
Epoch 25 loss 775.350830078125
Epoch 26 loss 742.543701171875
Epoch 27 loss 747.0595092773438
Epoch 28 loss 793.8201293945312
Epoch 29 loss 977.447021484375
Epoch 30 loss 654.0208740234375
Epoch 31 loss 690.3969116210938
Epoch 32 loss 1032.2301025390625
Epoch 33 loss 564.650390625
Epoch 34 loss 544.1109619140625
Epoch 35 loss 532.144775390625
Epoch 36 loss 539.84130859375
Epoch 37 loss 534.486328125
Epoch 38 loss 509.00494384765625
Epoch 39 loss 615.89501953125
Epoch 40 loss 583.8265380859375
Epoch 41 loss 530.680908203125
Epoch 42 loss 498.63665771484375
Epoch 43 loss 476.50677490234375
Epoch 44 loss 519.10791015625
Epoch 45 loss 537.7186889648438
Epoch 46 loss 506.99591064453125
Epoch 47 loss 504.0711975097656
Epoch 48 loss 672.100830078125
Epoch 49 loss 576.4691162109375
Epoch 50 loss 607.6049194335938
Epoch 51 loss 527.7692260742188
Epoch 52 loss 520.995361328125
Epoch 53 loss 456.90899658203125
Epoch 54 loss 532.279052734375
Epoch 55 loss 503.10418701171875
Epoch 56 loss 485.649658203125
Epoch 57 loss 450.45867919921875
Epoch 58 loss 508.181640625
Epoch 59 loss 480.38006591796875
Epoch 60 loss 437.655029296875
Epoch 61 loss 601.7588500976562
Epoch 62 loss 460.0099182128906
Epoch 63 loss 465.7285461425781
Epoch 64 loss 468.992431640625
Epoch 65 loss 483.5853271484375
Epoch 66 loss 436.52154541015625
Epoch 67 loss 431.59228515625
Epoch 68 loss 458.21319580078125
Epoch 69 loss 487.87457275390625
Epoch 70 loss 447.7641906738281
Epoch 71 loss 560.1029663085938
Epoch 72 loss 730.1494140625
Epoch 73 loss 761.0985717773438
Epoch 74 loss 476.84332275390625
Epoch 75 loss 434.2061767578125
Epoch 76 loss 548.0476684570312
Epoch 77 loss 458.6598815917969
Epoch 78 loss 462.2361755371094
Epoch 79 loss 523.504150390625
Epoch 80 loss 420.5563659667969
Epoch 81 loss 543.1846923828125
Epoch 82 loss 575.2283935546875
Epoch 83 loss 447.16058349609375
Epoch 84 loss 437.617431640625
Epoch 85 loss 451.37579345703125
Epoch 86 loss 431.14923095703125
Epoch 87 loss 517.1884765625
Epoch 88 loss 468.1673889160156
Epoch 89 loss 537.99951171875
Epoch 90 loss 527.4675903320312
Epoch 91 loss 470.7882385253906
Epoch 92 loss 471.7355041503906
Epoch 93 loss 429.8616027832031
Epoch 94 loss 473.9228210449219
Epoch 95 loss 456.185546875
Epoch 96 loss 471.3549499511719
Epoch 97 loss 440.9874267578125
Epoch 98 loss 455.0905456542969
Epoch 99 loss 504.02081298828125
Saved Losses
{'MSE - mean': 494.16595047232715, 'MSE - std': 73.6097702673874, 'R2 - mean': 0.9394704893019465, 'R2 - std': 0.005486315360369531} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513803.875
Epoch 1 loss 510197.25
Epoch 2 loss 505509.96875
Epoch 3 loss 500965.1875
Epoch 4 loss 491993.84375
Epoch 5 loss 473082.1875
Epoch 6 loss 438399.53125
Epoch 7 loss 382512.3125
Epoch 8 loss 302511.84375
Epoch 9 loss 203681.140625
Epoch 10 loss 104270.7421875
Epoch 11 loss 34657.453125
Epoch 12 loss 10639.2236328125
Epoch 13 loss 9565.5302734375
Epoch 14 loss 9217.857421875
Epoch 15 loss 8959.8720703125
Epoch 16 loss 4411.9775390625
Epoch 17 loss 2795.259033203125
Epoch 18 loss 2162.490966796875
Epoch 19 loss 1547.13037109375
Epoch 20 loss 1280.0306396484375
Epoch 21 loss 1467.282958984375
Epoch 22 loss 1080.226318359375
Epoch 23 loss 934.6163330078125
Epoch 24 loss 836.9425659179688
Epoch 25 loss 743.9410400390625
Epoch 26 loss 792.0906982421875
Epoch 27 loss 786.2323608398438
Epoch 28 loss 802.2611694335938
Epoch 29 loss 632.3504638671875
Epoch 30 loss 712.55810546875
Epoch 31 loss 615.6754150390625
Epoch 32 loss 910.2090454101562
Epoch 33 loss 643.74462890625
Epoch 34 loss 583.490478515625
Epoch 35 loss 581.3145141601562
Epoch 36 loss 590.0150146484375
Epoch 37 loss 754.7479248046875
Epoch 38 loss 552.6058959960938
Epoch 39 loss 544.0263671875
Epoch 40 loss 548.498046875
Epoch 41 loss 565.331298828125
Epoch 42 loss 526.178955078125
Epoch 43 loss 524.4332275390625
Epoch 44 loss 575.2784423828125
Epoch 45 loss 536.762939453125
Epoch 46 loss 622.437255859375
Epoch 47 loss 529.911376953125
Epoch 48 loss 618.926025390625
Epoch 49 loss 516.0458984375
Epoch 50 loss 520.6927490234375
Epoch 51 loss 553.5615844726562
Epoch 52 loss 530.126220703125
Epoch 53 loss 501.2968444824219
Epoch 54 loss 647.469482421875
Epoch 55 loss 511.2878112792969
Epoch 56 loss 522.2632446289062
Epoch 57 loss 540.3519287109375
Epoch 58 loss 514.1910400390625
Epoch 59 loss 513.80615234375
Epoch 60 loss 598.6277465820312
Epoch 61 loss 504.7784423828125
Epoch 62 loss 517.6718139648438
Epoch 63 loss 526.879638671875
Epoch 64 loss 607.0850830078125
Epoch 65 loss 559.15673828125
Epoch 66 loss 523.6400146484375
Epoch 67 loss 487.456787109375
Epoch 68 loss 485.1009216308594
Epoch 69 loss 486.2388000488281
Epoch 70 loss 492.8368835449219
Epoch 71 loss 539.3150024414062
Epoch 72 loss 496.68353271484375
Epoch 73 loss 542.3452758789062
Epoch 74 loss 632.7355346679688
Epoch 75 loss 498.0795593261719
Epoch 76 loss 499.7261962890625
Epoch 77 loss 536.9208374023438
Epoch 78 loss 527.5632934570312
Epoch 79 loss 469.4792175292969
Epoch 80 loss 631.0162353515625
Epoch 81 loss 610.6981201171875
Epoch 82 loss 553.7474365234375
Epoch 83 loss 543.213623046875
Epoch 84 loss 563.0264892578125
Epoch 85 loss 519.7313842773438
Epoch 86 loss 593.752685546875
Epoch 87 loss 501.83831787109375
Epoch 88 loss 502.6287841796875
Epoch 89 loss 483.7210693359375
Epoch 90 loss 543.9931030273438
Epoch 91 loss 560.926025390625
Epoch 92 loss 534.3579711914062
Epoch 93 loss 561.9451293945312
Epoch 94 loss 556.7455444335938
Epoch 95 loss 523.9225463867188
Epoch 96 loss 573.6720581054688
Epoch 97 loss 508.56622314453125
Epoch 98 loss 696.0758056640625
Epoch 99 loss 550.9819946289062
Saved Losses
{'MSE - mean': 485.9370186475064, 'MSE - std': 61.2184298815871, 'R2 - mean': 0.9428350290276931, 'R2 - std': 0.006535035778112084} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516937.15625
Epoch 1 loss 513363.6875
Epoch 2 loss 508489.46875
Epoch 3 loss 503527.40625
Epoch 4 loss 494813.5625
Epoch 5 loss 476494.5625
Epoch 6 loss 442081.34375
Epoch 7 loss 385781.375
Epoch 8 loss 304828.28125
Epoch 9 loss 204149.125
Epoch 10 loss 103525.1484375
Epoch 11 loss 32980.6875
Epoch 12 loss 9458.1904296875
Epoch 13 loss 8503.3837890625
Epoch 14 loss 8219.03515625
Epoch 15 loss 7494.84228515625
Epoch 16 loss 3639.985107421875
Epoch 17 loss 2543.362548828125
Epoch 18 loss 2357.686279296875
Epoch 19 loss 1507.789794921875
Epoch 20 loss 1369.1986083984375
Epoch 21 loss 1112.06005859375
Epoch 22 loss 1050.0467529296875
Epoch 23 loss 1017.8453979492188
Epoch 24 loss 865.5861206054688
Epoch 25 loss 831.4873046875
Epoch 26 loss 860.271240234375
Epoch 27 loss 773.3751831054688
Epoch 28 loss 849.6709594726562
Epoch 29 loss 751.66748046875
Epoch 30 loss 913.4822998046875
Epoch 31 loss 1142.5322265625
Epoch 32 loss 668.83642578125
Epoch 33 loss 688.08447265625
Epoch 34 loss 652.2501220703125
Epoch 35 loss 632.3522338867188
Epoch 36 loss 612.0305786132812
Epoch 37 loss 714.9696655273438
Epoch 38 loss 588.332275390625
Epoch 39 loss 619.6431274414062
Epoch 40 loss 588.6861572265625
Epoch 41 loss 568.1266479492188
Epoch 42 loss 634.3355712890625
Epoch 43 loss 562.7930297851562
Epoch 44 loss 549.4961547851562
Epoch 45 loss 561.1065673828125
Epoch 46 loss 632.1922607421875
Epoch 47 loss 576.13134765625
Epoch 48 loss 593.9757080078125
Epoch 49 loss 552.0081176757812
Epoch 50 loss 706.77294921875
Epoch 51 loss 596.5478515625
Epoch 52 loss 544.9556884765625
Epoch 53 loss 526.9368896484375
Epoch 54 loss 725.5765991210938
Epoch 55 loss 697.46923828125
Epoch 56 loss 532.297119140625
Epoch 57 loss 595.3068237304688
Epoch 58 loss 538.1458129882812
Epoch 59 loss 570.3312377929688
Epoch 60 loss 629.9268188476562
Epoch 61 loss 542.7714233398438
Epoch 62 loss 688.997802734375
Epoch 63 loss 593.5428466796875
Epoch 64 loss 532.6052856445312
Epoch 65 loss 531.0629272460938
Epoch 66 loss 657.7144775390625
Epoch 67 loss 515.1715087890625
Epoch 68 loss 569.3118896484375
Epoch 69 loss 537.5250854492188
Epoch 70 loss 553.9202880859375
Epoch 71 loss 507.1284484863281
Epoch 72 loss 513.3213500976562
Epoch 73 loss 586.8895874023438
Epoch 74 loss 667.7850341796875
Epoch 75 loss 512.861572265625
Epoch 76 loss 589.7227783203125
Epoch 77 loss 538.2109985351562
Epoch 78 loss 521.94287109375
Epoch 79 loss 556.114990234375
Epoch 80 loss 539.6890258789062
Epoch 81 loss 514.1200561523438
Epoch 82 loss 660.1300659179688
Epoch 83 loss 739.7587280273438
Epoch 84 loss 517.8373413085938
Epoch 85 loss 516.2692260742188
Epoch 86 loss 508.3465576171875
Epoch 87 loss 531.7470703125
Epoch 88 loss 568.0846557617188
Epoch 89 loss 538.4449462890625
Epoch 90 loss 539.5802001953125
Epoch 91 loss 522.954833984375
Epoch 92 loss 526.1084594726562
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 491.2348369542537, 'MSE - std': 53.804951020412766, 'R2 - mean': 0.9418614658960877, 'R2 - std': 0.005905378478943424} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514348.59375
Epoch 1 loss 510559.375
Epoch 2 loss 505695.125
Epoch 3 loss 501174.59375
Epoch 4 loss 493639.9375
Epoch 5 loss 477177.15625
Epoch 6 loss 445343.65625
Epoch 7 loss 392127.5625
Epoch 8 loss 314223.40625
Epoch 9 loss 215611.640625
Epoch 10 loss 113405.7421875
Epoch 11 loss 38404.33984375
Epoch 12 loss 9928.3994140625
Epoch 13 loss 8204.5380859375
Epoch 14 loss 7922.236328125
Epoch 15 loss 7489.07373046875
Epoch 16 loss 3714.464599609375
Epoch 17 loss 2476.365234375
Epoch 18 loss 1728.1322021484375
Epoch 19 loss 1434.8084716796875
Epoch 20 loss 1118.5352783203125
Epoch 21 loss 1095.7174072265625
Epoch 22 loss 956.1991577148438
Epoch 23 loss 832.4210815429688
Epoch 24 loss 766.4821166992188
Epoch 25 loss 853.2764892578125
Epoch 26 loss 839.3795166015625
Epoch 27 loss 701.6163330078125
Epoch 28 loss 741.883056640625
Epoch 29 loss 707.348876953125
Epoch 30 loss 656.3348999023438
Epoch 31 loss 665.9053344726562
Epoch 32 loss 577.9814453125
Epoch 33 loss 577.7438354492188
Epoch 34 loss 621.3932495117188
Epoch 35 loss 638.1556396484375
Epoch 36 loss 675.029052734375
Epoch 37 loss 583.2786865234375
Epoch 38 loss 572.69580078125
Epoch 39 loss 580.5252685546875
Epoch 40 loss 676.91845703125
Epoch 41 loss 583.975830078125
Epoch 42 loss 621.4995727539062
Epoch 43 loss 641.4437255859375
Epoch 44 loss 646.9895629882812
Epoch 45 loss 541.5744018554688
Epoch 46 loss 560.5986938476562
Epoch 47 loss 562.2797241210938
Epoch 48 loss 577.00634765625
Epoch 49 loss 517.1986083984375
Epoch 50 loss 518.458984375
Epoch 51 loss 557.7197265625
Epoch 52 loss 583.0989990234375
Epoch 53 loss 549.667724609375
Epoch 54 loss 494.05340576171875
Epoch 55 loss 517.4267578125
Epoch 56 loss 552.8853759765625
Epoch 57 loss 504.7875061035156
Epoch 58 loss 510.5450134277344
Epoch 59 loss 533.8811645507812
Epoch 60 loss 648.01220703125
Epoch 61 loss 490.49627685546875
Epoch 62 loss 527.8661499023438
Epoch 63 loss 731.7202758789062
Epoch 64 loss 597.73779296875
Epoch 65 loss 472.258544921875
Epoch 66 loss 574.8463745117188
Epoch 67 loss 495.72564697265625
Epoch 68 loss 509.8365478515625
Epoch 69 loss 523.7626342773438
Epoch 70 loss 532.593994140625
Epoch 71 loss 726.2205200195312
Epoch 72 loss 487.4416198730469
Epoch 73 loss 629.9037475585938
Epoch 74 loss 494.3818054199219
Epoch 75 loss 572.8489379882812
Epoch 76 loss 559.2808837890625
Epoch 77 loss 568.8873901367188
Epoch 78 loss 487.96282958984375
Epoch 79 loss 491.4770202636719
Epoch 80 loss 504.5060119628906
Epoch 81 loss 510.1448059082031
Epoch 82 loss 510.93243408203125
Epoch 83 loss 610.0675048828125
Epoch 84 loss 500.9674377441406
Epoch 85 loss 524.9969482421875
Epoch 86 loss 517.4186401367188
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 487.43958751249374, 'MSE - std': 48.71954306793046, 'R2 - mean': 0.9416502061795817, 'R2 - std': 0.005298803511636092} 
 

Results After CV: {'MSE - mean': 487.43958751249374, 'MSE - std': 48.71954306793046, 'R2 - mean': 0.9416502061795817, 'R2 - std': 0.005298803511636092}
Train time: 120.77443439320004
Inference time: 0.1426356991999455
Finished cross validation
Trial 5 finished with value: 487.43958751249374 and parameters: {'dim': 128, 'depth': 6, 'heads': 8, 'dropout': 0.1}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515503.78125
Epoch 1 loss 513969.96875
Epoch 2 loss 511186.40625
Epoch 3 loss 506064.71875
Epoch 4 loss 496486.25
Epoch 5 loss 478646.875
Epoch 6 loss 446357.78125
Epoch 7 loss 393135.5625
Epoch 8 loss 315449.96875
Epoch 9 loss 217384.984375
Epoch 10 loss 115987.5625
Epoch 11 loss 40352.27734375
Epoch 12 loss 10796.875
Epoch 13 loss 8890.271484375
Epoch 14 loss 8548.3955078125
Epoch 15 loss 8313.923828125
Epoch 16 loss 8035.9951171875
Epoch 17 loss 7324.720703125
Epoch 18 loss 5402.72265625
Epoch 19 loss 3837.84765625
Epoch 20 loss 2470.516357421875
Epoch 21 loss 1784.2349853515625
Epoch 22 loss 1771.1240234375
Epoch 23 loss 1508.2855224609375
Epoch 24 loss 1325.408203125
Epoch 25 loss 1374.9395751953125
Epoch 26 loss 1156.4114990234375
Epoch 27 loss 1415.0233154296875
Epoch 28 loss 1091.3365478515625
Epoch 29 loss 1016.3050537109375
Epoch 30 loss 1581.9031982421875
Epoch 31 loss 1086.4755859375
Epoch 32 loss 979.082275390625
Epoch 33 loss 1056.3887939453125
Epoch 34 loss 939.3820190429688
Epoch 35 loss 845.3409423828125
Epoch 36 loss 890.2062377929688
Epoch 37 loss 882.8877563476562
Epoch 38 loss 955.892822265625
Epoch 39 loss 803.88134765625
Epoch 40 loss 762.7184448242188
Epoch 41 loss 782.5133666992188
Epoch 42 loss 903.0763549804688
Epoch 43 loss 787.1182861328125
Epoch 44 loss 784.7037353515625
Epoch 45 loss 718.5206298828125
Epoch 46 loss 718.3155517578125
Epoch 47 loss 731.5462036132812
Epoch 48 loss 774.6328735351562
Epoch 49 loss 965.8779296875
Epoch 50 loss 694.648681640625
Epoch 51 loss 744.4948120117188
Epoch 52 loss 1152.1937255859375
Epoch 53 loss 673.10546875
Epoch 54 loss 682.3967895507812
Epoch 55 loss 726.0701293945312
Epoch 56 loss 662.2935791015625
Epoch 57 loss 670.697265625
Epoch 58 loss 711.36474609375
Epoch 59 loss 676.7628173828125
Epoch 60 loss 709.0942993164062
Epoch 61 loss 643.4071655273438
Epoch 62 loss 981.576416015625
Epoch 63 loss 654.5233764648438
Epoch 64 loss 684.7613525390625
Epoch 65 loss 638.4070434570312
Epoch 66 loss 643.3131103515625
Epoch 67 loss 689.2012329101562
Epoch 68 loss 791.7969360351562
Epoch 69 loss 648.0729370117188
Epoch 70 loss 760.531005859375
Epoch 71 loss 645.8934936523438
Epoch 72 loss 696.5248413085938
Epoch 73 loss 775.0579833984375
Epoch 74 loss 733.0279541015625
Epoch 75 loss 768.1563720703125
Epoch 76 loss 731.4279174804688
Epoch 77 loss 674.6864013671875
Epoch 78 loss 708.2984619140625
Epoch 79 loss 970.8477172851562
Epoch 80 loss 618.5025024414062
Epoch 81 loss 661.5543212890625
Epoch 82 loss 652.621337890625
Epoch 83 loss 675.7283935546875
Epoch 84 loss 701.4547729492188
Epoch 85 loss 626.67626953125
Epoch 86 loss 605.698486328125
Epoch 87 loss 712.2848510742188
Epoch 88 loss 606.481689453125
Epoch 89 loss 738.1889038085938
Epoch 90 loss 697.8043823242188
Epoch 91 loss 591.3683471679688
Epoch 92 loss 591.0432739257812
Epoch 93 loss 713.265869140625
Epoch 94 loss 627.33544921875
Epoch 95 loss 580.1162719726562
Epoch 96 loss 574.6935424804688
Epoch 97 loss 669.7922973632812
Epoch 98 loss 652.19677734375
Epoch 99 loss 577.269775390625
Saved Losses
{'MSE - mean': 574.6932421970192, 'MSE - std': 0.0, 'R2 - mean': 0.9331798671059732, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523260.96875
Epoch 1 loss 521106.875
Epoch 2 loss 517592.875
Epoch 3 loss 511340.4375
Epoch 4 loss 499867.8125
Epoch 5 loss 478751.75
Epoch 6 loss 441420.0625
Epoch 7 loss 381723.15625
Epoch 8 loss 297523.5
Epoch 9 loss 195509.015625
Epoch 10 loss 95863.8046875
Epoch 11 loss 29521.888671875
Epoch 12 loss 8552.537109375
Epoch 13 loss 7760.7294921875
Epoch 14 loss 7374.9609375
Epoch 15 loss 7140.22607421875
Epoch 16 loss 6453.95361328125
Epoch 17 loss 4193.00146484375
Epoch 18 loss 2450.4013671875
Epoch 19 loss 1821.6881103515625
Epoch 20 loss 1539.7794189453125
Epoch 21 loss 1482.6905517578125
Epoch 22 loss 1342.3487548828125
Epoch 23 loss 1081.010498046875
Epoch 24 loss 966.271240234375
Epoch 25 loss 1368.2098388671875
Epoch 26 loss 870.2145385742188
Epoch 27 loss 842.343994140625
Epoch 28 loss 851.6323852539062
Epoch 29 loss 1080.3739013671875
Epoch 30 loss 736.268310546875
Epoch 31 loss 786.7367553710938
Epoch 32 loss 802.5543212890625
Epoch 33 loss 693.293212890625
Epoch 34 loss 740.3929443359375
Epoch 35 loss 694.2076416015625
Epoch 36 loss 746.6296997070312
Epoch 37 loss 684.0011596679688
Epoch 38 loss 826.9984130859375
Epoch 39 loss 813.075439453125
Epoch 40 loss 633.9754028320312
Epoch 41 loss 634.0526733398438
Epoch 42 loss 849.407470703125
Epoch 43 loss 583.39404296875
Epoch 44 loss 610.872314453125
Epoch 45 loss 584.3154296875
Epoch 46 loss 620.135498046875
Epoch 47 loss 695.3113403320312
Epoch 48 loss 746.12060546875
Epoch 49 loss 725.913330078125
Epoch 50 loss 559.0297241210938
Epoch 51 loss 538.3419799804688
Epoch 52 loss 667.8590698242188
Epoch 53 loss 814.2491455078125
Epoch 54 loss 523.2067260742188
Epoch 55 loss 526.0182495117188
Epoch 56 loss 556.4364013671875
Epoch 57 loss 535.8145141601562
Epoch 58 loss 542.595458984375
Epoch 59 loss 743.5007934570312
Epoch 60 loss 616.6436157226562
Epoch 61 loss 530.6824951171875
Epoch 62 loss 590.4337768554688
Epoch 63 loss 560.9891357421875
Epoch 64 loss 762.3223266601562
Epoch 65 loss 545.226318359375
Epoch 66 loss 495.4322814941406
Epoch 67 loss 576.0739135742188
Epoch 68 loss 674.65869140625
Epoch 69 loss 549.9304809570312
Epoch 70 loss 510.9753112792969
Epoch 71 loss 600.482666015625
Epoch 72 loss 670.0680541992188
Epoch 73 loss 499.3433837890625
Epoch 74 loss 587.9296875
Epoch 75 loss 509.27911376953125
Epoch 76 loss 473.8601379394531
Epoch 77 loss 537.09521484375
Epoch 78 loss 580.0765991210938
Epoch 79 loss 494.18475341796875
Epoch 80 loss 532.08251953125
Epoch 81 loss 483.0092468261719
Epoch 82 loss 485.3972473144531
Epoch 83 loss 489.22515869140625
Epoch 84 loss 569.3966064453125
Epoch 85 loss 511.2984619140625
Epoch 86 loss 469.493896484375
Epoch 87 loss 494.4285583496094
Epoch 88 loss 716.3228149414062
Epoch 89 loss 547.680419921875
Epoch 90 loss 488.3803405761719
Epoch 91 loss 576.7095336914062
Epoch 92 loss 526.6343994140625
Epoch 93 loss 458.1200866699219
Epoch 94 loss 462.46173095703125
Epoch 95 loss 505.2850036621094
Epoch 96 loss 468.3405456542969
Epoch 97 loss 487.384765625
Epoch 98 loss 506.30621337890625
Epoch 99 loss 446.444091796875
Saved Losses
{'MSE - mean': 510.56862672144615, 'MSE - std': 64.12461547557308, 'R2 - mean': 0.9373742115222572, 'R2 - std': 0.004194344416284024} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516156.625
Epoch 1 loss 514031.46875
Epoch 2 loss 510426.75
Epoch 3 loss 504091.5
Epoch 4 loss 492791.125
Epoch 5 loss 471988.09375
Epoch 6 loss 434464.53125
Epoch 7 loss 374171.53125
Epoch 8 loss 289534.5
Epoch 9 loss 187594.015625
Epoch 10 loss 89907.609375
Epoch 11 loss 27113.474609375
Epoch 12 loss 9592.6083984375
Epoch 13 loss 9699.88671875
Epoch 14 loss 9041.232421875
Epoch 15 loss 8829.7822265625
Epoch 16 loss 8427.033203125
Epoch 17 loss 6900.7744140625
Epoch 18 loss 4311.89453125
Epoch 19 loss 3084.332275390625
Epoch 20 loss 2341.1630859375
Epoch 21 loss 1758.4683837890625
Epoch 22 loss 1668.3023681640625
Epoch 23 loss 1463.10009765625
Epoch 24 loss 1300.82568359375
Epoch 25 loss 1849.6112060546875
Epoch 26 loss 1216.6038818359375
Epoch 27 loss 1033.1527099609375
Epoch 28 loss 1195.0045166015625
Epoch 29 loss 987.79443359375
Epoch 30 loss 1158.102783203125
Epoch 31 loss 872.7279052734375
Epoch 32 loss 1528.8848876953125
Epoch 33 loss 1060.888427734375
Epoch 34 loss 895.834716796875
Epoch 35 loss 939.585205078125
Epoch 36 loss 825.2587280273438
Epoch 37 loss 990.9522094726562
Epoch 38 loss 993.8250122070312
Epoch 39 loss 828.6583251953125
Epoch 40 loss 883.4685668945312
Epoch 41 loss 1011.6534423828125
Epoch 42 loss 777.6317138671875
Epoch 43 loss 689.3155517578125
Epoch 44 loss 740.4432373046875
Epoch 45 loss 854.0601196289062
Epoch 46 loss 766.3612670898438
Epoch 47 loss 729.796142578125
Epoch 48 loss 626.732177734375
Epoch 49 loss 849.0789794921875
Epoch 50 loss 617.0245971679688
Epoch 51 loss 724.1181640625
Epoch 52 loss 763.3252563476562
Epoch 53 loss 687.8709106445312
Epoch 54 loss 554.022705078125
Epoch 55 loss 1050.213134765625
Epoch 56 loss 580.799072265625
Epoch 57 loss 871.0056762695312
Epoch 58 loss 749.3027954101562
Epoch 59 loss 562.657958984375
Epoch 60 loss 585.2348022460938
Epoch 61 loss 627.3577270507812
Epoch 62 loss 580.6171264648438
Epoch 63 loss 581.1602783203125
Epoch 64 loss 635.5526123046875
Epoch 65 loss 577.10693359375
Epoch 66 loss 613.93798828125
Epoch 67 loss 519.3719482421875
Epoch 68 loss 879.085205078125
Epoch 69 loss 685.0166015625
Epoch 70 loss 666.9962768554688
Epoch 71 loss 640.1372680664062
Epoch 72 loss 510.5451965332031
Epoch 73 loss 617.5814208984375
Epoch 74 loss 582.5095825195312
Epoch 75 loss 512.5490112304688
Epoch 76 loss 552.636962890625
Epoch 77 loss 589.8578491210938
Epoch 78 loss 509.2239990234375
Epoch 79 loss 612.9716186523438
Epoch 80 loss 605.0447998046875
Epoch 81 loss 600.588623046875
Epoch 82 loss 556.6780395507812
Epoch 83 loss 575.4688110351562
Epoch 84 loss 570.26318359375
Epoch 85 loss 577.9288940429688
Epoch 86 loss 829.7510986328125
Epoch 87 loss 604.9992065429688
Epoch 88 loss 478.1414794921875
Epoch 89 loss 568.9227294921875
Epoch 90 loss 602.7767333984375
Epoch 91 loss 510.48675537109375
Epoch 92 loss 620.653564453125
Epoch 93 loss 492.18536376953125
Epoch 94 loss 536.338134765625
Epoch 95 loss 560.0895385742188
Epoch 96 loss 600.3486328125
Epoch 97 loss 580.4812622070312
Epoch 98 loss 779.1032104492188
Epoch 99 loss 543.8015747070312
Saved Losses
{'MSE - mean': 499.75965368982423, 'MSE - std': 54.543365034225125, 'R2 - mean': 0.9411273060611042, 'R2 - std': 0.006316627841656317} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519059.65625
Epoch 1 loss 516890.375
Epoch 2 loss 513376.5625
Epoch 3 loss 507285.71875
Epoch 4 loss 496585.6875
Epoch 5 loss 477414.03125
Epoch 6 loss 442786.8125
Epoch 7 loss 386294.6875
Epoch 8 loss 305155.25
Epoch 9 loss 205158.359375
Epoch 10 loss 104766.4921875
Epoch 11 loss 34293.16015625
Epoch 12 loss 9576.2841796875
Epoch 13 loss 8550.78515625
Epoch 14 loss 8180.55322265625
Epoch 15 loss 7994.5673828125
Epoch 16 loss 7677.41015625
Epoch 17 loss 6721.85546875
Epoch 18 loss 4353.1806640625
Epoch 19 loss 2741.531982421875
Epoch 20 loss 2012.54443359375
Epoch 21 loss 2103.1279296875
Epoch 22 loss 1507.4468994140625
Epoch 23 loss 1415.78662109375
Epoch 24 loss 1931.23291015625
Epoch 25 loss 1077.02880859375
Epoch 26 loss 1533.213134765625
Epoch 27 loss 1003.9523315429688
Epoch 28 loss 1175.1883544921875
Epoch 29 loss 866.9075927734375
Epoch 30 loss 1046.356201171875
Epoch 31 loss 838.3395385742188
Epoch 32 loss 954.7300415039062
Epoch 33 loss 866.4979248046875
Epoch 34 loss 837.7635498046875
Epoch 35 loss 895.3466186523438
Epoch 36 loss 710.7689208984375
Epoch 37 loss 790.4060668945312
Epoch 38 loss 771.6880493164062
Epoch 39 loss 826.305908203125
Epoch 40 loss 984.038818359375
Epoch 41 loss 955.6932983398438
Epoch 42 loss 798.234375
Epoch 43 loss 627.5225219726562
Epoch 44 loss 734.7100830078125
Epoch 45 loss 625.9019165039062
Epoch 46 loss 854.6162109375
Epoch 47 loss 733.3524780273438
Epoch 48 loss 668.618896484375
Epoch 49 loss 608.6065673828125
Epoch 50 loss 1033.472900390625
Epoch 51 loss 569.3175048828125
Epoch 52 loss 556.27685546875
Epoch 53 loss 540.978271484375
Epoch 54 loss 596.4505615234375
Epoch 55 loss 695.8782348632812
Epoch 56 loss 632.278076171875
Epoch 57 loss 641.4307250976562
Epoch 58 loss 533.8848876953125
Epoch 59 loss 612.8955688476562
Epoch 60 loss 728.68798828125
Epoch 61 loss 650.6221923828125
Epoch 62 loss 617.7022094726562
Epoch 63 loss 536.6658935546875
Epoch 64 loss 655.6697998046875
Epoch 65 loss 537.80712890625
Epoch 66 loss 616.2118530273438
Epoch 67 loss 615.2781982421875
Epoch 68 loss 548.432373046875
Epoch 69 loss 855.6997680664062
Epoch 70 loss 712.7969970703125
Epoch 71 loss 744.2310180664062
Epoch 72 loss 537.66943359375
Epoch 73 loss 523.0465698242188
Epoch 74 loss 508.2771301269531
Epoch 75 loss 765.532958984375
Epoch 76 loss 676.5962524414062
Epoch 77 loss 535.39794921875
Epoch 78 loss 498.0225524902344
Epoch 79 loss 630.9081420898438
Epoch 80 loss 698.5891723632812
Epoch 81 loss 512.0202026367188
Epoch 82 loss 586.5264892578125
Epoch 83 loss 524.2782592773438
Epoch 84 loss 610.503662109375
Epoch 85 loss 626.0484008789062
Epoch 86 loss 611.0580444335938
Epoch 87 loss 595.3389892578125
Epoch 88 loss 729.91845703125
Epoch 89 loss 616.34521484375
Epoch 90 loss 657.14306640625
Epoch 91 loss 498.2524719238281
Epoch 92 loss 554.2239990234375
Epoch 93 loss 672.5640869140625
Epoch 94 loss 628.6165771484375
Epoch 95 loss 509.8887634277344
Epoch 96 loss 508.60516357421875
Epoch 97 loss 647.062744140625
Epoch 98 loss 753.8826904296875
Epoch 99 loss 488.4554138183594
Saved Losses
{'MSE - mean': 496.9335046899712, 'MSE - std': 47.488897191350524, 'R2 - mean': 0.9411427470151885, 'R2 - std': 0.005470425553526884} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516518.875
Epoch 1 loss 514192.25
Epoch 2 loss 510443.71875
Epoch 3 loss 503839.0625
Epoch 4 loss 492023.84375
Epoch 5 loss 470630.25
Epoch 6 loss 433147.9375
Epoch 7 loss 374085.3125
Epoch 8 loss 291370.5
Epoch 9 loss 191685.453125
Epoch 10 loss 94737.0078125
Epoch 11 loss 29404.197265625
Epoch 12 loss 8777.4375
Epoch 13 loss 8286.4306640625
Epoch 14 loss 7802.380859375
Epoch 15 loss 7544.9013671875
Epoch 16 loss 7085.17578125
Epoch 17 loss 5221.15283203125
Epoch 18 loss 3541.809326171875
Epoch 19 loss 2431.61865234375
Epoch 20 loss 1857.8182373046875
Epoch 21 loss 1569.5440673828125
Epoch 22 loss 1387.48779296875
Epoch 23 loss 1160.4036865234375
Epoch 24 loss 1362.9801025390625
Epoch 25 loss 1146.7991943359375
Epoch 26 loss 904.8106689453125
Epoch 27 loss 1106.2022705078125
Epoch 28 loss 810.327392578125
Epoch 29 loss 1077.0902099609375
Epoch 30 loss 758.7747192382812
Epoch 31 loss 1013.5333862304688
Epoch 32 loss 682.900634765625
Epoch 33 loss 789.0934448242188
Epoch 34 loss 697.41064453125
Epoch 35 loss 677.0650024414062
Epoch 36 loss 1009.05908203125
Epoch 37 loss 630.1174926757812
Epoch 38 loss 734.3853759765625
Epoch 39 loss 744.1514282226562
Epoch 40 loss 622.8258056640625
Epoch 41 loss 639.1320190429688
Epoch 42 loss 675.4783325195312
Epoch 43 loss 581.475830078125
Epoch 44 loss 735.1708374023438
Epoch 45 loss 593.3151245117188
Epoch 46 loss 663.0518188476562
Epoch 47 loss 781.7847900390625
Epoch 48 loss 675.2734985351562
Epoch 49 loss 598.02685546875
Epoch 50 loss 561.483642578125
Epoch 51 loss 577.1134033203125
Epoch 52 loss 552.5359497070312
Epoch 53 loss 612.9490966796875
Epoch 54 loss 539.9063720703125
Epoch 55 loss 546.6478271484375
Epoch 56 loss 570.138427734375
Epoch 57 loss 537.094970703125
Epoch 58 loss 612.6676025390625
Epoch 59 loss 607.6280517578125
Epoch 60 loss 536.413330078125
Epoch 61 loss 606.1958618164062
Epoch 62 loss 540.1229248046875
Epoch 63 loss 609.8767700195312
Epoch 64 loss 539.4442749023438
Epoch 65 loss 681.3029174804688
Epoch 66 loss 591.0657958984375
Epoch 67 loss 556.7920532226562
Epoch 68 loss 518.6502685546875
Epoch 69 loss 672.0693969726562
Epoch 70 loss 573.8656005859375
Epoch 71 loss 578.5623168945312
Epoch 72 loss 597.9883422851562
Epoch 73 loss 617.0252075195312
Epoch 74 loss 523.0148315429688
Epoch 75 loss 591.671875
Epoch 76 loss 518.4777221679688
Epoch 77 loss 661.8661499023438
Epoch 78 loss 572.9072875976562
Epoch 79 loss 511.4676513671875
Epoch 80 loss 556.2781982421875
Epoch 81 loss 539.0028686523438
Epoch 82 loss 498.0806579589844
Epoch 83 loss 515.7030029296875
Epoch 84 loss 520.4298706054688
Epoch 85 loss 569.5054321289062
Epoch 86 loss 686.7617797851562
Epoch 87 loss 506.35748291015625
Epoch 88 loss 492.5629577636719
Epoch 89 loss 562.9100341796875
Epoch 90 loss 612.3731689453125
Epoch 91 loss 488.97259521484375
Epoch 92 loss 495.7290344238281
Epoch 93 loss 543.369873046875
Epoch 94 loss 502.7856750488281
Epoch 95 loss 518.1625366210938
Epoch 96 loss 563.1446533203125
Epoch 97 loss 599.54345703125
Epoch 98 loss 540.65625
Epoch 99 loss 500.525390625
Saved Losses
{'MSE - mean': 495.34136287922075, 'MSE - std': 42.59455302433266, 'R2 - mean': 0.9406562256220559, 'R2 - std': 0.004988712945564884} 
 

Results After CV: {'MSE - mean': 495.34136287922075, 'MSE - std': 42.59455302433266, 'R2 - mean': 0.9406562256220559, 'R2 - std': 0.004988712945564884}
Train time: 97.31184538979997
Inference time: 0.14099416700000802
Finished cross validation
Trial 6 finished with value: 495.34136287922075 and parameters: {'dim': 256, 'depth': 2, 'heads': 2, 'dropout': 0.5}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514454.5625
Epoch 1 loss 512053.1875
Epoch 2 loss 508103.15625
Epoch 3 loss 501453.53125
Epoch 4 loss 489981.65625
Epoch 5 loss 469396.03125
Epoch 6 loss 432871.5625
Epoch 7 loss 374731.28125
Epoch 8 loss 293480.75
Epoch 9 loss 195412.5625
Epoch 10 loss 99115.4609375
Epoch 11 loss 32491.349609375
Epoch 12 loss 9737.431640625
Epoch 13 loss 8923.3955078125
Epoch 14 loss 8421.9501953125
Epoch 15 loss 8445.5849609375
Epoch 16 loss 7335.2412109375
Epoch 17 loss 4219.02294921875
Epoch 18 loss 2485.62060546875
Epoch 19 loss 2044.0850830078125
Epoch 20 loss 1591.9945068359375
Epoch 21 loss 1395.126953125
Epoch 22 loss 1200.38671875
Epoch 23 loss 1104.1943359375
Epoch 24 loss 1018.0046997070312
Epoch 25 loss 981.6476440429688
Epoch 26 loss 916.6920776367188
Epoch 27 loss 866.5035400390625
Epoch 28 loss 950.6695556640625
Epoch 29 loss 1061.70751953125
Epoch 30 loss 1007.734130859375
Epoch 31 loss 778.1907348632812
Epoch 32 loss 828.179443359375
Epoch 33 loss 753.4183959960938
Epoch 34 loss 838.4038696289062
Epoch 35 loss 755.5950317382812
Epoch 36 loss 790.7816772460938
Epoch 37 loss 736.2421875
Epoch 38 loss 739.470458984375
Epoch 39 loss 834.5177612304688
Epoch 40 loss 692.4732055664062
Epoch 41 loss 661.2734375
Epoch 42 loss 713.8967895507812
Epoch 43 loss 677.8890380859375
Epoch 44 loss 714.3618774414062
Epoch 45 loss 670.4589233398438
Epoch 46 loss 628.4938354492188
Epoch 47 loss 657.89599609375
Epoch 48 loss 653.2901000976562
Epoch 49 loss 724.2993774414062
Epoch 50 loss 646.1961059570312
Epoch 51 loss 617.9118041992188
Epoch 52 loss 677.27099609375
Epoch 53 loss 610.9749755859375
Epoch 54 loss 669.46826171875
Epoch 55 loss 662.697265625
Epoch 56 loss 615.7818603515625
Epoch 57 loss 930.684326171875
Epoch 58 loss 690.5075073242188
Epoch 59 loss 647.0072021484375
Epoch 60 loss 611.7797241210938
Epoch 61 loss 658.579833984375
Epoch 62 loss 626.8887939453125
Epoch 63 loss 706.4017944335938
Epoch 64 loss 713.975341796875
Epoch 65 loss 608.9171752929688
Epoch 66 loss 592.7130737304688
Epoch 67 loss 578.9296875
Epoch 68 loss 576.51171875
Epoch 69 loss 728.6840209960938
Epoch 70 loss 581.4777221679688
Epoch 71 loss 585.3626708984375
Epoch 72 loss 617.9154052734375
Epoch 73 loss 626.9085083007812
Epoch 74 loss 613.0377807617188
Epoch 75 loss 565.0107421875
Epoch 76 loss 821.71484375
Epoch 77 loss 583.8847045898438
Epoch 78 loss 560.6279907226562
Epoch 79 loss 557.304443359375
Epoch 80 loss 587.6878051757812
Epoch 81 loss 576.3453979492188
Epoch 82 loss 587.6033935546875
Epoch 83 loss 645.9545288085938
Epoch 84 loss 568.9794921875
Epoch 85 loss 562.7965698242188
Epoch 86 loss 561.3607788085938
Epoch 87 loss 591.7654418945312
Epoch 88 loss 591.6603393554688
Epoch 89 loss 564.9763793945312
Epoch 90 loss 613.8193359375
Epoch 91 loss 637.1935424804688
Epoch 92 loss 600.971923828125
Epoch 93 loss 568.032958984375
Epoch 94 loss 558.3279418945312
Epoch 95 loss 680.7162475585938
Epoch 96 loss 605.0111083984375
Epoch 97 loss 628.9933471679688
Epoch 98 loss 644.014404296875
Epoch 99 loss 656.336669921875
Saved Losses
{'MSE - mean': 557.3045611989039, 'MSE - std': 0.0, 'R2 - mean': 0.9352016656757702, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523423.3125
Epoch 1 loss 520859.34375
Epoch 2 loss 516752.3125
Epoch 3 loss 510079.0
Epoch 4 loss 498914.1875
Epoch 5 loss 478445.34375
Epoch 6 loss 441267.25
Epoch 7 loss 381229.90625
Epoch 8 loss 296201.53125
Epoch 9 loss 193386.140625
Epoch 10 loss 93715.421875
Epoch 11 loss 28261.708984375
Epoch 12 loss 8383.384765625
Epoch 13 loss 7789.19873046875
Epoch 14 loss 7531.7763671875
Epoch 15 loss 7196.07080078125
Epoch 16 loss 5596.8623046875
Epoch 17 loss 2806.00048828125
Epoch 18 loss 2065.684814453125
Epoch 19 loss 1603.0625
Epoch 20 loss 1554.4813232421875
Epoch 21 loss 1353.8603515625
Epoch 22 loss 1007.346923828125
Epoch 23 loss 1149.7052001953125
Epoch 24 loss 876.9906616210938
Epoch 25 loss 893.217529296875
Epoch 26 loss 830.3656616210938
Epoch 27 loss 1032.7156982421875
Epoch 28 loss 917.3564453125
Epoch 29 loss 749.408203125
Epoch 30 loss 744.5010375976562
Epoch 31 loss 683.8990478515625
Epoch 32 loss 629.8887939453125
Epoch 33 loss 640.5493774414062
Epoch 34 loss 936.8486938476562
Epoch 35 loss 647.0144653320312
Epoch 36 loss 600.6046752929688
Epoch 37 loss 618.0057373046875
Epoch 38 loss 582.13525390625
Epoch 39 loss 534.9999389648438
Epoch 40 loss 554.1805419921875
Epoch 41 loss 591.7826538085938
Epoch 42 loss 779.3723754882812
Epoch 43 loss 506.5403747558594
Epoch 44 loss 538.1766357421875
Epoch 45 loss 532.95068359375
Epoch 46 loss 682.575439453125
Epoch 47 loss 493.8704833984375
Epoch 48 loss 569.9473266601562
Epoch 49 loss 525.56396484375
Epoch 50 loss 559.5805053710938
Epoch 51 loss 547.5460815429688
Epoch 52 loss 524.08056640625
Epoch 53 loss 485.4131164550781
Epoch 54 loss 479.492919921875
Epoch 55 loss 483.276123046875
Epoch 56 loss 466.93310546875
Epoch 57 loss 683.03076171875
Epoch 58 loss 500.8310241699219
Epoch 59 loss 469.5093688964844
Epoch 60 loss 613.9464721679688
Epoch 61 loss 493.4712219238281
Epoch 62 loss 631.0739135742188
Epoch 63 loss 478.62274169921875
Epoch 64 loss 499.72686767578125
Epoch 65 loss 550.5886840820312
Epoch 66 loss 493.4828186035156
Epoch 67 loss 455.20526123046875
Epoch 68 loss 489.0983581542969
Epoch 69 loss 459.8716735839844
Epoch 70 loss 482.79315185546875
Epoch 71 loss 493.9087829589844
Epoch 72 loss 500.4941711425781
Epoch 73 loss 476.44970703125
Epoch 74 loss 608.3010864257812
Epoch 75 loss 451.9924621582031
Epoch 76 loss 475.1708068847656
Epoch 77 loss 438.27716064453125
Epoch 78 loss 440.2220153808594
Epoch 79 loss 459.562255859375
Epoch 80 loss 454.4556579589844
Epoch 81 loss 473.38140869140625
Epoch 82 loss 518.472412109375
Epoch 83 loss 448.32916259765625
Epoch 84 loss 497.0978088378906
Epoch 85 loss 474.1810607910156
Epoch 86 loss 456.08514404296875
Epoch 87 loss 434.7496643066406
Epoch 88 loss 452.4302673339844
Epoch 89 loss 675.0845336914062
Epoch 90 loss 454.2558288574219
Epoch 91 loss 457.17010498046875
Epoch 92 loss 602.6226196289062
Epoch 93 loss 491.933837890625
Epoch 94 loss 481.5390319824219
Epoch 95 loss 534.9720458984375
Epoch 96 loss 438.3181457519531
Epoch 97 loss 443.73760986328125
Epoch 98 loss 468.2837219238281
Epoch 99 loss 481.8882751464844
Saved Losses
{'MSE - mean': 496.02708683717947, 'MSE - std': 61.277474361724444, 'R2 - mean': 0.9391504034198611, 'R2 - std': 0.00394873774409088} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514501.96875
Epoch 1 loss 511399.46875
Epoch 2 loss 506803.78125
Epoch 3 loss 499634.65625
Epoch 4 loss 488047.21875
Epoch 5 loss 467376.625
Epoch 6 loss 429964.9375
Epoch 7 loss 370163.21875
Epoch 8 loss 286818.125
Epoch 9 loss 186372.40625
Epoch 10 loss 90023.1640625
Epoch 11 loss 27622.056640625
Epoch 12 loss 9660.4521484375
Epoch 13 loss 9678.515625
Epoch 14 loss 9072.45703125
Epoch 15 loss 8962.271484375
Epoch 16 loss 7242.4345703125
Epoch 17 loss 3832.2939453125
Epoch 18 loss 2218.804931640625
Epoch 19 loss 1853.4862060546875
Epoch 20 loss 1798.094482421875
Epoch 21 loss 1355.9984130859375
Epoch 22 loss 1300.3419189453125
Epoch 23 loss 1155.0347900390625
Epoch 24 loss 1054.4344482421875
Epoch 25 loss 1050.9881591796875
Epoch 26 loss 971.2868041992188
Epoch 27 loss 909.64404296875
Epoch 28 loss 914.724609375
Epoch 29 loss 859.3843383789062
Epoch 30 loss 852.8743896484375
Epoch 31 loss 834.308837890625
Epoch 32 loss 746.891357421875
Epoch 33 loss 897.9959716796875
Epoch 34 loss 809.072021484375
Epoch 35 loss 696.7158203125
Epoch 36 loss 680.8614501953125
Epoch 37 loss 758.28515625
Epoch 38 loss 825.8607177734375
Epoch 39 loss 641.1860961914062
Epoch 40 loss 648.85693359375
Epoch 41 loss 711.9024047851562
Epoch 42 loss 671.8427734375
Epoch 43 loss 645.3751831054688
Epoch 44 loss 609.5560913085938
Epoch 45 loss 656.40625
Epoch 46 loss 570.2784423828125
Epoch 47 loss 654.3828735351562
Epoch 48 loss 566.2920532226562
Epoch 49 loss 640.7523803710938
Epoch 50 loss 600.5540161132812
Epoch 51 loss 555.3327026367188
Epoch 52 loss 605.34765625
Epoch 53 loss 617.1327514648438
Epoch 54 loss 558.35986328125
Epoch 55 loss 590.1168823242188
Epoch 56 loss 570.69140625
Epoch 57 loss 679.6050415039062
Epoch 58 loss 547.7698974609375
Epoch 59 loss 816.215087890625
Epoch 60 loss 535.6561889648438
Epoch 61 loss 625.025146484375
Epoch 62 loss 642.7242431640625
Epoch 63 loss 689.7722778320312
Epoch 64 loss 840.8895874023438
Epoch 65 loss 511.4728698730469
Epoch 66 loss 570.32080078125
Epoch 67 loss 643.90771484375
Epoch 68 loss 515.6703491210938
Epoch 69 loss 508.5246887207031
Epoch 70 loss 538.4447021484375
Epoch 71 loss 590.8858642578125
Epoch 72 loss 627.9801025390625
Epoch 73 loss 558.0082397460938
Epoch 74 loss 670.8383178710938
Epoch 75 loss 616.5714721679688
Epoch 76 loss 548.7125854492188
Epoch 77 loss 496.0813903808594
Epoch 78 loss 554.4619750976562
Epoch 79 loss 505.2890930175781
Epoch 80 loss 887.427734375
Epoch 81 loss 536.1000366210938
Epoch 82 loss 654.2760620117188
Epoch 83 loss 493.45758056640625
Epoch 84 loss 551.8557739257812
Epoch 85 loss 840.7947998046875
Epoch 86 loss 541.8336791992188
Epoch 87 loss 492.8324890136719
Epoch 88 loss 572.266845703125
Epoch 89 loss 515.1234741210938
Epoch 90 loss 745.7769165039062
Epoch 91 loss 575.36376953125
Epoch 92 loss 651.1448974609375
Epoch 93 loss 492.52764892578125
Epoch 94 loss 653.5482177734375
Epoch 95 loss 492.794677734375
Epoch 96 loss 530.3322143554688
Epoch 97 loss 494.6369323730469
Epoch 98 loss 678.1085205078125
Epoch 99 loss 525.7452392578125
Saved Losses
{'MSE - mean': 494.8606511332136, 'MSE - std': 50.060034497965574, 'R2 - mean': 0.9417962713464219, 'R2 - std': 0.004939256423526146} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518178.78125
Epoch 1 loss 515673.59375
Epoch 2 loss 511980.59375
Epoch 3 loss 506136.3125
Epoch 4 loss 496668.78125
Epoch 5 loss 480182.15625
Epoch 6 loss 450228.46875
Epoch 7 loss 400903.0625
Epoch 8 loss 329357.25
Epoch 9 loss 237817.375
Epoch 10 loss 138565.484375
Epoch 11 loss 56340.859375
Epoch 12 loss 15182.9169921875
Epoch 13 loss 8290.2919921875
Epoch 14 loss 8318.908203125
Epoch 15 loss 8067.7529296875
Epoch 16 loss 7522.21240234375
Epoch 17 loss 5187.2080078125
Epoch 18 loss 2978.875732421875
Epoch 19 loss 2471.09619140625
Epoch 20 loss 1767.240478515625
Epoch 21 loss 1510.338623046875
Epoch 22 loss 1408.252197265625
Epoch 23 loss 1309.2030029296875
Epoch 24 loss 1097.09130859375
Epoch 25 loss 1088.3731689453125
Epoch 26 loss 1041.0946044921875
Epoch 27 loss 985.4286499023438
Epoch 28 loss 1147.3800048828125
Epoch 29 loss 985.3181762695312
Epoch 30 loss 819.3334350585938
Epoch 31 loss 779.2508544921875
Epoch 32 loss 779.2245483398438
Epoch 33 loss 792.7871704101562
Epoch 34 loss 827.1571044921875
Epoch 35 loss 775.1776733398438
Epoch 36 loss 806.1597900390625
Epoch 37 loss 864.7804565429688
Epoch 38 loss 685.712890625
Epoch 39 loss 778.1004638671875
Epoch 40 loss 685.3967895507812
Epoch 41 loss 660.0462036132812
Epoch 42 loss 627.7048950195312
Epoch 43 loss 801.4168701171875
Epoch 44 loss 745.5406494140625
Epoch 45 loss 637.3658447265625
Epoch 46 loss 889.5833129882812
Epoch 47 loss 608.5890502929688
Epoch 48 loss 866.8930053710938
Epoch 49 loss 588.8417358398438
Epoch 50 loss 607.5083618164062
Epoch 51 loss 882.3345336914062
Epoch 52 loss 620.8306884765625
Epoch 53 loss 591.4647827148438
Epoch 54 loss 611.3575439453125
Epoch 55 loss 623.6781616210938
Epoch 56 loss 634.4241943359375
Epoch 57 loss 605.6509399414062
Epoch 58 loss 546.2055053710938
Epoch 59 loss 714.1265258789062
Epoch 60 loss 613.6853637695312
Epoch 61 loss 529.4697265625
Epoch 62 loss 861.6954345703125
Epoch 63 loss 546.515869140625
Epoch 64 loss 555.7027587890625
Epoch 65 loss 529.5247802734375
Epoch 66 loss 594.826416015625
Epoch 67 loss 620.7869873046875
Epoch 68 loss 644.3408203125
Epoch 69 loss 534.5004272460938
Epoch 70 loss 557.1921997070312
Epoch 71 loss 635.7479248046875
Epoch 72 loss 523.9978637695312
Epoch 73 loss 513.66650390625
Epoch 74 loss 763.4989013671875
Epoch 75 loss 504.0956115722656
Epoch 76 loss 730.90478515625
Epoch 77 loss 514.8532104492188
Epoch 78 loss 734.1928100585938
Epoch 79 loss 510.553955078125
Epoch 80 loss 715.3601684570312
Epoch 81 loss 513.556640625
Epoch 82 loss 569.3104858398438
Epoch 83 loss 495.4780578613281
Epoch 84 loss 650.8059692382812
Epoch 85 loss 495.6397705078125
Epoch 86 loss 621.9021606445312
Epoch 87 loss 506.78948974609375
Epoch 88 loss 565.152099609375
Epoch 89 loss 493.5469055175781
Epoch 90 loss 619.7453002929688
Epoch 91 loss 546.6257934570312
Epoch 92 loss 490.2091979980469
Epoch 93 loss 508.338134765625
Epoch 94 loss 524.1206665039062
Epoch 95 loss 526.6586303710938
Epoch 96 loss 619.0637817382812
Epoch 97 loss 566.2399291992188
Epoch 98 loss 530.3878173828125
Epoch 99 loss 523.7200927734375
Saved Losses
{'MSE - mean': 493.6977394107726, 'MSE - std': 43.400027436347315, 'R2 - mean': 0.9415916763430351, 'R2 - std': 0.00429217518971916} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516195.6875
Epoch 1 loss 513997.1875
Epoch 2 loss 510464.3125
Epoch 3 loss 504707.84375
Epoch 4 loss 495390.34375
Epoch 5 loss 478259.03125
Epoch 6 loss 445949.375
Epoch 7 loss 392894.3125
Epoch 8 loss 316187.3125
Epoch 9 loss 218747.625
Epoch 10 loss 117051.1484375
Epoch 11 loss 40921.1484375
Epoch 12 loss 10431.271484375
Epoch 13 loss 8169.0849609375
Epoch 14 loss 7860.49560546875
Epoch 15 loss 7805.12548828125
Epoch 16 loss 7236.92236328125
Epoch 17 loss 4775.0791015625
Epoch 18 loss 2511.9716796875
Epoch 19 loss 2175.09912109375
Epoch 20 loss 1526.9893798828125
Epoch 21 loss 1268.05859375
Epoch 22 loss 1221.7392578125
Epoch 23 loss 1013.9814453125
Epoch 24 loss 931.5602416992188
Epoch 25 loss 883.01904296875
Epoch 26 loss 840.5374145507812
Epoch 27 loss 788.8790893554688
Epoch 28 loss 766.7818603515625
Epoch 29 loss 741.7451171875
Epoch 30 loss 682.7470092773438
Epoch 31 loss 774.2290649414062
Epoch 32 loss 866.9129638671875
Epoch 33 loss 694.51025390625
Epoch 34 loss 691.1555786132812
Epoch 35 loss 687.68701171875
Epoch 36 loss 628.5582885742188
Epoch 37 loss 769.71484375
Epoch 38 loss 773.3466796875
Epoch 39 loss 604.9713745117188
Epoch 40 loss 620.7546997070312
Epoch 41 loss 592.1243286132812
Epoch 42 loss 662.7359619140625
Epoch 43 loss 581.283935546875
Epoch 44 loss 550.5122680664062
Epoch 45 loss 737.4599609375
Epoch 46 loss 553.6023559570312
Epoch 47 loss 559.9824829101562
Epoch 48 loss 526.9824829101562
Epoch 49 loss 574.3461303710938
Epoch 50 loss 559.8981323242188
Epoch 51 loss 522.188720703125
Epoch 52 loss 523.5460815429688
Epoch 53 loss 519.3087768554688
Epoch 54 loss 495.72674560546875
Epoch 55 loss 503.9969787597656
Epoch 56 loss 567.8363647460938
Epoch 57 loss 523.9885864257812
Epoch 58 loss 493.6004638671875
Epoch 59 loss 502.7669677734375
Epoch 60 loss 486.9497985839844
Epoch 61 loss 527.6565551757812
Epoch 62 loss 503.5184020996094
Epoch 63 loss 530.6484985351562
Epoch 64 loss 488.71728515625
Epoch 65 loss 520.7609252929688
Epoch 66 loss 593.27880859375
Epoch 67 loss 513.0771484375
Epoch 68 loss 568.47314453125
Epoch 69 loss 518.1595458984375
Epoch 70 loss 477.7792053222656
Epoch 71 loss 467.358154296875
Epoch 72 loss 476.2681884765625
Epoch 73 loss 486.7894592285156
Epoch 74 loss 519.5012817382812
Epoch 75 loss 550.7089233398438
Epoch 76 loss 474.5246276855469
Epoch 77 loss 500.4359436035156
Epoch 78 loss 479.8434753417969
Epoch 79 loss 500.1606140136719
Epoch 80 loss 578.397705078125
Epoch 81 loss 559.4655151367188
Epoch 82 loss 590.3651733398438
Epoch 83 loss 483.7377014160156
Epoch 84 loss 518.6111450195312
Epoch 85 loss 467.72076416015625
Epoch 86 loss 518.1947021484375
Epoch 87 loss 537.867919921875
Epoch 88 loss 463.8255615234375
Epoch 89 loss 481.9026184082031
Epoch 90 loss 623.9195556640625
Epoch 91 loss 528.8323974609375
Epoch 92 loss 495.57098388671875
Epoch 93 loss 466.54742431640625
Epoch 94 loss 469.131591796875
Epoch 95 loss 460.1145324707031
Epoch 96 loss 501.2001953125
Epoch 97 loss 507.9260559082031
Epoch 98 loss 469.9091796875
Epoch 99 loss 471.7833251953125
Saved Losses
{'MSE - mean': 486.98109253645026, 'MSE - std': 41.07679741798205, 'R2 - mean': 0.9417388124353288, 'R2 - std': 0.0038503000410376356} 
 

Results After CV: {'MSE - mean': 486.98109253645026, 'MSE - std': 41.07679741798205, 'R2 - mean': 0.9417388124353288, 'R2 - std': 0.0038503000410376356}
Train time: 105.89562279440015
Inference time: 0.13887952740005857
Finished cross validation
Trial 7 finished with value: 486.98109253645026 and parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.3}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 512425.65625
Epoch 1 loss 509292.90625
Epoch 2 loss 504682.71875
Epoch 3 loss 498653.1875
Epoch 4 loss 489234.21875
Epoch 5 loss 469594.15625
Epoch 6 loss 433021.09375
Epoch 7 loss 374136.6875
Epoch 8 loss 290947.125
Epoch 9 loss 189999.84375
Epoch 10 loss 92197.4140625
Epoch 11 loss 27977.6875
Epoch 12 loss 9060.8291015625
Epoch 13 loss 9059.451171875
Epoch 14 loss 8593.5244140625
Epoch 15 loss 8644.2548828125
Epoch 16 loss 8152.2431640625
Epoch 17 loss 6321.73828125
Epoch 18 loss 4233.8330078125
Epoch 19 loss 2852.23828125
Epoch 20 loss 2172.99609375
Epoch 21 loss 1879.54833984375
Epoch 22 loss 1322.1759033203125
Epoch 23 loss 1915.00634765625
Epoch 24 loss 1276.95947265625
Epoch 25 loss 1075.924072265625
Epoch 26 loss 1434.5386962890625
Epoch 27 loss 928.72314453125
Epoch 28 loss 1219.70068359375
Epoch 29 loss 1042.009521484375
Epoch 30 loss 1105.6402587890625
Epoch 31 loss 989.8493041992188
Epoch 32 loss 809.9511108398438
Epoch 33 loss 1099.221435546875
Epoch 34 loss 763.85009765625
Epoch 35 loss 763.8326416015625
Epoch 36 loss 715.0703735351562
Epoch 37 loss 950.1534423828125
Epoch 38 loss 902.9981079101562
Epoch 39 loss 983.4144897460938
Epoch 40 loss 840.4947509765625
Epoch 41 loss 839.799560546875
Epoch 42 loss 809.8381958007812
Epoch 43 loss 828.3761596679688
Epoch 44 loss 713.4202880859375
Epoch 45 loss 837.755126953125
Epoch 46 loss 669.1317138671875
Epoch 47 loss 764.7789916992188
Epoch 48 loss 715.1796875
Epoch 49 loss 768.110595703125
Epoch 50 loss 817.6438598632812
Epoch 51 loss 776.4072875976562
Epoch 52 loss 717.6723022460938
Epoch 53 loss 661.22607421875
Epoch 54 loss 1099.1058349609375
Epoch 55 loss 905.8494873046875
Epoch 56 loss 911.977783203125
Epoch 57 loss 685.1551513671875
Epoch 58 loss 690.3643798828125
Epoch 59 loss 925.7726440429688
Epoch 60 loss 755.57470703125
Epoch 61 loss 801.8167724609375
Epoch 62 loss 705.3171997070312
Epoch 63 loss 769.3890380859375
Epoch 64 loss 680.498291015625
Epoch 65 loss 741.920654296875
Epoch 66 loss 598.8761596679688
Epoch 67 loss 682.9540405273438
Epoch 68 loss 611.6981201171875
Epoch 69 loss 927.264404296875
Epoch 70 loss 731.7689819335938
Epoch 71 loss 665.8531494140625
Epoch 72 loss 744.4359741210938
Epoch 73 loss 649.804931640625
Epoch 74 loss 626.806884765625
Epoch 75 loss 716.5125732421875
Epoch 76 loss 663.27783203125
Epoch 77 loss 640.4542236328125
Epoch 78 loss 651.5244140625
Epoch 79 loss 711.6397094726562
Epoch 80 loss 643.5255737304688
Epoch 81 loss 623.4470825195312
Epoch 82 loss 914.603515625
Epoch 83 loss 609.0596313476562
Epoch 84 loss 608.6043701171875
Epoch 85 loss 641.6264038085938
Epoch 86 loss 683.9255981445312
Epoch 87 loss 655.9797973632812
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 598.8761229295216, 'MSE - std': 0.0, 'R2 - mean': 0.9303681004352383, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 521411.65625
Epoch 1 loss 518458.90625
Epoch 2 loss 514149.46875
Epoch 3 loss 508158.1875
Epoch 4 loss 498830.25
Epoch 5 loss 479509.25
Epoch 6 loss 442989.875
Epoch 7 loss 383498.875
Epoch 8 loss 299209.5625
Epoch 9 loss 196286.609375
Epoch 10 loss 95818.5625
Epoch 11 loss 28728.53125
Epoch 12 loss 8423.8408203125
Epoch 13 loss 7784.02294921875
Epoch 14 loss 7731.75244140625
Epoch 15 loss 7654.255859375
Epoch 16 loss 7664.09130859375
Epoch 17 loss 7613.94580078125
Epoch 18 loss 6362.1005859375
Epoch 19 loss 4738.75
Epoch 20 loss 2659.583984375
Epoch 21 loss 1694.2803955078125
Epoch 22 loss 1297.6510009765625
Epoch 23 loss 1215.3173828125
Epoch 24 loss 1259.6923828125
Epoch 25 loss 966.3405151367188
Epoch 26 loss 883.0839233398438
Epoch 27 loss 1234.96533203125
Epoch 28 loss 1184.6212158203125
Epoch 29 loss 749.06591796875
Epoch 30 loss 738.9473876953125
Epoch 31 loss 674.3123779296875
Epoch 32 loss 656.285400390625
Epoch 33 loss 859.0609130859375
Epoch 34 loss 695.7626953125
Epoch 35 loss 622.18115234375
Epoch 36 loss 642.6561279296875
Epoch 37 loss 683.7748413085938
Epoch 38 loss 787.9530639648438
Epoch 39 loss 690.5852661132812
Epoch 40 loss 575.0744018554688
Epoch 41 loss 688.8088989257812
Epoch 42 loss 719.5557250976562
Epoch 43 loss 633.6593627929688
Epoch 44 loss 541.5917358398438
Epoch 45 loss 538.6231079101562
Epoch 46 loss 557.7451171875
Epoch 47 loss 599.205078125
Epoch 48 loss 609.1132202148438
Epoch 49 loss 581.0465087890625
Epoch 50 loss 686.0753173828125
Epoch 51 loss 560.0023803710938
Epoch 52 loss 577.0457153320312
Epoch 53 loss 519.767822265625
Epoch 54 loss 603.6004028320312
Epoch 55 loss 665.0478515625
Epoch 56 loss 581.2861938476562
Epoch 57 loss 528.6032104492188
Epoch 58 loss 547.0300903320312
Epoch 59 loss 641.7025756835938
Epoch 60 loss 550.7608032226562
Epoch 61 loss 534.4593505859375
Epoch 62 loss 525.8941040039062
Epoch 63 loss 554.9946899414062
Epoch 64 loss 553.0111694335938
Epoch 65 loss 561.4713134765625
Epoch 66 loss 550.199462890625
Epoch 67 loss 585.4846801757812
Epoch 68 loss 578.18017578125
Epoch 69 loss 567.4246215820312
Epoch 70 loss 532.0252685546875
Epoch 71 loss 666.2340087890625
Epoch 72 loss 496.82763671875
Epoch 73 loss 523.0134887695312
Epoch 74 loss 519.161376953125
Epoch 75 loss 495.5875549316406
Epoch 76 loss 545.0989990234375
Epoch 77 loss 494.039306640625
Epoch 78 loss 577.1544799804688
Epoch 79 loss 515.9719848632812
Epoch 80 loss 503.3036193847656
Epoch 81 loss 489.2386474609375
Epoch 82 loss 496.666259765625
Epoch 83 loss 510.4586486816406
Epoch 84 loss 520.3048706054688
Epoch 85 loss 586.1482543945312
Epoch 86 loss 536.1618041992188
Epoch 87 loss 493.4960021972656
Epoch 88 loss 483.78997802734375
Epoch 89 loss 524.9830322265625
Epoch 90 loss 614.4026489257812
Epoch 91 loss 534.0397338867188
Epoch 92 loss 529.4478759765625
Epoch 93 loss 740.0770874023438
Epoch 94 loss 558.01416015625
Epoch 95 loss 507.7065124511719
Epoch 96 loss 692.884521484375
Epoch 97 loss 472.1591491699219
Epoch 98 loss 476.0953369140625
Epoch 99 loss 549.2621459960938
Saved Losses
{'MSE - mean': 535.5176189513783, 'MSE - std': 63.35850397814329, 'R2 - mean': 0.9342855072651948, 'R2 - std': 0.003917406829956505} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515047.90625
Epoch 1 loss 512335.9375
Epoch 2 loss 508204.59375
Epoch 3 loss 502112.375
Epoch 4 loss 492570.78125
Epoch 5 loss 473044.6875
Epoch 6 loss 437007.9375
Epoch 7 loss 379551.96875
Epoch 8 loss 298326.59375
Epoch 9 loss 198669.921875
Epoch 10 loss 99963.609375
Epoch 11 loss 32400.22265625
Epoch 12 loss 10169.7802734375
Epoch 13 loss 9686.4580078125
Epoch 14 loss 9322.298828125
Epoch 15 loss 9312.8671875
Epoch 16 loss 8800.7744140625
Epoch 17 loss 5825.69482421875
Epoch 18 loss 4286.70068359375
Epoch 19 loss 2943.50830078125
Epoch 20 loss 1987.0848388671875
Epoch 21 loss 1449.888671875
Epoch 22 loss 1540.3995361328125
Epoch 23 loss 1090.1026611328125
Epoch 24 loss 1146.1278076171875
Epoch 25 loss 1067.16748046875
Epoch 26 loss 1056.9393310546875
Epoch 27 loss 1012.0140380859375
Epoch 28 loss 916.0211181640625
Epoch 29 loss 933.4810180664062
Epoch 30 loss 892.697998046875
Epoch 31 loss 740.9520874023438
Epoch 32 loss 1173.43408203125
Epoch 33 loss 1069.389892578125
Epoch 34 loss 894.42431640625
Epoch 35 loss 863.1146850585938
Epoch 36 loss 701.0924072265625
Epoch 37 loss 1131.3724365234375
Epoch 38 loss 642.873291015625
Epoch 39 loss 622.2459106445312
Epoch 40 loss 598.6729125976562
Epoch 41 loss 639.1576538085938
Epoch 42 loss 618.2302856445312
Epoch 43 loss 757.929443359375
Epoch 44 loss 821.9740600585938
Epoch 45 loss 788.662841796875
Epoch 46 loss 553.5502319335938
Epoch 47 loss 651.6422729492188
Epoch 48 loss 555.9803466796875
Epoch 49 loss 669.2178955078125
Epoch 50 loss 594.871826171875
Epoch 51 loss 560.2796020507812
Epoch 52 loss 561.4015502929688
Epoch 53 loss 943.1743774414062
Epoch 54 loss 593.5896606445312
Epoch 55 loss 515.5922241210938
Epoch 56 loss 537.200927734375
Epoch 57 loss 517.596435546875
Epoch 58 loss 658.250244140625
Epoch 59 loss 728.04345703125
Epoch 60 loss 551.57177734375
Epoch 61 loss 649.559326171875
Epoch 62 loss 650.3590698242188
Epoch 63 loss 566.923095703125
Epoch 64 loss 639.3848876953125
Epoch 65 loss 620.7283935546875
Epoch 66 loss 541.5159912109375
Epoch 67 loss 562.1324462890625
Epoch 68 loss 559.3932495117188
Epoch 69 loss 820.8414306640625
Epoch 70 loss 613.869873046875
Epoch 71 loss 846.17333984375
Epoch 72 loss 539.506591796875
Epoch 73 loss 518.6497802734375
Epoch 74 loss 559.5660400390625
Epoch 75 loss 568.2017822265625
Epoch 76 loss 526.2996826171875
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 528.8758466010648, 'MSE - std': 52.57781183610036, 'R2 - mean': 0.9377270708653612, 'R2 - std': 0.005824039624027338} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518699.90625
Epoch 1 loss 516610.1875
Epoch 2 loss 513297.59375
Epoch 3 loss 508506.25
Epoch 4 loss 501102.34375
Epoch 5 loss 485730.84375
Epoch 6 loss 456089.03125
Epoch 7 loss 406281.375
Epoch 8 loss 332279.1875
Epoch 9 loss 236621.015625
Epoch 10 loss 133416.078125
Epoch 11 loss 50692.6796875
Epoch 12 loss 13282.7294921875
Epoch 13 loss 8356.490234375
Epoch 14 loss 8392.68359375
Epoch 15 loss 8302.8017578125
Epoch 16 loss 8301.603515625
Epoch 17 loss 7436.50390625
Epoch 18 loss 5033.3193359375
Epoch 19 loss 3318.1103515625
Epoch 20 loss 2246.461181640625
Epoch 21 loss 1640.3575439453125
Epoch 22 loss 1469.1995849609375
Epoch 23 loss 1309.344970703125
Epoch 24 loss 1170.3525390625
Epoch 25 loss 1153.257568359375
Epoch 26 loss 1066.3023681640625
Epoch 27 loss 922.0352783203125
Epoch 28 loss 835.5587768554688
Epoch 29 loss 816.3840942382812
Epoch 30 loss 783.2756958007812
Epoch 31 loss 776.6592407226562
Epoch 32 loss 914.3594970703125
Epoch 33 loss 836.5487670898438
Epoch 34 loss 738.6863403320312
Epoch 35 loss 723.510009765625
Epoch 36 loss 815.134033203125
Epoch 37 loss 887.6143798828125
Epoch 38 loss 696.7147827148438
Epoch 39 loss 705.3284912109375
Epoch 40 loss 879.2542724609375
Epoch 41 loss 668.3583984375
Epoch 42 loss 639.522705078125
Epoch 43 loss 779.3504638671875
Epoch 44 loss 858.7481689453125
Epoch 45 loss 883.5943603515625
Epoch 46 loss 767.6984252929688
Epoch 47 loss 753.825439453125
Epoch 48 loss 656.95166015625
Epoch 49 loss 879.4974365234375
Epoch 50 loss 680.39013671875
Epoch 51 loss 749.7260131835938
Epoch 52 loss 726.7188720703125
Epoch 53 loss 636.6041259765625
Epoch 54 loss 679.9818115234375
Epoch 55 loss 659.3391723632812
Epoch 56 loss 1114.69677734375
Epoch 57 loss 689.735107421875
Epoch 58 loss 676.015625
Epoch 59 loss 805.3106689453125
Epoch 60 loss 588.4828491210938
Epoch 61 loss 612.3916015625
Epoch 62 loss 682.7067260742188
Epoch 63 loss 663.0514526367188
Epoch 64 loss 746.7366943359375
Epoch 65 loss 597.5424194335938
Epoch 66 loss 587.03466796875
Epoch 67 loss 673.0025024414062
Epoch 68 loss 616.5167846679688
Epoch 69 loss 611.8097534179688
Epoch 70 loss 665.0588989257812
Epoch 71 loss 676.3115844726562
Epoch 72 loss 560.9426879882812
Epoch 73 loss 620.3452758789062
Epoch 74 loss 878.654296875
Epoch 75 loss 579.5484619140625
Epoch 76 loss 774.615966796875
Epoch 77 loss 650.1193237304688
Epoch 78 loss 576.9996948242188
Epoch 79 loss 940.0117797851562
Epoch 80 loss 654.6209716796875
Epoch 81 loss 617.0527954101562
Epoch 82 loss 625.2708740234375
Epoch 83 loss 568.3505859375
Epoch 84 loss 638.0711059570312
Epoch 85 loss 613.2539672851562
Epoch 86 loss 579.084716796875
Epoch 87 loss 628.2346801757812
Epoch 88 loss 641.1617431640625
Epoch 89 loss 568.0110473632812
Epoch 90 loss 666.3504638671875
Epoch 91 loss 846.0556640625
Epoch 92 loss 615.1447143554688
Epoch 93 loss 559.8470458984375
Epoch 94 loss 594.2276611328125
Epoch 95 loss 710.6744995117188
Epoch 96 loss 595.654052734375
Epoch 97 loss 568.8899536132812
Epoch 98 loss 602.594970703125
Epoch 99 loss 573.6773071289062
Saved Losses
{'MSE - mean': 536.6186768363052, 'MSE - std': 47.46760983301707, 'R2 - mean': 0.9364436337214854, 'R2 - std': 0.005511915353442953} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514726.40625
Epoch 1 loss 511995.3125
Epoch 2 loss 508002.84375
Epoch 3 loss 502495.96875
Epoch 4 loss 494069.84375
Epoch 5 loss 477154.78125
Epoch 6 loss 445600.625
Epoch 7 loss 394285.65625
Epoch 8 loss 319990.75
Epoch 9 loss 225565.75
Epoch 10 loss 125267.5703125
Epoch 11 loss 46631.76953125
Epoch 12 loss 11966.357421875
Epoch 13 loss 8106.1875
Epoch 14 loss 8095.52490234375
Epoch 15 loss 8025.6181640625
Epoch 16 loss 7980.91552734375
Epoch 17 loss 7836.14599609375
Epoch 18 loss 4683.44091796875
Epoch 19 loss 4537.482421875
Epoch 20 loss 1969.17822265625
Epoch 21 loss 1545.020263671875
Epoch 22 loss 1274.0830078125
Epoch 23 loss 1307.0235595703125
Epoch 24 loss 1788.9561767578125
Epoch 25 loss 1215.3106689453125
Epoch 26 loss 903.76904296875
Epoch 27 loss 756.9224853515625
Epoch 28 loss 750.0105590820312
Epoch 29 loss 724.2549438476562
Epoch 30 loss 849.6682739257812
Epoch 31 loss 916.8475341796875
Epoch 32 loss 802.7299194335938
Epoch 33 loss 889.30859375
Epoch 34 loss 908.1557006835938
Epoch 35 loss 606.0382690429688
Epoch 36 loss 608.2913818359375
Epoch 37 loss 633.8560180664062
Epoch 38 loss 559.4230346679688
Epoch 39 loss 567.0399169921875
Epoch 40 loss 562.9189453125
Epoch 41 loss 1147.7733154296875
Epoch 42 loss 686.6399536132812
Epoch 43 loss 619.6860961914062
Epoch 44 loss 646.947998046875
Epoch 45 loss 525.9540405273438
Epoch 46 loss 841.7578735351562
Epoch 47 loss 628.5137939453125
Epoch 48 loss 706.6848754882812
Epoch 49 loss 555.7870483398438
Epoch 50 loss 717.8056030273438
Epoch 51 loss 767.263916015625
Epoch 52 loss 614.2532958984375
Epoch 53 loss 542.346435546875
Epoch 54 loss 543.7884521484375
Epoch 55 loss 549.7927856445312
Epoch 56 loss 639.3223266601562
Epoch 57 loss 492.99420166015625
Epoch 58 loss 474.3743591308594
Epoch 59 loss 583.4330444335938
Epoch 60 loss 638.6084594726562
Epoch 61 loss 533.0969848632812
Epoch 62 loss 650.8234252929688
Epoch 63 loss 496.95977783203125
Epoch 64 loss 535.5581665039062
Epoch 65 loss 530.8687744140625
Epoch 66 loss 633.50341796875
Epoch 67 loss 489.11199951171875
Epoch 68 loss 495.7060852050781
Epoch 69 loss 482.5574951171875
Epoch 70 loss 532.3370971679688
Epoch 71 loss 493.3060607910156
Epoch 72 loss 505.2652282714844
Epoch 73 loss 513.0138549804688
Epoch 74 loss 524.2444458007812
Epoch 75 loss 517.7594604492188
Epoch 76 loss 663.3174438476562
Epoch 77 loss 511.5909118652344
Epoch 78 loss 498.86114501953125
Epoch 79 loss 497.00128173828125
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 524.1697347342491, 'MSE - std': 49.21832813545185, 'R2 - mean': 0.9372629104408807, 'R2 - std': 0.005195173342881624} 
 

Results After CV: {'MSE - mean': 524.1697347342491, 'MSE - std': 49.21832813545185, 'R2 - mean': 0.9372629104408807, 'R2 - std': 0.005195173342881624}
Train time: 153.0733607385999
Inference time: 0.16073632299976454
Finished cross validation
Trial 8 finished with value: 524.1697347342491 and parameters: {'dim': 128, 'depth': 12, 'heads': 4, 'dropout': 0.5}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514038.0625
Epoch 1 loss 511386.78125
Epoch 2 loss 507310.03125
Epoch 3 loss 501235.78125
Epoch 4 loss 491423.15625
Epoch 5 loss 471497.34375
Epoch 6 loss 434367.8125
Epoch 7 loss 374810.4375
Epoch 8 loss 290479.6875
Epoch 9 loss 188742.953125
Epoch 10 loss 90392.859375
Epoch 11 loss 26887.716796875
Epoch 12 loss 8974.3076171875
Epoch 13 loss 8957.931640625
Epoch 14 loss 8489.4150390625
Epoch 15 loss 8335.763671875
Epoch 16 loss 7740.7978515625
Epoch 17 loss 4849.62109375
Epoch 18 loss 3024.532958984375
Epoch 19 loss 2057.328857421875
Epoch 20 loss 1590.1728515625
Epoch 21 loss 1543.5089111328125
Epoch 22 loss 1333.1134033203125
Epoch 23 loss 1538.63720703125
Epoch 24 loss 1077.29931640625
Epoch 25 loss 1262.887939453125
Epoch 26 loss 966.392333984375
Epoch 27 loss 1091.9251708984375
Epoch 28 loss 931.7334594726562
Epoch 29 loss 878.4736328125
Epoch 30 loss 1288.1329345703125
Epoch 31 loss 899.2122192382812
Epoch 32 loss 805.5659790039062
Epoch 33 loss 777.207763671875
Epoch 34 loss 784.06103515625
Epoch 35 loss 850.8165283203125
Epoch 36 loss 753.0062255859375
Epoch 37 loss 931.662353515625
Epoch 38 loss 723.0822143554688
Epoch 39 loss 746.8575439453125
Epoch 40 loss 838.0560913085938
Epoch 41 loss 746.6754760742188
Epoch 42 loss 725.1378173828125
Epoch 43 loss 732.53466796875
Epoch 44 loss 714.3101196289062
Epoch 45 loss 656.6709594726562
Epoch 46 loss 684.0477294921875
Epoch 47 loss 691.9588012695312
Epoch 48 loss 700.4871215820312
Epoch 49 loss 637.0714721679688
Epoch 50 loss 716.6317138671875
Epoch 51 loss 625.7720947265625
Epoch 52 loss 659.676025390625
Epoch 53 loss 695.2691040039062
Epoch 54 loss 653.832275390625
Epoch 55 loss 617.7409057617188
Epoch 56 loss 687.9385375976562
Epoch 57 loss 623.8797607421875
Epoch 58 loss 1007.492919921875
Epoch 59 loss 646.3299560546875
Epoch 60 loss 665.7421875
Epoch 61 loss 625.1904296875
Epoch 62 loss 621.6541748046875
Epoch 63 loss 656.962158203125
Epoch 64 loss 627.8026733398438
Epoch 65 loss 629.750732421875
Epoch 66 loss 601.5827026367188
Epoch 67 loss 596.0433959960938
Epoch 68 loss 610.041748046875
Epoch 69 loss 694.3793334960938
Epoch 70 loss 604.06884765625
Epoch 71 loss 611.203857421875
Epoch 72 loss 699.8042602539062
Epoch 73 loss 641.1964721679688
Epoch 74 loss 678.2630615234375
Epoch 75 loss 684.071533203125
Epoch 76 loss 682.30859375
Epoch 77 loss 609.1602783203125
Epoch 78 loss 649.5125122070312
Epoch 79 loss 696.9833374023438
Epoch 80 loss 631.0206298828125
Epoch 81 loss 709.3389892578125
Epoch 82 loss 648.7421875
Epoch 83 loss 629.6161499023438
Epoch 84 loss 661.6404418945312
Epoch 85 loss 614.4205322265625
Epoch 86 loss 599.8673095703125
Epoch 87 loss 646.50244140625
Epoch 88 loss 611.2568359375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 596.0432044505952, 'MSE - std': 0.0, 'R2 - mean': 0.930697486576123, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 521178.46875
Epoch 1 loss 517437.0
Epoch 2 loss 512173.09375
Epoch 3 loss 504445.59375
Epoch 4 loss 492881.5
Epoch 5 loss 470792.5625
Epoch 6 loss 430144.0
Epoch 7 loss 366080.90625
Epoch 8 loss 278286.1875
Epoch 9 loss 174870.953125
Epoch 10 loss 79330.84375
Epoch 11 loss 21943.5625
Epoch 12 loss 7858.90869140625
Epoch 13 loss 7742.6669921875
Epoch 14 loss 7553.6044921875
Epoch 15 loss 7338.443359375
Epoch 16 loss 6089.00634765625
Epoch 17 loss 4495.73291015625
Epoch 18 loss 2912.850830078125
Epoch 19 loss 2264.743896484375
Epoch 20 loss 1583.8695068359375
Epoch 21 loss 1320.58984375
Epoch 22 loss 1228.9542236328125
Epoch 23 loss 1115.2442626953125
Epoch 24 loss 1060.9693603515625
Epoch 25 loss 895.5482177734375
Epoch 26 loss 1035.873291015625
Epoch 27 loss 835.0045776367188
Epoch 28 loss 819.9907836914062
Epoch 29 loss 829.503662109375
Epoch 30 loss 736.4804077148438
Epoch 31 loss 652.2713623046875
Epoch 32 loss 692.2688598632812
Epoch 33 loss 678.5653686523438
Epoch 34 loss 699.5800170898438
Epoch 35 loss 690.5571899414062
Epoch 36 loss 586.0653076171875
Epoch 37 loss 577.3883666992188
Epoch 38 loss 605.0953369140625
Epoch 39 loss 752.9652099609375
Epoch 40 loss 550.0814819335938
Epoch 41 loss 538.1522216796875
Epoch 42 loss 575.4108276367188
Epoch 43 loss 662.8900756835938
Epoch 44 loss 597.5465698242188
Epoch 45 loss 839.2887573242188
Epoch 46 loss 517.3579711914062
Epoch 47 loss 545.9452514648438
Epoch 48 loss 555.277587890625
Epoch 49 loss 658.061279296875
Epoch 50 loss 523.1599731445312
Epoch 51 loss 540.2982177734375
Epoch 52 loss 506.2830505371094
Epoch 53 loss 534.262451171875
Epoch 54 loss 512.5875854492188
Epoch 55 loss 637.8564453125
Epoch 56 loss 505.91082763671875
Epoch 57 loss 500.1815490722656
Epoch 58 loss 595.14306640625
Epoch 59 loss 522.9376220703125
Epoch 60 loss 493.1463317871094
Epoch 61 loss 575.676513671875
Epoch 62 loss 526.4442138671875
Epoch 63 loss 503.3203125
Epoch 64 loss 682.8196411132812
Epoch 65 loss 491.835205078125
Epoch 66 loss 550.5372314453125
Epoch 67 loss 542.3416137695312
Epoch 68 loss 493.89422607421875
Epoch 69 loss 597.1682739257812
Epoch 70 loss 487.88751220703125
Epoch 71 loss 499.7730407714844
Epoch 72 loss 460.6076354980469
Epoch 73 loss 515.2943115234375
Epoch 74 loss 459.7960510253906
Epoch 75 loss 617.47314453125
Epoch 76 loss 473.14019775390625
Epoch 77 loss 506.93133544921875
Epoch 78 loss 451.69573974609375
Epoch 79 loss 493.929931640625
Epoch 80 loss 613.1575317382812
Epoch 81 loss 464.45111083984375
Epoch 82 loss 463.816650390625
Epoch 83 loss 527.5428466796875
Epoch 84 loss 535.2064819335938
Epoch 85 loss 525.576416015625
Epoch 86 loss 475.0564880371094
Epoch 87 loss 474.9082946777344
Epoch 88 loss 454.6703186035156
Epoch 89 loss 496.32012939453125
Epoch 90 loss 471.3357238769531
Epoch 91 loss 466.8466796875
Epoch 92 loss 519.8887939453125
Epoch 93 loss 464.2229309082031
Epoch 94 loss 487.91058349609375
Epoch 95 loss 583.4041137695312
Epoch 96 loss 478.295166015625
Epoch 97 loss 646.81884765625
Epoch 98 loss 469.9728088378906
Epoch 99 loss 566.2344360351562
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 523.8694167662684, 'MSE - std': 72.1737876843269, 'R2 - mean': 0.9357893503757763, 'R2 - std': 0.005091863799653318} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516080.5
Epoch 1 loss 513556.3125
Epoch 2 loss 509513.9375
Epoch 3 loss 503260.21875
Epoch 4 loss 493031.09375
Epoch 5 loss 472148.125
Epoch 6 loss 433384.5
Epoch 7 loss 371512.90625
Epoch 8 loss 285194.15625
Epoch 9 loss 182399.0
Epoch 10 loss 85517.8125
Epoch 11 loss 25181.283203125
Epoch 12 loss 9547.4384765625
Epoch 13 loss 9655.482421875
Epoch 14 loss 9122.6064453125
Epoch 15 loss 8921.861328125
Epoch 16 loss 7721.56201171875
Epoch 17 loss 4623.73681640625
Epoch 18 loss 2834.701171875
Epoch 19 loss 2545.208251953125
Epoch 20 loss 1907.0391845703125
Epoch 21 loss 1907.3609619140625
Epoch 22 loss 1510.2618408203125
Epoch 23 loss 1544.39404296875
Epoch 24 loss 1449.0452880859375
Epoch 25 loss 1296.2685546875
Epoch 26 loss 1127.4227294921875
Epoch 27 loss 1439.7318115234375
Epoch 28 loss 1075.8411865234375
Epoch 29 loss 932.9970092773438
Epoch 30 loss 882.3258666992188
Epoch 31 loss 949.3495483398438
Epoch 32 loss 932.9985961914062
Epoch 33 loss 814.3466796875
Epoch 34 loss 1015.5146484375
Epoch 35 loss 882.1527709960938
Epoch 36 loss 811.3740844726562
Epoch 37 loss 730.2982177734375
Epoch 38 loss 941.4647827148438
Epoch 39 loss 855.4459228515625
Epoch 40 loss 945.225830078125
Epoch 41 loss 736.9136352539062
Epoch 42 loss 749.3632202148438
Epoch 43 loss 678.7136840820312
Epoch 44 loss 862.103515625
Epoch 45 loss 869.1253051757812
Epoch 46 loss 649.792236328125
Epoch 47 loss 1075.4210205078125
Epoch 48 loss 754.44775390625
Epoch 49 loss 722.0560913085938
Epoch 50 loss 605.614013671875
Epoch 51 loss 693.0845947265625
Epoch 52 loss 784.3335571289062
Epoch 53 loss 661.0811767578125
Epoch 54 loss 615.1585693359375
Epoch 55 loss 741.185302734375
Epoch 56 loss 669.8896484375
Epoch 57 loss 683.945556640625
Epoch 58 loss 579.5592651367188
Epoch 59 loss 636.8184204101562
Epoch 60 loss 608.8907470703125
Epoch 61 loss 771.2078247070312
Epoch 62 loss 747.1685180664062
Epoch 63 loss 574.4618530273438
Epoch 64 loss 636.3550415039062
Epoch 65 loss 544.6202392578125
Epoch 66 loss 624.1742553710938
Epoch 67 loss 531.768310546875
Epoch 68 loss 657.8892822265625
Epoch 69 loss 706.9318237304688
Epoch 70 loss 615.2490844726562
Epoch 71 loss 594.393310546875
Epoch 72 loss 600.8834838867188
Epoch 73 loss 617.673095703125
Epoch 74 loss 527.8170776367188
Epoch 75 loss 549.0272216796875
Epoch 76 loss 559.7581176757812
Epoch 77 loss 659.4555053710938
Epoch 78 loss 531.548828125
Epoch 79 loss 524.5706787109375
Epoch 80 loss 604.9141235351562
Epoch 81 loss 511.73388671875
Epoch 82 loss 605.359619140625
Epoch 83 loss 495.50152587890625
Epoch 84 loss 551.9052734375
Epoch 85 loss 527.1808471679688
Epoch 86 loss 488.2528991699219
Epoch 87 loss 505.2001037597656
Epoch 88 loss 529.0613403320312
Epoch 89 loss 536.6455688476562
Epoch 90 loss 596.771240234375
Epoch 91 loss 710.9431762695312
Epoch 92 loss 485.9471130371094
Epoch 93 loss 592.1509399414062
Epoch 94 loss 495.1501770019531
Epoch 95 loss 553.13818359375
Epoch 96 loss 514.1482543945312
Epoch 97 loss 491.6851806640625
Epoch 98 loss 714.032470703125
Epoch 99 loss 481.6134948730469
Saved Losses
{'MSE - mean': 509.7841289520132, 'MSE - std': 62.20526037313089, 'R2 - mean': 0.93994640579541, 'R2 - std': 0.007200481754250321} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517947.65625
Epoch 1 loss 514680.84375
Epoch 2 loss 509978.65625
Epoch 3 loss 503049.78125
Epoch 4 loss 492534.65625
Epoch 5 loss 472261.375
Epoch 6 loss 434998.09375
Epoch 7 loss 375549.5
Epoch 8 loss 292497.5625
Epoch 9 loss 192485.15625
Epoch 10 loss 95154.4765625
Epoch 11 loss 29565.99609375
Epoch 12 loss 9186.3935546875
Epoch 13 loss 8482.5126953125
Epoch 14 loss 8175.22509765625
Epoch 15 loss 8036.8388671875
Epoch 16 loss 7299.76025390625
Epoch 17 loss 5190.14306640625
Epoch 18 loss 3588.604248046875
Epoch 19 loss 2973.869873046875
Epoch 20 loss 1892.51416015625
Epoch 21 loss 1909.3232421875
Epoch 22 loss 1428.7801513671875
Epoch 23 loss 1442.1871337890625
Epoch 24 loss 1656.0703125
Epoch 25 loss 1236.46923828125
Epoch 26 loss 1075.1788330078125
Epoch 27 loss 981.3490600585938
Epoch 28 loss 1300.0462646484375
Epoch 29 loss 964.7279052734375
Epoch 30 loss 878.7655029296875
Epoch 31 loss 835.09765625
Epoch 32 loss 781.7930297851562
Epoch 33 loss 1151.1920166015625
Epoch 34 loss 748.0318603515625
Epoch 35 loss 789.5857543945312
Epoch 36 loss 744.8259887695312
Epoch 37 loss 1078.358154296875
Epoch 38 loss 752.5369262695312
Epoch 39 loss 1209.25830078125
Epoch 40 loss 727.2425537109375
Epoch 41 loss 712.2108764648438
Epoch 42 loss 795.8353271484375
Epoch 43 loss 876.7789306640625
Epoch 44 loss 723.9140014648438
Epoch 45 loss 657.283935546875
Epoch 46 loss 1102.02783203125
Epoch 47 loss 665.78125
Epoch 48 loss 1101.0496826171875
Epoch 49 loss 633.372314453125
Epoch 50 loss 741.5089721679688
Epoch 51 loss 634.1943359375
Epoch 52 loss 954.27392578125
Epoch 53 loss 838.0535278320312
Epoch 54 loss 660.5777587890625
Epoch 55 loss 713.5006713867188
Epoch 56 loss 677.8203125
Epoch 57 loss 778.7775268554688
Epoch 58 loss 654.73193359375
Epoch 59 loss 721.038330078125
Epoch 60 loss 677.3536376953125
Epoch 61 loss 779.4195556640625
Epoch 62 loss 565.7706909179688
Epoch 63 loss 568.4392700195312
Epoch 64 loss 970.7865600585938
Epoch 65 loss 832.5914306640625
Epoch 66 loss 597.5460815429688
Epoch 67 loss 881.9430541992188
Epoch 68 loss 576.3843994140625
Epoch 69 loss 642.1377563476562
Epoch 70 loss 603.8365478515625
Epoch 71 loss 714.8544921875
Epoch 72 loss 596.2784423828125
Epoch 73 loss 560.4805908203125
Epoch 74 loss 690.119140625
Epoch 75 loss 575.8369140625
Epoch 76 loss 581.3582153320312
Epoch 77 loss 587.0459594726562
Epoch 78 loss 807.5302124023438
Epoch 79 loss 715.8228149414062
Epoch 80 loss 525.61572265625
Epoch 81 loss 624.7110595703125
Epoch 82 loss 611.18798828125
Epoch 83 loss 517.9657592773438
Epoch 84 loss 858.1292724609375
Epoch 85 loss 555.294189453125
Epoch 86 loss 682.3242797851562
Epoch 87 loss 556.0675048828125
Epoch 88 loss 541.759521484375
Epoch 89 loss 657.4125366210938
Epoch 90 loss 553.2573852539062
Epoch 91 loss 776.7823486328125
Epoch 92 loss 536.6029663085938
Epoch 93 loss 685.0402221679688
Epoch 94 loss 592.9480590820312
Epoch 95 loss 592.7036743164062
Epoch 96 loss 642.3502807617188
Epoch 97 loss 634.93505859375
Epoch 98 loss 524.2000732421875
Epoch 99 loss 667.403076171875
Saved Losses
{'MSE - mean': 511.82949018064517, 'MSE - std': 53.987696017088275, 'R2 - mean': 0.9393687910634771, 'R2 - std': 0.006315545855712426} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515631.375
Epoch 1 loss 513049.46875
Epoch 2 loss 509156.15625
Epoch 3 loss 503204.53125
Epoch 4 loss 494168.46875
Epoch 5 loss 476991.34375
Epoch 6 loss 444714.59375
Epoch 7 loss 391644.90625
Epoch 8 loss 314862.3125
Epoch 9 loss 217738.6875
Epoch 10 loss 116268.03125
Epoch 11 loss 40071.69140625
Epoch 12 loss 10417.8408203125
Epoch 13 loss 8125.33935546875
Epoch 14 loss 8033.07958984375
Epoch 15 loss 7693.46826171875
Epoch 16 loss 6562.72705078125
Epoch 17 loss 4407.60498046875
Epoch 18 loss 2933.0087890625
Epoch 19 loss 2288.606689453125
Epoch 20 loss 1776.05126953125
Epoch 21 loss 1459.853271484375
Epoch 22 loss 1199.0047607421875
Epoch 23 loss 1298.706787109375
Epoch 24 loss 1120.0428466796875
Epoch 25 loss 940.817626953125
Epoch 26 loss 957.8724365234375
Epoch 27 loss 947.9091186523438
Epoch 28 loss 783.3731079101562
Epoch 29 loss 859.164306640625
Epoch 30 loss 812.358642578125
Epoch 31 loss 712.3563842773438
Epoch 32 loss 707.0531005859375
Epoch 33 loss 1063.8482666015625
Epoch 34 loss 683.256591796875
Epoch 35 loss 707.5912475585938
Epoch 36 loss 760.4444580078125
Epoch 37 loss 616.2657470703125
Epoch 38 loss 640.489990234375
Epoch 39 loss 773.6441650390625
Epoch 40 loss 590.845458984375
Epoch 41 loss 609.8795776367188
Epoch 42 loss 627.4326782226562
Epoch 43 loss 580.822509765625
Epoch 44 loss 572.54052734375
Epoch 45 loss 719.7191162109375
Epoch 46 loss 552.9486083984375
Epoch 47 loss 580.7876586914062
Epoch 48 loss 587.8782958984375
Epoch 49 loss 545.3896484375
Epoch 50 loss 787.0464477539062
Epoch 51 loss 599.2852783203125
Epoch 52 loss 530.27978515625
Epoch 53 loss 524.2854614257812
Epoch 54 loss 578.9391479492188
Epoch 55 loss 541.4596557617188
Epoch 56 loss 624.9671020507812
Epoch 57 loss 640.9921875
Epoch 58 loss 513.1785278320312
Epoch 59 loss 765.7775268554688
Epoch 60 loss 517.6005249023438
Epoch 61 loss 502.2818603515625
Epoch 62 loss 622.731689453125
Epoch 63 loss 516.8577880859375
Epoch 64 loss 517.8638916015625
Epoch 65 loss 619.9860229492188
Epoch 66 loss 582.3184204101562
Epoch 67 loss 564.2310180664062
Epoch 68 loss 594.1071166992188
Epoch 69 loss 545.9873046875
Epoch 70 loss 594.4378662109375
Epoch 71 loss 500.472412109375
Epoch 72 loss 499.7908935546875
Epoch 73 loss 480.49090576171875
Epoch 74 loss 524.6685791015625
Epoch 75 loss 486.9778137207031
Epoch 76 loss 664.884521484375
Epoch 77 loss 500.2607727050781
Epoch 78 loss 489.7487487792969
Epoch 79 loss 526.6829223632812
Epoch 80 loss 478.539794921875
Epoch 81 loss 515.2957153320312
Epoch 82 loss 473.3817138671875
Epoch 83 loss 477.4612121582031
Epoch 84 loss 495.3354797363281
Epoch 85 loss 636.9234619140625
Epoch 86 loss 543.0535278320312
Epoch 87 loss 472.5335693359375
Epoch 88 loss 608.4876098632812
Epoch 89 loss 504.9938049316406
Epoch 90 loss 521.8958129882812
Epoch 91 loss 482.3514709472656
Epoch 92 loss 527.1220092773438
Epoch 93 loss 508.9580993652344
Epoch 94 loss 493.92413330078125
Epoch 95 loss 466.9231872558594
Epoch 96 loss 550.8367919921875
Epoch 97 loss 473.4328308105469
Epoch 98 loss 465.3616027832031
Epoch 99 loss 478.28009033203125
Saved Losses
{'MSE - mean': 502.5358906430412, 'MSE - std': 51.74186918200992, 'R2 - mean': 0.939828968417031, 'R2 - std': 0.005723281257406488} 
 

Results After CV: {'MSE - mean': 502.5358906430412, 'MSE - std': 51.74186918200992, 'R2 - mean': 0.939828968417031, 'R2 - std': 0.005723281257406488}
Train time: 104.27436190020016
Inference time: 0.14110174479992565
Finished cross validation
Trial 9 finished with value: 502.5358906430412 and parameters: {'dim': 32, 'depth': 3, 'heads': 4, 'dropout': 0.5}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513892.8125
Epoch 1 loss 511115.5625
Epoch 2 loss 506855.84375
Epoch 3 loss 500182.25
Epoch 4 loss 489457.3125
Epoch 5 loss 469224.28125
Epoch 6 loss 432581.96875
Epoch 7 loss 374647.125
Epoch 8 loss 293804.96875
Epoch 9 loss 196480.671875
Epoch 10 loss 100551.78125
Epoch 11 loss 33627.51171875
Epoch 12 loss 10035.6982421875
Epoch 13 loss 8802.046875
Epoch 14 loss 8588.173828125
Epoch 15 loss 8287.771484375
Epoch 16 loss 8081.69873046875
Epoch 17 loss 7246.67431640625
Epoch 18 loss 5338.50439453125
Epoch 19 loss 3725.978759765625
Epoch 20 loss 2628.62158203125
Epoch 21 loss 2000.3424072265625
Epoch 22 loss 1951.018310546875
Epoch 23 loss 1539.3292236328125
Epoch 24 loss 1438.74755859375
Epoch 25 loss 1446.2388916015625
Epoch 26 loss 1284.78515625
Epoch 27 loss 1028.7340087890625
Epoch 28 loss 1288.5023193359375
Epoch 29 loss 991.7385864257812
Epoch 30 loss 1199.20849609375
Epoch 31 loss 963.0137939453125
Epoch 32 loss 921.2730712890625
Epoch 33 loss 950.7396240234375
Epoch 34 loss 993.8472900390625
Epoch 35 loss 1051.50146484375
Epoch 36 loss 871.1590576171875
Epoch 37 loss 974.3548583984375
Epoch 38 loss 1345.354248046875
Epoch 39 loss 895.9557495117188
Epoch 40 loss 982.3758544921875
Epoch 41 loss 815.8826293945312
Epoch 42 loss 952.7611694335938
Epoch 43 loss 888.6041870117188
Epoch 44 loss 800.9212646484375
Epoch 45 loss 890.3768310546875
Epoch 46 loss 771.9560546875
Epoch 47 loss 1048.572509765625
Epoch 48 loss 782.4581298828125
Epoch 49 loss 782.8754272460938
Epoch 50 loss 872.4541625976562
Epoch 51 loss 750.388671875
Epoch 52 loss 947.7338256835938
Epoch 53 loss 789.5023193359375
Epoch 54 loss 915.69140625
Epoch 55 loss 843.8150634765625
Epoch 56 loss 730.3358154296875
Epoch 57 loss 780.5806274414062
Epoch 58 loss 1232.5440673828125
Epoch 59 loss 730.6575927734375
Epoch 60 loss 696.9354858398438
Epoch 61 loss 779.666015625
Epoch 62 loss 747.7545166015625
Epoch 63 loss 794.001708984375
Epoch 64 loss 723.1918334960938
Epoch 65 loss 842.70703125
Epoch 66 loss 785.6243896484375
Epoch 67 loss 918.9323120117188
Epoch 68 loss 796.0427856445312
Epoch 69 loss 725.7130126953125
Epoch 70 loss 714.40869140625
Epoch 71 loss 658.450927734375
Epoch 72 loss 742.7763061523438
Epoch 73 loss 690.7532348632812
Epoch 74 loss 875.620849609375
Epoch 75 loss 755.0615234375
Epoch 76 loss 781.0739135742188
Epoch 77 loss 741.935791015625
Epoch 78 loss 628.169677734375
Epoch 79 loss 742.1993408203125
Epoch 80 loss 622.4398193359375
Epoch 81 loss 701.9679565429688
Epoch 82 loss 670.1376953125
Epoch 83 loss 667.2896118164062
Epoch 84 loss 647.9353637695312
Epoch 85 loss 614.0047607421875
Epoch 86 loss 648.1004638671875
Epoch 87 loss 793.6762084960938
Epoch 88 loss 622.0135498046875
Epoch 89 loss 698.5614624023438
Epoch 90 loss 750.8590698242188
Epoch 91 loss 611.0231323242188
Epoch 92 loss 651.1611328125
Epoch 93 loss 620.784423828125
Epoch 94 loss 717.0463256835938
Epoch 95 loss 677.0296630859375
Epoch 96 loss 763.4547119140625
Epoch 97 loss 648.4083251953125
Epoch 98 loss 663.2305297851562
Epoch 99 loss 712.48486328125
Saved Losses
{'MSE - mean': 611.022905608164, 'MSE - std': 0.0, 'R2 - mean': 0.9289557823962808, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522002.09375
Epoch 1 loss 518660.1875
Epoch 2 loss 513773.34375
Epoch 3 loss 506319.40625
Epoch 4 loss 494877.03125
Epoch 5 loss 473544.84375
Epoch 6 loss 434590.65625
Epoch 7 loss 372947.1875
Epoch 8 loss 287954.5
Epoch 9 loss 186804.3125
Epoch 10 loss 90455.2265625
Epoch 11 loss 27682.904296875
Epoch 12 loss 8553.1083984375
Epoch 13 loss 7701.75439453125
Epoch 14 loss 7455.67919921875
Epoch 15 loss 7308.658203125
Epoch 16 loss 6905.47509765625
Epoch 17 loss 5557.2958984375
Epoch 18 loss 4341.36865234375
Epoch 19 loss 3177.997314453125
Epoch 20 loss 2372.76513671875
Epoch 21 loss 1844.186767578125
Epoch 22 loss 1604.8494873046875
Epoch 23 loss 1563.18310546875
Epoch 24 loss 1194.4757080078125
Epoch 25 loss 1736.54736328125
Epoch 26 loss 1043.85546875
Epoch 27 loss 1288.621826171875
Epoch 28 loss 969.825927734375
Epoch 29 loss 1115.990966796875
Epoch 30 loss 1005.5119018554688
Epoch 31 loss 768.4002075195312
Epoch 32 loss 752.0040893554688
Epoch 33 loss 862.8273315429688
Epoch 34 loss 931.4951782226562
Epoch 35 loss 712.12744140625
Epoch 36 loss 709.0607299804688
Epoch 37 loss 687.599853515625
Epoch 38 loss 649.2473754882812
Epoch 39 loss 625.5347900390625
Epoch 40 loss 687.72705078125
Epoch 41 loss 737.392333984375
Epoch 42 loss 629.5354614257812
Epoch 43 loss 604.1162719726562
Epoch 44 loss 642.8187866210938
Epoch 45 loss 585.7337646484375
Epoch 46 loss 662.5276489257812
Epoch 47 loss 735.0577392578125
Epoch 48 loss 731.3440551757812
Epoch 49 loss 774.7101440429688
Epoch 50 loss 545.725341796875
Epoch 51 loss 687.2239379882812
Epoch 52 loss 586.0501098632812
Epoch 53 loss 625.3637084960938
Epoch 54 loss 566.4845581054688
Epoch 55 loss 704.3153686523438
Epoch 56 loss 568.5592041015625
Epoch 57 loss 573.4126586914062
Epoch 58 loss 638.0781860351562
Epoch 59 loss 569.3831787109375
Epoch 60 loss 700.6165161132812
Epoch 61 loss 511.3976745605469
Epoch 62 loss 722.201171875
Epoch 63 loss 636.080078125
Epoch 64 loss 552.24072265625
Epoch 65 loss 553.4186401367188
Epoch 66 loss 495.79608154296875
Epoch 67 loss 566.8367919921875
Epoch 68 loss 524.6962280273438
Epoch 69 loss 527.5933837890625
Epoch 70 loss 791.5103149414062
Epoch 71 loss 512.4871826171875
Epoch 72 loss 546.042236328125
Epoch 73 loss 718.9185180664062
Epoch 74 loss 474.1662902832031
Epoch 75 loss 476.6797180175781
Epoch 76 loss 808.7052612304688
Epoch 77 loss 485.6554260253906
Epoch 78 loss 591.2997436523438
Epoch 79 loss 464.8635559082031
Epoch 80 loss 495.38934326171875
Epoch 81 loss 476.29412841796875
Epoch 82 loss 586.3494873046875
Epoch 83 loss 611.1193237304688
Epoch 84 loss 819.8887939453125
Epoch 85 loss 454.8679504394531
Epoch 86 loss 483.77783203125
Epoch 87 loss 512.2547607421875
Epoch 88 loss 466.98980712890625
Epoch 89 loss 477.5092468261719
Epoch 90 loss 669.111328125
Epoch 91 loss 553.4869384765625
Epoch 92 loss 454.0281677246094
Epoch 93 loss 528.5840454101562
Epoch 94 loss 543.7559204101562
Epoch 95 loss 535.2879028320312
Epoch 96 loss 524.5380859375
Epoch 97 loss 485.5509338378906
Epoch 98 loss 449.9559326171875
Epoch 99 loss 448.1295166015625
Saved Losses
{'MSE - mean': 529.5762302595217, 'MSE - std': 81.44667534864232, 'R2 - mean': 0.9351518655818616, 'R2 - std': 0.006196083185580791} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516556.28125
Epoch 1 loss 513907.8125
Epoch 2 loss 509958.15625
Epoch 3 loss 503981.1875
Epoch 4 loss 494655.90625
Epoch 5 loss 477546.125
Epoch 6 loss 445673.8125
Epoch 7 loss 393505.125
Epoch 8 loss 318417.375
Epoch 9 loss 223639.8125
Epoch 10 loss 123993.171875
Epoch 11 loss 46626.94921875
Epoch 12 loss 12897.267578125
Epoch 13 loss 9376.162109375
Epoch 14 loss 9390.36328125
Epoch 15 loss 8966.9794921875
Epoch 16 loss 8752.212890625
Epoch 17 loss 7618.91357421875
Epoch 18 loss 6174.4501953125
Epoch 19 loss 4077.56787109375
Epoch 20 loss 2828.573486328125
Epoch 21 loss 2108.526611328125
Epoch 22 loss 1908.61279296875
Epoch 23 loss 1855.848388671875
Epoch 24 loss 1462.8338623046875
Epoch 25 loss 1591.676513671875
Epoch 26 loss 1380.48388671875
Epoch 27 loss 1312.898681640625
Epoch 28 loss 1162.218017578125
Epoch 29 loss 1380.7742919921875
Epoch 30 loss 1038.5238037109375
Epoch 31 loss 1060.1658935546875
Epoch 32 loss 1114.18310546875
Epoch 33 loss 1667.9783935546875
Epoch 34 loss 1012.7025146484375
Epoch 35 loss 989.1070556640625
Epoch 36 loss 1080.2322998046875
Epoch 37 loss 1226.050048828125
Epoch 38 loss 941.4202880859375
Epoch 39 loss 1061.880126953125
Epoch 40 loss 813.3556518554688
Epoch 41 loss 857.9706420898438
Epoch 42 loss 894.9703979492188
Epoch 43 loss 820.804443359375
Epoch 44 loss 792.7440795898438
Epoch 45 loss 941.1403198242188
Epoch 46 loss 936.138671875
Epoch 47 loss 693.1267700195312
Epoch 48 loss 820.1626586914062
Epoch 49 loss 1052.36474609375
Epoch 50 loss 764.11279296875
Epoch 51 loss 779.0164184570312
Epoch 52 loss 777.3836059570312
Epoch 53 loss 723.6327514648438
Epoch 54 loss 713.3444213867188
Epoch 55 loss 778.7412719726562
Epoch 56 loss 687.915283203125
Epoch 57 loss 936.7672119140625
Epoch 58 loss 1022.979248046875
Epoch 59 loss 704.323486328125
Epoch 60 loss 668.4210815429688
Epoch 61 loss 899.0302124023438
Epoch 62 loss 581.2957763671875
Epoch 63 loss 908.0662231445312
Epoch 64 loss 769.4251708984375
Epoch 65 loss 584.7643432617188
Epoch 66 loss 649.6129760742188
Epoch 67 loss 1022.1580810546875
Epoch 68 loss 831.4088745117188
Epoch 69 loss 630.1761474609375
Epoch 70 loss 752.64892578125
Epoch 71 loss 883.0077514648438
Epoch 72 loss 576.1234741210938
Epoch 73 loss 759.2954711914062
Epoch 74 loss 1106.178466796875
Epoch 75 loss 1018.4815673828125
Epoch 76 loss 624.403564453125
Epoch 77 loss 555.200439453125
Epoch 78 loss 571.3877563476562
Epoch 79 loss 608.8187866210938
Epoch 80 loss 930.5760498046875
Epoch 81 loss 1187.6287841796875
Epoch 82 loss 633.7342529296875
Epoch 83 loss 562.1981201171875
Epoch 84 loss 578.3692626953125
Epoch 85 loss 748.0252685546875
Epoch 86 loss 738.8737182617188
Epoch 87 loss 823.5243530273438
Epoch 88 loss 595.1158447265625
Epoch 89 loss 918.9920043945312
Epoch 90 loss 602.97900390625
Epoch 91 loss 606.2000122070312
Epoch 92 loss 965.4367065429688
Epoch 93 loss 805.0528564453125
Epoch 94 loss 604.8274536132812
Epoch 95 loss 529.4459838867188
Epoch 96 loss 549.99755859375
Epoch 97 loss 641.7566528320312
Epoch 98 loss 513.30859375
Epoch 99 loss 585.813720703125
Saved Losses
{'MSE - mean': 524.1536370997438, 'MSE - std': 66.94163863683325, 'R2 - mean': 0.9383864273730519, 'R2 - std': 0.006820489561398552} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518758.53125
Epoch 1 loss 515566.5
Epoch 2 loss 511092.28125
Epoch 3 loss 504348.25
Epoch 4 loss 493775.21875
Epoch 5 loss 473672.4375
Epoch 6 loss 436294.71875
Epoch 7 loss 375823.5625
Epoch 8 loss 290854.375
Epoch 9 loss 188557.0625
Epoch 10 loss 90500.1171875
Epoch 11 loss 27119.798828125
Epoch 12 loss 8827.67578125
Epoch 13 loss 8444.0302734375
Epoch 14 loss 8060.00390625
Epoch 15 loss 7908.35498046875
Epoch 16 loss 7439.8349609375
Epoch 17 loss 5626.09716796875
Epoch 18 loss 3839.287353515625
Epoch 19 loss 2727.36376953125
Epoch 20 loss 2041.078125
Epoch 21 loss 2060.690673828125
Epoch 22 loss 1821.768310546875
Epoch 23 loss 1520.1239013671875
Epoch 24 loss 1349.3447265625
Epoch 25 loss 2050.7626953125
Epoch 26 loss 1275.6243896484375
Epoch 27 loss 1209.8240966796875
Epoch 28 loss 1120.737548828125
Epoch 29 loss 1375.663818359375
Epoch 30 loss 1044.637451171875
Epoch 31 loss 1009.3085327148438
Epoch 32 loss 1246.305419921875
Epoch 33 loss 1004.6331176757812
Epoch 34 loss 954.7871704101562
Epoch 35 loss 1169.845458984375
Epoch 36 loss 883.4060668945312
Epoch 37 loss 1122.5533447265625
Epoch 38 loss 885.7313232421875
Epoch 39 loss 973.2789306640625
Epoch 40 loss 993.7965698242188
Epoch 41 loss 903.9655151367188
Epoch 42 loss 1098.56298828125
Epoch 43 loss 754.7366333007812
Epoch 44 loss 977.5419921875
Epoch 45 loss 871.9278564453125
Epoch 46 loss 724.279296875
Epoch 47 loss 1046.4136962890625
Epoch 48 loss 851.0741577148438
Epoch 49 loss 872.312744140625
Epoch 50 loss 705.54443359375
Epoch 51 loss 709.9517211914062
Epoch 52 loss 872.0809326171875
Epoch 53 loss 787.1038818359375
Epoch 54 loss 659.2765502929688
Epoch 55 loss 702.9175415039062
Epoch 56 loss 699.1978759765625
Epoch 57 loss 850.409912109375
Epoch 58 loss 729.2298583984375
Epoch 59 loss 671.3989868164062
Epoch 60 loss 771.2039794921875
Epoch 61 loss 656.98876953125
Epoch 62 loss 615.1618041992188
Epoch 63 loss 746.5493774414062
Epoch 64 loss 844.5654296875
Epoch 65 loss 877.02001953125
Epoch 66 loss 696.8185424804688
Epoch 67 loss 652.109619140625
Epoch 68 loss 671.6199951171875
Epoch 69 loss 747.9930419921875
Epoch 70 loss 641.86669921875
Epoch 71 loss 597.713623046875
Epoch 72 loss 799.5332641601562
Epoch 73 loss 688.1500244140625
Epoch 74 loss 701.2019653320312
Epoch 75 loss 680.9174194335938
Epoch 76 loss 583.1456298828125
Epoch 77 loss 812.3123779296875
Epoch 78 loss 608.9550170898438
Epoch 79 loss 797.257080078125
Epoch 80 loss 594.0933227539062
Epoch 81 loss 638.58154296875
Epoch 82 loss 671.5082397460938
Epoch 83 loss 739.9873657226562
Epoch 84 loss 692.9221801757812
Epoch 85 loss 584.0198364257812
Epoch 86 loss 574.873046875
Epoch 87 loss 607.2649536132812
Epoch 88 loss 533.8999633789062
Epoch 89 loss 866.575927734375
Epoch 90 loss 562.5027465820312
Epoch 91 loss 610.0933227539062
Epoch 92 loss 557.6764526367188
Epoch 93 loss 801.8590698242188
Epoch 94 loss 684.9059448242188
Epoch 95 loss 685.7133178710938
Epoch 96 loss 608.4451293945312
Epoch 97 loss 669.9635009765625
Epoch 98 loss 604.6527709960938
Epoch 99 loss 620.8193359375
Saved Losses
{'MSE - mean': 526.5902902871899, 'MSE - std': 58.12657803282374, 'R2 - mean': 0.9377191658237125, 'R2 - std': 0.006018722648414729} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515188.09375
Epoch 1 loss 511815.4375
Epoch 2 loss 506855.28125
Epoch 3 loss 499286.9375
Epoch 4 loss 487286.1875
Epoch 5 loss 464858.25
Epoch 6 loss 423889.09375
Epoch 7 loss 359608.78125
Epoch 8 loss 272024.65625
Epoch 9 loss 170365.171875
Epoch 10 loss 77352.1875
Epoch 11 loss 21679.248046875
Epoch 12 loss 8099.79736328125
Epoch 13 loss 8249.2001953125
Epoch 14 loss 7726.4853515625
Epoch 15 loss 7509.20166015625
Epoch 16 loss 7020.4609375
Epoch 17 loss 5329.22412109375
Epoch 18 loss 3758.2236328125
Epoch 19 loss 2812.493896484375
Epoch 20 loss 2303.543701171875
Epoch 21 loss 1643.8048095703125
Epoch 22 loss 2135.26513671875
Epoch 23 loss 1319.525634765625
Epoch 24 loss 1345.2333984375
Epoch 25 loss 1217.637451171875
Epoch 26 loss 1090.146240234375
Epoch 27 loss 1006.420166015625
Epoch 28 loss 1022.7792358398438
Epoch 29 loss 892.1292114257812
Epoch 30 loss 937.7337646484375
Epoch 31 loss 835.4795532226562
Epoch 32 loss 816.787109375
Epoch 33 loss 1132.954345703125
Epoch 34 loss 881.675537109375
Epoch 35 loss 777.3822021484375
Epoch 36 loss 761.5142211914062
Epoch 37 loss 780.95458984375
Epoch 38 loss 737.4476318359375
Epoch 39 loss 774.8742065429688
Epoch 40 loss 1536.0589599609375
Epoch 41 loss 719.6920166015625
Epoch 42 loss 724.2017211914062
Epoch 43 loss 812.2909545898438
Epoch 44 loss 703.4054565429688
Epoch 45 loss 647.9405517578125
Epoch 46 loss 734.013916015625
Epoch 47 loss 867.9007568359375
Epoch 48 loss 755.5315551757812
Epoch 49 loss 617.2435913085938
Epoch 50 loss 654.4196166992188
Epoch 51 loss 768.4314575195312
Epoch 52 loss 636.5135498046875
Epoch 53 loss 632.8199462890625
Epoch 54 loss 620.863525390625
Epoch 55 loss 607.2793579101562
Epoch 56 loss 728.14697265625
Epoch 57 loss 590.1682739257812
Epoch 58 loss 600.3612670898438
Epoch 59 loss 641.9635009765625
Epoch 60 loss 589.8359375
Epoch 61 loss 640.5421142578125
Epoch 62 loss 562.8701782226562
Epoch 63 loss 688.9664306640625
Epoch 64 loss 677.2022094726562
Epoch 65 loss 560.3004150390625
Epoch 66 loss 603.4542236328125
Epoch 67 loss 661.135009765625
Epoch 68 loss 572.91064453125
Epoch 69 loss 684.7796020507812
Epoch 70 loss 578.15673828125
Epoch 71 loss 680.9061889648438
Epoch 72 loss 637.7135009765625
Epoch 73 loss 850.1187133789062
Epoch 74 loss 571.687744140625
Epoch 75 loss 555.8984985351562
Epoch 76 loss 553.4244995117188
Epoch 77 loss 567.8920288085938
Epoch 78 loss 549.5678100585938
Epoch 79 loss 525.904541015625
Epoch 80 loss 532.2434692382812
Epoch 81 loss 567.0955200195312
Epoch 82 loss 557.2186279296875
Epoch 83 loss 585.1270141601562
Epoch 84 loss 541.5697021484375
Epoch 85 loss 535.3306274414062
Epoch 86 loss 520.2401123046875
Epoch 87 loss 528.6939086914062
Epoch 88 loss 828.5257568359375
Epoch 89 loss 526.7053833007812
Epoch 90 loss 524.3941650390625
Epoch 91 loss 539.1913452148438
Epoch 92 loss 496.00677490234375
Epoch 93 loss 498.4403991699219
Epoch 94 loss 531.0313720703125
Epoch 95 loss 574.8894653320312
Epoch 96 loss 511.90655517578125
Epoch 97 loss 502.6300964355469
Epoch 98 loss 553.1989135742188
Epoch 99 loss 562.5625
Saved Losses
{'MSE - mean': 520.4735868538475, 'MSE - std': 53.40988206887009, 'R2 - mean': 0.9377410271391767, 'R2 - std': 0.005383486744043087} 
 

Results After CV: {'MSE - mean': 520.4735868538475, 'MSE - std': 53.40988206887009, 'R2 - mean': 0.9377410271391767, 'R2 - std': 0.005383486744043087}
Train time: 98.30850108899976
Inference time: 0.14279839240007278
Finished cross validation
Trial 10 finished with value: 520.4735868538475 and parameters: {'dim': 32, 'depth': 2, 'heads': 4, 'dropout': 0.6}. Best is trial 3 with value: 485.7394580560655.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514764.8125
Epoch 1 loss 512587.15625
Epoch 2 loss 509122.8125
Epoch 3 loss 503226.4375
Epoch 4 loss 492898.5
Epoch 5 loss 473445.71875
Epoch 6 loss 437322.625
Epoch 7 loss 378963.875
Epoch 8 loss 296046.1875
Epoch 9 loss 194800.265625
Epoch 10 loss 95539.84375
Epoch 11 loss 28937.30859375
Epoch 12 loss 9146.0244140625
Epoch 13 loss 9013.0986328125
Epoch 14 loss 8390.5859375
Epoch 15 loss 8229.2822265625
Epoch 16 loss 7517.84326171875
Epoch 17 loss 4163.4130859375
Epoch 18 loss 2419.21533203125
Epoch 19 loss 1889.4881591796875
Epoch 20 loss 1820.7337646484375
Epoch 21 loss 1424.3834228515625
Epoch 22 loss 1516.9962158203125
Epoch 23 loss 1170.45849609375
Epoch 24 loss 1084.18408203125
Epoch 25 loss 1115.332763671875
Epoch 26 loss 960.088134765625
Epoch 27 loss 988.3826293945312
Epoch 28 loss 1440.5994873046875
Epoch 29 loss 889.4592895507812
Epoch 30 loss 871.07958984375
Epoch 31 loss 859.0679321289062
Epoch 32 loss 1136.318603515625
Epoch 33 loss 770.9931640625
Epoch 34 loss 1025.7772216796875
Epoch 35 loss 726.77490234375
Epoch 36 loss 805.1483154296875
Epoch 37 loss 694.4873657226562
Epoch 38 loss 786.1539916992188
Epoch 39 loss 684.583251953125
Epoch 40 loss 720.1697998046875
Epoch 41 loss 668.7172241210938
Epoch 42 loss 847.4375
Epoch 43 loss 691.4503173828125
Epoch 44 loss 764.83251953125
Epoch 45 loss 640.8505859375
Epoch 46 loss 675.6233520507812
Epoch 47 loss 676.7098999023438
Epoch 48 loss 591.74755859375
Epoch 49 loss 676.6570434570312
Epoch 50 loss 589.7825927734375
Epoch 51 loss 574.7496948242188
Epoch 52 loss 694.9864501953125
Epoch 53 loss 573.8065185546875
Epoch 54 loss 656.5093994140625
Epoch 55 loss 680.9835205078125
Epoch 56 loss 560.6719360351562
Epoch 57 loss 732.952392578125
Epoch 58 loss 575.6510009765625
Epoch 59 loss 555.0980224609375
Epoch 60 loss 617.1311645507812
Epoch 61 loss 540.134765625
Epoch 62 loss 628.3697509765625
Epoch 63 loss 554.4729614257812
Epoch 64 loss 709.3699951171875
Epoch 65 loss 611.096923828125
Epoch 66 loss 543.8635864257812
Epoch 67 loss 616.1357421875
Epoch 68 loss 535.3535766601562
Epoch 69 loss 638.3811645507812
Epoch 70 loss 536.2221069335938
Epoch 71 loss 764.7592163085938
Epoch 72 loss 551.4036254882812
Epoch 73 loss 614.0693969726562
Epoch 74 loss 574.8350219726562
Epoch 75 loss 718.8485717773438
Epoch 76 loss 534.8058471679688
Epoch 77 loss 562.7142333984375
Epoch 78 loss 695.3843994140625
Epoch 79 loss 545.0866088867188
Epoch 80 loss 530.0517578125
Epoch 81 loss 558.8521118164062
Epoch 82 loss 548.7618408203125
Epoch 83 loss 530.2615966796875
Epoch 84 loss 565.6963500976562
Epoch 85 loss 521.8237915039062
Epoch 86 loss 519.6205444335938
Epoch 87 loss 525.4335327148438
Epoch 88 loss 534.6644897460938
Epoch 89 loss 735.5761108398438
Epoch 90 loss 551.2733154296875
Epoch 91 loss 535.3966674804688
Epoch 92 loss 568.4149780273438
Epoch 93 loss 584.9088745117188
Epoch 94 loss 535.0189819335938
Epoch 95 loss 589.0886840820312
Epoch 96 loss 535.5873413085938
Epoch 97 loss 518.2197875976562
Epoch 98 loss 524.2470092773438
Epoch 99 loss 568.7493286132812
Saved Losses
{'MSE - mean': 518.2200333517543, 'MSE - std': 0.0, 'R2 - mean': 0.9397460611081276, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 524474.125
Epoch 1 loss 523516.84375
Epoch 2 loss 521484.65625
Epoch 3 loss 517525.375
Epoch 4 loss 510260.5625
Epoch 5 loss 496545.4375
Epoch 6 loss 469441.375
Epoch 7 loss 421962.53125
Epoch 8 loss 349498.59375
Epoch 9 loss 252897.953125
Epoch 10 loss 145596.65625
Epoch 11 loss 56571.7109375
Epoch 12 loss 13757.275390625
Epoch 13 loss 7634.97216796875
Epoch 14 loss 7566.69384765625
Epoch 15 loss 7447.84619140625
Epoch 16 loss 6930.45068359375
Epoch 17 loss 4442.57080078125
Epoch 18 loss 2548.3876953125
Epoch 19 loss 1863.914306640625
Epoch 20 loss 1580.1053466796875
Epoch 21 loss 1382.4234619140625
Epoch 22 loss 1251.950439453125
Epoch 23 loss 1337.2657470703125
Epoch 24 loss 1058.946533203125
Epoch 25 loss 1033.688232421875
Epoch 26 loss 910.3115234375
Epoch 27 loss 830.553466796875
Epoch 28 loss 787.24951171875
Epoch 29 loss 784.9843139648438
Epoch 30 loss 733.8012084960938
Epoch 31 loss 694.9021606445312
Epoch 32 loss 768.1976928710938
Epoch 33 loss 644.1109619140625
Epoch 34 loss 650.7591552734375
Epoch 35 loss 636.2101440429688
Epoch 36 loss 621.96630859375
Epoch 37 loss 594.61083984375
Epoch 38 loss 647.4730224609375
Epoch 39 loss 614.6452026367188
Epoch 40 loss 555.0819702148438
Epoch 41 loss 561.1194458007812
Epoch 42 loss 554.7814331054688
Epoch 43 loss 548.1410522460938
Epoch 44 loss 664.8876342773438
Epoch 45 loss 532.59716796875
Epoch 46 loss 525.9059448242188
Epoch 47 loss 536.4122924804688
Epoch 48 loss 570.7108154296875
Epoch 49 loss 555.5914306640625
Epoch 50 loss 501.4933166503906
Epoch 51 loss 503.89947509765625
Epoch 52 loss 524.7732543945312
Epoch 53 loss 517.8701171875
Epoch 54 loss 556.8351440429688
Epoch 55 loss 564.0191040039062
Epoch 56 loss 600.3271484375
Epoch 57 loss 543.0222778320312
Epoch 58 loss 489.091796875
Epoch 59 loss 582.866455078125
Epoch 60 loss 494.298095703125
Epoch 61 loss 570.1226196289062
Epoch 62 loss 522.5980224609375
Epoch 63 loss 486.796142578125
Epoch 64 loss 644.574951171875
Epoch 65 loss 493.0508117675781
Epoch 66 loss 514.4186401367188
Epoch 67 loss 695.2725219726562
Epoch 68 loss 643.0537719726562
Epoch 69 loss 586.9633178710938
Epoch 70 loss 642.4561157226562
Epoch 71 loss 483.08837890625
Epoch 72 loss 538.1351318359375
Epoch 73 loss 510.022216796875
Epoch 74 loss 585.2648315429688
Epoch 75 loss 483.5552673339844
Epoch 76 loss 467.59002685546875
Epoch 77 loss 484.2181091308594
Epoch 78 loss 468.1462707519531
Epoch 79 loss 537.5842895507812
Epoch 80 loss 483.465087890625
Epoch 81 loss 466.1286315917969
Epoch 82 loss 503.93048095703125
Epoch 83 loss 522.3042602539062
Epoch 84 loss 474.91973876953125
Epoch 85 loss 512.526611328125
Epoch 86 loss 484.6747131347656
Epoch 87 loss 538.346435546875
Epoch 88 loss 466.9557189941406
Epoch 89 loss 504.1791687011719
Epoch 90 loss 460.2101135253906
Epoch 91 loss 491.72900390625
Epoch 92 loss 492.1321716308594
Epoch 93 loss 455.0262451171875
Epoch 94 loss 513.0890502929688
Epoch 95 loss 453.62847900390625
Epoch 96 loss 486.89337158203125
Epoch 97 loss 456.3911437988281
Epoch 98 loss 492.87689208984375
Epoch 99 loss 457.2901306152344
Saved Losses
{'MSE - mean': 485.9242572164774, 'MSE - std': 32.295776135276896, 'R2 - mean': 0.9401871499628884, 'R2 - std': 0.00044108885476079607} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516644.125
Epoch 1 loss 514579.625
Epoch 2 loss 511326.1875
Epoch 3 loss 505795.5
Epoch 4 loss 495970.4375
Epoch 5 loss 477644.65625
Epoch 6 loss 444181.6875
Epoch 7 loss 389552.78125
Epoch 8 loss 311023.15625
Epoch 9 loss 213023.4375
Epoch 10 loss 112958.96875
Epoch 11 loss 39367.3984375
Epoch 12 loss 11397.7431640625
Epoch 13 loss 9548.7880859375
Epoch 14 loss 9269.140625
Epoch 15 loss 9196.064453125
Epoch 16 loss 8847.6865234375
Epoch 17 loss 7406.64501953125
Epoch 18 loss 3961.82861328125
Epoch 19 loss 2716.71435546875
Epoch 20 loss 1876.0845947265625
Epoch 21 loss 1559.0765380859375
Epoch 22 loss 1390.97021484375
Epoch 23 loss 1164.216552734375
Epoch 24 loss 1129.8692626953125
Epoch 25 loss 1334.850830078125
Epoch 26 loss 981.6400756835938
Epoch 27 loss 942.7250366210938
Epoch 28 loss 867.6149291992188
Epoch 29 loss 826.3370971679688
Epoch 30 loss 936.3656616210938
Epoch 31 loss 720.6826171875
Epoch 32 loss 708.1602172851562
Epoch 33 loss 760.7990112304688
Epoch 34 loss 1110.6959228515625
Epoch 35 loss 653.947509765625
Epoch 36 loss 710.6708374023438
Epoch 37 loss 680.8409423828125
Epoch 38 loss 632.6107788085938
Epoch 39 loss 630.7333374023438
Epoch 40 loss 573.7741088867188
Epoch 41 loss 564.3117065429688
Epoch 42 loss 613.2003784179688
Epoch 43 loss 549.8487548828125
Epoch 44 loss 633.8567504882812
Epoch 45 loss 532.3924560546875
Epoch 46 loss 620.9961547851562
Epoch 47 loss 769.7642211914062
Epoch 48 loss 551.3760986328125
Epoch 49 loss 784.49755859375
Epoch 50 loss 515.5198974609375
Epoch 51 loss 537.5386962890625
Epoch 52 loss 560.3207397460938
Epoch 53 loss 567.515869140625
Epoch 54 loss 515.6920166015625
Epoch 55 loss 566.6852416992188
Epoch 56 loss 502.72149658203125
Epoch 57 loss 553.6093139648438
Epoch 58 loss 553.0486450195312
Epoch 59 loss 496.2579650878906
Epoch 60 loss 566.693603515625
Epoch 61 loss 497.08197021484375
Epoch 62 loss 477.83154296875
Epoch 63 loss 599.9108276367188
Epoch 64 loss 492.0699768066406
Epoch 65 loss 577.35107421875
Epoch 66 loss 702.4837036132812
Epoch 67 loss 514.6660766601562
Epoch 68 loss 585.24072265625
Epoch 69 loss 568.9752197265625
Epoch 70 loss 547.6140747070312
Epoch 71 loss 485.21734619140625
Epoch 72 loss 485.9739990234375
Epoch 73 loss 488.03204345703125
Epoch 74 loss 542.2678833007812
Epoch 75 loss 508.8453674316406
Epoch 76 loss 510.26495361328125
Epoch 77 loss 697.9453125
Epoch 78 loss 477.5308837890625
Epoch 79 loss 515.872314453125
Epoch 80 loss 497.9155578613281
Epoch 81 loss 500.5999450683594
Epoch 82 loss 588.6634521484375
Epoch 83 loss 491.03338623046875
Epoch 84 loss 540.7710571289062
Epoch 85 loss 774.592041015625
Epoch 86 loss 472.284912109375
Epoch 87 loss 479.37237548828125
Epoch 88 loss 571.8358154296875
Epoch 89 loss 554.463623046875
Epoch 90 loss 477.3796691894531
Epoch 91 loss 599.963134765625
Epoch 92 loss 482.11248779296875
Epoch 93 loss 638.4771118164062
Epoch 94 loss 602.3639526367188
Epoch 95 loss 481.33306884765625
Epoch 96 loss 572.0687255859375
Epoch 97 loss 484.4917907714844
Epoch 98 loss 606.9328002929688
Epoch 99 loss 466.3639831542969
Saved Losses
{'MSE - mean': 479.40422146433474, 'MSE - std': 27.935040776863936, 'R2 - mean': 0.9434243505700707, 'R2 - std': 0.0045922371230312595} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517572.78125
Epoch 1 loss 514659.625
Epoch 2 loss 510262.40625
Epoch 3 loss 502937.46875
Epoch 4 loss 490341.84375
Epoch 5 loss 467135.84375
Epoch 6 loss 426011.71875
Epoch 7 loss 362227.4375
Epoch 8 loss 275075.25
Epoch 9 loss 173535.390625
Epoch 10 loss 79999.484375
Epoch 11 loss 23114.26953125
Epoch 12 loss 8553.7685546875
Epoch 13 loss 8558.9140625
Epoch 14 loss 8236.466796875
Epoch 15 loss 7905.2548828125
Epoch 16 loss 6630.84619140625
Epoch 17 loss 3761.4716796875
Epoch 18 loss 2662.406005859375
Epoch 19 loss 2069.83642578125
Epoch 20 loss 1687.018798828125
Epoch 21 loss 1522.9742431640625
Epoch 22 loss 1624.52734375
Epoch 23 loss 1411.9124755859375
Epoch 24 loss 1243.450439453125
Epoch 25 loss 1037.425537109375
Epoch 26 loss 1089.0843505859375
Epoch 27 loss 952.1011352539062
Epoch 28 loss 901.5596923828125
Epoch 29 loss 1060.781494140625
Epoch 30 loss 825.9537353515625
Epoch 31 loss 958.4727783203125
Epoch 32 loss 765.2481689453125
Epoch 33 loss 790.068359375
Epoch 34 loss 924.5072021484375
Epoch 35 loss 782.052734375
Epoch 36 loss 820.8511962890625
Epoch 37 loss 719.0650024414062
Epoch 38 loss 662.96240234375
Epoch 39 loss 643.8129272460938
Epoch 40 loss 688.313232421875
Epoch 41 loss 765.122802734375
Epoch 42 loss 689.1752319335938
Epoch 43 loss 674.92919921875
Epoch 44 loss 628.741943359375
Epoch 45 loss 598.0702514648438
Epoch 46 loss 635.1078491210938
Epoch 47 loss 726.0667114257812
Epoch 48 loss 597.9224243164062
Epoch 49 loss 610.885498046875
Epoch 50 loss 598.2261352539062
Epoch 51 loss 692.46142578125
Epoch 52 loss 626.4212036132812
Epoch 53 loss 579.138671875
Epoch 54 loss 555.1974487304688
Epoch 55 loss 697.7869873046875
Epoch 56 loss 576.3256225585938
Epoch 57 loss 556.9114379882812
Epoch 58 loss 786.80712890625
Epoch 59 loss 658.5140380859375
Epoch 60 loss 552.8683471679688
Epoch 61 loss 538.8275756835938
Epoch 62 loss 574.6160888671875
Epoch 63 loss 537.1852416992188
Epoch 64 loss 757.6228637695312
Epoch 65 loss 553.5760498046875
Epoch 66 loss 574.467529296875
Epoch 67 loss 678.5618286132812
Epoch 68 loss 541.3441162109375
Epoch 69 loss 594.263916015625
Epoch 70 loss 702.8179931640625
Epoch 71 loss 556.323486328125
Epoch 72 loss 552.779296875
Epoch 73 loss 595.4890747070312
Epoch 74 loss 547.4172973632812
Epoch 75 loss 577.4800415039062
Epoch 76 loss 699.8811645507812
Epoch 77 loss 521.4830932617188
Epoch 78 loss 653.706787109375
Epoch 79 loss 540.2183227539062
Epoch 80 loss 674.9074096679688
Epoch 81 loss 598.1895141601562
Epoch 82 loss 588.5755615234375
Epoch 83 loss 534.2158813476562
Epoch 84 loss 586.5922241210938
Epoch 85 loss 523.9638671875
Epoch 86 loss 529.0948486328125
Epoch 87 loss 704.131591796875
Epoch 88 loss 529.460693359375
Epoch 89 loss 548.9166870117188
Epoch 90 loss 597.0450439453125
Epoch 91 loss 540.8662719726562
Epoch 92 loss 537.982421875
Epoch 93 loss 536.39208984375
Epoch 94 loss 560.9622802734375
Epoch 95 loss 619.4527587890625
Epoch 96 loss 546.8311157226562
Epoch 97 loss 513.468017578125
Epoch 98 loss 818.6146850585938
Epoch 99 loss 527.0259399414062
Saved Losses
{'MSE - mean': 487.92012335653556, 'MSE - std': 28.33437192733513, 'R2 - mean': 0.9421126339305711, 'R2 - std': 0.004580205560084641} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515324.71875
Epoch 1 loss 513011.8125
Epoch 2 loss 509244.59375
Epoch 3 loss 502843.15625
Epoch 4 loss 491797.96875
Epoch 5 loss 472232.25
Epoch 6 loss 437448.75
Epoch 7 loss 381609.5
Epoch 8 loss 302762.40625
Epoch 9 loss 205191.390625
Epoch 10 loss 106272.828125
Epoch 11 loss 35257.1015625
Epoch 12 loss 9421.357421875
Epoch 13 loss 8235.5556640625
Epoch 14 loss 7853.30810546875
Epoch 15 loss 7708.74951171875
Epoch 16 loss 6902.5908203125
Epoch 17 loss 3689.047119140625
Epoch 18 loss 2330.0693359375
Epoch 19 loss 1743.1949462890625
Epoch 20 loss 1496.966796875
Epoch 21 loss 1276.5660400390625
Epoch 22 loss 1140.626708984375
Epoch 23 loss 1137.2685546875
Epoch 24 loss 986.7296752929688
Epoch 25 loss 1194.3607177734375
Epoch 26 loss 929.75732421875
Epoch 27 loss 856.3466186523438
Epoch 28 loss 795.9703979492188
Epoch 29 loss 761.5557250976562
Epoch 30 loss 792.2341918945312
Epoch 31 loss 727.9825439453125
Epoch 32 loss 719.6643676757812
Epoch 33 loss 674.6730346679688
Epoch 34 loss 672.9539794921875
Epoch 35 loss 661.4049682617188
Epoch 36 loss 725.6572265625
Epoch 37 loss 757.5203857421875
Epoch 38 loss 617.7987060546875
Epoch 39 loss 593.1748046875
Epoch 40 loss 725.2110595703125
Epoch 41 loss 734.5941162109375
Epoch 42 loss 626.3458862304688
Epoch 43 loss 586.9219970703125
Epoch 44 loss 571.7402954101562
Epoch 45 loss 576.7219848632812
Epoch 46 loss 557.3450927734375
Epoch 47 loss 582.737548828125
Epoch 48 loss 566.0183715820312
Epoch 49 loss 547.7864379882812
Epoch 50 loss 613.157958984375
Epoch 51 loss 543.7960815429688
Epoch 52 loss 548.2017822265625
Epoch 53 loss 574.9052124023438
Epoch 54 loss 548.259765625
Epoch 55 loss 545.5484008789062
Epoch 56 loss 559.962646484375
Epoch 57 loss 516.8302612304688
Epoch 58 loss 556.2156372070312
Epoch 59 loss 567.91259765625
Epoch 60 loss 513.721435546875
Epoch 61 loss 505.517333984375
Epoch 62 loss 517.3247680664062
Epoch 63 loss 579.1427001953125
Epoch 64 loss 528.749267578125
Epoch 65 loss 533.4923706054688
Epoch 66 loss 508.47979736328125
Epoch 67 loss 576.0123291015625
Epoch 68 loss 491.7413330078125
Epoch 69 loss 605.7647094726562
Epoch 70 loss 502.7181091308594
Epoch 71 loss 525.0164794921875
Epoch 72 loss 525.995361328125
Epoch 73 loss 494.6435852050781
Epoch 74 loss 686.6472778320312
Epoch 75 loss 506.2279357910156
Epoch 76 loss 554.339599609375
Epoch 77 loss 488.6312561035156
Epoch 78 loss 665.4041748046875
Epoch 79 loss 495.93194580078125
Epoch 80 loss 519.1218872070312
Epoch 81 loss 482.7843933105469
Epoch 82 loss 620.2468872070312
Epoch 83 loss 499.28948974609375
Epoch 84 loss 603.18310546875
Epoch 85 loss 515.512451171875
Epoch 86 loss 491.1435852050781
Epoch 87 loss 526.4462890625
Epoch 88 loss 544.65087890625
Epoch 89 loss 480.3792419433594
Epoch 90 loss 486.58148193359375
Epoch 91 loss 547.0721435546875
Epoch 92 loss 484.5074462890625
Epoch 93 loss 531.5139770507812
Epoch 94 loss 469.67474365234375
Epoch 95 loss 484.0715026855469
Epoch 96 loss 497.6256103515625
Epoch 97 loss 486.2244567871094
Epoch 98 loss 484.73687744140625
Epoch 99 loss 621.230712890625
Saved Losses
{'MSE - mean': 484.2710912942501, 'MSE - std': 26.372922590786096, 'R2 - mean': 0.9419159090851051, 'R2 - std': 0.004115510786937476} 
 

Results After CV: {'MSE - mean': 484.2710912942501, 'MSE - std': 26.372922590786096, 'R2 - mean': 0.9419159090851051, 'R2 - std': 0.004115510786937476}
Train time: 104.77795562339998
Inference time: 0.14447721719971013
Finished cross validation
Trial 11 finished with value: 484.2710912942501 and parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.3}. Best is trial 11 with value: 484.2710912942501.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515147.03125
Epoch 1 loss 513353.5625
Epoch 2 loss 510310.28125
Epoch 3 loss 505051.28125
Epoch 4 loss 496488.96875
Epoch 5 loss 480603.75
Epoch 6 loss 450310.03125
Epoch 7 loss 399423.15625
Epoch 8 loss 325008.0625
Epoch 9 loss 229112.15625
Epoch 10 loss 126627.0859375
Epoch 11 loss 46426.453125
Epoch 12 loss 11983.615234375
Epoch 13 loss 8742.556640625
Epoch 14 loss 8410.6435546875
Epoch 15 loss 8128.470703125
Epoch 16 loss 7269.14599609375
Epoch 17 loss 4120.8857421875
Epoch 18 loss 2559.48291015625
Epoch 19 loss 1891.5924072265625
Epoch 20 loss 1533.8414306640625
Epoch 21 loss 1346.092529296875
Epoch 22 loss 1186.281982421875
Epoch 23 loss 1111.262939453125
Epoch 24 loss 1070.8480224609375
Epoch 25 loss 980.0631103515625
Epoch 26 loss 964.7216186523438
Epoch 27 loss 873.6432495117188
Epoch 28 loss 839.9764404296875
Epoch 29 loss 850.124755859375
Epoch 30 loss 808.3201293945312
Epoch 31 loss 894.9011840820312
Epoch 32 loss 763.675048828125
Epoch 33 loss 850.7633666992188
Epoch 34 loss 790.5137329101562
Epoch 35 loss 739.398193359375
Epoch 36 loss 706.7589111328125
Epoch 37 loss 710.5809936523438
Epoch 38 loss 692.0577392578125
Epoch 39 loss 680.35302734375
Epoch 40 loss 696.4619140625
Epoch 41 loss 776.3612670898438
Epoch 42 loss 699.360595703125
Epoch 43 loss 656.4298706054688
Epoch 44 loss 646.081298828125
Epoch 45 loss 628.5435180664062
Epoch 46 loss 645.7658081054688
Epoch 47 loss 666.6727905273438
Epoch 48 loss 661.6192016601562
Epoch 49 loss 620.2692260742188
Epoch 50 loss 634.8053588867188
Epoch 51 loss 655.2418212890625
Epoch 52 loss 635.73486328125
Epoch 53 loss 606.836181640625
Epoch 54 loss 747.2061157226562
Epoch 55 loss 644.8994750976562
Epoch 56 loss 724.1766967773438
Epoch 57 loss 598.4525756835938
Epoch 58 loss 662.4385375976562
Epoch 59 loss 749.0636596679688
Epoch 60 loss 588.1906127929688
Epoch 61 loss 590.5366821289062
Epoch 62 loss 585.3146362304688
Epoch 63 loss 596.5661010742188
Epoch 64 loss 581.7858276367188
Epoch 65 loss 585.3966674804688
Epoch 66 loss 579.6804809570312
Epoch 67 loss 577.298095703125
Epoch 68 loss 584.8015747070312
Epoch 69 loss 592.9457397460938
Epoch 70 loss 578.9992065429688
Epoch 71 loss 576.2041015625
Epoch 72 loss 684.7930297851562
Epoch 73 loss 577.6890258789062
Epoch 74 loss 578.0372314453125
Epoch 75 loss 580.3375244140625
Epoch 76 loss 660.45068359375
Epoch 77 loss 583.7315673828125
Epoch 78 loss 595.1578979492188
Epoch 79 loss 689.35302734375
Epoch 80 loss 570.6527709960938
Epoch 81 loss 557.5422973632812
Epoch 82 loss 681.7127685546875
Epoch 83 loss 555.32177734375
Epoch 84 loss 565.3599243164062
Epoch 85 loss 573.73779296875
Epoch 86 loss 555.3680419921875
Epoch 87 loss 566.8836669921875
Epoch 88 loss 565.0640869140625
Epoch 89 loss 571.8131713867188
Epoch 90 loss 579.919677734375
Epoch 91 loss 570.87109375
Epoch 92 loss 679.4232177734375
Epoch 93 loss 609.0292358398438
Epoch 94 loss 556.9365234375
Epoch 95 loss 573.4545288085938
Epoch 96 loss 551.1345825195312
Epoch 97 loss 538.4208984375
Epoch 98 loss 607.7968139648438
Epoch 99 loss 599.8765258789062
Saved Losses
{'MSE - mean': 538.420999599025, 'MSE - std': 0.0, 'R2 - mean': 0.9373972754428046, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523566.15625
Epoch 1 loss 521723.03125
Epoch 2 loss 518307.03125
Epoch 3 loss 512587.34375
Epoch 4 loss 503168.96875
Epoch 5 loss 484955.34375
Epoch 6 loss 451655.96875
Epoch 7 loss 398028.96875
Epoch 8 loss 321058.84375
Epoch 9 loss 224086.84375
Epoch 10 loss 123153.15625
Epoch 11 loss 45481.90234375
Epoch 12 loss 11790.21875
Epoch 13 loss 7603.48828125
Epoch 14 loss 7428.81298828125
Epoch 15 loss 7145.5771484375
Epoch 16 loss 6001.046875
Epoch 17 loss 3411.47119140625
Epoch 18 loss 2380.878662109375
Epoch 19 loss 1725.6318359375
Epoch 20 loss 1323.1827392578125
Epoch 21 loss 1127.9140625
Epoch 22 loss 1003.9107666015625
Epoch 23 loss 935.1724243164062
Epoch 24 loss 876.9476318359375
Epoch 25 loss 1112.02783203125
Epoch 26 loss 941.2681274414062
Epoch 27 loss 819.2128295898438
Epoch 28 loss 726.5193481445312
Epoch 29 loss 819.7037963867188
Epoch 30 loss 733.626953125
Epoch 31 loss 672.7711181640625
Epoch 32 loss 662.9730224609375
Epoch 33 loss 628.1632080078125
Epoch 34 loss 667.8472900390625
Epoch 35 loss 740.128173828125
Epoch 36 loss 729.2982788085938
Epoch 37 loss 626.530517578125
Epoch 38 loss 583.3683471679688
Epoch 39 loss 677.7213745117188
Epoch 40 loss 582.3717041015625
Epoch 41 loss 691.1151733398438
Epoch 42 loss 635.70458984375
Epoch 43 loss 575.3851928710938
Epoch 44 loss 559.2034301757812
Epoch 45 loss 544.0205078125
Epoch 46 loss 598.6240234375
Epoch 47 loss 599.8805541992188
Epoch 48 loss 671.9522705078125
Epoch 49 loss 620.1364135742188
Epoch 50 loss 550.8511352539062
Epoch 51 loss 608.0422973632812
Epoch 52 loss 580.9111938476562
Epoch 53 loss 509.11212158203125
Epoch 54 loss 533.6094970703125
Epoch 55 loss 524.7495727539062
Epoch 56 loss 745.2942504882812
Epoch 57 loss 556.652099609375
Epoch 58 loss 501.2661437988281
Epoch 59 loss 493.3977966308594
Epoch 60 loss 483.896728515625
Epoch 61 loss 614.0989379882812
Epoch 62 loss 523.286865234375
Epoch 63 loss 490.9210205078125
Epoch 64 loss 494.55572509765625
Epoch 65 loss 479.29302978515625
Epoch 66 loss 517.7472534179688
Epoch 67 loss 511.5785827636719
Epoch 68 loss 471.4287109375
Epoch 69 loss 545.7495727539062
Epoch 70 loss 477.72882080078125
Epoch 71 loss 490.3900451660156
Epoch 72 loss 477.4572448730469
Epoch 73 loss 476.882080078125
Epoch 74 loss 589.6626586914062
Epoch 75 loss 477.2756652832031
Epoch 76 loss 469.0889587402344
Epoch 77 loss 517.3689575195312
Epoch 78 loss 476.4533996582031
Epoch 79 loss 553.1683959960938
Epoch 80 loss 480.25
Epoch 81 loss 470.2194519042969
Epoch 82 loss 459.89581298828125
Epoch 83 loss 469.9637756347656
Epoch 84 loss 488.7409362792969
Epoch 85 loss 464.8962707519531
Epoch 86 loss 518.1803588867188
Epoch 87 loss 457.1189270019531
Epoch 88 loss 524.3145751953125
Epoch 89 loss 479.7784118652344
Epoch 90 loss 471.689453125
Epoch 91 loss 554.90576171875
Epoch 92 loss 503.5347900390625
Epoch 93 loss 451.0794677734375
Epoch 94 loss 488.06097412109375
Epoch 95 loss 500.014892578125
Epoch 96 loss 481.7702941894531
Epoch 97 loss 450.0198059082031
Epoch 98 loss 449.213134765625
Epoch 99 loss 463.3172607421875
Saved Losses
{'MSE - mean': 493.8169398884787, 'MSE - std': 44.604059710546295, 'R2 - mean': 0.9393017182660892, 'R2 - std': 0.0019044428232846133} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516786.15625
Epoch 1 loss 514596.53125
Epoch 2 loss 510936.3125
Epoch 3 loss 505094.53125
Epoch 4 loss 495939.5625
Epoch 5 loss 477984.375
Epoch 6 loss 444310.96875
Epoch 7 loss 389179.28125
Epoch 8 loss 309955.3125
Epoch 9 loss 211095.421875
Epoch 10 loss 110426.046875
Epoch 11 loss 37756.37890625
Epoch 12 loss 11111.8447265625
Epoch 13 loss 9484.7236328125
Epoch 14 loss 9052.51171875
Epoch 15 loss 8769.927734375
Epoch 16 loss 7794.63916015625
Epoch 17 loss 4872.79736328125
Epoch 18 loss 3358.189208984375
Epoch 19 loss 2512.8203125
Epoch 20 loss 1915.35693359375
Epoch 21 loss 1728.9986572265625
Epoch 22 loss 1375.7967529296875
Epoch 23 loss 1269.51416015625
Epoch 24 loss 1195.493896484375
Epoch 25 loss 1075.0970458984375
Epoch 26 loss 968.0166015625
Epoch 27 loss 954.562744140625
Epoch 28 loss 990.8674926757812
Epoch 29 loss 878.9835205078125
Epoch 30 loss 918.053466796875
Epoch 31 loss 763.23193359375
Epoch 32 loss 789.2669677734375
Epoch 33 loss 716.0640869140625
Epoch 34 loss 728.69091796875
Epoch 35 loss 684.1512451171875
Epoch 36 loss 666.45068359375
Epoch 37 loss 715.8782958984375
Epoch 38 loss 640.013916015625
Epoch 39 loss 673.7193603515625
Epoch 40 loss 604.8807983398438
Epoch 41 loss 575.1724853515625
Epoch 42 loss 618.9253540039062
Epoch 43 loss 603.9390258789062
Epoch 44 loss 548.08642578125
Epoch 45 loss 584.4976196289062
Epoch 46 loss 531.4866333007812
Epoch 47 loss 538.9013671875
Epoch 48 loss 513.2225341796875
Epoch 49 loss 540.312255859375
Epoch 50 loss 506.515869140625
Epoch 51 loss 501.7630615234375
Epoch 52 loss 693.2349853515625
Epoch 53 loss 493.2027893066406
Epoch 54 loss 739.4044799804688
Epoch 55 loss 618.3300170898438
Epoch 56 loss 550.7258911132812
Epoch 57 loss 514.7977294921875
Epoch 58 loss 484.0084533691406
Epoch 59 loss 490.3721923828125
Epoch 60 loss 518.166015625
Epoch 61 loss 475.70758056640625
Epoch 62 loss 480.861572265625
Epoch 63 loss 487.22161865234375
Epoch 64 loss 590.764404296875
Epoch 65 loss 480.8241271972656
Epoch 66 loss 502.072265625
Epoch 67 loss 491.7989196777344
Epoch 68 loss 508.3027648925781
Epoch 69 loss 797.5679321289062
Epoch 70 loss 467.0321960449219
Epoch 71 loss 464.72802734375
Epoch 72 loss 500.9431457519531
Epoch 73 loss 628.86865234375
Epoch 74 loss 461.85638427734375
Epoch 75 loss 578.5421752929688
Epoch 76 loss 498.4658203125
Epoch 77 loss 467.89117431640625
Epoch 78 loss 495.12823486328125
Epoch 79 loss 462.66607666015625
Epoch 80 loss 547.2285766601562
Epoch 81 loss 460.1000061035156
Epoch 82 loss 540.5281982421875
Epoch 83 loss 488.6988220214844
Epoch 84 loss 459.52880859375
Epoch 85 loss 468.8826904296875
Epoch 86 loss 485.9291076660156
Epoch 87 loss 479.6099853515625
Epoch 88 loss 570.3068237304688
Epoch 89 loss 469.81170654296875
Epoch 90 loss 458.1955871582031
Epoch 91 loss 477.2003173828125
Epoch 92 loss 546.681884765625
Epoch 93 loss 447.2818298339844
Epoch 94 loss 614.0325317382812
Epoch 95 loss 444.95111083984375
Epoch 96 loss 518.9017333984375
Epoch 97 loss 445.9410400390625
Epoch 98 loss 457.8698425292969
Epoch 99 loss 469.46234130859375
Saved Losses
{'MSE - mean': 477.5283416497742, 'MSE - std': 43.09274834901854, 'R2 - mean': 0.9436008586104645, 'R2 - std': 0.006275599603175516} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520252.78125
Epoch 1 loss 518862.40625
Epoch 2 loss 516263.34375
Epoch 3 loss 511586.125
Epoch 4 loss 504019.3125
Epoch 5 loss 489586.46875
Epoch 6 loss 461620.53125
Epoch 7 loss 414395.09375
Epoch 8 loss 344304.0625
Epoch 9 loss 252484.59375
Epoch 10 loss 150570.609375
Epoch 11 loss 63031.015625
Epoch 12 loss 17034.986328125
Epoch 13 loss 8301.662109375
Epoch 14 loss 8271.470703125
Epoch 15 loss 7944.17041015625
Epoch 16 loss 7429.53955078125
Epoch 17 loss 4886.978515625
Epoch 18 loss 3218.211669921875
Epoch 19 loss 2931.314697265625
Epoch 20 loss 2173.625
Epoch 21 loss 1787.1619873046875
Epoch 22 loss 1474.7850341796875
Epoch 23 loss 1392.3690185546875
Epoch 24 loss 1348.4814453125
Epoch 25 loss 1386.953369140625
Epoch 26 loss 1064.624755859375
Epoch 27 loss 1206.0052490234375
Epoch 28 loss 1516.8675537109375
Epoch 29 loss 917.2382202148438
Epoch 30 loss 1199.7342529296875
Epoch 31 loss 832.9462280273438
Epoch 32 loss 969.2022705078125
Epoch 33 loss 784.2881469726562
Epoch 34 loss 810.933837890625
Epoch 35 loss 822.35009765625
Epoch 36 loss 748.37548828125
Epoch 37 loss 782.8726196289062
Epoch 38 loss 884.17529296875
Epoch 39 loss 707.0344848632812
Epoch 40 loss 664.7642211914062
Epoch 41 loss 648.2528076171875
Epoch 42 loss 699.552734375
Epoch 43 loss 655.467529296875
Epoch 44 loss 625.8001098632812
Epoch 45 loss 621.9828491210938
Epoch 46 loss 820.4486694335938
Epoch 47 loss 656.8806762695312
Epoch 48 loss 637.9276733398438
Epoch 49 loss 591.548095703125
Epoch 50 loss 681.9849853515625
Epoch 51 loss 675.4384155273438
Epoch 52 loss 590.6061401367188
Epoch 53 loss 579.0228271484375
Epoch 54 loss 578.3946533203125
Epoch 55 loss 559.4215698242188
Epoch 56 loss 595.42822265625
Epoch 57 loss 836.5054321289062
Epoch 58 loss 563.6267700195312
Epoch 59 loss 787.7274169921875
Epoch 60 loss 599.71875
Epoch 61 loss 634.4937133789062
Epoch 62 loss 574.8497924804688
Epoch 63 loss 552.3189697265625
Epoch 64 loss 569.2598266601562
Epoch 65 loss 613.8668212890625
Epoch 66 loss 583.6646728515625
Epoch 67 loss 571.8336791992188
Epoch 68 loss 676.9224853515625
Epoch 69 loss 539.5321044921875
Epoch 70 loss 572.529296875
Epoch 71 loss 538.7141723632812
Epoch 72 loss 613.41552734375
Epoch 73 loss 523.1370239257812
Epoch 74 loss 591.7201538085938
Epoch 75 loss 534.9258422851562
Epoch 76 loss 529.97216796875
Epoch 77 loss 772.8939819335938
Epoch 78 loss 514.540771484375
Epoch 79 loss 527.4437255859375
Epoch 80 loss 565.9800415039062
Epoch 81 loss 515.4562377929688
Epoch 82 loss 573.3570556640625
Epoch 83 loss 560.5588989257812
Epoch 84 loss 509.0895080566406
Epoch 85 loss 552.4705810546875
Epoch 86 loss 512.048828125
Epoch 87 loss 633.9072265625
Epoch 88 loss 530.7905883789062
Epoch 89 loss 529.421142578125
Epoch 90 loss 519.3056640625
Epoch 91 loss 670.1737670898438
Epoch 92 loss 503.55706787109375
Epoch 93 loss 498.86077880859375
Epoch 94 loss 509.11419677734375
Epoch 95 loss 542.4518432617188
Epoch 96 loss 509.10675048828125
Epoch 97 loss 516.1050415039062
Epoch 98 loss 504.11688232421875
Epoch 99 loss 511.2364501953125
Saved Losses
{'MSE - mean': 482.8615014625901, 'MSE - std': 38.445630453550706, 'R2 - mean': 0.9426846881259217, 'R2 - std': 0.0056617548388088156} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515892.21875
Epoch 1 loss 513377.5625
Epoch 2 loss 509411.3125
Epoch 3 loss 503097.46875
Epoch 4 loss 493564.21875
Epoch 5 loss 475850.375
Epoch 6 loss 442821.84375
Epoch 7 loss 389414.90625
Epoch 8 loss 312639.375
Epoch 9 loss 216124.359375
Epoch 10 loss 116319.3203125
Epoch 11 loss 40907.09375
Epoch 12 loss 10549.9052734375
Epoch 13 loss 8115.21240234375
Epoch 14 loss 7811.8037109375
Epoch 15 loss 7554.20263671875
Epoch 16 loss 6794.72705078125
Epoch 17 loss 4230.92724609375
Epoch 18 loss 2585.7119140625
Epoch 19 loss 1868.0374755859375
Epoch 20 loss 1530.62060546875
Epoch 21 loss 1316.4656982421875
Epoch 22 loss 1151.9146728515625
Epoch 23 loss 1077.1651611328125
Epoch 24 loss 1017.6415405273438
Epoch 25 loss 934.785400390625
Epoch 26 loss 929.759521484375
Epoch 27 loss 884.0183715820312
Epoch 28 loss 772.85400390625
Epoch 29 loss 768.9702758789062
Epoch 30 loss 760.8875122070312
Epoch 31 loss 698.0739135742188
Epoch 32 loss 720.9757080078125
Epoch 33 loss 638.7882690429688
Epoch 34 loss 637.1082153320312
Epoch 35 loss 755.3052978515625
Epoch 36 loss 673.7393188476562
Epoch 37 loss 620.69189453125
Epoch 38 loss 585.7098388671875
Epoch 39 loss 577.048095703125
Epoch 40 loss 618.2008056640625
Epoch 41 loss 598.2509765625
Epoch 42 loss 575.221923828125
Epoch 43 loss 560.3350830078125
Epoch 44 loss 572.0360717773438
Epoch 45 loss 603.19091796875
Epoch 46 loss 713.0808715820312
Epoch 47 loss 595.5399780273438
Epoch 48 loss 538.522216796875
Epoch 49 loss 567.6209106445312
Epoch 50 loss 532.3026733398438
Epoch 51 loss 577.8206176757812
Epoch 52 loss 539.7160034179688
Epoch 53 loss 531.5509643554688
Epoch 54 loss 510.6206970214844
Epoch 55 loss 541.9409790039062
Epoch 56 loss 510.69073486328125
Epoch 57 loss 671.6490478515625
Epoch 58 loss 520.9920654296875
Epoch 59 loss 524.0128173828125
Epoch 60 loss 621.2360229492188
Epoch 61 loss 550.4620361328125
Epoch 62 loss 503.5168762207031
Epoch 63 loss 504.3963623046875
Epoch 64 loss 522.7576293945312
Epoch 65 loss 501.1103210449219
Epoch 66 loss 565.6837158203125
Epoch 67 loss 495.1144104003906
Epoch 68 loss 499.8722839355469
Epoch 69 loss 533.3873291015625
Epoch 70 loss 517.8240356445312
Epoch 71 loss 612.9546508789062
Epoch 72 loss 518.297119140625
Epoch 73 loss 581.7568969726562
Epoch 74 loss 575.8292846679688
Epoch 75 loss 521.255126953125
Epoch 76 loss 488.5514831542969
Epoch 77 loss 485.86846923828125
Epoch 78 loss 485.0928955078125
Epoch 79 loss 490.9538879394531
Epoch 80 loss 513.4163818359375
Epoch 81 loss 506.53497314453125
Epoch 82 loss 507.2987060546875
Epoch 83 loss 503.66302490234375
Epoch 84 loss 497.39111328125
Epoch 85 loss 503.31182861328125
Epoch 86 loss 488.27099609375
Epoch 87 loss 499.21600341796875
Epoch 88 loss 490.7470703125
Epoch 89 loss 508.595947265625
Epoch 90 loss 527.0255737304688
Epoch 91 loss 492.0125427246094
Epoch 92 loss 490.1482238769531
Epoch 93 loss 493.1487731933594
Epoch 94 loss 538.0157470703125
Epoch 95 loss 495.9910888671875
Epoch 96 loss 502.3096618652344
Epoch 97 loss 539.9174194335938
Epoch 98 loss 505.04998779296875
Epoch 99 loss 481.3846130371094
Saved Losses
{'MSE - mean': 482.5660834789284, 'MSE - std': 34.39189276438666, 'R2 - mean': 0.9420800103609196, 'R2 - std': 0.00520643016680064} 
 

Results After CV: {'MSE - mean': 482.5660834789284, 'MSE - std': 34.39189276438666, 'R2 - mean': 0.9420800103609196, 'R2 - std': 0.00520643016680064}
Train time: 96.57069430160008
Inference time: 0.14083817379996616
Finished cross validation
Trial 12 finished with value: 482.5660834789284 and parameters: {'dim': 256, 'depth': 2, 'heads': 4, 'dropout': 0.2}. Best is trial 12 with value: 482.5660834789284.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515122.65625
Epoch 1 loss 513038.96875
Epoch 2 loss 509783.28125
Epoch 3 loss 504081.25
Epoch 4 loss 494065.0625
Epoch 5 loss 475737.96875
Epoch 6 loss 442369.75
Epoch 7 loss 387312.03125
Epoch 8 loss 307326.65625
Epoch 9 loss 207567.421875
Epoch 10 loss 106672.0078125
Epoch 11 loss 34771.87109375
Epoch 12 loss 9796.4296875
Epoch 13 loss 8947.47265625
Epoch 14 loss 8777.1279296875
Epoch 15 loss 8428.3779296875
Epoch 16 loss 8373.5546875
Epoch 17 loss 7988.81787109375
Epoch 18 loss 6137.0234375
Epoch 19 loss 4136.91748046875
Epoch 20 loss 2611.644775390625
Epoch 21 loss 2608.006103515625
Epoch 22 loss 1972.986328125
Epoch 23 loss 2254.61181640625
Epoch 24 loss 1736.5037841796875
Epoch 25 loss 1629.12939453125
Epoch 26 loss 2005.5633544921875
Epoch 27 loss 1471.3345947265625
Epoch 28 loss 1586.8084716796875
Epoch 29 loss 1534.09619140625
Epoch 30 loss 1181.6070556640625
Epoch 31 loss 1119.25732421875
Epoch 32 loss 1445.7886962890625
Epoch 33 loss 1627.617919921875
Epoch 34 loss 1068.65087890625
Epoch 35 loss 1029.707275390625
Epoch 36 loss 1158.573974609375
Epoch 37 loss 1205.867431640625
Epoch 38 loss 1456.23046875
Epoch 39 loss 828.6373901367188
Epoch 40 loss 938.3260498046875
Epoch 41 loss 1043.25
Epoch 42 loss 1076.19287109375
Epoch 43 loss 998.6849975585938
Epoch 44 loss 1048.5902099609375
Epoch 45 loss 1274.794677734375
Epoch 46 loss 877.7201538085938
Epoch 47 loss 813.021484375
Epoch 48 loss 810.2774047851562
Epoch 49 loss 1217.8236083984375
Epoch 50 loss 789.3838500976562
Epoch 51 loss 907.0617065429688
Epoch 52 loss 1013.20654296875
Epoch 53 loss 1281.823974609375
Epoch 54 loss 721.8681030273438
Epoch 55 loss 988.013427734375
Epoch 56 loss 866.408935546875
Epoch 57 loss 849.5308837890625
Epoch 58 loss 666.6871337890625
Epoch 59 loss 942.9127807617188
Epoch 60 loss 1232.671142578125
Epoch 61 loss 720.8036499023438
Epoch 62 loss 703.7005004882812
Epoch 63 loss 803.9715576171875
Epoch 64 loss 1117.6612548828125
Epoch 65 loss 1096.468505859375
Epoch 66 loss 674.889892578125
Epoch 67 loss 827.5369873046875
Epoch 68 loss 871.7609252929688
Epoch 69 loss 728.2684326171875
Epoch 70 loss 708.2390747070312
Epoch 71 loss 809.482666015625
Epoch 72 loss 763.3489379882812
Epoch 73 loss 721.14599609375
Epoch 74 loss 681.4181518554688
Epoch 75 loss 1000.0674438476562
Epoch 76 loss 661.7244262695312
Epoch 77 loss 810.8289794921875
Epoch 78 loss 707.87451171875
Epoch 79 loss 715.4664306640625
Epoch 80 loss 706.3008422851562
Epoch 81 loss 710.5294799804688
Epoch 82 loss 789.341796875
Epoch 83 loss 895.1091918945312
Epoch 84 loss 599.3975830078125
Epoch 85 loss 676.324462890625
Epoch 86 loss 975.5432739257812
Epoch 87 loss 743.0562133789062
Epoch 88 loss 591.0958251953125
Epoch 89 loss 818.7992553710938
Epoch 90 loss 789.3345336914062
Epoch 91 loss 944.71826171875
Epoch 92 loss 754.9705810546875
Epoch 93 loss 638.2220458984375
Epoch 94 loss 782.5284423828125
Epoch 95 loss 763.9846801757812
Epoch 96 loss 1102.1419677734375
Epoch 97 loss 802.5734252929688
Epoch 98 loss 618.302490234375
Epoch 99 loss 743.8942260742188
Saved Losses
{'MSE - mean': 591.095602502149, 'MSE - std': 0.0, 'R2 - mean': 0.9312727489864449, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523098.6875
Epoch 1 loss 520979.125
Epoch 2 loss 517591.53125
Epoch 3 loss 512238.84375
Epoch 4 loss 503468.15625
Epoch 5 loss 487920.65625
Epoch 6 loss 459138.0
Epoch 7 loss 410109.875
Epoch 8 loss 336721.0625
Epoch 9 loss 241315.765625
Epoch 10 loss 137894.8125
Epoch 11 loss 53375.22265625
Epoch 12 loss 13399.2919921875
Epoch 13 loss 7625.06298828125
Epoch 14 loss 7658.47900390625
Epoch 15 loss 7537.98486328125
Epoch 16 loss 7366.4638671875
Epoch 17 loss 6996.17529296875
Epoch 18 loss 5460.65478515625
Epoch 19 loss 3817.644287109375
Epoch 20 loss 2133.08154296875
Epoch 21 loss 2388.14501953125
Epoch 22 loss 1487.932861328125
Epoch 23 loss 2004.469482421875
Epoch 24 loss 1257.9075927734375
Epoch 25 loss 1155.4132080078125
Epoch 26 loss 1150.2330322265625
Epoch 27 loss 1009.0394287109375
Epoch 28 loss 955.1910400390625
Epoch 29 loss 1469.587890625
Epoch 30 loss 1028.7032470703125
Epoch 31 loss 823.2315673828125
Epoch 32 loss 1172.9853515625
Epoch 33 loss 754.0859375
Epoch 34 loss 718.0257568359375
Epoch 35 loss 692.2222900390625
Epoch 36 loss 792.7080078125
Epoch 37 loss 1256.8055419921875
Epoch 38 loss 837.274658203125
Epoch 39 loss 726.471435546875
Epoch 40 loss 807.6747436523438
Epoch 41 loss 834.2180786132812
Epoch 42 loss 610.3248901367188
Epoch 43 loss 739.27685546875
Epoch 44 loss 611.0285034179688
Epoch 45 loss 592.6539916992188
Epoch 46 loss 764.4251098632812
Epoch 47 loss 591.506591796875
Epoch 48 loss 1135.561767578125
Epoch 49 loss 970.6774291992188
Epoch 50 loss 629.73291015625
Epoch 51 loss 629.9424438476562
Epoch 52 loss 537.3096313476562
Epoch 53 loss 822.3027954101562
Epoch 54 loss 542.5372314453125
Epoch 55 loss 704.6387329101562
Epoch 56 loss 1371.51806640625
Epoch 57 loss 642.66455078125
Epoch 58 loss 540.9357299804688
Epoch 59 loss 576.062744140625
Epoch 60 loss 582.7489013671875
Epoch 61 loss 836.545166015625
Epoch 62 loss 650.9522094726562
Epoch 63 loss 598.6832275390625
Epoch 64 loss 505.89410400390625
Epoch 65 loss 563.2894287109375
Epoch 66 loss 521.956298828125
Epoch 67 loss 532.8312377929688
Epoch 68 loss 527.5103759765625
Epoch 69 loss 699.7933959960938
Epoch 70 loss 577.4713134765625
Epoch 71 loss 538.925537109375
Epoch 72 loss 579.0484619140625
Epoch 73 loss 565.61865234375
Epoch 74 loss 620.0924072265625
Epoch 75 loss 838.7749633789062
Epoch 76 loss 538.4725952148438
Epoch 77 loss 647.9741821289062
Epoch 78 loss 827.277587890625
Epoch 79 loss 966.6488647460938
Epoch 80 loss 639.8157348632812
Epoch 81 loss 473.9816589355469
Epoch 82 loss 595.2594604492188
Epoch 83 loss 546.91845703125
Epoch 84 loss 785.4056396484375
Epoch 85 loss 643.6932373046875
Epoch 86 loss 875.1550903320312
Epoch 87 loss 698.8031005859375
Epoch 88 loss 571.8270263671875
Epoch 89 loss 494.7486267089844
Epoch 90 loss 478.6492004394531
Epoch 91 loss 577.4200439453125
Epoch 92 loss 648.8007202148438
Epoch 93 loss 917.158447265625
Epoch 94 loss 575.71875
Epoch 95 loss 556.5797119140625
Epoch 96 loss 526.9813232421875
Epoch 97 loss 458.804443359375
Epoch 98 loss 472.70819091796875
Epoch 99 loss 524.9984130859375
Saved Losses
{'MSE - mean': 524.9500860907816, 'MSE - std': 66.14551641136737, 'R2 - mean': 0.935611765725876, 'R2 - std': 0.004339016739431101} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516583.1875
Epoch 1 loss 514449.625
Epoch 2 loss 510871.9375
Epoch 3 loss 504792.5625
Epoch 4 loss 494106.28125
Epoch 5 loss 474271.8125
Epoch 6 loss 437687.4375
Epoch 7 loss 378070.09375
Epoch 8 loss 293673.90625
Epoch 9 loss 191220.9375
Epoch 10 loss 91815.7890625
Epoch 11 loss 27659.16015625
Epoch 12 loss 9664.79296875
Epoch 13 loss 9748.6796875
Epoch 14 loss 9214.0244140625
Epoch 15 loss 9043.408203125
Epoch 16 loss 8867.0
Epoch 17 loss 8037.705078125
Epoch 18 loss 6273.74658203125
Epoch 19 loss 4494.15283203125
Epoch 20 loss 3204.654296875
Epoch 21 loss 2229.365478515625
Epoch 22 loss 2299.768310546875
Epoch 23 loss 1882.0635986328125
Epoch 24 loss 1517.03271484375
Epoch 25 loss 2144.16943359375
Epoch 26 loss 1489.105712890625
Epoch 27 loss 1782.3682861328125
Epoch 28 loss 1506.4620361328125
Epoch 29 loss 1403.107666015625
Epoch 30 loss 1193.4400634765625
Epoch 31 loss 1238.1295166015625
Epoch 32 loss 1127.69580078125
Epoch 33 loss 1320.8675537109375
Epoch 34 loss 1071.4473876953125
Epoch 35 loss 1411.337890625
Epoch 36 loss 977.5418090820312
Epoch 37 loss 1108.910400390625
Epoch 38 loss 1726.861572265625
Epoch 39 loss 823.5588989257812
Epoch 40 loss 1173.66455078125
Epoch 41 loss 976.8139038085938
Epoch 42 loss 935.8179321289062
Epoch 43 loss 790.8558349609375
Epoch 44 loss 1019.3345947265625
Epoch 45 loss 831.322021484375
Epoch 46 loss 1029.70166015625
Epoch 47 loss 784.3864135742188
Epoch 48 loss 1238.2078857421875
Epoch 49 loss 1127.2796630859375
Epoch 50 loss 777.9641723632812
Epoch 51 loss 675.0557250976562
Epoch 52 loss 990.3369140625
Epoch 53 loss 801.966796875
Epoch 54 loss 999.15087890625
Epoch 55 loss 787.6921997070312
Epoch 56 loss 826.2379150390625
Epoch 57 loss 892.7809448242188
Epoch 58 loss 888.3572998046875
Epoch 59 loss 1147.26318359375
Epoch 60 loss 1147.21142578125
Epoch 61 loss 583.5809326171875
Epoch 62 loss 740.49462890625
Epoch 63 loss 798.6050415039062
Epoch 64 loss 814.826171875
Epoch 65 loss 723.1137084960938
Epoch 66 loss 566.3151245117188
Epoch 67 loss 602.5750732421875
Epoch 68 loss 621.7277221679688
Epoch 69 loss 1084.27783203125
Epoch 70 loss 745.4988403320312
Epoch 71 loss 787.9097900390625
Epoch 72 loss 861.3993530273438
Epoch 73 loss 793.0809326171875
Epoch 74 loss 814.948974609375
Epoch 75 loss 671.9456176757812
Epoch 76 loss 897.3547973632812
Epoch 77 loss 901.40185546875
Epoch 78 loss 820.6172485351562
Epoch 79 loss 955.7246704101562
Epoch 80 loss 748.1266479492188
Epoch 81 loss 584.9265747070312
Epoch 82 loss 656.51953125
Epoch 83 loss 626.4827270507812
Epoch 84 loss 539.5382080078125
Epoch 85 loss 551.69384765625
Epoch 86 loss 579.46240234375
Epoch 87 loss 587.14794921875
Epoch 88 loss 752.952392578125
Epoch 89 loss 758.688232421875
Epoch 90 loss 602.04736328125
Epoch 91 loss 928.4652099609375
Epoch 92 loss 1012.5452270507812
Epoch 93 loss 638.1958618164062
Epoch 94 loss 513.8884887695312
Epoch 95 loss 725.723388671875
Epoch 96 loss 903.8820190429688
Epoch 97 loss 620.71728515625
Epoch 98 loss 580.9116821289062
Epoch 99 loss 605.5377807617188
Saved Losses
{'MSE - mean': 521.2629764761704, 'MSE - std': 54.25872386542676, 'R2 - mean': 0.9386722467991816, 'R2 - std': 0.005593251854705523} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519093.0625
Epoch 1 loss 517120.6875
Epoch 2 loss 513857.6875
Epoch 3 loss 508542.40625
Epoch 4 loss 499759.28125
Epoch 5 loss 483587.28125
Epoch 6 loss 453216.65625
Epoch 7 loss 401989.34375
Epoch 8 loss 326307.6875
Epoch 9 loss 229488.09375
Epoch 10 loss 126917.9609375
Epoch 11 loss 46915.77734375
Epoch 12 loss 12064.7763671875
Epoch 13 loss 8426.9208984375
Epoch 14 loss 8480.775390625
Epoch 15 loss 8199.2158203125
Epoch 16 loss 8117.72021484375
Epoch 17 loss 7930.13818359375
Epoch 18 loss 6987.21435546875
Epoch 19 loss 4929.33642578125
Epoch 20 loss 3079.987060546875
Epoch 21 loss 2721.689453125
Epoch 22 loss 2191.537109375
Epoch 23 loss 2787.100830078125
Epoch 24 loss 1730.1033935546875
Epoch 25 loss 1920.431640625
Epoch 26 loss 1677.8388671875
Epoch 27 loss 1474.11376953125
Epoch 28 loss 2087.189208984375
Epoch 29 loss 1419.0037841796875
Epoch 30 loss 1494.5025634765625
Epoch 31 loss 1681.3828125
Epoch 32 loss 2109.966064453125
Epoch 33 loss 1197.599609375
Epoch 34 loss 1323.6407470703125
Epoch 35 loss 1395.4530029296875
Epoch 36 loss 1152.66845703125
Epoch 37 loss 1088.9154052734375
Epoch 38 loss 1565.136962890625
Epoch 39 loss 1313.1602783203125
Epoch 40 loss 1274.0726318359375
Epoch 41 loss 930.5929565429688
Epoch 42 loss 873.3480224609375
Epoch 43 loss 917.4497680664062
Epoch 44 loss 960.347412109375
Epoch 45 loss 995.2669067382812
Epoch 46 loss 1004.3937377929688
Epoch 47 loss 989.9038696289062
Epoch 48 loss 1146.015380859375
Epoch 49 loss 1550.1378173828125
Epoch 50 loss 1485.2513427734375
Epoch 51 loss 1128.5233154296875
Epoch 52 loss 774.822998046875
Epoch 53 loss 836.4987182617188
Epoch 54 loss 896.4479370117188
Epoch 55 loss 870.2449951171875
Epoch 56 loss 1014.3765258789062
Epoch 57 loss 1092.4344482421875
Epoch 58 loss 986.5123901367188
Epoch 59 loss 833.1868896484375
Epoch 60 loss 954.3897094726562
Epoch 61 loss 707.3564453125
Epoch 62 loss 1110.513427734375
Epoch 63 loss 953.452392578125
Epoch 64 loss 907.447509765625
Epoch 65 loss 695.1427612304688
Epoch 66 loss 690.4265747070312
Epoch 67 loss 684.4277954101562
Epoch 68 loss 684.0421142578125
Epoch 69 loss 802.9080810546875
Epoch 70 loss 718.9928588867188
Epoch 71 loss 664.895263671875
Epoch 72 loss 657.8777465820312
Epoch 73 loss 706.9953002929688
Epoch 74 loss 671.9852294921875
Epoch 75 loss 915.1642456054688
Epoch 76 loss 744.1641235351562
Epoch 77 loss 752.2846069335938
Epoch 78 loss 852.0277709960938
Epoch 79 loss 889.9322509765625
Epoch 80 loss 869.4216918945312
Epoch 81 loss 796.0906372070312
Epoch 82 loss 1094.1026611328125
Epoch 83 loss 842.437744140625
Epoch 84 loss 713.84375
Epoch 85 loss 915.7133178710938
Epoch 86 loss 1224.0816650390625
Epoch 87 loss 1020.58642578125
Epoch 88 loss 939.7786865234375
Epoch 89 loss 816.7874145507812
Epoch 90 loss 697.7978515625
Epoch 91 loss 771.158203125
Epoch 92 loss 1275.3441162109375
Epoch 93 loss 1674.0421142578125
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 555.4166670377276, 'MSE - std': 75.54753850094848, 'R2 - mean': 0.9342017482569203, 'R2 - std': 0.009133423311207402} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515586.96875
Epoch 1 loss 513094.5625
Epoch 2 loss 509363.6875
Epoch 3 loss 503146.53125
Epoch 4 loss 492274.71875
Epoch 5 loss 472385.4375
Epoch 6 loss 436915.03125
Epoch 7 loss 379888.5625
Epoch 8 loss 298839.5625
Epoch 9 loss 199780.421875
Epoch 10 loss 101673.375
Epoch 11 loss 32905.50390625
Epoch 12 loss 9357.9990234375
Epoch 13 loss 8255.8896484375
Epoch 14 loss 8048.3291015625
Epoch 15 loss 7780.26708984375
Epoch 16 loss 7652.0810546875
Epoch 17 loss 7110.0673828125
Epoch 18 loss 5478.46630859375
Epoch 19 loss 3542.880126953125
Epoch 20 loss 2134.162841796875
Epoch 21 loss 2015.6131591796875
Epoch 22 loss 1625.0411376953125
Epoch 23 loss 2603.157958984375
Epoch 24 loss 1180.2100830078125
Epoch 25 loss 1822.9083251953125
Epoch 26 loss 1219.587646484375
Epoch 27 loss 1126.1195068359375
Epoch 28 loss 1135.3985595703125
Epoch 29 loss 852.7246704101562
Epoch 30 loss 1128.331298828125
Epoch 31 loss 851.2085571289062
Epoch 32 loss 1027.575927734375
Epoch 33 loss 1154.976806640625
Epoch 34 loss 757.4808349609375
Epoch 35 loss 1045.9774169921875
Epoch 36 loss 967.3305053710938
Epoch 37 loss 829.6921997070312
Epoch 38 loss 793.904541015625
Epoch 39 loss 800.9913940429688
Epoch 40 loss 723.6768188476562
Epoch 41 loss 779.8599243164062
Epoch 42 loss 860.029541015625
Epoch 43 loss 850.5868530273438
Epoch 44 loss 833.4120483398438
Epoch 45 loss 808.7155151367188
Epoch 46 loss 872.7742309570312
Epoch 47 loss 665.2691040039062
Epoch 48 loss 622.4042358398438
Epoch 49 loss 689.1314697265625
Epoch 50 loss 720.3211059570312
Epoch 51 loss 565.172119140625
Epoch 52 loss 699.8673706054688
Epoch 53 loss 557.7299194335938
Epoch 54 loss 594.7784423828125
Epoch 55 loss 616.2721557617188
Epoch 56 loss 671.4968872070312
Epoch 57 loss 554.8695678710938
Epoch 58 loss 576.7703247070312
Epoch 59 loss 653.7339477539062
Epoch 60 loss 642.6630859375
Epoch 61 loss 638.9365234375
Epoch 62 loss 578.38720703125
Epoch 63 loss 532.463623046875
Epoch 64 loss 538.2916259765625
Epoch 65 loss 565.045166015625
Epoch 66 loss 559.0413818359375
Epoch 67 loss 535.0572509765625
Epoch 68 loss 553.3009643554688
Epoch 69 loss 538.6245727539062
Epoch 70 loss 520.5601806640625
Epoch 71 loss 861.229736328125
Epoch 72 loss 544.9599609375
Epoch 73 loss 640.7390747070312
Epoch 74 loss 596.0388793945312
Epoch 75 loss 587.8006591796875
Epoch 76 loss 622.4898681640625
Epoch 77 loss 513.178466796875
Epoch 78 loss 511.02313232421875
Epoch 79 loss 611.6548461914062
Epoch 80 loss 602.354248046875
Epoch 81 loss 573.22314453125
Epoch 82 loss 530.5831909179688
Epoch 83 loss 582.7459106445312
Epoch 84 loss 1089.4051513671875
Epoch 85 loss 685.4592895507812
Epoch 86 loss 763.802734375
Epoch 87 loss 656.0037841796875
Epoch 88 loss 473.8470458984375
Epoch 89 loss 479.6126708984375
Epoch 90 loss 684.4913330078125
Epoch 91 loss 474.8792419433594
Epoch 92 loss 481.03778076171875
Epoch 93 loss 580.1409912109375
Epoch 94 loss 708.9506225585938
Epoch 95 loss 585.8148803710938
Epoch 96 loss 651.762939453125
Epoch 97 loss 539.1751708984375
Epoch 98 loss 516.6813354492188
Epoch 99 loss 718.9963989257812
Saved Losses
{'MSE - mean': 539.1026828777051, 'MSE - std': 75.0368494510243, 'R2 - mean': 0.9354826188557942, 'R2 - std': 0.008561428331160834} 
 

Results After CV: {'MSE - mean': 539.1026828777051, 'MSE - std': 75.0368494510243, 'R2 - mean': 0.9354826188557942, 'R2 - std': 0.008561428331160834}
Train time: 101.03642008100033
Inference time: 0.14175278559996513
Finished cross validation
Trial 13 finished with value: 539.1026828777051 and parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'dropout': 0.7}. Best is trial 12 with value: 482.5660834789284.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516153.40625
Epoch 1 loss 515090.40625
Epoch 2 loss 512671.3125
Epoch 3 loss 507496.25
Epoch 4 loss 497268.9375
Epoch 5 loss 478013.03125
Epoch 6 loss 442942.0
Epoch 7 loss 385150.125
Epoch 8 loss 301781.5
Epoch 9 loss 198969.890625
Epoch 10 loss 97557.8984375
Epoch 11 loss 29720.28125
Epoch 12 loss 9145.068359375
Epoch 13 loss 8783.5625
Epoch 14 loss 8192.15625
Epoch 15 loss 7857.6357421875
Epoch 16 loss 7468.87548828125
Epoch 17 loss 6924.779296875
Epoch 18 loss 6230.11572265625
Epoch 19 loss 5411.0185546875
Epoch 20 loss 4496.29052734375
Epoch 21 loss 3632.4052734375
Epoch 22 loss 2700.920654296875
Epoch 23 loss 2141.554443359375
Epoch 24 loss 1855.5294189453125
Epoch 25 loss 1660.90185546875
Epoch 26 loss 1566.685302734375
Epoch 27 loss 1455.3828125
Epoch 28 loss 1387.78369140625
Epoch 29 loss 1330.7479248046875
Epoch 30 loss 1344.34033203125
Epoch 31 loss 1279.7869873046875
Epoch 32 loss 1186.817138671875
Epoch 33 loss 1157.417236328125
Epoch 34 loss 1137.121337890625
Epoch 35 loss 1089.9752197265625
Epoch 36 loss 1093.7396240234375
Epoch 37 loss 1037.9744873046875
Epoch 38 loss 1021.0523071289062
Epoch 39 loss 981.2568359375
Epoch 40 loss 983.3673095703125
Epoch 41 loss 940.5772705078125
Epoch 42 loss 926.618408203125
Epoch 43 loss 897.4588012695312
Epoch 44 loss 912.8048095703125
Epoch 45 loss 896.4901123046875
Epoch 46 loss 855.0338745117188
Epoch 47 loss 846.870849609375
Epoch 48 loss 852.3833618164062
Epoch 49 loss 876.8634643554688
Epoch 50 loss 797.5331420898438
Epoch 51 loss 796.3726806640625
Epoch 52 loss 787.274169921875
Epoch 53 loss 791.8063354492188
Epoch 54 loss 785.4182739257812
Epoch 55 loss 886.055908203125
Epoch 56 loss 795.6159057617188
Epoch 57 loss 754.81982421875
Epoch 58 loss 741.4814453125
Epoch 59 loss 760.5850219726562
Epoch 60 loss 940.8673706054688
Epoch 61 loss 732.2957153320312
Epoch 62 loss 737.1032104492188
Epoch 63 loss 728.0032348632812
Epoch 64 loss 722.041015625
Epoch 65 loss 810.8057250976562
Epoch 66 loss 738.5731811523438
Epoch 67 loss 689.6854858398438
Epoch 68 loss 712.13427734375
Epoch 69 loss 822.7202758789062
Epoch 70 loss 683.7059936523438
Epoch 71 loss 694.3630981445312
Epoch 72 loss 684.3359375
Epoch 73 loss 677.9382934570312
Epoch 74 loss 795.1538696289062
Epoch 75 loss 670.7061157226562
Epoch 76 loss 676.8081665039062
Epoch 77 loss 691.256591796875
Epoch 78 loss 691.8282470703125
Epoch 79 loss 671.1405639648438
Epoch 80 loss 658.898193359375
Epoch 81 loss 651.215576171875
Epoch 82 loss 686.4027099609375
Epoch 83 loss 683.8817138671875
Epoch 84 loss 692.3963623046875
Epoch 85 loss 659.3118896484375
Epoch 86 loss 753.3972778320312
Epoch 87 loss 666.6834106445312
Epoch 88 loss 647.4900512695312
Epoch 89 loss 639.701171875
Epoch 90 loss 643.5668334960938
Epoch 91 loss 629.9661865234375
Epoch 92 loss 629.0641479492188
Epoch 93 loss 685.1605834960938
Epoch 94 loss 621.715576171875
Epoch 95 loss 636.9108276367188
Epoch 96 loss 619.0016479492188
Epoch 97 loss 617.0426635742188
Epoch 98 loss 646.92431640625
Epoch 99 loss 691.8402099609375
Saved Losses
{'MSE - mean': 617.0428850929505, 'MSE - std': 0.0, 'R2 - mean': 0.9282558336242108, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 524064.1875
Epoch 1 loss 522498.65625
Epoch 2 loss 519388.09375
Epoch 3 loss 513123.34375
Epoch 4 loss 501632.875
Epoch 5 loss 481000.21875
Epoch 6 loss 444804.09375
Epoch 7 loss 386816.0625
Epoch 8 loss 304640.96875
Epoch 9 loss 204652.21875
Epoch 10 loss 104831.015625
Epoch 11 loss 34396.71484375
Epoch 12 loss 9394.765625
Epoch 13 loss 7494.92626953125
Epoch 14 loss 7113.1083984375
Epoch 15 loss 6968.01318359375
Epoch 16 loss 6573.7392578125
Epoch 17 loss 6145.3427734375
Epoch 18 loss 5564.193359375
Epoch 19 loss 4849.47802734375
Epoch 20 loss 4030.0166015625
Epoch 21 loss 3110.2177734375
Epoch 22 loss 2312.700439453125
Epoch 23 loss 1705.512939453125
Epoch 24 loss 1465.61865234375
Epoch 25 loss 1325.0013427734375
Epoch 26 loss 1243.6627197265625
Epoch 27 loss 1182.3902587890625
Epoch 28 loss 1159.9901123046875
Epoch 29 loss 1074.8028564453125
Epoch 30 loss 1026.680419921875
Epoch 31 loss 990.587646484375
Epoch 32 loss 985.9591674804688
Epoch 33 loss 954.4122314453125
Epoch 34 loss 939.7005615234375
Epoch 35 loss 926.8516845703125
Epoch 36 loss 910.0438232421875
Epoch 37 loss 814.3238525390625
Epoch 38 loss 793.080322265625
Epoch 39 loss 755.76318359375
Epoch 40 loss 749.33203125
Epoch 41 loss 733.6994018554688
Epoch 42 loss 755.5140991210938
Epoch 43 loss 684.513671875
Epoch 44 loss 709.5672607421875
Epoch 45 loss 671.3507080078125
Epoch 46 loss 638.17724609375
Epoch 47 loss 736.5215454101562
Epoch 48 loss 988.148193359375
Epoch 49 loss 612.1637573242188
Epoch 50 loss 604.6412963867188
Epoch 51 loss 595.191650390625
Epoch 52 loss 595.8355712890625
Epoch 53 loss 625.0784301757812
Epoch 54 loss 615.6279296875
Epoch 55 loss 608.8460693359375
Epoch 56 loss 554.3958740234375
Epoch 57 loss 624.5322265625
Epoch 58 loss 569.02587890625
Epoch 59 loss 531.6591796875
Epoch 60 loss 536.3157348632812
Epoch 61 loss 584.3110961914062
Epoch 62 loss 515.8594360351562
Epoch 63 loss 509.20220947265625
Epoch 64 loss 565.8284301757812
Epoch 65 loss 518.8406372070312
Epoch 66 loss 574.735595703125
Epoch 67 loss 505.58673095703125
Epoch 68 loss 511.928466796875
Epoch 69 loss 503.0901184082031
Epoch 70 loss 496.3702697753906
Epoch 71 loss 526.4232788085938
Epoch 72 loss 514.11474609375
Epoch 73 loss 528.54541015625
Epoch 74 loss 557.2514038085938
Epoch 75 loss 510.99151611328125
Epoch 76 loss 555.1227416992188
Epoch 77 loss 489.16455078125
Epoch 78 loss 484.3924865722656
Epoch 79 loss 515.7274169921875
Epoch 80 loss 598.9082641601562
Epoch 81 loss 523.392333984375
Epoch 82 loss 503.5662536621094
Epoch 83 loss 483.1270446777344
Epoch 84 loss 482.26806640625
Epoch 85 loss 531.2205200195312
Epoch 86 loss 543.9052734375
Epoch 87 loss 484.2474060058594
Epoch 88 loss 491.0984802246094
Epoch 89 loss 489.63604736328125
Epoch 90 loss 532.6118774414062
Epoch 91 loss 486.87481689453125
Epoch 92 loss 476.56231689453125
Epoch 93 loss 609.74853515625
Epoch 94 loss 480.40106201171875
Epoch 95 loss 488.9815979003906
Epoch 96 loss 480.3900146484375
Epoch 97 loss 480.5924987792969
Epoch 98 loss 477.6375427246094
Epoch 99 loss 480.0476989746094
Saved Losses
{'MSE - mean': 546.8024619204117, 'MSE - std': 70.24042317253887, 'R2 - mean': 0.9329412423272111, 'R2 - std': 0.004685408703000271} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516190.53125
Epoch 1 loss 513323.40625
Epoch 2 loss 508347.65625
Epoch 3 loss 499550.75
Epoch 4 loss 484462.5625
Epoch 5 loss 457582.25
Epoch 6 loss 410960.75
Epoch 7 loss 339851.53125
Epoch 8 loss 245860.4375
Epoch 9 loss 142184.9375
Epoch 10 loss 56346.55078125
Epoch 11 loss 14959.4345703125
Epoch 12 loss 9266.4833984375
Epoch 13 loss 9271.708984375
Epoch 14 loss 8756.2412109375
Epoch 15 loss 8426.48046875
Epoch 16 loss 7941.7314453125
Epoch 17 loss 7279.11572265625
Epoch 18 loss 6416.4892578125
Epoch 19 loss 5393.4833984375
Epoch 20 loss 4346.23876953125
Epoch 21 loss 3334.508544921875
Epoch 22 loss 2611.685302734375
Epoch 23 loss 2121.614501953125
Epoch 24 loss 1862.1217041015625
Epoch 25 loss 1709.8629150390625
Epoch 26 loss 1595.970947265625
Epoch 27 loss 1503.2491455078125
Epoch 28 loss 1457.6671142578125
Epoch 29 loss 1403.774169921875
Epoch 30 loss 1353.449462890625
Epoch 31 loss 1356.821044921875
Epoch 32 loss 1313.4051513671875
Epoch 33 loss 1324.67138671875
Epoch 34 loss 1229.644287109375
Epoch 35 loss 1155.6790771484375
Epoch 36 loss 1171.808349609375
Epoch 37 loss 1111.37548828125
Epoch 38 loss 1086.153564453125
Epoch 39 loss 1062.48291015625
Epoch 40 loss 1029.8829345703125
Epoch 41 loss 992.1979370117188
Epoch 42 loss 964.6605224609375
Epoch 43 loss 980.1103515625
Epoch 44 loss 908.3773193359375
Epoch 45 loss 997.9779663085938
Epoch 46 loss 875.5350341796875
Epoch 47 loss 859.0718383789062
Epoch 48 loss 923.656982421875
Epoch 49 loss 931.556640625
Epoch 50 loss 832.1806640625
Epoch 51 loss 771.7161865234375
Epoch 52 loss 831.297119140625
Epoch 53 loss 739.1929321289062
Epoch 54 loss 725.5109252929688
Epoch 55 loss 711.453857421875
Epoch 56 loss 882.9866333007812
Epoch 57 loss 694.0068359375
Epoch 58 loss 673.86669921875
Epoch 59 loss 707.7305297851562
Epoch 60 loss 687.5243530273438
Epoch 61 loss 635.4523315429688
Epoch 62 loss 667.4151000976562
Epoch 63 loss 626.4854125976562
Epoch 64 loss 607.4801635742188
Epoch 65 loss 660.5878295898438
Epoch 66 loss 635.5372314453125
Epoch 67 loss 673.1228637695312
Epoch 68 loss 731.7185668945312
Epoch 69 loss 581.9025268554688
Epoch 70 loss 572.00634765625
Epoch 71 loss 781.431884765625
Epoch 72 loss 636.0337524414062
Epoch 73 loss 576.404541015625
Epoch 74 loss 594.3025512695312
Epoch 75 loss 559.214111328125
Epoch 76 loss 564.8072509765625
Epoch 77 loss 663.5267944335938
Epoch 78 loss 594.4580688476562
Epoch 79 loss 540.0056762695312
Epoch 80 loss 532.0523681640625
Epoch 81 loss 550.3757934570312
Epoch 82 loss 528.9325561523438
Epoch 83 loss 645.181884765625
Epoch 84 loss 516.2046508789062
Epoch 85 loss 535.0573120117188
Epoch 86 loss 511.8979187011719
Epoch 87 loss 560.0708618164062
Epoch 88 loss 515.232666015625
Epoch 89 loss 511.42230224609375
Epoch 90 loss 536.4385986328125
Epoch 91 loss 516.62548828125
Epoch 92 loss 536.7549438476562
Epoch 93 loss 684.7557983398438
Epoch 94 loss 498.4882507324219
Epoch 95 loss 521.0936279296875
Epoch 96 loss 566.3070068359375
Epoch 97 loss 549.2141723632812
Epoch 98 loss 497.2290954589844
Epoch 99 loss 532.3497924804688
Saved Losses
{'MSE - mean': 530.2780125757732, 'MSE - std': 61.9294723907118, 'R2 - mean': 0.9374884766898578, 'R2 - std': 0.007482649965560621} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520718.875
Epoch 1 loss 520018.125
Epoch 2 loss 518364.40625
Epoch 3 loss 514549.71875
Epoch 4 loss 506676.78125
Epoch 5 loss 491782.65625
Epoch 6 loss 464647.75
Epoch 7 loss 417742.28125
Epoch 8 loss 345814.40625
Epoch 9 loss 249484.1875
Epoch 10 loss 142649.1875
Epoch 11 loss 54769.76953125
Epoch 12 loss 13337.9091796875
Epoch 13 loss 8250.5400390625
Epoch 14 loss 8068.76123046875
Epoch 15 loss 7719.1494140625
Epoch 16 loss 7364.369140625
Epoch 17 loss 6938.33056640625
Epoch 18 loss 6391.4580078125
Epoch 19 loss 5709.99609375
Epoch 20 loss 4923.474609375
Epoch 21 loss 4050.783935546875
Epoch 22 loss 3253.0419921875
Epoch 23 loss 2472.146728515625
Epoch 24 loss 2003.9312744140625
Epoch 25 loss 1772.7786865234375
Epoch 26 loss 1600.3175048828125
Epoch 27 loss 1546.109375
Epoch 28 loss 1516.7550048828125
Epoch 29 loss 1415.6131591796875
Epoch 30 loss 1319.73193359375
Epoch 31 loss 1370.006103515625
Epoch 32 loss 1242.1280517578125
Epoch 33 loss 1258.219970703125
Epoch 34 loss 1276.2796630859375
Epoch 35 loss 1132.5150146484375
Epoch 36 loss 1146.1475830078125
Epoch 37 loss 1114.5064697265625
Epoch 38 loss 1089.051513671875
Epoch 39 loss 1014.1051025390625
Epoch 40 loss 1072.8489990234375
Epoch 41 loss 977.9651489257812
Epoch 42 loss 986.0997924804688
Epoch 43 loss 1063.0582275390625
Epoch 44 loss 891.1588134765625
Epoch 45 loss 895.7733764648438
Epoch 46 loss 889.4098510742188
Epoch 47 loss 864.3052978515625
Epoch 48 loss 851.9306030273438
Epoch 49 loss 800.4203491210938
Epoch 50 loss 821.52880859375
Epoch 51 loss 790.4277954101562
Epoch 52 loss 757.9782104492188
Epoch 53 loss 740.4899291992188
Epoch 54 loss 812.2066040039062
Epoch 55 loss 730.621826171875
Epoch 56 loss 762.0105590820312
Epoch 57 loss 779.2754516601562
Epoch 58 loss 699.3547973632812
Epoch 59 loss 701.1233520507812
Epoch 60 loss 670.4759521484375
Epoch 61 loss 813.863037109375
Epoch 62 loss 772.230712890625
Epoch 63 loss 730.5536499023438
Epoch 64 loss 709.8184204101562
Epoch 65 loss 644.2406005859375
Epoch 66 loss 708.955078125
Epoch 67 loss 641.090576171875
Epoch 68 loss 875.67822265625
Epoch 69 loss 672.1959838867188
Epoch 70 loss 837.7572021484375
Epoch 71 loss 600.9376220703125
Epoch 72 loss 697.8316650390625
Epoch 73 loss 643.81591796875
Epoch 74 loss 718.216552734375
Epoch 75 loss 678.0150146484375
Epoch 76 loss 619.2781982421875
Epoch 77 loss 578.9693603515625
Epoch 78 loss 593.0889282226562
Epoch 79 loss 654.1516723632812
Epoch 80 loss 644.1905517578125
Epoch 81 loss 638.652587890625
Epoch 82 loss 569.1619262695312
Epoch 83 loss 639.5116577148438
Epoch 84 loss 677.9627075195312
Epoch 85 loss 574.3527221679688
Epoch 86 loss 612.8541870117188
Epoch 87 loss 547.8206176757812
Epoch 88 loss 585.66162109375
Epoch 89 loss 667.5861206054688
Epoch 90 loss 543.0238037109375
Epoch 91 loss 652.5840454101562
Epoch 92 loss 647.5266723632812
Epoch 93 loss 543.7578735351562
Epoch 94 loss 819.8973388671875
Epoch 95 loss 576.7979736328125
Epoch 96 loss 549.44091796875
Epoch 97 loss 536.9957275390625
Epoch 98 loss 533.7352294921875
Epoch 99 loss 543.7948608398438
Saved Losses
{'MSE - mean': 531.1422262576273, 'MSE - std': 53.65338068386429, 'R2 - mean': 0.9370506809056283, 'R2 - std': 0.006524379918919168} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517096.78125
Epoch 1 loss 515694.75
Epoch 2 loss 512897.03125
Epoch 3 loss 507335.40625
Epoch 4 loss 497066.09375
Epoch 5 loss 478771.65625
Epoch 6 loss 446106.90625
Epoch 7 loss 392804.65625
Epoch 8 loss 315773.84375
Epoch 9 loss 218831.609375
Epoch 10 loss 118001.3125
Epoch 11 loss 41492.21484375
Epoch 12 loss 10698.5869140625
Epoch 13 loss 8095.8779296875
Epoch 14 loss 7905.64599609375
Epoch 15 loss 7589.53955078125
Epoch 16 loss 7227.5048828125
Epoch 17 loss 6707.60205078125
Epoch 18 loss 6003.236328125
Epoch 19 loss 5148.150390625
Epoch 20 loss 4183.00537109375
Epoch 21 loss 3188.73388671875
Epoch 22 loss 2357.37158203125
Epoch 23 loss 1795.25732421875
Epoch 24 loss 1505.417236328125
Epoch 25 loss 1359.9217529296875
Epoch 26 loss 1267.700927734375
Epoch 27 loss 1189.794189453125
Epoch 28 loss 1171.890869140625
Epoch 29 loss 1087.9459228515625
Epoch 30 loss 1007.3863525390625
Epoch 31 loss 987.146484375
Epoch 32 loss 940.4458618164062
Epoch 33 loss 947.7726440429688
Epoch 34 loss 882.2176513671875
Epoch 35 loss 846.0491333007812
Epoch 36 loss 964.6178588867188
Epoch 37 loss 814.4443969726562
Epoch 38 loss 806.1260375976562
Epoch 39 loss 771.3235473632812
Epoch 40 loss 756.1842041015625
Epoch 41 loss 738.8739624023438
Epoch 42 loss 731.2872924804688
Epoch 43 loss 736.5855102539062
Epoch 44 loss 728.8619995117188
Epoch 45 loss 686.935546875
Epoch 46 loss 785.0423583984375
Epoch 47 loss 730.154296875
Epoch 48 loss 711.6259155273438
Epoch 49 loss 650.83740234375
Epoch 50 loss 667.0459594726562
Epoch 51 loss 638.1918334960938
Epoch 52 loss 701.1605224609375
Epoch 53 loss 659.8914794921875
Epoch 54 loss 620.6459350585938
Epoch 55 loss 620.4089965820312
Epoch 56 loss 601.0617065429688
Epoch 57 loss 612.2721557617188
Epoch 58 loss 601.6110229492188
Epoch 59 loss 605.5370483398438
Epoch 60 loss 599.9307250976562
Epoch 61 loss 574.9495239257812
Epoch 62 loss 585.813232421875
Epoch 63 loss 638.9711303710938
Epoch 64 loss 577.6310424804688
Epoch 65 loss 563.5537109375
Epoch 66 loss 554.4796752929688
Epoch 67 loss 596.8492431640625
Epoch 68 loss 643.1301879882812
Epoch 69 loss 576.529541015625
Epoch 70 loss 537.7398681640625
Epoch 71 loss 601.745361328125
Epoch 72 loss 551.0576782226562
Epoch 73 loss 523.3612060546875
Epoch 74 loss 588.8123168945312
Epoch 75 loss 527.3833618164062
Epoch 76 loss 519.1808471679688
Epoch 77 loss 512.7938232421875
Epoch 78 loss 511.7835388183594
Epoch 79 loss 617.501220703125
Epoch 80 loss 505.3649597167969
Epoch 81 loss 508.3699645996094
Epoch 82 loss 515.7029418945312
Epoch 83 loss 530.2877197265625
Epoch 84 loss 516.772216796875
Epoch 85 loss 575.6860961914062
Epoch 86 loss 545.190185546875
Epoch 87 loss 541.8760986328125
Epoch 88 loss 492.7012634277344
Epoch 89 loss 557.869140625
Epoch 90 loss 532.8287353515625
Epoch 91 loss 518.6488647460938
Epoch 92 loss 498.7774963378906
Epoch 93 loss 523.2608032226562
Epoch 94 loss 507.23541259765625
Epoch 95 loss 489.86431884765625
Epoch 96 loss 483.5578918457031
Epoch 97 loss 485.4761657714844
Epoch 98 loss 482.6881103515625
Epoch 99 loss 480.6624450683594
Saved Losses
{'MSE - mean': 521.0462659979503, 'MSE - std': 52.06401695322823, 'R2 - mean': 0.9375909039378915, 'R2 - std': 0.005934761188073787} 
 

Results After CV: {'MSE - mean': 521.0462659979503, 'MSE - std': 52.06401695322823, 'R2 - mean': 0.9375909039378915, 'R2 - std': 0.005934761188073787}
Train time: 86.91857471700004
Inference time: 0.13528485800015916
Finished cross validation
Trial 14 finished with value: 521.0462659979503 and parameters: {'dim': 256, 'depth': 1, 'heads': 4, 'dropout': 0.3}. Best is trial 12 with value: 482.5660834789284.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515666.46875
Epoch 1 loss 514210.09375
Epoch 2 loss 511519.75
Epoch 3 loss 506460.0
Epoch 4 loss 497023.6875
Epoch 5 loss 479546.625
Epoch 6 loss 447614.3125
Epoch 7 loss 394892.84375
Epoch 8 loss 318115.25
Epoch 9 loss 220975.328125
Epoch 10 loss 119635.03125
Epoch 11 loss 42444.72265625
Epoch 12 loss 11334.7978515625
Epoch 13 loss 8790.279296875
Epoch 14 loss 8591.8955078125
Epoch 15 loss 8197.7958984375
Epoch 16 loss 7653.56787109375
Epoch 17 loss 5190.70751953125
Epoch 18 loss 2778.463623046875
Epoch 19 loss 2374.979736328125
Epoch 20 loss 1990.701171875
Epoch 21 loss 1632.5235595703125
Epoch 22 loss 1545.213623046875
Epoch 23 loss 1349.5391845703125
Epoch 24 loss 1425.5220947265625
Epoch 25 loss 1150.243408203125
Epoch 26 loss 1075.89208984375
Epoch 27 loss 1077.54248046875
Epoch 28 loss 993.6358032226562
Epoch 29 loss 1202.1558837890625
Epoch 30 loss 981.6435546875
Epoch 31 loss 1028.9029541015625
Epoch 32 loss 895.934326171875
Epoch 33 loss 964.9093017578125
Epoch 34 loss 901.3372192382812
Epoch 35 loss 862.68212890625
Epoch 36 loss 841.15576171875
Epoch 37 loss 878.3594360351562
Epoch 38 loss 989.6783447265625
Epoch 39 loss 775.35791015625
Epoch 40 loss 828.7481689453125
Epoch 41 loss 755.898193359375
Epoch 42 loss 793.90869140625
Epoch 43 loss 736.2828979492188
Epoch 44 loss 724.8021240234375
Epoch 45 loss 696.4148559570312
Epoch 46 loss 779.4695434570312
Epoch 47 loss 718.5733642578125
Epoch 48 loss 726.2003173828125
Epoch 49 loss 686.9108276367188
Epoch 50 loss 778.400146484375
Epoch 51 loss 656.8588256835938
Epoch 52 loss 783.2479858398438
Epoch 53 loss 646.9391479492188
Epoch 54 loss 725.4450073242188
Epoch 55 loss 745.826904296875
Epoch 56 loss 644.903076171875
Epoch 57 loss 672.9414672851562
Epoch 58 loss 630.6016845703125
Epoch 59 loss 636.7892456054688
Epoch 60 loss 663.1292114257812
Epoch 61 loss 652.7877197265625
Epoch 62 loss 673.7090454101562
Epoch 63 loss 623.3731079101562
Epoch 64 loss 615.0134887695312
Epoch 65 loss 681.7341918945312
Epoch 66 loss 639.6514282226562
Epoch 67 loss 642.7892456054688
Epoch 68 loss 619.0377197265625
Epoch 69 loss 619.1740112304688
Epoch 70 loss 604.306640625
Epoch 71 loss 697.220458984375
Epoch 72 loss 607.5933227539062
Epoch 73 loss 632.6442260742188
Epoch 74 loss 631.6307373046875
Epoch 75 loss 611.9251098632812
Epoch 76 loss 684.8036499023438
Epoch 77 loss 613.1583862304688
Epoch 78 loss 603.523681640625
Epoch 79 loss 627.42138671875
Epoch 80 loss 619.9239501953125
Epoch 81 loss 634.7477416992188
Epoch 82 loss 609.1016235351562
Epoch 83 loss 778.9562377929688
Epoch 84 loss 608.8978881835938
Epoch 85 loss 611.7491455078125
Epoch 86 loss 695.4216918945312
Epoch 87 loss 612.4784545898438
Epoch 88 loss 643.7963256835938
Epoch 89 loss 616.8965454101562
Epoch 90 loss 581.9800415039062
Epoch 91 loss 636.2184448242188
Epoch 92 loss 586.3680419921875
Epoch 93 loss 570.5597534179688
Epoch 94 loss 614.1563720703125
Epoch 95 loss 589.7913818359375
Epoch 96 loss 632.2169189453125
Epoch 97 loss 603.0308837890625
Epoch 98 loss 592.2781982421875
Epoch 99 loss 615.77685546875
Saved Losses
{'MSE - mean': 570.559758773609, 'MSE - std': 0.0, 'R2 - mean': 0.9336604711767844, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522847.28125
Epoch 1 loss 520030.96875
Epoch 2 loss 515635.21875
Epoch 3 loss 508226.34375
Epoch 4 loss 495231.3125
Epoch 5 loss 471723.8125
Epoch 6 loss 430339.0625
Epoch 7 loss 365653.78125
Epoch 8 loss 276925.09375
Epoch 9 loss 173813.1875
Epoch 10 loss 79039.65625
Epoch 11 loss 21947.818359375
Epoch 12 loss 7853.45751953125
Epoch 13 loss 7722.86962890625
Epoch 14 loss 7549.4296875
Epoch 15 loss 7256.41552734375
Epoch 16 loss 6767.9072265625
Epoch 17 loss 4976.09521484375
Epoch 18 loss 3355.234619140625
Epoch 19 loss 2307.15380859375
Epoch 20 loss 1941.942626953125
Epoch 21 loss 1649.3082275390625
Epoch 22 loss 1376.257080078125
Epoch 23 loss 1195.2164306640625
Epoch 24 loss 1170.58349609375
Epoch 25 loss 1040.13134765625
Epoch 26 loss 963.7220458984375
Epoch 27 loss 1210.2584228515625
Epoch 28 loss 969.6168212890625
Epoch 29 loss 851.2874145507812
Epoch 30 loss 1132.1746826171875
Epoch 31 loss 792.2404174804688
Epoch 32 loss 976.18017578125
Epoch 33 loss 715.541748046875
Epoch 34 loss 782.6024780273438
Epoch 35 loss 679.5050659179688
Epoch 36 loss 913.8547973632812
Epoch 37 loss 625.96875
Epoch 38 loss 863.2831420898438
Epoch 39 loss 620.690673828125
Epoch 40 loss 660.6057739257812
Epoch 41 loss 575.30859375
Epoch 42 loss 674.4660034179688
Epoch 43 loss 547.145751953125
Epoch 44 loss 541.4481811523438
Epoch 45 loss 719.4165649414062
Epoch 46 loss 541.1964721679688
Epoch 47 loss 635.48095703125
Epoch 48 loss 747.7453002929688
Epoch 49 loss 515.8033447265625
Epoch 50 loss 659.2100219726562
Epoch 51 loss 503.5472412109375
Epoch 52 loss 542.9458618164062
Epoch 53 loss 700.1480712890625
Epoch 54 loss 490.951416015625
Epoch 55 loss 703.030029296875
Epoch 56 loss 525.2432250976562
Epoch 57 loss 695.3203735351562
Epoch 58 loss 500.1622009277344
Epoch 59 loss 605.4253540039062
Epoch 60 loss 491.9949951171875
Epoch 61 loss 482.9120178222656
Epoch 62 loss 560.6690673828125
Epoch 63 loss 480.6687927246094
Epoch 64 loss 533.1185913085938
Epoch 65 loss 492.58233642578125
Epoch 66 loss 471.3976135253906
Epoch 67 loss 563.5650634765625
Epoch 68 loss 459.3202819824219
Epoch 69 loss 559.4801635742188
Epoch 70 loss 465.4064025878906
Epoch 71 loss 534.4473876953125
Epoch 72 loss 493.1818542480469
Epoch 73 loss 462.7830810546875
Epoch 74 loss 716.3732299804688
Epoch 75 loss 457.2750549316406
Epoch 76 loss 470.88299560546875
Epoch 77 loss 476.23114013671875
Epoch 78 loss 495.600341796875
Epoch 79 loss 548.7179565429688
Epoch 80 loss 484.3630676269531
Epoch 81 loss 526.7352905273438
Epoch 82 loss 525.2803955078125
Epoch 83 loss 515.7614135742188
Epoch 84 loss 573.9605102539062
Epoch 85 loss 482.4600830078125
Epoch 86 loss 454.3533630371094
Epoch 87 loss 529.46875
Epoch 88 loss 442.5720520019531
Epoch 89 loss 582.6227416992188
Epoch 90 loss 455.80438232421875
Epoch 91 loss 444.4452819824219
Epoch 92 loss 622.2285766601562
Epoch 93 loss 485.8461608886719
Epoch 94 loss 440.25311279296875
Epoch 95 loss 486.8457946777344
Epoch 96 loss 448.2769775390625
Epoch 97 loss 584.3609619140625
Epoch 98 loss 453.49127197265625
Epoch 99 loss 454.8433532714844
Saved Losses
{'MSE - mean': 505.40633761271204, 'MSE - std': 65.15342116089698, 'R2 - mean': 0.9380196647076677, 'R2 - std': 0.004359193530883376} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516239.65625
Epoch 1 loss 513887.78125
Epoch 2 loss 510020.9375
Epoch 3 loss 503365.375
Epoch 4 loss 491840.25
Epoch 5 loss 470471.0625
Epoch 6 loss 431587.3125
Epoch 7 loss 369721.75
Epoch 8 loss 283502.5625
Epoch 9 loss 181185.421875
Epoch 10 loss 84868.7578125
Epoch 11 loss 25034.890625
Epoch 12 loss 9486.80078125
Epoch 13 loss 9620.6943359375
Epoch 14 loss 8916.11328125
Epoch 15 loss 8633.859375
Epoch 16 loss 7655.84814453125
Epoch 17 loss 5073.77001953125
Epoch 18 loss 3131.568359375
Epoch 19 loss 2366.92578125
Epoch 20 loss 1781.830322265625
Epoch 21 loss 1696.41015625
Epoch 22 loss 1550.6175537109375
Epoch 23 loss 1496.0240478515625
Epoch 24 loss 1244.344482421875
Epoch 25 loss 1671.427978515625
Epoch 26 loss 1349.7847900390625
Epoch 27 loss 1090.244140625
Epoch 28 loss 1173.69482421875
Epoch 29 loss 1109.5675048828125
Epoch 30 loss 1266.3974609375
Epoch 31 loss 929.1771850585938
Epoch 32 loss 1055.812744140625
Epoch 33 loss 960.5562133789062
Epoch 34 loss 881.772705078125
Epoch 35 loss 908.2962036132812
Epoch 36 loss 912.0818481445312
Epoch 37 loss 816.5436401367188
Epoch 38 loss 917.160888671875
Epoch 39 loss 742.8683471679688
Epoch 40 loss 1148.619384765625
Epoch 41 loss 727.1544189453125
Epoch 42 loss 865.0069580078125
Epoch 43 loss 701.3272705078125
Epoch 44 loss 687.1867065429688
Epoch 45 loss 861.135498046875
Epoch 46 loss 719.9688720703125
Epoch 47 loss 746.968017578125
Epoch 48 loss 642.0499267578125
Epoch 49 loss 1013.6070556640625
Epoch 50 loss 643.3059692382812
Epoch 51 loss 679.5664672851562
Epoch 52 loss 610.9212036132812
Epoch 53 loss 662.8152465820312
Epoch 54 loss 596.9408569335938
Epoch 55 loss 611.0121459960938
Epoch 56 loss 624.3461303710938
Epoch 57 loss 623.1342163085938
Epoch 58 loss 612.9318237304688
Epoch 59 loss 876.35693359375
Epoch 60 loss 571.187744140625
Epoch 61 loss 595.8270874023438
Epoch 62 loss 760.2032470703125
Epoch 63 loss 624.725830078125
Epoch 64 loss 619.6608276367188
Epoch 65 loss 564.2655639648438
Epoch 66 loss 875.87646484375
Epoch 67 loss 525.4788208007812
Epoch 68 loss 648.7343139648438
Epoch 69 loss 609.83984375
Epoch 70 loss 560.8718872070312
Epoch 71 loss 530.4004516601562
Epoch 72 loss 533.171142578125
Epoch 73 loss 707.7752685546875
Epoch 74 loss 552.3712158203125
Epoch 75 loss 607.9312744140625
Epoch 76 loss 518.577392578125
Epoch 77 loss 658.9725341796875
Epoch 78 loss 541.3253173828125
Epoch 79 loss 681.015380859375
Epoch 80 loss 504.9194030761719
Epoch 81 loss 553.9174194335938
Epoch 82 loss 492.2650451660156
Epoch 83 loss 584.9054565429688
Epoch 84 loss 620.942138671875
Epoch 85 loss 483.6943664550781
Epoch 86 loss 536.0106811523438
Epoch 87 loss 533.357177734375
Epoch 88 loss 515.01953125
Epoch 89 loss 474.23309326171875
Epoch 90 loss 557.0328369140625
Epoch 91 loss 528.6395874023438
Epoch 92 loss 483.4719543457031
Epoch 93 loss 569.640869140625
Epoch 94 loss 487.4170837402344
Epoch 95 loss 470.6011657714844
Epoch 96 loss 620.4149780273438
Epoch 97 loss 503.641357421875
Epoch 98 loss 503.72381591796875
Epoch 99 loss 511.5525207519531
Saved Losses
{'MSE - mean': 493.8045255982086, 'MSE - std': 55.670305759467155, 'R2 - mean': 0.9418276430891656, 'R2 - std': 0.00645521320595783} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518802.8125
Epoch 1 loss 516408.8125
Epoch 2 loss 512514.25
Epoch 3 loss 505896.5
Epoch 4 loss 494196.28125
Epoch 5 loss 472750.34375
Epoch 6 loss 434423.40625
Epoch 7 loss 373635.09375
Epoch 8 loss 289368.21875
Epoch 9 loss 188650.140625
Epoch 10 loss 91828.078125
Epoch 11 loss 28526.134765625
Epoch 12 loss 9050.6376953125
Epoch 13 loss 8499.9794921875
Epoch 14 loss 8043.16015625
Epoch 15 loss 7843.60498046875
Epoch 16 loss 7324.69384765625
Epoch 17 loss 5436.3095703125
Epoch 18 loss 2982.125732421875
Epoch 19 loss 2267.078857421875
Epoch 20 loss 1826.2119140625
Epoch 21 loss 1802.3656005859375
Epoch 22 loss 1651.47265625
Epoch 23 loss 1461.7808837890625
Epoch 24 loss 1563.6846923828125
Epoch 25 loss 1296.1719970703125
Epoch 26 loss 1307.9573974609375
Epoch 27 loss 1059.8450927734375
Epoch 28 loss 1237.2847900390625
Epoch 29 loss 966.228271484375
Epoch 30 loss 978.8321533203125
Epoch 31 loss 999.8743286132812
Epoch 32 loss 890.4520263671875
Epoch 33 loss 1040.732421875
Epoch 34 loss 816.7488403320312
Epoch 35 loss 1026.477294921875
Epoch 36 loss 813.4553833007812
Epoch 37 loss 791.708251953125
Epoch 38 loss 925.8670043945312
Epoch 39 loss 897.9044189453125
Epoch 40 loss 717.0307006835938
Epoch 41 loss 761.9534301757812
Epoch 42 loss 745.1115112304688
Epoch 43 loss 841.6712646484375
Epoch 44 loss 655.85107421875
Epoch 45 loss 747.3455810546875
Epoch 46 loss 681.2396850585938
Epoch 47 loss 687.7200927734375
Epoch 48 loss 688.6640014648438
Epoch 49 loss 805.9963989257812
Epoch 50 loss 737.6318359375
Epoch 51 loss 839.485107421875
Epoch 52 loss 595.6148071289062
Epoch 53 loss 808.93310546875
Epoch 54 loss 658.0322265625
Epoch 55 loss 777.6729736328125
Epoch 56 loss 606.953125
Epoch 57 loss 617.8894653320312
Epoch 58 loss 919.427734375
Epoch 59 loss 640.9696044921875
Epoch 60 loss 574.869140625
Epoch 61 loss 795.3703002929688
Epoch 62 loss 598.7335815429688
Epoch 63 loss 658.1718139648438
Epoch 64 loss 583.5901489257812
Epoch 65 loss 718.9290771484375
Epoch 66 loss 610.4397583007812
Epoch 67 loss 583.1425170898438
Epoch 68 loss 625.888671875
Epoch 69 loss 550.1607055664062
Epoch 70 loss 594.1050415039062
Epoch 71 loss 747.5872192382812
Epoch 72 loss 521.90380859375
Epoch 73 loss 597.7925415039062
Epoch 74 loss 704.2545166015625
Epoch 75 loss 624.7568359375
Epoch 76 loss 522.3280029296875
Epoch 77 loss 576.63818359375
Epoch 78 loss 546.506591796875
Epoch 79 loss 667.278564453125
Epoch 80 loss 506.6862487792969
Epoch 81 loss 520.7265625
Epoch 82 loss 531.871826171875
Epoch 83 loss 703.3167114257812
Epoch 84 loss 564.189453125
Epoch 85 loss 521.7579345703125
Epoch 86 loss 507.16290283203125
Epoch 87 loss 534.8740844726562
Epoch 88 loss 510.62579345703125
Epoch 89 loss 521.3165283203125
Epoch 90 loss 514.4804077148438
Epoch 91 loss 525.0757446289062
Epoch 92 loss 537.7409057617188
Epoch 93 loss 521.9489135742188
Epoch 94 loss 574.060546875
Epoch 95 loss 514.2850341796875
Epoch 96 loss 514.0313110351562
Epoch 97 loss 524.880615234375
Epoch 98 loss 581.81884765625
Epoch 99 loss 751.8394165039062
Saved Losses
{'MSE - mean': 497.0250080076977, 'MSE - std': 48.53351139536378, 'R2 - mean': 0.9411192259378434, 'R2 - std': 0.005723451557551787} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514511.71875
Epoch 1 loss 511309.1875
Epoch 2 loss 506641.375
Epoch 3 loss 499154.0
Epoch 4 loss 486580.78125
Epoch 5 loss 464178.125
Epoch 6 loss 425018.90625
Epoch 7 loss 363437.25
Epoch 8 loss 278584.9375
Epoch 9 loss 178605.59375
Epoch 10 loss 83861.0234375
Epoch 11 loss 24304.10546875
Epoch 12 loss 8229.392578125
Epoch 13 loss 8175.42724609375
Epoch 14 loss 7531.2861328125
Epoch 15 loss 6991.8935546875
Epoch 16 loss 4982.73876953125
Epoch 17 loss 3326.26806640625
Epoch 18 loss 2129.0625
Epoch 19 loss 1718.3721923828125
Epoch 20 loss 1697.4072265625
Epoch 21 loss 1331.620361328125
Epoch 22 loss 1253.2593994140625
Epoch 23 loss 1259.6292724609375
Epoch 24 loss 1091.2601318359375
Epoch 25 loss 1271.6339111328125
Epoch 26 loss 1056.2666015625
Epoch 27 loss 969.119140625
Epoch 28 loss 948.2216796875
Epoch 29 loss 867.5182495117188
Epoch 30 loss 835.70068359375
Epoch 31 loss 881.8651123046875
Epoch 32 loss 815.3021240234375
Epoch 33 loss 875.3181762695312
Epoch 34 loss 738.17822265625
Epoch 35 loss 786.7581176757812
Epoch 36 loss 758.7479858398438
Epoch 37 loss 705.4680786132812
Epoch 38 loss 742.6207885742188
Epoch 39 loss 692.940673828125
Epoch 40 loss 716.0209350585938
Epoch 41 loss 944.2368774414062
Epoch 42 loss 638.8603515625
Epoch 43 loss 681.641845703125
Epoch 44 loss 620.3804321289062
Epoch 45 loss 701.5065307617188
Epoch 46 loss 637.4882202148438
Epoch 47 loss 601.4328002929688
Epoch 48 loss 587.2280883789062
Epoch 49 loss 577.5834350585938
Epoch 50 loss 575.4675903320312
Epoch 51 loss 639.9783935546875
Epoch 52 loss 566.2269897460938
Epoch 53 loss 578.6607666015625
Epoch 54 loss 556.3937377929688
Epoch 55 loss 550.7836303710938
Epoch 56 loss 666.9379272460938
Epoch 57 loss 541.3169555664062
Epoch 58 loss 534.8898315429688
Epoch 59 loss 614.3834838867188
Epoch 60 loss 542.6460571289062
Epoch 61 loss 539.1185302734375
Epoch 62 loss 508.7577209472656
Epoch 63 loss 507.0701904296875
Epoch 64 loss 578.78515625
Epoch 65 loss 520.0533447265625
Epoch 66 loss 522.25634765625
Epoch 67 loss 550.2366333007812
Epoch 68 loss 522.3355102539062
Epoch 69 loss 497.5914306640625
Epoch 70 loss 497.7911376953125
Epoch 71 loss 544.6463012695312
Epoch 72 loss 489.7370910644531
Epoch 73 loss 484.3309020996094
Epoch 74 loss 506.45574951171875
Epoch 75 loss 541.7083129882812
Epoch 76 loss 532.75830078125
Epoch 77 loss 513.8184814453125
Epoch 78 loss 479.8896484375
Epoch 79 loss 517.88916015625
Epoch 80 loss 484.973388671875
Epoch 81 loss 480.97308349609375
Epoch 82 loss 498.95062255859375
Epoch 83 loss 548.14599609375
Epoch 84 loss 492.90838623046875
Epoch 85 loss 526.1503295898438
Epoch 86 loss 482.9773254394531
Epoch 87 loss 491.3431701660156
Epoch 88 loss 513.546142578125
Epoch 89 loss 468.6999206542969
Epoch 90 loss 489.095947265625
Epoch 91 loss 483.62725830078125
Epoch 92 loss 485.17376708984375
Epoch 93 loss 484.12579345703125
Epoch 94 loss 495.5296630859375
Epoch 95 loss 476.679443359375
Epoch 96 loss 519.0053100585938
Epoch 97 loss 469.4533386230469
Epoch 98 loss 460.9275207519531
Epoch 99 loss 483.2677917480469
Saved Losses
{'MSE - mean': 489.8054393206663, 'MSE - std': 45.74811548903604, 'R2 - mean': 0.9413404796939642, 'R2 - std': 0.005138300408082798} 
 

Results After CV: {'MSE - mean': 489.8054393206663, 'MSE - std': 45.74811548903604, 'R2 - mean': 0.9413404796939642, 'R2 - std': 0.005138300408082798}
Train time: 95.7880686913999
Inference time: 0.13545669020022616
Finished cross validation
Trial 15 finished with value: 489.8054393206663 and parameters: {'dim': 64, 'depth': 2, 'heads': 2, 'dropout': 0.4}. Best is trial 12 with value: 482.5660834789284.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513360.46875
Epoch 1 loss 510270.4375
Epoch 2 loss 505617.25
Epoch 3 loss 498653.53125
Epoch 4 loss 487537.625
Epoch 5 loss 465960.15625
Epoch 6 loss 427372.1875
Epoch 7 loss 367530.1875
Epoch 8 loss 285357.6875
Epoch 9 loss 187594.15625
Epoch 10 loss 93546.515625
Epoch 11 loss 30562.77734375
Epoch 12 loss 9674.3017578125
Epoch 13 loss 8750.8115234375
Epoch 14 loss 8409.05078125
Epoch 15 loss 8015.259765625
Epoch 16 loss 5105.12255859375
Epoch 17 loss 2957.644287109375
Epoch 18 loss 2283.462158203125
Epoch 19 loss 1941.8834228515625
Epoch 20 loss 1454.6121826171875
Epoch 21 loss 1374.07568359375
Epoch 22 loss 1167.546630859375
Epoch 23 loss 1130.9658203125
Epoch 24 loss 1044.6553955078125
Epoch 25 loss 982.8428344726562
Epoch 26 loss 935.6876220703125
Epoch 27 loss 893.6401977539062
Epoch 28 loss 930.464599609375
Epoch 29 loss 858.9725341796875
Epoch 30 loss 921.2105102539062
Epoch 31 loss 791.1083374023438
Epoch 32 loss 748.04736328125
Epoch 33 loss 791.0083618164062
Epoch 34 loss 715.9712524414062
Epoch 35 loss 766.895263671875
Epoch 36 loss 907.9854125976562
Epoch 37 loss 746.157470703125
Epoch 38 loss 684.666259765625
Epoch 39 loss 712.6175537109375
Epoch 40 loss 756.7216796875
Epoch 41 loss 671.1022338867188
Epoch 42 loss 635.9295654296875
Epoch 43 loss 703.2669677734375
Epoch 44 loss 633.5885620117188
Epoch 45 loss 704.3739013671875
Epoch 46 loss 704.1802978515625
Epoch 47 loss 650.1326904296875
Epoch 48 loss 613.812744140625
Epoch 49 loss 602.8641357421875
Epoch 50 loss 625.760498046875
Epoch 51 loss 829.92138671875
Epoch 52 loss 841.166015625
Epoch 53 loss 664.5745239257812
Epoch 54 loss 616.464599609375
Epoch 55 loss 706.6007080078125
Epoch 56 loss 589.1708374023438
Epoch 57 loss 585.2324829101562
Epoch 58 loss 626.2245483398438
Epoch 59 loss 684.0478515625
Epoch 60 loss 583.112060546875
Epoch 61 loss 579.3555297851562
Epoch 62 loss 635.1944580078125
Epoch 63 loss 646.4964599609375
Epoch 64 loss 574.2490844726562
Epoch 65 loss 576.8318481445312
Epoch 66 loss 754.9508056640625
Epoch 67 loss 584.1214599609375
Epoch 68 loss 641.471435546875
Epoch 69 loss 557.3167724609375
Epoch 70 loss 595.1641235351562
Epoch 71 loss 728.7250366210938
Epoch 72 loss 590.9260864257812
Epoch 73 loss 563.7274780273438
Epoch 74 loss 555.1661987304688
Epoch 75 loss 627.6312255859375
Epoch 76 loss 559.0361938476562
Epoch 77 loss 740.3196411132812
Epoch 78 loss 556.8733520507812
Epoch 79 loss 554.8737182617188
Epoch 80 loss 623.5208129882812
Epoch 81 loss 559.0819702148438
Epoch 82 loss 610.9014282226562
Epoch 83 loss 646.367431640625
Epoch 84 loss 588.7254638671875
Epoch 85 loss 655.8342895507812
Epoch 86 loss 581.7272338867188
Epoch 87 loss 548.3373413085938
Epoch 88 loss 593.138427734375
Epoch 89 loss 680.1552734375
Epoch 90 loss 583.8274536132812
Epoch 91 loss 641.4737548828125
Epoch 92 loss 680.9337158203125
Epoch 93 loss 584.570068359375
Epoch 94 loss 577.7793579101562
Epoch 95 loss 553.9718017578125
Epoch 96 loss 566.1006469726562
Epoch 97 loss 560.491943359375
Epoch 98 loss 618.2564697265625
Epoch 99 loss 575.8883666992188
Saved Losses
{'MSE - mean': 548.3370140949, 'MSE - std': 0.0, 'R2 - mean': 0.9362443309539145, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 521501.0
Epoch 1 loss 518332.84375
Epoch 2 loss 513786.5625
Epoch 3 loss 507242.09375
Epoch 4 loss 497203.0625
Epoch 5 loss 476881.21875
Epoch 6 loss 440005.3125
Epoch 7 loss 381739.6875
Epoch 8 loss 300366.03125
Epoch 9 loss 201469.3125
Epoch 10 loss 103432.78125
Epoch 11 loss 34357.28515625
Epoch 12 loss 9488.880859375
Epoch 13 loss 7660.35009765625
Epoch 14 loss 7550.62841796875
Epoch 15 loss 7195.5302734375
Epoch 16 loss 5461.59716796875
Epoch 17 loss 2882.41552734375
Epoch 18 loss 2139.6494140625
Epoch 19 loss 1728.9857177734375
Epoch 20 loss 1650.5045166015625
Epoch 21 loss 1430.1424560546875
Epoch 22 loss 1238.354736328125
Epoch 23 loss 1125.4532470703125
Epoch 24 loss 1172.3975830078125
Epoch 25 loss 1141.5576171875
Epoch 26 loss 1010.4637451171875
Epoch 27 loss 1069.9197998046875
Epoch 28 loss 906.2848510742188
Epoch 29 loss 896.2134399414062
Epoch 30 loss 876.6363525390625
Epoch 31 loss 815.9487915039062
Epoch 32 loss 764.682861328125
Epoch 33 loss 733.9931030273438
Epoch 34 loss 683.3097534179688
Epoch 35 loss 788.1525268554688
Epoch 36 loss 968.6928100585938
Epoch 37 loss 774.3699340820312
Epoch 38 loss 678.8681030273438
Epoch 39 loss 622.8633422851562
Epoch 40 loss 673.9251098632812
Epoch 41 loss 590.1235961914062
Epoch 42 loss 620.8723754882812
Epoch 43 loss 570.2181396484375
Epoch 44 loss 663.8027954101562
Epoch 45 loss 563.746337890625
Epoch 46 loss 656.2235717773438
Epoch 47 loss 545.9060668945312
Epoch 48 loss 547.7678833007812
Epoch 49 loss 612.5916137695312
Epoch 50 loss 529.27880859375
Epoch 51 loss 561.9348754882812
Epoch 52 loss 566.6600952148438
Epoch 53 loss 511.5481872558594
Epoch 54 loss 524.4592895507812
Epoch 55 loss 533.2981567382812
Epoch 56 loss 515.8324584960938
Epoch 57 loss 526.1915283203125
Epoch 58 loss 516.3253784179688
Epoch 59 loss 533.5826416015625
Epoch 60 loss 533.6878662109375
Epoch 61 loss 703.40966796875
Epoch 62 loss 598.277099609375
Epoch 63 loss 496.1813049316406
Epoch 64 loss 546.9521484375
Epoch 65 loss 498.66802978515625
Epoch 66 loss 476.09063720703125
Epoch 67 loss 508.4952392578125
Epoch 68 loss 465.8559265136719
Epoch 69 loss 474.8907470703125
Epoch 70 loss 472.49517822265625
Epoch 71 loss 456.8695068359375
Epoch 72 loss 493.5221252441406
Epoch 73 loss 528.8192749023438
Epoch 74 loss 652.9752807617188
Epoch 75 loss 569.3643798828125
Epoch 76 loss 485.2593078613281
Epoch 77 loss 475.8565368652344
Epoch 78 loss 461.4862060546875
Epoch 79 loss 455.50653076171875
Epoch 80 loss 456.61065673828125
Epoch 81 loss 469.9151916503906
Epoch 82 loss 463.0155029296875
Epoch 83 loss 443.5802917480469
Epoch 84 loss 462.6967468261719
Epoch 85 loss 448.908203125
Epoch 86 loss 538.0655517578125
Epoch 87 loss 522.7780151367188
Epoch 88 loss 523.2859497070312
Epoch 89 loss 467.4146728515625
Epoch 90 loss 472.0283508300781
Epoch 91 loss 456.781494140625
Epoch 92 loss 452.3459167480469
Epoch 93 loss 438.2862243652344
Epoch 94 loss 538.003662109375
Epoch 95 loss 533.3814697265625
Epoch 96 loss 848.1253662109375
Epoch 97 loss 515.7022705078125
Epoch 98 loss 471.0834655761719
Epoch 99 loss 470.24090576171875
Saved Losses
{'MSE - mean': 493.3116596387888, 'MSE - std': 55.025354456111245, 'R2 - mean': 0.9394402915139521, 'R2 - std': 0.003195960560037736} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515894.5625
Epoch 1 loss 513207.5625
Epoch 2 loss 509161.875
Epoch 3 loss 503530.0625
Epoch 4 loss 495299.03125
Epoch 5 loss 478326.875
Epoch 6 loss 445906.0625
Epoch 7 loss 393007.21875
Epoch 8 loss 316743.25
Epoch 9 loss 220671.75
Epoch 10 loss 120524.078125
Epoch 11 loss 44123.10546875
Epoch 12 loss 12372.7724609375
Epoch 13 loss 9403.9736328125
Epoch 14 loss 9237.1552734375
Epoch 15 loss 9092.41796875
Epoch 16 loss 8471.1611328125
Epoch 17 loss 4898.8720703125
Epoch 18 loss 3156.101806640625
Epoch 19 loss 2181.025146484375
Epoch 20 loss 1695.495361328125
Epoch 21 loss 1394.1240234375
Epoch 22 loss 1403.3682861328125
Epoch 23 loss 1215.63818359375
Epoch 24 loss 1075.95703125
Epoch 25 loss 1012.9912109375
Epoch 26 loss 879.2034912109375
Epoch 27 loss 875.4955444335938
Epoch 28 loss 825.9036865234375
Epoch 29 loss 883.343505859375
Epoch 30 loss 749.3529663085938
Epoch 31 loss 775.6141357421875
Epoch 32 loss 1115.60107421875
Epoch 33 loss 679.919189453125
Epoch 34 loss 880.3988037109375
Epoch 35 loss 717.2601928710938
Epoch 36 loss 650.794677734375
Epoch 37 loss 651.1962890625
Epoch 38 loss 588.7113647460938
Epoch 39 loss 728.449462890625
Epoch 40 loss 761.6156005859375
Epoch 41 loss 892.941650390625
Epoch 42 loss 643.5008544921875
Epoch 43 loss 624.0527954101562
Epoch 44 loss 561.8344116210938
Epoch 45 loss 726.6802368164062
Epoch 46 loss 531.014404296875
Epoch 47 loss 564.80712890625
Epoch 48 loss 620.5746459960938
Epoch 49 loss 613.8141479492188
Epoch 50 loss 530.8720703125
Epoch 51 loss 507.30230712890625
Epoch 52 loss 685.776123046875
Epoch 53 loss 497.0611572265625
Epoch 54 loss 485.1739501953125
Epoch 55 loss 548.6807250976562
Epoch 56 loss 528.1519775390625
Epoch 57 loss 678.7632446289062
Epoch 58 loss 500.7843933105469
Epoch 59 loss 472.478759765625
Epoch 60 loss 470.4202575683594
Epoch 61 loss 484.9502868652344
Epoch 62 loss 652.5743408203125
Epoch 63 loss 492.7131652832031
Epoch 64 loss 544.51123046875
Epoch 65 loss 597.5276489257812
Epoch 66 loss 605.987548828125
Epoch 67 loss 467.3450622558594
Epoch 68 loss 485.3968811035156
Epoch 69 loss 502.61370849609375
Epoch 70 loss 538.102294921875
Epoch 71 loss 477.5122375488281
Epoch 72 loss 472.5916442871094
Epoch 73 loss 515.056396484375
Epoch 74 loss 652.0011596679688
Epoch 75 loss 618.9307861328125
Epoch 76 loss 490.93292236328125
Epoch 77 loss 486.54254150390625
Epoch 78 loss 457.3378601074219
Epoch 79 loss 463.5293884277344
Epoch 80 loss 507.8101806640625
Epoch 81 loss 477.6407775878906
Epoch 82 loss 468.8013000488281
Epoch 83 loss 522.6737670898438
Epoch 84 loss 489.4364013671875
Epoch 85 loss 483.873779296875
Epoch 86 loss 465.0805358886719
Epoch 87 loss 524.0869750976562
Epoch 88 loss 468.6564025878906
Epoch 89 loss 465.7890319824219
Epoch 90 loss 502.3048400878906
Epoch 91 loss 495.24383544921875
Epoch 92 loss 470.5616455078125
Epoch 93 loss 506.64715576171875
Epoch 94 loss 582.4103393554688
Epoch 95 loss 535.9249267578125
Epoch 96 loss 510.1930847167969
Epoch 97 loss 463.6272888183594
Epoch 98 loss 451.1070861816406
Epoch 99 loss 536.8013305664062
Saved Losses
{'MSE - mean': 479.24357012749664, 'MSE - std': 49.136022498867824, 'R2 - mean': 0.9434727867195295, 'R2 - std': 0.006271481305631571} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518446.9375
Epoch 1 loss 515833.28125
Epoch 2 loss 511805.03125
Epoch 3 loss 505449.03125
Epoch 4 loss 495564.34375
Epoch 5 loss 476506.0625
Epoch 6 loss 441200.3125
Epoch 7 loss 384285.3125
Epoch 8 loss 303400.03125
Epoch 9 loss 203910.75
Epoch 10 loss 104591.3125
Epoch 11 loss 34625.625
Epoch 12 loss 9811.509765625
Epoch 13 loss 8472.8330078125
Epoch 14 loss 8190.7822265625
Epoch 15 loss 8019.10791015625
Epoch 16 loss 6970.7783203125
Epoch 17 loss 3668.74462890625
Epoch 18 loss 2452.03564453125
Epoch 19 loss 2011.164794921875
Epoch 20 loss 1635.2685546875
Epoch 21 loss 1521.1531982421875
Epoch 22 loss 1391.18310546875
Epoch 23 loss 1277.0455322265625
Epoch 24 loss 1204.3616943359375
Epoch 25 loss 1104.3929443359375
Epoch 26 loss 1108.7281494140625
Epoch 27 loss 1009.242919921875
Epoch 28 loss 900.5714111328125
Epoch 29 loss 864.253662109375
Epoch 30 loss 894.8035278320312
Epoch 31 loss 787.4369506835938
Epoch 32 loss 766.695068359375
Epoch 33 loss 809.387939453125
Epoch 34 loss 844.6990966796875
Epoch 35 loss 751.17626953125
Epoch 36 loss 721.344970703125
Epoch 37 loss 774.5703125
Epoch 38 loss 654.540771484375
Epoch 39 loss 1012.078369140625
Epoch 40 loss 764.1553344726562
Epoch 41 loss 635.5059204101562
Epoch 42 loss 806.4756469726562
Epoch 43 loss 617.3455200195312
Epoch 44 loss 675.27197265625
Epoch 45 loss 709.9114990234375
Epoch 46 loss 753.5614013671875
Epoch 47 loss 607.9182739257812
Epoch 48 loss 727.4644165039062
Epoch 49 loss 604.3526000976562
Epoch 50 loss 587.8832397460938
Epoch 51 loss 594.8363037109375
Epoch 52 loss 599.982421875
Epoch 53 loss 589.9804077148438
Epoch 54 loss 600.0845336914062
Epoch 55 loss 567.316650390625
Epoch 56 loss 668.8522338867188
Epoch 57 loss 560.352294921875
Epoch 58 loss 563.4503173828125
Epoch 59 loss 630.7733764648438
Epoch 60 loss 570.9349365234375
Epoch 61 loss 646.8768920898438
Epoch 62 loss 613.5237426757812
Epoch 63 loss 621.1275024414062
Epoch 64 loss 540.4425659179688
Epoch 65 loss 667.7083129882812
Epoch 66 loss 523.040283203125
Epoch 67 loss 546.549072265625
Epoch 68 loss 544.4227294921875
Epoch 69 loss 526.1156005859375
Epoch 70 loss 642.6932373046875
Epoch 71 loss 595.584228515625
Epoch 72 loss 702.065185546875
Epoch 73 loss 575.3633422851562
Epoch 74 loss 853.6301879882812
Epoch 75 loss 554.528564453125
Epoch 76 loss 560.1657104492188
Epoch 77 loss 569.21728515625
Epoch 78 loss 621.51708984375
Epoch 79 loss 539.721923828125
Epoch 80 loss 563.638427734375
Epoch 81 loss 530.2685546875
Epoch 82 loss 576.541015625
Epoch 83 loss 523.38916015625
Epoch 84 loss 524.8521118164062
Epoch 85 loss 538.2992553710938
Epoch 86 loss 499.9253234863281
Epoch 87 loss 546.3908081054688
Epoch 88 loss 773.64111328125
Epoch 89 loss 527.3424682617188
Epoch 90 loss 519.1995239257812
Epoch 91 loss 566.6679077148438
Epoch 92 loss 525.2058715820312
Epoch 93 loss 567.0993041992188
Epoch 94 loss 522.3252563476562
Epoch 95 loss 537.9652709960938
Epoch 96 loss 504.4136047363281
Epoch 97 loss 529.2002563476562
Epoch 98 loss 513.3164672851562
Epoch 99 loss 500.72235107421875
Saved Losses
{'MSE - mean': 484.41401076075766, 'MSE - std': 43.485191724116426, 'R2 - mean': 0.9425565967070495, 'R2 - std': 0.005658340811763597} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516164.0
Epoch 1 loss 514071.75
Epoch 2 loss 510680.25
Epoch 3 loss 505544.75
Epoch 4 loss 497539.59375
Epoch 5 loss 481258.84375
Epoch 6 loss 450901.5
Epoch 7 loss 401023.46875
Epoch 8 loss 328018.65625
Epoch 9 loss 233585.65625
Epoch 10 loss 131039.984375
Epoch 11 loss 49018.203125
Epoch 12 loss 12112.220703125
Epoch 13 loss 8074.91552734375
Epoch 14 loss 7872.49560546875
Epoch 15 loss 7652.5126953125
Epoch 16 loss 6676.51025390625
Epoch 17 loss 3468.76318359375
Epoch 18 loss 2176.94580078125
Epoch 19 loss 1577.3648681640625
Epoch 20 loss 1296.9598388671875
Epoch 21 loss 1404.7235107421875
Epoch 22 loss 1108.332763671875
Epoch 23 loss 1025.1175537109375
Epoch 24 loss 884.128662109375
Epoch 25 loss 826.4705200195312
Epoch 26 loss 817.7083129882812
Epoch 27 loss 794.6452026367188
Epoch 28 loss 813.5311279296875
Epoch 29 loss 778.4108276367188
Epoch 30 loss 826.5316772460938
Epoch 31 loss 654.3046264648438
Epoch 32 loss 640.9066162109375
Epoch 33 loss 648.778076171875
Epoch 34 loss 627.219970703125
Epoch 35 loss 617.181884765625
Epoch 36 loss 766.8882446289062
Epoch 37 loss 613.2691650390625
Epoch 38 loss 650.8947143554688
Epoch 39 loss 642.0064697265625
Epoch 40 loss 589.6416625976562
Epoch 41 loss 592.7685546875
Epoch 42 loss 637.1259765625
Epoch 43 loss 567.8585815429688
Epoch 44 loss 601.7032470703125
Epoch 45 loss 609.0843505859375
Epoch 46 loss 599.05126953125
Epoch 47 loss 554.2645874023438
Epoch 48 loss 562.1666259765625
Epoch 49 loss 540.7724609375
Epoch 50 loss 553.6746826171875
Epoch 51 loss 531.2504272460938
Epoch 52 loss 542.6553955078125
Epoch 53 loss 529.434326171875
Epoch 54 loss 498.61785888671875
Epoch 55 loss 517.5762939453125
Epoch 56 loss 525.0186157226562
Epoch 57 loss 500.6323547363281
Epoch 58 loss 565.0451049804688
Epoch 59 loss 501.9996643066406
Epoch 60 loss 509.9798889160156
Epoch 61 loss 496.9468078613281
Epoch 62 loss 486.86602783203125
Epoch 63 loss 500.85198974609375
Epoch 64 loss 506.7948913574219
Epoch 65 loss 478.4748229980469
Epoch 66 loss 513.7979736328125
Epoch 67 loss 548.6939697265625
Epoch 68 loss 501.9426574707031
Epoch 69 loss 478.2998352050781
Epoch 70 loss 479.1998596191406
Epoch 71 loss 479.4245300292969
Epoch 72 loss 470.23919677734375
Epoch 73 loss 526.7355346679688
Epoch 74 loss 479.1292419433594
Epoch 75 loss 511.5279235839844
Epoch 76 loss 460.72479248046875
Epoch 77 loss 472.6059875488281
Epoch 78 loss 551.8992309570312
Epoch 79 loss 626.7171020507812
Epoch 80 loss 471.8948059082031
Epoch 81 loss 764.7146606445312
Epoch 82 loss 478.0213928222656
Epoch 83 loss 505.6155090332031
Epoch 84 loss 515.890625
Epoch 85 loss 457.0867004394531
Epoch 86 loss 457.8975830078125
Epoch 87 loss 457.2174377441406
Epoch 88 loss 509.14727783203125
Epoch 89 loss 459.5535583496094
Epoch 90 loss 452.4427490234375
Epoch 91 loss 482.4272766113281
Epoch 92 loss 475.7275085449219
Epoch 93 loss 463.6021728515625
Epoch 94 loss 453.673583984375
Epoch 95 loss 546.94677734375
Epoch 96 loss 453.0342102050781
Epoch 97 loss 484.6473388671875
Epoch 98 loss 545.1844482421875
Epoch 99 loss 495.2628173828125
Saved Losses
{'MSE - mean': 478.0197831014686, 'MSE - std': 40.94281510670462, 'R2 - mean': 0.9427030675182196, 'R2 - std': 0.005069444879644608} 
 

Results After CV: {'MSE - mean': 478.0197831014686, 'MSE - std': 40.94281510670462, 'R2 - mean': 0.9427030675182196, 'R2 - std': 0.005069444879644608}
Train time: 104.3386716023997
Inference time: 0.13721486399990682
Finished cross validation
Trial 16 finished with value: 478.0197831014686 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.2}. Best is trial 16 with value: 478.0197831014686.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513709.3125
Epoch 1 loss 510487.90625
Epoch 2 loss 505469.84375
Epoch 3 loss 498019.3125
Epoch 4 loss 486594.15625
Epoch 5 loss 464587.21875
Epoch 6 loss 424799.3125
Epoch 7 loss 361919.875
Epoch 8 loss 275423.4375
Epoch 9 loss 173715.78125
Epoch 10 loss 79512.6171875
Epoch 11 loss 22639.98046875
Epoch 12 loss 8710.4833984375
Epoch 13 loss 8896.0283203125
Epoch 14 loss 8313.896484375
Epoch 15 loss 7919.4580078125
Epoch 16 loss 6214.15283203125
Epoch 17 loss 3522.849853515625
Epoch 18 loss 2506.56201171875
Epoch 19 loss 2117.727783203125
Epoch 20 loss 1753.3070068359375
Epoch 21 loss 1514.966796875
Epoch 22 loss 1371.3988037109375
Epoch 23 loss 1239.3857421875
Epoch 24 loss 1149.6611328125
Epoch 25 loss 1073.627197265625
Epoch 26 loss 1087.3800048828125
Epoch 27 loss 1025.2159423828125
Epoch 28 loss 1035.048095703125
Epoch 29 loss 914.5564575195312
Epoch 30 loss 909.5180053710938
Epoch 31 loss 917.7955932617188
Epoch 32 loss 835.82568359375
Epoch 33 loss 824.0301513671875
Epoch 34 loss 878.6748046875
Epoch 35 loss 829.91259765625
Epoch 36 loss 823.2308959960938
Epoch 37 loss 767.905517578125
Epoch 38 loss 847.327880859375
Epoch 39 loss 749.8408813476562
Epoch 40 loss 737.3265380859375
Epoch 41 loss 727.1604614257812
Epoch 42 loss 778.1792602539062
Epoch 43 loss 785.8465576171875
Epoch 44 loss 747.98974609375
Epoch 45 loss 761.1237182617188
Epoch 46 loss 702.4984130859375
Epoch 47 loss 723.12841796875
Epoch 48 loss 759.7222900390625
Epoch 49 loss 693.8460083007812
Epoch 50 loss 763.4006958007812
Epoch 51 loss 679.307861328125
Epoch 52 loss 670.246826171875
Epoch 53 loss 672.4384155273438
Epoch 54 loss 911.2182006835938
Epoch 55 loss 656.0980834960938
Epoch 56 loss 647.11767578125
Epoch 57 loss 645.0332641601562
Epoch 58 loss 642.1366577148438
Epoch 59 loss 687.1016235351562
Epoch 60 loss 665.1823120117188
Epoch 61 loss 644.90625
Epoch 62 loss 632.2966918945312
Epoch 63 loss 649.173583984375
Epoch 64 loss 623.46337890625
Epoch 65 loss 646.121337890625
Epoch 66 loss 627.1900024414062
Epoch 67 loss 616.0787963867188
Epoch 68 loss 717.1398315429688
Epoch 69 loss 629.0831298828125
Epoch 70 loss 637.4373779296875
Epoch 71 loss 695.758544921875
Epoch 72 loss 700.95849609375
Epoch 73 loss 612.442138671875
Epoch 74 loss 653.48583984375
Epoch 75 loss 615.1207885742188
Epoch 76 loss 612.4869995117188
Epoch 77 loss 713.5515747070312
Epoch 78 loss 597.4180297851562
Epoch 79 loss 602.0215454101562
Epoch 80 loss 651.2760620117188
Epoch 81 loss 598.7913208007812
Epoch 82 loss 590.9329223632812
Epoch 83 loss 626.4973754882812
Epoch 84 loss 623.9009399414062
Epoch 85 loss 582.5078735351562
Epoch 86 loss 591.893798828125
Epoch 87 loss 602.8714599609375
Epoch 88 loss 601.6613159179688
Epoch 89 loss 595.7432861328125
Epoch 90 loss 641.2633056640625
Epoch 91 loss 579.8778686523438
Epoch 92 loss 577.8426513671875
Epoch 93 loss 583.0949096679688
Epoch 94 loss 586.02001953125
Epoch 95 loss 569.7172241210938
Epoch 96 loss 572.6864013671875
Epoch 97 loss 569.764404296875
Epoch 98 loss 606.0987548828125
Epoch 99 loss 583.4512939453125
Saved Losses
{'MSE - mean': 569.7173746852769, 'MSE - std': 0.0, 'R2 - mean': 0.933758415980372, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523105.75
Epoch 1 loss 520830.46875
Epoch 2 loss 517158.25
Epoch 3 loss 511399.46875
Epoch 4 loss 502345.46875
Epoch 5 loss 484444.25
Epoch 6 loss 450652.125
Epoch 7 loss 395087.5625
Epoch 8 loss 314947.84375
Epoch 9 loss 214365.6875
Epoch 10 loss 111717.0234375
Epoch 11 loss 37104.8671875
Epoch 12 loss 9647.830078125
Epoch 13 loss 7673.8720703125
Epoch 14 loss 7482.31005859375
Epoch 15 loss 7302.61865234375
Epoch 16 loss 6803.544921875
Epoch 17 loss 4395.7197265625
Epoch 18 loss 2836.879150390625
Epoch 19 loss 1976.5439453125
Epoch 20 loss 1622.49853515625
Epoch 21 loss 1382.5177001953125
Epoch 22 loss 1172.517822265625
Epoch 23 loss 1361.457275390625
Epoch 24 loss 1057.672119140625
Epoch 25 loss 1058.4560546875
Epoch 26 loss 892.0970458984375
Epoch 27 loss 853.3572387695312
Epoch 28 loss 811.0216064453125
Epoch 29 loss 1036.7060546875
Epoch 30 loss 904.8297119140625
Epoch 31 loss 809.9024658203125
Epoch 32 loss 741.0421142578125
Epoch 33 loss 769.5465698242188
Epoch 34 loss 714.66796875
Epoch 35 loss 670.5926513671875
Epoch 36 loss 664.908935546875
Epoch 37 loss 638.0751953125
Epoch 38 loss 675.4747924804688
Epoch 39 loss 626.5325927734375
Epoch 40 loss 617.871337890625
Epoch 41 loss 628.2669067382812
Epoch 42 loss 606.6052856445312
Epoch 43 loss 567.2759399414062
Epoch 44 loss 609.2378540039062
Epoch 45 loss 556.3177490234375
Epoch 46 loss 541.6820678710938
Epoch 47 loss 533.0335693359375
Epoch 48 loss 560.0440673828125
Epoch 49 loss 522.166748046875
Epoch 50 loss 589.1510620117188
Epoch 51 loss 509.68536376953125
Epoch 52 loss 534.9075317382812
Epoch 53 loss 504.35498046875
Epoch 54 loss 637.8414306640625
Epoch 55 loss 514.9166870117188
Epoch 56 loss 511.1573791503906
Epoch 57 loss 525.85498046875
Epoch 58 loss 523.3056030273438
Epoch 59 loss 606.4447631835938
Epoch 60 loss 524.5514526367188
Epoch 61 loss 489.0008544921875
Epoch 62 loss 524.4354248046875
Epoch 63 loss 535.028564453125
Epoch 64 loss 548.7151489257812
Epoch 65 loss 465.0539855957031
Epoch 66 loss 493.33294677734375
Epoch 67 loss 512.633544921875
Epoch 68 loss 478.09857177734375
Epoch 69 loss 590.2367553710938
Epoch 70 loss 478.03741455078125
Epoch 71 loss 458.8912048339844
Epoch 72 loss 458.37774658203125
Epoch 73 loss 451.79241943359375
Epoch 74 loss 541.7396240234375
Epoch 75 loss 468.7337646484375
Epoch 76 loss 450.95147705078125
Epoch 77 loss 496.736083984375
Epoch 78 loss 580.8179321289062
Epoch 79 loss 527.6514282226562
Epoch 80 loss 457.5975036621094
Epoch 81 loss 445.027099609375
Epoch 82 loss 456.6764831542969
Epoch 83 loss 444.5801086425781
Epoch 84 loss 736.548095703125
Epoch 85 loss 443.1448059082031
Epoch 86 loss 454.3261413574219
Epoch 87 loss 483.4491882324219
Epoch 88 loss 483.80828857421875
Epoch 89 loss 458.45416259765625
Epoch 90 loss 442.1263427734375
Epoch 91 loss 538.6920166015625
Epoch 92 loss 474.7025451660156
Epoch 93 loss 517.3968505859375
Epoch 94 loss 507.43438720703125
Epoch 95 loss 466.9482727050781
Epoch 96 loss 502.9579162597656
Epoch 97 loss 438.7486877441406
Epoch 98 loss 457.69708251953125
Epoch 99 loss 464.4538269042969
Saved Losses
{'MSE - mean': 504.23299626900473, 'MSE - std': 65.48437841627216, 'R2 - mean': 0.9381670798449782, 'R2 - std': 0.004408663864606088} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516376.8125
Epoch 1 loss 514060.5625
Epoch 2 loss 510324.40625
Epoch 3 loss 504404.78125
Epoch 4 loss 495276.46875
Epoch 5 loss 477903.0
Epoch 6 loss 445124.59375
Epoch 7 loss 391698.8125
Epoch 8 loss 315137.28125
Epoch 9 loss 219215.53125
Epoch 10 loss 119498.03125
Epoch 11 loss 43829.0859375
Epoch 12 loss 12432.09765625
Epoch 13 loss 9422.3203125
Epoch 14 loss 9211.619140625
Epoch 15 loss 8932.6279296875
Epoch 16 loss 8440.2578125
Epoch 17 loss 5617.38916015625
Epoch 18 loss 3518.78662109375
Epoch 19 loss 2483.885498046875
Epoch 20 loss 1893.202392578125
Epoch 21 loss 1547.53369140625
Epoch 22 loss 1372.8330078125
Epoch 23 loss 1245.123046875
Epoch 24 loss 1167.2711181640625
Epoch 25 loss 1154.675048828125
Epoch 26 loss 1124.9351806640625
Epoch 27 loss 956.2496337890625
Epoch 28 loss 1088.814208984375
Epoch 29 loss 1074.52001953125
Epoch 30 loss 887.998291015625
Epoch 31 loss 842.763671875
Epoch 32 loss 834.5579833984375
Epoch 33 loss 706.6156616210938
Epoch 34 loss 816.404541015625
Epoch 35 loss 686.5307006835938
Epoch 36 loss 646.1474609375
Epoch 37 loss 624.4055786132812
Epoch 38 loss 695.6293334960938
Epoch 39 loss 754.092041015625
Epoch 40 loss 662.7567138671875
Epoch 41 loss 630.3108520507812
Epoch 42 loss 644.5914306640625
Epoch 43 loss 574.3206176757812
Epoch 44 loss 582.9993286132812
Epoch 45 loss 603.18115234375
Epoch 46 loss 569.717041015625
Epoch 47 loss 658.0903930664062
Epoch 48 loss 535.1272583007812
Epoch 49 loss 611.3705444335938
Epoch 50 loss 535.6009521484375
Epoch 51 loss 525.3711547851562
Epoch 52 loss 505.756591796875
Epoch 53 loss 525.6068115234375
Epoch 54 loss 566.65869140625
Epoch 55 loss 496.0643310546875
Epoch 56 loss 555.1336669921875
Epoch 57 loss 581.848388671875
Epoch 58 loss 693.7206420898438
Epoch 59 loss 499.2855529785156
Epoch 60 loss 621.0709228515625
Epoch 61 loss 515.4693603515625
Epoch 62 loss 475.0229187011719
Epoch 63 loss 485.4825744628906
Epoch 64 loss 674.0364379882812
Epoch 65 loss 556.2706909179688
Epoch 66 loss 509.84454345703125
Epoch 67 loss 492.2828369140625
Epoch 68 loss 470.79296875
Epoch 69 loss 482.2764587402344
Epoch 70 loss 539.6159057617188
Epoch 71 loss 517.1802368164062
Epoch 72 loss 526.4378662109375
Epoch 73 loss 460.0592346191406
Epoch 74 loss 470.81024169921875
Epoch 75 loss 469.0199279785156
Epoch 76 loss 489.9409484863281
Epoch 77 loss 563.6104736328125
Epoch 78 loss 462.062744140625
Epoch 79 loss 496.01641845703125
Epoch 80 loss 529.6901245117188
Epoch 81 loss 702.7800903320312
Epoch 82 loss 471.5115966796875
Epoch 83 loss 548.5516967773438
Epoch 84 loss 506.2208557128906
Epoch 85 loss 469.6805725097656
Epoch 86 loss 645.8958740234375
Epoch 87 loss 465.0727844238281
Epoch 88 loss 481.6322937011719
Epoch 89 loss 662.7198486328125
Epoch 90 loss 478.5497131347656
Epoch 91 loss 500.4941711425781
Epoch 92 loss 497.7308044433594
Epoch 93 loss 474.72210693359375
Epoch 94 loss 498.5218200683594
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 489.5085768656049, 'MSE - std': 57.37960960054939, 'R2 - mean': 0.9423033970109156, 'R2 - std': 0.006868463009182773} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519470.71875
Epoch 1 loss 517332.1875
Epoch 2 loss 513933.25
Epoch 3 loss 508588.6875
Epoch 4 loss 500276.71875
Epoch 5 loss 483812.5
Epoch 6 loss 452312.625
Epoch 7 loss 400700.625
Epoch 8 loss 325646.09375
Epoch 9 loss 229322.0625
Epoch 10 loss 126979.3828125
Epoch 11 loss 46624.96484375
Epoch 12 loss 12105.419921875
Epoch 13 loss 8350.9921875
Epoch 14 loss 8133.57080078125
Epoch 15 loss 7974.46240234375
Epoch 16 loss 7482.67431640625
Epoch 17 loss 5321.9248046875
Epoch 18 loss 3479.9384765625
Epoch 19 loss 2316.763671875
Epoch 20 loss 1944.608154296875
Epoch 21 loss 1613.9674072265625
Epoch 22 loss 1475.4732666015625
Epoch 23 loss 1305.0765380859375
Epoch 24 loss 1120.784912109375
Epoch 25 loss 1059.9776611328125
Epoch 26 loss 959.159912109375
Epoch 27 loss 1130.6180419921875
Epoch 28 loss 899.9824829101562
Epoch 29 loss 855.8493041992188
Epoch 30 loss 790.1969604492188
Epoch 31 loss 872.7869262695312
Epoch 32 loss 789.2310791015625
Epoch 33 loss 765.9359741210938
Epoch 34 loss 896.4155883789062
Epoch 35 loss 693.377685546875
Epoch 36 loss 809.593017578125
Epoch 37 loss 679.1826171875
Epoch 38 loss 647.5103759765625
Epoch 39 loss 731.9398193359375
Epoch 40 loss 888.4669799804688
Epoch 41 loss 609.3590087890625
Epoch 42 loss 692.45166015625
Epoch 43 loss 1066.444580078125
Epoch 44 loss 603.1512451171875
Epoch 45 loss 863.1234130859375
Epoch 46 loss 602.4813232421875
Epoch 47 loss 710.35595703125
Epoch 48 loss 582.8021850585938
Epoch 49 loss 574.2785034179688
Epoch 50 loss 581.4235229492188
Epoch 51 loss 631.9829711914062
Epoch 52 loss 556.5013427734375
Epoch 53 loss 558.6090087890625
Epoch 54 loss 655.3917236328125
Epoch 55 loss 800.3594360351562
Epoch 56 loss 539.2394409179688
Epoch 57 loss 653.6473388671875
Epoch 58 loss 558.9932861328125
Epoch 59 loss 719.2794799804688
Epoch 60 loss 600.76806640625
Epoch 61 loss 529.3510131835938
Epoch 62 loss 530.2616577148438
Epoch 63 loss 569.0269165039062
Epoch 64 loss 592.6463623046875
Epoch 65 loss 782.9940185546875
Epoch 66 loss 565.8363647460938
Epoch 67 loss 517.5179443359375
Epoch 68 loss 535.9733276367188
Epoch 69 loss 555.0014038085938
Epoch 70 loss 534.5643310546875
Epoch 71 loss 501.2600402832031
Epoch 72 loss 566.3080444335938
Epoch 73 loss 538.5068969726562
Epoch 74 loss 544.76708984375
Epoch 75 loss 656.253662109375
Epoch 76 loss 514.3853149414062
Epoch 77 loss 548.5006713867188
Epoch 78 loss 538.460205078125
Epoch 79 loss 514.9705200195312
Epoch 80 loss 523.7542114257812
Epoch 81 loss 593.5613403320312
Epoch 82 loss 562.0175170898438
Epoch 83 loss 505.414306640625
Epoch 84 loss 548.3609619140625
Epoch 85 loss 589.0619506835938
Epoch 86 loss 536.47265625
Epoch 87 loss 494.6411437988281
Epoch 88 loss 541.241455078125
Epoch 89 loss 635.4242553710938
Epoch 90 loss 541.2086791992188
Epoch 91 loss 494.5340881347656
Epoch 92 loss 504.0661315917969
Epoch 93 loss 535.5339965820312
Epoch 94 loss 504.8215026855469
Epoch 95 loss 490.2805480957031
Epoch 96 loss 529.4105834960938
Epoch 97 loss 492.5953063964844
Epoch 98 loss 498.032470703125
Epoch 99 loss 485.062255859375
Saved Losses
{'MSE - mean': 488.3969964638328, 'MSE - std': 49.72948352237741, 'R2 - mean': 0.9421269402150974, 'R2 - std': 0.005956110230994336} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516774.1875
Epoch 1 loss 515031.46875
Epoch 2 loss 511966.59375
Epoch 3 loss 506738.1875
Epoch 4 loss 498382.875
Epoch 5 loss 482179.125
Epoch 6 loss 451067.46875
Epoch 7 loss 399110.1875
Epoch 8 loss 322542.96875
Epoch 9 loss 224634.78125
Epoch 10 loss 120932.109375
Epoch 11 loss 41991.17578125
Epoch 12 loss 10537.3671875
Epoch 13 loss 8159.09423828125
Epoch 14 loss 7756.0439453125
Epoch 15 loss 7430.11474609375
Epoch 16 loss 5872.98046875
Epoch 17 loss 3607.211181640625
Epoch 18 loss 2312.324951171875
Epoch 19 loss 1902.711181640625
Epoch 20 loss 1364.9420166015625
Epoch 21 loss 1225.65966796875
Epoch 22 loss 1063.0623779296875
Epoch 23 loss 1137.9169921875
Epoch 24 loss 952.1050415039062
Epoch 25 loss 887.0389404296875
Epoch 26 loss 861.5517578125
Epoch 27 loss 800.4320678710938
Epoch 28 loss 846.7699584960938
Epoch 29 loss 731.3988647460938
Epoch 30 loss 769.450927734375
Epoch 31 loss 702.6751708984375
Epoch 32 loss 665.6952514648438
Epoch 33 loss 664.7920532226562
Epoch 34 loss 672.8389892578125
Epoch 35 loss 628.531005859375
Epoch 36 loss 629.2301635742188
Epoch 37 loss 671.7078857421875
Epoch 38 loss 699.0706176757812
Epoch 39 loss 702.4407958984375
Epoch 40 loss 661.013427734375
Epoch 41 loss 609.8936767578125
Epoch 42 loss 655.69775390625
Epoch 43 loss 567.6991577148438
Epoch 44 loss 582.28515625
Epoch 45 loss 555.4132080078125
Epoch 46 loss 652.928955078125
Epoch 47 loss 539.7646484375
Epoch 48 loss 559.6015014648438
Epoch 49 loss 598.556884765625
Epoch 50 loss 553.7650756835938
Epoch 51 loss 603.7327270507812
Epoch 52 loss 538.9083251953125
Epoch 53 loss 539.9654541015625
Epoch 54 loss 540.9081420898438
Epoch 55 loss 540.5447998046875
Epoch 56 loss 566.258056640625
Epoch 57 loss 531.4171752929688
Epoch 58 loss 502.2292175292969
Epoch 59 loss 503.8642272949219
Epoch 60 loss 642.9034423828125
Epoch 61 loss 517.4822998046875
Epoch 62 loss 548.613525390625
Epoch 63 loss 530.5562744140625
Epoch 64 loss 504.5809631347656
Epoch 65 loss 507.4351501464844
Epoch 66 loss 523.3480224609375
Epoch 67 loss 494.1247863769531
Epoch 68 loss 491.0637512207031
Epoch 69 loss 527.9977416992188
Epoch 70 loss 491.3208923339844
Epoch 71 loss 490.48773193359375
Epoch 72 loss 496.5069580078125
Epoch 73 loss 475.7295837402344
Epoch 74 loss 509.8571472167969
Epoch 75 loss 500.77252197265625
Epoch 76 loss 755.04736328125
Epoch 77 loss 496.53680419921875
Epoch 78 loss 466.26007080078125
Epoch 79 loss 621.2037353515625
Epoch 80 loss 472.6024475097656
Epoch 81 loss 471.091796875
Epoch 82 loss 501.05670166015625
Epoch 83 loss 483.2801513671875
Epoch 84 loss 508.140869140625
Epoch 85 loss 485.24365234375
Epoch 86 loss 465.2406005859375
Epoch 87 loss 470.1869201660156
Epoch 88 loss 475.8759460449219
Epoch 89 loss 521.0172729492188
Epoch 90 loss 467.9527587890625
Epoch 91 loss 493.94110107421875
Epoch 92 loss 463.0571594238281
Epoch 93 loss 468.68048095703125
Epoch 94 loss 461.8840637207031
Epoch 95 loss 470.90728759765625
Epoch 96 loss 507.4654235839844
Epoch 97 loss 469.97393798828125
Epoch 98 loss 468.21612548828125
Epoch 99 loss 510.6815185546875
Saved Losses
{'MSE - mean': 483.0944715933376, 'MSE - std': 45.72618839495376, 'R2 - mean': 0.9421226550503334, 'R2 - std': 0.00532731383696817} 
 

Results After CV: {'MSE - mean': 483.0944715933376, 'MSE - std': 45.72618839495376, 'R2 - mean': 0.9421226550503334, 'R2 - std': 0.00532731383696817}
Train time: 93.4207444636002
Inference time: 0.1372245157999714
Finished cross validation
Trial 17 finished with value: 483.0944715933376 and parameters: {'dim': 128, 'depth': 2, 'heads': 4, 'dropout': 0.2}. Best is trial 16 with value: 478.0197831014686.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514890.28125
Epoch 1 loss 512578.46875
Epoch 2 loss 508781.75
Epoch 3 loss 503101.5625
Epoch 4 loss 494349.40625
Epoch 5 loss 476729.59375
Epoch 6 loss 444468.6875
Epoch 7 loss 392570.71875
Epoch 8 loss 317701.53125
Epoch 9 loss 223245.9375
Epoch 10 loss 123315.1640625
Epoch 11 loss 45479.9296875
Epoch 12 loss 12073.10546875
Epoch 13 loss 8729.61328125
Epoch 14 loss 8502.2548828125
Epoch 15 loss 8461.970703125
Epoch 16 loss 7582.22998046875
Epoch 17 loss 3949.616455078125
Epoch 18 loss 2776.1923828125
Epoch 19 loss 1905.695556640625
Epoch 20 loss 1770.377197265625
Epoch 21 loss 1388.7860107421875
Epoch 22 loss 1363.31982421875
Epoch 23 loss 1228.2542724609375
Epoch 24 loss 1277.4761962890625
Epoch 25 loss 989.2313232421875
Epoch 26 loss 930.3187255859375
Epoch 27 loss 968.6517944335938
Epoch 28 loss 862.2933959960938
Epoch 29 loss 965.41748046875
Epoch 30 loss 796.8709716796875
Epoch 31 loss 897.4961547851562
Epoch 32 loss 794.7442016601562
Epoch 33 loss 741.2520141601562
Epoch 34 loss 730.3543701171875
Epoch 35 loss 871.9071044921875
Epoch 36 loss 756.4282836914062
Epoch 37 loss 867.704345703125
Epoch 38 loss 747.143310546875
Epoch 39 loss 662.0921630859375
Epoch 40 loss 645.2265014648438
Epoch 41 loss 650.915771484375
Epoch 42 loss 697.9216918945312
Epoch 43 loss 769.7927856445312
Epoch 44 loss 1010.5625
Epoch 45 loss 618.03271484375
Epoch 46 loss 617.2752075195312
Epoch 47 loss 1089.6058349609375
Epoch 48 loss 726.6152954101562
Epoch 49 loss 630.8201904296875
Epoch 50 loss 604.4237060546875
Epoch 51 loss 604.7987060546875
Epoch 52 loss 593.8193359375
Epoch 53 loss 675.2118530273438
Epoch 54 loss 591.1768188476562
Epoch 55 loss 588.7635498046875
Epoch 56 loss 590.99560546875
Epoch 57 loss 649.6519165039062
Epoch 58 loss 626.1998901367188
Epoch 59 loss 614.99072265625
Epoch 60 loss 566.4649658203125
Epoch 61 loss 659.6806640625
Epoch 62 loss 703.4369506835938
Epoch 63 loss 568.0375366210938
Epoch 64 loss 584.0550537109375
Epoch 65 loss 576.1544799804688
Epoch 66 loss 568.307861328125
Epoch 67 loss 772.202392578125
Epoch 68 loss 567.5999755859375
Epoch 69 loss 580.6885375976562
Epoch 70 loss 602.7052001953125
Epoch 71 loss 707.5704956054688
Epoch 72 loss 595.671630859375
Epoch 73 loss 598.8631591796875
Epoch 74 loss 565.6937255859375
Epoch 75 loss 599.255126953125
Epoch 76 loss 572.388427734375
Epoch 77 loss 566.876953125
Epoch 78 loss 571.1334838867188
Epoch 79 loss 564.6859741210938
Epoch 80 loss 571.0484619140625
Epoch 81 loss 562.9671630859375
Epoch 82 loss 554.4617919921875
Epoch 83 loss 577.3131713867188
Epoch 84 loss 555.6403198242188
Epoch 85 loss 646.912841796875
Epoch 86 loss 568.7542114257812
Epoch 87 loss 645.6932373046875
Epoch 88 loss 606.3031616210938
Epoch 89 loss 631.3214721679688
Epoch 90 loss 549.7684936523438
Epoch 91 loss 574.9623413085938
Epoch 92 loss 634.2079467773438
Epoch 93 loss 564.2245483398438
Epoch 94 loss 604.9484252929688
Epoch 95 loss 558.0953369140625
Epoch 96 loss 572.92041015625
Epoch 97 loss 576.218994140625
Epoch 98 loss 598.2194213867188
Epoch 99 loss 583.8080444335938
Saved Losses
{'MSE - mean': 549.7686791526764, 'MSE - std': 0.0, 'R2 - mean': 0.9360778698884343, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520413.875
Epoch 1 loss 516599.15625
Epoch 2 loss 511243.15625
Epoch 3 loss 503456.40625
Epoch 4 loss 491592.40625
Epoch 5 loss 468534.09375
Epoch 6 loss 426891.40625
Epoch 7 loss 361938.9375
Epoch 8 loss 273196.0
Epoch 9 loss 170124.125
Epoch 10 loss 76086.390625
Epoch 11 loss 20764.93359375
Epoch 12 loss 7809.96240234375
Epoch 13 loss 7628.70068359375
Epoch 14 loss 7599.54541015625
Epoch 15 loss 7016.21142578125
Epoch 16 loss 4421.06396484375
Epoch 17 loss 2716.352783203125
Epoch 18 loss 1938.1890869140625
Epoch 19 loss 1617.5101318359375
Epoch 20 loss 1355.3458251953125
Epoch 21 loss 1146.8974609375
Epoch 22 loss 1055.3433837890625
Epoch 23 loss 960.3294677734375
Epoch 24 loss 998.915283203125
Epoch 25 loss 830.6622314453125
Epoch 26 loss 786.4290161132812
Epoch 27 loss 981.4837646484375
Epoch 28 loss 691.74658203125
Epoch 29 loss 714.9573364257812
Epoch 30 loss 679.2936401367188
Epoch 31 loss 617.5009155273438
Epoch 32 loss 609.681884765625
Epoch 33 loss 609.5393676757812
Epoch 34 loss 585.522216796875
Epoch 35 loss 551.74560546875
Epoch 36 loss 629.3023681640625
Epoch 37 loss 546.8342895507812
Epoch 38 loss 571.6812744140625
Epoch 39 loss 590.2075805664062
Epoch 40 loss 649.45361328125
Epoch 41 loss 646.5827026367188
Epoch 42 loss 529.5467529296875
Epoch 43 loss 563.4295654296875
Epoch 44 loss 499.7003479003906
Epoch 45 loss 488.9328308105469
Epoch 46 loss 486.2279968261719
Epoch 47 loss 540.95654296875
Epoch 48 loss 501.475341796875
Epoch 49 loss 473.7940673828125
Epoch 50 loss 500.0982666015625
Epoch 51 loss 510.9295959472656
Epoch 52 loss 483.3064270019531
Epoch 53 loss 595.5280151367188
Epoch 54 loss 717.0882568359375
Epoch 55 loss 471.4093933105469
Epoch 56 loss 519.280517578125
Epoch 57 loss 472.6204833984375
Epoch 58 loss 510.4627990722656
Epoch 59 loss 464.35321044921875
Epoch 60 loss 495.3046875
Epoch 61 loss 545.1028442382812
Epoch 62 loss 476.90362548828125
Epoch 63 loss 493.74578857421875
Epoch 64 loss 450.21893310546875
Epoch 65 loss 476.7890625
Epoch 66 loss 470.7938537597656
Epoch 67 loss 515.5577392578125
Epoch 68 loss 447.9879150390625
Epoch 69 loss 461.04486083984375
Epoch 70 loss 474.671875
Epoch 71 loss 516.2950439453125
Epoch 72 loss 548.2349853515625
Epoch 73 loss 514.0537109375
Epoch 74 loss 489.01263427734375
Epoch 75 loss 453.5317077636719
Epoch 76 loss 448.3630065917969
Epoch 77 loss 489.4064025878906
Epoch 78 loss 470.42974853515625
Epoch 79 loss 469.49127197265625
Epoch 80 loss 470.6436767578125
Epoch 81 loss 452.5126037597656
Epoch 82 loss 449.4311218261719
Epoch 83 loss 451.8246765136719
Epoch 84 loss 449.7456970214844
Epoch 85 loss 499.0229187011719
Epoch 86 loss 459.8186340332031
Epoch 87 loss 463.16400146484375
Epoch 88 loss 463.03167724609375
Epoch 89 loss 457.7424621582031
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 498.8784343931251, 'MSE - std': 50.890244759551365, 'R2 - mean': 0.9387221604065563, 'R2 - std': 0.002644290518122039} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516430.625
Epoch 1 loss 514217.53125
Epoch 2 loss 510596.15625
Epoch 3 loss 505260.03125
Epoch 4 loss 496884.625
Epoch 5 loss 480076.8125
Epoch 6 loss 448534.09375
Epoch 7 loss 396805.59375
Epoch 8 loss 321035.125
Epoch 9 loss 224268.609375
Epoch 10 loss 122762.3828125
Epoch 11 loss 44689.4375
Epoch 12 loss 12348.3251953125
Epoch 13 loss 9423.53515625
Epoch 14 loss 9293.1005859375
Epoch 15 loss 9232.9970703125
Epoch 16 loss 8762.708984375
Epoch 17 loss 5619.1123046875
Epoch 18 loss 3260.78466796875
Epoch 19 loss 2185.875
Epoch 20 loss 1697.7625732421875
Epoch 21 loss 1487.933837890625
Epoch 22 loss 1298.6419677734375
Epoch 23 loss 1062.060791015625
Epoch 24 loss 942.9491577148438
Epoch 25 loss 854.8866577148438
Epoch 26 loss 839.4485473632812
Epoch 27 loss 763.2607421875
Epoch 28 loss 722.0204467773438
Epoch 29 loss 680.6921997070312
Epoch 30 loss 712.5538940429688
Epoch 31 loss 662.2747192382812
Epoch 32 loss 723.5834350585938
Epoch 33 loss 669.6127319335938
Epoch 34 loss 584.6052856445312
Epoch 35 loss 589.8944091796875
Epoch 36 loss 559.0377197265625
Epoch 37 loss 587.678955078125
Epoch 38 loss 649.1149291992188
Epoch 39 loss 844.301025390625
Epoch 40 loss 598.6329956054688
Epoch 41 loss 524.1316528320312
Epoch 42 loss 549.5179443359375
Epoch 43 loss 527.7529296875
Epoch 44 loss 509.257080078125
Epoch 45 loss 523.73291015625
Epoch 46 loss 541.8595581054688
Epoch 47 loss 490.8142395019531
Epoch 48 loss 478.677734375
Epoch 49 loss 580.8939208984375
Epoch 50 loss 558.6065673828125
Epoch 51 loss 646.46337890625
Epoch 52 loss 488.3326416015625
Epoch 53 loss 497.82159423828125
Epoch 54 loss 502.5713806152344
Epoch 55 loss 570.5203247070312
Epoch 56 loss 454.2680969238281
Epoch 57 loss 509.366455078125
Epoch 58 loss 556.129150390625
Epoch 59 loss 488.1856384277344
Epoch 60 loss 462.89080810546875
Epoch 61 loss 472.0916442871094
Epoch 62 loss 459.7880859375
Epoch 63 loss 478.6430358886719
Epoch 64 loss 472.2084655761719
Epoch 65 loss 621.90087890625
Epoch 66 loss 637.2711791992188
Epoch 67 loss 438.28936767578125
Epoch 68 loss 449.0846862792969
Epoch 69 loss 449.3448181152344
Epoch 70 loss 454.7847595214844
Epoch 71 loss 449.6712646484375
Epoch 72 loss 517.2853393554688
Epoch 73 loss 477.54241943359375
Epoch 74 loss 444.16119384765625
Epoch 75 loss 444.50152587890625
Epoch 76 loss 443.70745849609375
Epoch 77 loss 464.4374084472656
Epoch 78 loss 473.6686706542969
Epoch 79 loss 456.9545593261719
Epoch 80 loss 441.2137145996094
Epoch 81 loss 468.137939453125
Epoch 82 loss 479.3896789550781
Epoch 83 loss 449.45013427734375
Epoch 84 loss 441.9060363769531
Epoch 85 loss 616.060302734375
Epoch 86 loss 448.96441650390625
Epoch 87 loss 452.3966979980469
Epoch 88 loss 609.42578125
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 478.6822111592349, 'MSE - std': 50.421419459236546, 'R2 - mean': 0.9434530295373301, 'R2 - std': 0.007030203436684468} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518702.03125
Epoch 1 loss 516141.40625
Epoch 2 loss 512030.0625
Epoch 3 loss 505647.3125
Epoch 4 loss 495761.53125
Epoch 5 loss 475847.0
Epoch 6 loss 439475.4375
Epoch 7 loss 381587.375
Epoch 8 loss 300022.15625
Epoch 9 loss 200339.90625
Epoch 10 loss 101365.4765625
Epoch 11 loss 33160.4296875
Epoch 12 loss 9527.939453125
Epoch 13 loss 8473.6142578125
Epoch 14 loss 8156.2841796875
Epoch 15 loss 7924.99462890625
Epoch 16 loss 6177.62646484375
Epoch 17 loss 3471.23779296875
Epoch 18 loss 2236.4755859375
Epoch 19 loss 1815.7213134765625
Epoch 20 loss 1586.839111328125
Epoch 21 loss 1364.1024169921875
Epoch 22 loss 1348.548095703125
Epoch 23 loss 1126.081787109375
Epoch 24 loss 1057.33154296875
Epoch 25 loss 1090.635498046875
Epoch 26 loss 1128.38916015625
Epoch 27 loss 969.9299926757812
Epoch 28 loss 813.1586303710938
Epoch 29 loss 777.7716674804688
Epoch 30 loss 1295.0458984375
Epoch 31 loss 730.7738037109375
Epoch 32 loss 769.038818359375
Epoch 33 loss 730.3941040039062
Epoch 34 loss 653.1676025390625
Epoch 35 loss 733.2427978515625
Epoch 36 loss 636.28662109375
Epoch 37 loss 649.8128662109375
Epoch 38 loss 750.1566162109375
Epoch 39 loss 670.4517211914062
Epoch 40 loss 863.0147094726562
Epoch 41 loss 614.3895874023438
Epoch 42 loss 618.4400634765625
Epoch 43 loss 586.92626953125
Epoch 44 loss 852.9110717773438
Epoch 45 loss 562.9854736328125
Epoch 46 loss 650.5243530273438
Epoch 47 loss 551.531005859375
Epoch 48 loss 598.4431762695312
Epoch 49 loss 592.3738403320312
Epoch 50 loss 615.7958374023438
Epoch 51 loss 549.0107421875
Epoch 52 loss 549.109130859375
Epoch 53 loss 546.53173828125
Epoch 54 loss 611.9342651367188
Epoch 55 loss 545.1207885742188
Epoch 56 loss 525.4422607421875
Epoch 57 loss 681.9567260742188
Epoch 58 loss 618.60400390625
Epoch 59 loss 511.5455322265625
Epoch 60 loss 501.34228515625
Epoch 61 loss 582.1385498046875
Epoch 62 loss 676.3543701171875
Epoch 63 loss 617.1243286132812
Epoch 64 loss 506.6963806152344
Epoch 65 loss 506.9076843261719
Epoch 66 loss 525.0736083984375
Epoch 67 loss 532.2052612304688
Epoch 68 loss 545.018798828125
Epoch 69 loss 592.4216918945312
Epoch 70 loss 513.4893798828125
Epoch 71 loss 645.5612182617188
Epoch 72 loss 519.4191284179688
Epoch 73 loss 499.0013732910156
Epoch 74 loss 547.1627197265625
Epoch 75 loss 636.9111938476562
Epoch 76 loss 518.7633666992188
Epoch 77 loss 518.3760986328125
Epoch 78 loss 507.24462890625
Epoch 79 loss 613.60009765625
Epoch 80 loss 549.6473388671875
Epoch 81 loss 503.55322265625
Epoch 82 loss 493.5429382324219
Epoch 83 loss 550.172119140625
Epoch 84 loss 509.6014709472656
Epoch 85 loss 483.5140686035156
Epoch 86 loss 477.8595886230469
Epoch 87 loss 493.4535827636719
Epoch 88 loss 484.333984375
Epoch 89 loss 491.2431640625
Epoch 90 loss 614.0787353515625
Epoch 91 loss 499.18853759765625
Epoch 92 loss 481.18634033203125
Epoch 93 loss 477.741943359375
Epoch 94 loss 669.7555541992188
Epoch 95 loss 473.2046813964844
Epoch 96 loss 637.8665771484375
Epoch 97 loss 509.70562744140625
Epoch 98 loss 494.8761901855469
Epoch 99 loss 704.8387451171875
Saved Losses
{'MSE - mean': 477.3128851108305, 'MSE - std': 43.73059360097603, 'R2 - mean': 0.9433460765053392, 'R2 - std': 0.00609115236421104} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515161.40625
Epoch 1 loss 512395.21875
Epoch 2 loss 508232.96875
Epoch 3 loss 502292.625
Epoch 4 loss 493509.5625
Epoch 5 loss 475690.1875
Epoch 6 loss 442064.71875
Epoch 7 loss 387343.375
Epoch 8 loss 308659.40625
Epoch 9 loss 210346.265625
Epoch 10 loss 109759.5234375
Epoch 11 loss 36733.51953125
Epoch 12 loss 9752.9365234375
Epoch 13 loss 8210.310546875
Epoch 14 loss 7839.92529296875
Epoch 15 loss 7638.1572265625
Epoch 16 loss 6682.505859375
Epoch 17 loss 3492.93310546875
Epoch 18 loss 2404.337890625
Epoch 19 loss 1869.0430908203125
Epoch 20 loss 1626.4229736328125
Epoch 21 loss 1291.614501953125
Epoch 22 loss 1206.4571533203125
Epoch 23 loss 1095.7940673828125
Epoch 24 loss 1211.77197265625
Epoch 25 loss 923.1555786132812
Epoch 26 loss 992.255126953125
Epoch 27 loss 840.4566650390625
Epoch 28 loss 815.8386840820312
Epoch 29 loss 778.3333129882812
Epoch 30 loss 773.8257446289062
Epoch 31 loss 724.7152099609375
Epoch 32 loss 735.8931884765625
Epoch 33 loss 668.33251953125
Epoch 34 loss 981.9801635742188
Epoch 35 loss 892.2713012695312
Epoch 36 loss 643.8948364257812
Epoch 37 loss 620.5936279296875
Epoch 38 loss 598.9329223632812
Epoch 39 loss 739.4351806640625
Epoch 40 loss 591.1224365234375
Epoch 41 loss 568.6918334960938
Epoch 42 loss 641.9790649414062
Epoch 43 loss 564.594482421875
Epoch 44 loss 545.6940307617188
Epoch 45 loss 552.9867553710938
Epoch 46 loss 525.5739135742188
Epoch 47 loss 537.0138549804688
Epoch 48 loss 555.8491821289062
Epoch 49 loss 521.8525390625
Epoch 50 loss 563.8024291992188
Epoch 51 loss 510.8495178222656
Epoch 52 loss 519.9456787109375
Epoch 53 loss 610.2569580078125
Epoch 54 loss 510.4900207519531
Epoch 55 loss 511.51483154296875
Epoch 56 loss 555.8338012695312
Epoch 57 loss 521.6773681640625
Epoch 58 loss 510.9942626953125
Epoch 59 loss 632.1699829101562
Epoch 60 loss 549.6229248046875
Epoch 61 loss 515.6636352539062
Epoch 62 loss 517.5655517578125
Epoch 63 loss 478.057373046875
Epoch 64 loss 479.94256591796875
Epoch 65 loss 568.3956909179688
Epoch 66 loss 492.6881103515625
Epoch 67 loss 526.0399780273438
Epoch 68 loss 522.3818359375
Epoch 69 loss 641.7265625
Epoch 70 loss 475.9995422363281
Epoch 71 loss 485.65081787109375
Epoch 72 loss 525.1443481445312
Epoch 73 loss 473.4007873535156
Epoch 74 loss 520.5633544921875
Epoch 75 loss 486.94451904296875
Epoch 76 loss 463.52813720703125
Epoch 77 loss 465.1396789550781
Epoch 78 loss 459.3990478515625
Epoch 79 loss 490.53717041015625
Epoch 80 loss 558.9923706054688
Epoch 81 loss 483.4073486328125
Epoch 82 loss 537.3970947265625
Epoch 83 loss 506.9165954589844
Epoch 84 loss 466.8056945800781
Epoch 85 loss 481.7281188964844
Epoch 86 loss 485.52288818359375
Epoch 87 loss 502.18658447265625
Epoch 88 loss 499.657958984375
Epoch 89 loss 484.1495666503906
Epoch 90 loss 468.7243347167969
Epoch 91 loss 471.7093200683594
Epoch 92 loss 500.6343688964844
Epoch 93 loss 481.6357421875
Epoch 94 loss 716.8811645507812
Epoch 95 loss 466.2030944824219
Epoch 96 loss 525.6917724609375
Epoch 97 loss 454.8305358886719
Epoch 98 loss 474.3469543457031
Epoch 99 loss 532.7153930664062
Saved Losses
{'MSE - mean': 472.816397197097, 'MSE - std': 40.134342745190004, 'R2 - mean': 0.9432747977122851, 'R2 - std': 0.005449957097499393} 
 

Results After CV: {'MSE - mean': 472.816397197097, 'MSE - std': 40.134342745190004, 'R2 - mean': 0.9432747977122851, 'R2 - std': 0.005449957097499393}
Train time: 97.82926175800021
Inference time: 0.13567273059998114
Finished cross validation
Trial 18 finished with value: 472.816397197097 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.2}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515104.78125
Epoch 1 loss 513245.6875
Epoch 2 loss 510075.96875
Epoch 3 loss 504823.84375
Epoch 4 loss 497167.6875
Epoch 5 loss 482827.21875
Epoch 6 loss 455021.21875
Epoch 7 loss 407551.0
Epoch 8 loss 336395.46875
Epoch 9 loss 242631.578125
Epoch 10 loss 139415.328125
Epoch 11 loss 54819.59765625
Epoch 12 loss 14052.6240234375
Epoch 13 loss 8644.2509765625
Epoch 14 loss 8674.162109375
Epoch 15 loss 8594.7001953125
Epoch 16 loss 8156.1220703125
Epoch 17 loss 6227.4150390625
Epoch 18 loss 3945.3408203125
Epoch 19 loss 2490.02294921875
Epoch 20 loss 1862.604248046875
Epoch 21 loss 1635.8292236328125
Epoch 22 loss 1301.219970703125
Epoch 23 loss 1151.2596435546875
Epoch 24 loss 1279.8861083984375
Epoch 25 loss 992.9806518554688
Epoch 26 loss 935.2528076171875
Epoch 27 loss 943.5527954101562
Epoch 28 loss 953.8628540039062
Epoch 29 loss 814.1824340820312
Epoch 30 loss 771.3889770507812
Epoch 31 loss 779.6986694335938
Epoch 32 loss 721.0131225585938
Epoch 33 loss 786.2259521484375
Epoch 34 loss 773.6798095703125
Epoch 35 loss 882.4801025390625
Epoch 36 loss 755.4979858398438
Epoch 37 loss 679.0636596679688
Epoch 38 loss 659.1996459960938
Epoch 39 loss 660.7762451171875
Epoch 40 loss 645.6189575195312
Epoch 41 loss 656.1079711914062
Epoch 42 loss 632.6727294921875
Epoch 43 loss 673.524169921875
Epoch 44 loss 726.105224609375
Epoch 45 loss 649.3609619140625
Epoch 46 loss 885.1866455078125
Epoch 47 loss 736.0753173828125
Epoch 48 loss 639.774658203125
Epoch 49 loss 631.6429443359375
Epoch 50 loss 617.6231689453125
Epoch 51 loss 641.905517578125
Epoch 52 loss 614.2583618164062
Epoch 53 loss 590.0847778320312
Epoch 54 loss 632.6371459960938
Epoch 55 loss 597.1118774414062
Epoch 56 loss 632.5116577148438
Epoch 57 loss 643.2603759765625
Epoch 58 loss 583.0116577148438
Epoch 59 loss 688.9700317382812
Epoch 60 loss 615.3958740234375
Epoch 61 loss 600.4205322265625
Epoch 62 loss 590.63232421875
Epoch 63 loss 564.0604858398438
Epoch 64 loss 560.07568359375
Epoch 65 loss 600.989013671875
Epoch 66 loss 572.3681030273438
Epoch 67 loss 750.350830078125
Epoch 68 loss 596.1555786132812
Epoch 69 loss 621.9679565429688
Epoch 70 loss 615.276611328125
Epoch 71 loss 554.4862060546875
Epoch 72 loss 592.738525390625
Epoch 73 loss 565.6100463867188
Epoch 74 loss 580.0560913085938
Epoch 75 loss 572.3631591796875
Epoch 76 loss 720.9722900390625
Epoch 77 loss 615.0252075195312
Epoch 78 loss 649.4642333984375
Epoch 79 loss 565.569091796875
Epoch 80 loss 581.1917724609375
Epoch 81 loss 687.7681274414062
Epoch 82 loss 563.3339233398438
Epoch 83 loss 553.0209350585938
Epoch 84 loss 604.2423706054688
Epoch 85 loss 621.4237060546875
Epoch 86 loss 560.6561279296875
Epoch 87 loss 573.6996459960938
Epoch 88 loss 663.849853515625
Epoch 89 loss 586.6077880859375
Epoch 90 loss 558.1912841796875
Epoch 91 loss 560.9437255859375
Epoch 92 loss 579.5189208984375
Epoch 93 loss 559.2971801757812
Epoch 94 loss 939.3627319335938
Epoch 95 loss 566.885009765625
Epoch 96 loss 547.9635009765625
Epoch 97 loss 628.7845458984375
Epoch 98 loss 626.1421508789062
Epoch 99 loss 619.2913208007812
Saved Losses
{'MSE - mean': 547.9632258815653, 'MSE - std': 0.0, 'R2 - mean': 0.9362877916669616, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522517.375
Epoch 1 loss 519687.375
Epoch 2 loss 515482.15625
Epoch 3 loss 509341.28125
Epoch 4 loss 500138.8125
Epoch 5 loss 481516.90625
Epoch 6 loss 446926.96875
Epoch 7 loss 391504.46875
Epoch 8 loss 312730.625
Epoch 9 loss 215107.796875
Epoch 10 loss 115427.109375
Epoch 11 loss 40990.8359375
Epoch 12 loss 10861.091796875
Epoch 13 loss 7660.3994140625
Epoch 14 loss 7562.80322265625
Epoch 15 loss 7398.84130859375
Epoch 16 loss 6627.20751953125
Epoch 17 loss 3534.367431640625
Epoch 18 loss 2470.388671875
Epoch 19 loss 1890.36376953125
Epoch 20 loss 1558.5592041015625
Epoch 21 loss 1322.572021484375
Epoch 22 loss 1233.8380126953125
Epoch 23 loss 1029.5433349609375
Epoch 24 loss 998.505859375
Epoch 25 loss 903.380615234375
Epoch 26 loss 780.0339965820312
Epoch 27 loss 759.0413818359375
Epoch 28 loss 695.0121459960938
Epoch 29 loss 784.1405639648438
Epoch 30 loss 1033.2786865234375
Epoch 31 loss 819.527099609375
Epoch 32 loss 637.6412963867188
Epoch 33 loss 585.0642700195312
Epoch 34 loss 601.608154296875
Epoch 35 loss 575.059326171875
Epoch 36 loss 586.2808837890625
Epoch 37 loss 541.6512451171875
Epoch 38 loss 528.2161254882812
Epoch 39 loss 565.8786010742188
Epoch 40 loss 734.0357666015625
Epoch 41 loss 532.4226684570312
Epoch 42 loss 535.3934936523438
Epoch 43 loss 504.8303527832031
Epoch 44 loss 563.6107177734375
Epoch 45 loss 515.5201416015625
Epoch 46 loss 493.293212890625
Epoch 47 loss 511.51708984375
Epoch 48 loss 530.1132202148438
Epoch 49 loss 593.6328125
Epoch 50 loss 516.2852783203125
Epoch 51 loss 474.94580078125
Epoch 52 loss 548.1058349609375
Epoch 53 loss 472.57940673828125
Epoch 54 loss 507.1376647949219
Epoch 55 loss 556.3692626953125
Epoch 56 loss 854.8521728515625
Epoch 57 loss 493.6344909667969
Epoch 58 loss 469.7383728027344
Epoch 59 loss 526.7440795898438
Epoch 60 loss 449.8439636230469
Epoch 61 loss 458.5145568847656
Epoch 62 loss 499.94622802734375
Epoch 63 loss 445.56829833984375
Epoch 64 loss 449.5041198730469
Epoch 65 loss 479.6485595703125
Epoch 66 loss 521.2442016601562
Epoch 67 loss 490.4753112792969
Epoch 68 loss 447.8089599609375
Epoch 69 loss 505.3392333984375
Epoch 70 loss 443.5177001953125
Epoch 71 loss 456.82598876953125
Epoch 72 loss 443.1141662597656
Epoch 73 loss 529.1697998046875
Epoch 74 loss 438.3299560546875
Epoch 75 loss 434.640869140625
Epoch 76 loss 444.4587707519531
Epoch 77 loss 430.56317138671875
Epoch 78 loss 432.96356201171875
Epoch 79 loss 489.4524230957031
Epoch 80 loss 471.49249267578125
Epoch 81 loss 444.31182861328125
Epoch 82 loss 532.1214599609375
Epoch 83 loss 456.9898376464844
Epoch 84 loss 445.6117248535156
Epoch 85 loss 481.7759094238281
Epoch 86 loss 432.6717529296875
Epoch 87 loss 458.5574645996094
Epoch 88 loss 534.8373413085938
Epoch 89 loss 433.9730529785156
Epoch 90 loss 438.6273193359375
Epoch 91 loss 472.6860656738281
Epoch 92 loss 438.14532470703125
Epoch 93 loss 527.8318481445312
Epoch 94 loss 522.5494384765625
Epoch 95 loss 493.1568603515625
Epoch 96 loss 496.65631103515625
Epoch 97 loss 488.43011474609375
Epoch 98 loss 534.5802612304688
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 489.26316953117885, 'MSE - std': 58.70005635038652, 'R2 - mean': 0.939967434923475, 'R2 - std': 0.003679643256513432} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515703.90625
Epoch 1 loss 513001.53125
Epoch 2 loss 508840.5625
Epoch 3 loss 502789.375
Epoch 4 loss 493834.5625
Epoch 5 loss 475746.03125
Epoch 6 loss 441741.375
Epoch 7 loss 387156.34375
Epoch 8 loss 309090.71875
Epoch 9 loss 212055.53125
Epoch 10 loss 112428.2578125
Epoch 11 loss 39217.1328125
Epoch 12 loss 11324.8916015625
Epoch 13 loss 9527.689453125
Epoch 14 loss 9151.7109375
Epoch 15 loss 8951.5908203125
Epoch 16 loss 7757.466796875
Epoch 17 loss 3882.779052734375
Epoch 18 loss 2532.35205078125
Epoch 19 loss 1839.36474609375
Epoch 20 loss 1587.9122314453125
Epoch 21 loss 1414.9920654296875
Epoch 22 loss 1199.415283203125
Epoch 23 loss 1148.9671630859375
Epoch 24 loss 994.9619750976562
Epoch 25 loss 927.4345703125
Epoch 26 loss 856.3034057617188
Epoch 27 loss 819.063232421875
Epoch 28 loss 763.4527587890625
Epoch 29 loss 753.7897338867188
Epoch 30 loss 706.3622436523438
Epoch 31 loss 674.2186889648438
Epoch 32 loss 697.4970092773438
Epoch 33 loss 688.1180419921875
Epoch 34 loss 721.6920166015625
Epoch 35 loss 758.3229370117188
Epoch 36 loss 614.462646484375
Epoch 37 loss 897.1085815429688
Epoch 38 loss 670.8567504882812
Epoch 39 loss 554.7506103515625
Epoch 40 loss 563.4773559570312
Epoch 41 loss 624.5490112304688
Epoch 42 loss 605.078125
Epoch 43 loss 567.0104370117188
Epoch 44 loss 540.6578979492188
Epoch 45 loss 576.3414916992188
Epoch 46 loss 558.4722900390625
Epoch 47 loss 551.6433715820312
Epoch 48 loss 506.966064453125
Epoch 49 loss 501.09979248046875
Epoch 50 loss 513.0858764648438
Epoch 51 loss 511.9938049316406
Epoch 52 loss 505.4936828613281
Epoch 53 loss 496.917724609375
Epoch 54 loss 496.13800048828125
Epoch 55 loss 511.5379638671875
Epoch 56 loss 511.6888732910156
Epoch 57 loss 512.7706909179688
Epoch 58 loss 494.3137512207031
Epoch 59 loss 524.6775512695312
Epoch 60 loss 493.4761047363281
Epoch 61 loss 540.2295532226562
Epoch 62 loss 655.5578002929688
Epoch 63 loss 488.2330017089844
Epoch 64 loss 511.73956298828125
Epoch 65 loss 494.6885070800781
Epoch 66 loss 492.4733581542969
Epoch 67 loss 502.8250427246094
Epoch 68 loss 496.3587951660156
Epoch 69 loss 551.5253295898438
Epoch 70 loss 486.2252502441406
Epoch 71 loss 517.0455322265625
Epoch 72 loss 519.3494873046875
Epoch 73 loss 504.2417297363281
Epoch 74 loss 505.4829406738281
Epoch 75 loss 547.810546875
Epoch 76 loss 516.5400390625
Epoch 77 loss 485.0892028808594
Epoch 78 loss 527.7073364257812
Epoch 79 loss 713.778076171875
Epoch 80 loss 491.0252685546875
Epoch 81 loss 512.7847900390625
Epoch 82 loss 508.2123107910156
Epoch 83 loss 482.86114501953125
Epoch 84 loss 479.3751220703125
Epoch 85 loss 560.6005859375
Epoch 86 loss 488.20782470703125
Epoch 87 loss 496.41180419921875
Epoch 88 loss 478.10821533203125
Epoch 89 loss 474.2381896972656
Epoch 90 loss 477.9134216308594
Epoch 91 loss 542.2509155273438
Epoch 92 loss 540.010986328125
Epoch 93 loss 488.4098815917969
Epoch 94 loss 650.4198608398438
Epoch 95 loss 480.714599609375
Epoch 96 loss 471.45855712890625
Epoch 97 loss 476.8981018066406
Epoch 98 loss 499.7763977050781
Epoch 99 loss 567.3240966796875
Saved Losses
{'MSE - mean': 483.3282807598645, 'MSE - std': 48.65775258354468, 'R2 - mean': 0.9430954460060769, 'R2 - std': 0.005347468840105228} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519296.375
Epoch 1 loss 517136.75
Epoch 2 loss 513284.125
Epoch 3 loss 507064.9375
Epoch 4 loss 496936.6875
Epoch 5 loss 476553.21875
Epoch 6 loss 439421.90625
Epoch 7 loss 380429.84375
Epoch 8 loss 297421.78125
Epoch 9 loss 196801.390625
Epoch 10 loss 98278.1484375
Epoch 11 loss 31462.87890625
Epoch 12 loss 9486.205078125
Epoch 13 loss 8470.6806640625
Epoch 14 loss 8263.0673828125
Epoch 15 loss 7896.931640625
Epoch 16 loss 6237.8916015625
Epoch 17 loss 3245.933349609375
Epoch 18 loss 2189.7724609375
Epoch 19 loss 1822.8416748046875
Epoch 20 loss 1510.556884765625
Epoch 21 loss 1335.133544921875
Epoch 22 loss 1316.2474365234375
Epoch 23 loss 1159.306396484375
Epoch 24 loss 1030.547607421875
Epoch 25 loss 995.5853271484375
Epoch 26 loss 903.3279418945312
Epoch 27 loss 879.8728637695312
Epoch 28 loss 894.3607177734375
Epoch 29 loss 874.319091796875
Epoch 30 loss 771.4960327148438
Epoch 31 loss 796.8114624023438
Epoch 32 loss 782.8173217773438
Epoch 33 loss 848.9107055664062
Epoch 34 loss 889.6104125976562
Epoch 35 loss 655.6923217773438
Epoch 36 loss 771.7217407226562
Epoch 37 loss 695.0298461914062
Epoch 38 loss 630.4754638671875
Epoch 39 loss 662.650146484375
Epoch 40 loss 763.3001708984375
Epoch 41 loss 1010.2664794921875
Epoch 42 loss 743.2857666015625
Epoch 43 loss 801.1897583007812
Epoch 44 loss 613.125
Epoch 45 loss 821.7943115234375
Epoch 46 loss 708.114990234375
Epoch 47 loss 692.0752563476562
Epoch 48 loss 615.3095703125
Epoch 49 loss 651.4890747070312
Epoch 50 loss 629.9271850585938
Epoch 51 loss 652.6544189453125
Epoch 52 loss 585.8644409179688
Epoch 53 loss 641.1586303710938
Epoch 54 loss 563.8602905273438
Epoch 55 loss 603.7191772460938
Epoch 56 loss 566.5765991210938
Epoch 57 loss 611.2025146484375
Epoch 58 loss 540.5574951171875
Epoch 59 loss 660.5169677734375
Epoch 60 loss 581.1653442382812
Epoch 61 loss 708.2236938476562
Epoch 62 loss 582.7501831054688
Epoch 63 loss 576.6115112304688
Epoch 64 loss 566.9292602539062
Epoch 65 loss 609.2552490234375
Epoch 66 loss 547.01904296875
Epoch 67 loss 539.15185546875
Epoch 68 loss 624.9371337890625
Epoch 69 loss 527.4661865234375
Epoch 70 loss 546.8533325195312
Epoch 71 loss 575.6054077148438
Epoch 72 loss 557.2921752929688
Epoch 73 loss 529.3292236328125
Epoch 74 loss 590.78173828125
Epoch 75 loss 555.6297607421875
Epoch 76 loss 687.835693359375
Epoch 77 loss 549.4725341796875
Epoch 78 loss 639.9730224609375
Epoch 79 loss 529.4559936523438
Epoch 80 loss 539.0179443359375
Epoch 81 loss 616.6563110351562
Epoch 82 loss 518.0827026367188
Epoch 83 loss 526.7944946289062
Epoch 84 loss 594.028564453125
Epoch 85 loss 507.2029113769531
Epoch 86 loss 507.7940673828125
Epoch 87 loss 569.2779541015625
Epoch 88 loss 491.69091796875
Epoch 89 loss 766.1446533203125
Epoch 90 loss 555.2739868164062
Epoch 91 loss 521.6936645507812
Epoch 92 loss 508.37225341796875
Epoch 93 loss 529.8594970703125
Epoch 94 loss 497.2801513671875
Epoch 95 loss 509.0528259277344
Epoch 96 loss 636.1243286132812
Epoch 97 loss 509.2859802246094
Epoch 98 loss 543.7406616210938
Epoch 99 loss 558.5494995117188
Saved Losses
{'MSE - mean': 485.41900593382934, 'MSE - std': 42.294161064149705, 'R2 - mean': 0.9425214430897059, 'R2 - std': 0.004736560491636259} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516021.09375
Epoch 1 loss 513904.59375
Epoch 2 loss 510443.875
Epoch 3 loss 504964.34375
Epoch 4 loss 496544.4375
Epoch 5 loss 479735.78125
Epoch 6 loss 447834.84375
Epoch 7 loss 395022.53125
Epoch 8 loss 317602.75
Epoch 9 loss 219160.1875
Epoch 10 loss 116174.15625
Epoch 11 loss 39632.015625
Epoch 12 loss 10123.6279296875
Epoch 13 loss 8181.2080078125
Epoch 14 loss 7826.16259765625
Epoch 15 loss 7554.244140625
Epoch 16 loss 5461.17333984375
Epoch 17 loss 2972.189453125
Epoch 18 loss 2192.271728515625
Epoch 19 loss 1586.3858642578125
Epoch 20 loss 1258.169189453125
Epoch 21 loss 1091.10791015625
Epoch 22 loss 972.5986938476562
Epoch 23 loss 974.112060546875
Epoch 24 loss 847.766845703125
Epoch 25 loss 813.6519165039062
Epoch 26 loss 772.2185668945312
Epoch 27 loss 833.6494750976562
Epoch 28 loss 716.739013671875
Epoch 29 loss 669.4820556640625
Epoch 30 loss 649.4381103515625
Epoch 31 loss 650.91943359375
Epoch 32 loss 689.4391479492188
Epoch 33 loss 651.5751953125
Epoch 34 loss 591.2892456054688
Epoch 35 loss 606.8282470703125
Epoch 36 loss 646.0724487304688
Epoch 37 loss 635.7809448242188
Epoch 38 loss 574.170654296875
Epoch 39 loss 569.8027954101562
Epoch 40 loss 575.6143798828125
Epoch 41 loss 713.08154296875
Epoch 42 loss 615.0603637695312
Epoch 43 loss 549.9908447265625
Epoch 44 loss 530.4119873046875
Epoch 45 loss 667.242919921875
Epoch 46 loss 639.8801879882812
Epoch 47 loss 572.7715454101562
Epoch 48 loss 528.3958740234375
Epoch 49 loss 520.5801391601562
Epoch 50 loss 524.3500366210938
Epoch 51 loss 667.3251953125
Epoch 52 loss 507.1632080078125
Epoch 53 loss 554.239990234375
Epoch 54 loss 506.3561096191406
Epoch 55 loss 488.18353271484375
Epoch 56 loss 540.61328125
Epoch 57 loss 505.0204162597656
Epoch 58 loss 490.2857666015625
Epoch 59 loss 502.1977844238281
Epoch 60 loss 495.9263610839844
Epoch 61 loss 848.6832275390625
Epoch 62 loss 518.3772583007812
Epoch 63 loss 483.7309875488281
Epoch 64 loss 514.661865234375
Epoch 65 loss 485.0867004394531
Epoch 66 loss 482.4825744628906
Epoch 67 loss 543.9884033203125
Epoch 68 loss 528.6052856445312
Epoch 69 loss 513.5385131835938
Epoch 70 loss 516.0633544921875
Epoch 71 loss 573.4833984375
Epoch 72 loss 470.3249206542969
Epoch 73 loss 556.66162109375
Epoch 74 loss 491.2872009277344
Epoch 75 loss 480.6123962402344
Epoch 76 loss 510.9012145996094
Epoch 77 loss 492.1224060058594
Epoch 78 loss 496.38775634765625
Epoch 79 loss 485.45660400390625
Epoch 80 loss 541.0045776367188
Epoch 81 loss 475.73028564453125
Epoch 82 loss 495.07196044921875
Epoch 83 loss 498.2004089355469
Epoch 84 loss 509.5741271972656
Epoch 85 loss 491.1439208984375
Epoch 86 loss 589.79736328125
Epoch 87 loss 474.4411926269531
Epoch 88 loss 470.8948974609375
Epoch 89 loss 501.63934326171875
Epoch 90 loss 469.3791198730469
Epoch 91 loss 467.12335205078125
Epoch 92 loss 481.9090270996094
Epoch 93 loss 484.8932800292969
Epoch 94 loss 526.0055541992188
Epoch 95 loss 550.749755859375
Epoch 96 loss 477.6900329589844
Epoch 97 loss 560.3649291992188
Epoch 98 loss 502.2334289550781
Epoch 99 loss 495.3692626953125
Saved Losses
{'MSE - mean': 481.7599247909774, 'MSE - std': 38.53040808680968, 'R2 - mean': 0.942306916073014, 'R2 - std': 0.004258179375778643} 
 

Results After CV: {'MSE - mean': 481.7599247909774, 'MSE - std': 38.53040808680968, 'R2 - mean': 0.942306916073014, 'R2 - std': 0.004258179375778643}
Train time: 101.50232300940006
Inference time: 0.14097507320038857
Finished cross validation
Trial 19 finished with value: 481.7599247909774 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.2}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513386.21875
Epoch 1 loss 510165.96875
Epoch 2 loss 505379.5
Epoch 3 loss 498546.59375
Epoch 4 loss 488434.28125
Epoch 5 loss 468128.96875
Epoch 6 loss 429896.5625
Epoch 7 loss 368938.90625
Epoch 8 loss 283952.96875
Epoch 9 loss 181800.625
Epoch 10 loss 84969.75
Epoch 11 loss 24277.951171875
Epoch 12 loss 8746.7109375
Epoch 13 loss 8977.634765625
Epoch 14 loss 8399.248046875
Epoch 15 loss 8569.28515625
Epoch 16 loss 7400.55712890625
Epoch 17 loss 4278.86572265625
Epoch 18 loss 2573.95458984375
Epoch 19 loss 1976.7784423828125
Epoch 20 loss 1658.3695068359375
Epoch 21 loss 1358.4039306640625
Epoch 22 loss 1491.195068359375
Epoch 23 loss 1094.9637451171875
Epoch 24 loss 1087.2332763671875
Epoch 25 loss 986.0888671875
Epoch 26 loss 891.6011352539062
Epoch 27 loss 861.6461791992188
Epoch 28 loss 941.739013671875
Epoch 29 loss 888.806396484375
Epoch 30 loss 773.6295776367188
Epoch 31 loss 799.770751953125
Epoch 32 loss 872.0478515625
Epoch 33 loss 773.7959594726562
Epoch 34 loss 766.7186279296875
Epoch 35 loss 823.0597534179688
Epoch 36 loss 679.1719360351562
Epoch 37 loss 799.0191040039062
Epoch 38 loss 698.7760620117188
Epoch 39 loss 1066.9423828125
Epoch 40 loss 745.1319580078125
Epoch 41 loss 716.2894897460938
Epoch 42 loss 677.4412231445312
Epoch 43 loss 924.331298828125
Epoch 44 loss 623.1100463867188
Epoch 45 loss 642.349853515625
Epoch 46 loss 826.6544189453125
Epoch 47 loss 613.7603759765625
Epoch 48 loss 663.4533081054688
Epoch 49 loss 658.1356201171875
Epoch 50 loss 627.7258911132812
Epoch 51 loss 669.8770141601562
Epoch 52 loss 584.9118041992188
Epoch 53 loss 574.8050537109375
Epoch 54 loss 605.1614379882812
Epoch 55 loss 617.6271362304688
Epoch 56 loss 572.2208862304688
Epoch 57 loss 700.4718017578125
Epoch 58 loss 586.9189453125
Epoch 59 loss 589.9500122070312
Epoch 60 loss 604.615234375
Epoch 61 loss 659.7281494140625
Epoch 62 loss 639.6255493164062
Epoch 63 loss 651.4954223632812
Epoch 64 loss 555.4075317382812
Epoch 65 loss 631.3773193359375
Epoch 66 loss 561.5429077148438
Epoch 67 loss 711.682861328125
Epoch 68 loss 560.3203125
Epoch 69 loss 571.1355590820312
Epoch 70 loss 548.5562133789062
Epoch 71 loss 625.1577758789062
Epoch 72 loss 576.5106811523438
Epoch 73 loss 565.9920654296875
Epoch 74 loss 548.9425659179688
Epoch 75 loss 551.13671875
Epoch 76 loss 564.2392578125
Epoch 77 loss 695.7135620117188
Epoch 78 loss 564.5117797851562
Epoch 79 loss 839.5457153320312
Epoch 80 loss 564.4754638671875
Epoch 81 loss 557.1392822265625
Epoch 82 loss 547.8489379882812
Epoch 83 loss 732.970947265625
Epoch 84 loss 559.8250122070312
Epoch 85 loss 601.2467041015625
Epoch 86 loss 572.837158203125
Epoch 87 loss 583.0253295898438
Epoch 88 loss 570.4208374023438
Epoch 89 loss 576.7183837890625
Epoch 90 loss 588.8248901367188
Epoch 91 loss 583.828125
Epoch 92 loss 575.70068359375
Epoch 93 loss 562.5283203125
Epoch 94 loss 846.7740478515625
Epoch 95 loss 548.4244995117188
Epoch 96 loss 566.0623779296875
Epoch 97 loss 685.9508056640625
Epoch 98 loss 571.93359375
Epoch 99 loss 556.1464233398438
Saved Losses
{'MSE - mean': 547.8491630941094, 'MSE - std': 0.0, 'R2 - mean': 0.9363010538563462, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522283.40625
Epoch 1 loss 519461.3125
Epoch 2 loss 515272.6875
Epoch 3 loss 509016.125
Epoch 4 loss 499136.21875
Epoch 5 loss 479310.96875
Epoch 6 loss 442713.9375
Epoch 7 loss 384366.59375
Epoch 8 loss 302247.0625
Epoch 9 loss 201803.46875
Epoch 10 loss 102184.28125
Epoch 11 loss 32997.953125
Epoch 12 loss 9151.1259765625
Epoch 13 loss 7738.80908203125
Epoch 14 loss 7550.6298828125
Epoch 15 loss 7392.20849609375
Epoch 16 loss 6771.39501953125
Epoch 17 loss 4685.66455078125
Epoch 18 loss 2634.796142578125
Epoch 19 loss 1974.9598388671875
Epoch 20 loss 1587.2310791015625
Epoch 21 loss 1402.8719482421875
Epoch 22 loss 1237.8016357421875
Epoch 23 loss 1435.3331298828125
Epoch 24 loss 1125.291748046875
Epoch 25 loss 1539.0391845703125
Epoch 26 loss 883.8418579101562
Epoch 27 loss 862.4359741210938
Epoch 28 loss 791.138916015625
Epoch 29 loss 914.2957763671875
Epoch 30 loss 724.6412963867188
Epoch 31 loss 719.2383422851562
Epoch 32 loss 670.7567138671875
Epoch 33 loss 648.623779296875
Epoch 34 loss 605.6337280273438
Epoch 35 loss 746.6333618164062
Epoch 36 loss 631.178955078125
Epoch 37 loss 600.198974609375
Epoch 38 loss 562.9927978515625
Epoch 39 loss 565.9337158203125
Epoch 40 loss 560.8262329101562
Epoch 41 loss 590.82958984375
Epoch 42 loss 622.465576171875
Epoch 43 loss 552.3046875
Epoch 44 loss 523.67724609375
Epoch 45 loss 508.9547119140625
Epoch 46 loss 531.2322998046875
Epoch 47 loss 494.795166015625
Epoch 48 loss 576.2845458984375
Epoch 49 loss 498.44158935546875
Epoch 50 loss 612.1127319335938
Epoch 51 loss 494.1202697753906
Epoch 52 loss 486.5655212402344
Epoch 53 loss 528.9141235351562
Epoch 54 loss 468.7273864746094
Epoch 55 loss 548.5801391601562
Epoch 56 loss 547.630615234375
Epoch 57 loss 561.8504638671875
Epoch 58 loss 566.7192993164062
Epoch 59 loss 528.2959594726562
Epoch 60 loss 516.0110473632812
Epoch 61 loss 513.6372680664062
Epoch 62 loss 474.29241943359375
Epoch 63 loss 462.0783996582031
Epoch 64 loss 623.2410278320312
Epoch 65 loss 463.5094299316406
Epoch 66 loss 489.7844543457031
Epoch 67 loss 494.81756591796875
Epoch 68 loss 464.90655517578125
Epoch 69 loss 507.00823974609375
Epoch 70 loss 471.6859436035156
Epoch 71 loss 442.3656005859375
Epoch 72 loss 564.857177734375
Epoch 73 loss 471.3807678222656
Epoch 74 loss 475.6567687988281
Epoch 75 loss 487.7068786621094
Epoch 76 loss 598.0551147460938
Epoch 77 loss 496.3218688964844
Epoch 78 loss 554.888427734375
Epoch 79 loss 480.7238464355469
Epoch 80 loss 450.49151611328125
Epoch 81 loss 462.72967529296875
Epoch 82 loss 696.6763305664062
Epoch 83 loss 548.7386474609375
Epoch 84 loss 490.6766357421875
Epoch 85 loss 438.6674499511719
Epoch 86 loss 480.7486267089844
Epoch 87 loss 447.98724365234375
Epoch 88 loss 474.2075500488281
Epoch 89 loss 545.4405517578125
Epoch 90 loss 521.4839477539062
Epoch 91 loss 646.7293701171875
Epoch 92 loss 466.627685546875
Epoch 93 loss 545.445556640625
Epoch 94 loss 564.0042114257812
Epoch 95 loss 455.70135498046875
Epoch 96 loss 534.1058349609375
Epoch 97 loss 447.99847412109375
Epoch 98 loss 592.7639770507812
Epoch 99 loss 533.7714233398438
Saved Losses
{'MSE - mean': 493.2581847507284, 'MSE - std': 54.59097834338098, 'R2 - mean': 0.9394437264256227, 'R2 - std': 0.0031426725692764723} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515787.59375
Epoch 1 loss 512981.0625
Epoch 2 loss 508621.125
Epoch 3 loss 501626.15625
Epoch 4 loss 490554.59375
Epoch 5 loss 469406.09375
Epoch 6 loss 430962.25
Epoch 7 loss 370129.65625
Epoch 8 loss 285863.53125
Epoch 9 loss 185373.609375
Epoch 10 loss 89692.40625
Epoch 11 loss 27859.794921875
Epoch 12 loss 9794.775390625
Epoch 13 loss 9554.7734375
Epoch 14 loss 9142.419921875
Epoch 15 loss 9075.064453125
Epoch 16 loss 8141.05224609375
Epoch 17 loss 5508.1259765625
Epoch 18 loss 3526.126953125
Epoch 19 loss 2399.00732421875
Epoch 20 loss 1926.8599853515625
Epoch 21 loss 2003.5848388671875
Epoch 22 loss 1596.908935546875
Epoch 23 loss 1285.1202392578125
Epoch 24 loss 1187.57958984375
Epoch 25 loss 1184.802490234375
Epoch 26 loss 1046.23779296875
Epoch 27 loss 921.4534912109375
Epoch 28 loss 946.6758422851562
Epoch 29 loss 1196.2333984375
Epoch 30 loss 848.9179077148438
Epoch 31 loss 880.9447021484375
Epoch 32 loss 841.4632568359375
Epoch 33 loss 889.1058959960938
Epoch 34 loss 766.4754638671875
Epoch 35 loss 1023.9776000976562
Epoch 36 loss 644.8051147460938
Epoch 37 loss 720.60791015625
Epoch 38 loss 770.810302734375
Epoch 39 loss 795.4110717773438
Epoch 40 loss 703.0556640625
Epoch 41 loss 626.0821533203125
Epoch 42 loss 685.8840942382812
Epoch 43 loss 622.2098999023438
Epoch 44 loss 578.979248046875
Epoch 45 loss 615.9459838867188
Epoch 46 loss 638.0391235351562
Epoch 47 loss 743.3211059570312
Epoch 48 loss 800.0188598632812
Epoch 49 loss 734.0873413085938
Epoch 50 loss 552.7857055664062
Epoch 51 loss 547.85498046875
Epoch 52 loss 683.8938598632812
Epoch 53 loss 580.5459594726562
Epoch 54 loss 502.619384765625
Epoch 55 loss 563.0311889648438
Epoch 56 loss 501.3352966308594
Epoch 57 loss 638.4281616210938
Epoch 58 loss 499.8765563964844
Epoch 59 loss 639.444580078125
Epoch 60 loss 588.2444458007812
Epoch 61 loss 577.9988403320312
Epoch 62 loss 543.3848876953125
Epoch 63 loss 580.4990844726562
Epoch 64 loss 494.8294982910156
Epoch 65 loss 499.1406555175781
Epoch 66 loss 514.8043212890625
Epoch 67 loss 751.2859497070312
Epoch 68 loss 474.4813232421875
Epoch 69 loss 474.9405822753906
Epoch 70 loss 484.83343505859375
Epoch 71 loss 654.4994506835938
Epoch 72 loss 472.0591735839844
Epoch 73 loss 748.0377807617188
Epoch 74 loss 514.0265502929688
Epoch 75 loss 602.0257568359375
Epoch 76 loss 537.404052734375
Epoch 77 loss 476.3091125488281
Epoch 78 loss 476.1233215332031
Epoch 79 loss 568.7598876953125
Epoch 80 loss 593.3640747070312
Epoch 81 loss 603.6431274414062
Epoch 82 loss 522.2682495117188
Epoch 83 loss 561.4044799804688
Epoch 84 loss 511.5533142089844
Epoch 85 loss 580.5049438476562
Epoch 86 loss 473.24505615234375
Epoch 87 loss 607.572998046875
Epoch 88 loss 630.296875
Epoch 89 loss 659.6021118164062
Epoch 90 loss 508.0639953613281
Epoch 91 loss 963.0805053710938
Epoch 92 loss 519.1572265625
Epoch 93 loss 880.3128051757812
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 486.1918790450865, 'MSE - std': 45.67984928072225, 'R2 - mean': 0.9427247937421371, 'R2 - std': 0.005302364194971997} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518115.53125
Epoch 1 loss 515294.3125
Epoch 2 loss 511014.625
Epoch 3 loss 504876.53125
Epoch 4 loss 495530.4375
Epoch 5 loss 477278.03125
Epoch 6 loss 443117.90625
Epoch 7 loss 388088.84375
Epoch 8 loss 309704.875
Epoch 9 loss 212437.6875
Epoch 10 loss 113257.140625
Epoch 11 loss 39997.0078125
Epoch 12 loss 10861.501953125
Epoch 13 loss 8395.1826171875
Epoch 14 loss 8193.716796875
Epoch 15 loss 8061.361328125
Epoch 16 loss 7565.42333984375
Epoch 17 loss 4915.67529296875
Epoch 18 loss 3045.040771484375
Epoch 19 loss 2246.839111328125
Epoch 20 loss 1962.4866943359375
Epoch 21 loss 1843.13232421875
Epoch 22 loss 1504.6573486328125
Epoch 23 loss 1274.675048828125
Epoch 24 loss 1410.1458740234375
Epoch 25 loss 1022.1419067382812
Epoch 26 loss 982.3085327148438
Epoch 27 loss 992.0985107421875
Epoch 28 loss 904.347900390625
Epoch 29 loss 857.5851440429688
Epoch 30 loss 792.5457153320312
Epoch 31 loss 992.185546875
Epoch 32 loss 792.5986938476562
Epoch 33 loss 799.4248657226562
Epoch 34 loss 679.5289306640625
Epoch 35 loss 678.0527954101562
Epoch 36 loss 659.8795776367188
Epoch 37 loss 689.4303588867188
Epoch 38 loss 727.8582153320312
Epoch 39 loss 778.0560913085938
Epoch 40 loss 669.0767822265625
Epoch 41 loss 685.6703491210938
Epoch 42 loss 703.88427734375
Epoch 43 loss 762.8843994140625
Epoch 44 loss 603.0159301757812
Epoch 45 loss 575.8244018554688
Epoch 46 loss 567.3463745117188
Epoch 47 loss 814.1459350585938
Epoch 48 loss 569.3092041015625
Epoch 49 loss 706.3679809570312
Epoch 50 loss 663.9550170898438
Epoch 51 loss 664.6754760742188
Epoch 52 loss 783.4169921875
Epoch 53 loss 541.2669677734375
Epoch 54 loss 563.048095703125
Epoch 55 loss 839.579345703125
Epoch 56 loss 544.557373046875
Epoch 57 loss 609.7855224609375
Epoch 58 loss 607.8713989257812
Epoch 59 loss 677.8036499023438
Epoch 60 loss 743.6322021484375
Epoch 61 loss 562.9942626953125
Epoch 62 loss 579.9557495117188
Epoch 63 loss 527.703857421875
Epoch 64 loss 531.8546142578125
Epoch 65 loss 538.9329223632812
Epoch 66 loss 537.513671875
Epoch 67 loss 586.2572021484375
Epoch 68 loss 526.353759765625
Epoch 69 loss 759.503173828125
Epoch 70 loss 560.0651245117188
Epoch 71 loss 744.8236694335938
Epoch 72 loss 509.4543151855469
Epoch 73 loss 750.5661010742188
Epoch 74 loss 527.6889038085938
Epoch 75 loss 541.1831665039062
Epoch 76 loss 590.9652099609375
Epoch 77 loss 512.4773559570312
Epoch 78 loss 649.7307739257812
Epoch 79 loss 564.2576293945312
Epoch 80 loss 612.4097290039062
Epoch 81 loss 510.6746520996094
Epoch 82 loss 631.2171020507812
Epoch 83 loss 520.4437866210938
Epoch 84 loss 548.9055786132812
Epoch 85 loss 529.7041625976562
Epoch 86 loss 547.3923950195312
Epoch 87 loss 652.12060546875
Epoch 88 loss 498.5143737792969
Epoch 89 loss 630.294677734375
Epoch 90 loss 527.4583740234375
Epoch 91 loss 577.8167724609375
Epoch 92 loss 551.3230590820312
Epoch 93 loss 690.4425659179688
Epoch 94 loss 563.0032348632812
Epoch 95 loss 591.2733764648438
Epoch 96 loss 516.229248046875
Epoch 97 loss 577.2742309570312
Epoch 98 loss 596.4663696289062
Epoch 99 loss 505.4701232910156
Saved Losses
{'MSE - mean': 489.2724747417143, 'MSE - std': 39.91812473388962, 'R2 - mean': 0.9420380758856847, 'R2 - std': 0.004743526513597552} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516168.375
Epoch 1 loss 513656.125
Epoch 2 loss 510043.0
Epoch 3 loss 504500.0
Epoch 4 loss 496258.0625
Epoch 5 loss 480417.03125
Epoch 6 loss 449897.53125
Epoch 7 loss 398870.34375
Epoch 8 loss 323706.46875
Epoch 9 loss 227142.75
Epoch 10 loss 124640.5546875
Epoch 11 loss 44526.3671875
Epoch 12 loss 11071.375
Epoch 13 loss 8160.7099609375
Epoch 14 loss 8044.1435546875
Epoch 15 loss 7815.6787109375
Epoch 16 loss 7614.912109375
Epoch 17 loss 6428.23095703125
Epoch 18 loss 3489.090576171875
Epoch 19 loss 2349.324951171875
Epoch 20 loss 1641.5931396484375
Epoch 21 loss 1352.677734375
Epoch 22 loss 1342.313232421875
Epoch 23 loss 1116.158203125
Epoch 24 loss 1023.6011962890625
Epoch 25 loss 1306.02001953125
Epoch 26 loss 906.3831176757812
Epoch 27 loss 861.5303344726562
Epoch 28 loss 914.103759765625
Epoch 29 loss 855.6096801757812
Epoch 30 loss 824.9581909179688
Epoch 31 loss 748.5806274414062
Epoch 32 loss 712.259521484375
Epoch 33 loss 713.7400512695312
Epoch 34 loss 737.2548828125
Epoch 35 loss 776.6760864257812
Epoch 36 loss 714.6774291992188
Epoch 37 loss 710.1738891601562
Epoch 38 loss 632.6549682617188
Epoch 39 loss 636.494384765625
Epoch 40 loss 602.1624145507812
Epoch 41 loss 579.947265625
Epoch 42 loss 589.8865966796875
Epoch 43 loss 636.705810546875
Epoch 44 loss 596.3790283203125
Epoch 45 loss 603.7933349609375
Epoch 46 loss 686.8565673828125
Epoch 47 loss 538.7706909179688
Epoch 48 loss 552.1832275390625
Epoch 49 loss 554.6522827148438
Epoch 50 loss 545.1893310546875
Epoch 51 loss 619.7921752929688
Epoch 52 loss 537.4473876953125
Epoch 53 loss 510.9126892089844
Epoch 54 loss 539.340576171875
Epoch 55 loss 546.9012451171875
Epoch 56 loss 651.7843017578125
Epoch 57 loss 511.270751953125
Epoch 58 loss 522.9004516601562
Epoch 59 loss 499.27313232421875
Epoch 60 loss 516.2574462890625
Epoch 61 loss 581.1478881835938
Epoch 62 loss 485.2061462402344
Epoch 63 loss 677.4454956054688
Epoch 64 loss 509.1437683105469
Epoch 65 loss 502.9575500488281
Epoch 66 loss 660.7069702148438
Epoch 67 loss 530.8858032226562
Epoch 68 loss 548.8391723632812
Epoch 69 loss 518.5435791015625
Epoch 70 loss 480.8744812011719
Epoch 71 loss 481.5102844238281
Epoch 72 loss 501.62091064453125
Epoch 73 loss 480.94732666015625
Epoch 74 loss 473.1515808105469
Epoch 75 loss 482.6338195800781
Epoch 76 loss 466.566162109375
Epoch 77 loss 476.91461181640625
Epoch 78 loss 496.1759033203125
Epoch 79 loss 582.7221069335938
Epoch 80 loss 476.30389404296875
Epoch 81 loss 529.0498657226562
Epoch 82 loss 528.4806518554688
Epoch 83 loss 472.4574279785156
Epoch 84 loss 463.9928894042969
Epoch 85 loss 483.5890197753906
Epoch 86 loss 521.22021484375
Epoch 87 loss 471.91619873046875
Epoch 88 loss 584.3711547851562
Epoch 89 loss 463.317138671875
Epoch 90 loss 548.7361450195312
Epoch 91 loss 474.2445068359375
Epoch 92 loss 450.1695861816406
Epoch 93 loss 490.4700622558594
Epoch 94 loss 465.8739929199219
Epoch 95 loss 470.7500915527344
Epoch 96 loss 467.1592712402344
Epoch 97 loss 468.4701843261719
Epoch 98 loss 579.919189453125
Epoch 99 loss 497.63922119140625
Saved Losses
{'MSE - mean': 481.4518918381206, 'MSE - std': 38.97962818735221, 'R2 - mean': 0.9423452401210994, 'R2 - std': 0.004286984312804762} 
 

Results After CV: {'MSE - mean': 481.4518918381206, 'MSE - std': 38.97962818735221, 'R2 - mean': 0.9423452401210994, 'R2 - std': 0.004286984312804762}
Train time: 100.19232886260033
Inference time: 0.14311709520006843
Finished cross validation
Trial 20 finished with value: 481.4518918381206 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.4}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515163.0625
Epoch 1 loss 513336.78125
Epoch 2 loss 510159.15625
Epoch 3 loss 505039.15625
Epoch 4 loss 497217.6875
Epoch 5 loss 481559.09375
Epoch 6 loss 451134.78125
Epoch 7 loss 400044.71875
Epoch 8 loss 324626.09375
Epoch 9 loss 227833.6875
Epoch 10 loss 125103.4140625
Epoch 11 loss 45254.94921875
Epoch 12 loss 11739.6123046875
Epoch 13 loss 8746.3271484375
Epoch 14 loss 8601.2041015625
Epoch 15 loss 8366.876953125
Epoch 16 loss 7933.49560546875
Epoch 17 loss 5345.77685546875
Epoch 18 loss 3312.14794921875
Epoch 19 loss 2409.27294921875
Epoch 20 loss 1950.7203369140625
Epoch 21 loss 1794.4132080078125
Epoch 22 loss 1770.332275390625
Epoch 23 loss 1391.740234375
Epoch 24 loss 1250.345458984375
Epoch 25 loss 1029.611328125
Epoch 26 loss 1115.513427734375
Epoch 27 loss 943.0077514648438
Epoch 28 loss 923.9740600585938
Epoch 29 loss 981.0768432617188
Epoch 30 loss 994.7880859375
Epoch 31 loss 830.4600219726562
Epoch 32 loss 792.3729248046875
Epoch 33 loss 1200.887451171875
Epoch 34 loss 754.64306640625
Epoch 35 loss 724.5086059570312
Epoch 36 loss 812.7105712890625
Epoch 37 loss 852.1587524414062
Epoch 38 loss 746.7713012695312
Epoch 39 loss 759.2456665039062
Epoch 40 loss 757.8541259765625
Epoch 41 loss 801.2409057617188
Epoch 42 loss 705.476318359375
Epoch 43 loss 684.71826171875
Epoch 44 loss 689.6369018554688
Epoch 45 loss 810.1227416992188
Epoch 46 loss 640.9173583984375
Epoch 47 loss 718.4627685546875
Epoch 48 loss 873.0897216796875
Epoch 49 loss 675.8060913085938
Epoch 50 loss 785.333251953125
Epoch 51 loss 751.0695190429688
Epoch 52 loss 683.9846801757812
Epoch 53 loss 770.156494140625
Epoch 54 loss 631.8243408203125
Epoch 55 loss 713.8311767578125
Epoch 56 loss 619.6778564453125
Epoch 57 loss 679.9807739257812
Epoch 58 loss 650.6089477539062
Epoch 59 loss 610.24560546875
Epoch 60 loss 613.3628540039062
Epoch 61 loss 863.6480712890625
Epoch 62 loss 603.3448486328125
Epoch 63 loss 631.5857543945312
Epoch 64 loss 647.9638061523438
Epoch 65 loss 617.0436401367188
Epoch 66 loss 571.8001098632812
Epoch 67 loss 573.5174560546875
Epoch 68 loss 651.9170532226562
Epoch 69 loss 602.8009643554688
Epoch 70 loss 591.0670776367188
Epoch 71 loss 684.9524536132812
Epoch 72 loss 619.9738159179688
Epoch 73 loss 715.5018920898438
Epoch 74 loss 582.2384033203125
Epoch 75 loss 575.1171875
Epoch 76 loss 596.4509887695312
Epoch 77 loss 780.09375
Epoch 78 loss 621.4854736328125
Epoch 79 loss 620.7243041992188
Epoch 80 loss 604.4556274414062
Epoch 81 loss 561.0233764648438
Epoch 82 loss 909.4996337890625
Epoch 83 loss 574.9251708984375
Epoch 84 loss 561.5239868164062
Epoch 85 loss 577.248779296875
Epoch 86 loss 716.568603515625
Epoch 87 loss 679.0377197265625
Epoch 88 loss 568.9405517578125
Epoch 89 loss 621.9259033203125
Epoch 90 loss 578.2525634765625
Epoch 91 loss 565.51708984375
Epoch 92 loss 796.932861328125
Epoch 93 loss 572.8786010742188
Epoch 94 loss 551.0337524414062
Epoch 95 loss 555.0853881835938
Epoch 96 loss 610.8992309570312
Epoch 97 loss 557.197998046875
Epoch 98 loss 631.1632080078125
Epoch 99 loss 654.8309326171875
Saved Losses
{'MSE - mean': 551.0335656841878, 'MSE - std': 0.0, 'R2 - mean': 0.9359308003217063, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 521061.4375
Epoch 1 loss 517573.09375
Epoch 2 loss 512454.375
Epoch 3 loss 505097.71875
Epoch 4 loss 493588.28125
Epoch 5 loss 470139.15625
Epoch 6 loss 426897.46875
Epoch 7 loss 359343.75
Epoch 8 loss 267719.3125
Epoch 9 loss 162644.125
Epoch 10 loss 69456.15625
Epoch 11 loss 17756.291015625
Epoch 12 loss 7663.33203125
Epoch 13 loss 7663.36962890625
Epoch 14 loss 7505.771484375
Epoch 15 loss 7182.1328125
Epoch 16 loss 4785.01953125
Epoch 17 loss 3066.977294921875
Epoch 18 loss 2012.9638671875
Epoch 19 loss 1578.81982421875
Epoch 20 loss 1917.5755615234375
Epoch 21 loss 1396.8607177734375
Epoch 22 loss 1045.22802734375
Epoch 23 loss 968.6649780273438
Epoch 24 loss 836.3687133789062
Epoch 25 loss 817.6832885742188
Epoch 26 loss 748.8165893554688
Epoch 27 loss 682.8081665039062
Epoch 28 loss 756.2510375976562
Epoch 29 loss 644.6456298828125
Epoch 30 loss 683.7152099609375
Epoch 31 loss 1048.9736328125
Epoch 32 loss 624.0230712890625
Epoch 33 loss 606.1947021484375
Epoch 34 loss 552.3101196289062
Epoch 35 loss 737.146728515625
Epoch 36 loss 627.3863525390625
Epoch 37 loss 612.47412109375
Epoch 38 loss 600.5551147460938
Epoch 39 loss 570.3529663085938
Epoch 40 loss 574.0452880859375
Epoch 41 loss 663.2403564453125
Epoch 42 loss 505.84686279296875
Epoch 43 loss 525.3509521484375
Epoch 44 loss 490.6932678222656
Epoch 45 loss 503.6019287109375
Epoch 46 loss 547.8722534179688
Epoch 47 loss 495.8933410644531
Epoch 48 loss 487.09033203125
Epoch 49 loss 500.11065673828125
Epoch 50 loss 557.0980834960938
Epoch 51 loss 532.9574584960938
Epoch 52 loss 473.12200927734375
Epoch 53 loss 460.7906799316406
Epoch 54 loss 474.40240478515625
Epoch 55 loss 511.99627685546875
Epoch 56 loss 661.6070556640625
Epoch 57 loss 488.291748046875
Epoch 58 loss 513.0499267578125
Epoch 59 loss 491.85186767578125
Epoch 60 loss 487.1590881347656
Epoch 61 loss 535.9168701171875
Epoch 62 loss 521.6041259765625
Epoch 63 loss 510.55377197265625
Epoch 64 loss 452.3827209472656
Epoch 65 loss 450.0462951660156
Epoch 66 loss 519.6177368164062
Epoch 67 loss 499.6458740234375
Epoch 68 loss 463.6022644042969
Epoch 69 loss 448.3072204589844
Epoch 70 loss 658.92041015625
Epoch 71 loss 451.1274108886719
Epoch 72 loss 457.2689208984375
Epoch 73 loss 440.6751708984375
Epoch 74 loss 474.529541015625
Epoch 75 loss 452.00152587890625
Epoch 76 loss 473.3883056640625
Epoch 77 loss 481.4041442871094
Epoch 78 loss 436.41143798828125
Epoch 79 loss 577.687744140625
Epoch 80 loss 493.2300109863281
Epoch 81 loss 437.35296630859375
Epoch 82 loss 517.2947998046875
Epoch 83 loss 451.8521728515625
Epoch 84 loss 456.828125
Epoch 85 loss 578.4041748046875
Epoch 86 loss 589.2454223632812
Epoch 87 loss 460.3083190917969
Epoch 88 loss 520.7670288085938
Epoch 89 loss 464.41497802734375
Epoch 90 loss 452.9178466796875
Epoch 91 loss 440.2859802246094
Epoch 92 loss 589.7633666992188
Epoch 93 loss 488.47784423828125
Epoch 94 loss 468.0788269042969
Epoch 95 loss 439.87493896484375
Epoch 96 loss 648.3638916015625
Epoch 97 loss 452.8619079589844
Epoch 98 loss 547.7588500976562
Epoch 99 loss 436.3621826171875
Saved Losses
{'MSE - mean': 493.69796299803176, 'MSE - std': 57.33560268615605, 'R2 - mean': 0.9394094309857541, 'R2 - std': 0.0034786306640477993} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516931.6875
Epoch 1 loss 515113.0
Epoch 2 loss 511968.5625
Epoch 3 loss 506971.75
Epoch 4 loss 499097.59375
Epoch 5 loss 483299.96875
Epoch 6 loss 452917.5
Epoch 7 loss 402001.40625
Epoch 8 loss 326778.84375
Epoch 9 loss 229607.78125
Epoch 10 loss 126119.390625
Epoch 11 loss 45853.89453125
Epoch 12 loss 12439.87890625
Epoch 13 loss 9485.044921875
Epoch 14 loss 9310.828125
Epoch 15 loss 9135.9306640625
Epoch 16 loss 8722.6015625
Epoch 17 loss 6242.7255859375
Epoch 18 loss 3929.071533203125
Epoch 19 loss 2688.20849609375
Epoch 20 loss 1918.4393310546875
Epoch 21 loss 1757.257568359375
Epoch 22 loss 1796.6424560546875
Epoch 23 loss 1354.1851806640625
Epoch 24 loss 1221.2061767578125
Epoch 25 loss 1213.7940673828125
Epoch 26 loss 1334.6978759765625
Epoch 27 loss 996.8418579101562
Epoch 28 loss 883.68212890625
Epoch 29 loss 854.6878662109375
Epoch 30 loss 900.11962890625
Epoch 31 loss 990.5403442382812
Epoch 32 loss 792.5455932617188
Epoch 33 loss 739.4902954101562
Epoch 34 loss 816.822265625
Epoch 35 loss 694.2240600585938
Epoch 36 loss 690.9381103515625
Epoch 37 loss 705.75927734375
Epoch 38 loss 1003.0903930664062
Epoch 39 loss 637.837890625
Epoch 40 loss 693.1385498046875
Epoch 41 loss 582.4049682617188
Epoch 42 loss 661.7733764648438
Epoch 43 loss 555.9662475585938
Epoch 44 loss 594.7254638671875
Epoch 45 loss 731.853515625
Epoch 46 loss 555.0748291015625
Epoch 47 loss 536.5042114257812
Epoch 48 loss 602.9539794921875
Epoch 49 loss 538.9114990234375
Epoch 50 loss 553.7313842773438
Epoch 51 loss 531.6483154296875
Epoch 52 loss 517.672119140625
Epoch 53 loss 703.4269409179688
Epoch 54 loss 521.2992553710938
Epoch 55 loss 528.2662963867188
Epoch 56 loss 501.0263977050781
Epoch 57 loss 752.181640625
Epoch 58 loss 552.7874145507812
Epoch 59 loss 594.4151000976562
Epoch 60 loss 481.6697082519531
Epoch 61 loss 499.50225830078125
Epoch 62 loss 1059.740234375
Epoch 63 loss 509.21429443359375
Epoch 64 loss 500.015869140625
Epoch 65 loss 695.1324462890625
Epoch 66 loss 492.2262268066406
Epoch 67 loss 484.9659118652344
Epoch 68 loss 541.3197021484375
Epoch 69 loss 493.3048400878906
Epoch 70 loss 473.1784973144531
Epoch 71 loss 540.0420532226562
Epoch 72 loss 517.2929077148438
Epoch 73 loss 475.0672607421875
Epoch 74 loss 462.5321350097656
Epoch 75 loss 516.3657836914062
Epoch 76 loss 500.30120849609375
Epoch 77 loss 706.0426025390625
Epoch 78 loss 502.7622375488281
Epoch 79 loss 499.1342468261719
Epoch 80 loss 462.9684143066406
Epoch 81 loss 602.3570556640625
Epoch 82 loss 645.7166748046875
Epoch 83 loss 480.0509033203125
Epoch 84 loss 463.60125732421875
Epoch 85 loss 468.56304931640625
Epoch 86 loss 456.3123474121094
Epoch 87 loss 600.0101318359375
Epoch 88 loss 525.3681030273438
Epoch 89 loss 676.3592529296875
Epoch 90 loss 491.70233154296875
Epoch 91 loss 507.6290588378906
Epoch 92 loss 463.0111389160156
Epoch 93 loss 474.8663635253906
Epoch 94 loss 580.6148681640625
Epoch 95 loss 593.3463745117188
Epoch 96 loss 454.5364990234375
Epoch 97 loss 560.4240112304688
Epoch 98 loss 462.0775451660156
Epoch 99 loss 563.9987182617188
Saved Losses
{'MSE - mean': 480.6441208048391, 'MSE - std': 50.322822677847185, 'R2 - mean': 0.943329419540031, 'R2 - std': 0.00622895401031021} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519310.125
Epoch 1 loss 517018.78125
Epoch 2 loss 513516.5625
Epoch 3 loss 508438.59375
Epoch 4 loss 501228.96875
Epoch 5 loss 486408.5
Epoch 6 loss 458106.21875
Epoch 7 loss 410435.65625
Epoch 8 loss 338898.125
Epoch 9 loss 244726.859375
Epoch 10 loss 140578.203125
Epoch 11 loss 54689.58984375
Epoch 12 loss 13781.22265625
Epoch 13 loss 8341.3056640625
Epoch 14 loss 8364.8671875
Epoch 15 loss 8166.84521484375
Epoch 16 loss 7882.20068359375
Epoch 17 loss 6049.2548828125
Epoch 18 loss 3923.835205078125
Epoch 19 loss 2668.757080078125
Epoch 20 loss 2567.1875
Epoch 21 loss 1798.869873046875
Epoch 22 loss 1622.20654296875
Epoch 23 loss 1407.54150390625
Epoch 24 loss 1267.8848876953125
Epoch 25 loss 1188.693603515625
Epoch 26 loss 1453.801025390625
Epoch 27 loss 990.8369750976562
Epoch 28 loss 987.448486328125
Epoch 29 loss 1465.980712890625
Epoch 30 loss 978.1614379882812
Epoch 31 loss 1218.0665283203125
Epoch 32 loss 844.5355224609375
Epoch 33 loss 1093.708251953125
Epoch 34 loss 782.7990112304688
Epoch 35 loss 730.7023315429688
Epoch 36 loss 828.328857421875
Epoch 37 loss 745.815673828125
Epoch 38 loss 879.3666381835938
Epoch 39 loss 704.8189086914062
Epoch 40 loss 1047.614501953125
Epoch 41 loss 722.2401123046875
Epoch 42 loss 1004.4444580078125
Epoch 43 loss 656.033935546875
Epoch 44 loss 644.0283203125
Epoch 45 loss 882.9247436523438
Epoch 46 loss 660.8778686523438
Epoch 47 loss 592.1463012695312
Epoch 48 loss 836.0779418945312
Epoch 49 loss 620.1400756835938
Epoch 50 loss 647.8527221679688
Epoch 51 loss 580.6994018554688
Epoch 52 loss 695.5
Epoch 53 loss 560.816650390625
Epoch 54 loss 790.0548095703125
Epoch 55 loss 612.8906860351562
Epoch 56 loss 671.187744140625
Epoch 57 loss 856.4849853515625
Epoch 58 loss 602.6953125
Epoch 59 loss 570.5318603515625
Epoch 60 loss 630.3555297851562
Epoch 61 loss 596.763427734375
Epoch 62 loss 558.8544921875
Epoch 63 loss 563.5740356445312
Epoch 64 loss 549.715576171875
Epoch 65 loss 556.2933349609375
Epoch 66 loss 537.3378295898438
Epoch 67 loss 578.2740478515625
Epoch 68 loss 688.126708984375
Epoch 69 loss 524.5482177734375
Epoch 70 loss 731.9896850585938
Epoch 71 loss 553.410888671875
Epoch 72 loss 576.469482421875
Epoch 73 loss 758.3936157226562
Epoch 74 loss 549.3436889648438
Epoch 75 loss 510.0480041503906
Epoch 76 loss 511.3070373535156
Epoch 77 loss 561.4886474609375
Epoch 78 loss 805.5429077148438
Epoch 79 loss 514.15966796875
Epoch 80 loss 575.1578369140625
Epoch 81 loss 514.8444213867188
Epoch 82 loss 720.4471435546875
Epoch 83 loss 519.8549194335938
Epoch 84 loss 552.3705444335938
Epoch 85 loss 503.55810546875
Epoch 86 loss 550.5164794921875
Epoch 87 loss 507.2046813964844
Epoch 88 loss 843.7946166992188
Epoch 89 loss 494.1756591796875
Epoch 90 loss 786.25634765625
Epoch 91 loss 510.1296691894531
Epoch 92 loss 595.2245483398438
Epoch 93 loss 585.2024536132812
Epoch 94 loss 530.659912109375
Epoch 95 loss 515.9760131835938
Epoch 96 loss 744.5693969726562
Epoch 97 loss 525.809326171875
Epoch 98 loss 635.9431762695312
Epoch 99 loss 491.67620849609375
Saved Losses
{'MSE - mean': 483.40211637448067, 'MSE - std': 43.8418690339044, 'R2 - mean': 0.9426973771064417, 'R2 - std': 0.005504392242608831} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514417.75
Epoch 1 loss 510989.0625
Epoch 2 loss 506097.28125
Epoch 3 loss 499018.59375
Epoch 4 loss 488513.75
Epoch 5 loss 468756.34375
Epoch 6 loss 432932.8125
Epoch 7 loss 376104.78125
Epoch 8 loss 296464.4375
Epoch 9 loss 199541.15625
Epoch 10 loss 102454.5859375
Epoch 11 loss 33818.30859375
Epoch 12 loss 9575.1787109375
Epoch 13 loss 8183.5234375
Epoch 14 loss 7918.5517578125
Epoch 15 loss 7725.36962890625
Epoch 16 loss 7163.7275390625
Epoch 17 loss 5300.19189453125
Epoch 18 loss 2737.058837890625
Epoch 19 loss 2187.932861328125
Epoch 20 loss 1628.8221435546875
Epoch 21 loss 1270.9632568359375
Epoch 22 loss 1153.53515625
Epoch 23 loss 1239.99072265625
Epoch 24 loss 1048.1376953125
Epoch 25 loss 944.8165893554688
Epoch 26 loss 840.7271118164062
Epoch 27 loss 798.0259399414062
Epoch 28 loss 993.1365356445312
Epoch 29 loss 897.251220703125
Epoch 30 loss 996.9341430664062
Epoch 31 loss 843.731689453125
Epoch 32 loss 674.4410400390625
Epoch 33 loss 652.3244018554688
Epoch 34 loss 669.7342529296875
Epoch 35 loss 701.7791748046875
Epoch 36 loss 696.3399047851562
Epoch 37 loss 622.7460327148438
Epoch 38 loss 667.0018920898438
Epoch 39 loss 601.9487915039062
Epoch 40 loss 582.1815185546875
Epoch 41 loss 572.5015869140625
Epoch 42 loss 621.5132446289062
Epoch 43 loss 605.329833984375
Epoch 44 loss 649.59716796875
Epoch 45 loss 569.1422729492188
Epoch 46 loss 563.2843017578125
Epoch 47 loss 699.8335571289062
Epoch 48 loss 515.381103515625
Epoch 49 loss 561.0156860351562
Epoch 50 loss 553.534912109375
Epoch 51 loss 527.1016845703125
Epoch 52 loss 545.4419555664062
Epoch 53 loss 515.7154541015625
Epoch 54 loss 503.54730224609375
Epoch 55 loss 516.5369873046875
Epoch 56 loss 540.3526611328125
Epoch 57 loss 522.3400268554688
Epoch 58 loss 600.3843383789062
Epoch 59 loss 617.287841796875
Epoch 60 loss 499.3476867675781
Epoch 61 loss 608.159423828125
Epoch 62 loss 585.8384399414062
Epoch 63 loss 494.2807312011719
Epoch 64 loss 514.2457885742188
Epoch 65 loss 483.5596618652344
Epoch 66 loss 496.3996887207031
Epoch 67 loss 474.886962890625
Epoch 68 loss 537.52294921875
Epoch 69 loss 475.8153991699219
Epoch 70 loss 509.22216796875
Epoch 71 loss 491.1621398925781
Epoch 72 loss 488.16888427734375
Epoch 73 loss 484.0976257324219
Epoch 74 loss 522.1788330078125
Epoch 75 loss 505.9926452636719
Epoch 76 loss 485.7083740234375
Epoch 77 loss 491.88140869140625
Epoch 78 loss 515.6195068359375
Epoch 79 loss 500.2093505859375
Epoch 80 loss 474.4973449707031
Epoch 81 loss 509.6829528808594
Epoch 82 loss 567.0126953125
Epoch 83 loss 504.9328308105469
Epoch 84 loss 535.05224609375
Epoch 85 loss 470.6379089355469
Epoch 86 loss 479.3412170410156
Epoch 87 loss 518.8550415039062
Epoch 88 loss 461.25006103515625
Epoch 89 loss 495.8274841308594
Epoch 90 loss 483.9304504394531
Epoch 91 loss 545.0530395507812
Epoch 92 loss 629.3211059570312
Epoch 93 loss 491.3050842285156
Epoch 94 loss 631.9714965820312
Epoch 95 loss 476.3675842285156
Epoch 96 loss 472.4454040527344
Epoch 97 loss 492.2013854980469
Epoch 98 loss 496.4437561035156
Epoch 99 loss 530.7481079101562
Saved Losses
{'MSE - mean': 478.97172459395796, 'MSE - std': 40.202003303622966, 'R2 - mean': 0.9425949035773336, 'R2 - std': 0.004927542030776135} 
 

Results After CV: {'MSE - mean': 478.97172459395796, 'MSE - std': 40.202003303622966, 'R2 - mean': 0.9425949035773336, 'R2 - std': 0.004927542030776135}
Train time: 101.69362219879949
Inference time: 0.14153897679971122
Finished cross validation
Trial 21 finished with value: 478.97172459395796 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.4}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 512277.46875
Epoch 1 loss 508454.03125
Epoch 2 loss 503359.65625
Epoch 3 loss 496481.5
Epoch 4 loss 486422.75
Epoch 5 loss 466329.59375
Epoch 6 loss 428285.5625
Epoch 7 loss 368359.53125
Epoch 8 loss 284888.03125
Epoch 9 loss 184990.09375
Epoch 10 loss 89381.5234375
Epoch 11 loss 27252.9453125
Epoch 12 loss 9084.357421875
Epoch 13 loss 8928.48046875
Epoch 14 loss 8422.3701171875
Epoch 15 loss 8252.337890625
Epoch 16 loss 7085.93017578125
Epoch 17 loss 4068.655517578125
Epoch 18 loss 2786.59228515625
Epoch 19 loss 2024.5352783203125
Epoch 20 loss 1711.9443359375
Epoch 21 loss 1690.2437744140625
Epoch 22 loss 1279.958251953125
Epoch 23 loss 1168.669677734375
Epoch 24 loss 1335.422607421875
Epoch 25 loss 1091.8426513671875
Epoch 26 loss 1024.6661376953125
Epoch 27 loss 934.933837890625
Epoch 28 loss 918.4122314453125
Epoch 29 loss 1015.1419677734375
Epoch 30 loss 818.4950561523438
Epoch 31 loss 864.8148803710938
Epoch 32 loss 828.101318359375
Epoch 33 loss 940.5285034179688
Epoch 34 loss 847.593994140625
Epoch 35 loss 713.18359375
Epoch 36 loss 727.9345092773438
Epoch 37 loss 841.8255615234375
Epoch 38 loss 694.29052734375
Epoch 39 loss 731.205078125
Epoch 40 loss 713.8906860351562
Epoch 41 loss 697.505859375
Epoch 42 loss 724.7784423828125
Epoch 43 loss 672.0031127929688
Epoch 44 loss 636.5208740234375
Epoch 45 loss 629.1615600585938
Epoch 46 loss 827.7845458984375
Epoch 47 loss 692.9845581054688
Epoch 48 loss 648.7474975585938
Epoch 49 loss 643.7254638671875
Epoch 50 loss 734.3717041015625
Epoch 51 loss 595.103515625
Epoch 52 loss 644.242431640625
Epoch 53 loss 801.2106323242188
Epoch 54 loss 599.5636596679688
Epoch 55 loss 591.0317993164062
Epoch 56 loss 720.3236694335938
Epoch 57 loss 590.4586181640625
Epoch 58 loss 587.4969482421875
Epoch 59 loss 586.2801513671875
Epoch 60 loss 689.361328125
Epoch 61 loss 588.494140625
Epoch 62 loss 788.8881225585938
Epoch 63 loss 600.9697875976562
Epoch 64 loss 761.5775756835938
Epoch 65 loss 624.2958374023438
Epoch 66 loss 612.2282104492188
Epoch 67 loss 611.7067260742188
Epoch 68 loss 587.5607299804688
Epoch 69 loss 629.8941040039062
Epoch 70 loss 730.343017578125
Epoch 71 loss 556.3925170898438
Epoch 72 loss 638.0388793945312
Epoch 73 loss 587.5482788085938
Epoch 74 loss 573.31640625
Epoch 75 loss 604.84912109375
Epoch 76 loss 564.2311401367188
Epoch 77 loss 621.1918334960938
Epoch 78 loss 584.2128295898438
Epoch 79 loss 577.1450805664062
Epoch 80 loss 567.4854736328125
Epoch 81 loss 576.3018798828125
Epoch 82 loss 574.5552978515625
Epoch 83 loss 591.09619140625
Epoch 84 loss 543.185302734375
Epoch 85 loss 579.0948486328125
Epoch 86 loss 558.6328735351562
Epoch 87 loss 567.5752563476562
Epoch 88 loss 707.1087036132812
Epoch 89 loss 637.1837768554688
Epoch 90 loss 558.4593505859375
Epoch 91 loss 563.183837890625
Epoch 92 loss 576.8457641601562
Epoch 93 loss 556.0031127929688
Epoch 94 loss 631.2364501953125
Epoch 95 loss 553.0634155273438
Epoch 96 loss 567.04443359375
Epoch 97 loss 628.9183959960938
Epoch 98 loss 557.0291137695312
Epoch 99 loss 591.1478881835938
Saved Losses
{'MSE - mean': 543.1852662549147, 'MSE - std': 0.0, 'R2 - mean': 0.9368433296022861, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 520821.84375
Epoch 1 loss 517138.0625
Epoch 2 loss 511908.375
Epoch 3 loss 505053.375
Epoch 4 loss 495306.53125
Epoch 5 loss 475968.28125
Epoch 6 loss 440223.40625
Epoch 7 loss 383173.75
Epoch 8 loss 302495.375
Epoch 9 loss 203122.46875
Epoch 10 loss 103689.421875
Epoch 11 loss 33580.6796875
Epoch 12 loss 9209.3125
Epoch 13 loss 7734.78857421875
Epoch 14 loss 7508.490234375
Epoch 15 loss 7374.31005859375
Epoch 16 loss 6744.37548828125
Epoch 17 loss 3774.39990234375
Epoch 18 loss 2703.006591796875
Epoch 19 loss 1882.1326904296875
Epoch 20 loss 1530.7374267578125
Epoch 21 loss 1420.3785400390625
Epoch 22 loss 1222.6400146484375
Epoch 23 loss 1258.3599853515625
Epoch 24 loss 997.2554931640625
Epoch 25 loss 1129.3970947265625
Epoch 26 loss 882.4598999023438
Epoch 27 loss 873.6947631835938
Epoch 28 loss 778.7026977539062
Epoch 29 loss 784.2596435546875
Epoch 30 loss 747.4195556640625
Epoch 31 loss 683.5713500976562
Epoch 32 loss 760.4701538085938
Epoch 33 loss 707.5090942382812
Epoch 34 loss 647.8912963867188
Epoch 35 loss 632.4366455078125
Epoch 36 loss 617.5968017578125
Epoch 37 loss 581.35791015625
Epoch 38 loss 559.3172607421875
Epoch 39 loss 557.90087890625
Epoch 40 loss 610.8232421875
Epoch 41 loss 546.6992797851562
Epoch 42 loss 574.8536376953125
Epoch 43 loss 918.8773193359375
Epoch 44 loss 523.729736328125
Epoch 45 loss 516.9692993164062
Epoch 46 loss 536.2719116210938
Epoch 47 loss 570.4799194335938
Epoch 48 loss 517.47021484375
Epoch 49 loss 720.5308227539062
Epoch 50 loss 554.4059448242188
Epoch 51 loss 541.0563354492188
Epoch 52 loss 515.8009643554688
Epoch 53 loss 641.4950561523438
Epoch 54 loss 487.2140197753906
Epoch 55 loss 551.8817749023438
Epoch 56 loss 576.2485961914062
Epoch 57 loss 481.7626037597656
Epoch 58 loss 618.8353881835938
Epoch 59 loss 502.9615478515625
Epoch 60 loss 871.5885620117188
Epoch 61 loss 470.21417236328125
Epoch 62 loss 482.6023864746094
Epoch 63 loss 581.1500854492188
Epoch 64 loss 471.2920227050781
Epoch 65 loss 464.6246337890625
Epoch 66 loss 639.8634033203125
Epoch 67 loss 468.45751953125
Epoch 68 loss 515.1053466796875
Epoch 69 loss 543.5581665039062
Epoch 70 loss 501.8861389160156
Epoch 71 loss 530.3701171875
Epoch 72 loss 483.22357177734375
Epoch 73 loss 474.8210754394531
Epoch 74 loss 460.3585510253906
Epoch 75 loss 526.359619140625
Epoch 76 loss 459.60205078125
Epoch 77 loss 460.1756286621094
Epoch 78 loss 707.1041870117188
Epoch 79 loss 503.87091064453125
Epoch 80 loss 451.4407653808594
Epoch 81 loss 492.13128662109375
Epoch 82 loss 472.6088562011719
Epoch 83 loss 501.4565734863281
Epoch 84 loss 494.0098876953125
Epoch 85 loss 566.6255493164062
Epoch 86 loss 468.97857666015625
Epoch 87 loss 451.23089599609375
Epoch 88 loss 457.0809020996094
Epoch 89 loss 497.31549072265625
Epoch 90 loss 581.6724853515625
Epoch 91 loss 450.16717529296875
Epoch 92 loss 577.2513427734375
Epoch 93 loss 503.3165283203125
Epoch 94 loss 536.7003173828125
Epoch 95 loss 508.9468688964844
Epoch 96 loss 632.8652954101562
Epoch 97 loss 505.313720703125
Epoch 98 loss 476.2630310058594
Epoch 99 loss 534.9904174804688
Saved Losses
{'MSE - mean': 496.6761589118785, 'MSE - std': 46.50910734303622, 'R2 - mean': 0.9389623034596712, 'R2 - std': 0.002118973857385076} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515297.46875
Epoch 1 loss 512075.03125
Epoch 2 loss 507593.5
Epoch 3 loss 501133.96875
Epoch 4 loss 491987.96875
Epoch 5 loss 473872.34375
Epoch 6 loss 439247.03125
Epoch 7 loss 382873.59375
Epoch 8 loss 303125.65625
Epoch 9 loss 205237.234375
Epoch 10 loss 106780.5625
Epoch 11 loss 36494.3046875
Epoch 12 loss 10972.275390625
Epoch 13 loss 9512.4375
Epoch 14 loss 9237.3330078125
Epoch 15 loss 9041.828125
Epoch 16 loss 8635.7578125
Epoch 17 loss 5757.12158203125
Epoch 18 loss 3253.255126953125
Epoch 19 loss 2617.728759765625
Epoch 20 loss 1816.825927734375
Epoch 21 loss 1540.188232421875
Epoch 22 loss 1309.9234619140625
Epoch 23 loss 1206.8165283203125
Epoch 24 loss 1063.1845703125
Epoch 25 loss 1065.430908203125
Epoch 26 loss 995.7560424804688
Epoch 27 loss 1011.9157104492188
Epoch 28 loss 883.5525512695312
Epoch 29 loss 992.2249145507812
Epoch 30 loss 788.1932373046875
Epoch 31 loss 1148.6402587890625
Epoch 32 loss 787.5130615234375
Epoch 33 loss 745.4674072265625
Epoch 34 loss 817.122314453125
Epoch 35 loss 746.8948364257812
Epoch 36 loss 662.7144165039062
Epoch 37 loss 723.1401977539062
Epoch 38 loss 769.6210327148438
Epoch 39 loss 743.8526611328125
Epoch 40 loss 688.2426147460938
Epoch 41 loss 636.6527709960938
Epoch 42 loss 692.5671997070312
Epoch 43 loss 869.6386108398438
Epoch 44 loss 665.0612182617188
Epoch 45 loss 585.30322265625
Epoch 46 loss 714.4224853515625
Epoch 47 loss 680.5567016601562
Epoch 48 loss 577.9525146484375
Epoch 49 loss 550.0065307617188
Epoch 50 loss 701.1644897460938
Epoch 51 loss 567.34521484375
Epoch 52 loss 542.589599609375
Epoch 53 loss 538.20068359375
Epoch 54 loss 569.2626953125
Epoch 55 loss 560.6554565429688
Epoch 56 loss 613.032470703125
Epoch 57 loss 515.109375
Epoch 58 loss 720.0591430664062
Epoch 59 loss 505.7871398925781
Epoch 60 loss 669.2923583984375
Epoch 61 loss 749.00439453125
Epoch 62 loss 523.20947265625
Epoch 63 loss 479.9895935058594
Epoch 64 loss 766.5585327148438
Epoch 65 loss 482.94439697265625
Epoch 66 loss 475.0013732910156
Epoch 67 loss 552.4682006835938
Epoch 68 loss 554.2273559570312
Epoch 69 loss 545.4026489257812
Epoch 70 loss 483.7406311035156
Epoch 71 loss 674.4802856445312
Epoch 72 loss 488.1687316894531
Epoch 73 loss 478.1199645996094
Epoch 74 loss 775.0555419921875
Epoch 75 loss 558.9489135742188
Epoch 76 loss 647.8863525390625
Epoch 77 loss 490.85870361328125
Epoch 78 loss 555.5576171875
Epoch 79 loss 487.5811462402344
Epoch 80 loss 521.0452270507812
Epoch 81 loss 749.1897583007812
Epoch 82 loss 474.6387634277344
Epoch 83 loss 475.2564392089844
Epoch 84 loss 607.65966796875
Epoch 85 loss 508.0906677246094
Epoch 86 loss 659.5772094726562
Epoch 87 loss 502.4472351074219
Epoch 88 loss 576.2743530273438
Epoch 89 loss 563.4674682617188
Epoch 90 loss 501.90057373046875
Epoch 91 loss 476.9446716308594
Epoch 92 loss 570.8428344726562
Epoch 93 loss 497.37750244140625
Epoch 94 loss 641.89794921875
Epoch 95 loss 499.3218078613281
Epoch 96 loss 589.9390258789062
Epoch 97 loss 480.2474060058594
Epoch 98 loss 459.4635314941406
Epoch 99 loss 475.9540100097656
Saved Losses
{'MSE - mean': 484.2720256963973, 'MSE - std': 41.83048830959125, 'R2 - mean': 0.9428548879804457, 'R2 - std': 0.005770424187897073} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519478.5
Epoch 1 loss 517517.3125
Epoch 2 loss 514140.84375
Epoch 3 loss 508643.78125
Epoch 4 loss 499586.34375
Epoch 5 loss 481575.4375
Epoch 6 loss 448639.34375
Epoch 7 loss 395678.0
Epoch 8 loss 319808.96875
Epoch 9 loss 224724.453125
Epoch 10 loss 125254.203125
Epoch 11 loss 47708.73828125
Epoch 12 loss 12873.572265625
Epoch 13 loss 8309.1611328125
Epoch 14 loss 8304.80078125
Epoch 15 loss 8075.63037109375
Epoch 16 loss 7130.11572265625
Epoch 17 loss 4242.1962890625
Epoch 18 loss 3287.848876953125
Epoch 19 loss 2248.314697265625
Epoch 20 loss 2107.836669921875
Epoch 21 loss 1504.293701171875
Epoch 22 loss 1343.301513671875
Epoch 23 loss 1162.3388671875
Epoch 24 loss 1143.432373046875
Epoch 25 loss 1036.4310302734375
Epoch 26 loss 1024.8922119140625
Epoch 27 loss 1151.4031982421875
Epoch 28 loss 1041.0006103515625
Epoch 29 loss 829.32861328125
Epoch 30 loss 1317.01318359375
Epoch 31 loss 856.9334106445312
Epoch 32 loss 1248.2130126953125
Epoch 33 loss 718.233154296875
Epoch 34 loss 1142.0538330078125
Epoch 35 loss 757.5271606445312
Epoch 36 loss 742.6831665039062
Epoch 37 loss 665.6683959960938
Epoch 38 loss 894.947021484375
Epoch 39 loss 671.3875732421875
Epoch 40 loss 805.3602294921875
Epoch 41 loss 601.9869384765625
Epoch 42 loss 699.6182861328125
Epoch 43 loss 677.6554565429688
Epoch 44 loss 729.9443969726562
Epoch 45 loss 579.98779296875
Epoch 46 loss 647.7084350585938
Epoch 47 loss 764.9031372070312
Epoch 48 loss 677.5069580078125
Epoch 49 loss 639.6395874023438
Epoch 50 loss 668.485595703125
Epoch 51 loss 619.9750366210938
Epoch 52 loss 736.1393432617188
Epoch 53 loss 721.266845703125
Epoch 54 loss 593.6543579101562
Epoch 55 loss 628.8273315429688
Epoch 56 loss 645.0413208007812
Epoch 57 loss 647.5768432617188
Epoch 58 loss 759.5369262695312
Epoch 59 loss 607.9197387695312
Epoch 60 loss 526.6492309570312
Epoch 61 loss 562.5148315429688
Epoch 62 loss 647.5484008789062
Epoch 63 loss 558.947021484375
Epoch 64 loss 545.5
Epoch 65 loss 580.5458374023438
Epoch 66 loss 690.1591796875
Epoch 67 loss 522.5357666015625
Epoch 68 loss 550.1963500976562
Epoch 69 loss 534.1873779296875
Epoch 70 loss 580.8204956054688
Epoch 71 loss 543.1251220703125
Epoch 72 loss 592.4559326171875
Epoch 73 loss 543.1891479492188
Epoch 74 loss 687.957275390625
Epoch 75 loss 517.2406005859375
Epoch 76 loss 613.6200561523438
Epoch 77 loss 512.3572387695312
Epoch 78 loss 552.6633911132812
Epoch 79 loss 541.3618774414062
Epoch 80 loss 656.3610229492188
Epoch 81 loss 599.8053588867188
Epoch 82 loss 589.9437866210938
Epoch 83 loss 508.16650390625
Epoch 84 loss 570.8812255859375
Epoch 85 loss 510.07781982421875
Epoch 86 loss 531.7197265625
Epoch 87 loss 557.7178344726562
Epoch 88 loss 884.3826904296875
Epoch 89 loss 518.959228515625
Epoch 90 loss 491.8902893066406
Epoch 91 loss 898.0299072265625
Epoch 92 loss 495.7337341308594
Epoch 93 loss 662.2047729492188
Epoch 94 loss 523.0928344726562
Epoch 95 loss 521.4424438476562
Epoch 96 loss 523.4598999023438
Epoch 97 loss 568.7315673828125
Epoch 98 loss 525.70068359375
Epoch 99 loss 502.7528076171875
Saved Losses
{'MSE - mean': 486.17655745793985, 'MSE - std': 36.376146550401835, 'R2 - mean': 0.9423350354389018, 'R2 - std': 0.005077803312068073} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516239.9375
Epoch 1 loss 514099.9375
Epoch 2 loss 510598.875
Epoch 3 loss 505131.0
Epoch 4 loss 496313.59375
Epoch 5 loss 478164.125
Epoch 6 loss 444268.34375
Epoch 7 loss 388832.46875
Epoch 8 loss 308813.0
Epoch 9 loss 208632.5
Epoch 10 loss 107226.734375
Epoch 11 loss 34718.671875
Epoch 12 loss 9379.708984375
Epoch 13 loss 8203.205078125
Epoch 14 loss 7825.43310546875
Epoch 15 loss 7603.72021484375
Epoch 16 loss 6250.95703125
Epoch 17 loss 3861.596923828125
Epoch 18 loss 2420.87841796875
Epoch 19 loss 1801.2886962890625
Epoch 20 loss 1495.5264892578125
Epoch 21 loss 1405.972900390625
Epoch 22 loss 1127.6741943359375
Epoch 23 loss 1041.9808349609375
Epoch 24 loss 960.1739501953125
Epoch 25 loss 955.7702026367188
Epoch 26 loss 857.9408569335938
Epoch 27 loss 826.9720458984375
Epoch 28 loss 886.8748168945312
Epoch 29 loss 772.6576538085938
Epoch 30 loss 743.9871826171875
Epoch 31 loss 716.3057861328125
Epoch 32 loss 876.2052001953125
Epoch 33 loss 714.0518798828125
Epoch 34 loss 647.8173217773438
Epoch 35 loss 639.605224609375
Epoch 36 loss 798.7932739257812
Epoch 37 loss 593.3035888671875
Epoch 38 loss 811.0260620117188
Epoch 39 loss 663.19384765625
Epoch 40 loss 569.0593872070312
Epoch 41 loss 573.2816162109375
Epoch 42 loss 600.2509765625
Epoch 43 loss 540.2427368164062
Epoch 44 loss 603.3148803710938
Epoch 45 loss 577.2643432617188
Epoch 46 loss 572.9593505859375
Epoch 47 loss 538.6332397460938
Epoch 48 loss 555.8228759765625
Epoch 49 loss 660.8113403320312
Epoch 50 loss 523.6444091796875
Epoch 51 loss 540.2828369140625
Epoch 52 loss 572.8291625976562
Epoch 53 loss 586.5133056640625
Epoch 54 loss 533.0732421875
Epoch 55 loss 569.6549682617188
Epoch 56 loss 584.0426635742188
Epoch 57 loss 542.0869750976562
Epoch 58 loss 512.2655029296875
Epoch 59 loss 607.7501220703125
Epoch 60 loss 549.6058959960938
Epoch 61 loss 499.7814025878906
Epoch 62 loss 565.5548706054688
Epoch 63 loss 532.3273315429688
Epoch 64 loss 501.06585693359375
Epoch 65 loss 501.0868225097656
Epoch 66 loss 583.4358520507812
Epoch 67 loss 493.0412902832031
Epoch 68 loss 502.93011474609375
Epoch 69 loss 478.1607666015625
Epoch 70 loss 519.1041870117188
Epoch 71 loss 497.8886413574219
Epoch 72 loss 498.27685546875
Epoch 73 loss 678.3121948242188
Epoch 74 loss 474.66241455078125
Epoch 75 loss 470.4552917480469
Epoch 76 loss 559.6823120117188
Epoch 77 loss 474.6871032714844
Epoch 78 loss 474.7244567871094
Epoch 79 loss 483.2233581542969
Epoch 80 loss 479.8226623535156
Epoch 81 loss 517.9948120117188
Epoch 82 loss 553.1483764648438
Epoch 83 loss 592.2874755859375
Epoch 84 loss 497.6427001953125
Epoch 85 loss 484.87884521484375
Epoch 86 loss 550.0957641601562
Epoch 87 loss 482.58856201171875
Epoch 88 loss 521.111083984375
Epoch 89 loss 460.9889831542969
Epoch 90 loss 481.294189453125
Epoch 91 loss 470.0836181640625
Epoch 92 loss 540.873291015625
Epoch 93 loss 476.8292541503906
Epoch 94 loss 470.03448486328125
Epoch 95 loss 493.2784118652344
Epoch 96 loss 566.536865234375
Epoch 97 loss 492.2245788574219
Epoch 98 loss 498.4416198730469
Epoch 99 loss 482.2391357421875
Saved Losses
{'MSE - mean': 481.1390298060152, 'MSE - std': 34.06003478654528, 'R2 - mean': 0.9423115791790881, 'R2 - std': 0.004541967631471785} 
 

Results After CV: {'MSE - mean': 481.1390298060152, 'MSE - std': 34.06003478654528, 'R2 - mean': 0.9423115791790881, 'R2 - std': 0.004541967631471785}
Train time: 101.78468606560018
Inference time: 0.14528977259942621
Finished cross validation
Trial 22 finished with value: 481.1390298060152 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.4}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515467.15625
Epoch 1 loss 513796.15625
Epoch 2 loss 510837.75
Epoch 3 loss 505761.0625
Epoch 4 loss 497429.46875
Epoch 5 loss 481156.3125
Epoch 6 loss 450221.59375
Epoch 7 loss 399008.90625
Epoch 8 loss 324047.5625
Epoch 9 loss 228372.9375
Epoch 10 loss 126969.9140625
Epoch 11 loss 47273.02734375
Epoch 12 loss 12404.0
Epoch 13 loss 8695.8154296875
Epoch 14 loss 8398.9189453125
Epoch 15 loss 6058.68896484375
Epoch 16 loss 3114.60888671875
Epoch 17 loss 2143.75537109375
Epoch 18 loss 1715.51123046875
Epoch 19 loss 1516.11572265625
Epoch 20 loss 1364.7908935546875
Epoch 21 loss 1198.479736328125
Epoch 22 loss 1183.62890625
Epoch 23 loss 1158.9810791015625
Epoch 24 loss 1022.3946533203125
Epoch 25 loss 974.5623168945312
Epoch 26 loss 1016.5076293945312
Epoch 27 loss 967.3162841796875
Epoch 28 loss 886.92626953125
Epoch 29 loss 879.6465454101562
Epoch 30 loss 796.8507690429688
Epoch 31 loss 803.4151000976562
Epoch 32 loss 805.4282836914062
Epoch 33 loss 788.8511352539062
Epoch 34 loss 788.8729858398438
Epoch 35 loss 709.4697875976562
Epoch 36 loss 727.873779296875
Epoch 37 loss 963.7691040039062
Epoch 38 loss 710.3869018554688
Epoch 39 loss 703.23095703125
Epoch 40 loss 671.4003295898438
Epoch 41 loss 710.340576171875
Epoch 42 loss 756.9805908203125
Epoch 43 loss 719.1744995117188
Epoch 44 loss 713.4262084960938
Epoch 45 loss 672.4134521484375
Epoch 46 loss 751.7369995117188
Epoch 47 loss 616.283935546875
Epoch 48 loss 621.594482421875
Epoch 49 loss 644.8309326171875
Epoch 50 loss 630.4007568359375
Epoch 51 loss 628.3445434570312
Epoch 52 loss 596.603515625
Epoch 53 loss 598.5739135742188
Epoch 54 loss 591.7796630859375
Epoch 55 loss 679.1324462890625
Epoch 56 loss 683.5534057617188
Epoch 57 loss 583.5464477539062
Epoch 58 loss 598.5359497070312
Epoch 59 loss 757.5867919921875
Epoch 60 loss 600.9810791015625
Epoch 61 loss 587.0119018554688
Epoch 62 loss 617.5126342773438
Epoch 63 loss 583.063232421875
Epoch 64 loss 587.7550048828125
Epoch 65 loss 577.6245727539062
Epoch 66 loss 570.6702880859375
Epoch 67 loss 583.0524291992188
Epoch 68 loss 590.84814453125
Epoch 69 loss 617.2207641601562
Epoch 70 loss 579.969970703125
Epoch 71 loss 706.0264892578125
Epoch 72 loss 701.2569580078125
Epoch 73 loss 607.873046875
Epoch 74 loss 666.1077270507812
Epoch 75 loss 588.1949462890625
Epoch 76 loss 573.2962036132812
Epoch 77 loss 581.3072509765625
Epoch 78 loss 567.5845947265625
Epoch 79 loss 558.5476684570312
Epoch 80 loss 563.5771484375
Epoch 81 loss 604.5538330078125
Epoch 82 loss 558.2654418945312
Epoch 83 loss 556.963623046875
Epoch 84 loss 743.0292358398438
Epoch 85 loss 553.2811279296875
Epoch 86 loss 578.3931884765625
Epoch 87 loss 562.4082641601562
Epoch 88 loss 564.5860595703125
Epoch 89 loss 592.289794921875
Epoch 90 loss 577.817626953125
Epoch 91 loss 576.8242797851562
Epoch 92 loss 554.0217895507812
Epoch 93 loss 545.547607421875
Epoch 94 loss 555.3494873046875
Epoch 95 loss 546.4437255859375
Epoch 96 loss 593.6558227539062
Epoch 97 loss 658.7609252929688
Epoch 98 loss 627.0811767578125
Epoch 99 loss 545.0115966796875
Saved Losses
{'MSE - mean': 545.0117599300414, 'MSE - std': 0.0, 'R2 - mean': 0.9366309614358613, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 524176.625
Epoch 1 loss 522394.5625
Epoch 2 loss 519432.0
Epoch 3 loss 514355.53125
Epoch 4 loss 506185.96875
Epoch 5 loss 491349.84375
Epoch 6 loss 462644.9375
Epoch 7 loss 414160.40625
Epoch 8 loss 341910.78125
Epoch 9 loss 247433.9375
Epoch 10 loss 143504.59375
Epoch 11 loss 56947.7890625
Epoch 12 loss 14470.3623046875
Epoch 13 loss 7632.7958984375
Epoch 14 loss 7553.5810546875
Epoch 15 loss 7418.5517578125
Epoch 16 loss 3570.122314453125
Epoch 17 loss 2459.091064453125
Epoch 18 loss 2297.528076171875
Epoch 19 loss 2393.726318359375
Epoch 20 loss 1582.58935546875
Epoch 21 loss 1382.655517578125
Epoch 22 loss 1089.720458984375
Epoch 23 loss 1049.79052734375
Epoch 24 loss 948.7603759765625
Epoch 25 loss 850.8834228515625
Epoch 26 loss 855.7394409179688
Epoch 27 loss 771.1190795898438
Epoch 28 loss 698.2476196289062
Epoch 29 loss 685.8029174804688
Epoch 30 loss 722.5762329101562
Epoch 31 loss 735.6161499023438
Epoch 32 loss 620.5267944335938
Epoch 33 loss 672.4190673828125
Epoch 34 loss 560.5101318359375
Epoch 35 loss 646.1976318359375
Epoch 36 loss 632.0253295898438
Epoch 37 loss 521.6511840820312
Epoch 38 loss 599.106201171875
Epoch 39 loss 553.0938720703125
Epoch 40 loss 520.0936279296875
Epoch 41 loss 517.0181884765625
Epoch 42 loss 493.2262268066406
Epoch 43 loss 517.7108764648438
Epoch 44 loss 474.6297607421875
Epoch 45 loss 499.2035217285156
Epoch 46 loss 485.10504150390625
Epoch 47 loss 479.65509033203125
Epoch 48 loss 488.71630859375
Epoch 49 loss 534.6842041015625
Epoch 50 loss 544.2484130859375
Epoch 51 loss 458.87823486328125
Epoch 52 loss 564.6773681640625
Epoch 53 loss 530.4507446289062
Epoch 54 loss 573.4339599609375
Epoch 55 loss 471.7442626953125
Epoch 56 loss 460.6656188964844
Epoch 57 loss 560.0859985351562
Epoch 58 loss 480.04766845703125
Epoch 59 loss 448.0281066894531
Epoch 60 loss 466.1901550292969
Epoch 61 loss 459.67266845703125
Epoch 62 loss 520.2939453125
Epoch 63 loss 456.5758361816406
Epoch 64 loss 492.6435852050781
Epoch 65 loss 446.15081787109375
Epoch 66 loss 439.27764892578125
Epoch 67 loss 462.26873779296875
Epoch 68 loss 452.0250244140625
Epoch 69 loss 447.9112854003906
Epoch 70 loss 440.0922546386719
Epoch 71 loss 433.5545959472656
Epoch 72 loss 458.66790771484375
Epoch 73 loss 518.5474243164062
Epoch 74 loss 467.23382568359375
Epoch 75 loss 449.92156982421875
Epoch 76 loss 443.27667236328125
Epoch 77 loss 541.89990234375
Epoch 78 loss 458.14849853515625
Epoch 79 loss 439.3504943847656
Epoch 80 loss 466.14312744140625
Epoch 81 loss 441.7542419433594
Epoch 82 loss 451.42791748046875
Epoch 83 loss 440.85272216796875
Epoch 84 loss 457.09332275390625
Epoch 85 loss 446.0843811035156
Epoch 86 loss 442.2649841308594
Epoch 87 loss 483.7669677734375
Epoch 88 loss 457.1446228027344
Epoch 89 loss 486.25982666015625
Epoch 90 loss 439.21240234375
Epoch 91 loss 432.773681640625
Epoch 92 loss 436.3932800292969
Epoch 93 loss 443.32275390625
Epoch 94 loss 476.8955993652344
Epoch 95 loss 444.172607421875
Epoch 96 loss 440.6899108886719
Epoch 97 loss 439.0843811035156
Epoch 98 loss 478.1549072265625
Epoch 99 loss 632.6738891601562
Saved Losses
{'MSE - mean': 488.89277598575165, 'MSE - std': 56.118983944289766, 'R2 - mean': 0.9399943508741604, 'R2 - std': 0.0033633894382990026} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515052.65625
Epoch 1 loss 511848.46875
Epoch 2 loss 507112.28125
Epoch 3 loss 500266.125
Epoch 4 loss 489538.0
Epoch 5 loss 468110.34375
Epoch 6 loss 429184.5625
Epoch 7 loss 368163.0
Epoch 8 loss 283880.78125
Epoch 9 loss 184152.1875
Epoch 10 loss 89461.125
Epoch 11 loss 28191.185546875
Epoch 12 loss 10007.32421875
Epoch 13 loss 9466.236328125
Epoch 14 loss 9027.3798828125
Epoch 15 loss 7892.23046875
Epoch 16 loss 3721.2431640625
Epoch 17 loss 2362.271240234375
Epoch 18 loss 2093.778564453125
Epoch 19 loss 1605.802490234375
Epoch 20 loss 1377.3310546875
Epoch 21 loss 1268.6470947265625
Epoch 22 loss 1130.2109375
Epoch 23 loss 1081.6092529296875
Epoch 24 loss 1103.9932861328125
Epoch 25 loss 876.0769653320312
Epoch 26 loss 883.0211791992188
Epoch 27 loss 835.6521606445312
Epoch 28 loss 729.0148315429688
Epoch 29 loss 684.569580078125
Epoch 30 loss 674.711181640625
Epoch 31 loss 629.6809692382812
Epoch 32 loss 608.6715698242188
Epoch 33 loss 585.4402465820312
Epoch 34 loss 663.873779296875
Epoch 35 loss 673.6350708007812
Epoch 36 loss 628.0276489257812
Epoch 37 loss 571.2288818359375
Epoch 38 loss 1026.82275390625
Epoch 39 loss 662.2584228515625
Epoch 40 loss 647.250244140625
Epoch 41 loss 570.4164428710938
Epoch 42 loss 600.9383544921875
Epoch 43 loss 561.83837890625
Epoch 44 loss 523.0285034179688
Epoch 45 loss 512.2528686523438
Epoch 46 loss 502.225830078125
Epoch 47 loss 501.4259338378906
Epoch 48 loss 494.3352355957031
Epoch 49 loss 551.8640747070312
Epoch 50 loss 562.9102172851562
Epoch 51 loss 549.2587280273438
Epoch 52 loss 481.735107421875
Epoch 53 loss 495.2121276855469
Epoch 54 loss 495.33074951171875
Epoch 55 loss 482.36932373046875
Epoch 56 loss 501.23699951171875
Epoch 57 loss 504.90960693359375
Epoch 58 loss 475.9326477050781
Epoch 59 loss 557.2571411132812
Epoch 60 loss 544.7798461914062
Epoch 61 loss 667.110595703125
Epoch 62 loss 601.6827392578125
Epoch 63 loss 469.7772216796875
Epoch 64 loss 467.6294250488281
Epoch 65 loss 486.17034912109375
Epoch 66 loss 557.5032348632812
Epoch 67 loss 788.6123657226562
Epoch 68 loss 475.4010314941406
Epoch 69 loss 475.7253112792969
Epoch 70 loss 488.45013427734375
Epoch 71 loss 597.4822998046875
Epoch 72 loss 479.3661193847656
Epoch 73 loss 498.3835754394531
Epoch 74 loss 506.7296142578125
Epoch 75 loss 506.83648681640625
Epoch 76 loss 499.5011901855469
Epoch 77 loss 548.795166015625
Epoch 78 loss 500.5594787597656
Epoch 79 loss 588.1361694335938
Epoch 80 loss 509.7153015136719
Epoch 81 loss 467.8804016113281
Epoch 82 loss 480.23382568359375
Epoch 83 loss 470.6759338378906
Epoch 84 loss 498.57861328125
Epoch 85 loss 484.6058349609375
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 481.80501478276346, 'MSE - std': 46.904508920082904, 'R2 - mean': 0.943250506160593, 'R2 - std': 0.005361593684826228} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518004.75
Epoch 1 loss 515228.84375
Epoch 2 loss 511141.5
Epoch 3 loss 504952.03125
Epoch 4 loss 495521.375
Epoch 5 loss 477136.25
Epoch 6 loss 442537.46875
Epoch 7 loss 386535.90625
Epoch 8 loss 306199.90625
Epoch 9 loss 206150.046875
Epoch 10 loss 105215.2109375
Epoch 11 loss 34452.52734375
Epoch 12 loss 9772.13671875
Epoch 13 loss 8449.625
Epoch 14 loss 8268.142578125
Epoch 15 loss 7545.5869140625
Epoch 16 loss 3819.65185546875
Epoch 17 loss 2598.591796875
Epoch 18 loss 2024.149169921875
Epoch 19 loss 1625.43798828125
Epoch 20 loss 1612.887939453125
Epoch 21 loss 1326.3739013671875
Epoch 22 loss 1179.1673583984375
Epoch 23 loss 1118.3653564453125
Epoch 24 loss 1149.818115234375
Epoch 25 loss 1143.6099853515625
Epoch 26 loss 880.0311889648438
Epoch 27 loss 787.21728515625
Epoch 28 loss 803.4931030273438
Epoch 29 loss 722.5078735351562
Epoch 30 loss 743.9385986328125
Epoch 31 loss 783.7003784179688
Epoch 32 loss 712.7267456054688
Epoch 33 loss 655.3944702148438
Epoch 34 loss 637.9598388671875
Epoch 35 loss 611.2666015625
Epoch 36 loss 639.873046875
Epoch 37 loss 619.439453125
Epoch 38 loss 686.27490234375
Epoch 39 loss 641.3389282226562
Epoch 40 loss 589.4093017578125
Epoch 41 loss 588.826171875
Epoch 42 loss 588.7089233398438
Epoch 43 loss 566.9977416992188
Epoch 44 loss 580.9703979492188
Epoch 45 loss 648.4015502929688
Epoch 46 loss 777.4910888671875
Epoch 47 loss 547.3692626953125
Epoch 48 loss 546.36962890625
Epoch 49 loss 537.2468872070312
Epoch 50 loss 538.5302124023438
Epoch 51 loss 558.8173828125
Epoch 52 loss 713.1220092773438
Epoch 53 loss 679.8173217773438
Epoch 54 loss 593.051513671875
Epoch 55 loss 576.7410888671875
Epoch 56 loss 569.6904296875
Epoch 57 loss 526.9126586914062
Epoch 58 loss 532.022216796875
Epoch 59 loss 528.3541259765625
Epoch 60 loss 591.2144165039062
Epoch 61 loss 590.9576416015625
Epoch 62 loss 619.3609008789062
Epoch 63 loss 529.8067016601562
Epoch 64 loss 612.697998046875
Epoch 65 loss 512.4580688476562
Epoch 66 loss 527.5125122070312
Epoch 67 loss 542.6036376953125
Epoch 68 loss 535.517822265625
Epoch 69 loss 557.4097900390625
Epoch 70 loss 534.8203125
Epoch 71 loss 532.53173828125
Epoch 72 loss 501.3680114746094
Epoch 73 loss 528.4710083007812
Epoch 74 loss 513.9364624023438
Epoch 75 loss 504.7076110839844
Epoch 76 loss 513.3720092773438
Epoch 77 loss 497.9920959472656
Epoch 78 loss 504.1485595703125
Epoch 79 loss 517.5801391601562
Epoch 80 loss 495.3690185546875
Epoch 81 loss 509.2221374511719
Epoch 82 loss 499.7421875
Epoch 83 loss 487.4830627441406
Epoch 84 loss 512.732421875
Epoch 85 loss 492.2222900390625
Epoch 86 loss 513.5640869140625
Epoch 87 loss 509.003662109375
Epoch 88 loss 498.1981506347656
Epoch 89 loss 508.7508239746094
Epoch 90 loss 507.61181640625
Epoch 91 loss 512.9103393554688
Epoch 92 loss 496.72088623046875
Epoch 93 loss 516.5623168945312
Epoch 94 loss 528.4338989257812
Epoch 95 loss 500.9418640136719
Epoch 96 loss 492.48760986328125
Epoch 97 loss 520.8719482421875
Epoch 98 loss 561.8538818359375
Epoch 99 loss 486.4092712402344
Saved Losses
{'MSE - mean': 482.956086239278, 'MSE - std': 40.669394073057084, 'R2 - mean': 0.9427967253634247, 'R2 - std': 0.004709327570525606} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515051.15625
Epoch 1 loss 512366.21875
Epoch 2 loss 508402.0625
Epoch 3 loss 503219.9375
Epoch 4 loss 496125.625
Epoch 5 loss 481636.28125
Epoch 6 loss 453076.5625
Epoch 7 loss 405708.75
Epoch 8 loss 335568.1875
Epoch 9 loss 244357.71875
Epoch 10 loss 143408.671875
Epoch 11 loss 58558.87109375
Epoch 12 loss 15289.9912109375
Epoch 13 loss 7972.32763671875
Epoch 14 loss 8058.64697265625
Epoch 15 loss 8226.9208984375
Epoch 16 loss 6996.64501953125
Epoch 17 loss 3408.07666015625
Epoch 18 loss 2223.0673828125
Epoch 19 loss 1846.247314453125
Epoch 20 loss 1504.8861083984375
Epoch 21 loss 1360.7862548828125
Epoch 22 loss 1314.985107421875
Epoch 23 loss 1115.5115966796875
Epoch 24 loss 1101.1719970703125
Epoch 25 loss 1096.9290771484375
Epoch 26 loss 947.282470703125
Epoch 27 loss 862.6339721679688
Epoch 28 loss 833.1334838867188
Epoch 29 loss 855.572265625
Epoch 30 loss 932.3919677734375
Epoch 31 loss 913.8037109375
Epoch 32 loss 699.0565795898438
Epoch 33 loss 760.3232421875
Epoch 34 loss 696.6790771484375
Epoch 35 loss 757.0315551757812
Epoch 36 loss 651.0202026367188
Epoch 37 loss 659.42919921875
Epoch 38 loss 608.1506958007812
Epoch 39 loss 651.1011962890625
Epoch 40 loss 736.2235717773438
Epoch 41 loss 606.8448486328125
Epoch 42 loss 588.5479736328125
Epoch 43 loss 624.6248779296875
Epoch 44 loss 635.5558471679688
Epoch 45 loss 754.6544189453125
Epoch 46 loss 688.8887939453125
Epoch 47 loss 637.0272827148438
Epoch 48 loss 629.1747436523438
Epoch 49 loss 953.53857421875
Epoch 50 loss 747.7734985351562
Epoch 51 loss 566.9365234375
Epoch 52 loss 672.1244506835938
Epoch 53 loss 587.867919921875
Epoch 54 loss 516.0267944335938
Epoch 55 loss 721.9324951171875
Epoch 56 loss 526.81396484375
Epoch 57 loss 513.1876220703125
Epoch 58 loss 511.7071533203125
Epoch 59 loss 503.94708251953125
Epoch 60 loss 505.3979187011719
Epoch 61 loss 573.98193359375
Epoch 62 loss 566.3287353515625
Epoch 63 loss 505.0915832519531
Epoch 64 loss 533.9813232421875
Epoch 65 loss 494.5124206542969
Epoch 66 loss 487.3233947753906
Epoch 67 loss 573.5585327148438
Epoch 68 loss 483.4456787109375
Epoch 69 loss 562.3934326171875
Epoch 70 loss 502.7931823730469
Epoch 71 loss 483.745849609375
Epoch 72 loss 528.5415649414062
Epoch 73 loss 502.5579833984375
Epoch 74 loss 489.0335388183594
Epoch 75 loss 495.2696228027344
Epoch 76 loss 516.0317993164062
Epoch 77 loss 499.1463928222656
Epoch 78 loss 527.57861328125
Epoch 79 loss 656.7745361328125
Epoch 80 loss 518.0670776367188
Epoch 81 loss 584.2337036132812
Epoch 82 loss 621.1243286132812
Epoch 83 loss 471.31988525390625
Epoch 84 loss 490.6546630859375
Epoch 85 loss 484.2018737792969
Epoch 86 loss 565.5601196289062
Epoch 87 loss 482.81585693359375
Epoch 88 loss 686.5443115234375
Epoch 89 loss 513.4595336914062
Epoch 90 loss 478.2964782714844
Epoch 91 loss 564.97509765625
Epoch 92 loss 522.405517578125
Epoch 93 loss 488.83953857421875
Epoch 94 loss 495.4189453125
Epoch 95 loss 547.9085083007812
Epoch 96 loss 534.9367065429688
Epoch 97 loss 482.9739685058594
Epoch 98 loss 484.96923828125
Epoch 99 loss 489.2118835449219
Saved Losses
{'MSE - mean': 480.6288367119317, 'MSE - std': 36.67238815329352, 'R2 - mean': 0.9424219471387811, 'R2 - std': 0.004278323013036523} 
 

Results After CV: {'MSE - mean': 480.6288367119317, 'MSE - std': 36.67238815329352, 'R2 - mean': 0.9424219471387811, 'R2 - std': 0.004278323013036523}
Train time: 98.56479847459995
Inference time: 0.13962578240025322
Finished cross validation
Trial 23 finished with value: 480.6288367119317 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513649.0625
Epoch 1 loss 510797.0
Epoch 2 loss 506693.0
Epoch 3 loss 500685.34375
Epoch 4 loss 492103.0
Epoch 5 loss 475965.5625
Epoch 6 loss 444986.28125
Epoch 7 loss 392912.0625
Epoch 8 loss 316971.75
Epoch 9 loss 220411.9375
Epoch 10 loss 118612.296875
Epoch 11 loss 41536.17578125
Epoch 12 loss 10960.50390625
Epoch 13 loss 8816.0771484375
Epoch 14 loss 8607.28515625
Epoch 15 loss 8419.287109375
Epoch 16 loss 8277.8310546875
Epoch 17 loss 7667.41943359375
Epoch 18 loss 5356.45166015625
Epoch 19 loss 3296.5283203125
Epoch 20 loss 2468.404296875
Epoch 21 loss 2010.20703125
Epoch 22 loss 1652.4337158203125
Epoch 23 loss 1870.59130859375
Epoch 24 loss 1453.9259033203125
Epoch 25 loss 1299.89404296875
Epoch 26 loss 1312.4473876953125
Epoch 27 loss 1173.478515625
Epoch 28 loss 1123.8406982421875
Epoch 29 loss 1186.5550537109375
Epoch 30 loss 1166.8909912109375
Epoch 31 loss 1103.51171875
Epoch 32 loss 1653.4769287109375
Epoch 33 loss 1080.157470703125
Epoch 34 loss 989.3724975585938
Epoch 35 loss 931.9091796875
Epoch 36 loss 964.4733276367188
Epoch 37 loss 903.9805297851562
Epoch 38 loss 1439.5848388671875
Epoch 39 loss 1170.6522216796875
Epoch 40 loss 883.9616088867188
Epoch 41 loss 1187.3623046875
Epoch 42 loss 1012.477294921875
Epoch 43 loss 1108.614990234375
Epoch 44 loss 830.2239379882812
Epoch 45 loss 1029.6827392578125
Epoch 46 loss 839.6280517578125
Epoch 47 loss 838.9845581054688
Epoch 48 loss 783.2254028320312
Epoch 49 loss 845.9087524414062
Epoch 50 loss 820.8531494140625
Epoch 51 loss 932.6502075195312
Epoch 52 loss 911.89892578125
Epoch 53 loss 811.91259765625
Epoch 54 loss 732.4550170898438
Epoch 55 loss 751.79833984375
Epoch 56 loss 1079.3153076171875
Epoch 57 loss 893.6985473632812
Epoch 58 loss 1272.166259765625
Epoch 59 loss 762.1871337890625
Epoch 60 loss 761.9093627929688
Epoch 61 loss 822.62890625
Epoch 62 loss 740.7880249023438
Epoch 63 loss 731.4229736328125
Epoch 64 loss 696.729248046875
Epoch 65 loss 689.3184814453125
Epoch 66 loss 832.9298706054688
Epoch 67 loss 680.6376342773438
Epoch 68 loss 726.78369140625
Epoch 69 loss 884.4539184570312
Epoch 70 loss 792.2314453125
Epoch 71 loss 936.862060546875
Epoch 72 loss 694.9633178710938
Epoch 73 loss 875.0655517578125
Epoch 74 loss 678.273681640625
Epoch 75 loss 1101.1307373046875
Epoch 76 loss 766.8104858398438
Epoch 77 loss 847.700927734375
Epoch 78 loss 969.3706665039062
Epoch 79 loss 873.9859008789062
Epoch 80 loss 789.7053833007812
Epoch 81 loss 645.6566162109375
Epoch 82 loss 631.1063842773438
Epoch 83 loss 741.072021484375
Epoch 84 loss 643.8197021484375
Epoch 85 loss 770.5345458984375
Epoch 86 loss 699.4362182617188
Epoch 87 loss 657.62841796875
Epoch 88 loss 663.8587036132812
Epoch 89 loss 675.627685546875
Epoch 90 loss 700.270263671875
Epoch 91 loss 643.7169189453125
Epoch 92 loss 817.0779418945312
Epoch 93 loss 667.7177734375
Epoch 94 loss 656.566162109375
Epoch 95 loss 802.592041015625
Epoch 96 loss 682.1403198242188
Epoch 97 loss 726.7858276367188
Epoch 98 loss 634.2968139648438
Epoch 99 loss 676.887939453125
Saved Losses
{'MSE - mean': 631.1064367256757, 'MSE - std': 0.0, 'R2 - mean': 0.9266206510258073, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522850.71875
Epoch 1 loss 519933.03125
Epoch 2 loss 515488.375
Epoch 3 loss 508704.46875
Epoch 4 loss 497939.125
Epoch 5 loss 477339.875
Epoch 6 loss 439274.9375
Epoch 7 loss 377454.71875
Epoch 8 loss 290175.78125
Epoch 9 loss 185702.21875
Epoch 10 loss 86911.421875
Epoch 11 loss 24881.392578125
Epoch 12 loss 8030.59814453125
Epoch 13 loss 7779.2392578125
Epoch 14 loss 7556.267578125
Epoch 15 loss 7547.6796875
Epoch 16 loss 7441.4326171875
Epoch 17 loss 7024.4716796875
Epoch 18 loss 5447.6572265625
Epoch 19 loss 4087.7744140625
Epoch 20 loss 2756.04833984375
Epoch 21 loss 2139.975830078125
Epoch 22 loss 1543.296875
Epoch 23 loss 1624.4136962890625
Epoch 24 loss 1231.2596435546875
Epoch 25 loss 1455.6983642578125
Epoch 26 loss 1036.3441162109375
Epoch 27 loss 1668.3572998046875
Epoch 28 loss 971.1181640625
Epoch 29 loss 1051.2252197265625
Epoch 30 loss 860.4137573242188
Epoch 31 loss 844.0040283203125
Epoch 32 loss 1097.5574951171875
Epoch 33 loss 719.9474487304688
Epoch 34 loss 1045.150390625
Epoch 35 loss 702.5299682617188
Epoch 36 loss 754.201904296875
Epoch 37 loss 1126.0625
Epoch 38 loss 977.50634765625
Epoch 39 loss 686.7155151367188
Epoch 40 loss 673.1702880859375
Epoch 41 loss 691.0025634765625
Epoch 42 loss 1080.58349609375
Epoch 43 loss 642.2111206054688
Epoch 44 loss 708.3679809570312
Epoch 45 loss 686.0172119140625
Epoch 46 loss 604.6866455078125
Epoch 47 loss 774.7186279296875
Epoch 48 loss 598.9931640625
Epoch 49 loss 720.7929077148438
Epoch 50 loss 914.7025756835938
Epoch 51 loss 596.4874267578125
Epoch 52 loss 631.3779296875
Epoch 53 loss 921.8211059570312
Epoch 54 loss 637.7484130859375
Epoch 55 loss 619.20849609375
Epoch 56 loss 705.49267578125
Epoch 57 loss 552.2552490234375
Epoch 58 loss 701.5426635742188
Epoch 59 loss 543.537109375
Epoch 60 loss 542.05224609375
Epoch 61 loss 844.4207153320312
Epoch 62 loss 611.6060180664062
Epoch 63 loss 591.3383178710938
Epoch 64 loss 546.78125
Epoch 65 loss 862.2720336914062
Epoch 66 loss 569.0215454101562
Epoch 67 loss 581.9430541992188
Epoch 68 loss 536.0466918945312
Epoch 69 loss 591.6082763671875
Epoch 70 loss 773.0804443359375
Epoch 71 loss 628.9502563476562
Epoch 72 loss 583.369140625
Epoch 73 loss 617.936767578125
Epoch 74 loss 718.7715454101562
Epoch 75 loss 713.9773559570312
Epoch 76 loss 522.8587646484375
Epoch 77 loss 506.0906677246094
Epoch 78 loss 560.4540405273438
Epoch 79 loss 554.022705078125
Epoch 80 loss 579.0014038085938
Epoch 81 loss 973.0826416015625
Epoch 82 loss 686.9202270507812
Epoch 83 loss 540.2909545898438
Epoch 84 loss 662.3388061523438
Epoch 85 loss 880.4589233398438
Epoch 86 loss 529.439453125
Epoch 87 loss 770.3759155273438
Epoch 88 loss 725.5425415039062
Epoch 89 loss 489.3465270996094
Epoch 90 loss 666.9103393554688
Epoch 91 loss 518.5738525390625
Epoch 92 loss 703.3817749023438
Epoch 93 loss 638.1103515625
Epoch 94 loss 593.00537109375
Epoch 95 loss 562.753173828125
Epoch 96 loss 638.9249877929688
Epoch 97 loss 626.4588012695312
Epoch 98 loss 547.086669921875
Epoch 99 loss 612.7745361328125
Saved Losses
{'MSE - mean': 560.2263014005943, 'MSE - std': 70.88013532508151, 'R2 - mean': 0.9312870455388518, 'R2 - std': 0.004666394513044569} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516748.53125
Epoch 1 loss 514386.375
Epoch 2 loss 511050.03125
Epoch 3 loss 506164.84375
Epoch 4 loss 499096.28125
Epoch 5 loss 486165.71875
Epoch 6 loss 460736.75
Epoch 7 loss 416618.34375
Epoch 8 loss 349198.40625
Epoch 9 loss 258156.765625
Epoch 10 loss 155048.71875
Epoch 11 loss 65281.4375
Epoch 12 loss 17842.1796875
Epoch 13 loss 9299.1337890625
Epoch 14 loss 9589.11328125
Epoch 15 loss 9182.294921875
Epoch 16 loss 9074.40234375
Epoch 17 loss 8730.8642578125
Epoch 18 loss 6688.408203125
Epoch 19 loss 4839.0517578125
Epoch 20 loss 3543.172607421875
Epoch 21 loss 2553.13427734375
Epoch 22 loss 2561.859375
Epoch 23 loss 1741.21142578125
Epoch 24 loss 1528.630126953125
Epoch 25 loss 1976.881591796875
Epoch 26 loss 1400.605224609375
Epoch 27 loss 1339.10693359375
Epoch 28 loss 1264.8223876953125
Epoch 29 loss 1256.1671142578125
Epoch 30 loss 1274.4923095703125
Epoch 31 loss 1137.224609375
Epoch 32 loss 1021.088134765625
Epoch 33 loss 1155.0660400390625
Epoch 34 loss 1190.2095947265625
Epoch 35 loss 958.1113891601562
Epoch 36 loss 1243.8243408203125
Epoch 37 loss 782.6290283203125
Epoch 38 loss 1322.51416015625
Epoch 39 loss 871.5089721679688
Epoch 40 loss 814.8385009765625
Epoch 41 loss 749.4462280273438
Epoch 42 loss 799.5374145507812
Epoch 43 loss 774.6489868164062
Epoch 44 loss 1034.1024169921875
Epoch 45 loss 1095.3790283203125
Epoch 46 loss 936.9872436523438
Epoch 47 loss 742.0241088867188
Epoch 48 loss 998.4552612304688
Epoch 49 loss 799.022705078125
Epoch 50 loss 732.844970703125
Epoch 51 loss 773.6886596679688
Epoch 52 loss 755.3867797851562
Epoch 53 loss 623.1182250976562
Epoch 54 loss 675.5213012695312
Epoch 55 loss 876.8119506835938
Epoch 56 loss 928.060546875
Epoch 57 loss 591.416015625
Epoch 58 loss 730.3856201171875
Epoch 59 loss 811.0040283203125
Epoch 60 loss 671.9028930664062
Epoch 61 loss 799.5638427734375
Epoch 62 loss 608.3613891601562
Epoch 63 loss 1061.5748291015625
Epoch 64 loss 656.864501953125
Epoch 65 loss 596.2925415039062
Epoch 66 loss 918.4526977539062
Epoch 67 loss 566.92626953125
Epoch 68 loss 828.1525268554688
Epoch 69 loss 744.8423461914062
Epoch 70 loss 762.3652954101562
Epoch 71 loss 765.0721435546875
Epoch 72 loss 601.0045776367188
Epoch 73 loss 917.8350830078125
Epoch 74 loss 526.033203125
Epoch 75 loss 897.7360229492188
Epoch 76 loss 969.8228759765625
Epoch 77 loss 737.3084106445312
Epoch 78 loss 837.0617065429688
Epoch 79 loss 822.4906616210938
Epoch 80 loss 740.2091674804688
Epoch 81 loss 594.8106689453125
Epoch 82 loss 1065.7392578125
Epoch 83 loss 760.6743774414062
Epoch 84 loss 519.6519165039062
Epoch 85 loss 782.9276733398438
Epoch 86 loss 550.4641723632812
Epoch 87 loss 637.1209106445312
Epoch 88 loss 533.979248046875
Epoch 89 loss 576.7698974609375
Epoch 90 loss 554.4156494140625
Epoch 91 loss 741.7451171875
Epoch 92 loss 806.3671875
Epoch 93 loss 510.1012268066406
Epoch 94 loss 539.0689086914062
Epoch 95 loss 508.0617370605469
Epoch 96 loss 792.8480834960938
Epoch 97 loss 1036.915771484375
Epoch 98 loss 497.2991638183594
Epoch 99 loss 621.0947265625
Saved Losses
{'MSE - mean': 539.2506055925859, 'MSE - std': 65.03298151754576, 'R2 - mean': 0.9363831685593732, 'R2 - std': 0.008152163200534926} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518375.34375
Epoch 1 loss 515610.59375
Epoch 2 loss 511247.3125
Epoch 3 loss 504496.28125
Epoch 4 loss 493817.875
Epoch 5 loss 473326.5625
Epoch 6 loss 435359.75
Epoch 7 loss 373770.40625
Epoch 8 loss 286700.1875
Epoch 9 loss 182221.703125
Epoch 10 loss 83574.640625
Epoch 11 loss 23066.291015625
Epoch 12 loss 8451.244140625
Epoch 13 loss 8535.521484375
Epoch 14 loss 8170.42236328125
Epoch 15 loss 8064.72998046875
Epoch 16 loss 7719.10302734375
Epoch 17 loss 6097.85546875
Epoch 18 loss 4486.8525390625
Epoch 19 loss 3309.00439453125
Epoch 20 loss 2388.07177734375
Epoch 21 loss 1926.720703125
Epoch 22 loss 2365.9716796875
Epoch 23 loss 1924.563720703125
Epoch 24 loss 1569.97705078125
Epoch 25 loss 1744.4910888671875
Epoch 26 loss 1883.1824951171875
Epoch 27 loss 1532.350341796875
Epoch 28 loss 1739.782958984375
Epoch 29 loss 1079.7415771484375
Epoch 30 loss 1135.6927490234375
Epoch 31 loss 1860.1480712890625
Epoch 32 loss 949.7012939453125
Epoch 33 loss 1321.1910400390625
Epoch 34 loss 984.4432983398438
Epoch 35 loss 1126.7327880859375
Epoch 36 loss 937.080322265625
Epoch 37 loss 1285.1268310546875
Epoch 38 loss 1267.6500244140625
Epoch 39 loss 844.7450561523438
Epoch 40 loss 981.694580078125
Epoch 41 loss 1654.599853515625
Epoch 42 loss 1092.552001953125
Epoch 43 loss 850.1547241210938
Epoch 44 loss 950.8515625
Epoch 45 loss 1044.3929443359375
Epoch 46 loss 673.9373779296875
Epoch 47 loss 1402.060546875
Epoch 48 loss 1102.2894287109375
Epoch 49 loss 1055.7000732421875
Epoch 50 loss 877.8306274414062
Epoch 51 loss 1091.839111328125
Epoch 52 loss 740.2346801757812
Epoch 53 loss 896.9439697265625
Epoch 54 loss 870.2342529296875
Epoch 55 loss 624.640625
Epoch 56 loss 692.8260498046875
Epoch 57 loss 849.8467407226562
Epoch 58 loss 695.2026977539062
Epoch 59 loss 763.0699462890625
Epoch 60 loss 651.732177734375
Epoch 61 loss 713.284912109375
Epoch 62 loss 924.8070678710938
Epoch 63 loss 734.5119018554688
Epoch 64 loss 600.0506591796875
Epoch 65 loss 1052.0986328125
Epoch 66 loss 791.1777954101562
Epoch 67 loss 765.14453125
Epoch 68 loss 972.3550415039062
Epoch 69 loss 743.0277709960938
Epoch 70 loss 701.7568359375
Epoch 71 loss 857.3636474609375
Epoch 72 loss 767.520751953125
Epoch 73 loss 1151.6849365234375
Epoch 74 loss 737.2183837890625
Epoch 75 loss 601.5350341796875
Epoch 76 loss 914.1914672851562
Epoch 77 loss 746.4900512695312
Epoch 78 loss 979.3941650390625
Epoch 79 loss 766.5392456054688
Epoch 80 loss 964.2932739257812
Epoch 81 loss 621.9797973632812
Epoch 82 loss 563.7322998046875
Epoch 83 loss 629.0909423828125
Epoch 84 loss 623.9467163085938
Epoch 85 loss 770.6129150390625
Epoch 86 loss 544.2111206054688
Epoch 87 loss 686.0511474609375
Epoch 88 loss 583.5115356445312
Epoch 89 loss 983.3026733398438
Epoch 90 loss 615.3870849609375
Epoch 91 loss 556.041748046875
Epoch 92 loss 771.2666625976562
Epoch 93 loss 690.5322265625
Epoch 94 loss 1058.9598388671875
Epoch 95 loss 981.8883056640625
Epoch 96 loss 930.408935546875
Epoch 97 loss 579.2268676757812
Epoch 98 loss 557.4923706054688
Epoch 99 loss 678.375244140625
Saved Losses
{'MSE - mean': 540.4906984488903, 'MSE - std': 56.36115687841103, 'R2 - mean': 0.935906363858898, 'R2 - std': 0.007108118724620642} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515859.5625
Epoch 1 loss 513521.84375
Epoch 2 loss 509756.0
Epoch 3 loss 503914.65625
Epoch 4 loss 494917.6875
Epoch 5 loss 477707.65625
Epoch 6 loss 445532.5
Epoch 7 loss 392526.03125
Epoch 8 loss 315474.53125
Epoch 9 loss 218144.765625
Epoch 10 loss 116683.3671875
Epoch 11 loss 40873.16796875
Epoch 12 loss 10489.2177734375
Epoch 13 loss 8120.54248046875
Epoch 14 loss 8072.73779296875
Epoch 15 loss 7837.57275390625
Epoch 16 loss 7719.2109375
Epoch 17 loss 7202.27099609375
Epoch 18 loss 4696.67919921875
Epoch 19 loss 3288.236328125
Epoch 20 loss 2315.022705078125
Epoch 21 loss 2228.451171875
Epoch 22 loss 1530.9669189453125
Epoch 23 loss 1442.86962890625
Epoch 24 loss 1204.47607421875
Epoch 25 loss 1146.41455078125
Epoch 26 loss 1056.627197265625
Epoch 27 loss 1601.3909912109375
Epoch 28 loss 953.8092651367188
Epoch 29 loss 896.0121459960938
Epoch 30 loss 1148.24365234375
Epoch 31 loss 869.2434692382812
Epoch 32 loss 1034.7972412109375
Epoch 33 loss 1251.3153076171875
Epoch 34 loss 811.8461303710938
Epoch 35 loss 728.7952880859375
Epoch 36 loss 935.221435546875
Epoch 37 loss 854.9006958007812
Epoch 38 loss 813.5863647460938
Epoch 39 loss 689.93505859375
Epoch 40 loss 678.0526123046875
Epoch 41 loss 668.7601928710938
Epoch 42 loss 650.4491577148438
Epoch 43 loss 639.8391723632812
Epoch 44 loss 851.4066772460938
Epoch 45 loss 661.9804077148438
Epoch 46 loss 627.072021484375
Epoch 47 loss 638.2974243164062
Epoch 48 loss 601.1896362304688
Epoch 49 loss 731.7453002929688
Epoch 50 loss 739.9031372070312
Epoch 51 loss 599.2265014648438
Epoch 52 loss 614.2164916992188
Epoch 53 loss 643.078125
Epoch 54 loss 586.6463012695312
Epoch 55 loss 651.4247436523438
Epoch 56 loss 612.9450073242188
Epoch 57 loss 605.025146484375
Epoch 58 loss 931.512939453125
Epoch 59 loss 604.96533203125
Epoch 60 loss 588.3221435546875
Epoch 61 loss 584.0900268554688
Epoch 62 loss 626.1679077148438
Epoch 63 loss 564.8070068359375
Epoch 64 loss 601.7294921875
Epoch 65 loss 567.467529296875
Epoch 66 loss 672.8961181640625
Epoch 67 loss 553.0321044921875
Epoch 68 loss 573.8427124023438
Epoch 69 loss 550.994140625
Epoch 70 loss 652.5792236328125
Epoch 71 loss 551.009521484375
Epoch 72 loss 566.779052734375
Epoch 73 loss 540.822021484375
Epoch 74 loss 680.2171020507812
Epoch 75 loss 539.619384765625
Epoch 76 loss 591.1547241210938
Epoch 77 loss 727.1615600585938
Epoch 78 loss 617.0604248046875
Epoch 79 loss 533.4639282226562
Epoch 80 loss 618.404541015625
Epoch 81 loss 521.5287475585938
Epoch 82 loss 748.861572265625
Epoch 83 loss 530.5634155273438
Epoch 84 loss 652.840087890625
Epoch 85 loss 665.1441650390625
Epoch 86 loss 518.7517700195312
Epoch 87 loss 736.9218139648438
Epoch 88 loss 532.7501220703125
Epoch 89 loss 547.49169921875
Epoch 90 loss 581.21630859375
Epoch 91 loss 523.0747680664062
Epoch 92 loss 538.2620849609375
Epoch 93 loss 573.4664306640625
Epoch 94 loss 663.76220703125
Epoch 95 loss 512.9585571289062
Epoch 96 loss 529.69482421875
Epoch 97 loss 613.3306274414062
Epoch 98 loss 681.587890625
Epoch 99 loss 521.0816650390625
Saved Losses
{'MSE - mean': 534.9842659083238, 'MSE - std': 51.59987597885797, 'R2 - mean': 0.9358658248470121, 'R2 - std': 0.0063582116265960215} 
 

Results After CV: {'MSE - mean': 534.9842659083238, 'MSE - std': 51.59987597885797, 'R2 - mean': 0.9358658248470121, 'R2 - std': 0.0063582116265960215}
Train time: 101.27550213759969
Inference time: 0.13820181880037125
Finished cross validation
Trial 24 finished with value: 534.9842659083238 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.7}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515136.53125
Epoch 1 loss 513374.1875
Epoch 2 loss 510442.84375
Epoch 3 loss 505657.96875
Epoch 4 loss 497815.84375
Epoch 5 loss 482592.875
Epoch 6 loss 453146.84375
Epoch 7 loss 403432.5
Epoch 8 loss 329696.53125
Epoch 9 loss 234069.96875
Epoch 10 loss 131184.4375
Epoch 11 loss 49429.171875
Epoch 12 loss 12813.0263671875
Epoch 13 loss 8643.7392578125
Epoch 14 loss 8815.654296875
Epoch 15 loss 8500.3017578125
Epoch 16 loss 8459.857421875
Epoch 17 loss 8348.001953125
Epoch 18 loss 8121.73828125
Epoch 19 loss 6912.302734375
Epoch 20 loss 4923.83935546875
Epoch 21 loss 3430.38720703125
Epoch 22 loss 2489.76513671875
Epoch 23 loss 2005.0185546875
Epoch 24 loss 2616.51611328125
Epoch 25 loss 1700.5325927734375
Epoch 26 loss 1604.5494384765625
Epoch 27 loss 1485.414306640625
Epoch 28 loss 1439.6275634765625
Epoch 29 loss 1376.3773193359375
Epoch 30 loss 1273.13916015625
Epoch 31 loss 1390.495361328125
Epoch 32 loss 1386.0628662109375
Epoch 33 loss 1531.908447265625
Epoch 34 loss 1337.0211181640625
Epoch 35 loss 1094.708984375
Epoch 36 loss 981.0260620117188
Epoch 37 loss 1394.5145263671875
Epoch 38 loss 1535.900146484375
Epoch 39 loss 1217.8397216796875
Epoch 40 loss 890.5110473632812
Epoch 41 loss 893.0340576171875
Epoch 42 loss 881.4319458007812
Epoch 43 loss 915.7685546875
Epoch 44 loss 1305.5640869140625
Epoch 45 loss 1242.5853271484375
Epoch 46 loss 1182.7391357421875
Epoch 47 loss 851.3197631835938
Epoch 48 loss 848.11474609375
Epoch 49 loss 850.861328125
Epoch 50 loss 1385.7996826171875
Epoch 51 loss 839.0870361328125
Epoch 52 loss 811.861083984375
Epoch 53 loss 826.0184936523438
Epoch 54 loss 861.4940185546875
Epoch 55 loss 862.7049560546875
Epoch 56 loss 920.1859130859375
Epoch 57 loss 1477.7813720703125
Epoch 58 loss 918.5526733398438
Epoch 59 loss 765.1962280273438
Epoch 60 loss 761.1881713867188
Epoch 61 loss 879.7659301757812
Epoch 62 loss 995.514404296875
Epoch 63 loss 1046.45556640625
Epoch 64 loss 1081.6678466796875
Epoch 65 loss 1265.5926513671875
Epoch 66 loss 1021.6799926757812
Epoch 67 loss 878.8073120117188
Epoch 68 loss 951.2371215820312
Epoch 69 loss 713.6958618164062
Epoch 70 loss 695.478515625
Epoch 71 loss 687.0928955078125
Epoch 72 loss 743.693115234375
Epoch 73 loss 658.4688720703125
Epoch 74 loss 666.4387817382812
Epoch 75 loss 736.3329467773438
Epoch 76 loss 648.9873657226562
Epoch 77 loss 915.0534057617188
Epoch 78 loss 1006.4204711914062
Epoch 79 loss 775.9947509765625
Epoch 80 loss 1086.614501953125
Epoch 81 loss 673.7738037109375
Epoch 82 loss 716.1233520507812
Epoch 83 loss 644.0345458984375
Epoch 84 loss 860.1473388671875
Epoch 85 loss 940.2791137695312
Epoch 86 loss 767.5594482421875
Epoch 87 loss 635.8381958007812
Epoch 88 loss 710.877685546875
Epoch 89 loss 859.2210693359375
Epoch 90 loss 838.076416015625
Epoch 91 loss 643.5252685546875
Epoch 92 loss 615.368408203125
Epoch 93 loss 748.8428344726562
Epoch 94 loss 851.22705078125
Epoch 95 loss 759.5198974609375
Epoch 96 loss 1037.4661865234375
Epoch 97 loss 987.1243896484375
Epoch 98 loss 664.85205078125
Epoch 99 loss 658.5146484375
Saved Losses
{'MSE - mean': 615.3686627090158, 'MSE - std': 0.0, 'R2 - mean': 0.9284504970619798, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522700.875
Epoch 1 loss 520299.0625
Epoch 2 loss 516699.25
Epoch 3 loss 511224.3125
Epoch 4 loss 502696.21875
Epoch 5 loss 486647.53125
Epoch 6 loss 456484.03125
Epoch 7 loss 406028.3125
Epoch 8 loss 332078.0625
Epoch 9 loss 237496.875
Epoch 10 loss 136121.6875
Epoch 11 loss 53977.87109375
Epoch 12 loss 14035.6171875
Epoch 13 loss 7635.47705078125
Epoch 14 loss 7658.60888671875
Epoch 15 loss 7603.76025390625
Epoch 16 loss 7559.0244140625
Epoch 17 loss 7462.20947265625
Epoch 18 loss 7084.3994140625
Epoch 19 loss 5573.31396484375
Epoch 20 loss 4308.779296875
Epoch 21 loss 3038.441650390625
Epoch 22 loss 2521.59033203125
Epoch 23 loss 1972.4698486328125
Epoch 24 loss 1754.41455078125
Epoch 25 loss 1453.5164794921875
Epoch 26 loss 1730.0037841796875
Epoch 27 loss 1305.8779296875
Epoch 28 loss 1262.9569091796875
Epoch 29 loss 1215.7001953125
Epoch 30 loss 1075.0137939453125
Epoch 31 loss 1602.4534912109375
Epoch 32 loss 1072.70703125
Epoch 33 loss 984.7527465820312
Epoch 34 loss 995.0145874023438
Epoch 35 loss 867.4978637695312
Epoch 36 loss 1463.88818359375
Epoch 37 loss 958.1294555664062
Epoch 38 loss 878.1798706054688
Epoch 39 loss 866.2005615234375
Epoch 40 loss 751.7493896484375
Epoch 41 loss 877.0302734375
Epoch 42 loss 735.9390258789062
Epoch 43 loss 801.4227294921875
Epoch 44 loss 1061.50732421875
Epoch 45 loss 860.9324340820312
Epoch 46 loss 706.0269775390625
Epoch 47 loss 854.0902099609375
Epoch 48 loss 803.5755615234375
Epoch 49 loss 888.1862182617188
Epoch 50 loss 1114.796875
Epoch 51 loss 864.1541748046875
Epoch 52 loss 674.3493041992188
Epoch 53 loss 630.26708984375
Epoch 54 loss 688.8756103515625
Epoch 55 loss 799.8552856445312
Epoch 56 loss 628.0551147460938
Epoch 57 loss 658.46142578125
Epoch 58 loss 1217.701904296875
Epoch 59 loss 650.76416015625
Epoch 60 loss 609.4710693359375
Epoch 61 loss 640.5123291015625
Epoch 62 loss 621.1865844726562
Epoch 63 loss 646.9457397460938
Epoch 64 loss 898.580322265625
Epoch 65 loss 744.538330078125
Epoch 66 loss 668.9676513671875
Epoch 67 loss 845.4487915039062
Epoch 68 loss 683.8560791015625
Epoch 69 loss 859.592041015625
Epoch 70 loss 803.4497680664062
Epoch 71 loss 623.3135986328125
Epoch 72 loss 655.0303955078125
Epoch 73 loss 618.8663330078125
Epoch 74 loss 685.447509765625
Epoch 75 loss 727.0679931640625
Epoch 76 loss 814.8917236328125
Epoch 77 loss 589.021484375
Epoch 78 loss 563.139892578125
Epoch 79 loss 880.4761352539062
Epoch 80 loss 601.1438598632812
Epoch 81 loss 665.9271240234375
Epoch 82 loss 582.719482421875
Epoch 83 loss 602.3294677734375
Epoch 84 loss 790.901123046875
Epoch 85 loss 563.6383056640625
Epoch 86 loss 999.4111938476562
Epoch 87 loss 962.9376220703125
Epoch 88 loss 562.0671997070312
Epoch 89 loss 570.2238159179688
Epoch 90 loss 591.33984375
Epoch 91 loss 555.736328125
Epoch 92 loss 594.6046752929688
Epoch 93 loss 743.1358032226562
Epoch 94 loss 794.4610595703125
Epoch 95 loss 1010.8899536132812
Epoch 96 loss 715.90625
Epoch 97 loss 712.3522338867188
Epoch 98 loss 641.4773559570312
Epoch 99 loss 657.9985961914062
Saved Losses
{'MSE - mean': 585.5522833854066, 'MSE - std': 29.816379323609226, 'R2 - mean': 0.9278573607632589, 'R2 - std': 0.000593136298720931} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514493.59375
Epoch 1 loss 511433.0625
Epoch 2 loss 507155.8125
Epoch 3 loss 501182.34375
Epoch 4 loss 492300.78125
Epoch 5 loss 475362.1875
Epoch 6 loss 443571.84375
Epoch 7 loss 390797.3125
Epoch 8 loss 314612.28125
Epoch 9 loss 219417.578125
Epoch 10 loss 120183.1875
Epoch 11 loss 44786.33984375
Epoch 12 loss 12682.001953125
Epoch 13 loss 9414.5625
Epoch 14 loss 9491.8896484375
Epoch 15 loss 9166.416015625
Epoch 16 loss 9084.41796875
Epoch 17 loss 8870.923828125
Epoch 18 loss 7852.78369140625
Epoch 19 loss 6761.1552734375
Epoch 20 loss 5271.14208984375
Epoch 21 loss 3824.632080078125
Epoch 22 loss 2779.91259765625
Epoch 23 loss 2240.50048828125
Epoch 24 loss 2075.9697265625
Epoch 25 loss 1823.040283203125
Epoch 26 loss 1884.6610107421875
Epoch 27 loss 1495.7540283203125
Epoch 28 loss 1723.2037353515625
Epoch 29 loss 1813.2225341796875
Epoch 30 loss 1502.7796630859375
Epoch 31 loss 1248.5863037109375
Epoch 32 loss 1283.8287353515625
Epoch 33 loss 1115.74560546875
Epoch 34 loss 1259.4029541015625
Epoch 35 loss 1584.702880859375
Epoch 36 loss 979.0800170898438
Epoch 37 loss 1116.6226806640625
Epoch 38 loss 2220.739501953125
Epoch 39 loss 1212.54052734375
Epoch 40 loss 1011.7041625976562
Epoch 41 loss 871.4747924804688
Epoch 42 loss 1050.1474609375
Epoch 43 loss 1652.8265380859375
Epoch 44 loss 1327.2164306640625
Epoch 45 loss 1098.757080078125
Epoch 46 loss 1086.31201171875
Epoch 47 loss 937.37939453125
Epoch 48 loss 1026.2940673828125
Epoch 49 loss 1514.219970703125
Epoch 50 loss 878.3772583007812
Epoch 51 loss 758.97314453125
Epoch 52 loss 823.1581420898438
Epoch 53 loss 966.030517578125
Epoch 54 loss 1071.49951171875
Epoch 55 loss 2098.09814453125
Epoch 56 loss 1468.721923828125
Epoch 57 loss 786.153564453125
Epoch 58 loss 759.2044677734375
Epoch 59 loss 928.9257202148438
Epoch 60 loss 1048.834716796875
Epoch 61 loss 969.5723266601562
Epoch 62 loss 970.8013916015625
Epoch 63 loss 758.274169921875
Epoch 64 loss 1282.618896484375
Epoch 65 loss 763.0845336914062
Epoch 66 loss 1306.6416015625
Epoch 67 loss 922.3919677734375
Epoch 68 loss 748.02587890625
Epoch 69 loss 975.5409545898438
Epoch 70 loss 1278.4620361328125
Epoch 71 loss 634.2762451171875
Epoch 72 loss 810.0896606445312
Epoch 73 loss 891.1237182617188
Epoch 74 loss 711.3898315429688
Epoch 75 loss 753.3837280273438
Epoch 76 loss 986.9410400390625
Epoch 77 loss 744.938720703125
Epoch 78 loss 658.2062377929688
Epoch 79 loss 1250.838134765625
Epoch 80 loss 648.074951171875
Epoch 81 loss 614.806396484375
Epoch 82 loss 606.084228515625
Epoch 83 loss 648.31689453125
Epoch 84 loss 604.848388671875
Epoch 85 loss 750.1828002929688
Epoch 86 loss 665.7379150390625
Epoch 87 loss 917.8124389648438
Epoch 88 loss 1072.37548828125
Epoch 89 loss 1099.5301513671875
Epoch 90 loss 1245.320068359375
Epoch 91 loss 659.1989135742188
Epoch 92 loss 818.7098388671875
Epoch 93 loss 968.260498046875
Epoch 94 loss 1083.4471435546875
Epoch 95 loss 1002.4834594726562
Epoch 96 loss 870.6369018554688
Epoch 97 loss 669.7408447265625
Epoch 98 loss 562.8519897460938
Epoch 99 loss 556.4881591796875
Saved Losses
{'MSE - mean': 575.8642358439441, 'MSE - std': 27.935536167711284, 'R2 - mean': 0.9319771672526193, 'R2 - std': 0.005846379346694849} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518305.25
Epoch 1 loss 515658.71875
Epoch 2 loss 511717.25
Epoch 3 loss 505731.875
Epoch 4 loss 496703.84375
Epoch 5 loss 480883.1875
Epoch 6 loss 451169.59375
Epoch 7 loss 401566.21875
Epoch 8 loss 328577.0625
Epoch 9 loss 234715.59375
Epoch 10 loss 133063.765625
Epoch 11 loss 51054.19140625
Epoch 12 loss 13133.8857421875
Epoch 13 loss 8327.4638671875
Epoch 14 loss 8482.24609375
Epoch 15 loss 8214.1318359375
Epoch 16 loss 8207.9951171875
Epoch 17 loss 8072.87255859375
Epoch 18 loss 7788.61083984375
Epoch 19 loss 6599.27099609375
Epoch 20 loss 5122.99169921875
Epoch 21 loss 3743.861328125
Epoch 22 loss 2929.5751953125
Epoch 23 loss 2946.893798828125
Epoch 24 loss 2307.1767578125
Epoch 25 loss 2125.435302734375
Epoch 26 loss 1729.2689208984375
Epoch 27 loss 1897.7103271484375
Epoch 28 loss 1926.2425537109375
Epoch 29 loss 1622.53466796875
Epoch 30 loss 1438.5343017578125
Epoch 31 loss 1991.0401611328125
Epoch 32 loss 1489.848388671875
Epoch 33 loss 1514.8612060546875
Epoch 34 loss 2044.140869140625
Epoch 35 loss 1221.455078125
Epoch 36 loss 1795.74853515625
Epoch 37 loss 1214.7623291015625
Epoch 38 loss 1093.5152587890625
Epoch 39 loss 1064.9803466796875
Epoch 40 loss 1297.2410888671875
Epoch 41 loss 1530.2755126953125
Epoch 42 loss 2041.95458984375
Epoch 43 loss 1746.72119140625
Epoch 44 loss 1329.8111572265625
Epoch 45 loss 1128.5718994140625
Epoch 46 loss 1117.86669921875
Epoch 47 loss 994.5388793945312
Epoch 48 loss 1022.697998046875
Epoch 49 loss 1263.691162109375
Epoch 50 loss 863.1543579101562
Epoch 51 loss 796.7938232421875
Epoch 52 loss 981.422607421875
Epoch 53 loss 1291.2906494140625
Epoch 54 loss 1412.95458984375
Epoch 55 loss 1402.0498046875
Epoch 56 loss 933.7945556640625
Epoch 57 loss 983.3846435546875
Epoch 58 loss 926.2805786132812
Epoch 59 loss 777.738037109375
Epoch 60 loss 705.9680786132812
Epoch 61 loss 1044.49169921875
Epoch 62 loss 992.4841918945312
Epoch 63 loss 775.313720703125
Epoch 64 loss 716.4852905273438
Epoch 65 loss 1311.04931640625
Epoch 66 loss 1133.72412109375
Epoch 67 loss 745.155029296875
Epoch 68 loss 858.7052612304688
Epoch 69 loss 801.1357421875
Epoch 70 loss 735.2457885742188
Epoch 71 loss 1002.7092895507812
Epoch 72 loss 1185.1051025390625
Epoch 73 loss 1064.400634765625
Epoch 74 loss 776.6799926757812
Epoch 75 loss 696.9944458007812
Epoch 76 loss 767.6055908203125
Epoch 77 loss 998.50634765625
Epoch 78 loss 1008.2308349609375
Epoch 79 loss 887.7672729492188
Epoch 80 loss 1020.556884765625
Epoch 81 loss 909.3674926757812
Epoch 82 loss 774.12939453125
Epoch 83 loss 797.22998046875
Epoch 84 loss 623.184326171875
Epoch 85 loss 701.7535400390625
Epoch 86 loss 712.90966796875
Epoch 87 loss 936.26708984375
Epoch 88 loss 1252.69970703125
Epoch 89 loss 1048.6168212890625
Epoch 90 loss 879.1027221679688
Epoch 91 loss 876.7384033203125
Epoch 92 loss 656.1910400390625
Epoch 93 loss 964.1505126953125
Epoch 94 loss 1096.2908935546875
Epoch 95 loss 738.0590209960938
Epoch 96 loss 1159.6942138671875
Epoch 97 loss 1479.998046875
Epoch 98 loss 685.3421020507812
Epoch 99 loss 635.6378173828125
Saved Losses
{'MSE - mean': 587.6943067921393, 'MSE - std': 31.70405922987029, 'R2 - mean': 0.9302247212035815, 'R2 - std': 0.005903246146270715} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515949.75
Epoch 1 loss 513645.34375
Epoch 2 loss 510189.71875
Epoch 3 loss 504645.3125
Epoch 4 loss 495793.0
Epoch 5 loss 479411.84375
Epoch 6 loss 448501.46875
Epoch 7 loss 396447.46875
Epoch 8 loss 319969.15625
Epoch 9 loss 222691.34375
Epoch 10 loss 120588.7421875
Epoch 11 loss 42565.32421875
Epoch 12 loss 10745.7353515625
Epoch 13 loss 8140.58740234375
Epoch 14 loss 8051.060546875
Epoch 15 loss 7897.671875
Epoch 16 loss 7816.94970703125
Epoch 17 loss 7771.373046875
Epoch 18 loss 7364.5625
Epoch 19 loss 5869.3525390625
Epoch 20 loss 4493.26220703125
Epoch 21 loss 3362.9931640625
Epoch 22 loss 2532.260009765625
Epoch 23 loss 2055.985595703125
Epoch 24 loss 1974.50830078125
Epoch 25 loss 1632.5975341796875
Epoch 26 loss 1477.8048095703125
Epoch 27 loss 1458.872314453125
Epoch 28 loss 1759.045166015625
Epoch 29 loss 1263.294189453125
Epoch 30 loss 1620.612548828125
Epoch 31 loss 1514.8739013671875
Epoch 32 loss 1064.306396484375
Epoch 33 loss 1128.0670166015625
Epoch 34 loss 1081.1224365234375
Epoch 35 loss 989.8634643554688
Epoch 36 loss 1415.8048095703125
Epoch 37 loss 875.9520874023438
Epoch 38 loss 1101.3759765625
Epoch 39 loss 1063.6605224609375
Epoch 40 loss 901.3526000976562
Epoch 41 loss 867.6491088867188
Epoch 42 loss 979.6294555664062
Epoch 43 loss 845.9482421875
Epoch 44 loss 1229.56396484375
Epoch 45 loss 771.5079956054688
Epoch 46 loss 825.8143920898438
Epoch 47 loss 729.292724609375
Epoch 48 loss 723.8997192382812
Epoch 49 loss 709.0154418945312
Epoch 50 loss 855.7689208984375
Epoch 51 loss 802.366943359375
Epoch 52 loss 901.3348388671875
Epoch 53 loss 752.8235473632812
Epoch 54 loss 880.8622436523438
Epoch 55 loss 763.9951782226562
Epoch 56 loss 873.5045166015625
Epoch 57 loss 785.48388671875
Epoch 58 loss 657.7579345703125
Epoch 59 loss 673.4706420898438
Epoch 60 loss 684.128173828125
Epoch 61 loss 693.23193359375
Epoch 62 loss 701.0699462890625
Epoch 63 loss 857.1289672851562
Epoch 64 loss 1015.635986328125
Epoch 65 loss 739.00537109375
Epoch 66 loss 736.1520385742188
Epoch 67 loss 726.958740234375
Epoch 68 loss 603.6184692382812
Epoch 69 loss 792.6351318359375
Epoch 70 loss 804.0689697265625
Epoch 71 loss 822.2920532226562
Epoch 72 loss 838.3617553710938
Epoch 73 loss 574.7688598632812
Epoch 74 loss 596.7227783203125
Epoch 75 loss 777.9867553710938
Epoch 76 loss 1253.948974609375
Epoch 77 loss 793.9175415039062
Epoch 78 loss 680.166015625
Epoch 79 loss 562.3379516601562
Epoch 80 loss 589.92578125
Epoch 81 loss 634.8673706054688
Epoch 82 loss 826.3846435546875
Epoch 83 loss 674.7921752929688
Epoch 84 loss 655.6594848632812
Epoch 85 loss 568.1619262695312
Epoch 86 loss 594.6515502929688
Epoch 87 loss 561.5745239257812
Epoch 88 loss 546.169921875
Epoch 89 loss 548.2383422851562
Epoch 90 loss 701.7088623046875
Epoch 91 loss 713.0413818359375
Epoch 92 loss 638.4886474609375
Epoch 93 loss 560.5001220703125
Epoch 94 loss 645.2265625
Epoch 95 loss 549.778076171875
Epoch 96 loss 620.5114135742188
Epoch 97 loss 548.4673461914062
Epoch 98 loss 767.3837280273438
Epoch 99 loss 631.2337036132812
Saved Losses
{'MSE - mean': 579.3894265831348, 'MSE - std': 32.863384464545966, 'R2 - mean': 0.9304879407989126, 'R2 - std': 0.0053062029995311535} 
 

Results After CV: {'MSE - mean': 579.3894265831348, 'MSE - std': 32.863384464545966, 'R2 - mean': 0.9304879407989126, 'R2 - std': 0.0053062029995311535}
Train time: 101.43215845159975
Inference time: 0.138579538599879
Finished cross validation
Trial 25 finished with value: 579.3894265831348 and parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.8}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515929.65625
Epoch 1 loss 514429.40625
Epoch 2 loss 511295.46875
Epoch 3 loss 505721.8125
Epoch 4 loss 496804.21875
Epoch 5 loss 479929.71875
Epoch 6 loss 448177.46875
Epoch 7 loss 395741.0625
Epoch 8 loss 319207.65625
Epoch 9 loss 221878.28125
Epoch 10 loss 120123.7890625
Epoch 11 loss 42501.0078125
Epoch 12 loss 11330.576171875
Epoch 13 loss 8732.744140625
Epoch 14 loss 8688.6552734375
Epoch 15 loss 8249.4873046875
Epoch 16 loss 8036.41943359375
Epoch 17 loss 7720.859375
Epoch 18 loss 7285.34033203125
Epoch 19 loss 6736.51513671875
Epoch 20 loss 6035.1630859375
Epoch 21 loss 5119.14453125
Epoch 22 loss 4088.721923828125
Epoch 23 loss 3059.696533203125
Epoch 24 loss 2196.368408203125
Epoch 25 loss 1759.9278564453125
Epoch 26 loss 1575.6475830078125
Epoch 27 loss 1466.7301025390625
Epoch 28 loss 1410.1212158203125
Epoch 29 loss 1358.949462890625
Epoch 30 loss 1335.447021484375
Epoch 31 loss 1331.964599609375
Epoch 32 loss 1209.96484375
Epoch 33 loss 1193.5523681640625
Epoch 34 loss 1182.574951171875
Epoch 35 loss 1128.519287109375
Epoch 36 loss 1256.4547119140625
Epoch 37 loss 1069.2601318359375
Epoch 38 loss 1056.0120849609375
Epoch 39 loss 1023.7288208007812
Epoch 40 loss 1017.781005859375
Epoch 41 loss 975.6298217773438
Epoch 42 loss 964.2161865234375
Epoch 43 loss 910.474853515625
Epoch 44 loss 908.0018920898438
Epoch 45 loss 1057.8255615234375
Epoch 46 loss 883.689697265625
Epoch 47 loss 945.8557739257812
Epoch 48 loss 1025.81298828125
Epoch 49 loss 919.6236572265625
Epoch 50 loss 861.4458618164062
Epoch 51 loss 832.5713500976562
Epoch 52 loss 827.9697265625
Epoch 53 loss 1110.1805419921875
Epoch 54 loss 927.9609375
Epoch 55 loss 847.53466796875
Epoch 56 loss 789.953857421875
Epoch 57 loss 812.9837036132812
Epoch 58 loss 1026.006103515625
Epoch 59 loss 905.7744140625
Epoch 60 loss 769.90478515625
Epoch 61 loss 833.2658081054688
Epoch 62 loss 924.5340576171875
Epoch 63 loss 864.5222778320312
Epoch 64 loss 776.8129272460938
Epoch 65 loss 738.4112548828125
Epoch 66 loss 733.4474487304688
Epoch 67 loss 746.140869140625
Epoch 68 loss 721.4010620117188
Epoch 69 loss 765.3798217773438
Epoch 70 loss 727.7106323242188
Epoch 71 loss 728.8239135742188
Epoch 72 loss 737.1467895507812
Epoch 73 loss 804.35693359375
Epoch 74 loss 757.6986694335938
Epoch 75 loss 734.7537841796875
Epoch 76 loss 728.357421875
Epoch 77 loss 729.7428588867188
Epoch 78 loss 726.554443359375
Epoch 79 loss 828.5777587890625
Epoch 80 loss 802.4592895507812
Epoch 81 loss 721.573486328125
Epoch 82 loss 817.6931762695312
Epoch 83 loss 764.4523315429688
Epoch 84 loss 770.3416748046875
Epoch 85 loss 776.8494873046875
Epoch 86 loss 770.7727661132812
Epoch 87 loss 739.865478515625
Epoch 88 loss 759.3187255859375
Epoch 89 loss 708.8740234375
Epoch 90 loss 760.50732421875
Epoch 91 loss 742.8048095703125
Epoch 92 loss 663.6611938476562
Epoch 93 loss 762.2152099609375
Epoch 94 loss 674.0577392578125
Epoch 95 loss 665.6434936523438
Epoch 96 loss 793.363525390625
Epoch 97 loss 655.4721069335938
Epoch 98 loss 690.2802734375
Epoch 99 loss 688.3242797851562
Saved Losses
{'MSE - mean': 655.4717666932235, 'MSE - std': 0.0, 'R2 - mean': 0.9237876708080232, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523486.90625
Epoch 1 loss 520392.40625
Epoch 2 loss 515356.0
Epoch 3 loss 507478.625
Epoch 4 loss 495541.3125
Epoch 5 loss 473620.90625
Epoch 6 loss 434878.34375
Epoch 7 loss 374330.125
Epoch 8 loss 290524.0625
Epoch 9 loss 190267.609375
Epoch 10 loss 93794.6484375
Epoch 11 loss 29009.6171875
Epoch 12 loss 8659.71484375
Epoch 13 loss 7566.48291015625
Epoch 14 loss 7280.3525390625
Epoch 15 loss 7177.42724609375
Epoch 16 loss 6915.43115234375
Epoch 17 loss 6591.56298828125
Epoch 18 loss 6284.7841796875
Epoch 19 loss 5780.09619140625
Epoch 20 loss 5204.32177734375
Epoch 21 loss 4500.89599609375
Epoch 22 loss 3622.61962890625
Epoch 23 loss 2786.062255859375
Epoch 24 loss 2029.035888671875
Epoch 25 loss 1547.04052734375
Epoch 26 loss 1357.2353515625
Epoch 27 loss 1251.945068359375
Epoch 28 loss 1172.6422119140625
Epoch 29 loss 1128.249267578125
Epoch 30 loss 1090.1412353515625
Epoch 31 loss 1071.17138671875
Epoch 32 loss 1002.6736450195312
Epoch 33 loss 987.3619995117188
Epoch 34 loss 1024.0408935546875
Epoch 35 loss 996.364013671875
Epoch 36 loss 915.0516357421875
Epoch 37 loss 1099.2337646484375
Epoch 38 loss 933.850830078125
Epoch 39 loss 796.43359375
Epoch 40 loss 885.1309204101562
Epoch 41 loss 867.5073852539062
Epoch 42 loss 739.1614379882812
Epoch 43 loss 780.8410034179688
Epoch 44 loss 722.3650512695312
Epoch 45 loss 863.471435546875
Epoch 46 loss 772.9839477539062
Epoch 47 loss 691.1585083007812
Epoch 48 loss 678.8457641601562
Epoch 49 loss 650.7191162109375
Epoch 50 loss 640.556396484375
Epoch 51 loss 785.4015502929688
Epoch 52 loss 841.1276245117188
Epoch 53 loss 624.3101196289062
Epoch 54 loss 698.0966796875
Epoch 55 loss 590.4112548828125
Epoch 56 loss 584.3971557617188
Epoch 57 loss 742.9354858398438
Epoch 58 loss 559.9113159179688
Epoch 59 loss 646.10107421875
Epoch 60 loss 594.7991333007812
Epoch 61 loss 573.3742065429688
Epoch 62 loss 620.8978881835938
Epoch 63 loss 583.3547973632812
Epoch 64 loss 593.9286499023438
Epoch 65 loss 606.7874755859375
Epoch 66 loss 634.0253295898438
Epoch 67 loss 546.2379760742188
Epoch 68 loss 552.572998046875
Epoch 69 loss 603.0433959960938
Epoch 70 loss 549.1666259765625
Epoch 71 loss 649.0538330078125
Epoch 72 loss 549.8917846679688
Epoch 73 loss 531.6876220703125
Epoch 74 loss 695.3579711914062
Epoch 75 loss 567.8958129882812
Epoch 76 loss 580.3455200195312
Epoch 77 loss 849.5985717773438
Epoch 78 loss 558.7025756835938
Epoch 79 loss 550.2101440429688
Epoch 80 loss 532.8699340820312
Epoch 81 loss 578.9595336914062
Epoch 82 loss 562.5641479492188
Epoch 83 loss 574.593994140625
Epoch 84 loss 528.438232421875
Epoch 85 loss 539.8302001953125
Epoch 86 loss 742.7058715820312
Epoch 87 loss 540.4976806640625
Epoch 88 loss 545.1246948242188
Epoch 89 loss 548.5468139648438
Epoch 90 loss 582.8924560546875
Epoch 91 loss 859.2483520507812
Epoch 92 loss 512.1278076171875
Epoch 93 loss 604.70751953125
Epoch 94 loss 804.9129028320312
Epoch 95 loss 623.146484375
Epoch 96 loss 635.7391357421875
Epoch 97 loss 582.2948608398438
Epoch 98 loss 565.905517578125
Epoch 99 loss 524.22021484375
Saved Losses
{'MSE - mean': 583.7999901398489, 'MSE - std': 71.67177655337463, 'R2 - mean': 0.9283796765053804, 'R2 - std': 0.004592005697357349} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516508.21875
Epoch 1 loss 514050.3125
Epoch 2 loss 510013.40625
Epoch 3 loss 504314.125
Epoch 4 loss 495029.625
Epoch 5 loss 476171.5
Epoch 6 loss 441673.34375
Epoch 7 loss 386255.375
Epoch 8 loss 307550.625
Epoch 9 loss 210197.0
Epoch 10 loss 111483.5703125
Epoch 11 loss 39555.68359375
Epoch 12 loss 11634.70703125
Epoch 13 loss 9386.181640625
Epoch 14 loss 9322.8349609375
Epoch 15 loss 8973.4248046875
Epoch 16 loss 8779.4072265625
Epoch 17 loss 8514.4833984375
Epoch 18 loss 8099.73974609375
Epoch 19 loss 7563.056640625
Epoch 20 loss 6901.9794921875
Epoch 21 loss 6058.7587890625
Epoch 22 loss 5067.18115234375
Epoch 23 loss 3909.8935546875
Epoch 24 loss 2909.953125
Epoch 25 loss 2299.443359375
Epoch 26 loss 1804.6326904296875
Epoch 27 loss 1622.6474609375
Epoch 28 loss 1501.513916015625
Epoch 29 loss 1399.748779296875
Epoch 30 loss 1472.8349609375
Epoch 31 loss 1604.287841796875
Epoch 32 loss 1263.6607666015625
Epoch 33 loss 1206.3587646484375
Epoch 34 loss 1177.7220458984375
Epoch 35 loss 1271.53173828125
Epoch 36 loss 1137.8709716796875
Epoch 37 loss 1072.94580078125
Epoch 38 loss 1034.0855712890625
Epoch 39 loss 1036.330322265625
Epoch 40 loss 1154.60791015625
Epoch 41 loss 1177.6697998046875
Epoch 42 loss 1090.1427001953125
Epoch 43 loss 928.2434692382812
Epoch 44 loss 886.6978149414062
Epoch 45 loss 879.216064453125
Epoch 46 loss 858.353759765625
Epoch 47 loss 909.95703125
Epoch 48 loss 863.7926635742188
Epoch 49 loss 900.8138427734375
Epoch 50 loss 962.3494262695312
Epoch 51 loss 837.6615600585938
Epoch 52 loss 1123.4532470703125
Epoch 53 loss 751.7828979492188
Epoch 54 loss 751.757080078125
Epoch 55 loss 744.60693359375
Epoch 56 loss 903.8811645507812
Epoch 57 loss 945.6862182617188
Epoch 58 loss 823.5407104492188
Epoch 59 loss 874.8989868164062
Epoch 60 loss 725.115966796875
Epoch 61 loss 763.5159912109375
Epoch 62 loss 790.2323608398438
Epoch 63 loss 833.753662109375
Epoch 64 loss 679.5053100585938
Epoch 65 loss 712.8076171875
Epoch 66 loss 831.3506469726562
Epoch 67 loss 703.7288208007812
Epoch 68 loss 983.5657958984375
Epoch 69 loss 799.1359252929688
Epoch 70 loss 705.2117919921875
Epoch 71 loss 683.5834350585938
Epoch 72 loss 763.1455688476562
Epoch 73 loss 623.1500244140625
Epoch 74 loss 692.8789672851562
Epoch 75 loss 659.6210327148438
Epoch 76 loss 632.8099365234375
Epoch 77 loss 663.1703491210938
Epoch 78 loss 670.3056640625
Epoch 79 loss 702.6822509765625
Epoch 80 loss 833.3590698242188
Epoch 81 loss 588.6950073242188
Epoch 82 loss 606.5934448242188
Epoch 83 loss 966.6455688476562
Epoch 84 loss 597.5518188476562
Epoch 85 loss 692.9768676757812
Epoch 86 loss 587.7962036132812
Epoch 87 loss 1206.256103515625
Epoch 88 loss 611.2453002929688
Epoch 89 loss 654.6201782226562
Epoch 90 loss 646.890625
Epoch 91 loss 594.7540283203125
Epoch 92 loss 633.2041625976562
Epoch 93 loss 541.2954711914062
Epoch 94 loss 779.5053100585938
Epoch 95 loss 632.4127807617188
Epoch 96 loss 610.7581176757812
Epoch 97 loss 708.0803833007812
Epoch 98 loss 840.4962158203125
Epoch 99 loss 592.0645751953125
Saved Losses
{'MSE - mean': 569.6318527569096, 'MSE - std': 61.854948091064315, 'R2 - mean': 0.9328694206792226, 'R2 - std': 0.007373824180356273} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519070.6875
Epoch 1 loss 516631.71875
Epoch 2 loss 512524.53125
Epoch 3 loss 506428.3125
Epoch 4 loss 496552.8125
Epoch 5 loss 477193.15625
Epoch 6 loss 442315.84375
Epoch 7 loss 386517.1875
Epoch 8 loss 307983.21875
Epoch 9 loss 210946.5
Epoch 10 loss 112355.296875
Epoch 11 loss 39878.86328125
Epoch 12 loss 10909.0732421875
Epoch 13 loss 8146.4853515625
Epoch 14 loss 7871.2568359375
Epoch 15 loss 7595.361328125
Epoch 16 loss 7284.14306640625
Epoch 17 loss 6964.40771484375
Epoch 18 loss 6477.46044921875
Epoch 19 loss 5889.1591796875
Epoch 20 loss 5161.8994140625
Epoch 21 loss 4283.9794921875
Epoch 22 loss 3219.53515625
Epoch 23 loss 2412.3720703125
Epoch 24 loss 1847.03955078125
Epoch 25 loss 1610.8245849609375
Epoch 26 loss 1587.1513671875
Epoch 27 loss 1502.731201171875
Epoch 28 loss 1531.001708984375
Epoch 29 loss 1620.50732421875
Epoch 30 loss 1371.3145751953125
Epoch 31 loss 1567.85791015625
Epoch 32 loss 1271.5223388671875
Epoch 33 loss 1208.351806640625
Epoch 34 loss 1148.452392578125
Epoch 35 loss 1106.013427734375
Epoch 36 loss 1138.24072265625
Epoch 37 loss 1312.6129150390625
Epoch 38 loss 1332.490966796875
Epoch 39 loss 968.4920654296875
Epoch 40 loss 1019.751953125
Epoch 41 loss 1104.6553955078125
Epoch 42 loss 1032.826171875
Epoch 43 loss 978.384521484375
Epoch 44 loss 954.9195556640625
Epoch 45 loss 1020.576171875
Epoch 46 loss 1035.468505859375
Epoch 47 loss 833.805908203125
Epoch 48 loss 1072.7255859375
Epoch 49 loss 943.1736450195312
Epoch 50 loss 856.1988525390625
Epoch 51 loss 907.4421997070312
Epoch 52 loss 768.615966796875
Epoch 53 loss 800.5634155273438
Epoch 54 loss 819.9235229492188
Epoch 55 loss 889.9550170898438
Epoch 56 loss 782.7098999023438
Epoch 57 loss 726.3831176757812
Epoch 58 loss 744.0736083984375
Epoch 59 loss 729.1484985351562
Epoch 60 loss 888.0449829101562
Epoch 61 loss 877.20947265625
Epoch 62 loss 685.3245239257812
Epoch 63 loss 1039.09765625
Epoch 64 loss 682.02490234375
Epoch 65 loss 681.9286499023438
Epoch 66 loss 902.5974731445312
Epoch 67 loss 741.8119506835938
Epoch 68 loss 687.2740478515625
Epoch 69 loss 754.8823852539062
Epoch 70 loss 784.4240112304688
Epoch 71 loss 900.8544311523438
Epoch 72 loss 668.9970703125
Epoch 73 loss 672.709716796875
Epoch 74 loss 662.9592895507812
Epoch 75 loss 707.1357421875
Epoch 76 loss 683.1075439453125
Epoch 77 loss 916.6271362304688
Epoch 78 loss 670.6153564453125
Epoch 79 loss 739.889892578125
Epoch 80 loss 867.3211059570312
Epoch 81 loss 643.642578125
Epoch 82 loss 730.5787353515625
Epoch 83 loss 590.0796508789062
Epoch 84 loss 707.0455932617188
Epoch 85 loss 632.4506225585938
Epoch 86 loss 648.78564453125
Epoch 87 loss 631.037353515625
Epoch 88 loss 925.8744506835938
Epoch 89 loss 623.5369873046875
Epoch 90 loss 637.9592895507812
Epoch 91 loss 736.473876953125
Epoch 92 loss 577.8965454101562
Epoch 93 loss 695.3909301757812
Epoch 94 loss 767.5992431640625
Epoch 95 loss 610.2127685546875
Epoch 96 loss 730.335205078125
Epoch 97 loss 753.856689453125
Epoch 98 loss 568.1393432617188
Epoch 99 loss 709.8871459960938
Saved Losses
{'MSE - mean': 569.258744045105, 'MSE - std': 53.571854390562855, 'R2 - mean': 0.9325507953513468, 'R2 - std': 0.006409721412104973} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516261.53125
Epoch 1 loss 514070.75
Epoch 2 loss 510116.53125
Epoch 3 loss 504216.3125
Epoch 4 loss 494578.40625
Epoch 5 loss 475216.59375
Epoch 6 loss 439856.4375
Epoch 7 loss 383208.53125
Epoch 8 loss 302809.375
Epoch 9 loss 204001.75
Epoch 10 loss 105199.328125
Epoch 11 loss 35078.625
Epoch 12 loss 9575.15625
Epoch 13 loss 7949.71923828125
Epoch 14 loss 7600.96484375
Epoch 15 loss 7324.94140625
Epoch 16 loss 7061.560546875
Epoch 17 loss 6741.3359375
Epoch 18 loss 6330.49169921875
Epoch 19 loss 5808.384765625
Epoch 20 loss 5150.6279296875
Epoch 21 loss 4298.54150390625
Epoch 22 loss 3283.185302734375
Epoch 23 loss 2377.090087890625
Epoch 24 loss 1720.726806640625
Epoch 25 loss 1496.08984375
Epoch 26 loss 1365.3416748046875
Epoch 27 loss 1315.94677734375
Epoch 28 loss 1378.9857177734375
Epoch 29 loss 1215.0699462890625
Epoch 30 loss 1177.1593017578125
Epoch 31 loss 1128.751220703125
Epoch 32 loss 1125.11376953125
Epoch 33 loss 1071.329345703125
Epoch 34 loss 1046.5438232421875
Epoch 35 loss 1153.0274658203125
Epoch 36 loss 992.4100341796875
Epoch 37 loss 1003.9147338867188
Epoch 38 loss 967.5642700195312
Epoch 39 loss 934.4120483398438
Epoch 40 loss 930.1366577148438
Epoch 41 loss 928.5440673828125
Epoch 42 loss 885.2493896484375
Epoch 43 loss 864.0286254882812
Epoch 44 loss 832.013671875
Epoch 45 loss 835.9990234375
Epoch 46 loss 800.6488647460938
Epoch 47 loss 777.433349609375
Epoch 48 loss 768.5481567382812
Epoch 49 loss 797.5035400390625
Epoch 50 loss 742.0380859375
Epoch 51 loss 750.315673828125
Epoch 52 loss 761.74462890625
Epoch 53 loss 797.4256591796875
Epoch 54 loss 704.0384521484375
Epoch 55 loss 831.5299682617188
Epoch 56 loss 704.7992553710938
Epoch 57 loss 685.3470458984375
Epoch 58 loss 720.7525634765625
Epoch 59 loss 675.9771728515625
Epoch 60 loss 661.1732177734375
Epoch 61 loss 660.4189453125
Epoch 62 loss 677.4556274414062
Epoch 63 loss 643.2901611328125
Epoch 64 loss 663.4990844726562
Epoch 65 loss 617.1626586914062
Epoch 66 loss 640.7775268554688
Epoch 67 loss 610.1439208984375
Epoch 68 loss 636.074951171875
Epoch 69 loss 669.8707885742188
Epoch 70 loss 599.86181640625
Epoch 71 loss 814.747802734375
Epoch 72 loss 586.7589721679688
Epoch 73 loss 577.9269409179688
Epoch 74 loss 577.1165771484375
Epoch 75 loss 573.582763671875
Epoch 76 loss 702.1783447265625
Epoch 77 loss 568.7435302734375
Epoch 78 loss 604.6104125976562
Epoch 79 loss 565.1483764648438
Epoch 80 loss 559.0560913085938
Epoch 81 loss 779.2274780273438
Epoch 82 loss 648.4217529296875
Epoch 83 loss 574.7335205078125
Epoch 84 loss 592.4328002929688
Epoch 85 loss 559.8741455078125
Epoch 86 loss 668.1150512695312
Epoch 87 loss 614.6849975585938
Epoch 88 loss 615.862548828125
Epoch 89 loss 609.0352783203125
Epoch 90 loss 549.9428100585938
Epoch 91 loss 524.2127685546875
Epoch 92 loss 526.0050659179688
Epoch 93 loss 546.25927734375
Epoch 94 loss 546.542236328125
Epoch 95 loss 519.8538208007812
Epoch 96 loss 552.2919921875
Epoch 97 loss 512.5225219726562
Epoch 98 loss 1049.19482421875
Epoch 99 loss 555.9822998046875
Saved Losses
{'MSE - mean': 557.91144080011, 'MSE - std': 53.01886485026276, 'R2 - mean': 0.9331923077667152, 'R2 - std': 0.005874842600523473} 
 

Results After CV: {'MSE - mean': 557.91144080011, 'MSE - std': 53.01886485026276, 'R2 - mean': 0.9331923077667152, 'R2 - std': 0.005874842600523473}
Train time: 86.76016900259965
Inference time: 0.13801522020039556
Finished cross validation
Trial 26 finished with value: 557.91144080011 and parameters: {'dim': 128, 'depth': 1, 'heads': 8, 'dropout': 0.6}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513511.21875
Epoch 1 loss 510492.90625
Epoch 2 loss 506049.75
Epoch 3 loss 499480.53125
Epoch 4 loss 489684.15625
Epoch 5 loss 470408.8125
Epoch 6 loss 435285.65625
Epoch 7 loss 379801.21875
Epoch 8 loss 301453.6875
Epoch 9 loss 204939.15625
Epoch 10 loss 107272.890625
Epoch 11 loss 36730.73828125
Epoch 12 loss 10421.869140625
Epoch 13 loss 8822.703125
Epoch 14 loss 8466.48828125
Epoch 15 loss 8190.93408203125
Epoch 16 loss 6946.4091796875
Epoch 17 loss 3301.5439453125
Epoch 18 loss 2391.42822265625
Epoch 19 loss 1855.1407470703125
Epoch 20 loss 1539.4046630859375
Epoch 21 loss 1309.4954833984375
Epoch 22 loss 1159.82958984375
Epoch 23 loss 1076.234619140625
Epoch 24 loss 1069.9332275390625
Epoch 25 loss 984.203369140625
Epoch 26 loss 927.6316528320312
Epoch 27 loss 923.8892211914062
Epoch 28 loss 834.7341918945312
Epoch 29 loss 795.3862915039062
Epoch 30 loss 822.6061401367188
Epoch 31 loss 1137.7596435546875
Epoch 32 loss 826.0142211914062
Epoch 33 loss 839.2713012695312
Epoch 34 loss 802.22900390625
Epoch 35 loss 715.2186889648438
Epoch 36 loss 704.9862060546875
Epoch 37 loss 826.4320678710938
Epoch 38 loss 704.931396484375
Epoch 39 loss 661.1632080078125
Epoch 40 loss 667.0516357421875
Epoch 41 loss 699.566162109375
Epoch 42 loss 631.5693359375
Epoch 43 loss 648.808837890625
Epoch 44 loss 626.9412841796875
Epoch 45 loss 675.2108154296875
Epoch 46 loss 628.2887573242188
Epoch 47 loss 630.072265625
Epoch 48 loss 757.035400390625
Epoch 49 loss 706.7185668945312
Epoch 50 loss 625.4611206054688
Epoch 51 loss 636.3577270507812
Epoch 52 loss 598.8270263671875
Epoch 53 loss 615.26708984375
Epoch 54 loss 593.763916015625
Epoch 55 loss 578.3142700195312
Epoch 56 loss 685.6099853515625
Epoch 57 loss 572.8007202148438
Epoch 58 loss 596.6142578125
Epoch 59 loss 583.0419921875
Epoch 60 loss 589.4602661132812
Epoch 61 loss 566.7057495117188
Epoch 62 loss 558.20166015625
Epoch 63 loss 554.6744995117188
Epoch 64 loss 593.6004028320312
Epoch 65 loss 590.45166015625
Epoch 66 loss 596.99560546875
Epoch 67 loss 558.5245361328125
Epoch 68 loss 579.9119873046875
Epoch 69 loss 624.374755859375
Epoch 70 loss 572.7825317382812
Epoch 71 loss 553.5668334960938
Epoch 72 loss 605.4039916992188
Epoch 73 loss 576.222412109375
Epoch 74 loss 618.318359375
Epoch 75 loss 552.1997680664062
Epoch 76 loss 542.5497436523438
Epoch 77 loss 557.691650390625
Epoch 78 loss 576.87353515625
Epoch 79 loss 549.14501953125
Epoch 80 loss 617.3281860351562
Epoch 81 loss 592.2720336914062
Epoch 82 loss 562.6962280273438
Epoch 83 loss 543.8141479492188
Epoch 84 loss 585.4762573242188
Epoch 85 loss 563.0302734375
Epoch 86 loss 546.8834838867188
Epoch 87 loss 547.7950439453125
Epoch 88 loss 569.5123901367188
Epoch 89 loss 548.2721557617188
Epoch 90 loss 548.9762573242188
Epoch 91 loss 611.4246826171875
Epoch 92 loss 569.6708374023438
Epoch 93 loss 577.9758911132812
Epoch 94 loss 598.0343017578125
Epoch 95 loss 597.3955078125
Epoch 96 loss 577.9612426757812
Epoch 97 loss 555.5642700195312
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 542.5494084742094, 'MSE - std': 0.0, 'R2 - mean': 0.9369172613945689, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522872.625
Epoch 1 loss 520584.375
Epoch 2 loss 516802.09375
Epoch 3 loss 510983.96875
Epoch 4 loss 501979.21875
Epoch 5 loss 483733.28125
Epoch 6 loss 450172.3125
Epoch 7 loss 395933.15625
Epoch 8 loss 317896.84375
Epoch 9 loss 219795.640625
Epoch 10 loss 118596.890625
Epoch 11 loss 42506.6484375
Epoch 12 loss 10960.376953125
Epoch 13 loss 7652.6845703125
Epoch 14 loss 7609.80908203125
Epoch 15 loss 7382.0166015625
Epoch 16 loss 6362.9248046875
Epoch 17 loss 3102.44091796875
Epoch 18 loss 2224.848876953125
Epoch 19 loss 1740.7396240234375
Epoch 20 loss 1623.9317626953125
Epoch 21 loss 1351.0997314453125
Epoch 22 loss 1114.417724609375
Epoch 23 loss 1002.9573974609375
Epoch 24 loss 904.6754150390625
Epoch 25 loss 866.812255859375
Epoch 26 loss 864.656005859375
Epoch 27 loss 961.0496826171875
Epoch 28 loss 767.2557373046875
Epoch 29 loss 727.3204345703125
Epoch 30 loss 839.8733520507812
Epoch 31 loss 714.2134399414062
Epoch 32 loss 689.7396240234375
Epoch 33 loss 751.4384155273438
Epoch 34 loss 615.693603515625
Epoch 35 loss 600.3157348632812
Epoch 36 loss 612.3828125
Epoch 37 loss 577.2613525390625
Epoch 38 loss 581.9359741210938
Epoch 39 loss 569.2154541015625
Epoch 40 loss 618.4010620117188
Epoch 41 loss 541.5841674804688
Epoch 42 loss 552.8055419921875
Epoch 43 loss 688.1527099609375
Epoch 44 loss 528.0938110351562
Epoch 45 loss 558.7351684570312
Epoch 46 loss 542.8626098632812
Epoch 47 loss 514.9442138671875
Epoch 48 loss 554.7367553710938
Epoch 49 loss 505.86370849609375
Epoch 50 loss 515.7941284179688
Epoch 51 loss 517.55322265625
Epoch 52 loss 561.3585815429688
Epoch 53 loss 499.6949462890625
Epoch 54 loss 505.2847900390625
Epoch 55 loss 540.303466796875
Epoch 56 loss 508.9996032714844
Epoch 57 loss 529.8125610351562
Epoch 58 loss 514.4840698242188
Epoch 59 loss 538.4232177734375
Epoch 60 loss 488.037841796875
Epoch 61 loss 486.66912841796875
Epoch 62 loss 562.8435668945312
Epoch 63 loss 583.5637817382812
Epoch 64 loss 502.4084167480469
Epoch 65 loss 599.6697998046875
Epoch 66 loss 467.8302307128906
Epoch 67 loss 493.5841369628906
Epoch 68 loss 489.6178894042969
Epoch 69 loss 516.9361572265625
Epoch 70 loss 498.384765625
Epoch 71 loss 461.2314758300781
Epoch 72 loss 463.1532897949219
Epoch 73 loss 460.6341247558594
Epoch 74 loss 463.7272644042969
Epoch 75 loss 515.0156860351562
Epoch 76 loss 473.40399169921875
Epoch 77 loss 463.3017578125
Epoch 78 loss 500.3214416503906
Epoch 79 loss 495.9107971191406
Epoch 80 loss 469.6378479003906
Epoch 81 loss 468.8992919921875
Epoch 82 loss 460.32440185546875
Epoch 83 loss 498.95123291015625
Epoch 84 loss 619.5435180664062
Epoch 85 loss 460.5870666503906
Epoch 86 loss 446.3114013671875
Epoch 87 loss 442.6814270019531
Epoch 88 loss 469.5568542480469
Epoch 89 loss 467.9617004394531
Epoch 90 loss 473.25372314453125
Epoch 91 loss 450.1214599609375
Epoch 92 loss 449.99359130859375
Epoch 93 loss 460.9621276855469
Epoch 94 loss 468.5791320800781
Epoch 95 loss 504.6379089355469
Epoch 96 loss 447.8861389160156
Epoch 97 loss 436.3394470214844
Epoch 98 loss 468.2901306152344
Epoch 99 loss 452.6448669433594
Saved Losses
{'MSE - mean': 489.4446048021189, 'MSE - std': 53.104803672090526, 'R2 - mean': 0.9399041378165682, 'R2 - std': 0.002986876421999407} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 516790.0
Epoch 1 loss 514737.4375
Epoch 2 loss 511456.8125
Epoch 3 loss 506368.09375
Epoch 4 loss 498661.71875
Epoch 5 loss 482966.15625
Epoch 6 loss 452306.4375
Epoch 7 loss 400574.5625
Epoch 8 loss 324566.21875
Epoch 9 loss 227258.0
Epoch 10 loss 124393.1484375
Epoch 11 loss 44998.9609375
Epoch 12 loss 12286.85546875
Epoch 13 loss 9488.0283203125
Epoch 14 loss 9163.107421875
Epoch 15 loss 8864.783203125
Epoch 16 loss 7104.84765625
Epoch 17 loss 3615.405029296875
Epoch 18 loss 2540.896484375
Epoch 19 loss 2019.2437744140625
Epoch 20 loss 1711.657470703125
Epoch 21 loss 1539.9027099609375
Epoch 22 loss 1283.6358642578125
Epoch 23 loss 1345.609130859375
Epoch 24 loss 950.0880126953125
Epoch 25 loss 846.8931274414062
Epoch 26 loss 779.8681030273438
Epoch 27 loss 755.07861328125
Epoch 28 loss 687.539306640625
Epoch 29 loss 824.1679077148438
Epoch 30 loss 693.4864501953125
Epoch 31 loss 704.8758544921875
Epoch 32 loss 582.4495239257812
Epoch 33 loss 641.278564453125
Epoch 34 loss 589.4530029296875
Epoch 35 loss 615.2568969726562
Epoch 36 loss 593.6582641601562
Epoch 37 loss 534.4647827148438
Epoch 38 loss 622.7437744140625
Epoch 39 loss 594.7156982421875
Epoch 40 loss 523.374755859375
Epoch 41 loss 604.2266235351562
Epoch 42 loss 491.33746337890625
Epoch 43 loss 516.8436279296875
Epoch 44 loss 496.606201171875
Epoch 45 loss 477.9376220703125
Epoch 46 loss 485.8111572265625
Epoch 47 loss 566.7796020507812
Epoch 48 loss 523.513671875
Epoch 49 loss 534.5886840820312
Epoch 50 loss 467.6963806152344
Epoch 51 loss 483.0400695800781
Epoch 52 loss 486.4676818847656
Epoch 53 loss 489.0048828125
Epoch 54 loss 516.1323852539062
Epoch 55 loss 477.6955871582031
Epoch 56 loss 468.90057373046875
Epoch 57 loss 471.1593933105469
Epoch 58 loss 501.9103088378906
Epoch 59 loss 465.2041320800781
Epoch 60 loss 681.0234985351562
Epoch 61 loss 526.6859130859375
Epoch 62 loss 497.1925048828125
Epoch 63 loss 507.2491455078125
Epoch 64 loss 559.8456420898438
Epoch 65 loss 468.1912841796875
Epoch 66 loss 489.579833984375
Epoch 67 loss 488.91357421875
Epoch 68 loss 643.5762939453125
Epoch 69 loss 539.9172973632812
Epoch 70 loss 485.24237060546875
Epoch 71 loss 497.0350036621094
Epoch 72 loss 512.7428588867188
Epoch 73 loss 513.5942993164062
Epoch 74 loss 454.3825988769531
Epoch 75 loss 456.74334716796875
Epoch 76 loss 713.6838989257812
Epoch 77 loss 449.3826599121094
Epoch 78 loss 477.5556640625
Epoch 79 loss 467.5142517089844
Epoch 80 loss 502.97308349609375
Epoch 81 loss 446.1883850097656
Epoch 82 loss 557.0513916015625
Epoch 83 loss 453.04541015625
Epoch 84 loss 470.85498046875
Epoch 85 loss 463.3403015136719
Epoch 86 loss 472.68170166015625
Epoch 87 loss 458.6387023925781
Epoch 88 loss 503.3675231933594
Epoch 89 loss 522.8021240234375
Epoch 90 loss 583.5556030273438
Epoch 91 loss 509.5295104980469
Epoch 92 loss 452.2221374511719
Epoch 93 loss 453.1761169433594
Epoch 94 loss 641.2425537109375
Epoch 95 loss 454.4095458984375
Epoch 96 loss 506.3916320800781
Epoch 97 loss 458.4133605957031
Epoch 98 loss 533.809814453125
Epoch 99 loss 484.011474609375
Saved Losses
{'MSE - mean': 475.02593227511426, 'MSE - std': 47.91530392525456, 'R2 - mean': 0.9439581590676026, 'R2 - std': 0.006230393014452602} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 519314.34375
Epoch 1 loss 517196.78125
Epoch 2 loss 513760.5625
Epoch 3 loss 508500.21875
Epoch 4 loss 500845.1875
Epoch 5 loss 485319.4375
Epoch 6 loss 455575.09375
Epoch 7 loss 405978.03125
Epoch 8 loss 332405.25
Epoch 9 loss 236759.203125
Epoch 10 loss 133579.328125
Epoch 11 loss 50772.2578125
Epoch 12 loss 13102.318359375
Epoch 13 loss 8323.298828125
Epoch 14 loss 8223.0048828125
Epoch 15 loss 7954.0556640625
Epoch 16 loss 6480.89306640625
Epoch 17 loss 3031.131103515625
Epoch 18 loss 2217.08837890625
Epoch 19 loss 1863.5975341796875
Epoch 20 loss 1681.0919189453125
Epoch 21 loss 1444.9290771484375
Epoch 22 loss 1422.3948974609375
Epoch 23 loss 1267.4989013671875
Epoch 24 loss 1062.2784423828125
Epoch 25 loss 977.9232788085938
Epoch 26 loss 879.5350952148438
Epoch 27 loss 843.1973876953125
Epoch 28 loss 837.414306640625
Epoch 29 loss 802.4476928710938
Epoch 30 loss 721.4359130859375
Epoch 31 loss 717.376220703125
Epoch 32 loss 723.9315185546875
Epoch 33 loss 684.4369506835938
Epoch 34 loss 644.7922973632812
Epoch 35 loss 666.0724487304688
Epoch 36 loss 668.717529296875
Epoch 37 loss 625.4246215820312
Epoch 38 loss 693.2159423828125
Epoch 39 loss 642.0712280273438
Epoch 40 loss 650.8001708984375
Epoch 41 loss 618.91552734375
Epoch 42 loss 706.4027099609375
Epoch 43 loss 603.6468505859375
Epoch 44 loss 566.2766723632812
Epoch 45 loss 609.9085083007812
Epoch 46 loss 597.3353271484375
Epoch 47 loss 770.6216430664062
Epoch 48 loss 606.0181884765625
Epoch 49 loss 554.943359375
Epoch 50 loss 740.60888671875
Epoch 51 loss 567.6773681640625
Epoch 52 loss 538.00927734375
Epoch 53 loss 540.562255859375
Epoch 54 loss 531.7382202148438
Epoch 55 loss 521.8798217773438
Epoch 56 loss 577.3477172851562
Epoch 57 loss 574.2760009765625
Epoch 58 loss 536.3509521484375
Epoch 59 loss 619.4127197265625
Epoch 60 loss 521.4857177734375
Epoch 61 loss 511.8687438964844
Epoch 62 loss 499.9190673828125
Epoch 63 loss 561.4364624023438
Epoch 64 loss 492.8733825683594
Epoch 65 loss 553.9736938476562
Epoch 66 loss 676.0297241210938
Epoch 67 loss 505.4525146484375
Epoch 68 loss 529.6646728515625
Epoch 69 loss 682.7509155273438
Epoch 70 loss 570.089111328125
Epoch 71 loss 492.4209899902344
Epoch 72 loss 490.3343811035156
Epoch 73 loss 487.41424560546875
Epoch 74 loss 482.027099609375
Epoch 75 loss 700.5275268554688
Epoch 76 loss 485.6389465332031
Epoch 77 loss 524.5858764648438
Epoch 78 loss 506.89154052734375
Epoch 79 loss 558.4962768554688
Epoch 80 loss 507.86297607421875
Epoch 81 loss 483.77423095703125
Epoch 82 loss 504.07159423828125
Epoch 83 loss 548.1954956054688
Epoch 84 loss 492.80230712890625
Epoch 85 loss 522.662109375
Epoch 86 loss 527.9220581054688
Epoch 87 loss 483.8411865234375
Epoch 88 loss 502.6523742675781
Epoch 89 loss 697.96044921875
Epoch 90 loss 560.9148559570312
Epoch 91 loss 555.6939697265625
Epoch 92 loss 485.90789794921875
Epoch 93 loss 494.2795715332031
Epoch 94 loss 481.95977783203125
Epoch 95 loss 478.8446044921875
Epoch 96 loss 524.3776245117188
Epoch 97 loss 485.502197265625
Epoch 98 loss 535.7733764648438
Epoch 99 loss 477.8748474121094
Saved Losses
{'MSE - mean': 475.73816394393316, 'MSE - std': 41.514203407235726, 'R2 - mean': 0.9435843558487349, 'R2 - std': 0.005434384452282761} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514895.84375
Epoch 1 loss 511427.5625
Epoch 2 loss 506083.59375
Epoch 3 loss 498257.03125
Epoch 4 loss 486274.0625
Epoch 5 loss 462894.90625
Epoch 6 loss 421115.375
Epoch 7 loss 356402.78125
Epoch 8 loss 268457.78125
Epoch 9 loss 166761.984375
Epoch 10 loss 74322.6484375
Epoch 11 loss 20579.771484375
Epoch 12 loss 8077.7373046875
Epoch 13 loss 8124.79150390625
Epoch 14 loss 7699.2353515625
Epoch 15 loss 6967.22265625
Epoch 16 loss 3516.541015625
Epoch 17 loss 2433.833984375
Epoch 18 loss 1697.489501953125
Epoch 19 loss 1390.2591552734375
Epoch 20 loss 1212.132568359375
Epoch 21 loss 1068.9237060546875
Epoch 22 loss 956.9256591796875
Epoch 23 loss 887.0994262695312
Epoch 24 loss 858.3564453125
Epoch 25 loss 808.6409301757812
Epoch 26 loss 835.8600463867188
Epoch 27 loss 759.9691162109375
Epoch 28 loss 760.3703002929688
Epoch 29 loss 663.2612915039062
Epoch 30 loss 774.3208618164062
Epoch 31 loss 636.6441650390625
Epoch 32 loss 625.0792846679688
Epoch 33 loss 594.3575439453125
Epoch 34 loss 577.4923706054688
Epoch 35 loss 609.8974609375
Epoch 36 loss 578.1449584960938
Epoch 37 loss 604.8837280273438
Epoch 38 loss 555.7431030273438
Epoch 39 loss 581.8871459960938
Epoch 40 loss 559.0985717773438
Epoch 41 loss 620.5506591796875
Epoch 42 loss 584.3516235351562
Epoch 43 loss 567.01953125
Epoch 44 loss 578.8366088867188
Epoch 45 loss 548.75732421875
Epoch 46 loss 539.551025390625
Epoch 47 loss 532.7427368164062
Epoch 48 loss 541.7787475585938
Epoch 49 loss 527.8548583984375
Epoch 50 loss 539.8487548828125
Epoch 51 loss 532.3237915039062
Epoch 52 loss 548.8038940429688
Epoch 53 loss 536.74072265625
Epoch 54 loss 506.0117492675781
Epoch 55 loss 517.7252197265625
Epoch 56 loss 511.34716796875
Epoch 57 loss 500.41278076171875
Epoch 58 loss 570.9492797851562
Epoch 59 loss 609.7765502929688
Epoch 60 loss 512.8363037109375
Epoch 61 loss 494.02093505859375
Epoch 62 loss 493.1236572265625
Epoch 63 loss 504.8528137207031
Epoch 64 loss 493.4591979980469
Epoch 65 loss 570.5477294921875
Epoch 66 loss 531.253173828125
Epoch 67 loss 498.6483459472656
Epoch 68 loss 509.0198669433594
Epoch 69 loss 543.2935791015625
Epoch 70 loss 509.6794738769531
Epoch 71 loss 505.4151611328125
Epoch 72 loss 516.0494995117188
Epoch 73 loss 491.8951721191406
Epoch 74 loss 508.6847839355469
Epoch 75 loss 500.8228759765625
Epoch 76 loss 526.9240112304688
Epoch 77 loss 511.609375
Epoch 78 loss 512.1363525390625
Epoch 79 loss 494.4717712402344
Epoch 80 loss 492.46905517578125
Epoch 81 loss 550.6845703125
Epoch 82 loss 526.3558959960938
Epoch 83 loss 496.041015625
Epoch 84 loss 586.9008178710938
Epoch 85 loss 579.4319458007812
Epoch 86 loss 494.47430419921875
Epoch 87 loss 499.9747009277344
Epoch 88 loss 487.73626708984375
Epoch 89 loss 483.8846130371094
Epoch 90 loss 516.9752807617188
Epoch 91 loss 511.3220520019531
Epoch 92 loss 485.4132385253906
Epoch 93 loss 511.2159118652344
Epoch 94 loss 485.39422607421875
Epoch 95 loss 497.75970458984375
Epoch 96 loss 484.6249694824219
Epoch 97 loss 555.8253173828125
Epoch 98 loss 524.4464721679688
Epoch 99 loss 549.0072021484375
Saved Losses
{'MSE - mean': 477.36747611375824, 'MSE - std': 37.27414519766796, 'R2 - mean': 0.9427370646313236, 'R2 - std': 0.005147585563016853} 
 

Results After CV: {'MSE - mean': 477.36747611375824, 'MSE - std': 37.27414519766796, 'R2 - mean': 0.9427370646313236, 'R2 - std': 0.005147585563016853}
Train time: 102.03040001580048
Inference time: 0.1394810695997876
Finished cross validation
Trial 27 finished with value: 477.36747611375824 and parameters: {'dim': 32, 'depth': 3, 'heads': 4, 'dropout': 0.1}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513209.28125
Epoch 1 loss 510440.4375
Epoch 2 loss 506376.625
Epoch 3 loss 500826.59375
Epoch 4 loss 492075.625
Epoch 5 loss 473838.5
Epoch 6 loss 439942.09375
Epoch 7 loss 385166.75
Epoch 8 loss 306726.9375
Epoch 9 loss 209226.96875
Epoch 10 loss 110007.2421875
Epoch 11 loss 37488.89453125
Epoch 12 loss 10519.9716796875
Epoch 13 loss 8862.59765625
Epoch 14 loss 8581.388671875
Epoch 15 loss 8463.4306640625
Epoch 16 loss 4427.0244140625
Epoch 17 loss 2781.0693359375
Epoch 18 loss 2021.25439453125
Epoch 19 loss 1986.1546630859375
Epoch 20 loss 1490.178955078125
Epoch 21 loss 1239.908447265625
Epoch 22 loss 1060.4903564453125
Epoch 23 loss 986.7777099609375
Epoch 24 loss 900.6417846679688
Epoch 25 loss 863.0073852539062
Epoch 26 loss 805.9471435546875
Epoch 27 loss 916.7886962890625
Epoch 28 loss 951.0082397460938
Epoch 29 loss 794.5784912109375
Epoch 30 loss 820.7410278320312
Epoch 31 loss 767.9207153320312
Epoch 32 loss 818.0552978515625
Epoch 33 loss 678.637939453125
Epoch 34 loss 806.9935913085938
Epoch 35 loss 662.6813354492188
Epoch 36 loss 655.9127807617188
Epoch 37 loss 994.7510375976562
Epoch 38 loss 642.1915283203125
Epoch 39 loss 677.6716918945312
Epoch 40 loss 653.24462890625
Epoch 41 loss 697.0147094726562
Epoch 42 loss 757.3703002929688
Epoch 43 loss 662.3841552734375
Epoch 44 loss 622.8794555664062
Epoch 45 loss 617.2166748046875
Epoch 46 loss 723.2808837890625
Epoch 47 loss 650.21923828125
Epoch 48 loss 633.85986328125
Epoch 49 loss 614.6893920898438
Epoch 50 loss 632.9156494140625
Epoch 51 loss 608.1871337890625
Epoch 52 loss 672.126220703125
Epoch 53 loss 615.1155395507812
Epoch 54 loss 652.0667114257812
Epoch 55 loss 705.8037109375
Epoch 56 loss 801.0399169921875
Epoch 57 loss 607.8174438476562
Epoch 58 loss 617.3977661132812
Epoch 59 loss 601.87109375
Epoch 60 loss 584.7141723632812
Epoch 61 loss 647.3433837890625
Epoch 62 loss 653.0603637695312
Epoch 63 loss 605.75
Epoch 64 loss 618.53271484375
Epoch 65 loss 608.4588623046875
Epoch 66 loss 610.0322875976562
Epoch 67 loss 585.3846435546875
Epoch 68 loss 641.478271484375
Epoch 69 loss 605.5470581054688
Epoch 70 loss 597.558349609375
Epoch 71 loss 603.3427734375
Epoch 72 loss 685.7796630859375
Epoch 73 loss 627.0543212890625
Epoch 74 loss 619.2648315429688
Epoch 75 loss 612.5501098632812
Epoch 76 loss 712.0445556640625
Epoch 77 loss 710.9351196289062
Epoch 78 loss 590.671142578125
Epoch 79 loss 622.34716796875
Epoch 80 loss 600.2000122070312
Epoch 81 loss 610.9555053710938
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 584.7137616499052, 'MSE - std': 0.0, 'R2 - mean': 0.9320147717257853, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522178.6875
Epoch 1 loss 519326.96875
Epoch 2 loss 515182.5
Epoch 3 loss 509316.625
Epoch 4 loss 500483.5625
Epoch 5 loss 482355.4375
Epoch 6 loss 448016.28125
Epoch 7 loss 392277.84375
Epoch 8 loss 312251.09375
Epoch 9 loss 212390.03125
Epoch 10 loss 110693.6875
Epoch 11 loss 37294.6328125
Epoch 12 loss 9792.71484375
Epoch 13 loss 7745.044921875
Epoch 14 loss 7571.74560546875
Epoch 15 loss 7237.64892578125
Epoch 16 loss 4121.8427734375
Epoch 17 loss 2804.47216796875
Epoch 18 loss 1806.7127685546875
Epoch 19 loss 1598.5052490234375
Epoch 20 loss 1254.6319580078125
Epoch 21 loss 1234.287353515625
Epoch 22 loss 1000.323486328125
Epoch 23 loss 972.573486328125
Epoch 24 loss 752.4203491210938
Epoch 25 loss 730.169677734375
Epoch 26 loss 675.9935913085938
Epoch 27 loss 659.3893432617188
Epoch 28 loss 770.1781616210938
Epoch 29 loss 766.3870239257812
Epoch 30 loss 578.5961303710938
Epoch 31 loss 592.3984375
Epoch 32 loss 547.99267578125
Epoch 33 loss 564.2578125
Epoch 34 loss 535.2576293945312
Epoch 35 loss 502.7127380371094
Epoch 36 loss 571.2385864257812
Epoch 37 loss 542.6732788085938
Epoch 38 loss 557.6433715820312
Epoch 39 loss 504.8253479003906
Epoch 40 loss 637.034423828125
Epoch 41 loss 501.9606018066406
Epoch 42 loss 497.9331970214844
Epoch 43 loss 477.2119445800781
Epoch 44 loss 486.5858459472656
Epoch 45 loss 472.433837890625
Epoch 46 loss 496.8154602050781
Epoch 47 loss 465.42962646484375
Epoch 48 loss 477.4430847167969
Epoch 49 loss 457.8642883300781
Epoch 50 loss 465.23602294921875
Epoch 51 loss 570.8931274414062
Epoch 52 loss 532.8106689453125
Epoch 53 loss 470.33758544921875
Epoch 54 loss 473.06903076171875
Epoch 55 loss 567.537353515625
Epoch 56 loss 505.8323059082031
Epoch 57 loss 476.3885803222656
Epoch 58 loss 532.4281005859375
Epoch 59 loss 496.3909606933594
Epoch 60 loss 487.8781433105469
Epoch 61 loss 522.9629516601562
Epoch 62 loss 456.10906982421875
Epoch 63 loss 527.5948486328125
Epoch 64 loss 460.9412841796875
Epoch 65 loss 510.1161193847656
Epoch 66 loss 472.5818176269531
Epoch 67 loss 540.1739501953125
Epoch 68 loss 555.4583129882812
Epoch 69 loss 442.14068603515625
Epoch 70 loss 454.2832946777344
Epoch 71 loss 462.54541015625
Epoch 72 loss 465.5821838378906
Epoch 73 loss 484.6222839355469
Epoch 74 loss 478.8562316894531
Epoch 75 loss 447.02374267578125
Epoch 76 loss 437.0906677246094
Epoch 77 loss 458.8744812011719
Epoch 78 loss 469.9980773925781
Epoch 79 loss 525.337158203125
Epoch 80 loss 433.58831787109375
Epoch 81 loss 470.2237854003906
Epoch 82 loss 448.9120788574219
Epoch 83 loss 449.3319091796875
Epoch 84 loss 452.23455810546875
Epoch 85 loss 464.4903259277344
Epoch 86 loss 470.95458984375
Epoch 87 loss 523.5064697265625
Epoch 88 loss 439.9648742675781
Epoch 89 loss 434.43182373046875
Epoch 90 loss 457.45416259765625
Epoch 91 loss 445.04669189453125
Epoch 92 loss 512.3095092773438
Epoch 93 loss 501.54034423828125
Epoch 94 loss 549.6204833984375
Epoch 95 loss 484.99591064453125
Epoch 96 loss 539.5121459960938
Epoch 97 loss 455.7142639160156
Epoch 98 loss 530.1720581054688
Epoch 99 loss 458.907958984375
Saved Losses
{'MSE - mean': 509.15119265556064, 'MSE - std': 75.56256899434456, 'R2 - mean': 0.9376329326605266, 'R2 - std': 0.0056181609347412675} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514623.15625
Epoch 1 loss 511631.78125
Epoch 2 loss 507475.09375
Epoch 3 loss 501912.375
Epoch 4 loss 493253.03125
Epoch 5 loss 475254.25
Epoch 6 loss 441935.28125
Epoch 7 loss 387818.78125
Epoch 8 loss 310052.3125
Epoch 9 loss 212885.265625
Epoch 10 loss 113110.078125
Epoch 11 loss 39820.734375
Epoch 12 loss 11547.240234375
Epoch 13 loss 9521.103515625
Epoch 14 loss 9245.697265625
Epoch 15 loss 9098.59375
Epoch 16 loss 6770.8486328125
Epoch 17 loss 3436.099365234375
Epoch 18 loss 2345.96630859375
Epoch 19 loss 1834.9000244140625
Epoch 20 loss 1473.232177734375
Epoch 21 loss 1363.2236328125
Epoch 22 loss 1099.15771484375
Epoch 23 loss 1277.513916015625
Epoch 24 loss 995.1901245117188
Epoch 25 loss 836.352783203125
Epoch 26 loss 858.98828125
Epoch 27 loss 779.4133911132812
Epoch 28 loss 770.0194702148438
Epoch 29 loss 653.3746948242188
Epoch 30 loss 847.7982177734375
Epoch 31 loss 743.8094482421875
Epoch 32 loss 674.8724365234375
Epoch 33 loss 601.6018676757812
Epoch 34 loss 573.3427124023438
Epoch 35 loss 633.3634033203125
Epoch 36 loss 748.5357055664062
Epoch 37 loss 561.1931762695312
Epoch 38 loss 593.4885864257812
Epoch 39 loss 561.4362182617188
Epoch 40 loss 540.2958374023438
Epoch 41 loss 602.1965942382812
Epoch 42 loss 586.2705688476562
Epoch 43 loss 591.8540649414062
Epoch 44 loss 596.8527221679688
Epoch 45 loss 514.1397705078125
Epoch 46 loss 600.58251953125
Epoch 47 loss 559.4560546875
Epoch 48 loss 721.2236328125
Epoch 49 loss 522.1436767578125
Epoch 50 loss 506.4378967285156
Epoch 51 loss 507.3873596191406
Epoch 52 loss 489.97955322265625
Epoch 53 loss 497.213134765625
Epoch 54 loss 516.8558959960938
Epoch 55 loss 525.3667602539062
Epoch 56 loss 506.9798583984375
Epoch 57 loss 625.09375
Epoch 58 loss 495.98779296875
Epoch 59 loss 558.5758666992188
Epoch 60 loss 475.7267150878906
Epoch 61 loss 484.2574462890625
Epoch 62 loss 580.4745483398438
Epoch 63 loss 526.0873413085938
Epoch 64 loss 481.7174072265625
Epoch 65 loss 586.004150390625
Epoch 66 loss 484.3865966796875
Epoch 67 loss 479.75225830078125
Epoch 68 loss 487.7338562011719
Epoch 69 loss 492.4031066894531
Epoch 70 loss 490.36944580078125
Epoch 71 loss 510.1413879394531
Epoch 72 loss 607.5512084960938
Epoch 73 loss 529.0957641601562
Epoch 74 loss 639.3535766601562
Epoch 75 loss 575.197509765625
Epoch 76 loss 540.6278076171875
Epoch 77 loss 570.47412109375
Epoch 78 loss 565.968994140625
Epoch 79 loss 589.126953125
Epoch 80 loss 546.041015625
Epoch 81 loss 488.580078125
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 498.0096296112495, 'MSE - std': 63.67681479804171, 'R2 - mean': 0.9413862748431785, 'R2 - std': 0.007015528723666023} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517278.375
Epoch 1 loss 514197.09375
Epoch 2 loss 509801.46875
Epoch 3 loss 503712.96875
Epoch 4 loss 494285.03125
Epoch 5 loss 474859.125
Epoch 6 loss 438684.375
Epoch 7 loss 380786.65625
Epoch 8 loss 298319.375
Epoch 9 loss 196943.421875
Epoch 10 loss 97105.6875
Epoch 11 loss 29944.55078125
Epoch 12 loss 9073.1357421875
Epoch 13 loss 8523.49609375
Epoch 14 loss 8298.01953125
Epoch 15 loss 7911.26904296875
Epoch 16 loss 3636.97314453125
Epoch 17 loss 2517.91455078125
Epoch 18 loss 1820.398193359375
Epoch 19 loss 1439.531494140625
Epoch 20 loss 1266.7076416015625
Epoch 21 loss 1195.003173828125
Epoch 22 loss 976.1669311523438
Epoch 23 loss 899.2337036132812
Epoch 24 loss 854.5422973632812
Epoch 25 loss 796.7755126953125
Epoch 26 loss 755.3406982421875
Epoch 27 loss 923.4627075195312
Epoch 28 loss 733.675048828125
Epoch 29 loss 695.4683227539062
Epoch 30 loss 827.8007202148438
Epoch 31 loss 648.1585693359375
Epoch 32 loss 710.2975463867188
Epoch 33 loss 632.9080200195312
Epoch 34 loss 615.1425170898438
Epoch 35 loss 602.6959228515625
Epoch 36 loss 600.018798828125
Epoch 37 loss 696.9281616210938
Epoch 38 loss 598.8282470703125
Epoch 39 loss 643.0712280273438
Epoch 40 loss 1075.6143798828125
Epoch 41 loss 588.1598510742188
Epoch 42 loss 611.9127197265625
Epoch 43 loss 691.2769165039062
Epoch 44 loss 751.2393188476562
Epoch 45 loss 574.814453125
Epoch 46 loss 578.3546752929688
Epoch 47 loss 699.4945068359375
Epoch 48 loss 571.9781494140625
Epoch 49 loss 604.8818969726562
Epoch 50 loss 560.9044799804688
Epoch 51 loss 545.8223876953125
Epoch 52 loss 551.94091796875
Epoch 53 loss 561.1664428710938
Epoch 54 loss 663.09814453125
Epoch 55 loss 1044.4747314453125
Epoch 56 loss 650.3928833007812
Epoch 57 loss 537.146728515625
Epoch 58 loss 603.4307250976562
Epoch 59 loss 589.9146118164062
Epoch 60 loss 575.1912841796875
Epoch 61 loss 671.4056396484375
Epoch 62 loss 552.3980102539062
Epoch 63 loss 561.9264526367188
Epoch 64 loss 549.8221435546875
Epoch 65 loss 537.0516967773438
Epoch 66 loss 581.5298461914062
Epoch 67 loss 546.8552856445312
Epoch 68 loss 554.5731201171875
Epoch 69 loss 553.9089965820312
Epoch 70 loss 533.4261474609375
Epoch 71 loss 553.5753173828125
Epoch 72 loss 574.6319580078125
Epoch 73 loss 563.2771606445312
Epoch 74 loss 527.3862915039062
Epoch 75 loss 704.16064453125
Epoch 76 loss 567.522705078125
Epoch 77 loss 568.2930908203125
Epoch 78 loss 553.1986083984375
Epoch 79 loss 540.379150390625
Epoch 80 loss 581.9573364257812
Epoch 81 loss 542.8054809570312
Epoch 82 loss 551.0439453125
Epoch 83 loss 568.5515747070312
Epoch 84 loss 550.3592529296875
Epoch 85 loss 527.4955444335938
Epoch 86 loss 527.2410278320312
Epoch 87 loss 523.665283203125
Epoch 88 loss 575.5568237304688
Epoch 89 loss 542.5296020507812
Epoch 90 loss 519.489990234375
Epoch 91 loss 546.950927734375
Epoch 92 loss 571.9692993164062
Epoch 93 loss 523.6664428710938
Epoch 94 loss 590.22998046875
Epoch 95 loss 596.76318359375
Epoch 96 loss 620.7775268554688
Epoch 97 loss 599.5172729492188
Epoch 98 loss 564.4835205078125
Epoch 99 loss 507.9601135253906
Saved Losses
{'MSE - mean': 500.49729926652236, 'MSE - std': 55.313814351022415, 'R2 - mean': 0.9407498561645391, 'R2 - std': 0.006174813248835986} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514512.34375
Epoch 1 loss 511391.0
Epoch 2 loss 506747.875
Epoch 3 loss 500280.5
Epoch 4 loss 490574.09375
Epoch 5 loss 471110.90625
Epoch 6 loss 435819.6875
Epoch 7 loss 379461.28125
Epoch 8 loss 299568.75
Epoch 9 loss 201290.359375
Epoch 10 loss 102821.703125
Epoch 11 loss 33652.6015625
Epoch 12 loss 9288.2197265625
Epoch 13 loss 8218.3974609375
Epoch 14 loss 7941.66064453125
Epoch 15 loss 7929.93798828125
Epoch 16 loss 7415.509765625
Epoch 17 loss 3509.064208984375
Epoch 18 loss 2088.0986328125
Epoch 19 loss 1490.4608154296875
Epoch 20 loss 1167.6165771484375
Epoch 21 loss 1062.7109375
Epoch 22 loss 895.3092651367188
Epoch 23 loss 892.7921142578125
Epoch 24 loss 890.8463745117188
Epoch 25 loss 720.6103515625
Epoch 26 loss 683.1085205078125
Epoch 27 loss 971.509765625
Epoch 28 loss 725.3925170898438
Epoch 29 loss 658.2739868164062
Epoch 30 loss 757.5612182617188
Epoch 31 loss 649.8989868164062
Epoch 32 loss 578.310791015625
Epoch 33 loss 609.4034423828125
Epoch 34 loss 559.07568359375
Epoch 35 loss 594.4116821289062
Epoch 36 loss 543.42919921875
Epoch 37 loss 550.7139892578125
Epoch 38 loss 546.8079223632812
Epoch 39 loss 537.0523071289062
Epoch 40 loss 583.7930297851562
Epoch 41 loss 651.5526123046875
Epoch 42 loss 579.7957763671875
Epoch 43 loss 536.1734008789062
Epoch 44 loss 505.0350341796875
Epoch 45 loss 515.8090209960938
Epoch 46 loss 499.3593444824219
Epoch 47 loss 515.5604858398438
Epoch 48 loss 523.1613159179688
Epoch 49 loss 489.4880065917969
Epoch 50 loss 472.9216003417969
Epoch 51 loss 478.85198974609375
Epoch 52 loss 508.62109375
Epoch 53 loss 550.3638305664062
Epoch 54 loss 477.80572509765625
Epoch 55 loss 578.0966796875
Epoch 56 loss 537.8165893554688
Epoch 57 loss 481.7714538574219
Epoch 58 loss 488.665771484375
Epoch 59 loss 564.345703125
Epoch 60 loss 491.12005615234375
Epoch 61 loss 507.1636047363281
Epoch 62 loss 515.0824584960938
Epoch 63 loss 498.7071228027344
Epoch 64 loss 481.009521484375
Epoch 65 loss 477.994873046875
Epoch 66 loss 511.718505859375
Epoch 67 loss 476.8259582519531
Epoch 68 loss 482.6466369628906
Epoch 69 loss 565.3933715820312
Epoch 70 loss 473.189208984375
Epoch 71 loss 521.4900512695312
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 494.98216885282744, 'MSE - std': 50.68886564491013, 'R2 - mean': 0.9407442963250698, 'R2 - std': 0.005522932063103803} 
 

Results After CV: {'MSE - mean': 494.98216885282744, 'MSE - std': 50.68886564491013, 'R2 - mean': 0.9407442963250698, 'R2 - std': 0.005522932063103803}
Train time: 108.31975149940008
Inference time: 0.13911839600004897
Finished cross validation
Trial 28 finished with value: 494.98216885282744 and parameters: {'dim': 32, 'depth': 6, 'heads': 4, 'dropout': 0.1}. Best is trial 18 with value: 472.816397197097.
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513243.4375
Epoch 1 loss 510227.625
Epoch 2 loss 505922.875
Epoch 3 loss 500063.125
Epoch 4 loss 491737.71875
Epoch 5 loss 475025.4375
Epoch 6 loss 442703.09375
Epoch 7 loss 389772.59375
Epoch 8 loss 313341.6875
Epoch 9 loss 216990.890625
Epoch 10 loss 117120.6171875
Epoch 11 loss 41747.34375
Epoch 12 loss 11239.1474609375
Epoch 13 loss 8778.4189453125
Epoch 14 loss 8644.6064453125
Epoch 15 loss 8270.732421875
Epoch 16 loss 3984.225341796875
Epoch 17 loss 3105.25927734375
Epoch 18 loss 1963.1307373046875
Epoch 19 loss 1697.5687255859375
Epoch 20 loss 1362.6063232421875
Epoch 21 loss 1270.905517578125
Epoch 22 loss 1271.7825927734375
Epoch 23 loss 1023.2824096679688
Epoch 24 loss 1040.685546875
Epoch 25 loss 872.4788208007812
Epoch 26 loss 846.8937377929688
Epoch 27 loss 806.375
Epoch 28 loss 787.1754760742188
Epoch 29 loss 1034.171875
Epoch 30 loss 812.9705200195312
Epoch 31 loss 759.1436157226562
Epoch 32 loss 802.5818481445312
Epoch 33 loss 874.5469970703125
Epoch 34 loss 727.4491577148438
Epoch 35 loss 748.215576171875
Epoch 36 loss 680.1118774414062
Epoch 37 loss 686.958251953125
Epoch 38 loss 649.8740234375
Epoch 39 loss 660.90234375
Epoch 40 loss 713.7584228515625
Epoch 41 loss 655.2372436523438
Epoch 42 loss 658.149658203125
Epoch 43 loss 680.3214111328125
Epoch 44 loss 671.287353515625
Epoch 45 loss 668.1868896484375
Epoch 46 loss 667.4426879882812
Epoch 47 loss 644.319580078125
Epoch 48 loss 645.6929321289062
Epoch 49 loss 612.2626953125
Epoch 50 loss 750.00537109375
Epoch 51 loss 620.9027099609375
Epoch 52 loss 654.2970581054688
Epoch 53 loss 718.6398315429688
Epoch 54 loss 620.7222900390625
Epoch 55 loss 642.3649291992188
Epoch 56 loss 639.4736938476562
Epoch 57 loss 631.0113525390625
Epoch 58 loss 629.3755493164062
Epoch 59 loss 744.2003173828125
Epoch 60 loss 619.73291015625
Epoch 61 loss 696.4039916992188
Epoch 62 loss 617.4437866210938
Epoch 63 loss 926.2291870117188
Epoch 64 loss 607.0807495117188
Epoch 65 loss 628.5586547851562
Epoch 66 loss 791.4983520507812
Epoch 67 loss 653.176025390625
Epoch 68 loss 619.2818603515625
Epoch 69 loss 678.0
Epoch 70 loss 629.147216796875
Epoch 71 loss 644.8917236328125
Epoch 72 loss 635.5643920898438
Epoch 73 loss 706.4932861328125
Epoch 74 loss 622.4979858398438
Epoch 75 loss 630.681884765625
Epoch 76 loss 619.9575805664062
Epoch 77 loss 630.8806762695312
Epoch 78 loss 608.5829467773438
Epoch 79 loss 601.4647216796875
Epoch 80 loss 647.9804077148438
Epoch 81 loss 601.8939208984375
Epoch 82 loss 635.9898681640625
Epoch 83 loss 617.2265014648438
Epoch 84 loss 622.2647705078125
Epoch 85 loss 618.3482055664062
Epoch 86 loss 601.7273559570312
Epoch 87 loss 614.1674194335938
Epoch 88 loss 779.3442993164062
Epoch 89 loss 768.8018798828125
Epoch 90 loss 619.4595336914062
Epoch 91 loss 606.9321899414062
Epoch 92 loss 671.8654174804688
Epoch 93 loss 643.084716796875
Epoch 94 loss 622.9197998046875
Epoch 95 loss 607.07080078125
Epoch 96 loss 635.3211669921875
Epoch 97 loss 613.1179809570312
Epoch 98 loss 612.3746337890625
Epoch 99 loss 603.8985595703125
Saved Losses
{'MSE - mean': 601.4645751150332, 'MSE - std': 0.0, 'R2 - mean': 0.930067138624091, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 523938.4375
Epoch 1 loss 522156.0625
Epoch 2 loss 519202.28125
Epoch 3 loss 514469.09375
Epoch 4 loss 507447.09375
Epoch 5 loss 494041.09375
Epoch 6 loss 467302.25
Epoch 7 loss 421079.40625
Epoch 8 loss 350642.84375
Epoch 9 loss 256275.5625
Epoch 10 loss 150218.40625
Epoch 11 loss 60643.16015625
Epoch 12 loss 14970.763671875
Epoch 13 loss 7639.32666015625
Epoch 14 loss 7700.548828125
Epoch 15 loss 7489.09716796875
Epoch 16 loss 5723.8095703125
Epoch 17 loss 3121.363525390625
Epoch 18 loss 1841.256591796875
Epoch 19 loss 1521.872314453125
Epoch 20 loss 1528.2806396484375
Epoch 21 loss 999.7974853515625
Epoch 22 loss 906.7979125976562
Epoch 23 loss 872.9371948242188
Epoch 24 loss 735.5863037109375
Epoch 25 loss 678.7301635742188
Epoch 26 loss 688.80078125
Epoch 27 loss 631.2462768554688
Epoch 28 loss 647.4508056640625
Epoch 29 loss 669.9248657226562
Epoch 30 loss 587.4140014648438
Epoch 31 loss 673.4981689453125
Epoch 32 loss 693.4609985351562
Epoch 33 loss 642.8761596679688
Epoch 34 loss 549.1190795898438
Epoch 35 loss 489.4908752441406
Epoch 36 loss 489.08941650390625
Epoch 37 loss 501.12841796875
Epoch 38 loss 490.544189453125
Epoch 39 loss 481.4730529785156
Epoch 40 loss 486.7520751953125
Epoch 41 loss 484.22039794921875
Epoch 42 loss 462.7400207519531
Epoch 43 loss 458.2764892578125
Epoch 44 loss 448.5541687011719
Epoch 45 loss 459.64892578125
Epoch 46 loss 453.9175109863281
Epoch 47 loss 474.91259765625
Epoch 48 loss 455.3301086425781
Epoch 49 loss 464.7226257324219
Epoch 50 loss 445.5948486328125
Epoch 51 loss 451.3533630371094
Epoch 52 loss 475.0600280761719
Epoch 53 loss 448.29290771484375
Epoch 54 loss 625.5350341796875
Epoch 55 loss 560.6326293945312
Epoch 56 loss 463.048095703125
Epoch 57 loss 439.8824462890625
Epoch 58 loss 461.33447265625
Epoch 59 loss 543.1990356445312
Epoch 60 loss 440.26873779296875
Epoch 61 loss 469.55889892578125
Epoch 62 loss 448.91888427734375
Epoch 63 loss 449.9178161621094
Epoch 64 loss 436.0147705078125
Epoch 65 loss 466.49298095703125
Epoch 66 loss 449.064208984375
Epoch 67 loss 451.2196960449219
Epoch 68 loss 489.2373962402344
Epoch 69 loss 751.9326782226562
Epoch 70 loss 444.22308349609375
Epoch 71 loss 630.1908569335938
Epoch 72 loss 467.7054748535156
Epoch 73 loss 495.7210388183594
Epoch 74 loss 429.67987060546875
Epoch 75 loss 498.62664794921875
Epoch 76 loss 429.3662414550781
Epoch 77 loss 447.05242919921875
Epoch 78 loss 482.0004577636719
Epoch 79 loss 598.864501953125
Epoch 80 loss 438.92974853515625
Epoch 81 loss 463.07293701171875
Epoch 82 loss 439.5719299316406
Epoch 83 loss 437.0426940917969
Epoch 84 loss 442.0035705566406
Epoch 85 loss 470.4517822265625
Epoch 86 loss 444.0723876953125
Epoch 87 loss 447.1627502441406
Epoch 88 loss 467.2091369628906
Epoch 89 loss 443.1761779785156
Epoch 90 loss 502.6287841796875
Epoch 91 loss 487.2852478027344
Epoch 92 loss 449.3784484863281
Epoch 93 loss 490.8980407714844
Epoch 94 loss 519.6400146484375
Epoch 95 loss 472.213134765625
Epoch 96 loss 463.1769714355469
Epoch 97 loss 585.8020629882812
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 515.4153552011244, 'MSE - std': 86.04921991390887, 'R2 - mean': 0.9369354397773852, 'R2 - std': 0.006868301153294343} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515432.53125
Epoch 1 loss 512748.9375
Epoch 2 loss 508699.3125
Epoch 3 loss 503002.375
Epoch 4 loss 494852.28125
Epoch 5 loss 478330.90625
Epoch 6 loss 447062.625
Epoch 7 loss 395671.84375
Epoch 8 loss 320693.21875
Epoch 9 loss 225417.59375
Epoch 10 loss 124936.5625
Epoch 11 loss 46649.0390625
Epoch 12 loss 12873.833984375
Epoch 13 loss 9424.6845703125
Epoch 14 loss 9499.61328125
Epoch 15 loss 9092.57421875
Epoch 16 loss 6696.037109375
Epoch 17 loss 3359.08544921875
Epoch 18 loss 2309.76171875
Epoch 19 loss 1875.6380615234375
Epoch 20 loss 1299.461181640625
Epoch 21 loss 1112.287353515625
Epoch 22 loss 991.5918579101562
Epoch 23 loss 1303.287841796875
Epoch 24 loss 847.2151489257812
Epoch 25 loss 880.8900146484375
Epoch 26 loss 737.6709594726562
Epoch 27 loss 651.9558715820312
Epoch 28 loss 663.765380859375
Epoch 29 loss 622.1491088867188
Epoch 30 loss 648.945068359375
Epoch 31 loss 852.3800659179688
Epoch 32 loss 597.4109497070312
Epoch 33 loss 641.306640625
Epoch 34 loss 540.1162109375
Epoch 35 loss 534.656982421875
Epoch 36 loss 743.1083374023438
Epoch 37 loss 535.1046752929688
Epoch 38 loss 532.6483764648438
Epoch 39 loss 560.868896484375
Epoch 40 loss 515.2850341796875
Epoch 41 loss 548.6215209960938
Epoch 42 loss 505.5702819824219
Epoch 43 loss 580.4073486328125
Epoch 44 loss 517.8252563476562
Epoch 45 loss 563.70361328125
Epoch 46 loss 704.7167358398438
Epoch 47 loss 571.2808227539062
Epoch 48 loss 511.08245849609375
Epoch 49 loss 568.9174194335938
Epoch 50 loss 637.587646484375
Epoch 51 loss 545.302734375
Epoch 52 loss 519.1596069335938
Epoch 53 loss 491.90673828125
Epoch 54 loss 483.5238342285156
Epoch 55 loss 497.6209716796875
Epoch 56 loss 606.2601318359375
Epoch 57 loss 554.306884765625
Epoch 58 loss 536.29736328125
Epoch 59 loss 488.81292724609375
Epoch 60 loss 535.092041015625
Epoch 61 loss 577.8529052734375
Epoch 62 loss 491.1355285644531
Epoch 63 loss 565.1752319335938
Epoch 64 loss 486.0010070800781
Epoch 65 loss 575.6502075195312
Epoch 66 loss 476.5616760253906
Epoch 67 loss 531.8942260742188
Epoch 68 loss 597.7283935546875
Epoch 69 loss 522.5722045898438
Epoch 70 loss 567.2366333007812
Epoch 71 loss 493.05816650390625
Epoch 72 loss 582.5870971679688
Epoch 73 loss 547.1318359375
Epoch 74 loss 523.1510009765625
Epoch 75 loss 581.0493774414062
Epoch 76 loss 465.29913330078125
Epoch 77 loss 614.8855590820312
Epoch 78 loss 521.6261596679688
Epoch 79 loss 481.9612731933594
Epoch 80 loss 542.930908203125
Epoch 81 loss 498.09295654296875
Epoch 82 loss 476.8690185546875
Epoch 83 loss 601.6060791015625
Epoch 84 loss 470.70953369140625
Epoch 85 loss 482.7479248046875
Epoch 86 loss 500.0937805175781
Epoch 87 loss 499.88763427734375
Epoch 88 loss 540.2247924804688
Epoch 89 loss 584.29833984375
Epoch 90 loss 516.7738037109375
Epoch 91 loss 499.00531005859375
Epoch 92 loss 490.6310729980469
Epoch 93 loss 539.797119140625
Epoch 94 loss 556.1130981445312
Epoch 95 loss 555.7286376953125
Epoch 96 loss 642.9630126953125
Epoch 97 loss 495.0298156738281
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 498.710044416269, 'MSE - std': 74.12453697684761, 'R2 - mean': 0.9412946714655787, 'R2 - std': 0.008333957181971182} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 518644.78125
Epoch 1 loss 516405.71875
Epoch 2 loss 512991.71875
Epoch 3 loss 508298.34375
Epoch 4 loss 500985.46875
Epoch 5 loss 485478.75
Epoch 6 loss 456247.0
Epoch 7 loss 407893.96875
Epoch 8 loss 336283.5
Epoch 9 loss 243247.25
Epoch 10 loss 141332.703125
Epoch 11 loss 56774.28125
Epoch 12 loss 15031.16015625
Epoch 13 loss 8307.58984375
Epoch 14 loss 8279.7626953125
Epoch 15 loss 8124.84716796875
Epoch 16 loss 5607.55517578125
Epoch 17 loss 3225.899169921875
Epoch 18 loss 2546.6298828125
Epoch 19 loss 1905.2208251953125
Epoch 20 loss 1485.964111328125
Epoch 21 loss 1269.53125
Epoch 22 loss 1144.7547607421875
Epoch 23 loss 960.3992309570312
Epoch 24 loss 946.4982299804688
Epoch 25 loss 1022.8353881835938
Epoch 26 loss 999.3160400390625
Epoch 27 loss 768.8893432617188
Epoch 28 loss 763.0505981445312
Epoch 29 loss 788.8558349609375
Epoch 30 loss 669.708251953125
Epoch 31 loss 751.2410888671875
Epoch 32 loss 716.7890625
Epoch 33 loss 631.8515014648438
Epoch 34 loss 676.3242797851562
Epoch 35 loss 618.3609619140625
Epoch 36 loss 687.2898559570312
Epoch 37 loss 737.0439453125
Epoch 38 loss 641.6495971679688
Epoch 39 loss 635.0370483398438
Epoch 40 loss 604.707275390625
Epoch 41 loss 726.6409912109375
Epoch 42 loss 582.1619873046875
Epoch 43 loss 645.838134765625
Epoch 44 loss 595.3451538085938
Epoch 45 loss 617.1463012695312
Epoch 46 loss 627.0906982421875
Epoch 47 loss 569.1531982421875
Epoch 48 loss 614.2227783203125
Epoch 49 loss 537.7282104492188
Epoch 50 loss 619.7991943359375
Epoch 51 loss 696.7515258789062
Epoch 52 loss 521.0313110351562
Epoch 53 loss 530.559326171875
Epoch 54 loss 538.881591796875
Epoch 55 loss 560.58837890625
Epoch 56 loss 523.2379150390625
Epoch 57 loss 605.4517211914062
Epoch 58 loss 589.2574462890625
Epoch 59 loss 557.3308715820312
Epoch 60 loss 524.7105712890625
Epoch 61 loss 558.145751953125
Epoch 62 loss 543.9281005859375
Epoch 63 loss 508.9237060546875
Epoch 64 loss 647.9725341796875
Epoch 65 loss 541.3515014648438
Epoch 66 loss 523.8109130859375
Epoch 67 loss 607.4328002929688
Epoch 68 loss 744.7933349609375
Epoch 69 loss 506.874267578125
Epoch 70 loss 491.492431640625
Epoch 71 loss 482.81158447265625
Epoch 72 loss 500.0832214355469
Epoch 73 loss 548.3953247070312
Epoch 74 loss 491.81280517578125
Epoch 75 loss 535.5485229492188
Epoch 76 loss 552.2957763671875
Epoch 77 loss 516.6326293945312
Epoch 78 loss 498.8027038574219
Epoch 79 loss 511.30670166015625
Epoch 80 loss 511.0816650390625
Epoch 81 loss 496.0744323730469
Epoch 82 loss 502.963134765625
Epoch 83 loss 511.3688049316406
Epoch 84 loss 481.2568359375
Epoch 85 loss 493.58294677734375
Epoch 86 loss 491.7347106933594
Epoch 87 loss 523.3543701171875
Epoch 88 loss 480.6893310546875
Epoch 89 loss 700.399658203125
Epoch 90 loss 580.4451293945312
Epoch 91 loss 523.1358642578125
Epoch 92 loss 485.293212890625
Epoch 93 loss 501.6807556152344
Epoch 94 loss 551.759765625
Epoch 95 loss 595.4763793945312
Epoch 96 loss 526.9946899414062
Epoch 97 loss 538.2423706054688
Epoch 98 loss 486.1530456542969
Epoch 99 loss 509.7683410644531
Saved Losses
{'MSE - mean': 494.2048327850686, 'MSE - std': 64.66626656959363, 'R2 - mean': 0.9415020271893925, 'R2 - std': 0.007226349072788542} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513774.375
Epoch 1 loss 510168.625
Epoch 2 loss 505184.75
Epoch 3 loss 499218.9375
Epoch 4 loss 490679.65625
Epoch 5 loss 472935.1875
Epoch 6 loss 439849.25
Epoch 7 loss 386170.59375
Epoch 8 loss 309449.6875
Epoch 9 loss 213751.140625
Epoch 10 loss 114478.9375
Epoch 11 loss 40227.796875
Epoch 12 loss 10503.1396484375
Epoch 13 loss 8130.298828125
Epoch 14 loss 8132.2568359375
Epoch 15 loss 7900.7861328125
Epoch 16 loss 6369.86767578125
Epoch 17 loss 3009.19287109375
Epoch 18 loss 2016.913330078125
Epoch 19 loss 1553.1905517578125
Epoch 20 loss 1248.439697265625
Epoch 21 loss 1067.1221923828125
Epoch 22 loss 916.1695556640625
Epoch 23 loss 854.3126220703125
Epoch 24 loss 748.794921875
Epoch 25 loss 812.4027099609375
Epoch 26 loss 659.3690185546875
Epoch 27 loss 626.1378173828125
Epoch 28 loss 750.4768676757812
Epoch 29 loss 621.3895263671875
Epoch 30 loss 637.6983032226562
Epoch 31 loss 659.5078735351562
Epoch 32 loss 565.7694702148438
Epoch 33 loss 527.2999267578125
Epoch 34 loss 570.9439086914062
Epoch 35 loss 542.5493774414062
Epoch 36 loss 535.48681640625
Epoch 37 loss 493.87469482421875
Epoch 38 loss 523.7201538085938
Epoch 39 loss 568.9718017578125
Epoch 40 loss 490.3387451171875
Epoch 41 loss 488.69287109375
Epoch 42 loss 570.6072998046875
Epoch 43 loss 482.898193359375
Epoch 44 loss 557.6787109375
Epoch 45 loss 749.7125854492188
Epoch 46 loss 529.2322998046875
Epoch 47 loss 508.33306884765625
Epoch 48 loss 478.8843688964844
Epoch 49 loss 554.9762573242188
Epoch 50 loss 507.9004821777344
Epoch 51 loss 485.2321472167969
Epoch 52 loss 480.67230224609375
Epoch 53 loss 490.5751953125
Epoch 54 loss 573.506103515625
Epoch 55 loss 462.8199157714844
Epoch 56 loss 500.0514221191406
Epoch 57 loss 456.8780212402344
Epoch 58 loss 484.59002685546875
Epoch 59 loss 464.7154235839844
Epoch 60 loss 466.0510559082031
Epoch 61 loss 457.5524597167969
Epoch 62 loss 485.7239990234375
Epoch 63 loss 506.45220947265625
Epoch 64 loss 459.1158752441406
Epoch 65 loss 586.1879272460938
Epoch 66 loss 490.5791320800781
Epoch 67 loss 464.4057922363281
Epoch 68 loss 503.31854248046875
Epoch 69 loss 467.1243591308594
Epoch 70 loss 470.83197021484375
Epoch 71 loss 496.25640869140625
Epoch 72 loss 515.5462036132812
Epoch 73 loss 497.21002197265625
Epoch 74 loss 477.2122497558594
Epoch 75 loss 524.3850708007812
Epoch 76 loss 461.1610107421875
Epoch 77 loss 479.7635192871094
Epoch 78 loss 487.4998474121094
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 486.73943038878895, 'MSE - std': 59.735330897160914, 'R2 - mean': 0.9417482329734735, 'R2 - std': 0.0064821729296504526} 
 

Results After CV: {'MSE - mean': 486.73943038878895, 'MSE - std': 59.735330897160914, 'R2 - mean': 0.9417482329734735, 'R2 - std': 0.0064821729296504526}
Train time: 116.72619428300023
Inference time: 0.14604952900008356
Finished cross validation
Trial 29 finished with value: 486.73943038878895 and parameters: {'dim': 32, 'depth': 6, 'heads': 4, 'dropout': 0.1}. Best is trial 18 with value: 472.816397197097.
Best parameters: {'dim': 128, 'depth': 3, 'heads': 4, 'dropout': 0.2}
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Epoch 0 loss 513198.71875
Epoch 1 loss 509923.25
Epoch 2 loss 505118.84375
Epoch 3 loss 498039.84375
Epoch 4 loss 487714.65625
Epoch 5 loss 467428.0
Epoch 6 loss 429618.15625
Epoch 7 loss 369213.625
Epoch 8 loss 284495.09375
Epoch 9 loss 183125.609375
Epoch 10 loss 86643.4921875
Epoch 11 loss 25629.89453125
Epoch 12 loss 8881.16796875
Epoch 13 loss 8966.93359375
Epoch 14 loss 8390.2275390625
Epoch 15 loss 8070.9306640625
Epoch 16 loss 5960.80078125
Epoch 17 loss 2970.30419921875
Epoch 18 loss 2336.83349609375
Epoch 19 loss 1768.5677490234375
Epoch 20 loss 1910.134765625
Epoch 21 loss 1300.479248046875
Epoch 22 loss 1207.3056640625
Epoch 23 loss 1361.4891357421875
Epoch 24 loss 1068.674072265625
Epoch 25 loss 1050.50439453125
Epoch 26 loss 932.9053955078125
Epoch 27 loss 864.4728393554688
Epoch 28 loss 846.5128173828125
Epoch 29 loss 818.4255981445312
Epoch 30 loss 956.0731811523438
Epoch 31 loss 812.6400756835938
Epoch 32 loss 775.510009765625
Epoch 33 loss 767.819091796875
Epoch 34 loss 744.7166748046875
Epoch 35 loss 731.2239379882812
Epoch 36 loss 733.0444946289062
Epoch 37 loss 702.1083984375
Epoch 38 loss 687.3819580078125
Epoch 39 loss 675.5949096679688
Epoch 40 loss 819.4205322265625
Epoch 41 loss 719.9151000976562
Epoch 42 loss 768.8930053710938
Epoch 43 loss 717.3763427734375
Epoch 44 loss 809.165771484375
Epoch 45 loss 693.123046875
Epoch 46 loss 684.2052001953125
Epoch 47 loss 684.0751953125
Epoch 48 loss 643.7156372070312
Epoch 49 loss 673.827392578125
Epoch 50 loss 644.1712646484375
Epoch 51 loss 636.07666015625
Epoch 52 loss 633.59033203125
Epoch 53 loss 663.58349609375
Epoch 54 loss 619.65576171875
Epoch 55 loss 652.3618774414062
Epoch 56 loss 617.225830078125
Epoch 57 loss 675.3929443359375
Epoch 58 loss 705.5913696289062
Epoch 59 loss 608.01220703125
Epoch 60 loss 610.644287109375
Epoch 61 loss 641.2939453125
Epoch 62 loss 603.7262573242188
Epoch 63 loss 718.170166015625
Epoch 64 loss 620.4794921875
Epoch 65 loss 628.5518188476562
Epoch 66 loss 602.807861328125
Epoch 67 loss 601.281982421875
Epoch 68 loss 611.200927734375
Epoch 69 loss 585.0881958007812
Epoch 70 loss 621.0308837890625
Epoch 71 loss 624.467041015625
Epoch 72 loss 638.083251953125
Epoch 73 loss 590.3602294921875
Epoch 74 loss 617.4807739257812
Epoch 75 loss 601.00732421875
Epoch 76 loss 593.831298828125
Epoch 77 loss 637.9276123046875
Epoch 78 loss 581.6209716796875
Epoch 79 loss 644.2522583007812
Epoch 80 loss 584.1219482421875
Epoch 81 loss 602.5291137695312
Epoch 82 loss 591.0281982421875
Epoch 83 loss 594.322021484375
Epoch 84 loss 896.3231201171875
Epoch 85 loss 619.624755859375
Epoch 86 loss 608.7440185546875
Epoch 87 loss 666.8585815429688
Epoch 88 loss 591.0054321289062
Epoch 89 loss 602.1806640625
Epoch 90 loss 578.0020141601562
Epoch 91 loss 655.3546142578125
Epoch 92 loss 589.7488403320312
Epoch 93 loss 627.385009765625
Epoch 94 loss 637.1070556640625
Epoch 95 loss 590.7086181640625
Epoch 96 loss 589.9017333984375
Epoch 97 loss 652.6953735351562
Epoch 98 loss 621.9588623046875
Epoch 99 loss 604.292236328125
Saved Losses
{'MSE - mean': 578.0017988090724, 'MSE - std': 0.0, 'R2 - mean': 0.9327951780644602, 'R2 - std': 0.0} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 522208.375
Epoch 1 loss 519450.125
Epoch 2 loss 515350.15625
Epoch 3 loss 509694.8125
Epoch 4 loss 501204.25
Epoch 5 loss 483568.34375
Epoch 6 loss 450248.03125
Epoch 7 loss 395717.53125
Epoch 8 loss 317404.59375
Epoch 9 loss 218958.90625
Epoch 10 loss 117541.8828125
Epoch 11 loss 41313.45703125
Epoch 12 loss 10603.447265625
Epoch 13 loss 7665.341796875
Epoch 14 loss 7552.8798828125
Epoch 15 loss 7424.3779296875
Epoch 16 loss 6863.81591796875
Epoch 17 loss 4260.57275390625
Epoch 18 loss 2524.489501953125
Epoch 19 loss 1830.2994384765625
Epoch 20 loss 1489.3712158203125
Epoch 21 loss 1263.1895751953125
Epoch 22 loss 1188.214599609375
Epoch 23 loss 1010.5027465820312
Epoch 24 loss 884.5093383789062
Epoch 25 loss 884.7255859375
Epoch 26 loss 760.7928466796875
Epoch 27 loss 695.0948486328125
Epoch 28 loss 675.7734375
Epoch 29 loss 626.9080810546875
Epoch 30 loss 883.7532958984375
Epoch 31 loss 825.5682373046875
Epoch 32 loss 576.6867065429688
Epoch 33 loss 565.1876831054688
Epoch 34 loss 571.4774780273438
Epoch 35 loss 612.9364624023438
Epoch 36 loss 636.6026000976562
Epoch 37 loss 620.7490234375
Epoch 38 loss 583.5826416015625
Epoch 39 loss 589.4365844726562
Epoch 40 loss 549.8796997070312
Epoch 41 loss 512.041015625
Epoch 42 loss 619.0300903320312
Epoch 43 loss 497.3288879394531
Epoch 44 loss 551.4351196289062
Epoch 45 loss 514.52001953125
Epoch 46 loss 566.0278930664062
Epoch 47 loss 528.6923828125
Epoch 48 loss 595.7559814453125
Epoch 49 loss 562.2092895507812
Epoch 50 loss 494.8227233886719
Epoch 51 loss 694.2477416992188
Epoch 52 loss 482.8290100097656
Epoch 53 loss 542.7658081054688
Epoch 54 loss 536.7614135742188
Epoch 55 loss 486.00274658203125
Epoch 56 loss 483.0661926269531
Epoch 57 loss 524.781005859375
Epoch 58 loss 480.7593994140625
Epoch 59 loss 479.3084411621094
Epoch 60 loss 500.7680358886719
Epoch 61 loss 545.8768920898438
Epoch 62 loss 531.72998046875
Epoch 63 loss 525.4254150390625
Epoch 64 loss 483.0658264160156
Epoch 65 loss 565.3455810546875
Epoch 66 loss 639.7655639648438
Epoch 67 loss 519.8989868164062
Epoch 68 loss 480.6341247558594
Epoch 69 loss 459.2464599609375
Epoch 70 loss 501.9237365722656
Epoch 71 loss 467.9590148925781
Epoch 72 loss 482.0246276855469
Epoch 73 loss 464.9579162597656
Epoch 74 loss 465.35125732421875
Epoch 75 loss 466.1205139160156
Epoch 76 loss 488.78424072265625
Epoch 77 loss 466.3311767578125
Epoch 78 loss 483.45733642578125
Epoch 79 loss 471.52178955078125
Epoch 80 loss 465.4421081542969
Epoch 81 loss 464.34320068359375
Epoch 82 loss 455.859375
Epoch 83 loss 467.1000061035156
Epoch 84 loss 591.7578735351562
Epoch 85 loss 555.875244140625
Epoch 86 loss 638.0527954101562
Epoch 87 loss 603.5808715820312
Epoch 88 loss 490.5953063964844
Epoch 89 loss 495.1866455078125
Epoch 90 loss 468.95941162109375
Epoch 91 loss 523.2079467773438
Epoch 92 loss 455.654296875
Epoch 93 loss 497.3283386230469
Epoch 94 loss 466.5045166015625
Epoch 95 loss 465.8488464355469
Epoch 96 loss 521.6022338867188
Epoch 97 loss 503.0483703613281
Epoch 98 loss 506.0373229980469
Epoch 99 loss 494.3935241699219
Saved Losses
{'MSE - mean': 516.828099470348, 'MSE - std': 61.17369933872436, 'R2 - mean': 0.9365791303655449, 'R2 - std': 0.003783952301084581} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 515745.40625
Epoch 1 loss 512780.8125
Epoch 2 loss 508474.3125
Epoch 3 loss 502547.625
Epoch 4 loss 493942.15625
Epoch 5 loss 475769.15625
Epoch 6 loss 441030.6875
Epoch 7 loss 384583.34375
Epoch 8 loss 303839.65625
Epoch 9 loss 203558.734375
Epoch 10 loss 103189.78125
Epoch 11 loss 33414.2109375
Epoch 12 loss 10301.884765625
Epoch 13 loss 9605.744140625
Epoch 14 loss 9213.3203125
Epoch 15 loss 8886.201171875
Epoch 16 loss 6646.5576171875
Epoch 17 loss 3739.325439453125
Epoch 18 loss 2657.803955078125
Epoch 19 loss 2040.26318359375
Epoch 20 loss 1740.187744140625
Epoch 21 loss 1490.471435546875
Epoch 22 loss 1398.000244140625
Epoch 23 loss 1177.935791015625
Epoch 24 loss 1120.6656494140625
Epoch 25 loss 1079.0167236328125
Epoch 26 loss 1000.6097412109375
Epoch 27 loss 1056.4827880859375
Epoch 28 loss 973.3300170898438
Epoch 29 loss 792.0313720703125
Epoch 30 loss 764.3244018554688
Epoch 31 loss 750.2997436523438
Epoch 32 loss 733.3674926757812
Epoch 33 loss 689.2843627929688
Epoch 34 loss 750.2150268554688
Epoch 35 loss 646.3027954101562
Epoch 36 loss 699.8335571289062
Epoch 37 loss 732.4215698242188
Epoch 38 loss 606.3364868164062
Epoch 39 loss 603.4703979492188
Epoch 40 loss 585.7789306640625
Epoch 41 loss 569.6388549804688
Epoch 42 loss 554.8070068359375
Epoch 43 loss 633.0941772460938
Epoch 44 loss 615.4196166992188
Epoch 45 loss 576.9906005859375
Epoch 46 loss 555.2953491210938
Epoch 47 loss 522.6737670898438
Epoch 48 loss 533.6414794921875
Epoch 49 loss 683.1103515625
Epoch 50 loss 498.5932922363281
Epoch 51 loss 543.3190307617188
Epoch 52 loss 602.3424682617188
Epoch 53 loss 717.7692260742188
Epoch 54 loss 983.1480102539062
Epoch 55 loss 630.14453125
Epoch 56 loss 531.256591796875
Epoch 57 loss 649.7146606445312
Epoch 58 loss 510.66326904296875
Epoch 59 loss 501.3908996582031
Epoch 60 loss 859.626220703125
Epoch 61 loss 499.6916809082031
Epoch 62 loss 507.1515197753906
Epoch 63 loss 563.9306030273438
Epoch 64 loss 587.8993530273438
Epoch 65 loss 514.80224609375
Epoch 66 loss 497.29742431640625
Epoch 67 loss 630.07177734375
Epoch 68 loss 648.618896484375
Epoch 69 loss 537.263427734375
Epoch 70 loss 510.7373352050781
Epoch 71 loss 543.5526733398438
Epoch 72 loss 497.4575500488281
Epoch 73 loss 465.311279296875
Epoch 74 loss 473.1309509277344
Epoch 75 loss 482.53558349609375
Epoch 76 loss 800.0750732421875
Epoch 77 loss 477.83721923828125
Epoch 78 loss 499.6211853027344
Epoch 79 loss 537.1385498046875
Epoch 80 loss 697.1737670898438
Epoch 81 loss 480.18359375
Epoch 82 loss 477.3683776855469
Epoch 83 loss 571.6188354492188
Epoch 84 loss 474.5031433105469
Epoch 85 loss 650.016845703125
Epoch 86 loss 494.4167175292969
Epoch 87 loss 509.07513427734375
Epoch 88 loss 563.0625
Epoch 89 loss 488.9369812011719
Epoch 90 loss 587.6688232421875
Epoch 91 loss 462.1184387207031
Epoch 92 loss 471.2786865234375
Epoch 93 loss 460.20172119140625
Epoch 94 loss 489.08013916015625
Epoch 95 loss 523.2413330078125
Epoch 96 loss 504.34051513671875
Epoch 97 loss 489.2818908691406
Epoch 98 loss 506.5225830078125
Epoch 99 loss 478.8194580078125
Saved Losses
{'MSE - mean': 497.95258125937465, 'MSE - std': 56.633777047406404, 'R2 - mean': 0.9412396859494679, 'R2 - std': 0.007279222947054803} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 517752.625
Epoch 1 loss 514824.25
Epoch 2 loss 510499.75
Epoch 3 loss 504641.96875
Epoch 4 loss 495583.40625
Epoch 5 loss 476509.78125
Epoch 6 loss 441417.8125
Epoch 7 loss 385219.65625
Epoch 8 loss 305225.71875
Epoch 9 loss 206526.921875
Epoch 10 loss 107152.5234375
Epoch 11 loss 35851.70703125
Epoch 12 loss 10146.6083984375
Epoch 13 loss 8460.6748046875
Epoch 14 loss 8224.1396484375
Epoch 15 loss 8122.07421875
Epoch 16 loss 7638.02099609375
Epoch 17 loss 4653.38134765625
Epoch 18 loss 2608.37841796875
Epoch 19 loss 2020.8975830078125
Epoch 20 loss 1614.296142578125
Epoch 21 loss 1453.6763916015625
Epoch 22 loss 1230.3985595703125
Epoch 23 loss 1232.9744873046875
Epoch 24 loss 1099.634033203125
Epoch 25 loss 969.4852905273438
Epoch 26 loss 1122.8157958984375
Epoch 27 loss 845.629150390625
Epoch 28 loss 886.0816650390625
Epoch 29 loss 1126.0404052734375
Epoch 30 loss 998.51904296875
Epoch 31 loss 1062.421630859375
Epoch 32 loss 709.4012451171875
Epoch 33 loss 736.1243286132812
Epoch 34 loss 653.280517578125
Epoch 35 loss 706.46484375
Epoch 36 loss 648.5353393554688
Epoch 37 loss 648.72509765625
Epoch 38 loss 643.5578002929688
Epoch 39 loss 637.5703735351562
Epoch 40 loss 758.7791748046875
Epoch 41 loss 1261.716064453125
Epoch 42 loss 616.831787109375
Epoch 43 loss 595.8869018554688
Epoch 44 loss 650.9796752929688
Epoch 45 loss 572.53173828125
Epoch 46 loss 595.3970336914062
Epoch 47 loss 623.3079223632812
Epoch 48 loss 564.5496215820312
Epoch 49 loss 657.9490356445312
Epoch 50 loss 593.125244140625
Epoch 51 loss 607.2457885742188
Epoch 52 loss 598.43798828125
Epoch 53 loss 553.00634765625
Epoch 54 loss 751.2089233398438
Epoch 55 loss 580.1538696289062
Epoch 56 loss 628.2549438476562
Epoch 57 loss 595.0147705078125
Epoch 58 loss 778.0128173828125
Epoch 59 loss 553.2987060546875
Epoch 60 loss 540.6539306640625
Epoch 61 loss 601.6480712890625
Epoch 62 loss 666.8118286132812
Epoch 63 loss 538.7484741210938
Epoch 64 loss 523.5745239257812
Epoch 65 loss 559.3060913085938
Epoch 66 loss 642.1346435546875
Epoch 67 loss 549.0098876953125
Epoch 68 loss 524.8156127929688
Epoch 69 loss 721.9923706054688
Epoch 70 loss 533.4590454101562
Epoch 71 loss 552.8677978515625
Epoch 72 loss 554.1783447265625
Epoch 73 loss 521.443115234375
Epoch 74 loss 539.2420043945312
Epoch 75 loss 573.2484741210938
Epoch 76 loss 512.1129150390625
Epoch 77 loss 513.0022583007812
Epoch 78 loss 643.693603515625
Epoch 79 loss 584.9473266601562
Epoch 80 loss 510.9374084472656
Epoch 81 loss 540.1687622070312
Epoch 82 loss 576.1693115234375
Epoch 83 loss 516.6063232421875
Epoch 84 loss 546.3646850585938
Epoch 85 loss 513.496826171875
Epoch 86 loss 565.8054809570312
Epoch 87 loss 504.68328857421875
Epoch 88 loss 615.3092651367188
Epoch 89 loss 495.3555603027344
Epoch 90 loss 879.6361083984375
Epoch 91 loss 527.3300170898438
Epoch 92 loss 613.765869140625
Epoch 93 loss 547.6615600585938
Epoch 94 loss 542.7354736328125
Epoch 95 loss 528.3056640625
Epoch 96 loss 610.9561157226562
Epoch 97 loss 540.4076538085938
Epoch 98 loss 526.5050659179688
Epoch 99 loss 510.205078125
Saved Losses
{'MSE - mean': 497.30336196498604, 'MSE - std': 49.05917838761797, 'R2 - mean': 0.9410193191509629, 'R2 - std': 0.006315536367747948} 
 

In get_device
Using dim 8 and batch size 64
Epoch 0 loss 514233.28125
Epoch 1 loss 510594.53125
Epoch 2 loss 505533.75
Epoch 3 loss 498466.25
Epoch 4 loss 488071.125
Epoch 5 loss 467735.875
Epoch 6 loss 430428.03125
Epoch 7 loss 371725.8125
Epoch 8 loss 290252.78125
Epoch 9 loss 191932.765625
Epoch 10 loss 95896.953125
Epoch 11 loss 30229.22265625
Epoch 12 loss 8953.3349609375
Epoch 13 loss 8236.1162109375
Epoch 14 loss 7818.220703125
Epoch 15 loss 7529.486328125
Epoch 16 loss 5815.8359375
Epoch 17 loss 2805.67236328125
Epoch 18 loss 2005.908203125
Epoch 19 loss 1596.6549072265625
Epoch 20 loss 1283.5096435546875
Epoch 21 loss 1104.3251953125
Epoch 22 loss 978.5542602539062
Epoch 23 loss 918.6553344726562
Epoch 24 loss 874.6680297851562
Epoch 25 loss 872.9636840820312
Epoch 26 loss 794.43798828125
Epoch 27 loss 746.4307250976562
Epoch 28 loss 806.6220703125
Epoch 29 loss 737.494384765625
Epoch 30 loss 744.8712768554688
Epoch 31 loss 696.5938720703125
Epoch 32 loss 658.7320556640625
Epoch 33 loss 621.574951171875
Epoch 34 loss 615.8543701171875
Epoch 35 loss 605.0789794921875
Epoch 36 loss 708.29931640625
Epoch 37 loss 568.798095703125
Epoch 38 loss 677.5914916992188
Epoch 39 loss 578.3828735351562
Epoch 40 loss 685.4383544921875
Epoch 41 loss 594.1323852539062
Epoch 42 loss 628.168701171875
Epoch 43 loss 570.1917724609375
Epoch 44 loss 532.71044921875
Epoch 45 loss 536.150634765625
Epoch 46 loss 544.0042114257812
Epoch 47 loss 512.8945922851562
Epoch 48 loss 553.8233032226562
Epoch 49 loss 707.7770385742188
Epoch 50 loss 502.8025817871094
Epoch 51 loss 558.5695190429688
Epoch 52 loss 540.532470703125
Epoch 53 loss 528.6451416015625
Epoch 54 loss 603.364013671875
Epoch 55 loss 486.1205139160156
Epoch 56 loss 484.6075744628906
Epoch 57 loss 467.9120788574219
Epoch 58 loss 516.4019775390625
Epoch 59 loss 481.7440185546875
Epoch 60 loss 541.2368774414062
Epoch 61 loss 471.1950378417969
Epoch 62 loss 525.0130615234375
Epoch 63 loss 497.868896484375
Epoch 64 loss 564.5130615234375
Epoch 65 loss 477.3340148925781
Epoch 66 loss 457.50482177734375
Epoch 67 loss 455.6608581542969
Epoch 68 loss 452.3706970214844
Epoch 69 loss 447.53582763671875
Epoch 70 loss 512.2568969726562
Epoch 71 loss 483.32489013671875
Epoch 72 loss 474.7014465332031
Epoch 73 loss 467.0691833496094
Epoch 74 loss 471.5245666503906
Epoch 75 loss 502.1557922363281
Epoch 76 loss 447.3248291015625
Epoch 77 loss 516.9849243164062
Epoch 78 loss 443.9150695800781
Epoch 79 loss 499.07855224609375
Epoch 80 loss 439.3478088378906
Epoch 81 loss 478.2784423828125
Epoch 82 loss 464.61480712890625
Epoch 83 loss 464.1608581542969
Epoch 84 loss 440.6186828613281
Epoch 85 loss 474.3687438964844
Epoch 86 loss 452.63824462890625
Epoch 87 loss 590.2081909179688
Epoch 88 loss 444.76617431640625
Epoch 89 loss 443.0050048828125
Epoch 90 loss 439.4057312011719
Epoch 91 loss 640.142822265625
Epoch 92 loss 443.83209228515625
Epoch 93 loss 460.21905517578125
Epoch 94 loss 452.1639099121094
Epoch 95 loss 461.5609436035156
Epoch 96 loss 436.08172607421875
Epoch 97 loss 449.8343200683594
Epoch 98 loss 442.7725830078125
Epoch 99 loss 506.3558654785156
Saved Losses
{'MSE - mean': 485.05908379166584, 'MSE - std': 50.25068934051634, 'R2 - mean': 0.9418833939979023, 'R2 - std': 0.005907224479764658} 
 

Results After CV: {'MSE - mean': 485.05908379166584, 'MSE - std': 50.25068934051634, 'R2 - mean': 0.9418833939979023, 'R2 - std': 0.005907224479764658}
Train time: 101.92974360820044
Inference time: 0.13658249759973842
Finished cross validation


----------------------------------------------------------------------------
Training SAINT Vesion 1 with Dataset: config/black_friday.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/black_friday.yml', data_parallel=False, dataset='Black_Friday', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='SAINT', n_trials=30, nominal_idx=[0, 2, 3, 5, 6, 7, 8], num_classes=1, num_features=9, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[1], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Black_Friday...
Dataset loaded!
(166821, 9)
Scaling the data...
args.num_features: 71
args.cat_idx: [0]
New Shape: (166821, 71)
A new study created in RDB with name: SAINT_Black_Friday
In get_device
Using dim 8 and batch size 64
In get_device
Using dim 8 and batch size 64
Trial 0 failed with parameters: {'dim': 32, 'depth': 12, 'heads': 2, 'dropout': 0.7} because of the following error: RuntimeError('The size of tensor a (2) must match the size of tensor b (8) at non-singleton dimension 1').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint.py", line 113, in fit
    _, x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, self.model)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/saint_lib/augmentations.py", line 7, in embed_data_mask
    x_categ = x_categ + model.categories_offset.type_as(x_categ)
RuntimeError: The size of tensor a (2) must match the size of tensor b (8) at non-singleton dimension 1
Trial 0 failed with value None.
