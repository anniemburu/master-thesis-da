

----------------------------------------------------------------------------
Training LightGBM Vesion 1 with Dataset: config/brazillian_houses.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/brazillian_houses.yml', data_parallel=False, dataset='Brazillian_Houses', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=500, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='LightGBM', n_trials=100, nominal_idx=[0, 6], num_classes=1, num_features=12, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[7], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Brazillian_Houses...
Dataset loaded! 

X b4 encoding : ['Sao Paulo' 70 2 1 1 7 'acept' 'furnished' 2065 3300 211 42] 

(10692, 12)
Data Type of X: <class 'numpy.ndarray'>
Nominal Idx: [0, 6]
Ordinal Idx: [7]
Cat Dims: None 
 

Normonal Idx: [0, 6]
Cat Idx Part II: [0, 6, 7] 
ENDE 
 

No one Hot for this Baby!!! 

X after Nominal Encoding: [4 70 2 1 1 7 0 0 2065 3300 211 42] 
 

Scaling the data...
X after Scaling: [4 -0.1475216487529234 -0.43209900207114194 -0.8789596333110133
 -0.3832447761145863 0.31835221569081024 0 0 0.057144851637632804
 -0.1749353429179716 -0.05010297344484243 -0.23658935594737002] 
 

Using an existing study with name 'LightGBM_Brazillian_Houses' instead of creating a new one.
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[8]	train's l2: 2.96946e+08	eval's l2: 1.09333e+07
Saved Losses
{'MSE - mean': 10933308.638958525, 'MSE - std': 0.0, 'R2 - mean': 0.4669476823845603, 'R2 - std': 0.0} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 1.32608e+08	eval's l2: 4.7233e+08
[200]	train's l2: 1.16025e+08	eval's l2: 4.1146e+08
[300]	train's l2: 1.02094e+08	eval's l2: 3.60103e+08
[400]	train's l2: 9.12105e+07	eval's l2: 3.19022e+08
[500]	train's l2: 8.16978e+07	eval's l2: 2.83922e+08
Did not meet early stopping. Best iteration is:
[500]	train's l2: 8.16978e+07	eval's l2: 2.83922e+08
Saved Losses
{'MSE - mean': 147427875.4943363, 'MSE - std': 136494566.8553778, 'R2 - mean': 0.5061011993262979, 'R2 - std': 0.03915351694173763} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[9]	train's l2: 2.93732e+08	eval's l2: 1.24179e+07
Saved Losses
{'MSE - mean': 102424554.1160691, 'MSE - std': 128339818.67491218, 'R2 - mean': 0.5070566898389258, 'R2 - std': 0.03199725795820741} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 1.33113e+08	eval's l2: 4.78287e+08
[200]	train's l2: 1.16375e+08	eval's l2: 4.17995e+08
[300]	train's l2: 1.03163e+08	eval's l2: 3.69418e+08
[400]	train's l2: 9.20606e+07	eval's l2: 3.28575e+08
[500]	train's l2: 8.2892e+07	eval's l2: 2.94944e+08
Did not meet early stopping. Best iteration is:
[500]	train's l2: 8.2892e+07	eval's l2: 2.94944e+08
Saved Losses
{'MSE - mean': 150554527.4725752, 'MSE - std': 138934570.20851925, 'R2 - mean': 0.5118407638047627, 'R2 - std': 0.028922836630677275} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[29]	train's l2: 2.61229e+08	eval's l2: 4.89882e+07
Saved Losses
{'MSE - mean': 130241271.00847773, 'MSE - std': 130739303.16444844, 'R2 - mean': 0.4601676002128453, 'R2 - std': 0.10653491317591675} 
 

Saving model.....
Results After CV: {'MSE - mean': 130241271.00847773, 'MSE - std': 130739303.16444844, 'R2 - mean': 0.4601676002128453, 'R2 - std': 0.10653491317591675}
Train time: 13.676801818600001
Inference time: 0.16495876619999805
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 1 finished with value: 130241271.00847773 and parameters: {'num_leaves': 329, 'lambda_l1': 1.0360586645757879e-05, 'lambda_l2': 0.00028586578734205, 'learning_rate': 0.05267314879885228}. Best is trial 1 with value: 130241271.00847773.
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[9]	train's l2: 2.94919e+08	eval's l2: 1.03355e+07
Saved Losses
{'MSE - mean': 10335540.043734051, 'MSE - std': 0.0, 'R2 - mean': 0.4960918276386985, 'R2 - std': 0.0} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 1.3345e+08	eval's l2: 4.75699e+08
[200]	train's l2: 1.17213e+08	eval's l2: 4.15802e+08
[300]	train's l2: 1.03587e+08	eval's l2: 3.6507e+08
[400]	train's l2: 9.26148e+07	eval's l2: 3.24259e+08
[500]	train's l2: 8.31172e+07	eval's l2: 2.89463e+08
Did not meet early stopping. Best iteration is:
[500]	train's l2: 8.31172e+07	eval's l2: 2.89463e+08
Saved Losses
{'MSE - mean': 149899155.92234287, 'MSE - std': 139563615.8786088, 'R2 - mean': 0.5162364288010242, 'R2 - std': 0.020144601162325637} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[9]	train's l2: 2.94588e+08	eval's l2: 1.17895e+07
Saved Losses
{'MSE - mean': 103862594.30934031, 'MSE - std': 131240486.36645429, 'R2 - mean': 0.5220968265890874, 'R2 - std': 0.018418066179563677} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 1.34334e+08	eval's l2: 4.82606e+08
[200]	train's l2: 1.176e+08	eval's l2: 4.22989e+08
[300]	train's l2: 1.04088e+08	eval's l2: 3.73966e+08
[400]	train's l2: 9.33794e+07	eval's l2: 3.34589e+08
[500]	train's l2: 8.39734e+07	eval's l2: 3.00357e+08
Did not meet early stopping. Best iteration is:
[500]	train's l2: 8.39734e+07	eval's l2: 3.00357e+08
Saved Losses
{'MSE - mean': 152986252.78126365, 'MSE - std': 141976936.19484857, 'R2 - mean': 0.5209470557883599, 'R2 - std': 0.01607435193184185} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[30]	train's l2: 2.6126e+08	eval's l2: 4.88448e+07
Saved Losses
{'MSE - mean': 132157959.08680889, 'MSE - std': 133645918.76264213, 'R2 - mean': 0.467889869766557, 'R2 - std': 0.10708392870189125} 
 

Saving model.....
Results After CV: {'MSE - mean': 132157959.08680889, 'MSE - std': 133645918.76264213, 'R2 - mean': 0.467889869766557, 'R2 - std': 0.10708392870189125}
Train time: 6.135484845200002
Inference time: 0.1056075078000049
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 2 finished with value: 132157959.08680889 and parameters: {'num_leaves': 137, 'lambda_l1': 0.0004104366058788823, 'lambda_l2': 3.2684720841139208, 'learning_rate': 0.05630722600028315}. Best is trial 1 with value: 130241271.00847773.
Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[2]	train's l2: 2.99783e+08	eval's l2: 1.10449e+07
Saved Losses
{'MSE - mean': 11044882.430674031, 'MSE - std': 0.0, 'R2 - mean': 0.4615079138549162, 'R2 - std': 0.0} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 9.10276e+07	eval's l2: 3.2002e+08
[200]	train's l2: 5.97487e+07	eval's l2: 2.09547e+08
[300]	train's l2: 4.12575e+07	eval's l2: 1.48032e+08
[400]	train's l2: 2.77982e+07	eval's l2: 1.07339e+08
[500]	train's l2: 1.86455e+07	eval's l2: 8.20984e+07
Did not meet early stopping. Best iteration is:
[500]	train's l2: 1.86455e+07	eval's l2: 8.20984e+07
Saved Losses
{'MSE - mean': 46571640.633691244, 'MSE - std': 35526758.20301721, 'R2 - mean': 0.6650073759880162, 'R2 - std': 0.20349946213310005} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[2]	train's l2: 2.99261e+08	eval's l2: 1.27145e+07
Saved Losses
{'MSE - mean': 35285940.02755991, 'MSE - std': 33108424.536456477, 'R2 - mean': 0.609084367226299, 'R2 - std': 0.18401844077039362} 
 

Training until validation scores don't improve for 20 rounds
[100]	train's l2: 9.21746e+07	eval's l2: 3.30504e+08
[200]	train's l2: 6.04361e+07	eval's l2: 2.13656e+08
[300]	train's l2: 4.07618e+07	eval's l2: 1.49034e+08
[400]	train's l2: 2.60228e+07	eval's l2: 1.09052e+08
[500]	train's l2: 1.74876e+07	eval's l2: 8.88226e+07
Did not meet early stopping. Best iteration is:
[500]	train's l2: 1.74876e+07	eval's l2: 8.88226e+07
Saved Losses
{'MSE - mean': 48670094.86709702, 'MSE - std': 36871840.66155077, 'R2 - mean': 0.6711415141647351, 'R2 - std': 0.19222476002349714} 
 

Training until validation scores don't improve for 20 rounds
Early stopping, best iteration is:
[9]	train's l2: 2.60472e+08	eval's l2: 4.9048e+07
Saved Losses
{'MSE - mean': 48745669.870724514, 'MSE - std': 32979523.24308713, 'R2 - mean': 0.5874261731205477, 'R2 - std': 0.23998608292451304} 
 

Saving model.....
Results After CV: {'MSE - mean': 48745669.870724514, 'MSE - std': 32979523.24308713, 'R2 - mean': 0.5874261731205477, 'R2 - std': 0.23998608292451304}
Train time: 14.474949975600001
Inference time: 0.1881016681999995
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 3 finished with value: 48745669.870724514 and parameters: {'num_leaves': 597, 'lambda_l1': 2.7323296764144983e-07, 'lambda_l2': 3.908118260140544e-08, 'learning_rate': 0.17447920689018478}. Best is trial 3 with value: 48745669.870724514.
