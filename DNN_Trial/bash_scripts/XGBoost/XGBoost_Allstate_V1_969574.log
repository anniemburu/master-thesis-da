 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/allstate.yml', data_parallel=False, dataset='Allstate_Claims', direction='minimize', dropna_idx=[0], early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='XGBoost', n_trials=100, nominal_idx=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], num_classes=1, num_features=131, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Allstate_Claims...
Dataset loaded! 

X b4 encoding : ['A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'B' 'A' 'D' 'B' 'B' 'D' 'D' 'B' 'D' 'C' 'B' 'D' 'B' 'A' 'A' 'A'
 'A' 'A' 'D' 'B' 'C' 'E' 'A' 'C' 'T' 'B' 'G' 'A' 'A' 'I' 'E' 'G' 'J' 'G'
 'BU' 'BC' 'C' 'AS' 'S' 'A' 'O' 'LB' 0.7263 0.245921 0.187583 0.789639
 0.310061 0.718367 0.3350599999999999 0.3026 0.67135 0.8351 0.569745
 0.594646 0.822493 0.714843] 

(188318, 130)
Data Type of X: <class 'numpy.ndarray'>
Nominal Idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115]
Ordinal Idx: None
Cat Dims: None 
 

Normonal Idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115]
Cat Idx Part II: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115] 
ENDE 
 

No one Hot for this Baby!!! 

X after Nominal Encoding: [0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 3 1 1 3 3 1 3 2 1 3 1 0 0 0 0 0 3 1 2 4 0 2 15 1 6 0 0 8 4 6 9 6 45
 28 2 19 55 0 14 269 0.7263 0.245921 0.187583 0.789639 0.310061 0.718367
 0.3350599999999999 0.3026 0.67135 0.8351 0.569745 0.594646 0.822493
 0.714843] 
 

Scaling the data...
X after Scaling: [0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 3 1 1 3 3 1 3 2 1 3 1 0 0 0 0 0 3 1 2 4 0 2 15 1 6 0 0 8 4 6 9 6 45
 28 2 19 55 0 14 269 1.238749914994374 -1.2609356061477353
 -1.5404709478398098 1.4095526019295532 -0.8485379649282767
 1.1079077456610602 -0.8400698534898288 -0.9220915124049341
 1.0230320281848326 1.8132181032572763 0.36347602679004504
 0.4846367827213369 1.547892317048025 0.9848936450970709] 
 

Using an existing study with name 'XGBoost_Allstate_Claims' instead of creating a new one.
Feature Types: ['c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q', 'q']
Trial 402 failed with parameters: {'max_depth': 7, 'alpha': 5.391632038382476e-06, 'lambda': 0.0025403719638937587, 'eta': 0.036779441703915394} because of the following error: XGBoostError('[12:56:20] /workspace/src/c_api/../common/common.h:174: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x170a4e) [0x7f8de1a85a4e]\n  [bt] (1) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x170d11) [0x7f8de1a85d11]\n  [bt] (2) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x4db3df) [0x7f8de1df03df]\n  [bt] (3) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x52f130) [0x7f8de1e44130]\n  [bt] (4) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x1d) [0x7f8de199c4dd]\n  [bt] (5) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(+0xa052) [0x7f8dfb858052]\n  [bt] (6) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(+0x8925) [0x7f8dfb856925]\n  [bt] (7) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f8dfb85706e]\n  [bt] (8) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f8dfb8724af]\n\n').
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 134, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tree_models.py", line 51, in fit
    self.model = xgb.train(self.params, train, num_boost_round=self.args.epochs, evals=eval_list,
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/core.py", line 738, in inner_f
    return func(**kwargs)
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/training.py", line 176, in train
    bst = cb_container.before_training(bst)
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/callback.py", line 179, in before_training
    model = c.before_training(model=model)
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/callback.py", line 374, in before_training
    self.starting_round = model.num_boosted_rounds()
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/core.py", line 2755, in num_boosted_rounds
    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))
  File "/home/mburu/.local/lib/python3.8/site-packages/xgboost/core.py", line 296, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: [12:56:20] /workspace/src/c_api/../common/common.h:174: XGBoost version not compiled with GPU support.
Stack trace:
  [bt] (0) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x170a4e) [0x7f8de1a85a4e]
  [bt] (1) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x170d11) [0x7f8de1a85d11]
  [bt] (2) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x4db3df) [0x7f8de1df03df]
  [bt] (3) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x52f130) [0x7f8de1e44130]
  [bt] (4) /home/mburu/.local/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x1d) [0x7f8de199c4dd]
  [bt] (5) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(+0xa052) [0x7f8dfb858052]
  [bt] (6) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(+0x8925) [0x7f8dfb856925]
  [bt] (7) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f8dfb85706e]
  [bt] (8) /home/mburu/miniconda3/envs/TabSurvey/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x31f) [0x7f8dfb8724af]


Trial 402 failed with value None.
