

----------------------------------------------------------------------------
Training TabTransformer Vesion 1 with Dataset: config/boston.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/boston.yml', data_parallel=False, dataset='Boston', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=30, nominal_idx=[3], num_classes=1, num_features=13, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Boston...
Dataset loaded!
(506, 13)
Scaling the data...
args.num_features: 14
args.cat_idx: []
New Shape: (506, 14)
A new study created in RDB with name: TabTransformer_Boston
In get_device
()
On Device: cuda
Using dim 64 and batch size 128
On Device: cuda
In get_device
()
On Device: cuda
Using dim 64 and batch size 128
On Device: cuda
Trial 0 failed with parameters: {'dim': 64, 'depth': 3, 'heads': 2, 'weight_decay': -4, 'learning_rate': -3, 'dropout': 0.5} because of the following error: AttributeError("module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tabtransformer.py", line 59, in fit
    X = np.array(X, dtype=np.float)
  File "/home/mburu/.local/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training TabTransformer Vesion 1 with Dataset: config/socmob.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/socmob.yml', data_parallel=False, dataset='Socmob', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=30, nominal_idx=[0, 1, 2, 3], num_classes=1, num_features=5, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Socmob...
Dataset loaded!
(1156, 5)
Scaling the data...
args.num_features: 39
args.cat_idx: []
New Shape: (1156, 39)
A new study created in RDB with name: TabTransformer_Socmob
In get_device
()
On Device: cuda
Using dim 64 and batch size 128
On Device: cuda
In get_device
()
On Device: cuda
Using dim 64 and batch size 128
On Device: cuda
Trial 0 failed with parameters: {'dim': 64, 'depth': 6, 'heads': 2, 'weight_decay': -3, 'learning_rate': -6, 'dropout': 0.3} because of the following error: AttributeError("module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tabtransformer.py", line 59, in fit
    X = np.array(X, dtype=np.float)
  File "/home/mburu/.local/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training TabTransformer Vesion 1 with Dataset: config/sensory.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/sensory.yml', data_parallel=False, dataset='Sensory', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=30, nominal_idx=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], num_classes=1, num_features=11, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=False, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Sensory...
Dataset loaded!
(576, 11)
args.num_features: 36
args.cat_idx: []
New Shape: (576, 36)
A new study created in RDB with name: TabTransformer_Sensory
In get_device
()
On Device: cuda
Using dim 256 and batch size 128
On Device: cuda
In get_device
()
On Device: cuda
Using dim 256 and batch size 128
On Device: cuda
Trial 0 failed with parameters: {'dim': 256, 'depth': 6, 'heads': 4, 'weight_decay': -1, 'learning_rate': -5, 'dropout': 0.4} because of the following error: AttributeError("module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tabtransformer.py", line 59, in fit
    X = np.array(X, dtype=np.float)
  File "/home/mburu/.local/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training TabTransformer Vesion 1 with Dataset: config/moneyball.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/moneyball.yml', data_parallel=False, dataset='Moneyball', direction='minimize', dropna_idx=[9, 10, 12, 13], early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=30, nominal_idx=[0, 1, 8], num_classes=1, num_features=14, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Moneyball...
Dataset loaded!
(1232, 10)
Scaling the data...
args.num_features: 50
args.cat_idx: []
New Shape: (1232, 50)
A new study created in RDB with name: TabTransformer_Moneyball
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Trial 0 failed with parameters: {'dim': 128, 'depth': 6, 'heads': 4, 'weight_decay': -5, 'learning_rate': -5, 'dropout': 0.4} because of the following error: AttributeError("module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tabtransformer.py", line 59, in fit
    X = np.array(X, dtype=np.float)
  File "/home/mburu/.local/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
Trial 0 failed with value None.


----------------------------------------------------------------------------
Training TabTransformer Vesion 1 with Dataset: config/black_friday.yml 



----------------------------------------------------------------------------
 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/black_friday.yml', data_parallel=False, dataset='Black_Friday', direction='minimize', dropna_idx=None, early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=30, nominal_idx=[0, 2, 3, 5, 6, 7, 8], num_classes=1, num_features=9, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=True, ordinal_idx=[1], scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Black_Friday...
Dataset loaded!
(166821, 9)
Scaling the data...
args.num_features: 71
args.cat_idx: [0]
New Shape: (166821, 71)
A new study created in RDB with name: TabTransformer_Black_Friday
In get_device
[2, 21, 3, 2, 12, 14, 15]
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
[2, 21, 3, 2, 12, 14, 15]
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Trial 0 failed with parameters: {'dim': 256, 'depth': 12, 'heads': 8, 'weight_decay': -6, 'learning_rate': -4, 'dropout': 0.4} because of the following error: AttributeError("module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations").
Traceback (most recent call last):
  File "/home/mburu/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "train.py", line 136, in __call__
    sc, time = cross_validation(model, self.X, self.y, self.args, visual=False)
  File "train.py", line 46, in cross_validation
    loss_history, val_loss_history = curr_model.fit(X_train, y_train, X_test, y_test)  # X_val, y_val)
  File "/home/mburu/Master_Thesis/master-thesis-da/DNN_Trial/models/tabtransformer.py", line 59, in fit
    X = np.array(X, dtype=np.float)
  File "/home/mburu/.local/lib/python3.8/site-packages/numpy/__init__.py", line 305, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
Trial 0 failed with value None.
