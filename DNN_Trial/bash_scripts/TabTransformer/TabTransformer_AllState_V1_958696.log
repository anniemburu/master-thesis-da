 Panda Version: 2.0.3
Namespace(batch_size=128, cat_dims=None, cat_idx=None, config='config/allstate.yml', data_parallel=False, dataset='Allstate_Claims', direction='minimize', dropna_idx=[0], early_stopping_rounds=20, epochs=100, gpu_ids=[0, 1], logging_period=100, miss_cat_idx=None, miss_num_idx=None, model_name='TabTransformer', n_trials=100, nominal_idx=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], num_classes=1, num_features=131, num_idx=None, num_splits=5, objective='regression', one_hot_encode=True, optimize_hyperparameters=True, ordinal_encode=False, ordinal_idx=None, scale=True, seed=221, shuffle=True, target_encode=False, use_gpu=True, val_batch_size=256)
Start hyperparameter optimization
 Panda Version: 2.0.3
Loading dataset Allstate_Claims...
Dataset loaded! 

X b4 encoding : ['A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'B' 'A' 'D' 'B' 'B' 'D' 'D' 'B' 'D' 'C' 'B' 'D' 'B' 'A' 'A' 'A'
 'A' 'A' 'D' 'B' 'C' 'E' 'A' 'C' 'T' 'B' 'G' 'A' 'A' 'I' 'E' 'G' 'J' 'G'
 'BU' 'BC' 'C' 'AS' 'S' 'A' 'O' 'LB' 0.7263 0.245921 0.187583 0.789639
 0.310061 0.718367 0.3350599999999999 0.3026 0.67135 0.8351 0.569745
 0.594646 0.822493 0.714843] 

(188318, 130)
Data Type of X: <class 'numpy.ndarray'>
Nominal Idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115]
Ordinal Idx: None
Cat Dims: None 
 

Normonal Idx: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115]
Cat Idx Part II: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115] 
ENDE 
 

X after Nominal Encoding: ['A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'B' 'A' 'D' 'B' 'B' 'D' 'D' 'B' 'D' 'C' 'B' 'D' 'B' 'A' 'A' 'A'
 'A' 'A' 'D' 'B' 'C' 'E' 'A' 'C' 'T' 'B' 'G' 'A' 'A' 'I' 'E' 'G' 'J' 'G'
 'BU' 'BC' 'C' 'AS' 'S' 'A' 'O' 'LB' 0.7263 0.245921 0.187583 0.789639
 0.310061 0.718367 0.3350599999999999 0.3026 0.67135 0.8351 0.569745
 0.594646 0.822493 0.714843] 
 

Scaling the data...
X after Scaling: ['A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'
 'A' 'A' 'B' 'A' 'D' 'B' 'B' 'D' 'D' 'B' 'D' 'C' 'B' 'D' 'B' 'A' 'A' 'A'
 'A' 'A' 'D' 'B' 'C' 'E' 'A' 'C' 'T' 'B' 'G' 'A' 'A' 'I' 'E' 'G' 'J' 'G'
 'BU' 'BC' 'C' 'AS' 'S' 'A' 'O' 'LB' 1.238749914994374 -1.2609356061477353
 -1.5404709478398098 1.4095526019295532 -0.8485379649282767
 1.1079077456610602 -0.8400698534898288 -0.9220915124049341
 1.0230320281848326 1.8132181032572763 0.36347602679004504
 0.4846367827213369 1.547892317048025 0.9848936450970709] 
 

One Hot Encoding...
X after One Hot Encoding: [1.0 0.0 0.0 ... 0.4846367827213369 1.547892317048025 0.9848936450970709] 
 

args.num_features: 1153
args.cat_idx: None
Cat Dims: []
New Shape: (188318, 1153)
False 
 

Using an existing study with name 'TabTransformer_Allstate_Claims' instead of creating a new one.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8885270.00000
Epoch 1: Val Loss 8272374.00000
Epoch 2: Val Loss 7875109.50000
Epoch 3: Val Loss 7341685.00000
Epoch 4: Val Loss 6666907.50000
Epoch 5: Val Loss 5932476.00000
Epoch 6: Val Loss 5358922.00000
Epoch 7: Val Loss 5014455.50000
Epoch 8: Val Loss 4797433.00000
Epoch 9: Val Loss 4618612.50000
Epoch 10: Val Loss 4490355.00000
Epoch 11: Val Loss 4395938.00000
Epoch 12: Val Loss 4327784.50000
Epoch 13: Val Loss 4286330.50000
Epoch 14: Val Loss 4231119.00000
Epoch 15: Val Loss 4198803.50000
Epoch 16: Val Loss 4156950.25000
Epoch 17: Val Loss 4124975.25000
Epoch 18: Val Loss 4117702.25000
Epoch 19: Val Loss 4088553.50000
Epoch 20: Val Loss 4071318.50000
Epoch 21: Val Loss 4053671.50000
Epoch 22: Val Loss 4042909.00000
Epoch 23: Val Loss 4033706.50000
Epoch 24: Val Loss 4004101.25000
Epoch 25: Val Loss 3993121.75000
Epoch 26: Val Loss 4373337.00000
Epoch 27: Val Loss 3967405.00000
Epoch 28: Val Loss 3967903.75000
Epoch 29: Val Loss 3962939.75000
Epoch 30: Val Loss 3952134.50000
Epoch 31: Val Loss 3949319.50000
Epoch 32: Val Loss 3942179.00000
Epoch 33: Val Loss 3925215.25000
Epoch 34: Val Loss 3915917.00000
Epoch 35: Val Loss 3919587.00000
Epoch 36: Val Loss 3906585.25000
Epoch 37: Val Loss 3903531.00000
Epoch 38: Val Loss 3884571.25000
Epoch 39: Val Loss 3885453.00000
Epoch 40: Val Loss 3896164.50000
Epoch 41: Val Loss 3868733.50000
Epoch 42: Val Loss 3884420.50000
Epoch 43: Val Loss 3903926.25000
Epoch 44: Val Loss 3850865.00000
Epoch 45: Val Loss 3851640.00000
Epoch 46: Val Loss 3858752.50000
Epoch 47: Val Loss 3844091.75000
Epoch 48: Val Loss 3830692.75000
Epoch 49: Val Loss 3831566.00000
Epoch 50: Val Loss 3830620.25000
Epoch 51: Val Loss 3826544.00000
Epoch 52: Val Loss 3826961.75000
Epoch 53: Val Loss 3859092.00000
Epoch 54: Val Loss 3812828.75000
Epoch 55: Val Loss 3811730.75000
Epoch 56: Val Loss 3812444.75000
Epoch 57: Val Loss 3800119.50000
Epoch 58: Val Loss 3792461.00000
Epoch 59: Val Loss 3787886.75000
Epoch 60: Val Loss 3784382.00000
Epoch 61: Val Loss 3790283.00000
Epoch 62: Val Loss 3787588.75000
Epoch 63: Val Loss 3771210.00000
Epoch 64: Val Loss 3771857.75000
Epoch 65: Val Loss 3874143.75000
Epoch 66: Val Loss 3779873.00000
Epoch 67: Val Loss 3765278.25000
Epoch 68: Val Loss 3778361.50000
Epoch 69: Val Loss 3761586.25000
Epoch 70: Val Loss 3749074.75000
Epoch 71: Val Loss 3755946.50000
Epoch 72: Val Loss 3750758.25000
Epoch 73: Val Loss 3748840.75000
Epoch 74: Val Loss 3732430.00000
Epoch 75: Val Loss 3746007.75000
Epoch 76: Val Loss 3727213.00000
Epoch 77: Val Loss 3729755.00000
Epoch 78: Val Loss 3733174.25000
Epoch 79: Val Loss 3736045.50000
Epoch 80: Val Loss 3728661.25000
Epoch 81: Val Loss 3714197.75000
Epoch 82: Val Loss 3717878.50000
Epoch 83: Val Loss 3717420.25000
Epoch 84: Val Loss 3713086.00000
Epoch 85: Val Loss 3718462.00000
Epoch 86: Val Loss 3717956.00000
Epoch 87: Val Loss 3703022.25000
Epoch 88: Val Loss 3699002.50000
Epoch 89: Val Loss 3707145.50000
Epoch 90: Val Loss 3715319.00000
Epoch 91: Val Loss 3699457.50000
Epoch 92: Val Loss 3692648.25000
Epoch 93: Val Loss 3694302.25000
Epoch 94: Val Loss 3710030.25000
Epoch 95: Val Loss 3702819.00000
Epoch 96: Val Loss 3681099.75000
Epoch 97: Val Loss 3681332.75000
Epoch 98: Val Loss 3693385.25000
Epoch 99: Val Loss 3674206.25000
Saved Losses
{'MSE - mean': 3685611.2345796544, 'MSE - std': 0.0, 'R2 - mean': 0.5681731628332453, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8176020.00000
Epoch 1: Val Loss 7730994.50000
Epoch 2: Val Loss 7304755.00000
Epoch 3: Val Loss 6746105.50000
Epoch 4: Val Loss 6048201.00000
Epoch 5: Val Loss 5389176.50000
Epoch 6: Val Loss 4899279.00000
Epoch 7: Val Loss 4582950.50000
Epoch 8: Val Loss 4427939.50000
Epoch 9: Val Loss 4302729.50000
Epoch 10: Val Loss 4225675.00000
Epoch 11: Val Loss 4189285.25000
Epoch 12: Val Loss 4151249.00000
Epoch 13: Val Loss 4088275.50000
Epoch 14: Val Loss 4054827.00000
Epoch 15: Val Loss 4022643.50000
Epoch 16: Val Loss 4011472.00000
Epoch 17: Val Loss 3969768.75000
Epoch 18: Val Loss 3946325.75000
Epoch 19: Val Loss 3942987.00000
Epoch 20: Val Loss 3918148.75000
Epoch 21: Val Loss 3903054.00000
Epoch 22: Val Loss 3923172.50000
Epoch 23: Val Loss 3871144.75000
Epoch 24: Val Loss 3864666.00000
Epoch 25: Val Loss 3870603.25000
Epoch 26: Val Loss 3851902.75000
Epoch 27: Val Loss 3819322.50000
Epoch 28: Val Loss 3831525.75000
Epoch 29: Val Loss 3813139.00000
Epoch 30: Val Loss 3804114.25000
Epoch 31: Val Loss 3792254.00000
Epoch 32: Val Loss 3893716.50000
Epoch 33: Val Loss 3800908.25000
Epoch 34: Val Loss 3770184.25000
Epoch 35: Val Loss 3768328.25000
Epoch 36: Val Loss 3750935.50000
Epoch 37: Val Loss 3757328.00000
Epoch 38: Val Loss 3748504.75000
Epoch 39: Val Loss 3749214.25000
Epoch 40: Val Loss 3742033.50000
Epoch 41: Val Loss 3725745.50000
Epoch 42: Val Loss 3736430.25000
Epoch 43: Val Loss 3726729.50000
Epoch 44: Val Loss 3750529.75000
Epoch 45: Val Loss 3711992.25000
Epoch 46: Val Loss 3738106.00000
Epoch 47: Val Loss 3692075.00000
Epoch 48: Val Loss 3693472.00000
Epoch 49: Val Loss 3709985.75000
Epoch 50: Val Loss 3678063.75000
Epoch 51: Val Loss 3700007.50000
Epoch 52: Val Loss 3684218.50000
Epoch 53: Val Loss 3674211.50000
Epoch 54: Val Loss 3671160.75000
Epoch 55: Val Loss 3672791.75000
Epoch 56: Val Loss 3677091.00000
Epoch 57: Val Loss 3666945.75000
Epoch 58: Val Loss 3652615.75000
Epoch 59: Val Loss 3692960.50000
Epoch 60: Val Loss 3644590.75000
Epoch 61: Val Loss 3658454.50000
Epoch 62: Val Loss 3645585.50000
Epoch 63: Val Loss 3643788.25000
Epoch 64: Val Loss 3639010.75000
Epoch 65: Val Loss 3636161.00000
Epoch 66: Val Loss 3627188.75000
Epoch 67: Val Loss 3626593.25000
Epoch 68: Val Loss 3615835.75000
Epoch 69: Val Loss 3618661.50000
Epoch 70: Val Loss 3636926.25000
Epoch 71: Val Loss 3614253.25000
Epoch 72: Val Loss 3609111.75000
Epoch 73: Val Loss 3635080.75000
Epoch 74: Val Loss 3612257.50000
Epoch 75: Val Loss 3601106.75000
Epoch 76: Val Loss 3616316.50000
Epoch 77: Val Loss 3615736.25000
Epoch 78: Val Loss 3599140.00000
Epoch 79: Val Loss 3608082.00000
Epoch 80: Val Loss 3601922.50000
Epoch 81: Val Loss 3593889.50000
Epoch 82: Val Loss 3590831.00000
Epoch 83: Val Loss 3586574.50000
Epoch 84: Val Loss 3591229.25000
Epoch 85: Val Loss 3585473.50000
Epoch 86: Val Loss 3585047.00000
Epoch 87: Val Loss 3579619.00000
Epoch 88: Val Loss 3579631.00000
Epoch 89: Val Loss 3574776.75000
Epoch 90: Val Loss 3577674.00000
Epoch 91: Val Loss 3575719.75000
Epoch 92: Val Loss 3571269.50000
Epoch 93: Val Loss 3573360.75000
Epoch 94: Val Loss 3570235.25000
Epoch 95: Val Loss 3590474.00000
Epoch 96: Val Loss 3562535.00000
Epoch 97: Val Loss 3571831.25000
Epoch 98: Val Loss 3587893.25000
Epoch 99: Val Loss 3595332.75000
Saved Losses
{'MSE - mean': 3628807.419361253, 'MSE - std': 56803.81521840161, 'R2 - mean': 0.5610567552933026, 'R2 - std': 0.007116407539942637} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9246513.00000
Epoch 1: Val Loss 8716338.00000
Epoch 2: Val Loss 8254372.50000
Epoch 3: Val Loss 7707921.50000
Epoch 4: Val Loss 6991280.50000
Epoch 5: Val Loss 6298279.00000
Epoch 6: Val Loss 5768578.50000
Epoch 7: Val Loss 5403457.00000
Epoch 8: Val Loss 5192510.00000
Epoch 9: Val Loss 5081505.50000
Epoch 10: Val Loss 4958023.00000
Epoch 11: Val Loss 4874399.00000
Epoch 12: Val Loss 4808080.50000
Epoch 13: Val Loss 4758744.50000
Epoch 14: Val Loss 4724314.00000
Epoch 15: Val Loss 4681749.50000
Epoch 16: Val Loss 4644541.50000
Epoch 17: Val Loss 4627374.00000
Epoch 18: Val Loss 4584181.50000
Epoch 19: Val Loss 4571415.00000
Epoch 20: Val Loss 4557388.00000
Epoch 21: Val Loss 4521979.00000
Epoch 22: Val Loss 4531651.50000
Epoch 23: Val Loss 4504654.00000
Epoch 24: Val Loss 4514921.50000
Epoch 25: Val Loss 4478218.50000
Epoch 26: Val Loss 4481340.00000
Epoch 27: Val Loss 4460249.50000
Epoch 28: Val Loss 4447445.00000
Epoch 29: Val Loss 4435507.00000
Epoch 30: Val Loss 4439261.00000
Epoch 31: Val Loss 4419897.50000
Epoch 32: Val Loss 4416167.00000
Epoch 33: Val Loss 4401430.50000
Epoch 34: Val Loss 4391531.50000
Epoch 35: Val Loss 4396781.00000
Epoch 36: Val Loss 4383647.00000
Epoch 37: Val Loss 4376569.00000
Epoch 38: Val Loss 4378136.00000
Epoch 39: Val Loss 4361915.50000
Epoch 40: Val Loss 4362124.50000
Epoch 41: Val Loss 4354414.50000
Epoch 42: Val Loss 4361371.50000
Epoch 43: Val Loss 4343683.00000
Epoch 44: Val Loss 4339806.00000
Epoch 45: Val Loss 4338803.00000
Epoch 46: Val Loss 4325874.00000
Epoch 47: Val Loss 4316917.50000
Epoch 48: Val Loss 4322595.00000
Epoch 49: Val Loss 4306354.50000
Epoch 50: Val Loss 4310165.00000
Epoch 51: Val Loss 4323998.50000
Epoch 52: Val Loss 4292642.00000
Epoch 53: Val Loss 4293365.50000
Epoch 54: Val Loss 4298745.00000
Epoch 55: Val Loss 4282348.50000
Epoch 56: Val Loss 4286588.50000
Epoch 57: Val Loss 4282033.00000
Epoch 58: Val Loss 4275006.50000
Epoch 59: Val Loss 4272307.00000
Epoch 60: Val Loss 4263010.50000
Epoch 61: Val Loss 4275272.50000
Epoch 62: Val Loss 4254554.50000
Epoch 63: Val Loss 4301910.00000
Epoch 64: Val Loss 4270729.00000
Epoch 65: Val Loss 4254079.00000
Epoch 66: Val Loss 4241340.00000
Epoch 67: Val Loss 4286261.50000
Epoch 68: Val Loss 4261166.00000
Epoch 69: Val Loss 4229971.00000
Epoch 70: Val Loss 4230252.00000
Epoch 71: Val Loss 4230830.00000
Epoch 72: Val Loss 4217887.00000
Epoch 73: Val Loss 4238301.00000
Epoch 74: Val Loss 4224436.00000
Epoch 75: Val Loss 4217822.50000
Epoch 76: Val Loss 4211176.00000
Epoch 77: Val Loss 4205402.50000
Epoch 78: Val Loss 4214933.00000
Epoch 79: Val Loss 4209790.00000
Epoch 80: Val Loss 4217029.00000
Epoch 81: Val Loss 4210965.50000
Epoch 82: Val Loss 4193894.25000
Epoch 83: Val Loss 4208399.00000
Epoch 84: Val Loss 4195252.00000
Epoch 85: Val Loss 4184982.25000
Epoch 86: Val Loss 4198805.50000
Epoch 87: Val Loss 4194601.00000
Epoch 88: Val Loss 4209250.50000
Epoch 89: Val Loss 4190849.00000
Epoch 90: Val Loss 4180381.00000
Epoch 91: Val Loss 4185294.75000
Epoch 92: Val Loss 4180706.25000
Epoch 93: Val Loss 4172339.50000
Epoch 94: Val Loss 4165909.25000
Epoch 95: Val Loss 4192391.50000
Epoch 96: Val Loss 4175187.50000
Epoch 97: Val Loss 4175452.25000
Epoch 98: Val Loss 4168817.50000
Epoch 99: Val Loss 4170006.25000
Saved Losses
{'MSE - mean': 3812932.8539306247, 'MSE - std': 264490.95811822725, 'R2 - mean': 0.5514576454569414, 'R2 - std': 0.014766448122373666} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8996574.00000
Epoch 1: Val Loss 8370291.00000
Epoch 2: Val Loss 7945238.00000
Epoch 3: Val Loss 7519005.50000
Epoch 4: Val Loss 6811619.50000
Epoch 5: Val Loss 6071366.00000
Epoch 6: Val Loss 5503302.00000
Epoch 7: Val Loss 5158827.00000
Epoch 8: Val Loss 4906291.50000
Epoch 9: Val Loss 4747045.50000
Epoch 10: Val Loss 4710513.00000
Epoch 11: Val Loss 4559158.50000
Epoch 12: Val Loss 4505395.00000
Epoch 13: Val Loss 4455034.00000
Epoch 14: Val Loss 4438513.00000
Epoch 15: Val Loss 4391217.50000
Epoch 16: Val Loss 4354579.00000
Epoch 17: Val Loss 4332146.50000
Epoch 18: Val Loss 4322181.50000
Epoch 19: Val Loss 4276349.00000
Epoch 20: Val Loss 4260451.00000
Epoch 21: Val Loss 4251140.50000
Epoch 22: Val Loss 4227645.00000
Epoch 23: Val Loss 4223169.00000
Epoch 24: Val Loss 4201343.50000
Epoch 25: Val Loss 4189070.25000
Epoch 26: Val Loss 4184206.75000
Epoch 27: Val Loss 4188018.25000
Epoch 28: Val Loss 4167211.25000
Epoch 29: Val Loss 4164660.75000
Epoch 30: Val Loss 4162668.75000
Epoch 31: Val Loss 4138999.00000
Epoch 32: Val Loss 4127102.75000
Epoch 33: Val Loss 4124385.00000
Epoch 34: Val Loss 4111927.00000
Epoch 35: Val Loss 4116676.75000
Epoch 36: Val Loss 4108091.75000
Epoch 37: Val Loss 4095096.25000
Epoch 38: Val Loss 4244212.50000
Epoch 39: Val Loss 4094890.00000
Epoch 40: Val Loss 4080008.75000
Epoch 41: Val Loss 4082205.50000
Epoch 42: Val Loss 4062015.25000
Epoch 43: Val Loss 4065205.75000
Epoch 44: Val Loss 4067979.75000
Epoch 45: Val Loss 4055461.25000
Epoch 46: Val Loss 4132579.50000
Epoch 47: Val Loss 4038435.00000
Epoch 48: Val Loss 4047565.50000
Epoch 49: Val Loss 4042008.25000
Epoch 50: Val Loss 4024963.00000
Epoch 51: Val Loss 4028833.00000
Epoch 52: Val Loss 4012782.00000
Epoch 53: Val Loss 4014239.75000
Epoch 54: Val Loss 3997394.25000
Epoch 55: Val Loss 3997819.25000
Epoch 56: Val Loss 3997531.00000
Epoch 57: Val Loss 4003173.25000
Epoch 58: Val Loss 3994682.50000
Epoch 59: Val Loss 4013158.50000
Epoch 60: Val Loss 3983053.00000
Epoch 61: Val Loss 3988686.00000
Epoch 62: Val Loss 3974435.00000
Epoch 63: Val Loss 3972452.00000
Epoch 64: Val Loss 3968985.50000
Epoch 65: Val Loss 3972693.25000
Epoch 66: Val Loss 3961898.00000
Epoch 67: Val Loss 3967467.25000
Epoch 68: Val Loss 3946290.75000
Epoch 69: Val Loss 3971818.00000
Epoch 70: Val Loss 3952694.50000
Epoch 71: Val Loss 3968021.25000
Epoch 72: Val Loss 3949768.00000
Epoch 73: Val Loss 3935672.00000
Epoch 74: Val Loss 3937044.00000
Epoch 75: Val Loss 3947884.75000
Epoch 76: Val Loss 3986751.75000
Epoch 77: Val Loss 3924600.00000
Epoch 78: Val Loss 3938285.00000
Epoch 79: Val Loss 3928156.75000
Epoch 80: Val Loss 3916199.00000
Epoch 81: Val Loss 3930664.75000
Epoch 82: Val Loss 3919684.00000
Epoch 83: Val Loss 3915196.25000
Epoch 84: Val Loss 3908544.50000
Epoch 85: Val Loss 3939119.75000
Epoch 86: Val Loss 3930164.50000
Epoch 87: Val Loss 3898033.75000
Epoch 88: Val Loss 3913846.50000
Epoch 89: Val Loss 3900732.75000
Epoch 90: Val Loss 3905114.50000
Epoch 91: Val Loss 3914897.00000
Epoch 92: Val Loss 3903530.00000
Epoch 93: Val Loss 3887034.00000
Epoch 94: Val Loss 3904001.75000
Epoch 95: Val Loss 3890588.75000
Epoch 96: Val Loss 3881899.75000
Epoch 97: Val Loss 3887016.25000
Epoch 98: Val Loss 3906261.25000
Epoch 99: Val Loss 3889692.75000
Saved Losses
{'MSE - mean': 3833505.885480797, 'MSE - std': 231811.02017854218, 'R2 - mean': 0.5501814533230884, 'R2 - std': 0.012977749870474082} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8394861.00000
Epoch 1: Val Loss 7830035.00000
Epoch 2: Val Loss 7446726.00000
Epoch 3: Val Loss 6940793.00000
Epoch 4: Val Loss 6262219.50000
Epoch 5: Val Loss 5528719.50000
Epoch 6: Val Loss 4981508.50000
Epoch 7: Val Loss 4630782.50000
Epoch 8: Val Loss 4408093.50000
Epoch 9: Val Loss 4267356.00000
Epoch 10: Val Loss 4142176.00000
Epoch 11: Val Loss 4057663.25000
Epoch 12: Val Loss 3992054.50000
Epoch 13: Val Loss 3938307.00000
Epoch 14: Val Loss 3928294.50000
Epoch 15: Val Loss 3849247.25000
Epoch 16: Val Loss 3883948.25000
Epoch 17: Val Loss 3808394.50000
Epoch 18: Val Loss 3769208.00000
Epoch 19: Val Loss 3757070.00000
Epoch 20: Val Loss 3729036.25000
Epoch 21: Val Loss 3746097.75000
Epoch 22: Val Loss 3713030.50000
Epoch 23: Val Loss 3694354.75000
Epoch 24: Val Loss 3675044.00000
Epoch 25: Val Loss 3670209.00000
Epoch 26: Val Loss 3655001.50000
Epoch 27: Val Loss 3646173.50000
Epoch 28: Val Loss 3644702.00000
Epoch 29: Val Loss 3630558.00000
Epoch 30: Val Loss 3633470.25000
Epoch 31: Val Loss 3617998.75000
Epoch 32: Val Loss 3622881.50000
Epoch 33: Val Loss 3609349.50000
Epoch 34: Val Loss 3609447.25000
Epoch 35: Val Loss 3601158.75000
Epoch 36: Val Loss 3586885.00000
Epoch 37: Val Loss 3604540.75000
Epoch 38: Val Loss 3638429.50000
Epoch 39: Val Loss 3573378.00000
Epoch 40: Val Loss 3579481.00000
Epoch 41: Val Loss 3569805.75000
Epoch 42: Val Loss 3564529.25000
Epoch 43: Val Loss 3569575.75000
Epoch 44: Val Loss 3561219.75000
Epoch 45: Val Loss 3588929.00000
Epoch 46: Val Loss 3553919.75000
Epoch 47: Val Loss 3551410.25000
Epoch 48: Val Loss 3559076.50000
Epoch 49: Val Loss 3555080.75000
Epoch 50: Val Loss 3535413.75000
Epoch 51: Val Loss 3529133.75000
Epoch 52: Val Loss 3535633.50000
Epoch 53: Val Loss 3527960.50000
Epoch 54: Val Loss 3551144.25000
Epoch 55: Val Loss 3565196.00000
Epoch 56: Val Loss 3557048.00000
Epoch 57: Val Loss 3533350.00000
Epoch 58: Val Loss 3518705.25000
Epoch 59: Val Loss 3518397.50000
Epoch 60: Val Loss 3525039.75000
Epoch 61: Val Loss 3511519.50000
Epoch 62: Val Loss 3525596.25000
Epoch 63: Val Loss 3501754.50000
Epoch 64: Val Loss 3500106.00000
Epoch 65: Val Loss 3512031.00000
Epoch 66: Val Loss 3503984.50000
Epoch 67: Val Loss 3507237.25000
Epoch 68: Val Loss 3494174.50000
Epoch 69: Val Loss 3499979.50000
Epoch 70: Val Loss 3520499.00000
Epoch 71: Val Loss 3532650.25000
Epoch 72: Val Loss 3497353.25000
Epoch 73: Val Loss 3489133.50000
Epoch 74: Val Loss 3489413.00000
Epoch 75: Val Loss 3484380.25000
Epoch 76: Val Loss 3483944.50000
Epoch 77: Val Loss 3488484.00000
Epoch 78: Val Loss 3478116.75000
Epoch 79: Val Loss 3473838.25000
Epoch 80: Val Loss 3551986.25000
Epoch 81: Val Loss 3484563.50000
Epoch 82: Val Loss 3551282.75000
Epoch 83: Val Loss 3479967.75000
Epoch 84: Val Loss 3478695.25000
Epoch 85: Val Loss 3470110.25000
Epoch 86: Val Loss 3464157.75000
Epoch 87: Val Loss 3483884.50000
Epoch 88: Val Loss 3502257.75000
Epoch 89: Val Loss 3461648.00000
Epoch 90: Val Loss 3459608.00000
Epoch 91: Val Loss 3463585.25000
Epoch 92: Val Loss 3481345.75000
Epoch 93: Val Loss 3464367.75000
Epoch 94: Val Loss 3467096.75000
Epoch 95: Val Loss 3466465.25000
Epoch 96: Val Loss 3465002.25000
Epoch 97: Val Loss 3464286.75000
Epoch 98: Val Loss 3467956.75000
Epoch 99: Val Loss 3452811.75000
Saved Losses
{'MSE - mean': 3758325.806649287, 'MSE - std': 256119.6132150396, 'R2 - mean': 0.5547572366080316, 'R2 - std': 0.01478136543231151} 
 

Saving model.....
Results After CV: {'MSE - mean': 3758325.806649287, 'MSE - std': 256119.6132150396, 'R2 - mean': 0.5547572366080316, 'R2 - std': 0.01478136543231151}
Train time: 7602.2581693
Inference time: 6.770799457399517
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 9 finished with value: 3758325.806649287 and parameters: {'dim': 32, 'depth': 2, 'heads': 4, 'weight_decay': -2, 'learning_rate': -5, 'dropout': 0}. Best is trial 1 with value: 3552409.371169546.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4516361.00000
Epoch 1: Val Loss 4096265.50000
Epoch 2: Val Loss 3976824.00000
Epoch 3: Val Loss 3923404.75000
Epoch 4: Val Loss 4253855.00000
Epoch 5: Val Loss 3811537.00000
Epoch 6: Val Loss 3770329.25000
Epoch 7: Val Loss 3733101.50000
Epoch 8: Val Loss 3722799.75000
Epoch 9: Val Loss 3695815.50000
Epoch 10: Val Loss 3671960.75000
Epoch 11: Val Loss 3698318.75000
Epoch 12: Val Loss 3632082.25000
Epoch 13: Val Loss 3619127.75000
Epoch 14: Val Loss 3617831.50000
Epoch 15: Val Loss 3584320.25000
Epoch 16: Val Loss 3585293.75000
Epoch 17: Val Loss 3583111.25000
Epoch 18: Val Loss 3556697.00000
Epoch 19: Val Loss 3544776.25000
Epoch 20: Val Loss 3586303.75000
Epoch 21: Val Loss 3569185.75000
Epoch 22: Val Loss 3519798.00000
Epoch 23: Val Loss 3514575.75000
Epoch 24: Val Loss 3501937.75000
Epoch 25: Val Loss 3495789.25000
Epoch 26: Val Loss 3506278.25000
Epoch 27: Val Loss 3504642.75000
Epoch 28: Val Loss 3508374.00000
Epoch 29: Val Loss 3484027.75000
Epoch 30: Val Loss 3491006.00000
Epoch 31: Val Loss 3489348.50000
Epoch 32: Val Loss 3471503.75000
Epoch 33: Val Loss 3459445.50000
Epoch 34: Val Loss 3479432.75000
Epoch 35: Val Loss 3452248.25000
Epoch 36: Val Loss 3465391.25000
Epoch 37: Val Loss 3478825.50000
Epoch 38: Val Loss 3481787.75000
Epoch 39: Val Loss 3508533.25000
Epoch 40: Val Loss 3443771.00000
Epoch 41: Val Loss 3479516.50000
Epoch 42: Val Loss 3490119.00000
Epoch 43: Val Loss 3468061.75000
Epoch 44: Val Loss 3494455.50000
Epoch 45: Val Loss 3454121.75000
Epoch 46: Val Loss 3484808.25000
Epoch 47: Val Loss 3472425.75000
Epoch 48: Val Loss 3449231.25000
Epoch 49: Val Loss 3493922.75000
Epoch 50: Val Loss 3430039.75000
Epoch 51: Val Loss 3422086.00000
Epoch 52: Val Loss 3422221.25000
Epoch 53: Val Loss 3451423.75000
Epoch 54: Val Loss 3457944.50000
Epoch 55: Val Loss 3459891.75000
Epoch 56: Val Loss 3431752.50000
Epoch 57: Val Loss 3458689.25000
Epoch 58: Val Loss 3431126.50000
Epoch 59: Val Loss 3427517.75000
Epoch 60: Val Loss 3466388.50000
Epoch 61: Val Loss 3431475.00000
Epoch 62: Val Loss 3458153.50000
Epoch 63: Val Loss 3445126.25000
Epoch 64: Val Loss 3428085.25000
Epoch 65: Val Loss 3424547.00000
Epoch 66: Val Loss 3443784.00000
Epoch 67: Val Loss 3476719.75000
Epoch 68: Val Loss 3433677.50000
Epoch 69: Val Loss 3469467.25000
Epoch 70: Val Loss 3477430.25000
Epoch 71: Val Loss 3439297.75000
Epoch 72: Val Loss 3508802.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3433332.9294770965, 'MSE - std': 0.0, 'R2 - mean': 0.597731500825085, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4223368.00000
Epoch 1: Val Loss 3872665.50000
Epoch 2: Val Loss 3778379.25000
Epoch 3: Val Loss 3731454.00000
Epoch 4: Val Loss 3696846.25000
Epoch 5: Val Loss 3745159.50000
Epoch 6: Val Loss 3674747.00000
Epoch 7: Val Loss 3686882.75000
Epoch 8: Val Loss 3603738.50000
Epoch 9: Val Loss 3597071.75000
Epoch 10: Val Loss 3568504.00000
Epoch 11: Val Loss 3647774.25000
Epoch 12: Val Loss 3567621.00000
Epoch 13: Val Loss 3530434.75000
Epoch 14: Val Loss 3526559.75000
Epoch 15: Val Loss 3528347.00000
Epoch 16: Val Loss 3526403.25000
Epoch 17: Val Loss 3493684.75000
Epoch 18: Val Loss 3516315.00000
Epoch 19: Val Loss 3509837.75000
Epoch 20: Val Loss 3484669.75000
Epoch 21: Val Loss 3477059.75000
Epoch 22: Val Loss 3466147.25000
Epoch 23: Val Loss 3448059.00000
Epoch 24: Val Loss 3467503.75000
Epoch 25: Val Loss 3457670.75000
Epoch 26: Val Loss 3484569.25000
Epoch 27: Val Loss 3437835.25000
Epoch 28: Val Loss 3426501.25000
Epoch 29: Val Loss 3414094.25000
Epoch 30: Val Loss 3430215.50000
Epoch 31: Val Loss 3454306.25000
Epoch 32: Val Loss 3429398.50000
Epoch 33: Val Loss 3444504.50000
Epoch 34: Val Loss 3419947.50000
Epoch 35: Val Loss 3437210.75000
Epoch 36: Val Loss 3425578.25000
Epoch 37: Val Loss 3429590.50000
Epoch 38: Val Loss 3413485.50000
Epoch 39: Val Loss 3420396.75000
Epoch 40: Val Loss 3404919.00000
Epoch 41: Val Loss 3414642.75000
Epoch 42: Val Loss 3396683.25000
Epoch 43: Val Loss 3413166.00000
Epoch 44: Val Loss 3393392.00000
Epoch 45: Val Loss 3391572.50000
Epoch 46: Val Loss 3404302.25000
Epoch 47: Val Loss 3444991.50000
Epoch 48: Val Loss 3412420.00000
Epoch 49: Val Loss 3418970.50000
Epoch 50: Val Loss 3395985.00000
Epoch 51: Val Loss 3394697.50000
Epoch 52: Val Loss 3409794.75000
Epoch 53: Val Loss 3485160.50000
Epoch 54: Val Loss 3393430.25000
Epoch 55: Val Loss 3418667.25000
Epoch 56: Val Loss 3379817.75000
Epoch 57: Val Loss 3441777.75000
Epoch 58: Val Loss 3401736.50000
Epoch 59: Val Loss 3455581.50000
Epoch 60: Val Loss 3451431.75000
Epoch 61: Val Loss 3433025.50000
Epoch 62: Val Loss 3392806.25000
Epoch 63: Val Loss 3450362.75000
Epoch 64: Val Loss 3412724.75000
Epoch 65: Val Loss 3416412.25000
Epoch 66: Val Loss 3427076.50000
Epoch 67: Val Loss 3577250.00000
Epoch 68: Val Loss 3404261.50000
Epoch 69: Val Loss 3419079.50000
Epoch 70: Val Loss 3425920.00000
Epoch 71: Val Loss 3448812.00000
Epoch 72: Val Loss 3428313.25000
Epoch 73: Val Loss 3452057.50000
Epoch 74: Val Loss 3438018.50000
Epoch 75: Val Loss 3461534.50000
Epoch 76: Val Loss 3418327.75000
Epoch 77: Val Loss 3442039.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3413178.0387905957, 'MSE - std': 20154.890686500818, 'R2 - mean': 0.5870111593711521, 'R2 - std': 0.010720341453932858} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5017411.50000
Epoch 1: Val Loss 4556665.50000
Epoch 2: Val Loss 4474718.00000
Epoch 3: Val Loss 4384943.00000
Epoch 4: Val Loss 4366631.50000
Epoch 5: Val Loss 4313370.50000
Epoch 6: Val Loss 4285294.00000
Epoch 7: Val Loss 4241067.00000
Epoch 8: Val Loss 4225196.50000
Epoch 9: Val Loss 4204437.50000
Epoch 10: Val Loss 4187320.75000
Epoch 11: Val Loss 4160800.00000
Epoch 12: Val Loss 4146928.50000
Epoch 13: Val Loss 4145301.75000
Epoch 14: Val Loss 4114566.50000
Epoch 15: Val Loss 4112992.00000
Epoch 16: Val Loss 4078197.25000
Epoch 17: Val Loss 4072072.75000
Epoch 18: Val Loss 4121891.50000
Epoch 19: Val Loss 4055683.25000
Epoch 20: Val Loss 4049571.50000
Epoch 21: Val Loss 4046339.25000
Epoch 22: Val Loss 4036441.50000
Epoch 23: Val Loss 4021156.50000
Epoch 24: Val Loss 4016141.00000
Epoch 25: Val Loss 4012064.00000
Epoch 26: Val Loss 4000628.50000
Epoch 27: Val Loss 3999855.75000
Epoch 28: Val Loss 3992010.00000
Epoch 29: Val Loss 3988608.00000
Epoch 30: Val Loss 3970495.75000
Epoch 31: Val Loss 3999927.00000
Epoch 32: Val Loss 3951259.25000
Epoch 33: Val Loss 3947761.75000
Epoch 34: Val Loss 3955075.00000
Epoch 35: Val Loss 3949252.00000
Epoch 36: Val Loss 3944414.25000
Epoch 37: Val Loss 3937057.00000
Epoch 38: Val Loss 3930611.50000
Epoch 39: Val Loss 3921928.00000
Epoch 40: Val Loss 3922591.25000
Epoch 41: Val Loss 3928129.50000
Epoch 42: Val Loss 3917012.50000
Epoch 43: Val Loss 3932697.25000
Epoch 44: Val Loss 3908034.25000
Epoch 45: Val Loss 3887631.75000
Epoch 46: Val Loss 3938399.25000
Epoch 47: Val Loss 3915562.50000
Epoch 48: Val Loss 3892350.00000
Epoch 49: Val Loss 3904478.75000
Epoch 50: Val Loss 3916910.25000
Epoch 51: Val Loss 3866353.50000
Epoch 52: Val Loss 3869098.50000
Epoch 53: Val Loss 3883585.00000
Epoch 54: Val Loss 3859324.75000
Epoch 55: Val Loss 3894365.50000
Epoch 56: Val Loss 3862164.75000
Epoch 57: Val Loss 3870386.25000
Epoch 58: Val Loss 3892156.75000
Epoch 59: Val Loss 3856183.00000
Epoch 60: Val Loss 3845627.75000
Epoch 61: Val Loss 3847232.00000
Epoch 62: Val Loss 3864397.00000
Epoch 63: Val Loss 3858919.00000
Epoch 64: Val Loss 3838394.50000
Epoch 65: Val Loss 3845676.25000
Epoch 66: Val Loss 3840977.00000
Epoch 67: Val Loss 3876052.00000
Epoch 68: Val Loss 3858134.25000
Epoch 69: Val Loss 3846721.00000
Epoch 70: Val Loss 3839695.25000
Epoch 71: Val Loss 3857368.75000
Epoch 72: Val Loss 3853468.75000
Epoch 73: Val Loss 3850773.75000
Epoch 74: Val Loss 3847089.00000
Epoch 75: Val Loss 3847934.00000
Epoch 76: Val Loss 3856124.25000
Epoch 77: Val Loss 3864935.00000
Epoch 78: Val Loss 3855340.25000
Epoch 79: Val Loss 3848891.25000
Epoch 80: Val Loss 3881118.75000
Epoch 81: Val Loss 3864184.00000
Epoch 82: Val Loss 3934948.75000
Epoch 83: Val Loss 3860550.25000
Epoch 84: Val Loss 3887973.25000
Epoch 85: Val Loss 4002979.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3558488.7555935513, 'MSE - std': 206158.24483787685, 'R2 - mean': 0.5811433799140857, 'R2 - std': 0.012061460059744638} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4633657.00000
Epoch 1: Val Loss 4205938.50000
Epoch 2: Val Loss 4160605.50000
Epoch 3: Val Loss 4114084.75000
Epoch 4: Val Loss 4024463.75000
Epoch 5: Val Loss 3995013.25000
Epoch 6: Val Loss 3977785.25000
Epoch 7: Val Loss 3968660.50000
Epoch 8: Val Loss 3909114.50000
Epoch 9: Val Loss 3937055.25000
Epoch 10: Val Loss 3878419.50000
Epoch 11: Val Loss 3856408.75000
Epoch 12: Val Loss 3882883.00000
Epoch 13: Val Loss 3836148.00000
Epoch 14: Val Loss 3846596.50000
Epoch 15: Val Loss 3822276.75000
Epoch 16: Val Loss 3810209.00000
Epoch 17: Val Loss 3789614.00000
Epoch 18: Val Loss 3785432.75000
Epoch 19: Val Loss 3803472.00000
Epoch 20: Val Loss 3798439.00000
Epoch 21: Val Loss 3758714.00000
Epoch 22: Val Loss 3866915.50000
Epoch 23: Val Loss 3760721.00000
Epoch 24: Val Loss 3771049.50000
Epoch 25: Val Loss 3810192.50000
Epoch 26: Val Loss 3743981.50000
Epoch 27: Val Loss 3720447.75000
Epoch 28: Val Loss 3736280.25000
Epoch 29: Val Loss 3727147.00000
Epoch 30: Val Loss 3738823.50000
Epoch 31: Val Loss 3723041.00000
Epoch 32: Val Loss 3710972.75000
Epoch 33: Val Loss 3730516.50000
Epoch 34: Val Loss 3713998.75000
Epoch 35: Val Loss 3711532.75000
Epoch 36: Val Loss 3719363.50000
Epoch 37: Val Loss 3709082.00000
Epoch 38: Val Loss 3781793.75000
Epoch 39: Val Loss 3705952.00000
Epoch 40: Val Loss 3778938.00000
Epoch 41: Val Loss 3731154.25000
Epoch 42: Val Loss 3706091.25000
Epoch 43: Val Loss 3714321.50000
Epoch 44: Val Loss 3721929.25000
Epoch 45: Val Loss 3744127.25000
Epoch 46: Val Loss 3703734.25000
Epoch 47: Val Loss 3729635.00000
Epoch 48: Val Loss 3727180.25000
Epoch 49: Val Loss 3703322.00000
Epoch 50: Val Loss 3741048.75000
Epoch 51: Val Loss 3722915.50000
Epoch 52: Val Loss 3720526.25000
Epoch 53: Val Loss 3692791.00000
Epoch 54: Val Loss 3694554.50000
Epoch 55: Val Loss 3717666.25000
Epoch 56: Val Loss 3710424.25000
Epoch 57: Val Loss 3740742.50000
Epoch 58: Val Loss 3698961.75000
Epoch 59: Val Loss 3743995.75000
Epoch 60: Val Loss 3766764.75000
Epoch 61: Val Loss 3715208.25000
Epoch 62: Val Loss 3720209.50000
Epoch 63: Val Loss 3735874.75000
Epoch 64: Val Loss 3745981.50000
Epoch 65: Val Loss 3799128.75000
Epoch 66: Val Loss 3815745.50000
Epoch 67: Val Loss 3765656.75000
Epoch 68: Val Loss 3765863.00000
Epoch 69: Val Loss 3761817.50000
Epoch 70: Val Loss 3763313.50000
Epoch 71: Val Loss 3769604.00000
Epoch 72: Val Loss 3766514.25000
Epoch 73: Val Loss 3792692.75000
Epoch 74: Val Loss 3795794.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595363.881060287, 'MSE - std': 189618.67278972812, 'R2 - mean': 0.57795546423476, 'R2 - std': 0.011815139999808898} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4158972.75000
Epoch 1: Val Loss 3713657.50000
Epoch 2: Val Loss 3618931.00000
Epoch 3: Val Loss 3596737.75000
Epoch 4: Val Loss 3535832.00000
Epoch 5: Val Loss 3527995.50000
Epoch 6: Val Loss 3514708.75000
Epoch 7: Val Loss 3501513.50000
Epoch 8: Val Loss 3492110.25000
Epoch 9: Val Loss 3468556.25000
Epoch 10: Val Loss 3464531.00000
Epoch 11: Val Loss 3449716.75000
Epoch 12: Val Loss 3444353.50000
Epoch 13: Val Loss 3445585.25000
Epoch 14: Val Loss 3446033.50000
Epoch 15: Val Loss 3418582.50000
Epoch 16: Val Loss 3426673.75000
Epoch 17: Val Loss 3418017.00000
Epoch 18: Val Loss 3424905.50000
Epoch 19: Val Loss 3420759.00000
Epoch 20: Val Loss 3423680.25000
Epoch 21: Val Loss 3415818.25000
Epoch 22: Val Loss 3446835.50000
Epoch 23: Val Loss 3441942.75000
Epoch 24: Val Loss 3410134.75000
Epoch 25: Val Loss 3407125.00000
Epoch 26: Val Loss 3456975.25000
Epoch 27: Val Loss 3395804.50000
Epoch 28: Val Loss 3407021.00000
Epoch 29: Val Loss 3400439.75000
Epoch 30: Val Loss 3424539.75000
Epoch 31: Val Loss 3400156.50000
Epoch 32: Val Loss 3467451.75000
Epoch 33: Val Loss 3455448.75000
Epoch 34: Val Loss 3412622.25000
Epoch 35: Val Loss 3433931.00000
Epoch 36: Val Loss 3463033.75000
Epoch 37: Val Loss 3442379.00000
Epoch 38: Val Loss 3398897.50000
Epoch 39: Val Loss 3427493.00000
Epoch 40: Val Loss 3443166.25000
Epoch 41: Val Loss 3412384.75000
Epoch 42: Val Loss 3400062.50000
Epoch 43: Val Loss 3458030.25000
Epoch 44: Val Loss 3444336.50000
Epoch 45: Val Loss 3438223.25000
Epoch 46: Val Loss 3408857.50000
Epoch 47: Val Loss 3411333.75000
Epoch 48: Val Loss 3447929.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3557416.508405545, 'MSE - std': 185806.90305266372, 'R2 - mean': 0.5782600891960167, 'R2 - std': 0.01058533003926424} 
 

Saving model.....
Results After CV: {'MSE - mean': 3557416.508405545, 'MSE - std': 185806.90305266372, 'R2 - mean': 0.5782600891960167, 'R2 - std': 0.01058533003926424}
Train time: 5490.972324189601
Inference time: 6.639913597598206
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 10 finished with value: 3557416.508405545 and parameters: {'dim': 64, 'depth': 2, 'heads': 2, 'weight_decay': -6, 'learning_rate': -4, 'dropout': 0.1}. Best is trial 1 with value: 3552409.371169546.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3865086.00000
Epoch 1: Val Loss 3815481.50000
Epoch 2: Val Loss 3705468.75000
Epoch 3: Val Loss 3587874.75000
Epoch 4: Val Loss 3663916.25000
Epoch 5: Val Loss 3513891.25000
Epoch 6: Val Loss 3501706.25000
Epoch 7: Val Loss 3616019.50000
Epoch 8: Val Loss 3530101.00000
Epoch 9: Val Loss 3463611.00000
Epoch 10: Val Loss 3568704.25000
Epoch 11: Val Loss 3645791.25000
Epoch 12: Val Loss 3535078.25000
Epoch 13: Val Loss 3793270.50000
Epoch 14: Val Loss 3598894.25000
Epoch 15: Val Loss 3565086.75000
Epoch 16: Val Loss 3706707.00000
Epoch 17: Val Loss 3665483.00000
Epoch 18: Val Loss 3798194.75000
Epoch 19: Val Loss 3874331.00000
Epoch 20: Val Loss 3959729.50000
Epoch 21: Val Loss 3934275.00000
Epoch 22: Val Loss 3965634.75000
Epoch 23: Val Loss 4149262.00000
Epoch 24: Val Loss 4045872.50000
Epoch 25: Val Loss 4497689.00000
Epoch 26: Val Loss 4263960.00000
Epoch 27: Val Loss 4308306.50000
Epoch 28: Val Loss 4361731.00000
Epoch 29: Val Loss 4296818.50000
Epoch 30: Val Loss 4459465.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3454593.4189024903, 'MSE - std': 0.0, 'R2 - mean': 0.5952405029089056, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3716401.00000
Epoch 1: Val Loss 3761767.75000
Epoch 2: Val Loss 3651554.25000
Epoch 3: Val Loss 3605130.50000
Epoch 4: Val Loss 3594560.00000
Epoch 5: Val Loss 3481537.25000
Epoch 6: Val Loss 3439592.25000
Epoch 7: Val Loss 3525938.00000
Epoch 8: Val Loss 3545712.75000
Epoch 9: Val Loss 3467758.25000
Epoch 10: Val Loss 3495801.00000
Epoch 11: Val Loss 3522535.00000
Epoch 12: Val Loss 3480826.25000
Epoch 13: Val Loss 3550593.25000
Epoch 14: Val Loss 3527064.50000
Epoch 15: Val Loss 3530326.75000
Epoch 16: Val Loss 3654437.25000
Epoch 17: Val Loss 3783767.00000
Epoch 18: Val Loss 3774405.25000
Epoch 19: Val Loss 3811362.75000
Epoch 20: Val Loss 3769853.50000
Epoch 21: Val Loss 3866053.25000
Epoch 22: Val Loss 3877017.50000
Epoch 23: Val Loss 4008467.50000
Epoch 24: Val Loss 3975857.75000
Epoch 25: Val Loss 4024597.75000
Epoch 26: Val Loss 3999040.50000
Epoch 27: Val Loss 4118491.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3448523.733798571, 'MSE - std': 6069.68510391959, 'R2 - mean': 0.582679279102852, 'R2 - std': 0.012561223806053623} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4362618.50000
Epoch 1: Val Loss 4261231.50000
Epoch 2: Val Loss 4224476.00000
Epoch 3: Val Loss 4050695.00000
Epoch 4: Val Loss 4040789.75000
Epoch 5: Val Loss 3963835.00000
Epoch 6: Val Loss 3956714.50000
Epoch 7: Val Loss 3908533.75000
Epoch 8: Val Loss 4060522.00000
Epoch 9: Val Loss 3852814.75000
Epoch 10: Val Loss 3878772.50000
Epoch 11: Val Loss 3911480.00000
Epoch 12: Val Loss 3921398.50000
Epoch 13: Val Loss 3903053.00000
Epoch 14: Val Loss 4064865.75000
Epoch 15: Val Loss 3973386.00000
Epoch 16: Val Loss 3971278.00000
Epoch 17: Val Loss 3994101.25000
Epoch 18: Val Loss 4090942.75000
Epoch 19: Val Loss 4159965.50000
Epoch 20: Val Loss 4176489.50000
Epoch 21: Val Loss 4199526.50000
Epoch 22: Val Loss 4265396.50000
Epoch 23: Val Loss 4303576.50000
Epoch 24: Val Loss 4493215.00000
Epoch 25: Val Loss 4500106.00000
Epoch 26: Val Loss 4707121.50000
Epoch 27: Val Loss 4605433.00000
Epoch 28: Val Loss 4708554.50000
Epoch 29: Val Loss 4642575.00000
Epoch 30: Val Loss 4746354.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3586134.6186058572, 'MSE - std': 194674.2714203968, 'R2 - mean': 0.5777988072223254, 'R2 - std': 0.012362344999651189} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4005089.75000
Epoch 1: Val Loss 3942176.50000
Epoch 2: Val Loss 3855744.50000
Epoch 3: Val Loss 3792782.75000
Epoch 4: Val Loss 3776912.00000
Epoch 5: Val Loss 3971115.25000
Epoch 6: Val Loss 3831163.75000
Epoch 7: Val Loss 3784098.75000
Epoch 8: Val Loss 3972106.00000
Epoch 9: Val Loss 3888224.00000
Epoch 10: Val Loss 3895866.50000
Epoch 11: Val Loss 3962361.50000
Epoch 12: Val Loss 4229968.50000
Epoch 13: Val Loss 4010510.75000
Epoch 14: Val Loss 4081631.25000
Epoch 15: Val Loss 4185211.75000
Epoch 16: Val Loss 4230508.00000
Epoch 17: Val Loss 4196210.50000
Epoch 18: Val Loss 4296037.00000
Epoch 19: Val Loss 4222081.50000
Epoch 20: Val Loss 4208789.50000
Epoch 21: Val Loss 4347529.00000
Epoch 22: Val Loss 4552081.50000
Epoch 23: Val Loss 4508136.50000
Epoch 24: Val Loss 4658471.50000
Epoch 25: Val Loss 4579759.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3636958.575788887, 'MSE - std': 190191.4241915868, 'R2 - mean': 0.5730175950861851, 'R2 - std': 0.013535163423103732} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3680652.25000
Epoch 1: Val Loss 3516041.50000
Epoch 2: Val Loss 3483901.75000
Epoch 3: Val Loss 3473195.00000
Epoch 4: Val Loss 3507431.25000
Epoch 5: Val Loss 3427572.75000
Epoch 6: Val Loss 3561749.75000
Epoch 7: Val Loss 3442886.75000
Epoch 8: Val Loss 3467807.75000
Epoch 9: Val Loss 3497841.75000
Epoch 10: Val Loss 3472955.00000
Epoch 11: Val Loss 3486699.25000
Epoch 12: Val Loss 3491584.00000
Epoch 13: Val Loss 3535264.50000
Epoch 14: Val Loss 3561832.50000
Epoch 15: Val Loss 3494768.25000
Epoch 16: Val Loss 3652789.75000
Epoch 17: Val Loss 3593954.25000
Epoch 18: Val Loss 3744715.75000
Epoch 19: Val Loss 3662235.25000
Epoch 20: Val Loss 3821815.00000
Epoch 21: Val Loss 3858062.75000
Epoch 22: Val Loss 3889699.50000
Epoch 23: Val Loss 3870257.00000
Epoch 24: Val Loss 3974406.50000
Epoch 25: Val Loss 4016389.25000
Epoch 26: Val Loss 3998711.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3596006.213412009, 'MSE - std': 188803.08844350965, 'R2 - mean': 0.5736536358734778, 'R2 - std': 0.012172867806909737} 
 

Saving model.....
Results After CV: {'MSE - mean': 3596006.213412009, 'MSE - std': 188803.08844350965, 'R2 - mean': 0.5736536358734778, 'R2 - std': 0.012172867806909737}
Train time: 2176.4815602355984
Inference time: 6.674442610793631
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 11 finished with value: 3596006.213412009 and parameters: {'dim': 256, 'depth': 3, 'heads': 4, 'weight_decay': -4, 'learning_rate': -3, 'dropout': 0.3}. Best is trial 1 with value: 3552409.371169546.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4488288.00000
Epoch 1: Val Loss 4081463.00000
Epoch 2: Val Loss 3956642.25000
Epoch 3: Val Loss 3885996.25000
Epoch 4: Val Loss 3839395.00000
Epoch 5: Val Loss 3799422.25000
Epoch 6: Val Loss 3811300.50000
Epoch 7: Val Loss 3726882.75000
Epoch 8: Val Loss 3702086.25000
Epoch 9: Val Loss 3710006.25000
Epoch 10: Val Loss 3658797.00000
Epoch 11: Val Loss 3632886.25000
Epoch 12: Val Loss 3622220.75000
Epoch 13: Val Loss 3644413.50000
Epoch 14: Val Loss 3592657.75000
Epoch 15: Val Loss 3582052.75000
Epoch 16: Val Loss 3577434.75000
Epoch 17: Val Loss 3573858.75000
Epoch 18: Val Loss 3541492.75000
Epoch 19: Val Loss 3551016.50000
Epoch 20: Val Loss 3524984.00000
Epoch 21: Val Loss 3519316.50000
Epoch 22: Val Loss 3510806.25000
Epoch 23: Val Loss 3508683.50000
Epoch 24: Val Loss 3499674.25000
Epoch 25: Val Loss 3524639.50000
Epoch 26: Val Loss 3507695.50000
Epoch 27: Val Loss 3527123.50000
Epoch 28: Val Loss 3476577.50000
Epoch 29: Val Loss 3484006.25000
Epoch 30: Val Loss 3486085.25000
Epoch 31: Val Loss 3479282.00000
Epoch 32: Val Loss 3455763.25000
Epoch 33: Val Loss 3462921.25000
Epoch 34: Val Loss 3452001.75000
Epoch 35: Val Loss 3444050.00000
Epoch 36: Val Loss 3464558.75000
Epoch 37: Val Loss 3450263.25000
Epoch 38: Val Loss 3438893.75000
Epoch 39: Val Loss 3447918.25000
Epoch 40: Val Loss 3449857.25000
Epoch 41: Val Loss 3437506.00000
Epoch 42: Val Loss 3443087.50000
Epoch 43: Val Loss 3436981.75000
Epoch 44: Val Loss 3429941.50000
Epoch 45: Val Loss 3445476.25000
Epoch 46: Val Loss 3418056.50000
Epoch 47: Val Loss 3432263.50000
Epoch 48: Val Loss 3431703.75000
Epoch 49: Val Loss 3428255.75000
Epoch 50: Val Loss 3414148.00000
Epoch 51: Val Loss 3466931.25000
Epoch 52: Val Loss 3427949.25000
Epoch 53: Val Loss 3437441.50000
Epoch 54: Val Loss 3414865.25000
Epoch 55: Val Loss 3434843.25000
Epoch 56: Val Loss 3445182.50000
Epoch 57: Val Loss 3447590.00000
Epoch 58: Val Loss 3459595.50000
Epoch 59: Val Loss 3423535.00000
Epoch 60: Val Loss 3475244.75000
Epoch 61: Val Loss 3415305.00000
Epoch 62: Val Loss 3433671.00000
Epoch 63: Val Loss 3444648.00000
Epoch 64: Val Loss 3437687.50000
Epoch 65: Val Loss 3468164.75000
Epoch 66: Val Loss 3529289.50000
Epoch 67: Val Loss 3442595.50000
Epoch 68: Val Loss 3460358.50000
Epoch 69: Val Loss 3468092.75000
Epoch 70: Val Loss 3455009.50000
Epoch 71: Val Loss 3465993.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3420795.358347772, 'MSE - std': 0.0, 'R2 - mean': 0.5992004728196711, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4246056.50000
Epoch 1: Val Loss 3915263.75000
Epoch 2: Val Loss 3782532.75000
Epoch 3: Val Loss 3752088.25000
Epoch 4: Val Loss 3704211.50000
Epoch 5: Val Loss 3702797.00000
Epoch 6: Val Loss 3649268.00000
Epoch 7: Val Loss 3630708.75000
Epoch 8: Val Loss 3598713.00000
Epoch 9: Val Loss 3584055.25000
Epoch 10: Val Loss 3582698.00000
Epoch 11: Val Loss 3540930.50000
Epoch 12: Val Loss 3524275.25000
Epoch 13: Val Loss 3521559.75000
Epoch 14: Val Loss 3513735.75000
Epoch 15: Val Loss 3511506.25000
Epoch 16: Val Loss 3509223.25000
Epoch 17: Val Loss 3486336.50000
Epoch 18: Val Loss 3515437.50000
Epoch 19: Val Loss 3490032.25000
Epoch 20: Val Loss 3486922.00000
Epoch 21: Val Loss 3462152.75000
Epoch 22: Val Loss 3457722.75000
Epoch 23: Val Loss 3452285.75000
Epoch 24: Val Loss 3485420.25000
Epoch 25: Val Loss 3502945.50000
Epoch 26: Val Loss 3472750.50000
Epoch 27: Val Loss 3433094.75000
Epoch 28: Val Loss 3425233.75000
Epoch 29: Val Loss 3411442.75000
Epoch 30: Val Loss 3433603.00000
Epoch 31: Val Loss 3432510.25000
Epoch 32: Val Loss 3418716.50000
Epoch 33: Val Loss 3424999.50000
Epoch 34: Val Loss 3412971.25000
Epoch 35: Val Loss 3417134.00000
Epoch 36: Val Loss 3432945.50000
Epoch 37: Val Loss 3399500.00000
Epoch 38: Val Loss 3394064.25000
Epoch 39: Val Loss 3392439.75000
Epoch 40: Val Loss 3396835.25000
Epoch 41: Val Loss 3427469.00000
Epoch 42: Val Loss 3421521.00000
Epoch 43: Val Loss 3410041.50000
Epoch 44: Val Loss 3443095.75000
Epoch 45: Val Loss 3390710.25000
Epoch 46: Val Loss 3406441.25000
Epoch 47: Val Loss 3420219.75000
Epoch 48: Val Loss 3415328.00000
Epoch 49: Val Loss 3405944.00000
Epoch 50: Val Loss 3402786.00000
Epoch 51: Val Loss 3395574.25000
Epoch 52: Val Loss 3448105.50000
Epoch 53: Val Loss 3386033.75000
Epoch 54: Val Loss 3388392.50000
Epoch 55: Val Loss 3393721.25000
Epoch 56: Val Loss 3394725.75000
Epoch 57: Val Loss 3424348.50000
Epoch 58: Val Loss 3377028.75000
Epoch 59: Val Loss 3381822.25000
Epoch 60: Val Loss 3386984.25000
Epoch 61: Val Loss 3383317.00000
Epoch 62: Val Loss 3401698.75000
Epoch 63: Val Loss 3455492.50000
Epoch 64: Val Loss 3382018.25000
Epoch 65: Val Loss 3444288.25000
Epoch 66: Val Loss 3442581.25000
Epoch 67: Val Loss 3412741.25000
Epoch 68: Val Loss 3416470.25000
Epoch 69: Val Loss 3459542.00000
Epoch 70: Val Loss 3416741.50000
Epoch 71: Val Loss 3403342.25000
Epoch 72: Val Loss 3399349.00000
Epoch 73: Val Loss 3436727.50000
Epoch 74: Val Loss 3480651.25000
Epoch 75: Val Loss 3411718.25000
Epoch 76: Val Loss 3449955.75000
Epoch 77: Val Loss 3444225.50000
Epoch 78: Val Loss 3437388.50000
Epoch 79: Val Loss 3436947.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3405650.6627344787, 'MSE - std': 15144.695613293443, 'R2 - mean': 0.5879028138652206, 'R2 - std': 0.011297658954450562} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5006732.00000
Epoch 1: Val Loss 4586298.00000
Epoch 2: Val Loss 4446905.00000
Epoch 3: Val Loss 4387808.00000
Epoch 4: Val Loss 4334803.00000
Epoch 5: Val Loss 4288109.00000
Epoch 6: Val Loss 4263326.50000
Epoch 7: Val Loss 4232193.50000
Epoch 8: Val Loss 4189730.25000
Epoch 9: Val Loss 4174218.50000
Epoch 10: Val Loss 4152110.00000
Epoch 11: Val Loss 4135786.00000
Epoch 12: Val Loss 4134433.50000
Epoch 13: Val Loss 4108935.00000
Epoch 14: Val Loss 4117256.00000
Epoch 15: Val Loss 4105621.25000
Epoch 16: Val Loss 4062158.25000
Epoch 17: Val Loss 4059495.00000
Epoch 18: Val Loss 4047089.75000
Epoch 19: Val Loss 4052796.25000
Epoch 20: Val Loss 4029691.00000
Epoch 21: Val Loss 4057053.00000
Epoch 22: Val Loss 4020108.25000
Epoch 23: Val Loss 4006420.50000
Epoch 24: Val Loss 4011472.50000
Epoch 25: Val Loss 3990020.00000
Epoch 26: Val Loss 3989089.50000
Epoch 27: Val Loss 3977659.75000
Epoch 28: Val Loss 3981836.25000
Epoch 29: Val Loss 3962353.50000
Epoch 30: Val Loss 3979266.25000
Epoch 31: Val Loss 3954476.75000
Epoch 32: Val Loss 3984852.00000
Epoch 33: Val Loss 3947628.25000
Epoch 34: Val Loss 3964419.00000
Epoch 35: Val Loss 3957920.00000
Epoch 36: Val Loss 3948215.50000
Epoch 37: Val Loss 3923230.00000
Epoch 38: Val Loss 3921009.50000
Epoch 39: Val Loss 3911489.75000
Epoch 40: Val Loss 3908331.00000
Epoch 41: Val Loss 3910863.25000
Epoch 42: Val Loss 3919728.00000
Epoch 43: Val Loss 3895125.75000
Epoch 44: Val Loss 3916704.50000
Epoch 45: Val Loss 3889926.50000
Epoch 46: Val Loss 3886856.00000
Epoch 47: Val Loss 3878808.25000
Epoch 48: Val Loss 3872334.25000
Epoch 49: Val Loss 3892171.25000
Epoch 50: Val Loss 3879526.25000
Epoch 51: Val Loss 3888781.00000
Epoch 52: Val Loss 3879247.75000
Epoch 53: Val Loss 3862125.00000
Epoch 54: Val Loss 3862161.00000
Epoch 55: Val Loss 3901309.00000
Epoch 56: Val Loss 3854106.50000
Epoch 57: Val Loss 3932891.25000
Epoch 58: Val Loss 3853611.75000
Epoch 59: Val Loss 3850598.25000
Epoch 60: Val Loss 3862094.25000
Epoch 61: Val Loss 3867619.00000
Epoch 62: Val Loss 3854197.25000
Epoch 63: Val Loss 3853886.00000
Epoch 64: Val Loss 3869132.75000
Epoch 65: Val Loss 3874682.50000
Epoch 66: Val Loss 3847576.25000
Epoch 67: Val Loss 3846656.00000
Epoch 68: Val Loss 3863848.75000
Epoch 69: Val Loss 3849066.50000
Epoch 70: Val Loss 3869784.00000
Epoch 71: Val Loss 3864018.75000
Epoch 72: Val Loss 3852542.25000
Epoch 73: Val Loss 3873049.50000
Epoch 74: Val Loss 3853515.00000
Epoch 75: Val Loss 3871844.50000
Epoch 76: Val Loss 3855803.75000
Epoch 77: Val Loss 3897905.50000
Epoch 78: Val Loss 3866542.00000
Epoch 79: Val Loss 3890024.25000
Epoch 80: Val Loss 3855524.00000
Epoch 81: Val Loss 3890733.00000
Epoch 82: Val Loss 3872296.00000
Epoch 83: Val Loss 3912094.25000
Epoch 84: Val Loss 3924503.50000
Epoch 85: Val Loss 3918464.00000
Epoch 86: Val Loss 3973734.25000
Epoch 87: Val Loss 3906540.25000
Epoch 88: Val Loss 3895479.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3555242.753172387, 'MSE - std': 211916.24504344378, 'R2 - mean': 0.5815395584092228, 'R2 - std': 0.012886948380588611} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4603046.50000
Epoch 1: Val Loss 4212957.50000
Epoch 2: Val Loss 4130250.50000
Epoch 3: Val Loss 4072877.00000
Epoch 4: Val Loss 4066169.25000
Epoch 5: Val Loss 4002736.50000
Epoch 6: Val Loss 3957323.25000
Epoch 7: Val Loss 3933230.75000
Epoch 8: Val Loss 3921740.25000
Epoch 9: Val Loss 3891372.25000
Epoch 10: Val Loss 3898334.00000
Epoch 11: Val Loss 3870493.00000
Epoch 12: Val Loss 3863272.75000
Epoch 13: Val Loss 3838011.00000
Epoch 14: Val Loss 3829012.75000
Epoch 15: Val Loss 3832725.25000
Epoch 16: Val Loss 3832664.25000
Epoch 17: Val Loss 3821134.75000
Epoch 18: Val Loss 3796087.50000
Epoch 19: Val Loss 3790150.25000
Epoch 20: Val Loss 3805668.50000
Epoch 21: Val Loss 3790120.00000
Epoch 22: Val Loss 3756436.50000
Epoch 23: Val Loss 3750211.00000
Epoch 24: Val Loss 3757566.00000
Epoch 25: Val Loss 3777049.25000
Epoch 26: Val Loss 3751292.25000
Epoch 27: Val Loss 3739601.00000
Epoch 28: Val Loss 3758136.25000
Epoch 29: Val Loss 3733078.25000
Epoch 30: Val Loss 3775480.75000
Epoch 31: Val Loss 3736683.75000
Epoch 32: Val Loss 3714003.50000
Epoch 33: Val Loss 3720538.50000
Epoch 34: Val Loss 3743925.75000
Epoch 35: Val Loss 3755778.25000
Epoch 36: Val Loss 3727313.50000
Epoch 37: Val Loss 3719884.75000
Epoch 38: Val Loss 3705353.25000
Epoch 39: Val Loss 3714926.75000
Epoch 40: Val Loss 3702457.50000
Epoch 41: Val Loss 3705000.75000
Epoch 42: Val Loss 3731028.75000
Epoch 43: Val Loss 3841336.00000
Epoch 44: Val Loss 3698397.00000
Epoch 45: Val Loss 3686720.00000
Epoch 46: Val Loss 3712790.25000
Epoch 47: Val Loss 3728506.50000
Epoch 48: Val Loss 3715821.50000
Epoch 49: Val Loss 3709980.25000
Epoch 50: Val Loss 3716799.75000
Epoch 51: Val Loss 3752222.00000
Epoch 52: Val Loss 3776673.50000
Epoch 53: Val Loss 3693800.25000
Epoch 54: Val Loss 3699248.50000
Epoch 55: Val Loss 3725417.25000
Epoch 56: Val Loss 3765340.75000
Epoch 57: Val Loss 3735430.50000
Epoch 58: Val Loss 3734876.25000
Epoch 59: Val Loss 3743685.75000
Epoch 60: Val Loss 3758128.00000
Epoch 61: Val Loss 3756912.50000
Epoch 62: Val Loss 3743016.25000
Epoch 63: Val Loss 3811237.75000
Epoch 64: Val Loss 3730423.75000
Epoch 65: Val Loss 3754739.50000
Epoch 66: Val Loss 3834212.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3590359.887333044, 'MSE - std': 193341.69369268845, 'R2 - mean': 0.5785518472173483, 'R2 - std': 0.012301802039584446} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4128642.75000
Epoch 1: Val Loss 3723686.50000
Epoch 2: Val Loss 3612863.75000
Epoch 3: Val Loss 3582945.75000
Epoch 4: Val Loss 3562079.75000
Epoch 5: Val Loss 3516373.00000
Epoch 6: Val Loss 3549248.50000
Epoch 7: Val Loss 3478204.50000
Epoch 8: Val Loss 3468262.50000
Epoch 9: Val Loss 3473196.25000
Epoch 10: Val Loss 3431692.00000
Epoch 11: Val Loss 3426875.00000
Epoch 12: Val Loss 3426689.75000
Epoch 13: Val Loss 3428214.25000
Epoch 14: Val Loss 3428194.00000
Epoch 15: Val Loss 3503664.75000
Epoch 16: Val Loss 3430231.25000
Epoch 17: Val Loss 3404873.50000
Epoch 18: Val Loss 3437411.25000
Epoch 19: Val Loss 3420578.25000
Epoch 20: Val Loss 3399700.50000
Epoch 21: Val Loss 3403781.50000
Epoch 22: Val Loss 3387158.50000
Epoch 23: Val Loss 3400095.75000
Epoch 24: Val Loss 3390506.25000
Epoch 25: Val Loss 3396656.00000
Epoch 26: Val Loss 3388716.50000
Epoch 27: Val Loss 3428392.00000
Epoch 28: Val Loss 3426013.50000
Epoch 29: Val Loss 3388325.75000
Epoch 30: Val Loss 3398437.75000
Epoch 31: Val Loss 3397924.50000
Epoch 32: Val Loss 3447041.25000
Epoch 33: Val Loss 3470633.50000
Epoch 34: Val Loss 3410113.75000
Epoch 35: Val Loss 3395523.50000
Epoch 36: Val Loss 3389086.25000
Epoch 37: Val Loss 3403814.00000
Epoch 38: Val Loss 3392626.25000
Epoch 39: Val Loss 3437826.25000
Epoch 40: Val Loss 3432435.50000
Epoch 41: Val Loss 3413173.50000
Epoch 42: Val Loss 3414794.50000
Epoch 43: Val Loss 3569203.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551278.97940188, 'MSE - std': 189773.75444160443, 'R2 - mean': 0.5790007397546132, 'R2 - std': 0.011039632456605967} 
 

Saving model.....
Results After CV: {'MSE - mean': 3551278.97940188, 'MSE - std': 189773.75444160443, 'R2 - mean': 0.5790007397546132, 'R2 - std': 0.011039632456605967}
Train time: 5276.0273586396015
Inference time: 6.814441461398383
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 12 finished with value: 3551278.97940188 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -5, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3835825.75000
Epoch 1: Val Loss 3799960.25000
Epoch 2: Val Loss 3691580.25000
Epoch 3: Val Loss 3657371.00000
Epoch 4: Val Loss 3589255.00000
Epoch 5: Val Loss 3520795.50000
Epoch 6: Val Loss 3552424.50000
Epoch 7: Val Loss 3469198.00000
Epoch 8: Val Loss 3474864.25000
Epoch 9: Val Loss 3456028.50000
Epoch 10: Val Loss 3409260.50000
Epoch 11: Val Loss 3431830.00000
Epoch 12: Val Loss 3431668.50000
Epoch 13: Val Loss 3474482.00000
Epoch 14: Val Loss 3555736.00000
Epoch 15: Val Loss 3648691.50000
Epoch 16: Val Loss 3576363.75000
Epoch 17: Val Loss 3689634.25000
Epoch 18: Val Loss 3711611.00000
Epoch 19: Val Loss 3732225.50000
Epoch 20: Val Loss 3877666.75000
Epoch 21: Val Loss 3974836.50000
Epoch 22: Val Loss 3884089.50000
Epoch 23: Val Loss 3980553.50000
Epoch 24: Val Loss 4230684.50000
Epoch 25: Val Loss 4205576.00000
Epoch 26: Val Loss 4165683.50000
Epoch 27: Val Loss 4096034.25000
Epoch 28: Val Loss 4311086.00000
Epoch 29: Val Loss 4228923.50000
Epoch 30: Val Loss 4334667.50000
Epoch 31: Val Loss 4340409.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407661.5030116285, 'MSE - std': 0.0, 'R2 - mean': 0.6007393088087738, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3689566.25000
Epoch 1: Val Loss 3691321.50000
Epoch 2: Val Loss 3794012.75000
Epoch 3: Val Loss 3588982.50000
Epoch 4: Val Loss 3548267.50000
Epoch 5: Val Loss 3521460.50000
Epoch 6: Val Loss 3447145.00000
Epoch 7: Val Loss 3470965.00000
Epoch 8: Val Loss 3425650.00000
Epoch 9: Val Loss 3429332.25000
Epoch 10: Val Loss 3443093.75000
Epoch 11: Val Loss 3456965.25000
Epoch 12: Val Loss 3470264.00000
Epoch 13: Val Loss 3480100.25000
Epoch 14: Val Loss 3526779.00000
Epoch 15: Val Loss 3571124.75000
Epoch 16: Val Loss 3686742.25000
Epoch 17: Val Loss 3813986.75000
Epoch 18: Val Loss 3638871.50000
Epoch 19: Val Loss 3737039.75000
Epoch 20: Val Loss 3851641.25000
Epoch 21: Val Loss 3801297.50000
Epoch 22: Val Loss 3867488.50000
Epoch 23: Val Loss 3913548.75000
Epoch 24: Val Loss 3915546.00000
Epoch 25: Val Loss 4033557.75000
Epoch 26: Val Loss 4007041.75000
Epoch 27: Val Loss 4097809.50000
Epoch 28: Val Loss 4164839.50000
Epoch 29: Val Loss 4270238.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3420841.9025966944, 'MSE - std': 13180.39958506613, 'R2 - mean': 0.5859551459557073, 'R2 - std': 0.01478416285306644} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4306584.50000
Epoch 1: Val Loss 4255411.00000
Epoch 2: Val Loss 4203049.00000
Epoch 3: Val Loss 4133084.25000
Epoch 4: Val Loss 4429956.00000
Epoch 5: Val Loss 4052885.25000
Epoch 6: Val Loss 4024501.25000
Epoch 7: Val Loss 3984974.75000
Epoch 8: Val Loss 3955005.00000
Epoch 9: Val Loss 3933697.75000
Epoch 10: Val Loss 3856744.75000
Epoch 11: Val Loss 4046648.75000
Epoch 12: Val Loss 3908644.00000
Epoch 13: Val Loss 3937398.50000
Epoch 14: Val Loss 3960888.00000
Epoch 15: Val Loss 3940134.50000
Epoch 16: Val Loss 4002606.75000
Epoch 17: Val Loss 4100893.50000
Epoch 18: Val Loss 4096954.50000
Epoch 19: Val Loss 4176372.00000
Epoch 20: Val Loss 4254162.50000
Epoch 21: Val Loss 4267813.50000
Epoch 22: Val Loss 4458834.50000
Epoch 23: Val Loss 4446443.50000
Epoch 24: Val Loss 4472793.00000
Epoch 25: Val Loss 4734986.00000
Epoch 26: Val Loss 4613028.00000
Epoch 27: Val Loss 4708071.00000
Epoch 28: Val Loss 4649883.50000
Epoch 29: Val Loss 4706096.00000
Epoch 30: Val Loss 4766178.50000
Epoch 31: Val Loss 4853610.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3568080.5132649913, 'MSE - std': 208504.7534994715, 'R2 - mean': 0.5799379210601926, 'R2 - std': 0.01476916737882443} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4055043.25000
Epoch 1: Val Loss 3982487.50000
Epoch 2: Val Loss 4034886.25000
Epoch 3: Val Loss 3980004.50000
Epoch 4: Val Loss 3840782.00000
Epoch 5: Val Loss 3812361.50000
Epoch 6: Val Loss 3863345.50000
Epoch 7: Val Loss 3784262.25000
Epoch 8: Val Loss 3990200.25000
Epoch 9: Val Loss 3994343.50000
Epoch 10: Val Loss 3829050.00000
Epoch 11: Val Loss 3858676.50000
Epoch 12: Val Loss 3923590.50000
Epoch 13: Val Loss 3913052.75000
Epoch 14: Val Loss 3963972.50000
Epoch 15: Val Loss 4093171.50000
Epoch 16: Val Loss 4153227.00000
Epoch 17: Val Loss 4179962.50000
Epoch 18: Val Loss 4241369.50000
Epoch 19: Val Loss 4189026.25000
Epoch 20: Val Loss 4317727.00000
Epoch 21: Val Loss 4571845.50000
Epoch 22: Val Loss 4397422.50000
Epoch 23: Val Loss 4561652.50000
Epoch 24: Val Loss 4485095.00000
Epoch 25: Val Loss 4419082.50000
Epoch 26: Val Loss 4666692.00000
Epoch 27: Val Loss 4656911.50000
Epoch 28: Val Loss 4617421.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3624375.580752411, 'MSE - std': 205214.71205580235, 'R2 - mean': 0.5745104079684685, 'R2 - std': 0.01587356052939309} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3578793.50000
Epoch 1: Val Loss 3476700.00000
Epoch 2: Val Loss 3485347.00000
Epoch 3: Val Loss 3487774.25000
Epoch 4: Val Loss 3444509.75000
Epoch 5: Val Loss 3448885.50000
Epoch 6: Val Loss 3443788.00000
Epoch 7: Val Loss 3404746.75000
Epoch 8: Val Loss 3385573.25000
Epoch 9: Val Loss 3481404.50000
Epoch 10: Val Loss 3477273.50000
Epoch 11: Val Loss 3495261.25000
Epoch 12: Val Loss 3508343.25000
Epoch 13: Val Loss 3422825.75000
Epoch 14: Val Loss 3531790.25000
Epoch 15: Val Loss 3578979.00000
Epoch 16: Val Loss 3600180.75000
Epoch 17: Val Loss 3618431.25000
Epoch 18: Val Loss 3681751.75000
Epoch 19: Val Loss 3770299.00000
Epoch 20: Val Loss 3718997.75000
Epoch 21: Val Loss 3823973.75000
Epoch 22: Val Loss 3840726.25000
Epoch 23: Val Loss 3905397.75000
Epoch 24: Val Loss 3973175.50000
Epoch 25: Val Loss 4049764.75000
Epoch 26: Val Loss 4049200.00000
Epoch 27: Val Loss 4127985.75000
Epoch 28: Val Loss 4159485.50000
Epoch 29: Val Loss 4255113.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3578821.0177025646, 'MSE - std': 204917.87451065955, 'R2 - mean': 0.5757269042485892, 'R2 - std': 0.01440470034059837} 
 

Saving model.....
Results After CV: {'MSE - mean': 3578821.0177025646, 'MSE - std': 204917.87451065955, 'R2 - mean': 0.5757269042485892, 'R2 - std': 0.01440470034059837}
Train time: 2269.1062414532003
Inference time: 6.536953634198289
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 13 finished with value: 3578821.0177025646 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -5, 'learning_rate': -3, 'dropout': 0.5}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8790269.00000
Epoch 1: Val Loss 8228656.00000
Epoch 2: Val Loss 7860248.50000
Epoch 3: Val Loss 7300385.00000
Epoch 4: Val Loss 6567911.00000
Epoch 5: Val Loss 5827597.50000
Epoch 6: Val Loss 5391482.50000
Epoch 7: Val Loss 5020279.50000
Epoch 8: Val Loss 4763637.50000
Epoch 9: Val Loss 4576272.50000
Epoch 10: Val Loss 4477443.00000
Epoch 11: Val Loss 4392471.00000
Epoch 12: Val Loss 4331047.00000
Epoch 13: Val Loss 4269160.50000
Epoch 14: Val Loss 4228912.50000
Epoch 15: Val Loss 4191404.75000
Epoch 16: Val Loss 4164954.50000
Epoch 17: Val Loss 4144023.50000
Epoch 18: Val Loss 4099508.00000
Epoch 19: Val Loss 4095141.75000
Epoch 20: Val Loss 4074615.50000
Epoch 21: Val Loss 4057085.00000
Epoch 22: Val Loss 4058572.75000
Epoch 23: Val Loss 4059013.75000
Epoch 24: Val Loss 4011344.50000
Epoch 25: Val Loss 4004413.50000
Epoch 26: Val Loss 3988379.00000
Epoch 27: Val Loss 4011211.00000
Epoch 28: Val Loss 3973750.50000
Epoch 29: Val Loss 3961594.50000
Epoch 30: Val Loss 3958563.00000
Epoch 31: Val Loss 3940395.25000
Epoch 32: Val Loss 3933986.75000
Epoch 33: Val Loss 3925656.75000
Epoch 34: Val Loss 3923192.00000
Epoch 35: Val Loss 3926894.25000
Epoch 36: Val Loss 3907042.75000
Epoch 37: Val Loss 3891928.75000
Epoch 38: Val Loss 3890513.50000
Epoch 39: Val Loss 3881284.00000
Epoch 40: Val Loss 3874008.00000
Epoch 41: Val Loss 3878973.50000
Epoch 42: Val Loss 3862495.75000
Epoch 43: Val Loss 3851105.75000
Epoch 44: Val Loss 3852770.75000
Epoch 45: Val Loss 3845557.75000
Epoch 46: Val Loss 3841096.00000
Epoch 47: Val Loss 3855656.25000
Epoch 48: Val Loss 3821151.25000
Epoch 49: Val Loss 3826133.75000
Epoch 50: Val Loss 3818356.75000
Epoch 51: Val Loss 3820767.75000
Epoch 52: Val Loss 3803790.75000
Epoch 53: Val Loss 3823644.75000
Epoch 54: Val Loss 3804875.25000
Epoch 55: Val Loss 3791194.00000
Epoch 56: Val Loss 3791582.00000
Epoch 57: Val Loss 3786878.00000
Epoch 58: Val Loss 3790619.75000
Epoch 59: Val Loss 3782634.00000
Epoch 60: Val Loss 3778999.50000
Epoch 61: Val Loss 3781129.25000
Epoch 62: Val Loss 3772611.00000
Epoch 63: Val Loss 3755260.75000
Epoch 64: Val Loss 3770290.75000
Epoch 65: Val Loss 3786870.50000
Epoch 66: Val Loss 3757979.00000
Epoch 67: Val Loss 3752576.00000
Epoch 68: Val Loss 3746643.00000
Epoch 69: Val Loss 3742918.50000
Epoch 70: Val Loss 3732852.50000
Epoch 71: Val Loss 3737652.00000
Epoch 72: Val Loss 3735066.00000
Epoch 73: Val Loss 3730546.75000
Epoch 74: Val Loss 3734637.50000
Epoch 75: Val Loss 3717767.50000
Epoch 76: Val Loss 3725787.75000
Epoch 77: Val Loss 3722099.50000
Epoch 78: Val Loss 3710573.50000
Epoch 79: Val Loss 3716246.25000
Epoch 80: Val Loss 3716324.75000
Epoch 81: Val Loss 3762497.75000
Epoch 82: Val Loss 3707052.75000
Epoch 83: Val Loss 3742452.00000
Epoch 84: Val Loss 3694836.00000
Epoch 85: Val Loss 3697704.25000
Epoch 86: Val Loss 3710880.00000
Epoch 87: Val Loss 3699940.75000
Epoch 88: Val Loss 3713047.50000
Epoch 89: Val Loss 3682897.75000
Epoch 90: Val Loss 3679359.25000
Epoch 91: Val Loss 3682421.75000
Epoch 92: Val Loss 3690570.00000
Epoch 93: Val Loss 3673306.50000
Epoch 94: Val Loss 3680224.50000
Epoch 95: Val Loss 3680409.50000
Epoch 96: Val Loss 3675736.75000
Epoch 97: Val Loss 3690477.00000
Epoch 98: Val Loss 3676260.75000
Epoch 99: Val Loss 3685021.00000
Saved Losses
{'MSE - mean': 3683818.0758112785, 'MSE - std': 0.0, 'R2 - mean': 0.5683832593491829, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8233149.50000
Epoch 1: Val Loss 7751472.50000
Epoch 2: Val Loss 7416196.50000
Epoch 3: Val Loss 6852267.50000
Epoch 4: Val Loss 6193289.00000
Epoch 5: Val Loss 5499109.50000
Epoch 6: Val Loss 4982861.00000
Epoch 7: Val Loss 4655432.00000
Epoch 8: Val Loss 4459664.50000
Epoch 9: Val Loss 4339213.50000
Epoch 10: Val Loss 4258437.50000
Epoch 11: Val Loss 4175156.00000
Epoch 12: Val Loss 4171350.25000
Epoch 13: Val Loss 4098509.00000
Epoch 14: Val Loss 4039898.00000
Epoch 15: Val Loss 4013103.25000
Epoch 16: Val Loss 3971844.50000
Epoch 17: Val Loss 3960002.75000
Epoch 18: Val Loss 3930865.50000
Epoch 19: Val Loss 3912778.50000
Epoch 20: Val Loss 3897062.50000
Epoch 21: Val Loss 3994788.50000
Epoch 22: Val Loss 3860503.00000
Epoch 23: Val Loss 3863055.75000
Epoch 24: Val Loss 3846309.25000
Epoch 25: Val Loss 3837997.50000
Epoch 26: Val Loss 3822150.50000
Epoch 27: Val Loss 3809720.00000
Epoch 28: Val Loss 3825626.00000
Epoch 29: Val Loss 3817678.75000
Epoch 30: Val Loss 3795020.75000
Epoch 31: Val Loss 3791105.50000
Epoch 32: Val Loss 3780008.75000
Epoch 33: Val Loss 3786823.00000
Epoch 34: Val Loss 3767075.00000
Epoch 35: Val Loss 3783242.00000
Epoch 36: Val Loss 3752615.00000
Epoch 37: Val Loss 3739121.00000
Epoch 38: Val Loss 3787041.00000
Epoch 39: Val Loss 3751882.50000
Epoch 40: Val Loss 3746786.75000
Epoch 41: Val Loss 3722372.75000
Epoch 42: Val Loss 3746251.75000
Epoch 43: Val Loss 3725567.25000
Epoch 44: Val Loss 3705905.75000
Epoch 45: Val Loss 3701119.75000
Epoch 46: Val Loss 3722895.25000
Epoch 47: Val Loss 3692829.50000
Epoch 48: Val Loss 3703260.75000
Epoch 49: Val Loss 3691223.75000
Epoch 50: Val Loss 3687057.75000
Epoch 51: Val Loss 3685239.00000
Epoch 52: Val Loss 3675701.25000
Epoch 53: Val Loss 3669519.25000
Epoch 54: Val Loss 3678313.50000
Epoch 55: Val Loss 3676495.25000
Epoch 56: Val Loss 3659467.75000
Epoch 57: Val Loss 3670820.00000
Epoch 58: Val Loss 3657418.50000
Epoch 59: Val Loss 3647278.25000
Epoch 60: Val Loss 3650756.00000
Epoch 61: Val Loss 3647426.25000
Epoch 62: Val Loss 3642103.50000
Epoch 63: Val Loss 3702686.25000
Epoch 64: Val Loss 3646625.75000
Epoch 65: Val Loss 3644530.25000
Epoch 66: Val Loss 3645909.75000
Epoch 67: Val Loss 3635089.00000
Epoch 68: Val Loss 3626481.75000
Epoch 69: Val Loss 3630597.25000
Epoch 70: Val Loss 3632048.00000
Epoch 71: Val Loss 3637766.50000
Epoch 72: Val Loss 3623088.50000
Epoch 73: Val Loss 3620710.25000
Epoch 74: Val Loss 3626556.50000
Epoch 75: Val Loss 3609094.25000
Epoch 76: Val Loss 3613640.25000
Epoch 77: Val Loss 3612807.50000
Epoch 78: Val Loss 3599108.50000
Epoch 79: Val Loss 3623519.75000
Epoch 80: Val Loss 3592848.25000
Epoch 81: Val Loss 3609859.00000
Epoch 82: Val Loss 3604883.75000
Epoch 83: Val Loss 3589662.50000
Epoch 84: Val Loss 3599775.25000
Epoch 85: Val Loss 3592364.00000
Epoch 86: Val Loss 3585731.75000
Epoch 87: Val Loss 3579795.25000
Epoch 88: Val Loss 3597345.75000
Epoch 89: Val Loss 3595760.25000
Epoch 90: Val Loss 3572910.25000
Epoch 91: Val Loss 3567581.50000
Epoch 92: Val Loss 3580136.00000
Epoch 93: Val Loss 3580506.75000
Epoch 94: Val Loss 3564848.25000
Epoch 95: Val Loss 3569454.50000
Epoch 96: Val Loss 3567067.00000
Epoch 97: Val Loss 3561290.50000
Epoch 98: Val Loss 3633636.50000
Epoch 99: Val Loss 3562459.25000
Saved Losses
{'MSE - mean': 3630266.9691888858, 'MSE - std': 53551.10662239278, 'R2 - mean': 0.560867578154731, 'R2 - std': 0.007515681194451895} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9165631.00000
Epoch 1: Val Loss 8637445.00000
Epoch 2: Val Loss 8235363.00000
Epoch 3: Val Loss 7748165.50000
Epoch 4: Val Loss 6987606.50000
Epoch 5: Val Loss 6269130.50000
Epoch 6: Val Loss 5748395.00000
Epoch 7: Val Loss 5424621.50000
Epoch 8: Val Loss 5276270.50000
Epoch 9: Val Loss 5081091.00000
Epoch 10: Val Loss 4970867.50000
Epoch 11: Val Loss 5032659.00000
Epoch 12: Val Loss 4838081.00000
Epoch 13: Val Loss 4785062.00000
Epoch 14: Val Loss 4730073.00000
Epoch 15: Val Loss 4695829.50000
Epoch 16: Val Loss 4656132.50000
Epoch 17: Val Loss 4628931.50000
Epoch 18: Val Loss 4616341.50000
Epoch 19: Val Loss 4621525.00000
Epoch 20: Val Loss 4572835.00000
Epoch 21: Val Loss 4593800.00000
Epoch 22: Val Loss 4528455.50000
Epoch 23: Val Loss 4522855.50000
Epoch 24: Val Loss 4495864.00000
Epoch 25: Val Loss 4482639.50000
Epoch 26: Val Loss 4475470.00000
Epoch 27: Val Loss 4478474.50000
Epoch 28: Val Loss 4476537.50000
Epoch 29: Val Loss 4449246.00000
Epoch 30: Val Loss 4499975.50000
Epoch 31: Val Loss 4429712.00000
Epoch 32: Val Loss 4424667.00000
Epoch 33: Val Loss 4422940.50000
Epoch 34: Val Loss 4416719.50000
Epoch 35: Val Loss 4392697.00000
Epoch 36: Val Loss 4441313.00000
Epoch 37: Val Loss 4385325.00000
Epoch 38: Val Loss 4370557.00000
Epoch 39: Val Loss 4390177.00000
Epoch 40: Val Loss 4360934.00000
Epoch 41: Val Loss 4357886.00000
Epoch 42: Val Loss 4409805.00000
Epoch 43: Val Loss 4341832.50000
Epoch 44: Val Loss 4343711.50000
Epoch 45: Val Loss 4320716.50000
Epoch 46: Val Loss 4335877.50000
Epoch 47: Val Loss 4310027.00000
Epoch 48: Val Loss 4317865.00000
Epoch 49: Val Loss 4308450.00000
Epoch 50: Val Loss 4319099.00000
Epoch 51: Val Loss 4315873.00000
Epoch 52: Val Loss 4306987.00000
Epoch 53: Val Loss 4288354.50000
Epoch 54: Val Loss 4278647.00000
Epoch 55: Val Loss 4292966.00000
Epoch 56: Val Loss 4270908.50000
Epoch 57: Val Loss 4287490.50000
Epoch 58: Val Loss 4274389.50000
Epoch 59: Val Loss 4279311.00000
Epoch 60: Val Loss 4252578.50000
Epoch 61: Val Loss 4253064.00000
Epoch 62: Val Loss 4253496.50000
Epoch 63: Val Loss 4245446.50000
Epoch 64: Val Loss 4250135.00000
Epoch 65: Val Loss 4237985.00000
Epoch 66: Val Loss 4233031.00000
Epoch 67: Val Loss 4230216.00000
Epoch 68: Val Loss 4222372.50000
Epoch 69: Val Loss 4264585.00000
Epoch 70: Val Loss 4227849.00000
Epoch 71: Val Loss 4225638.50000
Epoch 72: Val Loss 4215298.50000
Epoch 73: Val Loss 4232633.50000
Epoch 74: Val Loss 4205833.50000
Epoch 75: Val Loss 4208588.00000
Epoch 76: Val Loss 4197714.00000
Epoch 77: Val Loss 4200450.00000
Epoch 78: Val Loss 4205769.00000
Epoch 79: Val Loss 4197143.00000
Epoch 80: Val Loss 4207782.50000
Epoch 81: Val Loss 4189143.00000
Epoch 82: Val Loss 4188036.75000
Epoch 83: Val Loss 4185824.50000
Epoch 84: Val Loss 4187088.00000
Epoch 85: Val Loss 4180637.50000
Epoch 86: Val Loss 4180884.75000
Epoch 87: Val Loss 4178878.25000
Epoch 88: Val Loss 4171211.75000
Epoch 89: Val Loss 4165823.25000
Epoch 90: Val Loss 4165921.00000
Epoch 91: Val Loss 4167122.25000
Epoch 92: Val Loss 4156300.75000
Epoch 93: Val Loss 4168535.50000
Epoch 94: Val Loss 4204354.50000
Epoch 95: Val Loss 4161550.00000
Epoch 96: Val Loss 4151468.75000
Epoch 97: Val Loss 4160531.50000
Epoch 98: Val Loss 4146593.00000
Epoch 99: Val Loss 4148244.75000
Saved Losses
{'MSE - mean': 3807983.0608659405, 'MSE - std': 255103.57209492387, 'R2 - mean': 0.5519941019726445, 'R2 - std': 0.013969042021050366} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8846999.00000
Epoch 1: Val Loss 8277885.50000
Epoch 2: Val Loss 7900777.50000
Epoch 3: Val Loss 7364697.50000
Epoch 4: Val Loss 6674326.00000
Epoch 5: Val Loss 5970209.50000
Epoch 6: Val Loss 5390364.00000
Epoch 7: Val Loss 5060022.00000
Epoch 8: Val Loss 4844411.00000
Epoch 9: Val Loss 4700272.00000
Epoch 10: Val Loss 4588276.50000
Epoch 11: Val Loss 4509418.50000
Epoch 12: Val Loss 4451225.50000
Epoch 13: Val Loss 4432132.00000
Epoch 14: Val Loss 4368644.50000
Epoch 15: Val Loss 4351029.50000
Epoch 16: Val Loss 4321390.50000
Epoch 17: Val Loss 4417094.50000
Epoch 18: Val Loss 4249259.00000
Epoch 19: Val Loss 4231607.50000
Epoch 20: Val Loss 4217817.50000
Epoch 21: Val Loss 4218528.00000
Epoch 22: Val Loss 4186569.25000
Epoch 23: Val Loss 4199528.00000
Epoch 24: Val Loss 4169316.00000
Epoch 25: Val Loss 4171832.00000
Epoch 26: Val Loss 4187717.25000
Epoch 27: Val Loss 4138392.25000
Epoch 28: Val Loss 4131864.25000
Epoch 29: Val Loss 4147541.25000
Epoch 30: Val Loss 4125828.75000
Epoch 31: Val Loss 4117016.75000
Epoch 32: Val Loss 4113620.75000
Epoch 33: Val Loss 4110600.25000
Epoch 34: Val Loss 4100570.50000
Epoch 35: Val Loss 4095089.00000
Epoch 36: Val Loss 4073415.00000
Epoch 37: Val Loss 4072622.00000
Epoch 38: Val Loss 4118697.25000
Epoch 39: Val Loss 4071103.75000
Epoch 40: Val Loss 4068712.75000
Epoch 41: Val Loss 4051596.25000
Epoch 42: Val Loss 4074214.50000
Epoch 43: Val Loss 4038879.25000
Epoch 44: Val Loss 4040490.50000
Epoch 45: Val Loss 4053873.50000
Epoch 46: Val Loss 4030094.25000
Epoch 47: Val Loss 4023292.75000
Epoch 48: Val Loss 4024682.00000
Epoch 49: Val Loss 4016542.00000
Epoch 50: Val Loss 4002886.25000
Epoch 51: Val Loss 4012187.00000
Epoch 52: Val Loss 4015840.50000
Epoch 53: Val Loss 3988120.75000
Epoch 54: Val Loss 4005342.25000
Epoch 55: Val Loss 4141234.25000
Epoch 56: Val Loss 3983430.25000
Epoch 57: Val Loss 3985109.75000
Epoch 58: Val Loss 3972540.75000
Epoch 59: Val Loss 3972752.00000
Epoch 60: Val Loss 3992522.00000
Epoch 61: Val Loss 3961770.00000
Epoch 62: Val Loss 3954286.00000
Epoch 63: Val Loss 3955024.00000
Epoch 64: Val Loss 3952580.50000
Epoch 65: Val Loss 3974628.50000
Epoch 66: Val Loss 3993004.25000
Epoch 67: Val Loss 3951360.50000
Epoch 68: Val Loss 3970611.50000
Epoch 69: Val Loss 3950952.25000
Epoch 70: Val Loss 3942115.50000
Epoch 71: Val Loss 3937833.50000
Epoch 72: Val Loss 3938784.00000
Epoch 73: Val Loss 3929417.25000
Epoch 74: Val Loss 3972074.00000
Epoch 75: Val Loss 3922718.75000
Epoch 76: Val Loss 3945954.75000
Epoch 77: Val Loss 3933160.25000
Epoch 78: Val Loss 3921298.75000
Epoch 79: Val Loss 3943287.00000
Epoch 80: Val Loss 3914472.25000
Epoch 81: Val Loss 3917274.50000
Epoch 82: Val Loss 3928522.50000
Epoch 83: Val Loss 3911932.75000
Epoch 84: Val Loss 3924313.25000
Epoch 85: Val Loss 3911873.50000
Epoch 86: Val Loss 3897259.25000
Epoch 87: Val Loss 3912017.75000
Epoch 88: Val Loss 3893537.00000
Epoch 89: Val Loss 3893669.75000
Epoch 90: Val Loss 3889664.00000
Epoch 91: Val Loss 3894311.50000
Epoch 92: Val Loss 3901809.50000
Epoch 93: Val Loss 3894688.50000
Epoch 94: Val Loss 3925529.50000
Epoch 95: Val Loss 3890290.75000
Epoch 96: Val Loss 3887818.00000
Epoch 97: Val Loss 3881608.75000
Epoch 98: Val Loss 3895651.50000
Epoch 99: Val Loss 3896790.50000
Saved Losses
{'MSE - mean': 3827983.2200582796, 'MSE - std': 223625.56534271574, 'R2 - mean': 0.5507946299356468, 'R2 - std': 0.012274640554493725} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8288082.50000
Epoch 1: Val Loss 7868250.00000
Epoch 2: Val Loss 7388252.50000
Epoch 3: Val Loss 6835377.00000
Epoch 4: Val Loss 6114892.50000
Epoch 5: Val Loss 5372585.50000
Epoch 6: Val Loss 4855806.00000
Epoch 7: Val Loss 4541884.00000
Epoch 8: Val Loss 4334921.50000
Epoch 9: Val Loss 4192856.00000
Epoch 10: Val Loss 4080374.25000
Epoch 11: Val Loss 3998451.00000
Epoch 12: Val Loss 3954030.75000
Epoch 13: Val Loss 3893598.25000
Epoch 14: Val Loss 3853501.50000
Epoch 15: Val Loss 3807024.50000
Epoch 16: Val Loss 3807748.50000
Epoch 17: Val Loss 3803616.50000
Epoch 18: Val Loss 3731667.50000
Epoch 19: Val Loss 3740107.00000
Epoch 20: Val Loss 3691105.75000
Epoch 21: Val Loss 3691490.75000
Epoch 22: Val Loss 3668933.75000
Epoch 23: Val Loss 3656279.00000
Epoch 24: Val Loss 3662519.00000
Epoch 25: Val Loss 3641350.25000
Epoch 26: Val Loss 3634068.50000
Epoch 27: Val Loss 3670880.00000
Epoch 28: Val Loss 3627635.50000
Epoch 29: Val Loss 3604575.50000
Epoch 30: Val Loss 3602071.75000
Epoch 31: Val Loss 3601023.75000
Epoch 32: Val Loss 3599878.00000
Epoch 33: Val Loss 3622350.50000
Epoch 34: Val Loss 3621921.50000
Epoch 35: Val Loss 3589970.00000
Epoch 36: Val Loss 3577170.50000
Epoch 37: Val Loss 3578668.75000
Epoch 38: Val Loss 3596384.50000
Epoch 39: Val Loss 3608764.75000
Epoch 40: Val Loss 3554923.00000
Epoch 41: Val Loss 3550475.75000
Epoch 42: Val Loss 3550977.25000
Epoch 43: Val Loss 3546211.25000
Epoch 44: Val Loss 3543683.50000
Epoch 45: Val Loss 3585999.50000
Epoch 46: Val Loss 3552247.75000
Epoch 47: Val Loss 3583049.00000
Epoch 48: Val Loss 3551955.25000
Epoch 49: Val Loss 3536038.75000
Epoch 50: Val Loss 3542460.75000
Epoch 51: Val Loss 3535987.75000
Epoch 52: Val Loss 3533885.00000
Epoch 53: Val Loss 3545682.75000
Epoch 54: Val Loss 3523768.75000
Epoch 55: Val Loss 3542219.00000
Epoch 56: Val Loss 3527809.00000
Epoch 57: Val Loss 3525522.75000
Epoch 58: Val Loss 3513279.50000
Epoch 59: Val Loss 3536618.25000
Epoch 60: Val Loss 3512460.50000
Epoch 61: Val Loss 3518197.50000
Epoch 62: Val Loss 3521954.00000
Epoch 63: Val Loss 3513373.00000
Epoch 64: Val Loss 3516303.50000
Epoch 65: Val Loss 3513682.50000
Epoch 66: Val Loss 3496760.75000
Epoch 67: Val Loss 3504309.75000
Epoch 68: Val Loss 3490045.75000
Epoch 69: Val Loss 3511632.25000
Epoch 70: Val Loss 3506309.50000
Epoch 71: Val Loss 3506097.00000
Epoch 72: Val Loss 3496140.75000
Epoch 73: Val Loss 3514415.25000
Epoch 74: Val Loss 3498471.75000
Epoch 75: Val Loss 3497636.50000
Epoch 76: Val Loss 3482637.00000
Epoch 77: Val Loss 3483584.75000
Epoch 78: Val Loss 3488642.75000
Epoch 79: Val Loss 3500389.00000
Epoch 80: Val Loss 3485619.25000
Epoch 81: Val Loss 3480260.50000
Epoch 82: Val Loss 3482327.50000
Epoch 83: Val Loss 3472619.75000
Epoch 84: Val Loss 3499054.25000
Epoch 85: Val Loss 3470719.00000
Epoch 86: Val Loss 3469896.00000
Epoch 87: Val Loss 3472543.25000
Epoch 88: Val Loss 3484735.25000
Epoch 89: Val Loss 3467501.75000
Epoch 90: Val Loss 3482951.25000
Epoch 91: Val Loss 3479934.25000
Epoch 92: Val Loss 3463346.75000
Epoch 93: Val Loss 3469960.75000
Epoch 94: Val Loss 3463508.50000
Epoch 95: Val Loss 3500168.50000
Epoch 96: Val Loss 3482042.75000
Epoch 97: Val Loss 3457427.25000
Epoch 98: Val Loss 3474203.75000
Epoch 99: Val Loss 3462335.25000
Saved Losses
{'MSE - mean': 3756605.1369802253, 'MSE - std': 245735.70712346642, 'R2 - mean': 0.5549146994952959, 'R2 - std': 0.013727102144990686} 
 

Saving model.....
Results After CV: {'MSE - mean': 3756605.1369802253, 'MSE - std': 245735.70712346642, 'R2 - mean': 0.5549146994952959, 'R2 - std': 0.013727102144990686}
Train time: 7262.1798618292
Inference time: 6.512577793595847
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 14 finished with value: 3756605.1369802253 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -4, 'learning_rate': -5, 'dropout': 0.2}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4527239.50000
Epoch 1: Val Loss 4097415.00000
Epoch 2: Val Loss 3974802.25000
Epoch 3: Val Loss 3902811.75000
Epoch 4: Val Loss 3868926.75000
Epoch 5: Val Loss 3830885.25000
Epoch 6: Val Loss 3775154.25000
Epoch 7: Val Loss 3751940.50000
Epoch 8: Val Loss 3720359.50000
Epoch 9: Val Loss 3700574.75000
Epoch 10: Val Loss 3671830.50000
Epoch 11: Val Loss 3659831.50000
Epoch 12: Val Loss 3650628.00000
Epoch 13: Val Loss 3636539.00000
Epoch 14: Val Loss 3623614.25000
Epoch 15: Val Loss 3585875.75000
Epoch 16: Val Loss 3576502.25000
Epoch 17: Val Loss 3568100.00000
Epoch 18: Val Loss 3577276.75000
Epoch 19: Val Loss 3563107.50000
Epoch 20: Val Loss 3550650.50000
Epoch 21: Val Loss 3538014.75000
Epoch 22: Val Loss 3522089.75000
Epoch 23: Val Loss 3519124.25000
Epoch 24: Val Loss 3541327.25000
Epoch 25: Val Loss 3570841.50000
Epoch 26: Val Loss 3501675.25000
Epoch 27: Val Loss 3491099.00000
Epoch 28: Val Loss 3483305.50000
Epoch 29: Val Loss 3607476.25000
Epoch 30: Val Loss 3486183.75000
Epoch 31: Val Loss 3477123.50000
Epoch 32: Val Loss 3478595.50000
Epoch 33: Val Loss 3480784.75000
Epoch 34: Val Loss 3495657.00000
Epoch 35: Val Loss 3461414.75000
Epoch 36: Val Loss 3483489.50000
Epoch 37: Val Loss 3437483.25000
Epoch 38: Val Loss 3446463.75000
Epoch 39: Val Loss 3457676.25000
Epoch 40: Val Loss 3450436.50000
Epoch 41: Val Loss 3442051.25000
Epoch 42: Val Loss 3442464.00000
Epoch 43: Val Loss 3454362.75000
Epoch 44: Val Loss 3436084.50000
Epoch 45: Val Loss 3445052.50000
Epoch 46: Val Loss 3451621.75000
Epoch 47: Val Loss 3419880.75000
Epoch 48: Val Loss 3443278.75000
Epoch 49: Val Loss 3457519.25000
Epoch 50: Val Loss 3422727.50000
Epoch 51: Val Loss 3448451.25000
Epoch 52: Val Loss 3439436.50000
Epoch 53: Val Loss 3437168.25000
Epoch 54: Val Loss 3421597.50000
Epoch 55: Val Loss 3479655.50000
Epoch 56: Val Loss 3421182.25000
Epoch 57: Val Loss 3421057.50000
Epoch 58: Val Loss 3441633.25000
Epoch 59: Val Loss 3530943.50000
Epoch 60: Val Loss 3457490.75000
Epoch 61: Val Loss 3412568.25000
Epoch 62: Val Loss 3423698.75000
Epoch 63: Val Loss 3484758.50000
Epoch 64: Val Loss 3421560.25000
Epoch 65: Val Loss 3459753.25000
Epoch 66: Val Loss 3454129.25000
Epoch 67: Val Loss 3422617.50000
Epoch 68: Val Loss 3437916.00000
Epoch 69: Val Loss 3439880.75000
Epoch 70: Val Loss 3451716.25000
Epoch 71: Val Loss 3442061.25000
Epoch 72: Val Loss 3464233.75000
Epoch 73: Val Loss 3483450.00000
Epoch 74: Val Loss 3457481.00000
Epoch 75: Val Loss 3464993.75000
Epoch 76: Val Loss 3471255.00000
Epoch 77: Val Loss 3469428.75000
Epoch 78: Val Loss 3496678.75000
Epoch 79: Val Loss 3510452.50000
Epoch 80: Val Loss 3532325.25000
Epoch 81: Val Loss 3504573.75000
Epoch 82: Val Loss 3488859.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3422876.470020087, 'MSE - std': 0.0, 'R2 - mean': 0.5989566381301046, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4250371.00000
Epoch 1: Val Loss 3882700.25000
Epoch 2: Val Loss 3781764.50000
Epoch 3: Val Loss 3744206.00000
Epoch 4: Val Loss 3706489.25000
Epoch 5: Val Loss 3669692.75000
Epoch 6: Val Loss 3621582.25000
Epoch 7: Val Loss 3616733.75000
Epoch 8: Val Loss 3597014.75000
Epoch 9: Val Loss 3565254.00000
Epoch 10: Val Loss 3583344.25000
Epoch 11: Val Loss 3569578.75000
Epoch 12: Val Loss 3559604.50000
Epoch 13: Val Loss 3512311.25000
Epoch 14: Val Loss 3511631.75000
Epoch 15: Val Loss 3503402.50000
Epoch 16: Val Loss 3493452.25000
Epoch 17: Val Loss 3495678.25000
Epoch 18: Val Loss 3483215.00000
Epoch 19: Val Loss 3462931.50000
Epoch 20: Val Loss 3460027.75000
Epoch 21: Val Loss 3465151.00000
Epoch 22: Val Loss 3457611.00000
Epoch 23: Val Loss 3446187.50000
Epoch 24: Val Loss 3444439.00000
Epoch 25: Val Loss 3440312.50000
Epoch 26: Val Loss 3435791.50000
Epoch 27: Val Loss 3436271.50000
Epoch 28: Val Loss 3425420.50000
Epoch 29: Val Loss 3425752.75000
Epoch 30: Val Loss 3427245.25000
Epoch 31: Val Loss 3448465.50000
Epoch 32: Val Loss 3421670.00000
Epoch 33: Val Loss 3411771.50000
Epoch 34: Val Loss 3438820.25000
Epoch 35: Val Loss 3409230.50000
Epoch 36: Val Loss 3469020.25000
Epoch 37: Val Loss 3401294.25000
Epoch 38: Val Loss 3451367.25000
Epoch 39: Val Loss 3424771.00000
Epoch 40: Val Loss 3419532.25000
Epoch 41: Val Loss 3427903.75000
Epoch 42: Val Loss 3401026.75000
Epoch 43: Val Loss 3385978.25000
Epoch 44: Val Loss 3400920.00000
Epoch 45: Val Loss 3437673.50000
Epoch 46: Val Loss 3431310.00000
Epoch 47: Val Loss 3401241.75000
Epoch 48: Val Loss 3402737.25000
Epoch 49: Val Loss 3399671.75000
Epoch 50: Val Loss 3405428.00000
Epoch 51: Val Loss 3400018.50000
Epoch 52: Val Loss 3448435.50000
Epoch 53: Val Loss 3466156.25000
Epoch 54: Val Loss 3502695.75000
Epoch 55: Val Loss 3444254.00000
Epoch 56: Val Loss 3401194.75000
Epoch 57: Val Loss 3401260.50000
Epoch 58: Val Loss 3401448.00000
Epoch 59: Val Loss 3398323.25000
Epoch 60: Val Loss 3418812.50000
Epoch 61: Val Loss 3437453.00000
Epoch 62: Val Loss 3395098.75000
Epoch 63: Val Loss 3442498.75000
Epoch 64: Val Loss 3418416.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3410180.2198824314, 'MSE - std': 12696.25013765553, 'R2 - mean': 0.5873452019119485, 'R2 - std': 0.01161143621815608} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5013845.50000
Epoch 1: Val Loss 4617557.50000
Epoch 2: Val Loss 4463506.00000
Epoch 3: Val Loss 4396438.50000
Epoch 4: Val Loss 4377768.50000
Epoch 5: Val Loss 4342274.00000
Epoch 6: Val Loss 4304457.50000
Epoch 7: Val Loss 4282677.50000
Epoch 8: Val Loss 4301820.50000
Epoch 9: Val Loss 4205034.50000
Epoch 10: Val Loss 4203596.00000
Epoch 11: Val Loss 4185213.50000
Epoch 12: Val Loss 4145440.50000
Epoch 13: Val Loss 4143321.25000
Epoch 14: Val Loss 4116857.25000
Epoch 15: Val Loss 4133872.00000
Epoch 16: Val Loss 4140964.75000
Epoch 17: Val Loss 4082758.50000
Epoch 18: Val Loss 4111390.00000
Epoch 19: Val Loss 4054523.00000
Epoch 20: Val Loss 4057212.25000
Epoch 21: Val Loss 4052841.25000
Epoch 22: Val Loss 4031723.25000
Epoch 23: Val Loss 4147229.50000
Epoch 24: Val Loss 4014656.50000
Epoch 25: Val Loss 4028865.75000
Epoch 26: Val Loss 4008097.75000
Epoch 27: Val Loss 3980657.75000
Epoch 28: Val Loss 4014962.25000
Epoch 29: Val Loss 3982400.00000
Epoch 30: Val Loss 3960586.00000
Epoch 31: Val Loss 3967314.25000
Epoch 32: Val Loss 3959788.25000
Epoch 33: Val Loss 3956155.25000
Epoch 34: Val Loss 3963852.75000
Epoch 35: Val Loss 3931813.75000
Epoch 36: Val Loss 3942314.50000
Epoch 37: Val Loss 3950236.25000
Epoch 38: Val Loss 3922950.25000
Epoch 39: Val Loss 3915736.75000
Epoch 40: Val Loss 3919428.50000
Epoch 41: Val Loss 3970015.75000
Epoch 42: Val Loss 3920452.75000
Epoch 43: Val Loss 3906936.75000
Epoch 44: Val Loss 3892426.00000
Epoch 45: Val Loss 3905134.25000
Epoch 46: Val Loss 3922329.50000
Epoch 47: Val Loss 3904502.25000
Epoch 48: Val Loss 3898049.50000
Epoch 49: Val Loss 3899671.50000
Epoch 50: Val Loss 3921255.00000
Epoch 51: Val Loss 3860382.25000
Epoch 52: Val Loss 3862714.50000
Epoch 53: Val Loss 3865650.75000
Epoch 54: Val Loss 3879315.50000
Epoch 55: Val Loss 3865118.75000
Epoch 56: Val Loss 3896810.50000
Epoch 57: Val Loss 3845719.00000
Epoch 58: Val Loss 3841225.50000
Epoch 59: Val Loss 3864417.50000
Epoch 60: Val Loss 3854446.25000
Epoch 61: Val Loss 3868581.25000
Epoch 62: Val Loss 3843972.00000
Epoch 63: Val Loss 3882675.50000
Epoch 64: Val Loss 3841604.50000
Epoch 65: Val Loss 3841540.75000
Epoch 66: Val Loss 3848375.00000
Epoch 67: Val Loss 3850498.25000
Epoch 68: Val Loss 3873974.50000
Epoch 69: Val Loss 3865417.50000
Epoch 70: Val Loss 3858292.00000
Epoch 71: Val Loss 3861160.25000
Epoch 72: Val Loss 3844521.50000
Epoch 73: Val Loss 3853113.50000
Epoch 74: Val Loss 3857745.75000
Epoch 75: Val Loss 3849272.75000
Epoch 76: Val Loss 3880433.75000
Epoch 77: Val Loss 3875353.25000
Epoch 78: Val Loss 3865971.50000
Epoch 79: Val Loss 3886315.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3558754.004258798, 'MSE - std': 210370.6300465967, 'R2 - mean': 0.5811128288133626, 'R2 - std': 0.012944828423434541} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4593977.00000
Epoch 1: Val Loss 4206981.00000
Epoch 2: Val Loss 4128245.25000
Epoch 3: Val Loss 4088680.25000
Epoch 4: Val Loss 4030254.00000
Epoch 5: Val Loss 4004719.75000
Epoch 6: Val Loss 3958216.75000
Epoch 7: Val Loss 3945168.00000
Epoch 8: Val Loss 3920135.50000
Epoch 9: Val Loss 3909674.00000
Epoch 10: Val Loss 3885544.25000
Epoch 11: Val Loss 3876491.00000
Epoch 12: Val Loss 3848348.75000
Epoch 13: Val Loss 3850215.00000
Epoch 14: Val Loss 3828610.75000
Epoch 15: Val Loss 3828156.25000
Epoch 16: Val Loss 3813205.75000
Epoch 17: Val Loss 3802355.00000
Epoch 18: Val Loss 3802971.00000
Epoch 19: Val Loss 3790427.00000
Epoch 20: Val Loss 3859435.00000
Epoch 21: Val Loss 3781793.75000
Epoch 22: Val Loss 3786484.50000
Epoch 23: Val Loss 3756929.00000
Epoch 24: Val Loss 3766075.25000
Epoch 25: Val Loss 3762047.75000
Epoch 26: Val Loss 3745969.50000
Epoch 27: Val Loss 3776121.50000
Epoch 28: Val Loss 3747212.75000
Epoch 29: Val Loss 3761255.00000
Epoch 30: Val Loss 3719678.25000
Epoch 31: Val Loss 3746049.75000
Epoch 32: Val Loss 3720458.00000
Epoch 33: Val Loss 3763166.75000
Epoch 34: Val Loss 3733399.75000
Epoch 35: Val Loss 3725458.25000
Epoch 36: Val Loss 3742422.25000
Epoch 37: Val Loss 3737776.00000
Epoch 38: Val Loss 3779900.75000
Epoch 39: Val Loss 3704640.00000
Epoch 40: Val Loss 3702318.75000
Epoch 41: Val Loss 3710898.75000
Epoch 42: Val Loss 3737639.00000
Epoch 43: Val Loss 3759812.75000
Epoch 44: Val Loss 3747766.50000
Epoch 45: Val Loss 3729694.75000
Epoch 46: Val Loss 3752824.75000
Epoch 47: Val Loss 3715696.50000
Epoch 48: Val Loss 3727423.75000
Epoch 49: Val Loss 3742158.75000
Epoch 50: Val Loss 3718095.75000
Epoch 51: Val Loss 3715308.25000
Epoch 52: Val Loss 3804495.25000
Epoch 53: Val Loss 3732135.00000
Epoch 54: Val Loss 3727729.75000
Epoch 55: Val Loss 3749784.75000
Epoch 56: Val Loss 3838684.75000
Epoch 57: Val Loss 3803879.00000
Epoch 58: Val Loss 3783327.25000
Epoch 59: Val Loss 3780689.00000
Epoch 60: Val Loss 3767464.00000
Epoch 61: Val Loss 3761783.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3597637.6131768776, 'MSE - std': 194236.08474517314, 'R2 - mean': 0.5776909152995349, 'R2 - std': 0.012680887724148835} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4099724.75000
Epoch 1: Val Loss 3707236.50000
Epoch 2: Val Loss 3622755.00000
Epoch 3: Val Loss 3592603.50000
Epoch 4: Val Loss 3558895.50000
Epoch 5: Val Loss 3664441.50000
Epoch 6: Val Loss 3513093.00000
Epoch 7: Val Loss 3486517.00000
Epoch 8: Val Loss 3472628.50000
Epoch 9: Val Loss 3490713.25000
Epoch 10: Val Loss 3472356.75000
Epoch 11: Val Loss 3436185.50000
Epoch 12: Val Loss 3449191.00000
Epoch 13: Val Loss 3425259.25000
Epoch 14: Val Loss 3464543.00000
Epoch 15: Val Loss 3425360.25000
Epoch 16: Val Loss 3408489.75000
Epoch 17: Val Loss 3449147.00000
Epoch 18: Val Loss 3414087.75000
Epoch 19: Val Loss 3398618.00000
Epoch 20: Val Loss 3395398.00000
Epoch 21: Val Loss 3380550.25000
Epoch 22: Val Loss 3396011.50000
Epoch 23: Val Loss 3405335.50000
Epoch 24: Val Loss 3439481.75000
Epoch 25: Val Loss 3423651.75000
Epoch 26: Val Loss 3393708.75000
Epoch 27: Val Loss 3423695.00000
Epoch 28: Val Loss 3473374.50000
Epoch 29: Val Loss 3374834.25000
Epoch 30: Val Loss 3409678.25000
Epoch 31: Val Loss 3424971.00000
Epoch 32: Val Loss 3394190.00000
Epoch 33: Val Loss 3389287.75000
Epoch 34: Val Loss 3401504.00000
Epoch 35: Val Loss 3400061.75000
Epoch 36: Val Loss 3416935.75000
Epoch 37: Val Loss 3430967.25000
Epoch 38: Val Loss 3403429.00000
Epoch 39: Val Loss 3425172.00000
Epoch 40: Val Loss 3442855.50000
Epoch 41: Val Loss 3425300.75000
Epoch 42: Val Loss 3432316.25000
Epoch 43: Val Loss 3393617.75000
Epoch 44: Val Loss 3388156.50000
Epoch 45: Val Loss 3426297.50000
Epoch 46: Val Loss 3405080.00000
Epoch 47: Val Loss 3438463.25000
Epoch 48: Val Loss 3443118.75000
Epoch 49: Val Loss 3477647.75000
Epoch 50: Val Loss 3433171.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554813.4499998116, 'MSE - std': 193695.0208471331, 'R2 - mean': 0.5785944770244035, 'R2 - std': 0.011485191593550588} 
 

Saving model.....
Results After CV: {'MSE - mean': 3554813.4499998116, 'MSE - std': 193695.0208471331, 'R2 - mean': 0.5785944770244035, 'R2 - std': 0.011485191593550588}
Train time: 4953.742017958604
Inference time: 6.41641801141086
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 15 finished with value: 3554813.4499998116 and parameters: {'dim': 256, 'depth': 12, 'heads': 4, 'weight_decay': -6, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8869234.00000
Epoch 1: Val Loss 8286396.00000
Epoch 2: Val Loss 7862362.00000
Epoch 3: Val Loss 7334406.00000
Epoch 4: Val Loss 6666225.50000
Epoch 5: Val Loss 5923903.50000
Epoch 6: Val Loss 5349529.00000
Epoch 7: Val Loss 4997168.50000
Epoch 8: Val Loss 4809519.50000
Epoch 9: Val Loss 4641976.00000
Epoch 10: Val Loss 4535537.50000
Epoch 11: Val Loss 4450213.00000
Epoch 12: Val Loss 4386416.00000
Epoch 13: Val Loss 4334848.50000
Epoch 14: Val Loss 4305524.50000
Epoch 15: Val Loss 4251845.50000
Epoch 16: Val Loss 4231846.00000
Epoch 17: Val Loss 4191156.50000
Epoch 18: Val Loss 4165561.50000
Epoch 19: Val Loss 4165923.50000
Epoch 20: Val Loss 4122254.75000
Epoch 21: Val Loss 4103029.75000
Epoch 22: Val Loss 4089974.50000
Epoch 23: Val Loss 4074604.75000
Epoch 24: Val Loss 4057723.25000
Epoch 25: Val Loss 4041741.00000
Epoch 26: Val Loss 4034127.75000
Epoch 27: Val Loss 4024213.75000
Epoch 28: Val Loss 4012003.50000
Epoch 29: Val Loss 4016367.25000
Epoch 30: Val Loss 3998575.25000
Epoch 31: Val Loss 4017784.25000
Epoch 32: Val Loss 4026552.75000
Epoch 33: Val Loss 3974985.25000
Epoch 34: Val Loss 3978306.75000
Epoch 35: Val Loss 3964725.75000
Epoch 36: Val Loss 3943329.75000
Epoch 37: Val Loss 3943507.50000
Epoch 38: Val Loss 3928254.00000
Epoch 39: Val Loss 3915989.25000
Epoch 40: Val Loss 3909630.00000
Epoch 41: Val Loss 3902026.00000
Epoch 42: Val Loss 3908258.25000
Epoch 43: Val Loss 3904993.75000
Epoch 44: Val Loss 3897404.75000
Epoch 45: Val Loss 3887257.50000
Epoch 46: Val Loss 3882287.25000
Epoch 47: Val Loss 3875850.50000
Epoch 48: Val Loss 3875719.00000
Epoch 49: Val Loss 3861714.25000
Epoch 50: Val Loss 3847586.75000
Epoch 51: Val Loss 3856318.00000
Epoch 52: Val Loss 3845891.50000
Epoch 53: Val Loss 3840467.50000
Epoch 54: Val Loss 3825088.50000
Epoch 55: Val Loss 3831865.50000
Epoch 56: Val Loss 3813329.00000
Epoch 57: Val Loss 3824120.75000
Epoch 58: Val Loss 3817014.25000
Epoch 59: Val Loss 3801034.50000
Epoch 60: Val Loss 3790587.75000
Epoch 61: Val Loss 3794963.50000
Epoch 62: Val Loss 3797212.75000
Epoch 63: Val Loss 3786483.00000
Epoch 64: Val Loss 3815307.75000
Epoch 65: Val Loss 3770186.50000
Epoch 66: Val Loss 3776037.75000
Epoch 67: Val Loss 3769229.00000
Epoch 68: Val Loss 3765439.25000
Epoch 69: Val Loss 3773707.00000
Epoch 70: Val Loss 3765241.25000
Epoch 71: Val Loss 3752519.50000
Epoch 72: Val Loss 3753574.25000
Epoch 73: Val Loss 3755518.00000
Epoch 74: Val Loss 3752297.50000
Epoch 75: Val Loss 3739913.50000
Epoch 76: Val Loss 3744607.25000
Epoch 77: Val Loss 3734772.75000
Epoch 78: Val Loss 3748513.75000
Epoch 79: Val Loss 3736042.50000
Epoch 80: Val Loss 3727432.25000
Epoch 81: Val Loss 3716038.50000
Epoch 82: Val Loss 3718042.00000
Epoch 83: Val Loss 3724790.25000
Epoch 84: Val Loss 3730428.75000
Epoch 85: Val Loss 3710562.25000
Epoch 86: Val Loss 3755893.25000
Epoch 87: Val Loss 3708815.25000
Epoch 88: Val Loss 3700048.50000
Epoch 89: Val Loss 3694694.25000
Epoch 90: Val Loss 3744839.50000
Epoch 91: Val Loss 3691473.00000
Epoch 92: Val Loss 3693407.25000
Epoch 93: Val Loss 3710135.00000
Epoch 94: Val Loss 3703751.00000
Epoch 95: Val Loss 3691184.00000
Epoch 96: Val Loss 3693538.25000
Epoch 97: Val Loss 3682862.00000
Epoch 98: Val Loss 3682267.00000
Epoch 99: Val Loss 3691454.75000
Saved Losses
{'MSE - mean': 3692128.4188727424, 'MSE - std': 0.0, 'R2 - mean': 0.5674095730508741, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8166820.50000
Epoch 1: Val Loss 7711900.00000
Epoch 2: Val Loss 7381926.00000
Epoch 3: Val Loss 6819448.00000
Epoch 4: Val Loss 6169095.50000
Epoch 5: Val Loss 5427314.00000
Epoch 6: Val Loss 4968741.50000
Epoch 7: Val Loss 4639241.50000
Epoch 8: Val Loss 4474432.50000
Epoch 9: Val Loss 4316036.50000
Epoch 10: Val Loss 4223259.50000
Epoch 11: Val Loss 4148838.50000
Epoch 12: Val Loss 4091063.00000
Epoch 13: Val Loss 4075458.75000
Epoch 14: Val Loss 4021346.75000
Epoch 15: Val Loss 3970498.75000
Epoch 16: Val Loss 3942414.75000
Epoch 17: Val Loss 3918237.50000
Epoch 18: Val Loss 3900449.75000
Epoch 19: Val Loss 3888894.75000
Epoch 20: Val Loss 3870964.00000
Epoch 21: Val Loss 3882743.50000
Epoch 22: Val Loss 3843922.75000
Epoch 23: Val Loss 3839364.50000
Epoch 24: Val Loss 3819235.50000
Epoch 25: Val Loss 3837669.25000
Epoch 26: Val Loss 3795064.00000
Epoch 27: Val Loss 3790426.00000
Epoch 28: Val Loss 3790370.75000
Epoch 29: Val Loss 3784272.00000
Epoch 30: Val Loss 3768321.00000
Epoch 31: Val Loss 3772280.25000
Epoch 32: Val Loss 3751393.50000
Epoch 33: Val Loss 3846341.75000
Epoch 34: Val Loss 3740526.75000
Epoch 35: Val Loss 3751853.00000
Epoch 36: Val Loss 3734667.00000
Epoch 37: Val Loss 3723614.75000
Epoch 38: Val Loss 3730826.00000
Epoch 39: Val Loss 3722952.75000
Epoch 40: Val Loss 3762524.25000
Epoch 41: Val Loss 3705203.50000
Epoch 42: Val Loss 3706396.75000
Epoch 43: Val Loss 3701461.75000
Epoch 44: Val Loss 3694227.50000
Epoch 45: Val Loss 3706607.75000
Epoch 46: Val Loss 3701553.75000
Epoch 47: Val Loss 3686093.50000
Epoch 48: Val Loss 3680651.00000
Epoch 49: Val Loss 3670987.25000
Epoch 50: Val Loss 3696735.25000
Epoch 51: Val Loss 3669188.00000
Epoch 52: Val Loss 3714733.50000
Epoch 53: Val Loss 3672026.00000
Epoch 54: Val Loss 3671125.75000
Epoch 55: Val Loss 3645742.75000
Epoch 56: Val Loss 3676943.75000
Epoch 57: Val Loss 3645073.50000
Epoch 58: Val Loss 3647417.25000
Epoch 59: Val Loss 3642926.00000
Epoch 60: Val Loss 3648043.75000
Epoch 61: Val Loss 3640731.25000
Epoch 62: Val Loss 3627825.50000
Epoch 63: Val Loss 3638027.75000
Epoch 64: Val Loss 3628512.50000
Epoch 65: Val Loss 3622411.75000
Epoch 66: Val Loss 3630843.00000
Epoch 67: Val Loss 3625597.25000
Epoch 68: Val Loss 3608748.75000
Epoch 69: Val Loss 3616266.50000
Epoch 70: Val Loss 3617964.75000
Epoch 71: Val Loss 3616177.50000
Epoch 72: Val Loss 3622863.75000
Epoch 73: Val Loss 3597561.75000
Epoch 74: Val Loss 3611524.25000
Epoch 75: Val Loss 3596579.00000
Epoch 76: Val Loss 3602119.50000
Epoch 77: Val Loss 3635377.75000
Epoch 78: Val Loss 3584177.00000
Epoch 79: Val Loss 3593935.25000
Epoch 80: Val Loss 3590358.50000
Epoch 81: Val Loss 3590548.00000
Epoch 82: Val Loss 3594286.50000
Epoch 83: Val Loss 3573796.50000
Epoch 84: Val Loss 3582986.50000
Epoch 85: Val Loss 3576410.00000
Epoch 86: Val Loss 3572591.75000
Epoch 87: Val Loss 3573912.50000
Epoch 88: Val Loss 3574057.00000
Epoch 89: Val Loss 3590029.25000
Epoch 90: Val Loss 3570631.75000
Epoch 91: Val Loss 3570438.75000
Epoch 92: Val Loss 3569355.00000
Epoch 93: Val Loss 3570858.25000
Epoch 94: Val Loss 4072980.50000
Epoch 95: Val Loss 3556911.00000
Epoch 96: Val Loss 3634208.50000
Epoch 97: Val Loss 3605106.00000
Epoch 98: Val Loss 3565974.25000
Epoch 99: Val Loss 3547380.75000
Saved Losses
{'MSE - mean': 3625494.305850924, 'MSE - std': 66634.11302181822, 'R2 - mean': 0.5614956126367823, 'R2 - std': 0.005913960414091868} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9334149.00000
Epoch 1: Val Loss 8686956.00000
Epoch 2: Val Loss 8315281.50000
Epoch 3: Val Loss 7837890.00000
Epoch 4: Val Loss 7144230.50000
Epoch 5: Val Loss 6380498.50000
Epoch 6: Val Loss 5816556.50000
Epoch 7: Val Loss 5483102.00000
Epoch 8: Val Loss 5253797.50000
Epoch 9: Val Loss 5102688.50000
Epoch 10: Val Loss 4992627.50000
Epoch 11: Val Loss 4921865.00000
Epoch 12: Val Loss 4855905.50000
Epoch 13: Val Loss 4798647.00000
Epoch 14: Val Loss 4771727.00000
Epoch 15: Val Loss 4730684.00000
Epoch 16: Val Loss 4693643.00000
Epoch 17: Val Loss 4665128.00000
Epoch 18: Val Loss 4641635.50000
Epoch 19: Val Loss 4648797.00000
Epoch 20: Val Loss 4605059.00000
Epoch 21: Val Loss 4578369.00000
Epoch 22: Val Loss 4573552.50000
Epoch 23: Val Loss 4536861.50000
Epoch 24: Val Loss 4555586.00000
Epoch 25: Val Loss 4518748.00000
Epoch 26: Val Loss 4504590.50000
Epoch 27: Val Loss 4497972.50000
Epoch 28: Val Loss 4481415.00000
Epoch 29: Val Loss 4470441.50000
Epoch 30: Val Loss 4473593.50000
Epoch 31: Val Loss 4452468.00000
Epoch 32: Val Loss 4444316.00000
Epoch 33: Val Loss 4458454.00000
Epoch 34: Val Loss 4435469.50000
Epoch 35: Val Loss 4418287.50000
Epoch 36: Val Loss 4425381.50000
Epoch 37: Val Loss 4428084.50000
Epoch 38: Val Loss 4421703.00000
Epoch 39: Val Loss 4394748.50000
Epoch 40: Val Loss 4412907.50000
Epoch 41: Val Loss 4394654.00000
Epoch 42: Val Loss 4382122.50000
Epoch 43: Val Loss 4372256.00000
Epoch 44: Val Loss 4366056.00000
Epoch 45: Val Loss 4368920.00000
Epoch 46: Val Loss 4370986.00000
Epoch 47: Val Loss 4798833.00000
Epoch 48: Val Loss 4347381.00000
Epoch 49: Val Loss 4347796.50000
Epoch 50: Val Loss 4337640.00000
Epoch 51: Val Loss 4335326.00000
Epoch 52: Val Loss 4417471.00000
Epoch 53: Val Loss 4339514.50000
Epoch 54: Val Loss 4315254.50000
Epoch 55: Val Loss 4312926.50000
Epoch 56: Val Loss 4310709.50000
Epoch 57: Val Loss 4303458.50000
Epoch 58: Val Loss 4304377.50000
Epoch 59: Val Loss 4298834.50000
Epoch 60: Val Loss 4311214.00000
Epoch 61: Val Loss 4286514.50000
Epoch 62: Val Loss 4285119.00000
Epoch 63: Val Loss 4284355.00000
Epoch 64: Val Loss 4273404.00000
Epoch 65: Val Loss 4293983.00000
Epoch 66: Val Loss 4290555.00000
Epoch 67: Val Loss 4273919.00000
Epoch 68: Val Loss 4268205.00000
Epoch 69: Val Loss 4254473.00000
Epoch 70: Val Loss 4264774.50000
Epoch 71: Val Loss 4259107.00000
Epoch 72: Val Loss 4281140.50000
Epoch 73: Val Loss 4267957.00000
Epoch 74: Val Loss 4237125.50000
Epoch 75: Val Loss 4263401.00000
Epoch 76: Val Loss 4245179.00000
Epoch 77: Val Loss 4253155.50000
Epoch 78: Val Loss 4229285.50000
Epoch 79: Val Loss 4245370.50000
Epoch 80: Val Loss 4235612.00000
Epoch 81: Val Loss 4225945.00000
Epoch 82: Val Loss 4225429.50000
Epoch 83: Val Loss 4222245.00000
Epoch 84: Val Loss 4209727.50000
Epoch 85: Val Loss 4231296.50000
Epoch 86: Val Loss 4219746.50000
Epoch 87: Val Loss 4217182.50000
Epoch 88: Val Loss 4209320.00000
Epoch 89: Val Loss 4199691.00000
Epoch 90: Val Loss 4203489.50000
Epoch 91: Val Loss 4196527.50000
Epoch 92: Val Loss 4208248.50000
Epoch 93: Val Loss 4195056.00000
Epoch 94: Val Loss 4197600.00000
Epoch 95: Val Loss 4205841.00000
Epoch 96: Val Loss 4181662.75000
Epoch 97: Val Loss 4244240.50000
Epoch 98: Val Loss 4186697.25000
Epoch 99: Val Loss 4200428.50000
Saved Losses
{'MSE - mean': 3816883.867868483, 'MSE - std': 276079.6966650793, 'R2 - mean': 0.5510611375314022, 'R2 - std': 0.015526530841408879} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8996803.00000
Epoch 1: Val Loss 8338537.00000
Epoch 2: Val Loss 7941310.50000
Epoch 3: Val Loss 7496913.50000
Epoch 4: Val Loss 6812627.50000
Epoch 5: Val Loss 6108173.00000
Epoch 6: Val Loss 5551724.00000
Epoch 7: Val Loss 5146624.50000
Epoch 8: Val Loss 4927725.50000
Epoch 9: Val Loss 4735375.00000
Epoch 10: Val Loss 4621161.50000
Epoch 11: Val Loss 4525258.50000
Epoch 12: Val Loss 4468304.50000
Epoch 13: Val Loss 4414874.50000
Epoch 14: Val Loss 4430377.00000
Epoch 15: Val Loss 4348015.50000
Epoch 16: Val Loss 4301085.00000
Epoch 17: Val Loss 4279989.50000
Epoch 18: Val Loss 4266142.50000
Epoch 19: Val Loss 4226880.50000
Epoch 20: Val Loss 4219429.50000
Epoch 21: Val Loss 4206531.50000
Epoch 22: Val Loss 4373925.50000
Epoch 23: Val Loss 4194080.00000
Epoch 24: Val Loss 4206167.00000
Epoch 25: Val Loss 4151637.75000
Epoch 26: Val Loss 4156336.50000
Epoch 27: Val Loss 4137410.25000
Epoch 28: Val Loss 4128620.75000
Epoch 29: Val Loss 4129983.25000
Epoch 30: Val Loss 4127154.25000
Epoch 31: Val Loss 4116259.50000
Epoch 32: Val Loss 4095743.75000
Epoch 33: Val Loss 4103333.75000
Epoch 34: Val Loss 4097855.75000
Epoch 35: Val Loss 4079618.25000
Epoch 36: Val Loss 4096952.75000
Epoch 37: Val Loss 4072472.25000
Epoch 38: Val Loss 4068785.50000
Epoch 39: Val Loss 4060433.00000
Epoch 40: Val Loss 4061438.00000
Epoch 41: Val Loss 4050564.00000
Epoch 42: Val Loss 4044064.00000
Epoch 43: Val Loss 4039966.25000
Epoch 44: Val Loss 4035798.50000
Epoch 45: Val Loss 4038125.50000
Epoch 46: Val Loss 4016097.50000
Epoch 47: Val Loss 4030198.25000
Epoch 48: Val Loss 4008484.50000
Epoch 49: Val Loss 4006527.75000
Epoch 50: Val Loss 4091151.75000
Epoch 51: Val Loss 3999765.25000
Epoch 52: Val Loss 3998104.25000
Epoch 53: Val Loss 3997469.50000
Epoch 54: Val Loss 3993037.50000
Epoch 55: Val Loss 3988396.25000
Epoch 56: Val Loss 3978798.75000
Epoch 57: Val Loss 3985937.50000
Epoch 58: Val Loss 4021715.00000
Epoch 59: Val Loss 3975383.00000
Epoch 60: Val Loss 3969569.00000
Epoch 61: Val Loss 3981383.00000
Epoch 62: Val Loss 3990674.75000
Epoch 63: Val Loss 3956765.00000
Epoch 64: Val Loss 3962200.75000
Epoch 65: Val Loss 3956043.75000
Epoch 66: Val Loss 4018550.25000
Epoch 67: Val Loss 3953272.00000
Epoch 68: Val Loss 3940606.25000
Epoch 69: Val Loss 3942260.50000
Epoch 70: Val Loss 3943721.50000
Epoch 71: Val Loss 3929237.75000
Epoch 72: Val Loss 3929605.25000
Epoch 73: Val Loss 3931086.75000
Epoch 74: Val Loss 3949025.75000
Epoch 75: Val Loss 4027769.25000
Epoch 76: Val Loss 3939101.00000
Epoch 77: Val Loss 3930376.25000
Epoch 78: Val Loss 3920382.25000
Epoch 79: Val Loss 3933764.50000
Epoch 80: Val Loss 3922912.50000
Epoch 81: Val Loss 3904138.00000
Epoch 82: Val Loss 3907075.50000
Epoch 83: Val Loss 4052723.50000
Epoch 84: Val Loss 3894958.75000
Epoch 85: Val Loss 3895790.75000
Epoch 86: Val Loss 3908411.75000
Epoch 87: Val Loss 3893574.50000
Epoch 88: Val Loss 3892432.00000
Epoch 89: Val Loss 3926719.75000
Epoch 90: Val Loss 3887419.75000
Epoch 91: Val Loss 3892043.00000
Epoch 92: Val Loss 3882751.25000
Epoch 93: Val Loss 3886831.75000
Epoch 94: Val Loss 3880482.75000
Epoch 95: Val Loss 3880875.25000
Epoch 96: Val Loss 3875530.00000
Epoch 97: Val Loss 3899407.75000
Epoch 98: Val Loss 3881172.00000
Epoch 99: Val Loss 3901766.50000
Saved Losses
{'MSE - mean': 3835253.1179599045, 'MSE - std': 241199.68331192975, 'R2 - mean': 0.5500256938757491, 'R2 - std': 0.013565445096605313} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8317225.00000
Epoch 1: Val Loss 7787625.00000
Epoch 2: Val Loss 7472604.50000
Epoch 3: Val Loss 6863708.50000
Epoch 4: Val Loss 6189614.00000
Epoch 5: Val Loss 5446513.50000
Epoch 6: Val Loss 4921625.50000
Epoch 7: Val Loss 4597323.00000
Epoch 8: Val Loss 4400523.50000
Epoch 9: Val Loss 4248330.50000
Epoch 10: Val Loss 4137083.75000
Epoch 11: Val Loss 4111265.50000
Epoch 12: Val Loss 4010170.00000
Epoch 13: Val Loss 3963429.25000
Epoch 14: Val Loss 3920793.50000
Epoch 15: Val Loss 3884616.25000
Epoch 16: Val Loss 3845152.00000
Epoch 17: Val Loss 3844403.00000
Epoch 18: Val Loss 3807284.75000
Epoch 19: Val Loss 3783741.00000
Epoch 20: Val Loss 3754624.50000
Epoch 21: Val Loss 3746781.50000
Epoch 22: Val Loss 3742352.00000
Epoch 23: Val Loss 3710862.25000
Epoch 24: Val Loss 3705330.25000
Epoch 25: Val Loss 3688464.50000
Epoch 26: Val Loss 3686109.00000
Epoch 27: Val Loss 3663576.25000
Epoch 28: Val Loss 3656822.25000
Epoch 29: Val Loss 3681043.00000
Epoch 30: Val Loss 3645792.50000
Epoch 31: Val Loss 3638999.75000
Epoch 32: Val Loss 3678747.00000
Epoch 33: Val Loss 3635356.25000
Epoch 34: Val Loss 3630070.25000
Epoch 35: Val Loss 3611907.25000
Epoch 36: Val Loss 3603447.75000
Epoch 37: Val Loss 3597196.00000
Epoch 38: Val Loss 3596681.50000
Epoch 39: Val Loss 3597483.00000
Epoch 40: Val Loss 3593494.25000
Epoch 41: Val Loss 3576601.50000
Epoch 42: Val Loss 3577589.25000
Epoch 43: Val Loss 3571598.50000
Epoch 44: Val Loss 3574383.75000
Epoch 45: Val Loss 3565676.50000
Epoch 46: Val Loss 3570768.00000
Epoch 47: Val Loss 3551915.25000
Epoch 48: Val Loss 3549873.50000
Epoch 49: Val Loss 3543048.50000
Epoch 50: Val Loss 3535371.00000
Epoch 51: Val Loss 3544960.75000
Epoch 52: Val Loss 3530606.25000
Epoch 53: Val Loss 3532720.00000
Epoch 54: Val Loss 3527278.25000
Epoch 55: Val Loss 3539948.75000
Epoch 56: Val Loss 3530516.25000
Epoch 57: Val Loss 3521951.75000
Epoch 58: Val Loss 3543929.50000
Epoch 59: Val Loss 3516287.75000
Epoch 60: Val Loss 3521159.00000
Epoch 61: Val Loss 3512962.50000
Epoch 62: Val Loss 3529344.25000
Epoch 63: Val Loss 3506818.25000
Epoch 64: Val Loss 3510169.25000
Epoch 65: Val Loss 3522313.00000
Epoch 66: Val Loss 3499701.50000
Epoch 67: Val Loss 3489730.25000
Epoch 68: Val Loss 3490541.50000
Epoch 69: Val Loss 3487835.75000
Epoch 70: Val Loss 3499024.00000
Epoch 71: Val Loss 3485116.25000
Epoch 72: Val Loss 3483700.50000
Epoch 73: Val Loss 3487899.75000
Epoch 74: Val Loss 3494156.75000
Epoch 75: Val Loss 3485233.50000
Epoch 76: Val Loss 3481238.00000
Epoch 77: Val Loss 3479064.25000
Epoch 78: Val Loss 3472246.00000
Epoch 79: Val Loss 3481704.25000
Epoch 80: Val Loss 3468974.00000
Epoch 81: Val Loss 3466126.25000
Epoch 82: Val Loss 3483788.00000
Epoch 83: Val Loss 3462180.50000
Epoch 84: Val Loss 3487091.00000
Epoch 85: Val Loss 3457985.00000
Epoch 86: Val Loss 3455657.50000
Epoch 87: Val Loss 3476476.25000
Epoch 88: Val Loss 3469075.00000
Epoch 89: Val Loss 3475118.75000
Epoch 90: Val Loss 3455231.50000
Epoch 91: Val Loss 3486690.75000
Epoch 92: Val Loss 3466335.75000
Epoch 93: Val Loss 3455930.75000
Epoch 94: Val Loss 3451559.25000
Epoch 95: Val Loss 3459652.25000
Epoch 96: Val Loss 3452452.25000
Epoch 97: Val Loss 3448207.75000
Epoch 98: Val Loss 3467489.50000
Epoch 99: Val Loss 3457733.25000
Saved Losses
{'MSE - mean': 3759075.1755647226, 'MSE - std': 264110.10093155183, 'R2 - mean': 0.5547126945590481, 'R2 - std': 0.01533261041558796} 
 

Saving model.....
Results After CV: {'MSE - mean': 3759075.1755647226, 'MSE - std': 264110.10093155183, 'R2 - mean': 0.5547126945590481, 'R2 - std': 0.01533261041558796}
Train time: 7233.721671922802
Inference time: 6.457786031003343
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 16 finished with value: 3759075.1755647226 and parameters: {'dim': 128, 'depth': 3, 'heads': 2, 'weight_decay': -5, 'learning_rate': -5, 'dropout': 0.5}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3896708.00000
Epoch 1: Val Loss 3779599.75000
Epoch 2: Val Loss 3635565.50000
Epoch 3: Val Loss 3631579.75000
Epoch 4: Val Loss 3595306.25000
Epoch 5: Val Loss 3508240.50000
Epoch 6: Val Loss 3536273.25000
Epoch 7: Val Loss 3456592.75000
Epoch 8: Val Loss 3443515.25000
Epoch 9: Val Loss 3439159.75000
Epoch 10: Val Loss 3527999.75000
Epoch 11: Val Loss 3601045.00000
Epoch 12: Val Loss 3591361.50000
Epoch 13: Val Loss 3481164.50000
Epoch 14: Val Loss 3570844.50000
Epoch 15: Val Loss 3548125.50000
Epoch 16: Val Loss 3745858.75000
Epoch 17: Val Loss 3765207.50000
Epoch 18: Val Loss 3844021.75000
Epoch 19: Val Loss 3836038.50000
Epoch 20: Val Loss 3920123.25000
Epoch 21: Val Loss 3906161.75000
Epoch 22: Val Loss 3968641.75000
Epoch 23: Val Loss 4085581.00000
Epoch 24: Val Loss 4108849.50000
Epoch 25: Val Loss 4174916.50000
Epoch 26: Val Loss 4213228.50000
Epoch 27: Val Loss 4310814.00000
Epoch 28: Val Loss 4259784.00000
Epoch 29: Val Loss 4359919.00000
Epoch 30: Val Loss 4385760.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3443807.9440734778, 'MSE - std': 0.0, 'R2 - mean': 0.5965041894961008, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3726822.25000
Epoch 1: Val Loss 3644169.50000
Epoch 2: Val Loss 3634460.75000
Epoch 3: Val Loss 3509106.50000
Epoch 4: Val Loss 3475017.25000
Epoch 5: Val Loss 3498073.75000
Epoch 6: Val Loss 3611610.75000
Epoch 7: Val Loss 3408163.00000
Epoch 8: Val Loss 3464242.50000
Epoch 9: Val Loss 3443386.25000
Epoch 10: Val Loss 3480887.00000
Epoch 11: Val Loss 3468547.00000
Epoch 12: Val Loss 3422972.75000
Epoch 13: Val Loss 3561060.00000
Epoch 14: Val Loss 3558686.50000
Epoch 15: Val Loss 3536569.00000
Epoch 16: Val Loss 3893944.75000
Epoch 17: Val Loss 3677462.25000
Epoch 18: Val Loss 3718173.00000
Epoch 19: Val Loss 3699177.25000
Epoch 20: Val Loss 3790094.75000
Epoch 21: Val Loss 3921534.25000
Epoch 22: Val Loss 3887950.25000
Epoch 23: Val Loss 3963068.25000
Epoch 24: Val Loss 3964929.75000
Epoch 25: Val Loss 4104180.50000
Epoch 26: Val Loss 4170473.25000
Epoch 27: Val Loss 4117678.00000
Epoch 28: Val Loss 4266581.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3426218.515826396, 'MSE - std': 17589.42824708158, 'R2 - mean': 0.5854230954043804, 'R2 - std': 0.011081094091720367} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4326568.00000
Epoch 1: Val Loss 4455707.00000
Epoch 2: Val Loss 4207469.50000
Epoch 3: Val Loss 4153350.50000
Epoch 4: Val Loss 4075851.00000
Epoch 5: Val Loss 4006241.00000
Epoch 6: Val Loss 3987755.25000
Epoch 7: Val Loss 3971484.75000
Epoch 8: Val Loss 3902383.75000
Epoch 9: Val Loss 3921320.25000
Epoch 10: Val Loss 3890814.00000
Epoch 11: Val Loss 3971691.00000
Epoch 12: Val Loss 3901669.25000
Epoch 13: Val Loss 3905549.00000
Epoch 14: Val Loss 4218914.50000
Epoch 15: Val Loss 3971016.25000
Epoch 16: Val Loss 4009630.25000
Epoch 17: Val Loss 4047790.25000
Epoch 18: Val Loss 4099240.00000
Epoch 19: Val Loss 4161283.50000
Epoch 20: Val Loss 4210632.00000
Epoch 21: Val Loss 4319556.50000
Epoch 22: Val Loss 4377361.50000
Epoch 23: Val Loss 4461059.50000
Epoch 24: Val Loss 4519603.00000
Epoch 25: Val Loss 4618786.50000
Epoch 26: Val Loss 4667628.50000
Epoch 27: Val Loss 4627036.50000
Epoch 28: Val Loss 4760751.00000
Epoch 29: Val Loss 4710067.00000
Epoch 30: Val Loss 4793325.00000
Epoch 31: Val Loss 4873620.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3582911.9470830876, 'MSE - std': 222062.87725633904, 'R2 - mean': 0.5783250387328541, 'R2 - std': 0.01351389092270516} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4048672.00000
Epoch 1: Val Loss 4053194.50000
Epoch 2: Val Loss 3934756.50000
Epoch 3: Val Loss 3931230.25000
Epoch 4: Val Loss 3931135.75000
Epoch 5: Val Loss 3812865.00000
Epoch 6: Val Loss 3958327.50000
Epoch 7: Val Loss 3837242.50000
Epoch 8: Val Loss 3842420.00000
Epoch 9: Val Loss 3825724.75000
Epoch 10: Val Loss 3853072.50000
Epoch 11: Val Loss 3975227.00000
Epoch 12: Val Loss 3937693.50000
Epoch 13: Val Loss 4127919.25000
Epoch 14: Val Loss 4062260.75000
Epoch 15: Val Loss 4104214.25000
Epoch 16: Val Loss 4227310.00000
Epoch 17: Val Loss 4400277.00000
Epoch 18: Val Loss 4346819.50000
Epoch 19: Val Loss 4284608.50000
Epoch 20: Val Loss 4459446.50000
Epoch 21: Val Loss 4405802.00000
Epoch 22: Val Loss 4628735.50000
Epoch 23: Val Loss 4552522.50000
Epoch 24: Val Loss 4641961.00000
Epoch 25: Val Loss 4791553.00000
Epoch 26: Val Loss 4779593.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3635048.2275286536, 'MSE - std': 212458.26956750583, 'R2 - mean': 0.5733532624338125, 'R2 - std': 0.01453012782484097} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3599705.50000
Epoch 1: Val Loss 3552630.25000
Epoch 2: Val Loss 3489254.50000
Epoch 3: Val Loss 3499387.25000
Epoch 4: Val Loss 3508200.50000
Epoch 5: Val Loss 3475314.50000
Epoch 6: Val Loss 3394805.75000
Epoch 7: Val Loss 3440597.50000
Epoch 8: Val Loss 3472972.50000
Epoch 9: Val Loss 3492885.00000
Epoch 10: Val Loss 3397268.00000
Epoch 11: Val Loss 3406101.75000
Epoch 12: Val Loss 3623847.75000
Epoch 13: Val Loss 3446600.00000
Epoch 14: Val Loss 3456544.75000
Epoch 15: Val Loss 3488368.00000
Epoch 16: Val Loss 3568260.75000
Epoch 17: Val Loss 3559379.50000
Epoch 18: Val Loss 3610585.50000
Epoch 19: Val Loss 3747573.25000
Epoch 20: Val Loss 3712208.50000
Epoch 21: Val Loss 3836835.00000
Epoch 22: Val Loss 3876558.00000
Epoch 23: Val Loss 3949182.75000
Epoch 24: Val Loss 4001381.75000
Epoch 25: Val Loss 4026767.75000
Epoch 26: Val Loss 4005397.25000
Epoch 27: Val Loss 4123153.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3588834.559394808, 'MSE - std': 211314.04481395954, 'R2 - mean': 0.5746190047770171, 'R2 - std': 0.01324039676152113} 
 

Saving model.....
Results After CV: {'MSE - mean': 3588834.559394808, 'MSE - std': 211314.04481395954, 'R2 - mean': 0.5746190047770171, 'R2 - std': 0.01324039676152113}
Train time: 2108.970043416991
Inference time: 6.297820429201238
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 17 finished with value: 3588834.559394808 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -4, 'learning_rate': -3, 'dropout': 0.3}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4505041.50000
Epoch 1: Val Loss 4076306.25000
Epoch 2: Val Loss 3961720.25000
Epoch 3: Val Loss 3909633.50000
Epoch 4: Val Loss 3850479.25000
Epoch 5: Val Loss 3839923.50000
Epoch 6: Val Loss 3782658.25000
Epoch 7: Val Loss 3726756.00000
Epoch 8: Val Loss 3758990.75000
Epoch 9: Val Loss 3682622.00000
Epoch 10: Val Loss 3713881.50000
Epoch 11: Val Loss 3650046.25000
Epoch 12: Val Loss 3639413.25000
Epoch 13: Val Loss 3621021.50000
Epoch 14: Val Loss 3595124.75000
Epoch 15: Val Loss 3603123.00000
Epoch 16: Val Loss 3581312.75000
Epoch 17: Val Loss 3623869.75000
Epoch 18: Val Loss 3556110.75000
Epoch 19: Val Loss 3540825.50000
Epoch 20: Val Loss 3552956.75000
Epoch 21: Val Loss 3532016.00000
Epoch 22: Val Loss 3537175.75000
Epoch 23: Val Loss 3548668.00000
Epoch 24: Val Loss 3516998.25000
Epoch 25: Val Loss 3500705.75000
Epoch 26: Val Loss 3529921.25000
Epoch 27: Val Loss 3498817.50000
Epoch 28: Val Loss 3504798.25000
Epoch 29: Val Loss 3481771.00000
Epoch 30: Val Loss 3492179.50000
Epoch 31: Val Loss 3492621.75000
Epoch 32: Val Loss 3476155.25000
Epoch 33: Val Loss 3474946.00000
Epoch 34: Val Loss 3460353.00000
Epoch 35: Val Loss 3452321.75000
Epoch 36: Val Loss 3484534.50000
Epoch 37: Val Loss 3469146.75000
Epoch 38: Val Loss 3494277.25000
Epoch 39: Val Loss 3482585.75000
Epoch 40: Val Loss 3470027.25000
Epoch 41: Val Loss 3492714.25000
Epoch 42: Val Loss 3442535.00000
Epoch 43: Val Loss 3427679.00000
Epoch 44: Val Loss 3452607.75000
Epoch 45: Val Loss 3430241.50000
Epoch 46: Val Loss 3442413.00000
Epoch 47: Val Loss 3442118.50000
Epoch 48: Val Loss 3429571.50000
Epoch 49: Val Loss 3431217.00000
Epoch 50: Val Loss 3423817.00000
Epoch 51: Val Loss 3433601.75000
Epoch 52: Val Loss 3425400.00000
Epoch 53: Val Loss 3413498.25000
Epoch 54: Val Loss 3473743.75000
Epoch 55: Val Loss 3423547.50000
Epoch 56: Val Loss 3444695.25000
Epoch 57: Val Loss 3437551.00000
Epoch 58: Val Loss 3418543.25000
Epoch 59: Val Loss 3410557.50000
Epoch 60: Val Loss 3455554.00000
Epoch 61: Val Loss 3432744.50000
Epoch 62: Val Loss 3449204.25000
Epoch 63: Val Loss 3421262.00000
Epoch 64: Val Loss 3455990.75000
Epoch 65: Val Loss 3432918.25000
Epoch 66: Val Loss 3475433.75000
Epoch 67: Val Loss 3450028.00000
Epoch 68: Val Loss 3490731.00000
Epoch 69: Val Loss 3480356.00000
Epoch 70: Val Loss 3442935.75000
Epoch 71: Val Loss 3507754.50000
Epoch 72: Val Loss 3454948.25000
Epoch 73: Val Loss 3506645.00000
Epoch 74: Val Loss 3520223.25000
Epoch 75: Val Loss 3500701.50000
Epoch 76: Val Loss 3481356.75000
Epoch 77: Val Loss 3523932.75000
Epoch 78: Val Loss 3486593.25000
Epoch 79: Val Loss 3495521.50000
Epoch 80: Val Loss 3457170.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3424500.574730432, 'MSE - std': 0.0, 'R2 - mean': 0.5987663489336436, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4218341.50000
Epoch 1: Val Loss 3895096.00000
Epoch 2: Val Loss 3771480.75000
Epoch 3: Val Loss 3744242.25000
Epoch 4: Val Loss 3691030.50000
Epoch 5: Val Loss 3660827.75000
Epoch 6: Val Loss 3664338.25000
Epoch 7: Val Loss 3626118.50000
Epoch 8: Val Loss 3634367.75000
Epoch 9: Val Loss 3586119.50000
Epoch 10: Val Loss 3565786.75000
Epoch 11: Val Loss 3560643.50000
Epoch 12: Val Loss 3542224.75000
Epoch 13: Val Loss 3533569.50000
Epoch 14: Val Loss 3522383.75000
Epoch 15: Val Loss 3553637.25000
Epoch 16: Val Loss 3522593.50000
Epoch 17: Val Loss 3491676.75000
Epoch 18: Val Loss 3495182.75000
Epoch 19: Val Loss 3485636.00000
Epoch 20: Val Loss 3463107.00000
Epoch 21: Val Loss 3468294.75000
Epoch 22: Val Loss 3449764.50000
Epoch 23: Val Loss 3490167.75000
Epoch 24: Val Loss 3456266.75000
Epoch 25: Val Loss 3443664.75000
Epoch 26: Val Loss 3429531.00000
Epoch 27: Val Loss 3436023.25000
Epoch 28: Val Loss 3438427.50000
Epoch 29: Val Loss 3456761.50000
Epoch 30: Val Loss 3535133.25000
Epoch 31: Val Loss 3433068.50000
Epoch 32: Val Loss 3417962.00000
Epoch 33: Val Loss 3466993.50000
Epoch 34: Val Loss 3448414.00000
Epoch 35: Val Loss 3422218.50000
Epoch 36: Val Loss 3460419.25000
Epoch 37: Val Loss 3414861.50000
Epoch 38: Val Loss 3403737.50000
Epoch 39: Val Loss 3518959.25000
Epoch 40: Val Loss 3410125.50000
Epoch 41: Val Loss 3441299.50000
Epoch 42: Val Loss 3420052.25000
Epoch 43: Val Loss 3397289.25000
Epoch 44: Val Loss 3384867.75000
Epoch 45: Val Loss 3445405.00000
Epoch 46: Val Loss 3384468.25000
Epoch 47: Val Loss 3395096.25000
Epoch 48: Val Loss 3407298.50000
Epoch 49: Val Loss 3405808.50000
Epoch 50: Val Loss 3410865.75000
Epoch 51: Val Loss 3378515.50000
Epoch 52: Val Loss 3413737.50000
Epoch 53: Val Loss 3448465.25000
Epoch 54: Val Loss 3400277.50000
Epoch 55: Val Loss 3504319.00000
Epoch 56: Val Loss 3408840.00000
Epoch 57: Val Loss 3434993.25000
Epoch 58: Val Loss 3525821.00000
Epoch 59: Val Loss 3401326.75000
Epoch 60: Val Loss 3468225.75000
Epoch 61: Val Loss 3408304.75000
Epoch 62: Val Loss 3416724.50000
Epoch 63: Val Loss 3426240.25000
Epoch 64: Val Loss 3403570.25000
Epoch 65: Val Loss 3426658.50000
Epoch 66: Val Loss 3413629.75000
Epoch 67: Val Loss 3413464.00000
Epoch 68: Val Loss 3443987.00000
Epoch 69: Val Loss 3417582.75000
Epoch 70: Val Loss 3434852.50000
Epoch 71: Val Loss 3437975.00000
Epoch 72: Val Loss 3433510.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3406848.0425049122, 'MSE - std': 17652.532225520117, 'R2 - mean': 0.5877675746172422, 'R2 - std': 0.010998774316401339} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4951927.00000
Epoch 1: Val Loss 4549402.00000
Epoch 2: Val Loss 4463964.00000
Epoch 3: Val Loss 4380018.00000
Epoch 4: Val Loss 4320728.50000
Epoch 5: Val Loss 4276487.50000
Epoch 6: Val Loss 6502529.00000
Epoch 7: Val Loss 4227810.00000
Epoch 8: Val Loss 4176171.75000
Epoch 9: Val Loss 4220846.50000
Epoch 10: Val Loss 4137329.00000
Epoch 11: Val Loss 4149959.50000
Epoch 12: Val Loss 4127201.75000
Epoch 13: Val Loss 4112168.25000
Epoch 14: Val Loss 4091453.00000
Epoch 15: Val Loss 4070629.75000
Epoch 16: Val Loss 4100034.75000
Epoch 17: Val Loss 4060411.75000
Epoch 18: Val Loss 4053692.25000
Epoch 19: Val Loss 4023876.75000
Epoch 20: Val Loss 4037370.50000
Epoch 21: Val Loss 4046603.25000
Epoch 22: Val Loss 4027190.25000
Epoch 23: Val Loss 4019433.50000
Epoch 24: Val Loss 4025980.75000
Epoch 25: Val Loss 3989797.25000
Epoch 26: Val Loss 3997138.75000
Epoch 27: Val Loss 3978534.50000
Epoch 28: Val Loss 3963880.75000
Epoch 29: Val Loss 4017512.00000
Epoch 30: Val Loss 3944290.75000
Epoch 31: Val Loss 3969328.50000
Epoch 32: Val Loss 3982260.00000
Epoch 33: Val Loss 3941916.75000
Epoch 34: Val Loss 3967286.50000
Epoch 35: Val Loss 3931035.00000
Epoch 36: Val Loss 3909243.75000
Epoch 37: Val Loss 3907251.50000
Epoch 38: Val Loss 3958456.00000
Epoch 39: Val Loss 3904365.50000
Epoch 40: Val Loss 3911042.25000
Epoch 41: Val Loss 3906796.75000
Epoch 42: Val Loss 3916191.75000
Epoch 43: Val Loss 3939065.25000
Epoch 44: Val Loss 3896969.25000
Epoch 45: Val Loss 3879333.25000
Epoch 46: Val Loss 3893307.00000
Epoch 47: Val Loss 3951034.50000
Epoch 48: Val Loss 3866413.50000
Epoch 49: Val Loss 3870105.50000
Epoch 50: Val Loss 3886135.50000
Epoch 51: Val Loss 3874733.00000
Epoch 52: Val Loss 3870005.25000
Epoch 53: Val Loss 3951854.00000
Epoch 54: Val Loss 3869489.75000
Epoch 55: Val Loss 3863937.00000
Epoch 56: Val Loss 3941483.00000
Epoch 57: Val Loss 3880155.75000
Epoch 58: Val Loss 3883550.25000
Epoch 59: Val Loss 3863795.50000
Epoch 60: Val Loss 3852014.00000
Epoch 61: Val Loss 3858443.75000
Epoch 62: Val Loss 3857534.75000
Epoch 63: Val Loss 3848712.75000
Epoch 64: Val Loss 3863630.25000
Epoch 65: Val Loss 3870739.00000
Epoch 66: Val Loss 3893251.50000
Epoch 67: Val Loss 3966313.50000
Epoch 68: Val Loss 3868454.25000
Epoch 69: Val Loss 3858913.50000
Epoch 70: Val Loss 3858242.75000
Epoch 71: Val Loss 3846228.75000
Epoch 72: Val Loss 3862352.00000
Epoch 73: Val Loss 3842659.00000
Epoch 74: Val Loss 3858875.75000
Epoch 75: Val Loss 3891477.75000
Epoch 76: Val Loss 3862974.75000
Epoch 77: Val Loss 3865331.50000
Epoch 78: Val Loss 3860666.00000
Epoch 79: Val Loss 3982462.75000
Epoch 80: Val Loss 3887772.25000
Epoch 81: Val Loss 3928396.75000
Epoch 82: Val Loss 3883061.75000
Epoch 83: Val Loss 3917124.75000
Epoch 84: Val Loss 3894548.50000
Epoch 85: Val Loss 3888859.00000
Epoch 86: Val Loss 3933069.50000
Epoch 87: Val Loss 3945530.50000
Epoch 88: Val Loss 3938616.00000
Epoch 89: Val Loss 3937965.50000
Epoch 90: Val Loss 4048855.50000
Epoch 91: Val Loss 3923030.25000
Epoch 92: Val Loss 3928746.00000
Epoch 93: Val Loss 4220956.00000
Epoch 94: Val Loss 4000794.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3555231.175949753, 'MSE - std': 210339.84369221976, 'R2 - mean': 0.5815399930013279, 'R2 - std': 0.012578324075216375} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4606052.00000
Epoch 1: Val Loss 4207174.00000
Epoch 2: Val Loss 4107334.25000
Epoch 3: Val Loss 4094154.50000
Epoch 4: Val Loss 4027481.25000
Epoch 5: Val Loss 3988139.25000
Epoch 6: Val Loss 3974066.75000
Epoch 7: Val Loss 3952288.00000
Epoch 8: Val Loss 3933880.25000
Epoch 9: Val Loss 3927660.25000
Epoch 10: Val Loss 3893460.75000
Epoch 11: Val Loss 3877947.25000
Epoch 12: Val Loss 3867660.25000
Epoch 13: Val Loss 3841341.00000
Epoch 14: Val Loss 3838338.25000
Epoch 15: Val Loss 3847144.25000
Epoch 16: Val Loss 3845079.00000
Epoch 17: Val Loss 3833554.25000
Epoch 18: Val Loss 3781562.50000
Epoch 19: Val Loss 3789564.25000
Epoch 20: Val Loss 3783468.75000
Epoch 21: Val Loss 3800900.50000
Epoch 22: Val Loss 3768456.75000
Epoch 23: Val Loss 3945409.75000
Epoch 24: Val Loss 3777074.25000
Epoch 25: Val Loss 3764340.50000
Epoch 26: Val Loss 3741718.25000
Epoch 27: Val Loss 3796606.25000
Epoch 28: Val Loss 3744065.75000
Epoch 29: Val Loss 3737927.50000
Epoch 30: Val Loss 3731235.50000
Epoch 31: Val Loss 3725959.00000
Epoch 32: Val Loss 3793866.50000
Epoch 33: Val Loss 3710194.75000
Epoch 34: Val Loss 3725696.00000
Epoch 35: Val Loss 3707401.25000
Epoch 36: Val Loss 3705976.25000
Epoch 37: Val Loss 3731742.25000
Epoch 38: Val Loss 3716257.75000
Epoch 39: Val Loss 3727097.25000
Epoch 40: Val Loss 3726773.75000
Epoch 41: Val Loss 3858714.00000
Epoch 42: Val Loss 3762526.00000
Epoch 43: Val Loss 3699342.75000
Epoch 44: Val Loss 3703906.75000
Epoch 45: Val Loss 3703206.25000
Epoch 46: Val Loss 3728307.50000
Epoch 47: Val Loss 3721502.00000
Epoch 48: Val Loss 4875246.00000
Epoch 49: Val Loss 3762465.75000
Epoch 50: Val Loss 3714046.25000
Epoch 51: Val Loss 3708612.75000
Epoch 52: Val Loss 3714253.00000
Epoch 53: Val Loss 3775314.75000
Epoch 54: Val Loss 3739766.25000
Epoch 55: Val Loss 3799167.75000
Epoch 56: Val Loss 3723553.00000
Epoch 57: Val Loss 3810207.25000
Epoch 58: Val Loss 3758022.25000
Epoch 59: Val Loss 3754817.00000
Epoch 60: Val Loss 3726803.50000
Epoch 61: Val Loss 3736775.50000
Epoch 62: Val Loss 3728385.50000
Epoch 63: Val Loss 3837624.00000
Epoch 64: Val Loss 3734451.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595031.0366698843, 'MSE - std': 194767.10226158885, 'R2 - mean': 0.5780071488177081, 'R2 - std': 0.012494144287748678} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4141236.75000
Epoch 1: Val Loss 3721036.75000
Epoch 2: Val Loss 3615358.00000
Epoch 3: Val Loss 3566321.50000
Epoch 4: Val Loss 3563118.75000
Epoch 5: Val Loss 3507078.75000
Epoch 6: Val Loss 3507879.75000
Epoch 7: Val Loss 3530081.50000
Epoch 8: Val Loss 3483990.25000
Epoch 9: Val Loss 3444354.00000
Epoch 10: Val Loss 3451552.75000
Epoch 11: Val Loss 3438860.50000
Epoch 12: Val Loss 3431422.75000
Epoch 13: Val Loss 3448439.00000
Epoch 14: Val Loss 3440586.25000
Epoch 15: Val Loss 3410735.25000
Epoch 16: Val Loss 3441141.50000
Epoch 17: Val Loss 3449675.50000
Epoch 18: Val Loss 3432971.25000
Epoch 19: Val Loss 3422526.75000
Epoch 20: Val Loss 3401173.00000
Epoch 21: Val Loss 3431391.75000
Epoch 22: Val Loss 3410037.25000
Epoch 23: Val Loss 3397060.25000
Epoch 24: Val Loss 3389239.00000
Epoch 25: Val Loss 3391604.00000
Epoch 26: Val Loss 3397080.50000
Epoch 27: Val Loss 3435234.00000
Epoch 28: Val Loss 3383232.50000
Epoch 29: Val Loss 3387558.75000
Epoch 30: Val Loss 3377034.25000
Epoch 31: Val Loss 3401551.50000
Epoch 32: Val Loss 3425742.25000
Epoch 33: Val Loss 3427067.75000
Epoch 34: Val Loss 3369442.50000
Epoch 35: Val Loss 3389230.25000
Epoch 36: Val Loss 3404990.25000
Epoch 37: Val Loss 3447770.00000
Epoch 38: Val Loss 3383973.50000
Epoch 39: Val Loss 3376079.25000
Epoch 40: Val Loss 3450148.50000
Epoch 41: Val Loss 3391276.50000
Epoch 42: Val Loss 3400695.25000
Epoch 43: Val Loss 3404810.75000
Epoch 44: Val Loss 3438814.25000
Epoch 45: Val Loss 3445767.75000
Epoch 46: Val Loss 3409731.00000
Epoch 47: Val Loss 3424151.50000
Epoch 48: Val Loss 3409235.50000
Epoch 49: Val Loss 3407319.75000
Epoch 50: Val Loss 3459923.75000
Epoch 51: Val Loss 3426446.50000
Epoch 52: Val Loss 3405528.25000
Epoch 53: Val Loss 3414172.75000
Epoch 54: Val Loss 3404446.25000
Epoch 55: Val Loss 3402961.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3552339.2416718667, 'MSE - std': 194004.4760806099, 'R2 - mean': 0.5788954904113837, 'R2 - std': 0.01131545475598231} 
 

Saving model.....
Results After CV: {'MSE - mean': 3552339.2416718667, 'MSE - std': 194004.4760806099, 'R2 - mean': 0.5788954904113837, 'R2 - std': 0.01131545475598231}
Train time: 5330.966905794392
Inference time: 6.491520194202894
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 18 finished with value: 3552339.2416718667 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -6, 'learning_rate': -4, 'dropout': 0.2}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8874933.00000
Epoch 1: Val Loss 8251764.00000
Epoch 2: Val Loss 7859310.00000
Epoch 3: Val Loss 7369999.00000
Epoch 4: Val Loss 6654432.00000
Epoch 5: Val Loss 5951959.50000
Epoch 6: Val Loss 5338711.00000
Epoch 7: Val Loss 4991924.00000
Epoch 8: Val Loss 4767373.50000
Epoch 9: Val Loss 4627867.50000
Epoch 10: Val Loss 4527778.50000
Epoch 11: Val Loss 4440905.00000
Epoch 12: Val Loss 4448786.00000
Epoch 13: Val Loss 4332440.00000
Epoch 14: Val Loss 4279102.00000
Epoch 15: Val Loss 4239256.50000
Epoch 16: Val Loss 4223630.50000
Epoch 17: Val Loss 4169856.00000
Epoch 18: Val Loss 4141638.50000
Epoch 19: Val Loss 4339862.50000
Epoch 20: Val Loss 4107190.50000
Epoch 21: Val Loss 4086735.75000
Epoch 22: Val Loss 4073787.75000
Epoch 23: Val Loss 4057502.25000
Epoch 24: Val Loss 4045918.25000
Epoch 25: Val Loss 4044160.00000
Epoch 26: Val Loss 4024123.00000
Epoch 27: Val Loss 4001604.00000
Epoch 28: Val Loss 3995216.00000
Epoch 29: Val Loss 3988595.50000
Epoch 30: Val Loss 3977242.00000
Epoch 31: Val Loss 3969878.25000
Epoch 32: Val Loss 4001217.00000
Epoch 33: Val Loss 3952287.75000
Epoch 34: Val Loss 3959705.25000
Epoch 35: Val Loss 3946153.25000
Epoch 36: Val Loss 3931129.50000
Epoch 37: Val Loss 3918659.50000
Epoch 38: Val Loss 3922139.25000
Epoch 39: Val Loss 3920875.75000
Epoch 40: Val Loss 3925223.50000
Epoch 41: Val Loss 3900347.75000
Epoch 42: Val Loss 3894289.00000
Epoch 43: Val Loss 3893091.00000
Epoch 44: Val Loss 3900261.75000
Epoch 45: Val Loss 3881586.25000
Epoch 46: Val Loss 3870480.50000
Epoch 47: Val Loss 3866378.50000
Epoch 48: Val Loss 3859908.50000
Epoch 49: Val Loss 3853778.75000
Epoch 50: Val Loss 3844994.25000
Epoch 51: Val Loss 3839908.75000
Epoch 52: Val Loss 3841204.50000
Epoch 53: Val Loss 3822880.00000
Epoch 54: Val Loss 4102455.50000
Epoch 55: Val Loss 3828911.75000
Epoch 56: Val Loss 3821016.00000
Epoch 57: Val Loss 3802898.25000
Epoch 58: Val Loss 3817620.00000
Epoch 59: Val Loss 3810756.00000
Epoch 60: Val Loss 3795867.00000
Epoch 61: Val Loss 3788872.75000
Epoch 62: Val Loss 3790798.75000
Epoch 63: Val Loss 3810781.00000
Epoch 64: Val Loss 3785208.75000
Epoch 65: Val Loss 3807075.50000
Epoch 66: Val Loss 3771161.50000
Epoch 67: Val Loss 3763991.75000
Epoch 68: Val Loss 3766259.00000
Epoch 69: Val Loss 3780895.75000
Epoch 70: Val Loss 3765259.00000
Epoch 71: Val Loss 3781183.75000
Epoch 72: Val Loss 3745339.75000
Epoch 73: Val Loss 3744576.50000
Epoch 74: Val Loss 3746180.75000
Epoch 75: Val Loss 3744897.50000
Epoch 76: Val Loss 3740914.75000
Epoch 77: Val Loss 3755447.75000
Epoch 78: Val Loss 3752839.75000
Epoch 79: Val Loss 3747454.25000
Epoch 80: Val Loss 3724424.25000
Epoch 81: Val Loss 3767622.50000
Epoch 82: Val Loss 3726969.25000
Epoch 83: Val Loss 3737710.00000
Epoch 84: Val Loss 3719273.25000
Epoch 85: Val Loss 3740786.25000
Epoch 86: Val Loss 3707271.75000
Epoch 87: Val Loss 3707190.25000
Epoch 88: Val Loss 3704524.75000
Epoch 89: Val Loss 3701572.75000
Epoch 90: Val Loss 3706520.75000
Epoch 91: Val Loss 3700011.00000
Epoch 92: Val Loss 3694622.00000
Epoch 93: Val Loss 3698258.25000
Epoch 94: Val Loss 3694804.75000
Epoch 95: Val Loss 3690431.25000
Epoch 96: Val Loss 3705960.25000
Epoch 97: Val Loss 3680485.75000
Epoch 98: Val Loss 3674524.25000
Epoch 99: Val Loss 3705998.75000
Saved Losses
{'MSE - mean': 3689143.343660255, 'MSE - std': 0.0, 'R2 - mean': 0.5677593211674469, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8189116.00000
Epoch 1: Val Loss 7719333.50000
Epoch 2: Val Loss 7338780.00000
Epoch 3: Val Loss 6814220.50000
Epoch 4: Val Loss 6192169.00000
Epoch 5: Val Loss 5435139.50000
Epoch 6: Val Loss 4929609.00000
Epoch 7: Val Loss 4640873.00000
Epoch 8: Val Loss 4460449.50000
Epoch 9: Val Loss 4310265.00000
Epoch 10: Val Loss 4209647.50000
Epoch 11: Val Loss 4205221.50000
Epoch 12: Val Loss 4090692.50000
Epoch 13: Val Loss 4072142.75000
Epoch 14: Val Loss 4008423.50000
Epoch 15: Val Loss 3968478.25000
Epoch 16: Val Loss 3956342.25000
Epoch 17: Val Loss 3917486.00000
Epoch 18: Val Loss 3893546.50000
Epoch 19: Val Loss 3884070.50000
Epoch 20: Val Loss 3905766.50000
Epoch 21: Val Loss 3844120.25000
Epoch 22: Val Loss 3835281.50000
Epoch 23: Val Loss 3816537.50000
Epoch 24: Val Loss 3815894.50000
Epoch 25: Val Loss 3828563.00000
Epoch 26: Val Loss 3800558.75000
Epoch 27: Val Loss 3790191.25000
Epoch 28: Val Loss 3789958.25000
Epoch 29: Val Loss 3777203.00000
Epoch 30: Val Loss 3765099.00000
Epoch 31: Val Loss 3761211.25000
Epoch 32: Val Loss 3768352.00000
Epoch 33: Val Loss 3742076.25000
Epoch 34: Val Loss 3747310.25000
Epoch 35: Val Loss 3729946.00000
Epoch 36: Val Loss 3722429.50000
Epoch 37: Val Loss 3726116.00000
Epoch 38: Val Loss 3731026.25000
Epoch 39: Val Loss 3732836.75000
Epoch 40: Val Loss 3710396.25000
Epoch 41: Val Loss 3696978.75000
Epoch 42: Val Loss 3712612.50000
Epoch 43: Val Loss 3692556.75000
Epoch 44: Val Loss 3689662.25000
Epoch 45: Val Loss 3705567.25000
Epoch 46: Val Loss 3675249.75000
Epoch 47: Val Loss 3678577.75000
Epoch 48: Val Loss 3674983.00000
Epoch 49: Val Loss 3665907.00000
Epoch 50: Val Loss 3673054.25000
Epoch 51: Val Loss 3673280.00000
Epoch 52: Val Loss 3668159.25000
Epoch 53: Val Loss 3655556.75000
Epoch 54: Val Loss 3653629.50000
Epoch 55: Val Loss 3650205.00000
Epoch 56: Val Loss 3640453.75000
Epoch 57: Val Loss 3650275.50000
Epoch 58: Val Loss 3650787.00000
Epoch 59: Val Loss 3670080.50000
Epoch 60: Val Loss 3646329.50000
Epoch 61: Val Loss 3626319.75000
Epoch 62: Val Loss 3642851.00000
Epoch 63: Val Loss 3636244.75000
Epoch 64: Val Loss 3635710.25000
Epoch 65: Val Loss 3628062.25000
Epoch 66: Val Loss 3631818.50000
Epoch 67: Val Loss 3611358.25000
Epoch 68: Val Loss 3621358.50000
Epoch 69: Val Loss 3608937.50000
Epoch 70: Val Loss 3621292.00000
Epoch 71: Val Loss 3605016.00000
Epoch 72: Val Loss 3610824.75000
Epoch 73: Val Loss 3610243.00000
Epoch 74: Val Loss 3604479.50000
Epoch 75: Val Loss 3601497.25000
Epoch 76: Val Loss 3595622.00000
Epoch 77: Val Loss 3588950.25000
Epoch 78: Val Loss 3597410.00000
Epoch 79: Val Loss 3601827.25000
Epoch 80: Val Loss 3607327.75000
Epoch 81: Val Loss 3582709.50000
Epoch 82: Val Loss 3579636.25000
Epoch 83: Val Loss 3572196.50000
Epoch 84: Val Loss 3575216.75000
Epoch 85: Val Loss 3568912.00000
Epoch 86: Val Loss 3568672.00000
Epoch 87: Val Loss 3571692.75000
Epoch 88: Val Loss 3568977.25000
Epoch 89: Val Loss 3582585.00000
Epoch 90: Val Loss 3565258.00000
Epoch 91: Val Loss 3558238.25000
Epoch 92: Val Loss 3574095.75000
Epoch 93: Val Loss 3565528.75000
Epoch 94: Val Loss 3568070.25000
Epoch 95: Val Loss 3599677.25000
Epoch 96: Val Loss 3558477.50000
Epoch 97: Val Loss 3552626.50000
Epoch 98: Val Loss 3577889.00000
Epoch 99: Val Loss 3549967.00000
Saved Losses
{'MSE - mean': 3624717.13178373, 'MSE - std': 64426.21187652508, 'R2 - mean': 0.5615811545311569, 'R2 - std': 0.00617816663628995} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9198664.00000
Epoch 1: Val Loss 8678285.00000
Epoch 2: Val Loss 8248386.00000
Epoch 3: Val Loss 7828689.50000
Epoch 4: Val Loss 6982297.50000
Epoch 5: Val Loss 6227653.50000
Epoch 6: Val Loss 5744758.00000
Epoch 7: Val Loss 5434515.00000
Epoch 8: Val Loss 5201902.00000
Epoch 9: Val Loss 5054269.00000
Epoch 10: Val Loss 4955021.50000
Epoch 11: Val Loss 4876442.50000
Epoch 12: Val Loss 4817279.50000
Epoch 13: Val Loss 4764955.00000
Epoch 14: Val Loss 4720097.50000
Epoch 15: Val Loss 4707936.00000
Epoch 16: Val Loss 4654945.50000
Epoch 17: Val Loss 4627423.50000
Epoch 18: Val Loss 4633974.50000
Epoch 19: Val Loss 4577881.00000
Epoch 20: Val Loss 4561823.00000
Epoch 21: Val Loss 4541315.50000
Epoch 22: Val Loss 4528395.50000
Epoch 23: Val Loss 4513860.50000
Epoch 24: Val Loss 4493534.00000
Epoch 25: Val Loss 4502693.50000
Epoch 26: Val Loss 4600357.50000
Epoch 27: Val Loss 4461150.50000
Epoch 28: Val Loss 4479583.50000
Epoch 29: Val Loss 4464369.50000
Epoch 30: Val Loss 4445718.50000
Epoch 31: Val Loss 4439698.50000
Epoch 32: Val Loss 4431797.50000
Epoch 33: Val Loss 4422324.00000
Epoch 34: Val Loss 4410105.00000
Epoch 35: Val Loss 4445863.00000
Epoch 36: Val Loss 4397845.50000
Epoch 37: Val Loss 4384571.00000
Epoch 38: Val Loss 4452396.00000
Epoch 39: Val Loss 4402270.00000
Epoch 40: Val Loss 4368857.00000
Epoch 41: Val Loss 4371937.00000
Epoch 42: Val Loss 4361730.00000
Epoch 43: Val Loss 4363721.50000
Epoch 44: Val Loss 4348912.50000
Epoch 45: Val Loss 4341674.00000
Epoch 46: Val Loss 4354208.50000
Epoch 47: Val Loss 4323504.50000
Epoch 48: Val Loss 4315519.50000
Epoch 49: Val Loss 4318876.00000
Epoch 50: Val Loss 4321252.50000
Epoch 51: Val Loss 4300951.50000
Epoch 52: Val Loss 4304277.50000
Epoch 53: Val Loss 4298938.00000
Epoch 54: Val Loss 4319148.00000
Epoch 55: Val Loss 4319871.00000
Epoch 56: Val Loss 4291017.50000
Epoch 57: Val Loss 4276429.50000
Epoch 58: Val Loss 4285577.50000
Epoch 59: Val Loss 4271023.50000
Epoch 60: Val Loss 4275419.00000
Epoch 61: Val Loss 4263637.00000
Epoch 62: Val Loss 4261322.50000
Epoch 63: Val Loss 4254547.00000
Epoch 64: Val Loss 4243275.00000
Epoch 65: Val Loss 4241682.00000
Epoch 66: Val Loss 4246067.00000
Epoch 67: Val Loss 4238649.50000
Epoch 68: Val Loss 4240553.00000
Epoch 69: Val Loss 4232763.50000
Epoch 70: Val Loss 4237055.00000
Epoch 71: Val Loss 4220038.50000
Epoch 72: Val Loss 4226154.00000
Epoch 73: Val Loss 4220974.50000
Epoch 74: Val Loss 4215338.00000
Epoch 75: Val Loss 4218046.00000
Epoch 76: Val Loss 4235316.00000
Epoch 77: Val Loss 4226946.00000
Epoch 78: Val Loss 4243011.00000
Epoch 79: Val Loss 4208480.50000
Epoch 80: Val Loss 4201218.50000
Epoch 81: Val Loss 4198135.00000
Epoch 82: Val Loss 4187912.75000
Epoch 83: Val Loss 4196236.00000
Epoch 84: Val Loss 4192735.75000
Epoch 85: Val Loss 4194393.00000
Epoch 86: Val Loss 4204301.00000
Epoch 87: Val Loss 4185781.75000
Epoch 88: Val Loss 4181496.25000
Epoch 89: Val Loss 4180929.00000
Epoch 90: Val Loss 4173311.25000
Epoch 91: Val Loss 4192037.75000
Epoch 92: Val Loss 4178258.25000
Epoch 93: Val Loss 4163194.50000
Epoch 94: Val Loss 4164696.25000
Epoch 95: Val Loss 4176784.50000
Epoch 96: Val Loss 4168734.00000
Epoch 97: Val Loss 4155773.50000
Epoch 98: Val Loss 4156001.00000
Epoch 99: Val Loss 4213979.00000
Saved Losses
{'MSE - mean': 3806652.6034452417, 'MSE - std': 262617.95359146025, 'R2 - mean': 0.5522047557428019, 'R2 - std': 0.014187325463256788} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8943929.00000
Epoch 1: Val Loss 8303168.00000
Epoch 2: Val Loss 7895925.00000
Epoch 3: Val Loss 7366264.50000
Epoch 4: Val Loss 6671541.50000
Epoch 5: Val Loss 5932229.50000
Epoch 6: Val Loss 5437366.50000
Epoch 7: Val Loss 5054889.50000
Epoch 8: Val Loss 4852077.00000
Epoch 9: Val Loss 4696906.00000
Epoch 10: Val Loss 4608099.00000
Epoch 11: Val Loss 4548103.00000
Epoch 12: Val Loss 4464129.00000
Epoch 13: Val Loss 4413203.50000
Epoch 14: Val Loss 4365442.00000
Epoch 15: Val Loss 4325139.50000
Epoch 16: Val Loss 4298093.50000
Epoch 17: Val Loss 4274646.00000
Epoch 18: Val Loss 4257996.00000
Epoch 19: Val Loss 4222269.50000
Epoch 20: Val Loss 4219330.50000
Epoch 21: Val Loss 4209874.00000
Epoch 22: Val Loss 4186255.25000
Epoch 23: Val Loss 4223818.50000
Epoch 24: Val Loss 4172894.00000
Epoch 25: Val Loss 4152055.50000
Epoch 26: Val Loss 4151323.75000
Epoch 27: Val Loss 4144912.50000
Epoch 28: Val Loss 4151358.25000
Epoch 29: Val Loss 4112860.75000
Epoch 30: Val Loss 4160442.50000
Epoch 31: Val Loss 4106103.00000
Epoch 32: Val Loss 4111763.25000
Epoch 33: Val Loss 4091004.75000
Epoch 34: Val Loss 4080814.75000
Epoch 35: Val Loss 4087817.50000
Epoch 36: Val Loss 4065788.75000
Epoch 37: Val Loss 4061345.75000
Epoch 38: Val Loss 4067718.50000
Epoch 39: Val Loss 4053939.25000
Epoch 40: Val Loss 4042735.75000
Epoch 41: Val Loss 4042552.00000
Epoch 42: Val Loss 4031561.25000
Epoch 43: Val Loss 4028475.25000
Epoch 44: Val Loss 4019551.25000
Epoch 45: Val Loss 4018593.00000
Epoch 46: Val Loss 4009037.00000
Epoch 47: Val Loss 4032424.75000
Epoch 48: Val Loss 4001963.25000
Epoch 49: Val Loss 3990616.25000
Epoch 50: Val Loss 4003997.00000
Epoch 51: Val Loss 3995699.50000
Epoch 52: Val Loss 3996673.50000
Epoch 53: Val Loss 3988091.25000
Epoch 54: Val Loss 3977997.00000
Epoch 55: Val Loss 3995910.50000
Epoch 56: Val Loss 3972458.00000
Epoch 57: Val Loss 3963408.00000
Epoch 58: Val Loss 3963868.25000
Epoch 59: Val Loss 3963916.75000
Epoch 60: Val Loss 3965039.75000
Epoch 61: Val Loss 3954211.50000
Epoch 62: Val Loss 3949176.75000
Epoch 63: Val Loss 3950654.25000
Epoch 64: Val Loss 3945569.00000
Epoch 65: Val Loss 3936996.00000
Epoch 66: Val Loss 3933411.50000
Epoch 67: Val Loss 3930824.75000
Epoch 68: Val Loss 4024955.00000
Epoch 69: Val Loss 3928049.50000
Epoch 70: Val Loss 3941846.50000
Epoch 71: Val Loss 3919742.00000
Epoch 72: Val Loss 3911500.25000
Epoch 73: Val Loss 3916054.50000
Epoch 74: Val Loss 3916298.50000
Epoch 75: Val Loss 3904963.00000
Epoch 76: Val Loss 3917236.50000
Epoch 77: Val Loss 3909848.00000
Epoch 78: Val Loss 3900378.50000
Epoch 79: Val Loss 3912972.75000
Epoch 80: Val Loss 3895251.50000
Epoch 81: Val Loss 3905754.00000
Epoch 82: Val Loss 3907553.75000
Epoch 83: Val Loss 3911809.75000
Epoch 84: Val Loss 3890849.50000
Epoch 85: Val Loss 3896243.00000
Epoch 86: Val Loss 3880717.50000
Epoch 87: Val Loss 3892905.25000
Epoch 88: Val Loss 3888983.50000
Epoch 89: Val Loss 3880633.25000
Epoch 90: Val Loss 3883696.50000
Epoch 91: Val Loss 3883727.25000
Epoch 92: Val Loss 3902258.25000
Epoch 93: Val Loss 3928646.25000
Epoch 94: Val Loss 3880440.75000
Epoch 95: Val Loss 3870237.00000
Epoch 96: Val Loss 3896901.25000
Epoch 97: Val Loss 3865290.50000
Epoch 98: Val Loss 3876404.00000
Epoch 99: Val Loss 3861992.75000
Saved Losses
{'MSE - mean': 3822995.9435311593, 'MSE - std': 229188.6918172811, 'R2 - mean': 0.5514172391291319, 'R2 - std': 0.012362066983344638} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8367890.50000
Epoch 1: Val Loss 7807019.50000
Epoch 2: Val Loss 7466230.00000
Epoch 3: Val Loss 6951167.50000
Epoch 4: Val Loss 6227351.50000
Epoch 5: Val Loss 5499516.00000
Epoch 6: Val Loss 4955248.50000
Epoch 7: Val Loss 4615010.50000
Epoch 8: Val Loss 4411137.00000
Epoch 9: Val Loss 4258158.50000
Epoch 10: Val Loss 4145371.75000
Epoch 11: Val Loss 4080067.25000
Epoch 12: Val Loss 4009080.75000
Epoch 13: Val Loss 3961864.00000
Epoch 14: Val Loss 3923100.75000
Epoch 15: Val Loss 3925279.25000
Epoch 16: Val Loss 3877889.75000
Epoch 17: Val Loss 3822206.25000
Epoch 18: Val Loss 3798105.25000
Epoch 19: Val Loss 3794260.75000
Epoch 20: Val Loss 3781123.50000
Epoch 21: Val Loss 3738158.00000
Epoch 22: Val Loss 3728457.50000
Epoch 23: Val Loss 3716504.75000
Epoch 24: Val Loss 3711121.75000
Epoch 25: Val Loss 3684104.75000
Epoch 26: Val Loss 3680190.25000
Epoch 27: Val Loss 3662564.75000
Epoch 28: Val Loss 3666053.25000
Epoch 29: Val Loss 3643334.50000
Epoch 30: Val Loss 3663163.00000
Epoch 31: Val Loss 3642412.75000
Epoch 32: Val Loss 3631959.00000
Epoch 33: Val Loss 3626798.75000
Epoch 34: Val Loss 3649223.00000
Epoch 35: Val Loss 3613850.00000
Epoch 36: Val Loss 3607689.00000
Epoch 37: Val Loss 3597560.75000
Epoch 38: Val Loss 3593694.75000
Epoch 39: Val Loss 3613958.00000
Epoch 40: Val Loss 3589288.25000
Epoch 41: Val Loss 3587499.75000
Epoch 42: Val Loss 3588311.00000
Epoch 43: Val Loss 3566604.50000
Epoch 44: Val Loss 3573114.00000
Epoch 45: Val Loss 3574003.25000
Epoch 46: Val Loss 3553789.25000
Epoch 47: Val Loss 3555367.25000
Epoch 48: Val Loss 3567188.25000
Epoch 49: Val Loss 3547079.50000
Epoch 50: Val Loss 3533228.75000
Epoch 51: Val Loss 3537830.25000
Epoch 52: Val Loss 3541281.25000
Epoch 53: Val Loss 3519779.75000
Epoch 54: Val Loss 3513411.75000
Epoch 55: Val Loss 3540427.00000
Epoch 56: Val Loss 3520197.50000
Epoch 57: Val Loss 3506418.75000
Epoch 58: Val Loss 3511811.25000
Epoch 59: Val Loss 3509097.75000
Epoch 60: Val Loss 3525724.00000
Epoch 61: Val Loss 3530777.50000
Epoch 62: Val Loss 3496478.50000
Epoch 63: Val Loss 3535538.00000
Epoch 64: Val Loss 3497598.25000
Epoch 65: Val Loss 3496966.50000
Epoch 66: Val Loss 3495388.75000
Epoch 67: Val Loss 3499855.25000
Epoch 68: Val Loss 3480240.00000
Epoch 69: Val Loss 3480699.25000
Epoch 70: Val Loss 3479454.25000
Epoch 71: Val Loss 3481901.50000
Epoch 72: Val Loss 3491967.00000
Epoch 73: Val Loss 3493092.25000
Epoch 74: Val Loss 3470602.00000
Epoch 75: Val Loss 3474753.50000
Epoch 76: Val Loss 3475999.25000
Epoch 77: Val Loss 3461072.75000
Epoch 78: Val Loss 3477760.75000
Epoch 79: Val Loss 3467859.50000
Epoch 80: Val Loss 3451785.50000
Epoch 81: Val Loss 3457059.25000
Epoch 82: Val Loss 3455340.00000
Epoch 83: Val Loss 3453858.75000
Epoch 84: Val Loss 3453449.50000
Epoch 85: Val Loss 3451410.00000
Epoch 86: Val Loss 3448375.75000
Epoch 87: Val Loss 3452195.00000
Epoch 88: Val Loss 3484011.50000
Epoch 89: Val Loss 3443115.75000
Epoch 90: Val Loss 3447395.00000
Epoch 91: Val Loss 3473631.50000
Epoch 92: Val Loss 3480522.50000
Epoch 93: Val Loss 3437867.50000
Epoch 94: Val Loss 3431677.00000
Epoch 95: Val Loss 3439632.75000
Epoch 96: Val Loss 3437067.75000
Epoch 97: Val Loss 3449419.75000
Epoch 98: Val Loss 3431823.00000
Epoch 99: Val Loss 3445250.50000
Saved Losses
{'MSE - mean': 3747877.473662275, 'MSE - std': 254151.7326860147, 'R2 - mean': 0.5559978080613945, 'R2 - std': 0.014359074031893522} 
 

Saving model.....
Results After CV: {'MSE - mean': 3747877.473662275, 'MSE - std': 254151.7326860147, 'R2 - mean': 0.5559978080613945, 'R2 - std': 0.014359074031893522}
Train time: 7177.27192428321
Inference time: 6.416888343199389
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 19 finished with value: 3747877.473662275 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -5, 'dropout': 0.2}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3888079.25000
Epoch 1: Val Loss 3806250.00000
Epoch 2: Val Loss 3824984.75000
Epoch 3: Val Loss 3664641.50000
Epoch 4: Val Loss 3605110.75000
Epoch 5: Val Loss 3550514.50000
Epoch 6: Val Loss 3553102.75000
Epoch 7: Val Loss 3535161.25000
Epoch 8: Val Loss 3431576.25000
Epoch 9: Val Loss 3539367.00000
Epoch 10: Val Loss 3508830.25000
Epoch 11: Val Loss 3502171.50000
Epoch 12: Val Loss 3469377.75000
Epoch 13: Val Loss 3511631.50000
Epoch 14: Val Loss 3476140.25000
Epoch 15: Val Loss 3587389.75000
Epoch 16: Val Loss 3677520.00000
Epoch 17: Val Loss 3774112.50000
Epoch 18: Val Loss 3866555.25000
Epoch 19: Val Loss 3803918.75000
Epoch 20: Val Loss 3847550.00000
Epoch 21: Val Loss 3905649.50000
Epoch 22: Val Loss 3887743.25000
Epoch 23: Val Loss 4059622.25000
Epoch 24: Val Loss 4001835.00000
Epoch 25: Val Loss 4086299.75000
Epoch 26: Val Loss 4168694.50000
Epoch 27: Val Loss 4165069.50000
Epoch 28: Val Loss 4191227.00000
Epoch 29: Val Loss 4072830.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3441044.153139727, 'MSE - std': 0.0, 'R2 - mean': 0.5968280107082553, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3681474.25000
Epoch 1: Val Loss 3735845.75000
Epoch 2: Val Loss 3591102.00000
Epoch 3: Val Loss 3531695.50000
Epoch 4: Val Loss 3573876.75000
Epoch 5: Val Loss 3504997.75000
Epoch 6: Val Loss 3477035.25000
Epoch 7: Val Loss 3413484.50000
Epoch 8: Val Loss 3408711.25000
Epoch 9: Val Loss 3491543.75000
Epoch 10: Val Loss 3460261.75000
Epoch 11: Val Loss 3453050.75000
Epoch 12: Val Loss 3460873.00000
Epoch 13: Val Loss 3721650.75000
Epoch 14: Val Loss 3575782.50000
Epoch 15: Val Loss 3550226.75000
Epoch 16: Val Loss 3612499.25000
Epoch 17: Val Loss 3767063.00000
Epoch 18: Val Loss 3713514.50000
Epoch 19: Val Loss 3814416.00000
Epoch 20: Val Loss 3909959.00000
Epoch 21: Val Loss 3861907.50000
Epoch 22: Val Loss 3914606.25000
Epoch 23: Val Loss 3921292.75000
Epoch 24: Val Loss 4141668.50000
Epoch 25: Val Loss 4012477.50000
Epoch 26: Val Loss 4160462.00000
Epoch 27: Val Loss 4087633.50000
Epoch 28: Val Loss 4218380.50000
Epoch 29: Val Loss 4223124.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3422794.5655501597, 'MSE - std': 18249.58758956776, 'R2 - mean': 0.5858400108646175, 'R2 - std': 0.010987999843637852} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4320615.00000
Epoch 1: Val Loss 4307529.00000
Epoch 2: Val Loss 4146338.25000
Epoch 3: Val Loss 4112545.00000
Epoch 4: Val Loss 4027985.50000
Epoch 5: Val Loss 3981468.75000
Epoch 6: Val Loss 3975054.25000
Epoch 7: Val Loss 3914764.25000
Epoch 8: Val Loss 3900168.25000
Epoch 9: Val Loss 3889810.25000
Epoch 10: Val Loss 3980228.00000
Epoch 11: Val Loss 3905067.25000
Epoch 12: Val Loss 3991778.25000
Epoch 13: Val Loss 3994192.50000
Epoch 14: Val Loss 3939896.25000
Epoch 15: Val Loss 3967237.75000
Epoch 16: Val Loss 4055010.25000
Epoch 17: Val Loss 4073293.00000
Epoch 18: Val Loss 4199281.50000
Epoch 19: Val Loss 4311065.00000
Epoch 20: Val Loss 4316036.50000
Epoch 21: Val Loss 4397185.00000
Epoch 22: Val Loss 4414125.00000
Epoch 23: Val Loss 4506401.50000
Epoch 24: Val Loss 4547313.50000
Epoch 25: Val Loss 4613743.50000
Epoch 26: Val Loss 4587689.50000
Epoch 27: Val Loss 4827896.50000
Epoch 28: Val Loss 4686646.00000
Epoch 29: Val Loss 4763865.00000
Epoch 30: Val Loss 4780141.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3575022.2816485483, 'MSE - std': 215797.55959816303, 'R2 - mean': 0.5792302297034885, 'R2 - std': 0.012956433705765146} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4017869.50000
Epoch 1: Val Loss 3895618.75000
Epoch 2: Val Loss 4010875.00000
Epoch 3: Val Loss 3842932.00000
Epoch 4: Val Loss 3798791.00000
Epoch 5: Val Loss 4127505.50000
Epoch 6: Val Loss 3814577.00000
Epoch 7: Val Loss 3834887.00000
Epoch 8: Val Loss 3825400.75000
Epoch 9: Val Loss 3860888.25000
Epoch 10: Val Loss 3953819.25000
Epoch 11: Val Loss 3919872.50000
Epoch 12: Val Loss 3982372.75000
Epoch 13: Val Loss 4037899.00000
Epoch 14: Val Loss 4163626.50000
Epoch 15: Val Loss 4151784.00000
Epoch 16: Val Loss 4182459.75000
Epoch 17: Val Loss 4157380.50000
Epoch 18: Val Loss 4284557.50000
Epoch 19: Val Loss 4346689.00000
Epoch 20: Val Loss 4350948.50000
Epoch 21: Val Loss 4480094.50000
Epoch 22: Val Loss 4469234.50000
Epoch 23: Val Loss 4643209.50000
Epoch 24: Val Loss 4522245.50000
Epoch 25: Val Loss 4666953.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3629649.920908088, 'MSE - std': 209473.09364117222, 'R2 - mean': 0.5739717183948502, 'R2 - std': 0.014451910058125409} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3613012.75000
Epoch 1: Val Loss 3507625.75000
Epoch 2: Val Loss 3641921.50000
Epoch 3: Val Loss 3496930.25000
Epoch 4: Val Loss 3457903.50000
Epoch 5: Val Loss 3471241.75000
Epoch 6: Val Loss 3432592.25000
Epoch 7: Val Loss 3575716.25000
Epoch 8: Val Loss 3390803.00000
Epoch 9: Val Loss 3394694.75000
Epoch 10: Val Loss 3421312.50000
Epoch 11: Val Loss 3448151.75000
Epoch 12: Val Loss 3483017.50000
Epoch 13: Val Loss 3571323.00000
Epoch 14: Val Loss 3529703.25000
Epoch 15: Val Loss 3449480.75000
Epoch 16: Val Loss 3608033.75000
Epoch 17: Val Loss 3728414.00000
Epoch 18: Val Loss 3647958.25000
Epoch 19: Val Loss 3813180.25000
Epoch 20: Val Loss 3830824.25000
Epoch 21: Val Loss 3847309.50000
Epoch 22: Val Loss 3876579.50000
Epoch 23: Val Loss 3991075.50000
Epoch 24: Val Loss 4048941.50000
Epoch 25: Val Loss 4143020.25000
Epoch 26: Val Loss 4150214.50000
Epoch 27: Val Loss 4066478.25000
Epoch 28: Val Loss 4162796.75000
Epoch 29: Val Loss 4276923.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3584505.3326785006, 'MSE - std': 207979.12624433896, 'R2 - mean': 0.5751150761227519, 'R2 - std': 0.0131268896178161} 
 

Saving model.....
Results After CV: {'MSE - mean': 3584505.3326785006, 'MSE - std': 207979.12624433896, 'R2 - mean': 0.5751150761227519, 'R2 - std': 0.0131268896178161}
Train time: 2097.038694154401
Inference time: 6.436361083004158
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 20 finished with value: 3584505.3326785006 and parameters: {'dim': 128, 'depth': 1, 'heads': 8, 'weight_decay': -5, 'learning_rate': -3, 'dropout': 0.2}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4485069.50000
Epoch 1: Val Loss 4064148.00000
Epoch 2: Val Loss 3952027.75000
Epoch 3: Val Loss 3882987.00000
Epoch 4: Val Loss 3864481.75000
Epoch 5: Val Loss 3794783.25000
Epoch 6: Val Loss 3799016.25000
Epoch 7: Val Loss 3734795.75000
Epoch 8: Val Loss 3730514.75000
Epoch 9: Val Loss 3740338.75000
Epoch 10: Val Loss 3683710.75000
Epoch 11: Val Loss 3666890.50000
Epoch 12: Val Loss 3719814.50000
Epoch 13: Val Loss 3696836.50000
Epoch 14: Val Loss 3628059.25000
Epoch 15: Val Loss 3609292.00000
Epoch 16: Val Loss 3617100.00000
Epoch 17: Val Loss 3592915.00000
Epoch 18: Val Loss 3570965.75000
Epoch 19: Val Loss 3551595.00000
Epoch 20: Val Loss 3571188.00000
Epoch 21: Val Loss 3577071.50000
Epoch 22: Val Loss 3550951.00000
Epoch 23: Val Loss 3530575.50000
Epoch 24: Val Loss 3538340.25000
Epoch 25: Val Loss 3526020.25000
Epoch 26: Val Loss 3533383.75000
Epoch 27: Val Loss 3495355.50000
Epoch 28: Val Loss 3545745.50000
Epoch 29: Val Loss 3500784.75000
Epoch 30: Val Loss 3491294.00000
Epoch 31: Val Loss 3503515.00000
Epoch 32: Val Loss 3472888.25000
Epoch 33: Val Loss 3486257.75000
Epoch 34: Val Loss 3472924.00000
Epoch 35: Val Loss 3476081.50000
Epoch 36: Val Loss 3454647.75000
Epoch 37: Val Loss 3451316.25000
Epoch 38: Val Loss 3464824.25000
Epoch 39: Val Loss 3465795.00000
Epoch 40: Val Loss 3454531.75000
Epoch 41: Val Loss 3446990.50000
Epoch 42: Val Loss 3505845.25000
Epoch 43: Val Loss 3480844.00000
Epoch 44: Val Loss 3431119.75000
Epoch 45: Val Loss 3428737.50000
Epoch 46: Val Loss 3485192.50000
Epoch 47: Val Loss 3498460.00000
Epoch 48: Val Loss 3442431.00000
Epoch 49: Val Loss 3432412.25000
Epoch 50: Val Loss 3466363.25000
Epoch 51: Val Loss 3436289.50000
Epoch 52: Val Loss 3459565.25000
Epoch 53: Val Loss 3474504.50000
Epoch 54: Val Loss 3436259.50000
Epoch 55: Val Loss 3417571.00000
Epoch 56: Val Loss 3428277.00000
Epoch 57: Val Loss 3454909.25000
Epoch 58: Val Loss 3456996.00000
Epoch 59: Val Loss 3450428.50000
Epoch 60: Val Loss 3485364.00000
Epoch 61: Val Loss 3463463.75000
Epoch 62: Val Loss 3449227.25000
Epoch 63: Val Loss 3441670.00000
Epoch 64: Val Loss 3469530.00000
Epoch 65: Val Loss 3442687.25000
Epoch 66: Val Loss 3453209.00000
Epoch 67: Val Loss 3466908.75000
Epoch 68: Val Loss 3469198.25000
Epoch 69: Val Loss 3457214.75000
Epoch 70: Val Loss 3573842.00000
Epoch 71: Val Loss 3498887.75000
Epoch 72: Val Loss 3482346.25000
Epoch 73: Val Loss 3531689.75000
Epoch 74: Val Loss 3501382.50000
Epoch 75: Val Loss 3489615.00000
Epoch 76: Val Loss 3514340.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3431660.1439190907, 'MSE - std': 0.0, 'R2 - mean': 0.5979274937420792, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4244163.50000
Epoch 1: Val Loss 3911117.50000
Epoch 2: Val Loss 3780175.75000
Epoch 3: Val Loss 3724954.00000
Epoch 4: Val Loss 3698790.25000
Epoch 5: Val Loss 3668290.75000
Epoch 6: Val Loss 3682774.25000
Epoch 7: Val Loss 3622168.25000
Epoch 8: Val Loss 3594821.75000
Epoch 9: Val Loss 3579220.00000
Epoch 10: Val Loss 3577446.25000
Epoch 11: Val Loss 3551368.75000
Epoch 12: Val Loss 3600051.00000
Epoch 13: Val Loss 3575071.25000
Epoch 14: Val Loss 3511258.00000
Epoch 15: Val Loss 3612895.75000
Epoch 16: Val Loss 3513910.50000
Epoch 17: Val Loss 3548557.25000
Epoch 18: Val Loss 3488680.25000
Epoch 19: Val Loss 3499202.50000
Epoch 20: Val Loss 3501435.50000
Epoch 21: Val Loss 3465227.00000
Epoch 22: Val Loss 3463519.75000
Epoch 23: Val Loss 3467205.75000
Epoch 24: Val Loss 3493030.75000
Epoch 25: Val Loss 3458545.50000
Epoch 26: Val Loss 3485576.50000
Epoch 27: Val Loss 3457263.50000
Epoch 28: Val Loss 3422409.50000
Epoch 29: Val Loss 3456997.00000
Epoch 30: Val Loss 3434410.25000
Epoch 31: Val Loss 3462803.25000
Epoch 32: Val Loss 3462815.75000
Epoch 33: Val Loss 3439979.75000
Epoch 34: Val Loss 3437591.50000
Epoch 35: Val Loss 3429567.25000
Epoch 36: Val Loss 3458412.75000
Epoch 37: Val Loss 3403245.25000
Epoch 38: Val Loss 3392166.75000
Epoch 39: Val Loss 3453787.00000
Epoch 40: Val Loss 3403614.75000
Epoch 41: Val Loss 3415112.50000
Epoch 42: Val Loss 3412850.25000
Epoch 43: Val Loss 3399425.25000
Epoch 44: Val Loss 3440178.25000
Epoch 45: Val Loss 3419067.25000
Epoch 46: Val Loss 3398988.50000
Epoch 47: Val Loss 3492977.75000
Epoch 48: Val Loss 3394449.75000
Epoch 49: Val Loss 3377250.00000
Epoch 50: Val Loss 3403721.50000
Epoch 51: Val Loss 3376326.25000
Epoch 52: Val Loss 3423645.75000
Epoch 53: Val Loss 3387619.25000
Epoch 54: Val Loss 3462461.25000
Epoch 55: Val Loss 3404391.50000
Epoch 56: Val Loss 3414332.75000
Epoch 57: Val Loss 3414530.25000
Epoch 58: Val Loss 3406125.50000
Epoch 59: Val Loss 3458881.50000
Epoch 60: Val Loss 3380909.75000
Epoch 61: Val Loss 3419435.00000
Epoch 62: Val Loss 3401488.75000
Epoch 63: Val Loss 3407966.25000
Epoch 64: Val Loss 3394663.75000
Epoch 65: Val Loss 3448555.50000
Epoch 66: Val Loss 3401738.75000
Epoch 67: Val Loss 3468529.50000
Epoch 68: Val Loss 3395355.50000
Epoch 69: Val Loss 3429941.25000
Epoch 70: Val Loss 3415617.00000
Epoch 71: Val Loss 3409339.25000
Epoch 72: Val Loss 3420528.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407381.354064229, 'MSE - std': 24278.789854861796, 'R2 - mean': 0.5877285802049541, 'R2 - std': 0.010198913537125043} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4961809.00000
Epoch 1: Val Loss 4553685.50000
Epoch 2: Val Loss 4425734.00000
Epoch 3: Val Loss 4365932.00000
Epoch 4: Val Loss 4356251.50000
Epoch 5: Val Loss 4321465.50000
Epoch 6: Val Loss 4255564.50000
Epoch 7: Val Loss 4256633.50000
Epoch 8: Val Loss 4213381.50000
Epoch 9: Val Loss 4186691.25000
Epoch 10: Val Loss 4147734.50000
Epoch 11: Val Loss 4139844.50000
Epoch 12: Val Loss 4119876.75000
Epoch 13: Val Loss 4100816.00000
Epoch 14: Val Loss 4088972.75000
Epoch 15: Val Loss 4092565.75000
Epoch 16: Val Loss 4082870.50000
Epoch 17: Val Loss 4119044.50000
Epoch 18: Val Loss 4036819.50000
Epoch 19: Val Loss 4034749.50000
Epoch 20: Val Loss 4014468.00000
Epoch 21: Val Loss 4015480.00000
Epoch 22: Val Loss 4016081.75000
Epoch 23: Val Loss 3995260.75000
Epoch 24: Val Loss 3986784.00000
Epoch 25: Val Loss 4031426.75000
Epoch 26: Val Loss 3987070.25000
Epoch 27: Val Loss 3961253.25000
Epoch 28: Val Loss 3961653.75000
Epoch 29: Val Loss 3965124.00000
Epoch 30: Val Loss 3973848.75000
Epoch 31: Val Loss 3950677.75000
Epoch 32: Val Loss 3935777.00000
Epoch 33: Val Loss 3930271.25000
Epoch 34: Val Loss 3925792.00000
Epoch 35: Val Loss 3929637.75000
Epoch 36: Val Loss 3914258.25000
Epoch 37: Val Loss 3913528.25000
Epoch 38: Val Loss 3962266.50000
Epoch 39: Val Loss 3906931.00000
Epoch 40: Val Loss 3913219.50000
Epoch 41: Val Loss 3887119.25000
Epoch 42: Val Loss 3910410.00000
Epoch 43: Val Loss 3976415.25000
Epoch 44: Val Loss 3895602.25000
Epoch 45: Val Loss 3880881.00000
Epoch 46: Val Loss 3884252.25000
Epoch 47: Val Loss 3864883.00000
Epoch 48: Val Loss 3900211.50000
Epoch 49: Val Loss 3866662.25000
Epoch 50: Val Loss 3883227.00000
Epoch 51: Val Loss 3875617.50000
Epoch 52: Val Loss 3865169.50000
Epoch 53: Val Loss 3874675.00000
Epoch 54: Val Loss 3867187.00000
Epoch 55: Val Loss 3851595.75000
Epoch 56: Val Loss 3857891.50000
Epoch 57: Val Loss 3863231.75000
Epoch 58: Val Loss 3918193.00000
Epoch 59: Val Loss 3861316.75000
Epoch 60: Val Loss 3867352.00000
Epoch 61: Val Loss 3853243.75000
Epoch 62: Val Loss 3838962.25000
Epoch 63: Val Loss 3867426.75000
Epoch 64: Val Loss 3851282.25000
Epoch 65: Val Loss 4200103.00000
Epoch 66: Val Loss 3880491.75000
Epoch 67: Val Loss 3854550.25000
Epoch 68: Val Loss 3850584.00000
Epoch 69: Val Loss 3861391.75000
Epoch 70: Val Loss 3862801.00000
Epoch 71: Val Loss 3860843.75000
Epoch 72: Val Loss 3863718.25000
Epoch 73: Val Loss 3859856.00000
Epoch 74: Val Loss 3881278.00000
Epoch 75: Val Loss 3850155.75000
Epoch 76: Val Loss 3876649.25000
Epoch 77: Val Loss 3878700.25000
Epoch 78: Val Loss 3888968.00000
Epoch 79: Val Loss 3930455.50000
Epoch 80: Val Loss 3889475.00000
Epoch 81: Val Loss 3868337.75000
Epoch 82: Val Loss 3898136.75000
Epoch 83: Val Loss 3897050.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3555721.0474927947, 'MSE - std': 210718.5383020985, 'R2 - mean': 0.5814989694444834, 'R2 - std': 0.012122760632206662} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4614962.50000
Epoch 1: Val Loss 4217746.50000
Epoch 2: Val Loss 4128447.75000
Epoch 3: Val Loss 4069579.75000
Epoch 4: Val Loss 4039086.25000
Epoch 5: Val Loss 4008226.25000
Epoch 6: Val Loss 4022308.00000
Epoch 7: Val Loss 3987473.75000
Epoch 8: Val Loss 3971278.00000
Epoch 9: Val Loss 3933688.25000
Epoch 10: Val Loss 3941065.50000
Epoch 11: Val Loss 3939688.00000
Epoch 12: Val Loss 3913266.25000
Epoch 13: Val Loss 3898844.25000
Epoch 14: Val Loss 3887850.00000
Epoch 15: Val Loss 3874241.50000
Epoch 16: Val Loss 3849375.75000
Epoch 17: Val Loss 3835916.25000
Epoch 18: Val Loss 3839028.75000
Epoch 19: Val Loss 3826443.00000
Epoch 20: Val Loss 3816166.25000
Epoch 21: Val Loss 3823198.75000
Epoch 22: Val Loss 3807345.00000
Epoch 23: Val Loss 3809768.25000
Epoch 24: Val Loss 3793974.25000
Epoch 25: Val Loss 3781629.00000
Epoch 26: Val Loss 3756055.50000
Epoch 27: Val Loss 3776368.50000
Epoch 28: Val Loss 3760333.50000
Epoch 29: Val Loss 3775367.50000
Epoch 30: Val Loss 3789507.00000
Epoch 31: Val Loss 3758948.00000
Epoch 32: Val Loss 3743347.00000
Epoch 33: Val Loss 3735795.50000
Epoch 34: Val Loss 3745135.75000
Epoch 35: Val Loss 3754839.00000
Epoch 36: Val Loss 3741528.75000
Epoch 37: Val Loss 3733172.00000
Epoch 38: Val Loss 3745809.00000
Epoch 39: Val Loss 3722391.50000
Epoch 40: Val Loss 3733617.50000
Epoch 41: Val Loss 3726712.75000
Epoch 42: Val Loss 3768708.00000
Epoch 43: Val Loss 3724119.75000
Epoch 44: Val Loss 3707381.75000
Epoch 45: Val Loss 3708214.50000
Epoch 46: Val Loss 3745034.50000
Epoch 47: Val Loss 3727982.75000
Epoch 48: Val Loss 3717592.25000
Epoch 49: Val Loss 3729473.00000
Epoch 50: Val Loss 3725819.25000
Epoch 51: Val Loss 3705893.75000
Epoch 52: Val Loss 3722045.50000
Epoch 53: Val Loss 3755014.25000
Epoch 54: Val Loss 3705380.50000
Epoch 55: Val Loss 3734025.50000
Epoch 56: Val Loss 3767675.25000
Epoch 57: Val Loss 3741431.75000
Epoch 58: Val Loss 3731420.75000
Epoch 59: Val Loss 3748935.00000
Epoch 60: Val Loss 3785373.50000
Epoch 61: Val Loss 3772190.75000
Epoch 62: Val Loss 3747730.25000
Epoch 63: Val Loss 3799479.00000
Epoch 64: Val Loss 3732064.50000
Epoch 65: Val Loss 3757045.25000
Epoch 66: Val Loss 3754730.00000
Epoch 67: Val Loss 3859865.25000
Epoch 68: Val Loss 3787801.25000
Epoch 69: Val Loss 3785646.75000
Epoch 70: Val Loss 3764678.25000
Epoch 71: Val Loss 3807224.25000
Epoch 72: Val Loss 3804165.75000
Epoch 73: Val Loss 3802932.50000
Epoch 74: Val Loss 3857430.50000
Epoch 75: Val Loss 3819237.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3596416.931002416, 'MSE - std': 195627.68615923397, 'R2 - mean': 0.5778577653147723, 'R2 - std': 0.012247289355282309} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4108380.25000
Epoch 1: Val Loss 3708811.25000
Epoch 2: Val Loss 3618591.50000
Epoch 3: Val Loss 3574921.50000
Epoch 4: Val Loss 3545156.25000
Epoch 5: Val Loss 3536680.75000
Epoch 6: Val Loss 3544207.00000
Epoch 7: Val Loss 3480566.25000
Epoch 8: Val Loss 3456407.75000
Epoch 9: Val Loss 3443372.00000
Epoch 10: Val Loss 3439678.75000
Epoch 11: Val Loss 3427834.00000
Epoch 12: Val Loss 3469363.25000
Epoch 13: Val Loss 3431694.75000
Epoch 14: Val Loss 3414888.25000
Epoch 15: Val Loss 3419546.75000
Epoch 16: Val Loss 3457193.50000
Epoch 17: Val Loss 3421450.75000
Epoch 18: Val Loss 3395487.75000
Epoch 19: Val Loss 3390131.75000
Epoch 20: Val Loss 3438047.50000
Epoch 21: Val Loss 3399821.50000
Epoch 22: Val Loss 3392461.75000
Epoch 23: Val Loss 3472289.50000
Epoch 24: Val Loss 3377694.25000
Epoch 25: Val Loss 3406723.00000
Epoch 26: Val Loss 3375895.25000
Epoch 27: Val Loss 3412632.25000
Epoch 28: Val Loss 3430253.75000
Epoch 29: Val Loss 3413102.25000
Epoch 30: Val Loss 3418779.00000
Epoch 31: Val Loss 3466539.50000
Epoch 32: Val Loss 3500362.50000
Epoch 33: Val Loss 3407369.50000
Epoch 34: Val Loss 3455736.25000
Epoch 35: Val Loss 3441726.75000
Epoch 36: Val Loss 3434164.50000
Epoch 37: Val Loss 3390470.00000
Epoch 38: Val Loss 3384508.00000
Epoch 39: Val Loss 3526526.50000
Epoch 40: Val Loss 3417068.50000
Epoch 41: Val Loss 3394425.00000
Epoch 42: Val Loss 3369539.00000
Epoch 43: Val Loss 3393428.25000
Epoch 44: Val Loss 3393835.00000
Epoch 45: Val Loss 3376098.75000
Epoch 46: Val Loss 3445271.00000
Epoch 47: Val Loss 3423572.25000
Epoch 48: Val Loss 3454547.75000
Epoch 49: Val Loss 3451707.00000
Epoch 50: Val Loss 3532058.75000
Epoch 51: Val Loss 3437360.00000
Epoch 52: Val Loss 3400842.25000
Epoch 53: Val Loss 3433593.50000
Epoch 54: Val Loss 3397590.75000
Epoch 55: Val Loss 3440400.50000
Epoch 56: Val Loss 3416927.50000
Epoch 57: Val Loss 3438311.75000
Epoch 58: Val Loss 3423467.25000
Epoch 59: Val Loss 3425134.50000
Epoch 60: Val Loss 3413863.25000
Epoch 61: Val Loss 3476890.25000
Epoch 62: Val Loss 3435426.00000
Epoch 63: Val Loss 3455575.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3552337.684078374, 'MSE - std': 195928.7454948237, 'R2 - mean': 0.5789130783616606, 'R2 - std': 0.011155788620682096} 
 

Saving model.....
Results After CV: {'MSE - mean': 3552337.684078374, 'MSE - std': 195928.7454948237, 'R2 - mean': 0.5789130783616606, 'R2 - std': 0.011155788620682096}
Train time: 5358.201134028985
Inference time: 6.42007602499798
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 21 finished with value: 3552337.684078374 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 12 with value: 3551278.97940188.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4496906.50000
Epoch 1: Val Loss 4064062.00000
Epoch 2: Val Loss 3961139.50000
Epoch 3: Val Loss 3919454.00000
Epoch 4: Val Loss 3863343.75000
Epoch 5: Val Loss 3800705.75000
Epoch 6: Val Loss 3775316.50000
Epoch 7: Val Loss 3745463.00000
Epoch 8: Val Loss 3697467.25000
Epoch 9: Val Loss 3715100.25000
Epoch 10: Val Loss 3652767.25000
Epoch 11: Val Loss 3680934.50000
Epoch 12: Val Loss 3628421.25000
Epoch 13: Val Loss 3630821.75000
Epoch 14: Val Loss 3598902.25000
Epoch 15: Val Loss 3571695.75000
Epoch 16: Val Loss 3638345.50000
Epoch 17: Val Loss 3581893.50000
Epoch 18: Val Loss 3546079.75000
Epoch 19: Val Loss 3568570.50000
Epoch 20: Val Loss 3550667.75000
Epoch 21: Val Loss 3527548.75000
Epoch 22: Val Loss 3532241.00000
Epoch 23: Val Loss 3545818.25000
Epoch 24: Val Loss 3510158.50000
Epoch 25: Val Loss 3517611.00000
Epoch 26: Val Loss 3519215.25000
Epoch 27: Val Loss 3797528.25000
Epoch 28: Val Loss 3501190.50000
Epoch 29: Val Loss 3480328.75000
Epoch 30: Val Loss 3496433.25000
Epoch 31: Val Loss 3456956.00000
Epoch 32: Val Loss 3468995.00000
Epoch 33: Val Loss 3472225.50000
Epoch 34: Val Loss 3459819.25000
Epoch 35: Val Loss 3460472.50000
Epoch 36: Val Loss 3452249.25000
Epoch 37: Val Loss 3483826.00000
Epoch 38: Val Loss 3440102.25000
Epoch 39: Val Loss 3443314.50000
Epoch 40: Val Loss 3435591.25000
Epoch 41: Val Loss 3441186.00000
Epoch 42: Val Loss 3444394.75000
Epoch 43: Val Loss 3520883.00000
Epoch 44: Val Loss 3445379.75000
Epoch 45: Val Loss 3436999.75000
Epoch 46: Val Loss 3422120.00000
Epoch 47: Val Loss 3499653.50000
Epoch 48: Val Loss 3444764.75000
Epoch 49: Val Loss 3426775.75000
Epoch 50: Val Loss 3430246.50000
Epoch 51: Val Loss 3434155.75000
Epoch 52: Val Loss 3443768.50000
Epoch 53: Val Loss 3443609.50000
Epoch 54: Val Loss 3424613.25000
Epoch 55: Val Loss 3439875.25000
Epoch 56: Val Loss 3448467.25000
Epoch 57: Val Loss 3460904.50000
Epoch 58: Val Loss 3452173.75000
Epoch 59: Val Loss 3451659.50000
Epoch 60: Val Loss 3428404.00000
Epoch 61: Val Loss 3453591.75000
Epoch 62: Val Loss 3451686.25000
Epoch 63: Val Loss 3447030.25000
Epoch 64: Val Loss 3453558.25000
Epoch 65: Val Loss 3442419.50000
Epoch 66: Val Loss 3480384.75000
Epoch 67: Val Loss 3468966.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3427344.2734419852, 'MSE - std': 0.0, 'R2 - mean': 0.5984331652790725, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4242607.00000
Epoch 1: Val Loss 3866659.00000
Epoch 2: Val Loss 3777894.50000
Epoch 3: Val Loss 3722735.75000
Epoch 4: Val Loss 3687358.00000
Epoch 5: Val Loss 3675997.50000
Epoch 6: Val Loss 3644927.25000
Epoch 7: Val Loss 3602086.75000
Epoch 8: Val Loss 3601772.75000
Epoch 9: Val Loss 3567055.50000
Epoch 10: Val Loss 3595733.25000
Epoch 11: Val Loss 3555892.25000
Epoch 12: Val Loss 3589403.00000
Epoch 13: Val Loss 3540271.25000
Epoch 14: Val Loss 3504943.75000
Epoch 15: Val Loss 3512823.75000
Epoch 16: Val Loss 3501456.00000
Epoch 17: Val Loss 3483380.75000
Epoch 18: Val Loss 3508539.00000
Epoch 19: Val Loss 3484444.75000
Epoch 20: Val Loss 3494719.00000
Epoch 21: Val Loss 3484287.25000
Epoch 22: Val Loss 3466537.75000
Epoch 23: Val Loss 3447969.50000
Epoch 24: Val Loss 3431908.00000
Epoch 25: Val Loss 3432927.75000
Epoch 26: Val Loss 3429077.00000
Epoch 27: Val Loss 3520118.25000
Epoch 28: Val Loss 3448490.75000
Epoch 29: Val Loss 3418941.50000
Epoch 30: Val Loss 3438010.50000
Epoch 31: Val Loss 3426198.25000
Epoch 32: Val Loss 3414569.25000
Epoch 33: Val Loss 3425636.75000
Epoch 34: Val Loss 3408769.00000
Epoch 35: Val Loss 3416925.75000
Epoch 36: Val Loss 3404644.00000
Epoch 37: Val Loss 3434498.50000
Epoch 38: Val Loss 3434749.25000
Epoch 39: Val Loss 3394908.50000
Epoch 40: Val Loss 3434385.50000
Epoch 41: Val Loss 3408524.75000
Epoch 42: Val Loss 3393414.75000
Epoch 43: Val Loss 3388453.25000
Epoch 44: Val Loss 3380031.75000
Epoch 45: Val Loss 3476248.50000
Epoch 46: Val Loss 3391036.75000
Epoch 47: Val Loss 3406144.25000
Epoch 48: Val Loss 3432136.00000
Epoch 49: Val Loss 3465649.50000
Epoch 50: Val Loss 3398213.25000
Epoch 51: Val Loss 3479653.00000
Epoch 52: Val Loss 3417082.75000
Epoch 53: Val Loss 3450377.25000
Epoch 54: Val Loss 3463473.50000
Epoch 55: Val Loss 3403828.50000
Epoch 56: Val Loss 3466257.75000
Epoch 57: Val Loss 3435964.50000
Epoch 58: Val Loss 3412319.50000
Epoch 59: Val Loss 3415594.00000
Epoch 60: Val Loss 3462363.00000
Epoch 61: Val Loss 3407682.75000
Epoch 62: Val Loss 3408452.75000
Epoch 63: Val Loss 3433476.25000
Epoch 64: Val Loss 3487513.00000
Epoch 65: Val Loss 3434976.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3409268.458247846, 'MSE - std': 18075.815194139024, 'R2 - mean': 0.5874762852182958, 'R2 - std': 0.01095688006077672} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4923955.50000
Epoch 1: Val Loss 4551125.50000
Epoch 2: Val Loss 4468610.50000
Epoch 3: Val Loss 4440706.50000
Epoch 4: Val Loss 4335810.50000
Epoch 5: Val Loss 4311969.50000
Epoch 6: Val Loss 4267688.50000
Epoch 7: Val Loss 4234528.50000
Epoch 8: Val Loss 4214134.50000
Epoch 9: Val Loss 4172431.75000
Epoch 10: Val Loss 5013440.50000
Epoch 11: Val Loss 4147918.75000
Epoch 12: Val Loss 4149839.75000
Epoch 13: Val Loss 4151601.75000
Epoch 14: Val Loss 4081630.00000
Epoch 15: Val Loss 4088670.75000
Epoch 16: Val Loss 4067513.50000
Epoch 17: Val Loss 4050788.00000
Epoch 18: Val Loss 4045076.75000
Epoch 19: Val Loss 4051084.25000
Epoch 20: Val Loss 4024502.50000
Epoch 21: Val Loss 4015008.00000
Epoch 22: Val Loss 4007938.25000
Epoch 23: Val Loss 3987094.50000
Epoch 24: Val Loss 4041580.75000
Epoch 25: Val Loss 4003502.00000
Epoch 26: Val Loss 3993089.50000
Epoch 27: Val Loss 3994831.75000
Epoch 28: Val Loss 4010488.00000
Epoch 29: Val Loss 3969262.75000
Epoch 30: Val Loss 3960319.25000
Epoch 31: Val Loss 3947221.25000
Epoch 32: Val Loss 3930854.25000
Epoch 33: Val Loss 3941481.25000
Epoch 34: Val Loss 4083232.50000
Epoch 35: Val Loss 3920347.00000
Epoch 36: Val Loss 3915390.25000
Epoch 37: Val Loss 3912324.00000
Epoch 38: Val Loss 3907868.75000
Epoch 39: Val Loss 3906575.25000
Epoch 40: Val Loss 3890582.25000
Epoch 41: Val Loss 3910071.00000
Epoch 42: Val Loss 3891950.00000
Epoch 43: Val Loss 3886037.75000
Epoch 44: Val Loss 3898230.25000
Epoch 45: Val Loss 3879436.25000
Epoch 46: Val Loss 3872077.50000
Epoch 47: Val Loss 3879454.25000
Epoch 48: Val Loss 3884719.75000
Epoch 49: Val Loss 3864411.75000
Epoch 50: Val Loss 3865529.25000
Epoch 51: Val Loss 3859350.50000
Epoch 52: Val Loss 3859621.75000
Epoch 53: Val Loss 3873636.00000
Epoch 54: Val Loss 3869643.75000
Epoch 55: Val Loss 3881979.25000
Epoch 56: Val Loss 3866644.75000
Epoch 57: Val Loss 3842948.75000
Epoch 58: Val Loss 3854522.50000
Epoch 59: Val Loss 3891496.25000
Epoch 60: Val Loss 3840546.75000
Epoch 61: Val Loss 3890879.25000
Epoch 62: Val Loss 3865573.75000
Epoch 63: Val Loss 3847027.00000
Epoch 64: Val Loss 3843077.75000
Epoch 65: Val Loss 3854587.25000
Epoch 66: Val Loss 3841016.00000
Epoch 67: Val Loss 3842653.50000
Epoch 68: Val Loss 3846750.00000
Epoch 69: Val Loss 3872465.75000
Epoch 70: Val Loss 3874427.75000
Epoch 71: Val Loss 3856760.75000
Epoch 72: Val Loss 3978905.50000
Epoch 73: Val Loss 3854889.25000
Epoch 74: Val Loss 3873057.00000
Epoch 75: Val Loss 3931687.00000
Epoch 76: Val Loss 3885800.25000
Epoch 77: Val Loss 3869691.75000
Epoch 78: Val Loss 3890044.75000
Epoch 79: Val Loss 3847462.25000
Epoch 80: Val Loss 3889433.50000
Epoch 81: Val Loss 3888358.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3556867.134359889, 'MSE - std': 209257.1666076873, 'R2 - mean': 0.5813433000526212, 'R2 - std': 0.012460437172464409} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4621408.50000
Epoch 1: Val Loss 4216954.00000
Epoch 2: Val Loss 4128016.00000
Epoch 3: Val Loss 4059116.75000
Epoch 4: Val Loss 4052216.00000
Epoch 5: Val Loss 4036481.50000
Epoch 6: Val Loss 3962462.25000
Epoch 7: Val Loss 3938658.75000
Epoch 8: Val Loss 3914185.25000
Epoch 9: Val Loss 3895573.25000
Epoch 10: Val Loss 3881432.25000
Epoch 11: Val Loss 3863004.25000
Epoch 12: Val Loss 3840834.75000
Epoch 13: Val Loss 3829127.50000
Epoch 14: Val Loss 3842264.00000
Epoch 15: Val Loss 3834761.50000
Epoch 16: Val Loss 3811881.50000
Epoch 17: Val Loss 3824503.00000
Epoch 18: Val Loss 3829304.00000
Epoch 19: Val Loss 3785981.50000
Epoch 20: Val Loss 3791410.25000
Epoch 21: Val Loss 3772344.75000
Epoch 22: Val Loss 3782672.00000
Epoch 23: Val Loss 3803505.50000
Epoch 24: Val Loss 3776030.25000
Epoch 25: Val Loss 3750799.25000
Epoch 26: Val Loss 3734871.75000
Epoch 27: Val Loss 3759018.00000
Epoch 28: Val Loss 3739628.25000
Epoch 29: Val Loss 3752446.25000
Epoch 30: Val Loss 3726017.75000
Epoch 31: Val Loss 3732596.50000
Epoch 32: Val Loss 3728888.25000
Epoch 33: Val Loss 3747411.00000
Epoch 34: Val Loss 3731646.25000
Epoch 35: Val Loss 3716615.00000
Epoch 36: Val Loss 3754916.00000
Epoch 37: Val Loss 3710683.25000
Epoch 38: Val Loss 3706616.75000
Epoch 39: Val Loss 3718678.50000
Epoch 40: Val Loss 3727989.75000
Epoch 41: Val Loss 3733688.75000
Epoch 42: Val Loss 3732345.25000
Epoch 43: Val Loss 3795025.00000
Epoch 44: Val Loss 3704776.75000
Epoch 45: Val Loss 3714657.75000
Epoch 46: Val Loss 3712275.00000
Epoch 47: Val Loss 3729887.75000
Epoch 48: Val Loss 3705347.00000
Epoch 49: Val Loss 3716549.25000
Epoch 50: Val Loss 3743835.25000
Epoch 51: Val Loss 3721813.25000
Epoch 52: Val Loss 3705286.50000
Epoch 53: Val Loss 3779059.50000
Epoch 54: Val Loss 3699202.25000
Epoch 55: Val Loss 3732971.25000
Epoch 56: Val Loss 3748141.50000
Epoch 57: Val Loss 3735596.25000
Epoch 58: Val Loss 3700718.75000
Epoch 59: Val Loss 3767606.25000
Epoch 60: Val Loss 3753522.25000
Epoch 61: Val Loss 3754070.25000
Epoch 62: Val Loss 3719155.50000
Epoch 63: Val Loss 3735592.75000
Epoch 64: Val Loss 3734853.25000
Epoch 65: Val Loss 3745406.25000
Epoch 66: Val Loss 3758714.50000
Epoch 67: Val Loss 3751828.75000
Epoch 68: Val Loss 3743019.25000
Epoch 69: Val Loss 3765649.00000
Epoch 70: Val Loss 3803565.50000
Epoch 71: Val Loss 3758079.75000
Epoch 72: Val Loss 3789860.50000
Epoch 73: Val Loss 3755895.00000
Epoch 74: Val Loss 3814101.75000
Epoch 75: Val Loss 3879019.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595289.6972222235, 'MSE - std': 193055.17693974983, 'R2 - mean': 0.5779724005780428, 'R2 - std': 0.012269301557131901} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4191395.25000
Epoch 1: Val Loss 3720256.00000
Epoch 2: Val Loss 3656359.75000
Epoch 3: Val Loss 3565911.25000
Epoch 4: Val Loss 3536204.50000
Epoch 5: Val Loss 3522710.75000
Epoch 6: Val Loss 3483759.75000
Epoch 7: Val Loss 3477771.75000
Epoch 8: Val Loss 3467489.50000
Epoch 9: Val Loss 3443218.75000
Epoch 10: Val Loss 3444827.50000
Epoch 11: Val Loss 3432530.50000
Epoch 12: Val Loss 3435462.75000
Epoch 13: Val Loss 3423102.00000
Epoch 14: Val Loss 3448843.00000
Epoch 15: Val Loss 3426441.50000
Epoch 16: Val Loss 3453246.50000
Epoch 17: Val Loss 3405637.00000
Epoch 18: Val Loss 3434152.75000
Epoch 19: Val Loss 3429424.25000
Epoch 20: Val Loss 3411233.50000
Epoch 21: Val Loss 3441537.00000
Epoch 22: Val Loss 3392909.00000
Epoch 23: Val Loss 3391293.75000
Epoch 24: Val Loss 3385838.00000
Epoch 25: Val Loss 3394699.50000
Epoch 26: Val Loss 3421394.00000
Epoch 27: Val Loss 3392760.75000
Epoch 28: Val Loss 3405292.25000
Epoch 29: Val Loss 3379362.00000
Epoch 30: Val Loss 3432360.25000
Epoch 31: Val Loss 3411411.00000
Epoch 32: Val Loss 3408238.25000
Epoch 33: Val Loss 3451051.75000
Epoch 34: Val Loss 3408089.50000
Epoch 35: Val Loss 3422058.50000
Epoch 36: Val Loss 3415340.50000
Epoch 37: Val Loss 3394468.00000
Epoch 38: Val Loss 3392949.75000
Epoch 39: Val Loss 3441426.00000
Epoch 40: Val Loss 3395611.50000
Epoch 41: Val Loss 3419610.25000
Epoch 42: Val Loss 3416684.50000
Epoch 43: Val Loss 3411598.75000
Epoch 44: Val Loss 3462135.00000
Epoch 45: Val Loss 3389758.75000
Epoch 46: Val Loss 3365027.50000
Epoch 47: Val Loss 3396198.75000
Epoch 48: Val Loss 3425481.50000
Epoch 49: Val Loss 3446942.00000
Epoch 50: Val Loss 3398756.25000
Epoch 51: Val Loss 3425213.00000
Epoch 52: Val Loss 3397381.50000
Epoch 53: Val Loss 3381611.00000
Epoch 54: Val Loss 3398718.25000
Epoch 55: Val Loss 3474648.50000
Epoch 56: Val Loss 3419709.00000
Epoch 57: Val Loss 3379893.25000
Epoch 58: Val Loss 3445866.50000
Epoch 59: Val Loss 3449248.25000
Epoch 60: Val Loss 3433057.50000
Epoch 61: Val Loss 3404837.75000
Epoch 62: Val Loss 3407942.25000
Epoch 63: Val Loss 3393150.75000
Epoch 64: Val Loss 3464275.50000
Epoch 65: Val Loss 3419897.25000
Epoch 66: Val Loss 3462630.25000
Epoch 67: Val Loss 3449404.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551246.41642021, 'MSE - std': 193843.96665826498, 'R2 - mean': 0.5790281833397877, 'R2 - std': 0.011175299437592814} 
 

Saving model.....
Results After CV: {'MSE - mean': 3551246.41642021, 'MSE - std': 193843.96665826498, 'R2 - mean': 0.5790281833397877, 'R2 - std': 0.011175299437592814}
Train time: 5186.573133965791
Inference time: 6.597021353605669
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 22 finished with value: 3551246.41642021 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4519387.00000
Epoch 1: Val Loss 4089835.00000
Epoch 2: Val Loss 4007365.25000
Epoch 3: Val Loss 3942831.25000
Epoch 4: Val Loss 3864290.25000
Epoch 5: Val Loss 3828601.50000
Epoch 6: Val Loss 3845067.25000
Epoch 7: Val Loss 3772898.25000
Epoch 8: Val Loss 3739111.75000
Epoch 9: Val Loss 3704728.25000
Epoch 10: Val Loss 3694351.25000
Epoch 11: Val Loss 3661412.00000
Epoch 12: Val Loss 3658713.25000
Epoch 13: Val Loss 3625070.25000
Epoch 14: Val Loss 3627482.00000
Epoch 15: Val Loss 3611236.25000
Epoch 16: Val Loss 3595450.00000
Epoch 17: Val Loss 3608415.75000
Epoch 18: Val Loss 3567120.00000
Epoch 19: Val Loss 3617115.50000
Epoch 20: Val Loss 3559854.25000
Epoch 21: Val Loss 3542550.75000
Epoch 22: Val Loss 3553321.50000
Epoch 23: Val Loss 3539414.50000
Epoch 24: Val Loss 3518403.25000
Epoch 25: Val Loss 3515068.50000
Epoch 26: Val Loss 3532239.25000
Epoch 27: Val Loss 3495748.00000
Epoch 28: Val Loss 3495746.25000
Epoch 29: Val Loss 3498820.25000
Epoch 30: Val Loss 3514014.00000
Epoch 31: Val Loss 3495516.75000
Epoch 32: Val Loss 3482341.00000
Epoch 33: Val Loss 3484112.25000
Epoch 34: Val Loss 3477691.50000
Epoch 35: Val Loss 3472425.25000
Epoch 36: Val Loss 3465137.50000
Epoch 37: Val Loss 3510003.50000
Epoch 38: Val Loss 3473339.25000
Epoch 39: Val Loss 3461993.00000
Epoch 40: Val Loss 3467640.75000
Epoch 41: Val Loss 3465244.25000
Epoch 42: Val Loss 3453049.75000
Epoch 43: Val Loss 3440523.75000
Epoch 44: Val Loss 3430909.50000
Epoch 45: Val Loss 3443082.75000
Epoch 46: Val Loss 3441133.00000
Epoch 47: Val Loss 3439764.75000
Epoch 48: Val Loss 3423615.00000
Epoch 49: Val Loss 3518238.00000
Epoch 50: Val Loss 3565175.50000
Epoch 51: Val Loss 3445266.25000
Epoch 52: Val Loss 3448617.00000
Epoch 53: Val Loss 3422106.50000
Epoch 54: Val Loss 3477115.00000
Epoch 55: Val Loss 3445819.75000
Epoch 56: Val Loss 3456980.50000
Epoch 57: Val Loss 3450325.25000
Epoch 58: Val Loss 3420508.00000
Epoch 59: Val Loss 3484576.50000
Epoch 60: Val Loss 3456231.75000
Epoch 61: Val Loss 3419286.75000
Epoch 62: Val Loss 3420046.50000
Epoch 63: Val Loss 3487570.00000
Epoch 64: Val Loss 3425684.50000
Epoch 65: Val Loss 3452866.00000
Epoch 66: Val Loss 3494312.00000
Epoch 67: Val Loss 3458068.00000
Epoch 68: Val Loss 3431869.00000
Epoch 69: Val Loss 3453399.25000
Epoch 70: Val Loss 3469529.00000
Epoch 71: Val Loss 3429494.25000
Epoch 72: Val Loss 3471125.50000
Epoch 73: Val Loss 3420671.50000
Epoch 74: Val Loss 3463090.25000
Epoch 75: Val Loss 3483021.75000
Epoch 76: Val Loss 3422551.25000
Epoch 77: Val Loss 3444506.75000
Epoch 78: Val Loss 3483257.50000
Epoch 79: Val Loss 3421500.50000
Epoch 80: Val Loss 3502814.50000
Epoch 81: Val Loss 3448229.75000
Epoch 82: Val Loss 3516491.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3431169.174625569, 'MSE - std': 0.0, 'R2 - mean': 0.5979850184520048, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4249589.50000
Epoch 1: Val Loss 3881178.50000
Epoch 2: Val Loss 3788120.75000
Epoch 3: Val Loss 3732530.75000
Epoch 4: Val Loss 3693249.75000
Epoch 5: Val Loss 3671090.25000
Epoch 6: Val Loss 3634763.75000
Epoch 7: Val Loss 3618747.00000
Epoch 8: Val Loss 3631076.50000
Epoch 9: Val Loss 3577804.00000
Epoch 10: Val Loss 3571655.50000
Epoch 11: Val Loss 3564099.75000
Epoch 12: Val Loss 3536026.00000
Epoch 13: Val Loss 3525353.25000
Epoch 14: Val Loss 3530328.25000
Epoch 15: Val Loss 3527371.25000
Epoch 16: Val Loss 3493196.75000
Epoch 17: Val Loss 3495060.50000
Epoch 18: Val Loss 3492221.00000
Epoch 19: Val Loss 3496728.50000
Epoch 20: Val Loss 3475111.75000
Epoch 21: Val Loss 3448499.75000
Epoch 22: Val Loss 3461075.00000
Epoch 23: Val Loss 3492015.50000
Epoch 24: Val Loss 3454252.75000
Epoch 25: Val Loss 3456710.50000
Epoch 26: Val Loss 3423503.00000
Epoch 27: Val Loss 3473379.75000
Epoch 28: Val Loss 3485453.25000
Epoch 29: Val Loss 3420630.50000
Epoch 30: Val Loss 3480495.25000
Epoch 31: Val Loss 3411871.75000
Epoch 32: Val Loss 3405174.00000
Epoch 33: Val Loss 3435176.50000
Epoch 34: Val Loss 3436006.25000
Epoch 35: Val Loss 3400233.75000
Epoch 36: Val Loss 3426201.00000
Epoch 37: Val Loss 3442458.75000
Epoch 38: Val Loss 3447720.75000
Epoch 39: Val Loss 3410970.25000
Epoch 40: Val Loss 3397434.75000
Epoch 41: Val Loss 3404566.25000
Epoch 42: Val Loss 3386852.25000
Epoch 43: Val Loss 3432154.00000
Epoch 44: Val Loss 3379131.75000
Epoch 45: Val Loss 3390801.75000
Epoch 46: Val Loss 3439393.50000
Epoch 47: Val Loss 3383329.00000
Epoch 48: Val Loss 3422256.00000
Epoch 49: Val Loss 3389265.50000
Epoch 50: Val Loss 3391714.00000
Epoch 51: Val Loss 3416948.25000
Epoch 52: Val Loss 3419466.25000
Epoch 53: Val Loss 3401898.50000
Epoch 54: Val Loss 3448311.75000
Epoch 55: Val Loss 3394889.25000
Epoch 56: Val Loss 3423541.00000
Epoch 57: Val Loss 3375416.50000
Epoch 58: Val Loss 3450958.50000
Epoch 59: Val Loss 3436918.25000
Epoch 60: Val Loss 3398904.25000
Epoch 61: Val Loss 3417134.25000
Epoch 62: Val Loss 3413791.50000
Epoch 63: Val Loss 3412041.50000
Epoch 64: Val Loss 3424279.25000
Epoch 65: Val Loss 3424482.50000
Epoch 66: Val Loss 3410285.00000
Epoch 67: Val Loss 3427659.00000
Epoch 68: Val Loss 3437138.75000
Epoch 69: Val Loss 3436770.50000
Epoch 70: Val Loss 3441891.75000
Epoch 71: Val Loss 3477772.50000
Epoch 72: Val Loss 3426810.00000
Epoch 73: Val Loss 3458593.25000
Epoch 74: Val Loss 3439065.00000
Epoch 75: Val Loss 3416572.75000
Epoch 76: Val Loss 3464483.00000
Epoch 77: Val Loss 3477764.50000
Epoch 78: Val Loss 3459326.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407959.9814184722, 'MSE - std': 23209.193207096774, 'R2 - mean': 0.5876544302582177, 'R2 - std': 0.010330588193787071} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4965265.50000
Epoch 1: Val Loss 4603396.50000
Epoch 2: Val Loss 4442764.50000
Epoch 3: Val Loss 4412382.00000
Epoch 4: Val Loss 4328733.00000
Epoch 5: Val Loss 4294475.00000
Epoch 6: Val Loss 4249631.50000
Epoch 7: Val Loss 4226102.00000
Epoch 8: Val Loss 4211419.00000
Epoch 9: Val Loss 4223229.50000
Epoch 10: Val Loss 4162008.75000
Epoch 11: Val Loss 4166001.50000
Epoch 12: Val Loss 4140110.00000
Epoch 13: Val Loss 4134723.50000
Epoch 14: Val Loss 4112279.50000
Epoch 15: Val Loss 4097284.00000
Epoch 16: Val Loss 4094639.25000
Epoch 17: Val Loss 4103574.25000
Epoch 18: Val Loss 4093857.00000
Epoch 19: Val Loss 4038850.75000
Epoch 20: Val Loss 4057408.00000
Epoch 21: Val Loss 4021032.75000
Epoch 22: Val Loss 4048552.00000
Epoch 23: Val Loss 4016204.25000
Epoch 24: Val Loss 4005440.50000
Epoch 25: Val Loss 3989430.50000
Epoch 26: Val Loss 4014048.00000
Epoch 27: Val Loss 3993502.75000
Epoch 28: Val Loss 4402464.50000
Epoch 29: Val Loss 3964183.50000
Epoch 30: Val Loss 4053020.75000
Epoch 31: Val Loss 3966744.00000
Epoch 32: Val Loss 3956231.00000
Epoch 33: Val Loss 3956729.50000
Epoch 34: Val Loss 3956055.50000
Epoch 35: Val Loss 3927035.75000
Epoch 36: Val Loss 4395247.00000
Epoch 37: Val Loss 3926424.25000
Epoch 38: Val Loss 3923288.25000
Epoch 39: Val Loss 3920400.00000
Epoch 40: Val Loss 3901070.25000
Epoch 41: Val Loss 3906647.00000
Epoch 42: Val Loss 3908758.25000
Epoch 43: Val Loss 3895073.50000
Epoch 44: Val Loss 3892013.00000
Epoch 45: Val Loss 3907339.75000
Epoch 46: Val Loss 3886978.25000
Epoch 47: Val Loss 3918765.50000
Epoch 48: Val Loss 3897891.00000
Epoch 49: Val Loss 3883841.50000
Epoch 50: Val Loss 3896463.75000
Epoch 51: Val Loss 3877340.25000
Epoch 52: Val Loss 3881959.50000
Epoch 53: Val Loss 3881165.00000
Epoch 54: Val Loss 3869248.00000
Epoch 55: Val Loss 3851411.50000
Epoch 56: Val Loss 3874691.50000
Epoch 57: Val Loss 3853712.00000
Epoch 58: Val Loss 3846576.00000
Epoch 59: Val Loss 3861835.75000
Epoch 60: Val Loss 3855375.75000
Epoch 61: Val Loss 3856875.00000
Epoch 62: Val Loss 3871810.75000
Epoch 63: Val Loss 3851420.25000
Epoch 64: Val Loss 3876150.50000
Epoch 65: Val Loss 3874273.00000
Epoch 66: Val Loss 3830219.25000
Epoch 67: Val Loss 3885507.50000
Epoch 68: Val Loss 3879773.50000
Epoch 69: Val Loss 3840566.50000
Epoch 70: Val Loss 3865905.00000
Epoch 71: Val Loss 3842284.25000
Epoch 72: Val Loss 3869662.25000
Epoch 73: Val Loss 3855484.75000
Epoch 74: Val Loss 3862821.75000
Epoch 75: Val Loss 3845169.00000
Epoch 76: Val Loss 3869803.25000
Epoch 77: Val Loss 3844599.00000
Epoch 78: Val Loss 3899943.00000
Epoch 79: Val Loss 3880915.50000
Epoch 80: Val Loss 3874326.25000
Epoch 81: Val Loss 3900610.25000
Epoch 82: Val Loss 3865369.25000
Epoch 83: Val Loss 3877710.75000
Epoch 84: Val Loss 3875758.00000
Epoch 85: Val Loss 3881652.75000
Epoch 86: Val Loss 3872222.75000
Epoch 87: Val Loss 3879727.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553816.3354604295, 'MSE - std': 207140.68438714603, 'R2 - mean': 0.5817057656814781, 'R2 - std': 0.011913042801044637} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4601085.50000
Epoch 1: Val Loss 4252563.50000
Epoch 2: Val Loss 4137163.75000
Epoch 3: Val Loss 4057573.25000
Epoch 4: Val Loss 4110886.50000
Epoch 5: Val Loss 4011615.75000
Epoch 6: Val Loss 4002419.50000
Epoch 7: Val Loss 3931469.00000
Epoch 8: Val Loss 3910081.50000
Epoch 9: Val Loss 3896340.75000
Epoch 10: Val Loss 3890875.25000
Epoch 11: Val Loss 3867915.00000
Epoch 12: Val Loss 3858063.25000
Epoch 13: Val Loss 3879769.25000
Epoch 14: Val Loss 3853689.25000
Epoch 15: Val Loss 3917787.25000
Epoch 16: Val Loss 3829400.00000
Epoch 17: Val Loss 3806660.00000
Epoch 18: Val Loss 3794508.75000
Epoch 19: Val Loss 3777528.25000
Epoch 20: Val Loss 3762284.25000
Epoch 21: Val Loss 3790226.75000
Epoch 22: Val Loss 3754250.50000
Epoch 23: Val Loss 3765927.75000
Epoch 24: Val Loss 3758367.75000
Epoch 25: Val Loss 3745238.50000
Epoch 26: Val Loss 3744183.50000
Epoch 27: Val Loss 3739227.00000
Epoch 28: Val Loss 3731446.50000
Epoch 29: Val Loss 3748257.00000
Epoch 30: Val Loss 3827195.75000
Epoch 31: Val Loss 3733924.75000
Epoch 32: Val Loss 3717873.75000
Epoch 33: Val Loss 3740444.75000
Epoch 34: Val Loss 3722549.25000
Epoch 35: Val Loss 3711155.50000
Epoch 36: Val Loss 3714113.50000
Epoch 37: Val Loss 3714555.00000
Epoch 38: Val Loss 3736880.00000
Epoch 39: Val Loss 3704111.75000
Epoch 40: Val Loss 3706066.75000
Epoch 41: Val Loss 3717192.75000
Epoch 42: Val Loss 3748575.75000
Epoch 43: Val Loss 3703913.25000
Epoch 44: Val Loss 3745497.25000
Epoch 45: Val Loss 3707508.75000
Epoch 46: Val Loss 3699964.25000
Epoch 47: Val Loss 3704736.00000
Epoch 48: Val Loss 3691999.25000
Epoch 49: Val Loss 3726022.25000
Epoch 50: Val Loss 3722996.75000
Epoch 51: Val Loss 3745971.00000
Epoch 52: Val Loss 3720934.50000
Epoch 53: Val Loss 3741596.25000
Epoch 54: Val Loss 3742196.75000
Epoch 55: Val Loss 3725957.25000
Epoch 56: Val Loss 3747052.75000
Epoch 57: Val Loss 3730755.00000
Epoch 58: Val Loss 3753401.25000
Epoch 59: Val Loss 3715795.50000
Epoch 60: Val Loss 3756987.75000
Epoch 61: Val Loss 3762143.25000
Epoch 62: Val Loss 3744127.75000
Epoch 63: Val Loss 3748300.75000
Epoch 64: Val Loss 3763985.00000
Epoch 65: Val Loss 3774136.00000
Epoch 66: Val Loss 3753062.25000
Epoch 67: Val Loss 3768387.50000
Epoch 68: Val Loss 3772211.50000
Epoch 69: Val Loss 3805270.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591705.8911278816, 'MSE - std': 191016.49832491507, 'R2 - mean': 0.5783951508951277, 'R2 - std': 0.011803429686978529} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4184850.75000
Epoch 1: Val Loss 3733206.25000
Epoch 2: Val Loss 3670660.50000
Epoch 3: Val Loss 3576151.75000
Epoch 4: Val Loss 3548311.75000
Epoch 5: Val Loss 3522903.75000
Epoch 6: Val Loss 3485203.75000
Epoch 7: Val Loss 3483027.25000
Epoch 8: Val Loss 3484278.50000
Epoch 9: Val Loss 3450326.25000
Epoch 10: Val Loss 3451693.25000
Epoch 11: Val Loss 3432694.50000
Epoch 12: Val Loss 3422067.00000
Epoch 13: Val Loss 3411407.50000
Epoch 14: Val Loss 3426354.00000
Epoch 15: Val Loss 3462157.50000
Epoch 16: Val Loss 3415175.75000
Epoch 17: Val Loss 3421809.50000
Epoch 18: Val Loss 3447334.25000
Epoch 19: Val Loss 3453114.75000
Epoch 20: Val Loss 3397194.00000
Epoch 21: Val Loss 3423729.00000
Epoch 22: Val Loss 3429685.75000
Epoch 23: Val Loss 3386348.00000
Epoch 24: Val Loss 3421235.75000
Epoch 25: Val Loss 3390525.75000
Epoch 26: Val Loss 3392205.50000
Epoch 27: Val Loss 3422017.00000
Epoch 28: Val Loss 3591235.00000
Epoch 29: Val Loss 3443034.00000
Epoch 30: Val Loss 3415062.25000
Epoch 31: Val Loss 3387566.00000
Epoch 32: Val Loss 3399881.25000
Epoch 33: Val Loss 3397496.25000
Epoch 34: Val Loss 3391544.75000
Epoch 35: Val Loss 3402761.00000
Epoch 36: Val Loss 3390270.75000
Epoch 37: Val Loss 3383393.50000
Epoch 38: Val Loss 3416727.25000
Epoch 39: Val Loss 3404808.25000
Epoch 40: Val Loss 3381629.50000
Epoch 41: Val Loss 3386753.75000
Epoch 42: Val Loss 3396888.50000
Epoch 43: Val Loss 3411022.75000
Epoch 44: Val Loss 3419171.75000
Epoch 45: Val Loss 3407293.75000
Epoch 46: Val Loss 3475527.00000
Epoch 47: Val Loss 3413756.50000
Epoch 48: Val Loss 3431222.00000
Epoch 49: Val Loss 3469577.50000
Epoch 50: Val Loss 3422781.25000
Epoch 51: Val Loss 3389974.25000
Epoch 52: Val Loss 3424428.00000
Epoch 53: Val Loss 3383614.00000
Epoch 54: Val Loss 3396725.25000
Epoch 55: Val Loss 3384363.00000
Epoch 56: Val Loss 3401014.50000
Epoch 57: Val Loss 3407188.50000
Epoch 58: Val Loss 3405595.00000
Epoch 59: Val Loss 3421676.50000
Epoch 60: Val Loss 3414417.25000
Epoch 61: Val Loss 3411821.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551292.639002528, 'MSE - std': 189004.67162279197, 'R2 - mean': 0.579006657958366, 'R2 - std': 0.010627912563336157} 
 

Saving model.....
Results After CV: {'MSE - mean': 3551292.639002528, 'MSE - std': 189004.67162279197, 'R2 - mean': 0.579006657958366, 'R2 - std': 0.010627912563336157}
Train time: 6299.7785727569835
Inference time: 7.291109726589639
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 23 finished with value: 3551292.639002528 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4467502.00000
Epoch 1: Val Loss 4079392.00000
Epoch 2: Val Loss 3975807.25000
Epoch 3: Val Loss 3903538.75000
Epoch 4: Val Loss 3853317.25000
Epoch 5: Val Loss 3806006.25000
Epoch 6: Val Loss 3773096.25000
Epoch 7: Val Loss 3752977.75000
Epoch 8: Val Loss 3722833.50000
Epoch 9: Val Loss 3739389.50000
Epoch 10: Val Loss 3660680.25000
Epoch 11: Val Loss 3666190.75000
Epoch 12: Val Loss 3650150.50000
Epoch 13: Val Loss 3643148.75000
Epoch 14: Val Loss 3613415.75000
Epoch 15: Val Loss 3612619.00000
Epoch 16: Val Loss 3599299.00000
Epoch 17: Val Loss 3569858.75000
Epoch 18: Val Loss 3569202.50000
Epoch 19: Val Loss 3547817.25000
Epoch 20: Val Loss 3543448.75000
Epoch 21: Val Loss 3554878.50000
Epoch 22: Val Loss 3526915.50000
Epoch 23: Val Loss 3511519.75000
Epoch 24: Val Loss 3535120.50000
Epoch 25: Val Loss 3507328.25000
Epoch 26: Val Loss 3519489.75000
Epoch 27: Val Loss 3493486.25000
Epoch 28: Val Loss 3488277.00000
Epoch 29: Val Loss 3718252.75000
Epoch 30: Val Loss 3501843.50000
Epoch 31: Val Loss 3468868.50000
Epoch 32: Val Loss 3483683.75000
Epoch 33: Val Loss 3470365.00000
Epoch 34: Val Loss 3472685.25000
Epoch 35: Val Loss 3454377.00000
Epoch 36: Val Loss 3456899.25000
Epoch 37: Val Loss 3499605.00000
Epoch 38: Val Loss 3463721.25000
Epoch 39: Val Loss 3440530.00000
Epoch 40: Val Loss 3444378.75000
Epoch 41: Val Loss 3435396.50000
Epoch 42: Val Loss 3446311.75000
Epoch 43: Val Loss 3447108.25000
Epoch 44: Val Loss 3450262.00000
Epoch 45: Val Loss 3787978.50000
Epoch 46: Val Loss 3462932.50000
Epoch 47: Val Loss 3434446.00000
Epoch 48: Val Loss 3423724.50000
Epoch 49: Val Loss 3469419.00000
Epoch 50: Val Loss 3434018.75000
Epoch 51: Val Loss 3448282.75000
Epoch 52: Val Loss 3455088.50000
Epoch 53: Val Loss 3443273.50000
Epoch 54: Val Loss 3413012.75000
Epoch 55: Val Loss 3428926.25000
Epoch 56: Val Loss 3443493.25000
Epoch 57: Val Loss 3461043.25000
Epoch 58: Val Loss 3459041.25000
Epoch 59: Val Loss 3418383.50000
Epoch 60: Val Loss 3414779.00000
Epoch 61: Val Loss 3444062.75000
Epoch 62: Val Loss 3445943.25000
Epoch 63: Val Loss 3485273.00000
Epoch 64: Val Loss 3466320.75000
Epoch 65: Val Loss 3456386.25000
Epoch 66: Val Loss 3435823.50000
Epoch 67: Val Loss 3436956.50000
Epoch 68: Val Loss 3489822.25000
Epoch 69: Val Loss 3448958.25000
Epoch 70: Val Loss 3487658.50000
Epoch 71: Val Loss 3515832.75000
Epoch 72: Val Loss 3483397.25000
Epoch 73: Val Loss 3466891.25000
Epoch 74: Val Loss 3502205.25000
Epoch 75: Val Loss 3503711.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3423150.998612876, 'MSE - std': 0.0, 'R2 - mean': 0.5989244728238933, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4232272.50000
Epoch 1: Val Loss 3898691.50000
Epoch 2: Val Loss 3792628.50000
Epoch 3: Val Loss 3729438.25000
Epoch 4: Val Loss 3715873.75000
Epoch 5: Val Loss 3674058.50000
Epoch 6: Val Loss 3641684.75000
Epoch 7: Val Loss 3679950.25000
Epoch 8: Val Loss 3607485.25000
Epoch 9: Val Loss 3583081.00000
Epoch 10: Val Loss 3576715.50000
Epoch 11: Val Loss 3584731.00000
Epoch 12: Val Loss 3563277.00000
Epoch 13: Val Loss 3526307.00000
Epoch 14: Val Loss 3524011.00000
Epoch 15: Val Loss 3523749.75000
Epoch 16: Val Loss 3510277.25000
Epoch 17: Val Loss 3508645.00000
Epoch 18: Val Loss 3475343.00000
Epoch 19: Val Loss 3488419.50000
Epoch 20: Val Loss 3491997.75000
Epoch 21: Val Loss 3562587.00000
Epoch 22: Val Loss 3473072.75000
Epoch 23: Val Loss 3457473.25000
Epoch 24: Val Loss 3471185.25000
Epoch 25: Val Loss 3546167.25000
Epoch 26: Val Loss 3458743.75000
Epoch 27: Val Loss 3450905.50000
Epoch 28: Val Loss 3648982.50000
Epoch 29: Val Loss 3463932.25000
Epoch 30: Val Loss 3421045.75000
Epoch 31: Val Loss 3437553.00000
Epoch 32: Val Loss 3476272.25000
Epoch 33: Val Loss 3470064.25000
Epoch 34: Val Loss 3441013.50000
Epoch 35: Val Loss 3413085.25000
Epoch 36: Val Loss 3455860.00000
Epoch 37: Val Loss 3442675.25000
Epoch 38: Val Loss 3481889.50000
Epoch 39: Val Loss 3429483.75000
Epoch 40: Val Loss 3429226.25000
Epoch 41: Val Loss 3473217.25000
Epoch 42: Val Loss 3411455.75000
Epoch 43: Val Loss 3389172.00000
Epoch 44: Val Loss 3407440.25000
Epoch 45: Val Loss 3429207.50000
Epoch 46: Val Loss 3416734.25000
Epoch 47: Val Loss 3413508.75000
Epoch 48: Val Loss 3427860.50000
Epoch 49: Val Loss 3433880.75000
Epoch 50: Val Loss 3426281.50000
Epoch 51: Val Loss 3442996.50000
Epoch 52: Val Loss 3404268.75000
Epoch 53: Val Loss 3403397.00000
Epoch 54: Val Loss 3480643.25000
Epoch 55: Val Loss 3389267.75000
Epoch 56: Val Loss 3405441.75000
Epoch 57: Val Loss 3430779.00000
Epoch 58: Val Loss 3429068.50000
Epoch 59: Val Loss 3397781.00000
Epoch 60: Val Loss 3405241.25000
Epoch 61: Val Loss 3432045.75000
Epoch 62: Val Loss 3419895.75000
Epoch 63: Val Loss 3451138.75000
Epoch 64: Val Loss 3430703.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3409965.7421101388, 'MSE - std': 13185.256502737058, 'R2 - mean': 0.5873730436111748, 'R2 - std': 0.011551429212718511} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5006337.00000
Epoch 1: Val Loss 4585590.50000
Epoch 2: Val Loss 4453813.50000
Epoch 3: Val Loss 4368200.00000
Epoch 4: Val Loss 4348374.50000
Epoch 5: Val Loss 4278418.50000
Epoch 6: Val Loss 4237204.00000
Epoch 7: Val Loss 4235353.00000
Epoch 8: Val Loss 4190241.75000
Epoch 9: Val Loss 4190244.50000
Epoch 10: Val Loss 4155926.25000
Epoch 11: Val Loss 4130171.75000
Epoch 12: Val Loss 4113403.75000
Epoch 13: Val Loss 4119223.00000
Epoch 14: Val Loss 4088629.25000
Epoch 15: Val Loss 4093537.00000
Epoch 16: Val Loss 4069095.00000
Epoch 17: Val Loss 4074727.50000
Epoch 18: Val Loss 4056859.25000
Epoch 19: Val Loss 4056248.25000
Epoch 20: Val Loss 4031795.50000
Epoch 21: Val Loss 4026814.75000
Epoch 22: Val Loss 4037364.00000
Epoch 23: Val Loss 4016402.75000
Epoch 24: Val Loss 4028257.50000
Epoch 25: Val Loss 4024467.00000
Epoch 26: Val Loss 4000155.25000
Epoch 27: Val Loss 3983526.25000
Epoch 28: Val Loss 3981492.00000
Epoch 29: Val Loss 3976843.00000
Epoch 30: Val Loss 3969309.50000
Epoch 31: Val Loss 3941661.00000
Epoch 32: Val Loss 3955491.50000
Epoch 33: Val Loss 3941715.00000
Epoch 34: Val Loss 3938917.75000
Epoch 35: Val Loss 3956754.25000
Epoch 36: Val Loss 3933713.00000
Epoch 37: Val Loss 3924210.75000
Epoch 38: Val Loss 3918178.25000
Epoch 39: Val Loss 3951098.00000
Epoch 40: Val Loss 3915384.75000
Epoch 41: Val Loss 3931285.75000
Epoch 42: Val Loss 3906482.25000
Epoch 43: Val Loss 3892057.50000
Epoch 44: Val Loss 3881359.25000
Epoch 45: Val Loss 3889846.25000
Epoch 46: Val Loss 3893600.00000
Epoch 47: Val Loss 3904530.25000
Epoch 48: Val Loss 3880724.00000
Epoch 49: Val Loss 3900956.75000
Epoch 50: Val Loss 3877010.25000
Epoch 51: Val Loss 3885697.75000
Epoch 52: Val Loss 3864584.00000
Epoch 53: Val Loss 3857605.25000
Epoch 54: Val Loss 3880201.25000
Epoch 55: Val Loss 3950005.25000
Epoch 56: Val Loss 3856782.75000
Epoch 57: Val Loss 3874781.50000
Epoch 58: Val Loss 3856613.25000
Epoch 59: Val Loss 3867231.25000
Epoch 60: Val Loss 3878562.25000
Epoch 61: Val Loss 3856982.50000
Epoch 62: Val Loss 3876617.25000
Epoch 63: Val Loss 3863646.25000
Epoch 64: Val Loss 3847555.50000
Epoch 65: Val Loss 3840678.25000
Epoch 66: Val Loss 3853537.50000
Epoch 67: Val Loss 3833777.50000
Epoch 68: Val Loss 3860729.50000
Epoch 69: Val Loss 3846824.25000
Epoch 70: Val Loss 3843615.75000
Epoch 71: Val Loss 3849367.00000
Epoch 72: Val Loss 3851378.25000
Epoch 73: Val Loss 3866469.25000
Epoch 74: Val Loss 3860256.50000
Epoch 75: Val Loss 3861745.00000
Epoch 76: Val Loss 3847083.00000
Epoch 77: Val Loss 3851777.00000
Epoch 78: Val Loss 3854634.50000
Epoch 79: Val Loss 3860491.75000
Epoch 80: Val Loss 3873412.50000
Epoch 81: Val Loss 3864871.00000
Epoch 82: Val Loss 3886610.75000
Epoch 83: Val Loss 3858867.50000
Epoch 84: Val Loss 3879941.75000
Epoch 85: Val Loss 3867535.75000
Epoch 86: Val Loss 3882809.25000
Epoch 87: Val Loss 4103206.50000
Epoch 88: Val Loss 3912983.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554443.155030916, 'MSE - std': 204605.34291147793, 'R2 - mean': 0.5815976404750768, 'R2 - std': 0.012476681209621986} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4637663.00000
Epoch 1: Val Loss 4229829.00000
Epoch 2: Val Loss 4115778.25000
Epoch 3: Val Loss 4072923.75000
Epoch 4: Val Loss 4035750.25000
Epoch 5: Val Loss 4001116.25000
Epoch 6: Val Loss 3981824.00000
Epoch 7: Val Loss 3948561.50000
Epoch 8: Val Loss 3931531.75000
Epoch 9: Val Loss 3919908.00000
Epoch 10: Val Loss 3888883.50000
Epoch 11: Val Loss 3882794.00000
Epoch 12: Val Loss 3872942.25000
Epoch 13: Val Loss 3864505.25000
Epoch 14: Val Loss 3850109.00000
Epoch 15: Val Loss 3835019.00000
Epoch 16: Val Loss 3813652.00000
Epoch 17: Val Loss 3851983.25000
Epoch 18: Val Loss 3792429.00000
Epoch 19: Val Loss 3824945.00000
Epoch 20: Val Loss 3782526.25000
Epoch 21: Val Loss 3776925.00000
Epoch 22: Val Loss 3775154.75000
Epoch 23: Val Loss 3759319.50000
Epoch 24: Val Loss 3765266.25000
Epoch 25: Val Loss 3754178.25000
Epoch 26: Val Loss 3781101.50000
Epoch 27: Val Loss 3729302.25000
Epoch 28: Val Loss 3739455.75000
Epoch 29: Val Loss 3754603.75000
Epoch 30: Val Loss 3789003.75000
Epoch 31: Val Loss 3721108.50000
Epoch 32: Val Loss 3733349.75000
Epoch 33: Val Loss 3732142.00000
Epoch 34: Val Loss 3779626.00000
Epoch 35: Val Loss 3735153.50000
Epoch 36: Val Loss 3711982.25000
Epoch 37: Val Loss 3720246.50000
Epoch 38: Val Loss 3720116.75000
Epoch 39: Val Loss 3751905.75000
Epoch 40: Val Loss 3708319.25000
Epoch 41: Val Loss 3704717.50000
Epoch 42: Val Loss 3707350.50000
Epoch 43: Val Loss 3713882.00000
Epoch 44: Val Loss 3707081.50000
Epoch 45: Val Loss 3723882.00000
Epoch 46: Val Loss 3704846.25000
Epoch 47: Val Loss 3710083.50000
Epoch 48: Val Loss 3763543.00000
Epoch 49: Val Loss 3724526.25000
Epoch 50: Val Loss 3726388.50000
Epoch 51: Val Loss 3724677.75000
Epoch 52: Val Loss 3737426.25000
Epoch 53: Val Loss 3744153.25000
Epoch 54: Val Loss 3779403.25000
Epoch 55: Val Loss 3727744.00000
Epoch 56: Val Loss 3730431.25000
Epoch 57: Val Loss 3765175.75000
Epoch 58: Val Loss 3761896.75000
Epoch 59: Val Loss 3775550.75000
Epoch 60: Val Loss 3765859.00000
Epoch 61: Val Loss 3737230.25000
Epoch 62: Val Loss 3752351.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3593088.8361022077, 'MSE - std': 189414.82454479247, 'R2 - mean': 0.5782077466128875, 'R2 - std': 0.012297350190005347} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4120908.25000
Epoch 1: Val Loss 3798234.00000
Epoch 2: Val Loss 3629950.75000
Epoch 3: Val Loss 3578977.00000
Epoch 4: Val Loss 3551137.00000
Epoch 5: Val Loss 3548428.75000
Epoch 6: Val Loss 3485899.75000
Epoch 7: Val Loss 3505109.75000
Epoch 8: Val Loss 3479460.00000
Epoch 9: Val Loss 3439475.50000
Epoch 10: Val Loss 3464910.50000
Epoch 11: Val Loss 3438138.25000
Epoch 12: Val Loss 3469862.00000
Epoch 13: Val Loss 3467315.00000
Epoch 14: Val Loss 3422947.00000
Epoch 15: Val Loss 3427966.00000
Epoch 16: Val Loss 3403399.25000
Epoch 17: Val Loss 3398916.00000
Epoch 18: Val Loss 3399110.75000
Epoch 19: Val Loss 3417097.50000
Epoch 20: Val Loss 3426805.25000
Epoch 21: Val Loss 3397176.25000
Epoch 22: Val Loss 3408448.75000
Epoch 23: Val Loss 3416477.50000
Epoch 24: Val Loss 3413607.75000
Epoch 25: Val Loss 3441076.75000
Epoch 26: Val Loss 3378708.75000
Epoch 27: Val Loss 3399576.00000
Epoch 28: Val Loss 3396922.25000
Epoch 29: Val Loss 3431986.75000
Epoch 30: Val Loss 3388681.00000
Epoch 31: Val Loss 3392531.00000
Epoch 32: Val Loss 3408240.50000
Epoch 33: Val Loss 3414814.50000
Epoch 34: Val Loss 3419667.00000
Epoch 35: Val Loss 3406857.50000
Epoch 36: Val Loss 3419361.00000
Epoch 37: Val Loss 3423635.00000
Epoch 38: Val Loss 3463796.50000
Epoch 39: Val Loss 3445639.00000
Epoch 40: Val Loss 3407250.50000
Epoch 41: Val Loss 3404232.50000
Epoch 42: Val Loss 3440610.25000
Epoch 43: Val Loss 3421276.25000
Epoch 44: Val Loss 3378758.25000
Epoch 45: Val Loss 3420962.25000
Epoch 46: Val Loss 3442493.75000
Epoch 47: Val Loss 3383130.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3552868.9233552376, 'MSE - std': 187544.5177320928, 'R2 - mean': 0.57879870852399, 'R2 - std': 0.011062404859613255} 
 

Saving model.....
Results After CV: {'MSE - mean': 3552868.9233552376, 'MSE - std': 187544.5177320928, 'R2 - mean': 0.57879870852399, 'R2 - std': 0.011062404859613255}
Train time: 5400.380909377209
Inference time: 6.96284212958999
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 24 finished with value: 3552868.9233552376 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8852990.00000
Epoch 1: Val Loss 8301857.00000
Epoch 2: Val Loss 7877354.50000
Epoch 3: Val Loss 7334918.00000
Epoch 4: Val Loss 6658734.00000
Epoch 5: Val Loss 5910258.50000
Epoch 6: Val Loss 5355083.50000
Epoch 7: Val Loss 5000094.50000
Epoch 8: Val Loss 4777279.00000
Epoch 9: Val Loss 4618161.50000
Epoch 10: Val Loss 4502064.00000
Epoch 11: Val Loss 4485578.00000
Epoch 12: Val Loss 4343027.00000
Epoch 13: Val Loss 4317579.50000
Epoch 14: Val Loss 4259945.50000
Epoch 15: Val Loss 4202596.00000
Epoch 16: Val Loss 4178815.25000
Epoch 17: Val Loss 4146091.25000
Epoch 18: Val Loss 4123570.25000
Epoch 19: Val Loss 4096736.50000
Epoch 20: Val Loss 4088703.75000
Epoch 21: Val Loss 4104077.50000
Epoch 22: Val Loss 4057003.00000
Epoch 23: Val Loss 4053312.00000
Epoch 24: Val Loss 4017723.00000
Epoch 25: Val Loss 4020742.25000
Epoch 26: Val Loss 4002249.25000
Epoch 27: Val Loss 3986590.00000
Epoch 28: Val Loss 3969461.25000
Epoch 29: Val Loss 3975192.00000
Epoch 30: Val Loss 3954768.50000
Epoch 31: Val Loss 3945134.00000
Epoch 32: Val Loss 3933444.00000
Epoch 33: Val Loss 3930767.75000
Epoch 34: Val Loss 3926873.50000
Epoch 35: Val Loss 3928491.00000
Epoch 36: Val Loss 3911748.75000
Epoch 37: Val Loss 3905098.00000
Epoch 38: Val Loss 3893029.25000
Epoch 39: Val Loss 3892796.75000
Epoch 40: Val Loss 3881888.50000
Epoch 41: Val Loss 3869588.50000
Epoch 42: Val Loss 3860127.25000
Epoch 43: Val Loss 3857745.75000
Epoch 44: Val Loss 3869133.50000
Epoch 45: Val Loss 3846539.75000
Epoch 46: Val Loss 3861655.00000
Epoch 47: Val Loss 3849095.50000
Epoch 48: Val Loss 3836315.25000
Epoch 49: Val Loss 3831070.00000
Epoch 50: Val Loss 3840981.25000
Epoch 51: Val Loss 3817902.00000
Epoch 52: Val Loss 3813353.25000
Epoch 53: Val Loss 3804828.75000
Epoch 54: Val Loss 3791845.75000
Epoch 55: Val Loss 3796452.50000
Epoch 56: Val Loss 3798414.25000
Epoch 57: Val Loss 3788288.00000
Epoch 58: Val Loss 3795655.50000
Epoch 59: Val Loss 3859073.00000
Epoch 60: Val Loss 3805207.00000
Epoch 61: Val Loss 3772580.00000
Epoch 62: Val Loss 3757000.25000
Epoch 63: Val Loss 3758692.00000
Epoch 64: Val Loss 3755905.50000
Epoch 65: Val Loss 3754829.50000
Epoch 66: Val Loss 3751287.75000
Epoch 67: Val Loss 3759613.50000
Epoch 68: Val Loss 3749022.75000
Epoch 69: Val Loss 3734274.25000
Epoch 70: Val Loss 3730062.75000
Epoch 71: Val Loss 3730614.25000
Epoch 72: Val Loss 3736228.00000
Epoch 73: Val Loss 3716785.50000
Epoch 74: Val Loss 3730194.25000
Epoch 75: Val Loss 3727677.50000
Epoch 76: Val Loss 3715781.75000
Epoch 77: Val Loss 3730189.00000
Epoch 78: Val Loss 3705089.75000
Epoch 79: Val Loss 3707777.50000
Epoch 80: Val Loss 3708376.75000
Epoch 81: Val Loss 3695001.25000
Epoch 82: Val Loss 3693952.00000
Epoch 83: Val Loss 3687710.75000
Epoch 84: Val Loss 3687673.25000
Epoch 85: Val Loss 3684258.75000
Epoch 86: Val Loss 3688912.00000
Epoch 87: Val Loss 3679317.75000
Epoch 88: Val Loss 3675085.00000
Epoch 89: Val Loss 3691771.75000
Epoch 90: Val Loss 3686989.00000
Epoch 91: Val Loss 3672480.50000
Epoch 92: Val Loss 3674511.25000
Epoch 93: Val Loss 3674712.75000
Epoch 94: Val Loss 3665994.50000
Epoch 95: Val Loss 3671140.50000
Epoch 96: Val Loss 3659697.00000
Epoch 97: Val Loss 3659717.75000
Epoch 98: Val Loss 3652113.50000
Epoch 99: Val Loss 3656591.25000
Saved Losses
{'MSE - mean': 3665246.036629613, 'MSE - std': 0.0, 'R2 - mean': 0.5705592633900622, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8161132.50000
Epoch 1: Val Loss 7728566.00000
Epoch 2: Val Loss 7307769.50000
Epoch 3: Val Loss 6781833.00000
Epoch 4: Val Loss 6100502.50000
Epoch 5: Val Loss 5362798.50000
Epoch 6: Val Loss 4893879.00000
Epoch 7: Val Loss 4746137.00000
Epoch 8: Val Loss 4478636.00000
Epoch 9: Val Loss 4295593.00000
Epoch 10: Val Loss 4196770.00000
Epoch 11: Val Loss 4135322.50000
Epoch 12: Val Loss 4086065.75000
Epoch 13: Val Loss 4029428.75000
Epoch 14: Val Loss 4000204.25000
Epoch 15: Val Loss 3975924.75000
Epoch 16: Val Loss 3939152.50000
Epoch 17: Val Loss 3931286.25000
Epoch 18: Val Loss 3903927.00000
Epoch 19: Val Loss 3929403.25000
Epoch 20: Val Loss 3889204.50000
Epoch 21: Val Loss 3854370.25000
Epoch 22: Val Loss 3841356.25000
Epoch 23: Val Loss 3858210.75000
Epoch 24: Val Loss 3827076.50000
Epoch 25: Val Loss 3810193.00000
Epoch 26: Val Loss 3802519.00000
Epoch 27: Val Loss 3791771.75000
Epoch 28: Val Loss 3779353.50000
Epoch 29: Val Loss 3785991.50000
Epoch 30: Val Loss 3774788.75000
Epoch 31: Val Loss 3759697.50000
Epoch 32: Val Loss 3748295.50000
Epoch 33: Val Loss 3761895.75000
Epoch 34: Val Loss 3779720.25000
Epoch 35: Val Loss 3793322.50000
Epoch 36: Val Loss 3767182.75000
Epoch 37: Val Loss 3732750.75000
Epoch 38: Val Loss 3727022.00000
Epoch 39: Val Loss 3730214.50000
Epoch 40: Val Loss 3717242.50000
Epoch 41: Val Loss 3711090.75000
Epoch 42: Val Loss 3715506.75000
Epoch 43: Val Loss 3703550.25000
Epoch 44: Val Loss 3706225.75000
Epoch 45: Val Loss 3723980.25000
Epoch 46: Val Loss 3699879.50000
Epoch 47: Val Loss 3713131.00000
Epoch 48: Val Loss 3682347.25000
Epoch 49: Val Loss 3693739.00000
Epoch 50: Val Loss 3673949.50000
Epoch 51: Val Loss 3686746.00000
Epoch 52: Val Loss 3682024.25000
Epoch 53: Val Loss 3688378.00000
Epoch 54: Val Loss 3661620.75000
Epoch 55: Val Loss 3671920.50000
Epoch 56: Val Loss 3666966.25000
Epoch 57: Val Loss 3655141.75000
Epoch 58: Val Loss 3655468.75000
Epoch 59: Val Loss 3645563.00000
Epoch 60: Val Loss 3646620.75000
Epoch 61: Val Loss 3648647.50000
Epoch 62: Val Loss 3645774.25000
Epoch 63: Val Loss 3631917.50000
Epoch 64: Val Loss 3652270.75000
Epoch 65: Val Loss 3640865.75000
Epoch 66: Val Loss 3627178.25000
Epoch 67: Val Loss 3624188.25000
Epoch 68: Val Loss 3625546.25000
Epoch 69: Val Loss 3634174.25000
Epoch 70: Val Loss 3623861.00000
Epoch 71: Val Loss 3606439.50000
Epoch 72: Val Loss 3605577.25000
Epoch 73: Val Loss 3607544.50000
Epoch 74: Val Loss 3606494.75000
Epoch 75: Val Loss 3603436.25000
Epoch 76: Val Loss 3606485.75000
Epoch 77: Val Loss 3597418.75000
Epoch 78: Val Loss 3614440.00000
Epoch 79: Val Loss 3596432.25000
Epoch 80: Val Loss 3609628.00000
Epoch 81: Val Loss 3600969.75000
Epoch 82: Val Loss 3624303.75000
Epoch 83: Val Loss 3620547.00000
Epoch 84: Val Loss 3604123.25000
Epoch 85: Val Loss 3578695.75000
Epoch 86: Val Loss 3576504.00000
Epoch 87: Val Loss 3586724.75000
Epoch 88: Val Loss 3584049.00000
Epoch 89: Val Loss 3575123.00000
Epoch 90: Val Loss 3565753.50000
Epoch 91: Val Loss 3577238.25000
Epoch 92: Val Loss 3599534.00000
Epoch 93: Val Loss 3898307.50000
Epoch 94: Val Loss 3561083.00000
Epoch 95: Val Loss 3590089.25000
Epoch 96: Val Loss 3561816.50000
Epoch 97: Val Loss 3560693.00000
Epoch 98: Val Loss 3574257.75000
Epoch 99: Val Loss 3559871.25000
Saved Losses
{'MSE - mean': 3616417.7528364705, 'MSE - std': 48828.28379314253, 'R2 - mean': 0.5625254166552469, 'R2 - std': 0.00803384673481533} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9207269.00000
Epoch 1: Val Loss 8651749.00000
Epoch 2: Val Loss 8267653.50000
Epoch 3: Val Loss 7748570.00000
Epoch 4: Val Loss 7030447.00000
Epoch 5: Val Loss 6325992.50000
Epoch 6: Val Loss 5795299.00000
Epoch 7: Val Loss 5456239.00000
Epoch 8: Val Loss 5243466.50000
Epoch 9: Val Loss 5102074.00000
Epoch 10: Val Loss 4971333.50000
Epoch 11: Val Loss 4923160.00000
Epoch 12: Val Loss 4880320.50000
Epoch 13: Val Loss 4804391.50000
Epoch 14: Val Loss 4716042.50000
Epoch 15: Val Loss 4701431.00000
Epoch 16: Val Loss 4645458.00000
Epoch 17: Val Loss 4617184.00000
Epoch 18: Val Loss 4623870.00000
Epoch 19: Val Loss 4584519.50000
Epoch 20: Val Loss 4568963.50000
Epoch 21: Val Loss 4531774.50000
Epoch 22: Val Loss 4528067.00000
Epoch 23: Val Loss 4536615.00000
Epoch 24: Val Loss 4537020.50000
Epoch 25: Val Loss 4478963.50000
Epoch 26: Val Loss 4464125.00000
Epoch 27: Val Loss 4455826.50000
Epoch 28: Val Loss 4446305.00000
Epoch 29: Val Loss 4454038.50000
Epoch 30: Val Loss 4435692.00000
Epoch 31: Val Loss 4421498.00000
Epoch 32: Val Loss 4425591.00000
Epoch 33: Val Loss 4404182.00000
Epoch 34: Val Loss 4393771.50000
Epoch 35: Val Loss 4400050.00000
Epoch 36: Val Loss 4387493.50000
Epoch 37: Val Loss 4404613.50000
Epoch 38: Val Loss 4364326.50000
Epoch 39: Val Loss 4358389.00000
Epoch 40: Val Loss 4393545.50000
Epoch 41: Val Loss 4345888.50000
Epoch 42: Val Loss 4347006.50000
Epoch 43: Val Loss 4349993.50000
Epoch 44: Val Loss 4328074.50000
Epoch 45: Val Loss 4320678.00000
Epoch 46: Val Loss 4323273.00000
Epoch 47: Val Loss 4312098.00000
Epoch 48: Val Loss 4323756.50000
Epoch 49: Val Loss 4310592.50000
Epoch 50: Val Loss 4303685.50000
Epoch 51: Val Loss 4295772.00000
Epoch 52: Val Loss 4294944.50000
Epoch 53: Val Loss 4282814.50000
Epoch 54: Val Loss 4297451.00000
Epoch 55: Val Loss 4274881.50000
Epoch 56: Val Loss 4281327.00000
Epoch 57: Val Loss 4270046.50000
Epoch 58: Val Loss 4272366.00000
Epoch 59: Val Loss 4268365.00000
Epoch 60: Val Loss 4254276.00000
Epoch 61: Val Loss 4254268.50000
Epoch 62: Val Loss 4275927.00000
Epoch 63: Val Loss 4237406.00000
Epoch 64: Val Loss 4238647.50000
Epoch 65: Val Loss 4243909.50000
Epoch 66: Val Loss 4263527.50000
Epoch 67: Val Loss 4225491.00000
Epoch 68: Val Loss 4234876.00000
Epoch 69: Val Loss 4222098.00000
Epoch 70: Val Loss 4217091.50000
Epoch 71: Val Loss 4213847.50000
Epoch 72: Val Loss 4233701.50000
Epoch 73: Val Loss 4223321.00000
Epoch 74: Val Loss 4213552.50000
Epoch 75: Val Loss 4200168.00000
Epoch 76: Val Loss 4202085.50000
Epoch 77: Val Loss 4197120.50000
Epoch 78: Val Loss 4219302.00000
Epoch 79: Val Loss 4230501.50000
Epoch 80: Val Loss 4195682.50000
Epoch 81: Val Loss 4232408.00000
Epoch 82: Val Loss 4202525.50000
Epoch 83: Val Loss 4177193.25000
Epoch 84: Val Loss 4174919.50000
Epoch 85: Val Loss 4170421.75000
Epoch 86: Val Loss 4181875.25000
Epoch 87: Val Loss 4190494.25000
Epoch 88: Val Loss 4194400.50000
Epoch 89: Val Loss 4179272.25000
Epoch 90: Val Loss 4157685.25000
Epoch 91: Val Loss 4168838.25000
Epoch 92: Val Loss 4207444.00000
Epoch 93: Val Loss 4183188.50000
Epoch 94: Val Loss 4151139.50000
Epoch 95: Val Loss 4153593.25000
Epoch 96: Val Loss 4152295.50000
Epoch 97: Val Loss 4162136.25000
Epoch 98: Val Loss 4165248.50000
Epoch 99: Val Loss 4141267.25000
Saved Losses
{'MSE - mean': 3796169.1574831097, 'MSE - std': 257314.20962901006, 'R2 - mean': 0.5533880692399367, 'R2 - std': 0.014491745851178723} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9218531.00000
Epoch 1: Val Loss 8378210.00000
Epoch 2: Val Loss 8028571.00000
Epoch 3: Val Loss 7585827.50000
Epoch 4: Val Loss 7003199.50000
Epoch 5: Val Loss 6326465.50000
Epoch 6: Val Loss 5694140.00000
Epoch 7: Val Loss 5280785.00000
Epoch 8: Val Loss 5107954.50000
Epoch 9: Val Loss 4841122.50000
Epoch 10: Val Loss 4696523.50000
Epoch 11: Val Loss 4683405.00000
Epoch 12: Val Loss 4532901.00000
Epoch 13: Val Loss 4481771.50000
Epoch 14: Val Loss 4435164.50000
Epoch 15: Val Loss 4416802.50000
Epoch 16: Val Loss 4358888.00000
Epoch 17: Val Loss 4363383.00000
Epoch 18: Val Loss 4305069.00000
Epoch 19: Val Loss 4283603.50000
Epoch 20: Val Loss 4264730.50000
Epoch 21: Val Loss 4247016.50000
Epoch 22: Val Loss 4234263.00000
Epoch 23: Val Loss 4238234.50000
Epoch 24: Val Loss 4209955.00000
Epoch 25: Val Loss 4196614.00000
Epoch 26: Val Loss 4190546.25000
Epoch 27: Val Loss 4179752.75000
Epoch 28: Val Loss 4167208.25000
Epoch 29: Val Loss 4149656.75000
Epoch 30: Val Loss 4143514.50000
Epoch 31: Val Loss 4135019.25000
Epoch 32: Val Loss 4136889.50000
Epoch 33: Val Loss 4125822.00000
Epoch 34: Val Loss 4112009.50000
Epoch 35: Val Loss 4111848.75000
Epoch 36: Val Loss 4103098.00000
Epoch 37: Val Loss 4099937.00000
Epoch 38: Val Loss 4088051.50000
Epoch 39: Val Loss 4089401.25000
Epoch 40: Val Loss 4075800.00000
Epoch 41: Val Loss 4085044.00000
Epoch 42: Val Loss 4085055.75000
Epoch 43: Val Loss 4056234.50000
Epoch 44: Val Loss 4074392.75000
Epoch 45: Val Loss 4055468.25000
Epoch 46: Val Loss 4040548.75000
Epoch 47: Val Loss 4033204.50000
Epoch 48: Val Loss 4027643.75000
Epoch 49: Val Loss 4072595.25000
Epoch 50: Val Loss 4018442.00000
Epoch 51: Val Loss 4018663.50000
Epoch 52: Val Loss 4028396.75000
Epoch 53: Val Loss 4038349.00000
Epoch 54: Val Loss 3999583.75000
Epoch 55: Val Loss 3998896.50000
Epoch 56: Val Loss 4145139.50000
Epoch 57: Val Loss 4011307.00000
Epoch 58: Val Loss 3992686.75000
Epoch 59: Val Loss 3979883.00000
Epoch 60: Val Loss 3975847.50000
Epoch 61: Val Loss 3971432.25000
Epoch 62: Val Loss 3968488.75000
Epoch 63: Val Loss 3966740.75000
Epoch 64: Val Loss 3975284.50000
Epoch 65: Val Loss 3953580.75000
Epoch 66: Val Loss 4012622.00000
Epoch 67: Val Loss 3956682.00000
Epoch 68: Val Loss 3942784.50000
Epoch 69: Val Loss 3954666.50000
Epoch 70: Val Loss 3935593.50000
Epoch 71: Val Loss 3939819.75000
Epoch 72: Val Loss 3947402.00000
Epoch 73: Val Loss 3968737.75000
Epoch 74: Val Loss 3927934.00000
Epoch 75: Val Loss 3930123.25000
Epoch 76: Val Loss 3925967.25000
Epoch 77: Val Loss 3962465.50000
Epoch 78: Val Loss 3934948.50000
Epoch 79: Val Loss 3908778.50000
Epoch 80: Val Loss 3910219.00000
Epoch 81: Val Loss 3918749.00000
Epoch 82: Val Loss 3906406.50000
Epoch 83: Val Loss 3912147.00000
Epoch 84: Val Loss 3920970.00000
Epoch 85: Val Loss 3904072.00000
Epoch 86: Val Loss 3935358.25000
Epoch 87: Val Loss 3894414.00000
Epoch 88: Val Loss 3905624.25000
Epoch 89: Val Loss 3885643.00000
Epoch 90: Val Loss 3884734.25000
Epoch 91: Val Loss 3890004.50000
Epoch 92: Val Loss 3885262.00000
Epoch 93: Val Loss 3885459.50000
Epoch 94: Val Loss 3886318.00000
Epoch 95: Val Loss 3871336.00000
Epoch 96: Val Loss 3903258.50000
Epoch 97: Val Loss 3881028.75000
Epoch 98: Val Loss 3885680.50000
Epoch 99: Val Loss 3871006.75000
Saved Losses
{'MSE - mean': 3817160.3787100893, 'MSE - std': 225787.16961676895, 'R2 - mean': 0.5520686527445409, 'R2 - std': 0.012756590572184043} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8252676.50000
Epoch 1: Val Loss 7770911.50000
Epoch 2: Val Loss 7385196.50000
Epoch 3: Val Loss 6842671.50000
Epoch 4: Val Loss 6074329.00000
Epoch 5: Val Loss 5363694.00000
Epoch 6: Val Loss 4874559.50000
Epoch 7: Val Loss 4562967.50000
Epoch 8: Val Loss 4342911.50000
Epoch 9: Val Loss 4215472.50000
Epoch 10: Val Loss 4199165.50000
Epoch 11: Val Loss 4035259.25000
Epoch 12: Val Loss 3976863.75000
Epoch 13: Val Loss 3925841.00000
Epoch 14: Val Loss 3899574.50000
Epoch 15: Val Loss 3842793.25000
Epoch 16: Val Loss 3823155.50000
Epoch 17: Val Loss 3794069.25000
Epoch 18: Val Loss 3761080.75000
Epoch 19: Val Loss 3739330.25000
Epoch 20: Val Loss 3733598.25000
Epoch 21: Val Loss 3708798.00000
Epoch 22: Val Loss 3712775.00000
Epoch 23: Val Loss 3693994.00000
Epoch 24: Val Loss 3673731.00000
Epoch 25: Val Loss 3661972.00000
Epoch 26: Val Loss 3658615.75000
Epoch 27: Val Loss 3652273.75000
Epoch 28: Val Loss 3647223.75000
Epoch 29: Val Loss 3652851.00000
Epoch 30: Val Loss 3622289.25000
Epoch 31: Val Loss 3632576.00000
Epoch 32: Val Loss 3623247.50000
Epoch 33: Val Loss 3610219.00000
Epoch 34: Val Loss 3597201.25000
Epoch 35: Val Loss 3603064.00000
Epoch 36: Val Loss 3595379.50000
Epoch 37: Val Loss 3585563.00000
Epoch 38: Val Loss 3580951.00000
Epoch 39: Val Loss 3565258.75000
Epoch 40: Val Loss 3560831.25000
Epoch 41: Val Loss 3559229.25000
Epoch 42: Val Loss 3560730.75000
Epoch 43: Val Loss 3548988.75000
Epoch 44: Val Loss 3556309.25000
Epoch 45: Val Loss 3539332.00000
Epoch 46: Val Loss 3539636.25000
Epoch 47: Val Loss 3535455.25000
Epoch 48: Val Loss 3533452.25000
Epoch 49: Val Loss 3531860.75000
Epoch 50: Val Loss 3544036.25000
Epoch 51: Val Loss 3522128.00000
Epoch 52: Val Loss 3525040.00000
Epoch 53: Val Loss 3517058.50000
Epoch 54: Val Loss 3514787.25000
Epoch 55: Val Loss 3508868.75000
Epoch 56: Val Loss 3511165.00000
Epoch 57: Val Loss 3504660.50000
Epoch 58: Val Loss 3515258.75000
Epoch 59: Val Loss 3542909.50000
Epoch 60: Val Loss 3517526.75000
Epoch 61: Val Loss 3511265.50000
Epoch 62: Val Loss 3505085.25000
Epoch 63: Val Loss 3511036.25000
Epoch 64: Val Loss 3500694.75000
Epoch 65: Val Loss 3504473.50000
Epoch 66: Val Loss 3506165.50000
Epoch 67: Val Loss 3496586.25000
Epoch 68: Val Loss 3538158.25000
Epoch 69: Val Loss 3475383.25000
Epoch 70: Val Loss 3492297.50000
Epoch 71: Val Loss 3480166.25000
Epoch 72: Val Loss 3501497.00000
Epoch 73: Val Loss 3467854.00000
Epoch 74: Val Loss 3464297.75000
Epoch 75: Val Loss 3474423.25000
Epoch 76: Val Loss 3470255.25000
Epoch 77: Val Loss 3470318.25000
Epoch 78: Val Loss 3465807.75000
Epoch 79: Val Loss 3487589.25000
Epoch 80: Val Loss 3460556.50000
Epoch 81: Val Loss 3454502.50000
Epoch 82: Val Loss 3457653.50000
Epoch 83: Val Loss 3470722.25000
Epoch 84: Val Loss 3454178.25000
Epoch 85: Val Loss 3457658.25000
Epoch 86: Val Loss 3451355.00000
Epoch 87: Val Loss 3453262.50000
Epoch 88: Val Loss 3461250.75000
Epoch 89: Val Loss 3462270.50000
Epoch 90: Val Loss 3450508.75000
Epoch 91: Val Loss 3446773.00000
Epoch 92: Val Loss 3445223.00000
Epoch 93: Val Loss 3449911.50000
Epoch 94: Val Loss 3443529.75000
Epoch 95: Val Loss 3440694.25000
Epoch 96: Val Loss 3435487.75000
Epoch 97: Val Loss 3436946.50000
Epoch 98: Val Loss 3442861.00000
Epoch 99: Val Loss 3436055.50000
Saved Losses
{'MSE - mean': 3743403.7792845615, 'MSE - std': 250088.02571517136, 'R2 - mean': 0.5564948906097615, 'R2 - std': 0.01444128834208083} 
 

Saving model.....
Results After CV: {'MSE - mean': 3743403.7792845615, 'MSE - std': 250088.02571517136, 'R2 - mean': 0.5564948906097615, 'R2 - std': 0.01444128834208083}
Train time: 7517.645825953607
Inference time: 6.762196318584029
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 25 finished with value: 3743403.7792845615 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -5, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4489785.00000
Epoch 1: Val Loss 4080690.75000
Epoch 2: Val Loss 3971247.25000
Epoch 3: Val Loss 3894616.25000
Epoch 4: Val Loss 3852411.25000
Epoch 5: Val Loss 3810483.50000
Epoch 6: Val Loss 3766610.25000
Epoch 7: Val Loss 3751853.00000
Epoch 8: Val Loss 3737488.00000
Epoch 9: Val Loss 3717109.75000
Epoch 10: Val Loss 3676692.00000
Epoch 11: Val Loss 3661091.00000
Epoch 12: Val Loss 3668825.50000
Epoch 13: Val Loss 3649157.25000
Epoch 14: Val Loss 3628177.75000
Epoch 15: Val Loss 3602857.75000
Epoch 16: Val Loss 3606187.75000
Epoch 17: Val Loss 3607616.00000
Epoch 18: Val Loss 3570635.50000
Epoch 19: Val Loss 3573409.50000
Epoch 20: Val Loss 3580876.00000
Epoch 21: Val Loss 3580164.00000
Epoch 22: Val Loss 3547018.75000
Epoch 23: Val Loss 3545934.25000
Epoch 24: Val Loss 3509306.75000
Epoch 25: Val Loss 3598496.75000
Epoch 26: Val Loss 3505955.75000
Epoch 27: Val Loss 3501134.00000
Epoch 28: Val Loss 3515572.00000
Epoch 29: Val Loss 3501487.50000
Epoch 30: Val Loss 3475075.25000
Epoch 31: Val Loss 3473976.00000
Epoch 32: Val Loss 3468023.00000
Epoch 33: Val Loss 3513105.75000
Epoch 34: Val Loss 3462306.75000
Epoch 35: Val Loss 3473628.25000
Epoch 36: Val Loss 3447810.25000
Epoch 37: Val Loss 3503679.50000
Epoch 38: Val Loss 3439825.50000
Epoch 39: Val Loss 3441280.25000
Epoch 40: Val Loss 3455731.25000
Epoch 41: Val Loss 3464308.50000
Epoch 42: Val Loss 3567397.25000
Epoch 43: Val Loss 3495014.50000
Epoch 44: Val Loss 3433493.25000
Epoch 45: Val Loss 3449471.50000
Epoch 46: Val Loss 3444480.50000
Epoch 47: Val Loss 3436639.25000
Epoch 48: Val Loss 3431141.25000
Epoch 49: Val Loss 3459123.50000
Epoch 50: Val Loss 3518209.75000
Epoch 51: Val Loss 3433817.00000
Epoch 52: Val Loss 3455728.50000
Epoch 53: Val Loss 3449448.25000
Epoch 54: Val Loss 3502481.00000
Epoch 55: Val Loss 3435602.00000
Epoch 56: Val Loss 3414834.75000
Epoch 57: Val Loss 3451615.25000
Epoch 58: Val Loss 3432321.25000
Epoch 59: Val Loss 3434786.00000
Epoch 60: Val Loss 3432598.75000
Epoch 61: Val Loss 3462371.00000
Epoch 62: Val Loss 3453036.50000
Epoch 63: Val Loss 3455956.00000
Epoch 64: Val Loss 3447367.75000
Epoch 65: Val Loss 3468281.25000
Epoch 66: Val Loss 3533204.00000
Epoch 67: Val Loss 3509319.00000
Epoch 68: Val Loss 3417080.00000
Epoch 69: Val Loss 3473763.00000
Epoch 70: Val Loss 3475747.50000
Epoch 71: Val Loss 3450307.00000
Epoch 72: Val Loss 3464067.50000
Epoch 73: Val Loss 3473669.75000
Epoch 74: Val Loss 3470998.25000
Epoch 75: Val Loss 3476124.25000
Epoch 76: Val Loss 3545529.00000
Epoch 77: Val Loss 3485547.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3422250.445925444, 'MSE - std': 0.0, 'R2 - mean': 0.5990299866163051, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4267876.50000
Epoch 1: Val Loss 3899240.75000
Epoch 2: Val Loss 3795947.75000
Epoch 3: Val Loss 3723761.75000
Epoch 4: Val Loss 3697087.75000
Epoch 5: Val Loss 3681279.25000
Epoch 6: Val Loss 3645181.00000
Epoch 7: Val Loss 3619368.25000
Epoch 8: Val Loss 3588286.25000
Epoch 9: Val Loss 3599811.00000
Epoch 10: Val Loss 3564056.75000
Epoch 11: Val Loss 3549627.75000
Epoch 12: Val Loss 3537111.75000
Epoch 13: Val Loss 3537339.75000
Epoch 14: Val Loss 3527891.25000
Epoch 15: Val Loss 3506606.25000
Epoch 16: Val Loss 3505084.75000
Epoch 17: Val Loss 3510463.50000
Epoch 18: Val Loss 3493251.00000
Epoch 19: Val Loss 3475422.50000
Epoch 20: Val Loss 3470985.50000
Epoch 21: Val Loss 3500742.25000
Epoch 22: Val Loss 3481354.25000
Epoch 23: Val Loss 3483970.50000
Epoch 24: Val Loss 3439795.00000
Epoch 25: Val Loss 3440439.50000
Epoch 26: Val Loss 3442317.50000
Epoch 27: Val Loss 3434448.00000
Epoch 28: Val Loss 3455244.75000
Epoch 29: Val Loss 3453582.25000
Epoch 30: Val Loss 3440494.75000
Epoch 31: Val Loss 3425828.00000
Epoch 32: Val Loss 3465961.75000
Epoch 33: Val Loss 3421861.25000
Epoch 34: Val Loss 3435372.75000
Epoch 35: Val Loss 3435912.00000
Epoch 36: Val Loss 3394652.50000
Epoch 37: Val Loss 3411350.25000
Epoch 38: Val Loss 3404830.00000
Epoch 39: Val Loss 3433364.25000
Epoch 40: Val Loss 3415236.00000
Epoch 41: Val Loss 3499811.00000
Epoch 42: Val Loss 3398208.00000
Epoch 43: Val Loss 3448771.00000
Epoch 44: Val Loss 3409578.25000
Epoch 45: Val Loss 3527595.75000
Epoch 46: Val Loss 3541486.50000
Epoch 47: Val Loss 3414452.25000
Epoch 48: Val Loss 3405619.00000
Epoch 49: Val Loss 3438721.25000
Epoch 50: Val Loss 3397012.00000
Epoch 51: Val Loss 3410251.25000
Epoch 52: Val Loss 3433780.00000
Epoch 53: Val Loss 3397838.50000
Epoch 54: Val Loss 3482792.25000
Epoch 55: Val Loss 3419397.75000
Epoch 56: Val Loss 3393809.50000
Epoch 57: Val Loss 3388595.50000
Epoch 58: Val Loss 3440897.50000
Epoch 59: Val Loss 3399313.50000
Epoch 60: Val Loss 3393569.00000
Epoch 61: Val Loss 3402109.00000
Epoch 62: Val Loss 3399764.75000
Epoch 63: Val Loss 3413401.50000
Epoch 64: Val Loss 3416100.50000
Epoch 65: Val Loss 3403425.25000
Epoch 66: Val Loss 3408456.50000
Epoch 67: Val Loss 3459184.25000
Epoch 68: Val Loss 3388781.50000
Epoch 69: Val Loss 3397553.75000
Epoch 70: Val Loss 3417003.50000
Epoch 71: Val Loss 3431481.00000
Epoch 72: Val Loss 3457623.25000
Epoch 73: Val Loss 3432374.25000
Epoch 74: Val Loss 3485670.00000
Epoch 75: Val Loss 3461505.50000
Epoch 76: Val Loss 3423057.50000
Epoch 77: Val Loss 3438850.50000
Epoch 78: Val Loss 3489227.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3408783.0065986332, 'MSE - std': 13467.43932681065, 'R2 - mean': 0.5875172675152219, 'R2 - std': 0.011512719101083202} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4997563.50000
Epoch 1: Val Loss 4536130.50000
Epoch 2: Val Loss 4433026.50000
Epoch 3: Val Loss 4384180.50000
Epoch 4: Val Loss 4310095.00000
Epoch 5: Val Loss 4283554.50000
Epoch 6: Val Loss 4256179.50000
Epoch 7: Val Loss 4207472.50000
Epoch 8: Val Loss 4206620.00000
Epoch 9: Val Loss 4171782.50000
Epoch 10: Val Loss 4172725.25000
Epoch 11: Val Loss 4135796.00000
Epoch 12: Val Loss 4129373.50000
Epoch 13: Val Loss 4113640.75000
Epoch 14: Val Loss 4077695.25000
Epoch 15: Val Loss 4166318.75000
Epoch 16: Val Loss 4058906.00000
Epoch 17: Val Loss 4040010.00000
Epoch 18: Val Loss 4042478.25000
Epoch 19: Val Loss 4037641.50000
Epoch 20: Val Loss 4032264.00000
Epoch 21: Val Loss 4024811.75000
Epoch 22: Val Loss 3992436.75000
Epoch 23: Val Loss 4006222.25000
Epoch 24: Val Loss 3991754.00000
Epoch 25: Val Loss 3987217.75000
Epoch 26: Val Loss 3961308.25000
Epoch 27: Val Loss 3971683.00000
Epoch 28: Val Loss 3957649.00000
Epoch 29: Val Loss 3955546.50000
Epoch 30: Val Loss 3965482.00000
Epoch 31: Val Loss 3944761.25000
Epoch 32: Val Loss 3934101.25000
Epoch 33: Val Loss 3941371.00000
Epoch 34: Val Loss 3915003.75000
Epoch 35: Val Loss 3922331.00000
Epoch 36: Val Loss 4131130.00000
Epoch 37: Val Loss 3929936.50000
Epoch 38: Val Loss 3904403.00000
Epoch 39: Val Loss 3907570.25000
Epoch 40: Val Loss 3929246.00000
Epoch 41: Val Loss 3902964.00000
Epoch 42: Val Loss 3887877.25000
Epoch 43: Val Loss 3924367.25000
Epoch 44: Val Loss 3889349.25000
Epoch 45: Val Loss 3874240.50000
Epoch 46: Val Loss 3916957.50000
Epoch 47: Val Loss 3887129.25000
Epoch 48: Val Loss 3891517.00000
Epoch 49: Val Loss 3867199.25000
Epoch 50: Val Loss 3875671.50000
Epoch 51: Val Loss 3863701.25000
Epoch 52: Val Loss 3862743.00000
Epoch 53: Val Loss 3886922.50000
Epoch 54: Val Loss 3860492.75000
Epoch 55: Val Loss 3875754.00000
Epoch 56: Val Loss 3862415.75000
Epoch 57: Val Loss 3870016.00000
Epoch 58: Val Loss 3857165.50000
Epoch 59: Val Loss 3841899.00000
Epoch 60: Val Loss 3860321.50000
Epoch 61: Val Loss 3843259.75000
Epoch 62: Val Loss 3841481.25000
Epoch 63: Val Loss 3861946.50000
Epoch 64: Val Loss 3905455.75000
Epoch 65: Val Loss 3862234.00000
Epoch 66: Val Loss 3842288.50000
Epoch 67: Val Loss 3847742.00000
Epoch 68: Val Loss 3851315.50000
Epoch 69: Val Loss 3866914.25000
Epoch 70: Val Loss 3864111.25000
Epoch 71: Val Loss 3872608.00000
Epoch 72: Val Loss 3872724.75000
Epoch 73: Val Loss 3864437.25000
Epoch 74: Val Loss 3870955.00000
Epoch 75: Val Loss 3901787.00000
Epoch 76: Val Loss 3891409.50000
Epoch 77: Val Loss 3879299.00000
Epoch 78: Val Loss 3866118.25000
Epoch 79: Val Loss 3879095.00000
Epoch 80: Val Loss 3869058.25000
Epoch 81: Val Loss 3911259.25000
Epoch 82: Val Loss 3884103.50000
Epoch 83: Val Loss 3910052.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3556098.8879887164, 'MSE - std': 208626.10678952682, 'R2 - mean': 0.5814203594230264, 'R2 - std': 0.012755640999298688} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4597480.00000
Epoch 1: Val Loss 4208283.50000
Epoch 2: Val Loss 4127195.25000
Epoch 3: Val Loss 4073396.00000
Epoch 4: Val Loss 4021163.25000
Epoch 5: Val Loss 4015895.00000
Epoch 6: Val Loss 3987356.25000
Epoch 7: Val Loss 3971330.25000
Epoch 8: Val Loss 3924273.00000
Epoch 9: Val Loss 3915820.75000
Epoch 10: Val Loss 3912182.25000
Epoch 11: Val Loss 3869047.00000
Epoch 12: Val Loss 3846718.25000
Epoch 13: Val Loss 3842143.25000
Epoch 14: Val Loss 3837851.75000
Epoch 15: Val Loss 3844548.75000
Epoch 16: Val Loss 3812009.50000
Epoch 17: Val Loss 3810083.50000
Epoch 18: Val Loss 3795211.25000
Epoch 19: Val Loss 3803128.00000
Epoch 20: Val Loss 3834158.00000
Epoch 21: Val Loss 3783611.75000
Epoch 22: Val Loss 3760042.00000
Epoch 23: Val Loss 3751817.25000
Epoch 24: Val Loss 3779457.50000
Epoch 25: Val Loss 3780342.50000
Epoch 26: Val Loss 3744324.75000
Epoch 27: Val Loss 3755705.25000
Epoch 28: Val Loss 3763034.50000
Epoch 29: Val Loss 3771688.25000
Epoch 30: Val Loss 3733122.25000
Epoch 31: Val Loss 3723993.25000
Epoch 32: Val Loss 3722062.00000
Epoch 33: Val Loss 3723251.00000
Epoch 34: Val Loss 3716576.50000
Epoch 35: Val Loss 3771333.25000
Epoch 36: Val Loss 3712766.00000
Epoch 37: Val Loss 3714250.50000
Epoch 38: Val Loss 3714216.75000
Epoch 39: Val Loss 3716753.75000
Epoch 40: Val Loss 3753018.50000
Epoch 41: Val Loss 3700794.50000
Epoch 42: Val Loss 3726981.75000
Epoch 43: Val Loss 3729011.50000
Epoch 44: Val Loss 3714345.25000
Epoch 45: Val Loss 3702341.75000
Epoch 46: Val Loss 3713741.50000
Epoch 47: Val Loss 3721388.75000
Epoch 48: Val Loss 3736307.50000
Epoch 49: Val Loss 3740091.00000
Epoch 50: Val Loss 3719022.75000
Epoch 51: Val Loss 3876987.00000
Epoch 52: Val Loss 3728399.25000
Epoch 53: Val Loss 3706210.75000
Epoch 54: Val Loss 3752967.75000
Epoch 55: Val Loss 3728493.00000
Epoch 56: Val Loss 3742255.25000
Epoch 57: Val Loss 3734649.50000
Epoch 58: Val Loss 3735790.25000
Epoch 59: Val Loss 3721617.50000
Epoch 60: Val Loss 3819368.00000
Epoch 61: Val Loss 3736720.50000
Epoch 62: Val Loss 3740597.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3593401.1990185366, 'MSE - std': 191880.24012417908, 'R2 - mean': 0.5781830302342421, 'R2 - std': 0.012388328531602016} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4157360.50000
Epoch 1: Val Loss 3732046.00000
Epoch 2: Val Loss 3616429.25000
Epoch 3: Val Loss 3576644.25000
Epoch 4: Val Loss 3547535.75000
Epoch 5: Val Loss 3518997.25000
Epoch 6: Val Loss 3495983.50000
Epoch 7: Val Loss 3469059.75000
Epoch 8: Val Loss 3469711.50000
Epoch 9: Val Loss 3441481.00000
Epoch 10: Val Loss 3466542.00000
Epoch 11: Val Loss 3456567.25000
Epoch 12: Val Loss 3443023.75000
Epoch 13: Val Loss 3430635.25000
Epoch 14: Val Loss 3423680.00000
Epoch 15: Val Loss 3422238.75000
Epoch 16: Val Loss 3408394.25000
Epoch 17: Val Loss 3433360.25000
Epoch 18: Val Loss 3396990.25000
Epoch 19: Val Loss 3397889.75000
Epoch 20: Val Loss 3417461.50000
Epoch 21: Val Loss 3427389.25000
Epoch 22: Val Loss 3395952.50000
Epoch 23: Val Loss 3392207.25000
Epoch 24: Val Loss 3431827.25000
Epoch 25: Val Loss 3441871.25000
Epoch 26: Val Loss 3389744.75000
Epoch 27: Val Loss 3381990.50000
Epoch 28: Val Loss 3391010.50000
Epoch 29: Val Loss 3444404.50000
Epoch 30: Val Loss 3393071.75000
Epoch 31: Val Loss 3428315.25000
Epoch 32: Val Loss 3406126.75000
Epoch 33: Val Loss 3406553.50000
Epoch 34: Val Loss 3393803.75000
Epoch 35: Val Loss 3386779.00000
Epoch 36: Val Loss 3398760.00000
Epoch 37: Val Loss 3427686.75000
Epoch 38: Val Loss 3394946.00000
Epoch 39: Val Loss 3463273.00000
Epoch 40: Val Loss 3458135.75000
Epoch 41: Val Loss 3411101.75000
Epoch 42: Val Loss 3465403.00000
Epoch 43: Val Loss 3402041.50000
Epoch 44: Val Loss 3402421.50000
Epoch 45: Val Loss 3424822.25000
Epoch 46: Val Loss 3398884.00000
Epoch 47: Val Loss 3424811.25000
Epoch 48: Val Loss 3430379.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554025.979076552, 'MSE - std': 188828.1044283628, 'R2 - mean': 0.5786669200808592, 'R2 - std': 0.011122641079355207} 
 

Saving model.....
Results After CV: {'MSE - mean': 3554025.979076552, 'MSE - std': 188828.1044283628, 'R2 - mean': 0.5786669200808592, 'R2 - std': 0.011122641079355207}
Train time: 5374.191418920585
Inference time: 6.659023211011663
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 26 finished with value: 3554025.979076552 and parameters: {'dim': 256, 'depth': 12, 'heads': 8, 'weight_decay': -4, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3944471.00000
Epoch 1: Val Loss 3805035.00000
Epoch 2: Val Loss 3710612.50000
Epoch 3: Val Loss 3662096.00000
Epoch 4: Val Loss 3612891.25000
Epoch 5: Val Loss 3596564.00000
Epoch 6: Val Loss 3482176.00000
Epoch 7: Val Loss 3646327.50000
Epoch 8: Val Loss 3500323.50000
Epoch 9: Val Loss 3460052.00000
Epoch 10: Val Loss 3516396.00000
Epoch 11: Val Loss 3497354.00000
Epoch 12: Val Loss 3499226.00000
Epoch 13: Val Loss 3551664.25000
Epoch 14: Val Loss 3604437.75000
Epoch 15: Val Loss 3675998.25000
Epoch 16: Val Loss 3729767.75000
Epoch 17: Val Loss 3629474.25000
Epoch 18: Val Loss 3706718.00000
Epoch 19: Val Loss 3857316.00000
Epoch 20: Val Loss 3940766.25000
Epoch 21: Val Loss 3889193.50000
Epoch 22: Val Loss 3888749.00000
Epoch 23: Val Loss 3988794.50000
Epoch 24: Val Loss 4051922.25000
Epoch 25: Val Loss 4207389.00000
Epoch 26: Val Loss 4220224.00000
Epoch 27: Val Loss 4167489.50000
Epoch 28: Val Loss 4159570.75000
Epoch 29: Val Loss 4196802.50000
Epoch 30: Val Loss 4221006.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3457798.2265763367, 'MSE - std': 0.0, 'R2 - mean': 0.5948650097075228, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3724769.50000
Epoch 1: Val Loss 3741003.00000
Epoch 2: Val Loss 3607717.00000
Epoch 3: Val Loss 3568573.00000
Epoch 4: Val Loss 3695276.75000
Epoch 5: Val Loss 3525749.50000
Epoch 6: Val Loss 3442881.25000
Epoch 7: Val Loss 3441676.25000
Epoch 8: Val Loss 3572039.75000
Epoch 9: Val Loss 3578275.00000
Epoch 10: Val Loss 3470981.25000
Epoch 11: Val Loss 3412584.50000
Epoch 12: Val Loss 3471565.75000
Epoch 13: Val Loss 3448916.00000
Epoch 14: Val Loss 3626004.75000
Epoch 15: Val Loss 3561256.25000
Epoch 16: Val Loss 3596051.25000
Epoch 17: Val Loss 3671719.00000
Epoch 18: Val Loss 3700173.00000
Epoch 19: Val Loss 3728044.75000
Epoch 20: Val Loss 3743780.75000
Epoch 21: Val Loss 3747890.25000
Epoch 22: Val Loss 3878203.75000
Epoch 23: Val Loss 3810899.00000
Epoch 24: Val Loss 3946286.00000
Epoch 25: Val Loss 4041243.00000
Epoch 26: Val Loss 4050435.50000
Epoch 27: Val Loss 4101972.75000
Epoch 28: Val Loss 4111163.75000
Epoch 29: Val Loss 4385161.50000
Epoch 30: Val Loss 4156205.00000
Epoch 31: Val Loss 4166060.75000
Epoch 32: Val Loss 4237628.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3436873.8337569134, 'MSE - std': 20924.392819422996, 'R2 - mean': 0.5841464351043557, 'R2 - std': 0.010718574603167053} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4303865.00000
Epoch 1: Val Loss 4223957.00000
Epoch 2: Val Loss 4123941.25000
Epoch 3: Val Loss 4072102.25000
Epoch 4: Val Loss 4158077.50000
Epoch 5: Val Loss 4008378.50000
Epoch 6: Val Loss 4284021.50000
Epoch 7: Val Loss 3931943.00000
Epoch 8: Val Loss 4065624.75000
Epoch 9: Val Loss 3965988.50000
Epoch 10: Val Loss 4028004.00000
Epoch 11: Val Loss 3917879.50000
Epoch 12: Val Loss 3906488.75000
Epoch 13: Val Loss 3921685.75000
Epoch 14: Val Loss 3926484.00000
Epoch 15: Val Loss 3914542.00000
Epoch 16: Val Loss 3978225.50000
Epoch 17: Val Loss 4047300.00000
Epoch 18: Val Loss 4088060.75000
Epoch 19: Val Loss 4214389.50000
Epoch 20: Val Loss 4268627.50000
Epoch 21: Val Loss 4202480.50000
Epoch 22: Val Loss 4325334.50000
Epoch 23: Val Loss 4351772.50000
Epoch 24: Val Loss 4415396.50000
Epoch 25: Val Loss 4481468.50000
Epoch 26: Val Loss 4529719.00000
Epoch 27: Val Loss 4664857.00000
Epoch 28: Val Loss 4771423.50000
Epoch 29: Val Loss 4688104.00000
Epoch 30: Val Loss 4657296.50000
Epoch 31: Val Loss 4783544.50000
Epoch 32: Val Loss 4753715.50000
Epoch 33: Val Loss 4892346.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595357.6711360365, 'MSE - std': 224780.20426792992, 'R2 - mean': 0.5768763131225229, 'R2 - std': 0.013501897704047562} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4044157.00000
Epoch 1: Val Loss 3944373.75000
Epoch 2: Val Loss 3910574.00000
Epoch 3: Val Loss 3972522.50000
Epoch 4: Val Loss 3861296.00000
Epoch 5: Val Loss 3816679.50000
Epoch 6: Val Loss 3769961.50000
Epoch 7: Val Loss 3797121.00000
Epoch 8: Val Loss 3826592.00000
Epoch 9: Val Loss 3799640.25000
Epoch 10: Val Loss 3768920.25000
Epoch 11: Val Loss 3833270.25000
Epoch 12: Val Loss 3814694.25000
Epoch 13: Val Loss 3887043.50000
Epoch 14: Val Loss 4038690.75000
Epoch 15: Val Loss 4016198.50000
Epoch 16: Val Loss 4090347.25000
Epoch 17: Val Loss 4077920.50000
Epoch 18: Val Loss 4230295.00000
Epoch 19: Val Loss 4150053.75000
Epoch 20: Val Loss 4127567.75000
Epoch 21: Val Loss 4388696.00000
Epoch 22: Val Loss 4494274.00000
Epoch 23: Val Loss 4525191.00000
Epoch 24: Val Loss 4430155.00000
Epoch 25: Val Loss 4520920.50000
Epoch 26: Val Loss 4509209.00000
Epoch 27: Val Loss 4523827.50000
Epoch 28: Val Loss 4594614.50000
Epoch 29: Val Loss 4591722.00000
Epoch 30: Val Loss 4633589.50000
Epoch 31: Val Loss 4664735.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3636350.353669797, 'MSE - std': 207209.56840114837, 'R2 - mean': 0.5732021633991176, 'R2 - std': 0.013312552714559308} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3560453.50000
Epoch 1: Val Loss 3566975.25000
Epoch 2: Val Loss 3554877.25000
Epoch 3: Val Loss 3541496.25000
Epoch 4: Val Loss 3493884.75000
Epoch 5: Val Loss 3456461.25000
Epoch 6: Val Loss 3509806.00000
Epoch 7: Val Loss 3483030.25000
Epoch 8: Val Loss 3473524.00000
Epoch 9: Val Loss 3619627.75000
Epoch 10: Val Loss 3401170.75000
Epoch 11: Val Loss 3515201.25000
Epoch 12: Val Loss 3397286.25000
Epoch 13: Val Loss 3691550.75000
Epoch 14: Val Loss 3474764.75000
Epoch 15: Val Loss 3530237.25000
Epoch 16: Val Loss 3480432.50000
Epoch 17: Val Loss 3591852.50000
Epoch 18: Val Loss 3641192.75000
Epoch 19: Val Loss 3816035.00000
Epoch 20: Val Loss 3694756.50000
Epoch 21: Val Loss 3828887.00000
Epoch 22: Val Loss 3810963.50000
Epoch 23: Val Loss 3895523.00000
Epoch 24: Val Loss 3985873.75000
Epoch 25: Val Loss 3858981.75000
Epoch 26: Val Loss 4022838.50000
Epoch 27: Val Loss 4087871.75000
Epoch 28: Val Loss 4117212.75000
Epoch 29: Val Loss 4130448.00000
Epoch 30: Val Loss 4181737.50000
Epoch 31: Val Loss 4167427.25000
Epoch 32: Val Loss 4242918.50000
Epoch 33: Val Loss 4236178.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3590202.8327255123, 'MSE - std': 207043.5194513582, 'R2 - mean': 0.5744578009061949, 'R2 - std': 0.012169048854329335} 
 

Saving model.....
Results After CV: {'MSE - mean': 3590202.8327255123, 'MSE - std': 207043.5194513582, 'R2 - mean': 0.5744578009061949, 'R2 - std': 0.012169048854329335}
Train time: 2459.1231665142113
Inference time: 6.675656137394253
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 27 finished with value: 3590202.8327255123 and parameters: {'dim': 256, 'depth': 1, 'heads': 4, 'weight_decay': -2, 'learning_rate': -3, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4508484.00000
Epoch 1: Val Loss 4108083.50000
Epoch 2: Val Loss 3975185.00000
Epoch 3: Val Loss 3928463.75000
Epoch 4: Val Loss 3862033.00000
Epoch 5: Val Loss 3813376.00000
Epoch 6: Val Loss 3801524.00000
Epoch 7: Val Loss 3803195.25000
Epoch 8: Val Loss 3751332.50000
Epoch 9: Val Loss 3709808.50000
Epoch 10: Val Loss 3692528.50000
Epoch 11: Val Loss 3713829.75000
Epoch 12: Val Loss 3665640.25000
Epoch 13: Val Loss 3709100.25000
Epoch 14: Val Loss 3661755.00000
Epoch 15: Val Loss 3638098.75000
Epoch 16: Val Loss 3617551.75000
Epoch 17: Val Loss 3608497.50000
Epoch 18: Val Loss 3615873.75000
Epoch 19: Val Loss 3588193.00000
Epoch 20: Val Loss 3573625.25000
Epoch 21: Val Loss 3558419.75000
Epoch 22: Val Loss 3572077.50000
Epoch 23: Val Loss 3562937.50000
Epoch 24: Val Loss 3549975.25000
Epoch 25: Val Loss 3574623.50000
Epoch 26: Val Loss 3517137.75000
Epoch 27: Val Loss 3513557.75000
Epoch 28: Val Loss 3513952.75000
Epoch 29: Val Loss 3514765.50000
Epoch 30: Val Loss 3516721.50000
Epoch 31: Val Loss 3513059.00000
Epoch 32: Val Loss 3482328.00000
Epoch 33: Val Loss 3576542.25000
Epoch 34: Val Loss 3496579.00000
Epoch 35: Val Loss 3493073.00000
Epoch 36: Val Loss 3476542.00000
Epoch 37: Val Loss 3482415.75000
Epoch 38: Val Loss 3464477.50000
Epoch 39: Val Loss 3466834.50000
Epoch 40: Val Loss 3484828.50000
Epoch 41: Val Loss 3473146.50000
Epoch 42: Val Loss 3438438.25000
Epoch 43: Val Loss 3484364.50000
Epoch 44: Val Loss 3448301.00000
Epoch 45: Val Loss 3441819.75000
Epoch 46: Val Loss 3430540.75000
Epoch 47: Val Loss 3456955.00000
Epoch 48: Val Loss 3438912.25000
Epoch 49: Val Loss 3427930.75000
Epoch 50: Val Loss 3491395.50000
Epoch 51: Val Loss 3419052.00000
Epoch 52: Val Loss 3437523.00000
Epoch 53: Val Loss 3422175.75000
Epoch 54: Val Loss 3456945.50000
Epoch 55: Val Loss 3439316.00000
Epoch 56: Val Loss 3429465.75000
Epoch 57: Val Loss 3423400.25000
Epoch 58: Val Loss 3422849.00000
Epoch 59: Val Loss 3442259.00000
Epoch 60: Val Loss 3459336.50000
Epoch 61: Val Loss 3479381.50000
Epoch 62: Val Loss 3427255.75000
Epoch 63: Val Loss 3460522.50000
Epoch 64: Val Loss 3442758.25000
Epoch 65: Val Loss 3472455.50000
Epoch 66: Val Loss 3418855.75000
Epoch 67: Val Loss 3438454.25000
Epoch 68: Val Loss 3470971.75000
Epoch 69: Val Loss 3481316.00000
Epoch 70: Val Loss 3427865.75000
Epoch 71: Val Loss 3554391.00000
Epoch 72: Val Loss 3448828.25000
Epoch 73: Val Loss 3459698.25000
Epoch 74: Val Loss 3434858.25000
Epoch 75: Val Loss 3461427.25000
Epoch 76: Val Loss 3484529.75000
Epoch 77: Val Loss 3460281.75000
Epoch 78: Val Loss 3456905.00000
Epoch 79: Val Loss 3456276.50000
Epoch 80: Val Loss 3458929.25000
Epoch 81: Val Loss 3473895.25000
Epoch 82: Val Loss 3446260.75000
Epoch 83: Val Loss 3480822.25000
Epoch 84: Val Loss 3521418.00000
Epoch 85: Val Loss 3490351.75000
Epoch 86: Val Loss 3499823.75000
Epoch 87: Val Loss 3512553.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3429464.3256880734, 'MSE - std': 0.0, 'R2 - mean': 0.5981847680939687, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4274954.00000
Epoch 1: Val Loss 3895069.50000
Epoch 2: Val Loss 3845743.25000
Epoch 3: Val Loss 3738144.00000
Epoch 4: Val Loss 3698746.50000
Epoch 5: Val Loss 3700993.75000
Epoch 6: Val Loss 3654880.00000
Epoch 7: Val Loss 3671019.00000
Epoch 8: Val Loss 3627395.00000
Epoch 9: Val Loss 3613992.25000
Epoch 10: Val Loss 3591277.50000
Epoch 11: Val Loss 3574863.75000
Epoch 12: Val Loss 3590994.00000
Epoch 13: Val Loss 3558074.75000
Epoch 14: Val Loss 3558776.75000
Epoch 15: Val Loss 3573881.50000
Epoch 16: Val Loss 3560459.00000
Epoch 17: Val Loss 3516884.75000
Epoch 18: Val Loss 3534062.00000
Epoch 19: Val Loss 3505413.00000
Epoch 20: Val Loss 3517379.25000
Epoch 21: Val Loss 3489986.75000
Epoch 22: Val Loss 3484685.25000
Epoch 23: Val Loss 3488948.50000
Epoch 24: Val Loss 3468393.75000
Epoch 25: Val Loss 3449965.50000
Epoch 26: Val Loss 3459004.50000
Epoch 27: Val Loss 3476075.75000
Epoch 28: Val Loss 3448851.00000
Epoch 29: Val Loss 3462035.25000
Epoch 30: Val Loss 3470798.00000
Epoch 31: Val Loss 3435653.25000
Epoch 32: Val Loss 3451488.75000
Epoch 33: Val Loss 3427304.00000
Epoch 34: Val Loss 3451603.25000
Epoch 35: Val Loss 3432585.00000
Epoch 36: Val Loss 3420441.50000
Epoch 37: Val Loss 3425377.75000
Epoch 38: Val Loss 3404694.50000
Epoch 39: Val Loss 3417731.50000
Epoch 40: Val Loss 3467730.75000
Epoch 41: Val Loss 3399110.00000
Epoch 42: Val Loss 3398342.50000
Epoch 43: Val Loss 3430647.00000
Epoch 44: Val Loss 3400792.00000
Epoch 45: Val Loss 3410205.00000
Epoch 46: Val Loss 3414725.75000
Epoch 47: Val Loss 3498016.25000
Epoch 48: Val Loss 3408000.75000
Epoch 49: Val Loss 3425159.75000
Epoch 50: Val Loss 3430881.50000
Epoch 51: Val Loss 3397529.25000
Epoch 52: Val Loss 3415318.75000
Epoch 53: Val Loss 3387448.75000
Epoch 54: Val Loss 3453151.75000
Epoch 55: Val Loss 3410789.00000
Epoch 56: Val Loss 3422412.50000
Epoch 57: Val Loss 3399231.75000
Epoch 58: Val Loss 3430873.00000
Epoch 59: Val Loss 3414513.75000
Epoch 60: Val Loss 3407614.25000
Epoch 61: Val Loss 3411162.50000
Epoch 62: Val Loss 3416991.75000
Epoch 63: Val Loss 3405290.75000
Epoch 64: Val Loss 3388796.75000
Epoch 65: Val Loss 3410927.75000
Epoch 66: Val Loss 3405168.25000
Epoch 67: Val Loss 3456945.25000
Epoch 68: Val Loss 3405274.50000
Epoch 69: Val Loss 3451815.25000
Epoch 70: Val Loss 3431105.75000
Epoch 71: Val Loss 3405317.25000
Epoch 72: Val Loss 3444480.50000
Epoch 73: Val Loss 3451830.25000
Epoch 74: Val Loss 3427161.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3413274.669359279, 'MSE - std': 16189.656328794314, 'R2 - mean': 0.5869841770721671, 'R2 - std': 0.011200591021801654} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4971546.50000
Epoch 1: Val Loss 4551070.50000
Epoch 2: Val Loss 4435393.00000
Epoch 3: Val Loss 4390625.50000
Epoch 4: Val Loss 4375570.50000
Epoch 5: Val Loss 4290728.00000
Epoch 6: Val Loss 4286201.50000
Epoch 7: Val Loss 4234263.00000
Epoch 8: Val Loss 4221033.50000
Epoch 9: Val Loss 4211745.00000
Epoch 10: Val Loss 4172469.75000
Epoch 11: Val Loss 4183679.75000
Epoch 12: Val Loss 4137502.75000
Epoch 13: Val Loss 4123985.75000
Epoch 14: Val Loss 4107966.75000
Epoch 15: Val Loss 4109262.75000
Epoch 16: Val Loss 4113872.50000
Epoch 17: Val Loss 4085188.50000
Epoch 18: Val Loss 4062688.00000
Epoch 19: Val Loss 4049323.25000
Epoch 20: Val Loss 4036406.50000
Epoch 21: Val Loss 4035373.00000
Epoch 22: Val Loss 4022609.00000
Epoch 23: Val Loss 4020934.50000
Epoch 24: Val Loss 4020342.50000
Epoch 25: Val Loss 4003061.25000
Epoch 26: Val Loss 4038095.75000
Epoch 27: Val Loss 3993899.25000
Epoch 28: Val Loss 3978516.75000
Epoch 29: Val Loss 3988481.00000
Epoch 30: Val Loss 3975515.75000
Epoch 31: Val Loss 3946703.75000
Epoch 32: Val Loss 3950343.50000
Epoch 33: Val Loss 3940444.25000
Epoch 34: Val Loss 3933403.25000
Epoch 35: Val Loss 3939115.00000
Epoch 36: Val Loss 3933787.25000
Epoch 37: Val Loss 3926014.25000
Epoch 38: Val Loss 3921364.50000
Epoch 39: Val Loss 3937915.25000
Epoch 40: Val Loss 3909481.25000
Epoch 41: Val Loss 3954296.00000
Epoch 42: Val Loss 3894426.00000
Epoch 43: Val Loss 3889450.50000
Epoch 44: Val Loss 3928013.00000
Epoch 45: Val Loss 3916337.00000
Epoch 46: Val Loss 3881249.50000
Epoch 47: Val Loss 3905658.00000
Epoch 48: Val Loss 3895944.75000
Epoch 49: Val Loss 3876931.50000
Epoch 50: Val Loss 3885658.00000
Epoch 51: Val Loss 3851264.00000
Epoch 52: Val Loss 3867700.00000
Epoch 53: Val Loss 3853748.50000
Epoch 54: Val Loss 3856468.50000
Epoch 55: Val Loss 3872705.50000
Epoch 56: Val Loss 3871476.50000
Epoch 57: Val Loss 3848871.00000
Epoch 58: Val Loss 3853573.25000
Epoch 59: Val Loss 3883939.50000
Epoch 60: Val Loss 3837570.75000
Epoch 61: Val Loss 3847378.75000
Epoch 62: Val Loss 3842521.50000
Epoch 63: Val Loss 3842976.50000
Epoch 64: Val Loss 3838937.25000
Epoch 65: Val Loss 3842668.25000
Epoch 66: Val Loss 3853409.00000
Epoch 67: Val Loss 3854014.75000
Epoch 68: Val Loss 3992118.50000
Epoch 69: Val Loss 3845551.25000
Epoch 70: Val Loss 3865516.75000
Epoch 71: Val Loss 3869956.50000
Epoch 72: Val Loss 3851308.25000
Epoch 73: Val Loss 3847102.25000
Epoch 74: Val Loss 3903944.25000
Epoch 75: Val Loss 3881107.00000
Epoch 76: Val Loss 3864030.25000
Epoch 77: Val Loss 3886008.75000
Epoch 78: Val Loss 3867279.75000
Epoch 79: Val Loss 3863367.50000
Epoch 80: Val Loss 3881544.75000
Epoch 81: Val Loss 3869264.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3560199.406310352, 'MSE - std': 208203.0098349058, 'R2 - mean': 0.5809412312534105, 'R2 - std': 0.012516783978401344} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4572942.00000
Epoch 1: Val Loss 4230942.50000
Epoch 2: Val Loss 4120850.75000
Epoch 3: Val Loss 4065316.00000
Epoch 4: Val Loss 4035196.75000
Epoch 5: Val Loss 4022816.00000
Epoch 6: Val Loss 3960051.00000
Epoch 7: Val Loss 3923374.25000
Epoch 8: Val Loss 3900434.75000
Epoch 9: Val Loss 3918382.75000
Epoch 10: Val Loss 3903073.75000
Epoch 11: Val Loss 3844747.00000
Epoch 12: Val Loss 3833268.75000
Epoch 13: Val Loss 3828494.00000
Epoch 14: Val Loss 3845119.25000
Epoch 15: Val Loss 3811839.25000
Epoch 16: Val Loss 3795032.25000
Epoch 17: Val Loss 3781356.25000
Epoch 18: Val Loss 3788978.75000
Epoch 19: Val Loss 3782911.25000
Epoch 20: Val Loss 3780180.50000
Epoch 21: Val Loss 3763423.25000
Epoch 22: Val Loss 3750257.75000
Epoch 23: Val Loss 3773816.00000
Epoch 24: Val Loss 3802819.00000
Epoch 25: Val Loss 3741899.25000
Epoch 26: Val Loss 3749212.25000
Epoch 27: Val Loss 3784648.25000
Epoch 28: Val Loss 3742756.50000
Epoch 29: Val Loss 3741491.50000
Epoch 30: Val Loss 3722643.00000
Epoch 31: Val Loss 3721317.75000
Epoch 32: Val Loss 3715230.75000
Epoch 33: Val Loss 3705968.00000
Epoch 34: Val Loss 3715495.75000
Epoch 35: Val Loss 3724665.25000
Epoch 36: Val Loss 3690247.75000
Epoch 37: Val Loss 3724033.50000
Epoch 38: Val Loss 3698676.00000
Epoch 39: Val Loss 3739714.75000
Epoch 40: Val Loss 3734107.00000
Epoch 41: Val Loss 3736474.00000
Epoch 42: Val Loss 3703826.75000
Epoch 43: Val Loss 3696017.75000
Epoch 44: Val Loss 3717456.50000
Epoch 45: Val Loss 3698029.50000
Epoch 46: Val Loss 3766092.25000
Epoch 47: Val Loss 3749903.75000
Epoch 48: Val Loss 3751001.50000
Epoch 49: Val Loss 3729389.00000
Epoch 50: Val Loss 3718103.00000
Epoch 51: Val Loss 3718707.00000
Epoch 52: Val Loss 3734671.25000
Epoch 53: Val Loss 3741177.50000
Epoch 54: Val Loss 3756495.25000
Epoch 55: Val Loss 3717674.50000
Epoch 56: Val Loss 3752108.25000
Epoch 57: Val Loss 3769009.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595992.363027753, 'MSE - std': 190669.2875896812, 'R2 - mean': 0.5778800780657157, 'R2 - std': 0.012067078660018538} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4147964.25000
Epoch 1: Val Loss 3717328.00000
Epoch 2: Val Loss 3623302.25000
Epoch 3: Val Loss 3563901.50000
Epoch 4: Val Loss 3550716.75000
Epoch 5: Val Loss 3517776.75000
Epoch 6: Val Loss 3507175.75000
Epoch 7: Val Loss 3469137.50000
Epoch 8: Val Loss 3476655.75000
Epoch 9: Val Loss 3457934.75000
Epoch 10: Val Loss 3461577.75000
Epoch 11: Val Loss 3476736.50000
Epoch 12: Val Loss 3420822.00000
Epoch 13: Val Loss 3405171.75000
Epoch 14: Val Loss 3439782.50000
Epoch 15: Val Loss 3414967.75000
Epoch 16: Val Loss 3426283.00000
Epoch 17: Val Loss 3420607.00000
Epoch 18: Val Loss 3438294.25000
Epoch 19: Val Loss 3397430.50000
Epoch 20: Val Loss 3412865.50000
Epoch 21: Val Loss 3400793.25000
Epoch 22: Val Loss 3410860.75000
Epoch 23: Val Loss 3407636.50000
Epoch 24: Val Loss 3401421.25000
Epoch 25: Val Loss 3411454.50000
Epoch 26: Val Loss 3395487.75000
Epoch 27: Val Loss 3396216.25000
Epoch 28: Val Loss 3405063.75000
Epoch 29: Val Loss 3467573.25000
Epoch 30: Val Loss 3398414.75000
Epoch 31: Val Loss 3386716.75000
Epoch 32: Val Loss 3404444.25000
Epoch 33: Val Loss 3390720.00000
Epoch 34: Val Loss 3411844.50000
Epoch 35: Val Loss 3378119.75000
Epoch 36: Val Loss 3396565.75000
Epoch 37: Val Loss 3446569.25000
Epoch 38: Val Loss 3405244.25000
Epoch 39: Val Loss 3388813.50000
Epoch 40: Val Loss 3423314.25000
Epoch 41: Val Loss 3403821.50000
Epoch 42: Val Loss 3393025.25000
Epoch 43: Val Loss 3483377.50000
Epoch 44: Val Loss 3378510.75000
Epoch 45: Val Loss 3408007.75000
Epoch 46: Val Loss 3385582.75000
Epoch 47: Val Loss 3430274.25000
Epoch 48: Val Loss 3441624.25000
Epoch 49: Val Loss 3422731.25000
Epoch 50: Val Loss 3431860.25000
Epoch 51: Val Loss 3404112.75000
Epoch 52: Val Loss 3432141.50000
Epoch 53: Val Loss 3460426.25000
Epoch 54: Val Loss 3450246.00000
Epoch 55: Val Loss 3456319.75000
Epoch 56: Val Loss 3405582.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553880.4474036843, 'MSE - std': 190203.77371145948, 'R2 - mean': 0.578698490616274, 'R2 - std': 0.010916533622048037} 
 

Saving model.....
Results After CV: {'MSE - mean': 3553880.4474036843, 'MSE - std': 190203.77371145948, 'R2 - mean': 0.578698490616274, 'R2 - std': 0.010916533622048037}
Train time: 5444.769387041405
Inference time: 6.667685997800436
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 28 finished with value: 3553880.4474036843 and parameters: {'dim': 128, 'depth': 6, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8809842.00000
Epoch 1: Val Loss 8287291.00000
Epoch 2: Val Loss 7860880.00000
Epoch 3: Val Loss 7329234.50000
Epoch 4: Val Loss 6665677.50000
Epoch 5: Val Loss 5872406.00000
Epoch 6: Val Loss 5328673.00000
Epoch 7: Val Loss 4981468.50000
Epoch 8: Val Loss 4813241.00000
Epoch 9: Val Loss 4619752.00000
Epoch 10: Val Loss 4493281.00000
Epoch 11: Val Loss 4430180.50000
Epoch 12: Val Loss 4339133.50000
Epoch 13: Val Loss 4292816.50000
Epoch 14: Val Loss 4251529.50000
Epoch 15: Val Loss 4200303.00000
Epoch 16: Val Loss 4177407.75000
Epoch 17: Val Loss 4135312.00000
Epoch 18: Val Loss 4106262.25000
Epoch 19: Val Loss 4101608.75000
Epoch 20: Val Loss 4076983.50000
Epoch 21: Val Loss 4071612.75000
Epoch 22: Val Loss 4040235.25000
Epoch 23: Val Loss 4057483.00000
Epoch 24: Val Loss 4016926.75000
Epoch 25: Val Loss 4015515.25000
Epoch 26: Val Loss 3995731.50000
Epoch 27: Val Loss 3995385.25000
Epoch 28: Val Loss 3987241.50000
Epoch 29: Val Loss 3966721.00000
Epoch 30: Val Loss 3957700.50000
Epoch 31: Val Loss 3956127.75000
Epoch 32: Val Loss 3936032.00000
Epoch 33: Val Loss 3931291.25000
Epoch 34: Val Loss 3936084.50000
Epoch 35: Val Loss 3923277.50000
Epoch 36: Val Loss 3905916.75000
Epoch 37: Val Loss 3903306.00000
Epoch 38: Val Loss 3895584.50000
Epoch 39: Val Loss 3909440.50000
Epoch 40: Val Loss 3896015.75000
Epoch 41: Val Loss 3883046.50000
Epoch 42: Val Loss 3872279.50000
Epoch 43: Val Loss 3863239.50000
Epoch 44: Val Loss 3868231.50000
Epoch 45: Val Loss 3866755.00000
Epoch 46: Val Loss 3851481.50000
Epoch 47: Val Loss 3863092.00000
Epoch 48: Val Loss 3838922.50000
Epoch 49: Val Loss 3907461.75000
Epoch 50: Val Loss 3820811.25000
Epoch 51: Val Loss 3829991.00000
Epoch 52: Val Loss 3830062.00000
Epoch 53: Val Loss 3822633.25000
Epoch 54: Val Loss 3813953.50000
Epoch 55: Val Loss 3804718.25000
Epoch 56: Val Loss 3828513.75000
Epoch 57: Val Loss 3803875.00000
Epoch 58: Val Loss 3790200.00000
Epoch 59: Val Loss 3793112.00000
Epoch 60: Val Loss 3787214.75000
Epoch 61: Val Loss 3784922.50000
Epoch 62: Val Loss 3780407.50000
Epoch 63: Val Loss 3769956.75000
Epoch 64: Val Loss 3785830.25000
Epoch 65: Val Loss 3771369.25000
Epoch 66: Val Loss 3793619.50000
Epoch 67: Val Loss 3785783.50000
Epoch 68: Val Loss 3761679.75000
Epoch 69: Val Loss 3750222.00000
Epoch 70: Val Loss 3758100.75000
Epoch 71: Val Loss 3748149.25000
Epoch 72: Val Loss 3735721.50000
Epoch 73: Val Loss 3743752.75000
Epoch 74: Val Loss 3746151.75000
Epoch 75: Val Loss 3748129.75000
Epoch 76: Val Loss 3734710.25000
Epoch 77: Val Loss 3728061.50000
Epoch 78: Val Loss 3722451.00000
Epoch 79: Val Loss 3724113.50000
Epoch 80: Val Loss 3725123.50000
Epoch 81: Val Loss 3718435.50000
Epoch 82: Val Loss 3720076.75000
Epoch 83: Val Loss 3710155.75000
Epoch 84: Val Loss 3714971.00000
Epoch 85: Val Loss 3709459.00000
Epoch 86: Val Loss 3701108.00000
Epoch 87: Val Loss 3712144.00000
Epoch 88: Val Loss 3713102.00000
Epoch 89: Val Loss 3724014.75000
Epoch 90: Val Loss 3709262.25000
Epoch 91: Val Loss 3694922.00000
Epoch 92: Val Loss 3715806.75000
Epoch 93: Val Loss 3695006.00000
Epoch 94: Val Loss 3683170.75000
Epoch 95: Val Loss 3681557.25000
Epoch 96: Val Loss 3685493.75000
Epoch 97: Val Loss 3681468.75000
Epoch 98: Val Loss 3702293.25000
Epoch 99: Val Loss 3671775.25000
Saved Losses
{'MSE - mean': 3681177.5860485947, 'MSE - std': 0.0, 'R2 - mean': 0.5686926339061337, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8352960.00000
Epoch 1: Val Loss 7738378.50000
Epoch 2: Val Loss 7369285.50000
Epoch 3: Val Loss 6871799.00000
Epoch 4: Val Loss 6265738.00000
Epoch 5: Val Loss 5569225.00000
Epoch 6: Val Loss 4994358.50000
Epoch 7: Val Loss 4665515.50000
Epoch 8: Val Loss 4507039.00000
Epoch 9: Val Loss 4337980.50000
Epoch 10: Val Loss 4330026.50000
Epoch 11: Val Loss 4162033.50000
Epoch 12: Val Loss 4088564.75000
Epoch 13: Val Loss 4049995.25000
Epoch 14: Val Loss 4010954.50000
Epoch 15: Val Loss 3975196.75000
Epoch 16: Val Loss 3979182.25000
Epoch 17: Val Loss 3933012.75000
Epoch 18: Val Loss 3915319.00000
Epoch 19: Val Loss 3880845.50000
Epoch 20: Val Loss 3868046.25000
Epoch 21: Val Loss 3861263.25000
Epoch 22: Val Loss 3835102.75000
Epoch 23: Val Loss 3838894.75000
Epoch 24: Val Loss 3830826.50000
Epoch 25: Val Loss 3804789.75000
Epoch 26: Val Loss 3800826.50000
Epoch 27: Val Loss 3798217.25000
Epoch 28: Val Loss 3780013.50000
Epoch 29: Val Loss 3768587.00000
Epoch 30: Val Loss 3815731.50000
Epoch 31: Val Loss 3757783.75000
Epoch 32: Val Loss 3756322.75000
Epoch 33: Val Loss 3750395.25000
Epoch 34: Val Loss 3758077.00000
Epoch 35: Val Loss 3739036.75000
Epoch 36: Val Loss 3752327.75000
Epoch 37: Val Loss 3745100.75000
Epoch 38: Val Loss 3729382.50000
Epoch 39: Val Loss 3737311.25000
Epoch 40: Val Loss 3708413.00000
Epoch 41: Val Loss 3705553.75000
Epoch 42: Val Loss 3702459.25000
Epoch 43: Val Loss 3700168.75000
Epoch 44: Val Loss 3722442.00000
Epoch 45: Val Loss 3701767.75000
Epoch 46: Val Loss 3698336.00000
Epoch 47: Val Loss 3691303.50000
Epoch 48: Val Loss 3685211.00000
Epoch 49: Val Loss 3668663.75000
Epoch 50: Val Loss 3670754.75000
Epoch 51: Val Loss 3673111.50000
Epoch 52: Val Loss 3667289.50000
Epoch 53: Val Loss 3751752.75000
Epoch 54: Val Loss 3667684.75000
Epoch 55: Val Loss 3656503.00000
Epoch 56: Val Loss 3688905.50000
Epoch 57: Val Loss 3651499.25000
Epoch 58: Val Loss 3646268.75000
Epoch 59: Val Loss 3675061.75000
Epoch 60: Val Loss 3647915.75000
Epoch 61: Val Loss 3637081.25000
Epoch 62: Val Loss 3637149.00000
Epoch 63: Val Loss 3642811.75000
Epoch 64: Val Loss 3633421.50000
Epoch 65: Val Loss 3620332.75000
Epoch 66: Val Loss 3615116.00000
Epoch 67: Val Loss 3612539.00000
Epoch 68: Val Loss 3614915.75000
Epoch 69: Val Loss 3615960.00000
Epoch 70: Val Loss 3640203.25000
Epoch 71: Val Loss 3617582.50000
Epoch 72: Val Loss 3609870.25000
Epoch 73: Val Loss 3605700.50000
Epoch 74: Val Loss 3631856.00000
Epoch 75: Val Loss 3597273.50000
Epoch 76: Val Loss 3600520.00000
Epoch 77: Val Loss 3623364.75000
Epoch 78: Val Loss 3604079.00000
Epoch 79: Val Loss 3615000.75000
Epoch 80: Val Loss 3598350.25000
Epoch 81: Val Loss 3589504.50000
Epoch 82: Val Loss 3584961.50000
Epoch 83: Val Loss 3594702.25000
Epoch 84: Val Loss 3579691.50000
Epoch 85: Val Loss 3582952.00000
Epoch 86: Val Loss 3578742.25000
Epoch 87: Val Loss 3580604.75000
Epoch 88: Val Loss 3590914.50000
Epoch 89: Val Loss 3585395.50000
Epoch 90: Val Loss 3597985.25000
Epoch 91: Val Loss 3573444.50000
Epoch 92: Val Loss 3566350.50000
Epoch 93: Val Loss 3562591.50000
Epoch 94: Val Loss 3565497.50000
Epoch 95: Val Loss 3571160.75000
Epoch 96: Val Loss 3604207.00000
Epoch 97: Val Loss 3554423.75000
Epoch 98: Val Loss 3588215.50000
Epoch 99: Val Loss 3551097.75000
Saved Losses
{'MSE - mean': 3622960.572244914, 'MSE - std': 58217.01380368089, 'R2 - mean': 0.5617697957280401, 'R2 - std': 0.006922838178093527} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9275019.00000
Epoch 1: Val Loss 8871467.00000
Epoch 2: Val Loss 8362828.50000
Epoch 3: Val Loss 7761176.50000
Epoch 4: Val Loss 7123868.50000
Epoch 5: Val Loss 6366962.00000
Epoch 6: Val Loss 5823256.50000
Epoch 7: Val Loss 5486885.50000
Epoch 8: Val Loss 5242193.50000
Epoch 9: Val Loss 5076413.00000
Epoch 10: Val Loss 4982967.00000
Epoch 11: Val Loss 4880775.00000
Epoch 12: Val Loss 4833727.50000
Epoch 13: Val Loss 4761999.50000
Epoch 14: Val Loss 4705744.50000
Epoch 15: Val Loss 4663693.50000
Epoch 16: Val Loss 4628314.50000
Epoch 17: Val Loss 4604323.00000
Epoch 18: Val Loss 4574973.00000
Epoch 19: Val Loss 4550959.50000
Epoch 20: Val Loss 4539685.00000
Epoch 21: Val Loss 4523760.50000
Epoch 22: Val Loss 4519026.50000
Epoch 23: Val Loss 4494613.00000
Epoch 24: Val Loss 4474313.00000
Epoch 25: Val Loss 4475375.00000
Epoch 26: Val Loss 4472198.00000
Epoch 27: Val Loss 4511298.50000
Epoch 28: Val Loss 4533148.50000
Epoch 29: Val Loss 4423761.50000
Epoch 30: Val Loss 4426604.50000
Epoch 31: Val Loss 4462870.50000
Epoch 32: Val Loss 4412610.50000
Epoch 33: Val Loss 4392695.00000
Epoch 34: Val Loss 4423315.50000
Epoch 35: Val Loss 4377078.50000
Epoch 36: Val Loss 4391739.50000
Epoch 37: Val Loss 4379435.50000
Epoch 38: Val Loss 4370736.50000
Epoch 39: Val Loss 4364476.50000
Epoch 40: Val Loss 4353341.00000
Epoch 41: Val Loss 4376541.50000
Epoch 42: Val Loss 4342020.50000
Epoch 43: Val Loss 4337586.50000
Epoch 44: Val Loss 4348687.00000
Epoch 45: Val Loss 4359346.00000
Epoch 46: Val Loss 4325045.50000
Epoch 47: Val Loss 4319962.50000
Epoch 48: Val Loss 4315233.50000
Epoch 49: Val Loss 4325017.00000
Epoch 50: Val Loss 4303894.00000
Epoch 51: Val Loss 4300934.50000
Epoch 52: Val Loss 4299929.00000
Epoch 53: Val Loss 4292503.50000
Epoch 54: Val Loss 4304286.00000
Epoch 55: Val Loss 4299421.00000
Epoch 56: Val Loss 4276556.50000
Epoch 57: Val Loss 4272318.50000
Epoch 58: Val Loss 4273935.00000
Epoch 59: Val Loss 4282269.50000
Epoch 60: Val Loss 4280682.50000
Epoch 61: Val Loss 4261716.50000
Epoch 62: Val Loss 4253702.00000
Epoch 63: Val Loss 4255570.00000
Epoch 64: Val Loss 4248907.00000
Epoch 65: Val Loss 4250134.50000
Epoch 66: Val Loss 4243634.50000
Epoch 67: Val Loss 4244972.50000
Epoch 68: Val Loss 4236462.00000
Epoch 69: Val Loss 4241598.50000
Epoch 70: Val Loss 4250973.00000
Epoch 71: Val Loss 4228124.50000
Epoch 72: Val Loss 4223072.00000
Epoch 73: Val Loss 4247856.50000
Epoch 74: Val Loss 4216931.50000
Epoch 75: Val Loss 4220244.00000
Epoch 76: Val Loss 4214843.00000
Epoch 77: Val Loss 4206598.50000
Epoch 78: Val Loss 4212834.50000
Epoch 79: Val Loss 4214088.00000
Epoch 80: Val Loss 4200291.50000
Epoch 81: Val Loss 4197354.50000
Epoch 82: Val Loss 4215008.00000
Epoch 83: Val Loss 4193418.50000
Epoch 84: Val Loss 4193423.75000
Epoch 85: Val Loss 4190366.25000
Epoch 86: Val Loss 4187387.00000
Epoch 87: Val Loss 4181153.75000
Epoch 88: Val Loss 4180101.75000
Epoch 89: Val Loss 4186428.75000
Epoch 90: Val Loss 4180573.50000
Epoch 91: Val Loss 4172631.50000
Epoch 92: Val Loss 4167953.50000
Epoch 93: Val Loss 4196718.00000
Epoch 94: Val Loss 4170518.25000
Epoch 95: Val Loss 4164662.25000
Epoch 96: Val Loss 4162183.50000
Epoch 97: Val Loss 4158856.25000
Epoch 98: Val Loss 4162143.25000
Epoch 99: Val Loss 4159830.50000
Saved Losses
{'MSE - mean': 3806507.871844943, 'MSE - std': 263891.46034889243, 'R2 - mean': 0.552215705528297, 'R2 - std': 0.014646219240804143} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8874923.00000
Epoch 1: Val Loss 8285609.50000
Epoch 2: Val Loss 7966281.50000
Epoch 3: Val Loss 7431013.50000
Epoch 4: Val Loss 6673490.50000
Epoch 5: Val Loss 5951346.50000
Epoch 6: Val Loss 5476127.50000
Epoch 7: Val Loss 5085210.00000
Epoch 8: Val Loss 4911063.00000
Epoch 9: Val Loss 4762934.00000
Epoch 10: Val Loss 4624308.50000
Epoch 11: Val Loss 4568090.00000
Epoch 12: Val Loss 4501938.00000
Epoch 13: Val Loss 4448141.00000
Epoch 14: Val Loss 4413544.50000
Epoch 15: Val Loss 4385678.50000
Epoch 16: Val Loss 4345906.50000
Epoch 17: Val Loss 4350095.50000
Epoch 18: Val Loss 4301653.00000
Epoch 19: Val Loss 4296102.00000
Epoch 20: Val Loss 4263229.50000
Epoch 21: Val Loss 4253434.50000
Epoch 22: Val Loss 4226074.50000
Epoch 23: Val Loss 4225092.50000
Epoch 24: Val Loss 4214825.00000
Epoch 25: Val Loss 4201287.00000
Epoch 26: Val Loss 4188798.75000
Epoch 27: Val Loss 4174506.50000
Epoch 28: Val Loss 4160385.50000
Epoch 29: Val Loss 4158374.50000
Epoch 30: Val Loss 4141005.00000
Epoch 31: Val Loss 4219412.00000
Epoch 32: Val Loss 4132973.50000
Epoch 33: Val Loss 4137291.75000
Epoch 34: Val Loss 4114025.25000
Epoch 35: Val Loss 4143899.75000
Epoch 36: Val Loss 4095769.25000
Epoch 37: Val Loss 4096983.00000
Epoch 38: Val Loss 4090238.00000
Epoch 39: Val Loss 4095128.75000
Epoch 40: Val Loss 4076846.00000
Epoch 41: Val Loss 4077116.75000
Epoch 42: Val Loss 4073879.00000
Epoch 43: Val Loss 4059549.50000
Epoch 44: Val Loss 4050986.50000
Epoch 45: Val Loss 4051553.75000
Epoch 46: Val Loss 4041190.25000
Epoch 47: Val Loss 4039404.25000
Epoch 48: Val Loss 4037572.50000
Epoch 49: Val Loss 4042908.25000
Epoch 50: Val Loss 4014542.25000
Epoch 51: Val Loss 4036822.25000
Epoch 52: Val Loss 4002007.50000
Epoch 53: Val Loss 4016103.00000
Epoch 54: Val Loss 3996113.00000
Epoch 55: Val Loss 3993893.75000
Epoch 56: Val Loss 3991992.25000
Epoch 57: Val Loss 4009657.25000
Epoch 58: Val Loss 3971881.50000
Epoch 59: Val Loss 3973073.75000
Epoch 60: Val Loss 3986846.75000
Epoch 61: Val Loss 3964259.00000
Epoch 62: Val Loss 3964763.75000
Epoch 63: Val Loss 3961980.25000
Epoch 64: Val Loss 4035695.75000
Epoch 65: Val Loss 3973075.50000
Epoch 66: Val Loss 3956874.00000
Epoch 67: Val Loss 3946597.75000
Epoch 68: Val Loss 3937224.75000
Epoch 69: Val Loss 3938906.50000
Epoch 70: Val Loss 3939540.75000
Epoch 71: Val Loss 3941522.75000
Epoch 72: Val Loss 3923716.00000
Epoch 73: Val Loss 3945909.75000
Epoch 74: Val Loss 3932470.25000
Epoch 75: Val Loss 3922190.25000
Epoch 76: Val Loss 3935592.25000
Epoch 77: Val Loss 3916120.00000
Epoch 78: Val Loss 3912504.00000
Epoch 79: Val Loss 3916665.50000
Epoch 80: Val Loss 3906504.00000
Epoch 81: Val Loss 3925853.00000
Epoch 82: Val Loss 3901494.25000
Epoch 83: Val Loss 3891126.25000
Epoch 84: Val Loss 3893363.00000
Epoch 85: Val Loss 3900596.00000
Epoch 86: Val Loss 3898850.25000
Epoch 87: Val Loss 3895206.50000
Epoch 88: Val Loss 3902736.00000
Epoch 89: Val Loss 3893002.50000
Epoch 90: Val Loss 3903362.75000
Epoch 91: Val Loss 3873553.50000
Epoch 92: Val Loss 3881768.75000
Epoch 93: Val Loss 3879478.50000
Epoch 94: Val Loss 3874020.50000
Epoch 95: Val Loss 4005059.50000
Epoch 96: Val Loss 3885976.75000
Epoch 97: Val Loss 3871043.50000
Epoch 98: Val Loss 3877556.50000
Epoch 99: Val Loss 3861543.00000
Saved Losses
{'MSE - mean': 3823639.1190942866, 'MSE - std': 230454.91105801525, 'R2 - mean': 0.5513379038808464, 'R2 - std': 0.012774795917511845} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8344525.00000
Epoch 1: Val Loss 7813644.50000
Epoch 2: Val Loss 7400018.50000
Epoch 3: Val Loss 6844771.00000
Epoch 4: Val Loss 6144863.00000
Epoch 5: Val Loss 5400653.50000
Epoch 6: Val Loss 4878855.50000
Epoch 7: Val Loss 4570091.00000
Epoch 8: Val Loss 4364295.50000
Epoch 9: Val Loss 4238983.00000
Epoch 10: Val Loss 4132352.00000
Epoch 11: Val Loss 4098318.75000
Epoch 12: Val Loss 4020654.25000
Epoch 13: Val Loss 3989537.00000
Epoch 14: Val Loss 3952504.75000
Epoch 15: Val Loss 3910746.50000
Epoch 16: Val Loss 3917783.00000
Epoch 17: Val Loss 3837532.75000
Epoch 18: Val Loss 3802779.75000
Epoch 19: Val Loss 3788020.50000
Epoch 20: Val Loss 3826136.00000
Epoch 21: Val Loss 3753088.50000
Epoch 22: Val Loss 3728596.75000
Epoch 23: Val Loss 3716702.25000
Epoch 24: Val Loss 3704122.00000
Epoch 25: Val Loss 3712011.00000
Epoch 26: Val Loss 3689793.00000
Epoch 27: Val Loss 3682103.50000
Epoch 28: Val Loss 3700007.50000
Epoch 29: Val Loss 3664865.50000
Epoch 30: Val Loss 3649472.50000
Epoch 31: Val Loss 3642923.00000
Epoch 32: Val Loss 3637185.75000
Epoch 33: Val Loss 3636995.00000
Epoch 34: Val Loss 3633898.00000
Epoch 35: Val Loss 3608998.25000
Epoch 36: Val Loss 3625492.75000
Epoch 37: Val Loss 3603957.75000
Epoch 38: Val Loss 3606064.00000
Epoch 39: Val Loss 3593726.25000
Epoch 40: Val Loss 3586939.75000
Epoch 41: Val Loss 3583464.25000
Epoch 42: Val Loss 3576185.25000
Epoch 43: Val Loss 3579694.50000
Epoch 44: Val Loss 3644765.50000
Epoch 45: Val Loss 3563065.50000
Epoch 46: Val Loss 3557616.25000
Epoch 47: Val Loss 3555040.00000
Epoch 48: Val Loss 3548706.25000
Epoch 49: Val Loss 3555337.25000
Epoch 50: Val Loss 3541082.75000
Epoch 51: Val Loss 3546387.75000
Epoch 52: Val Loss 3527872.50000
Epoch 53: Val Loss 3535495.25000
Epoch 54: Val Loss 3551339.00000
Epoch 55: Val Loss 3520686.25000
Epoch 56: Val Loss 3520293.75000
Epoch 57: Val Loss 3529745.50000
Epoch 58: Val Loss 3525705.50000
Epoch 59: Val Loss 3545514.25000
Epoch 60: Val Loss 3515595.75000
Epoch 61: Val Loss 3510892.25000
Epoch 62: Val Loss 3512043.75000
Epoch 63: Val Loss 3515663.00000
Epoch 64: Val Loss 3503789.00000
Epoch 65: Val Loss 3494392.50000
Epoch 66: Val Loss 3498216.00000
Epoch 67: Val Loss 3513530.75000
Epoch 68: Val Loss 3496147.00000
Epoch 69: Val Loss 3492888.25000
Epoch 70: Val Loss 3496287.75000
Epoch 71: Val Loss 3474977.00000
Epoch 72: Val Loss 3491111.75000
Epoch 73: Val Loss 3472985.50000
Epoch 74: Val Loss 3478270.00000
Epoch 75: Val Loss 3478439.00000
Epoch 76: Val Loss 3470601.50000
Epoch 77: Val Loss 3465908.50000
Epoch 78: Val Loss 3472062.25000
Epoch 79: Val Loss 3504165.00000
Epoch 80: Val Loss 3496613.00000
Epoch 81: Val Loss 3487253.00000
Epoch 82: Val Loss 3459105.50000
Epoch 83: Val Loss 3454600.00000
Epoch 84: Val Loss 3464102.75000
Epoch 85: Val Loss 3446851.00000
Epoch 86: Val Loss 3491527.75000
Epoch 87: Val Loss 3460009.75000
Epoch 88: Val Loss 3446751.75000
Epoch 89: Val Loss 3449236.50000
Epoch 90: Val Loss 3450447.50000
Epoch 91: Val Loss 3446111.75000
Epoch 92: Val Loss 3438640.00000
Epoch 93: Val Loss 3453037.00000
Epoch 94: Val Loss 3447201.75000
Epoch 95: Val Loss 3457024.25000
Epoch 96: Val Loss 3459533.00000
Epoch 97: Val Loss 3471872.50000
Epoch 98: Val Loss 3448221.75000
Epoch 99: Val Loss 3442525.25000
Saved Losses
{'MSE - mean': 3748959.936637097, 'MSE - std': 254549.59044261536, 'R2 - mean': 0.5558642136921682, 'R2 - std': 0.01457759413001792} 
 

Saving model.....
Results After CV: {'MSE - mean': 3748959.936637097, 'MSE - std': 254549.59044261536, 'R2 - mean': 0.5558642136921682, 'R2 - std': 0.01457759413001792}
Train time: 7613.201144741196
Inference time: 6.848573151591699
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 29 finished with value: 3748959.936637097 and parameters: {'dim': 64, 'depth': 1, 'heads': 8, 'weight_decay': -4, 'learning_rate': -5, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4485984.50000
Epoch 1: Val Loss 4089211.25000
Epoch 2: Val Loss 3980795.25000
Epoch 3: Val Loss 3932859.00000
Epoch 4: Val Loss 3894768.00000
Epoch 5: Val Loss 3827725.50000
Epoch 6: Val Loss 3797610.50000
Epoch 7: Val Loss 3781176.00000
Epoch 8: Val Loss 3786617.25000
Epoch 9: Val Loss 3730977.00000
Epoch 10: Val Loss 3715986.25000
Epoch 11: Val Loss 3736400.50000
Epoch 12: Val Loss 3684374.25000
Epoch 13: Val Loss 3683748.75000
Epoch 14: Val Loss 3669042.75000
Epoch 15: Val Loss 3652398.00000
Epoch 16: Val Loss 3641563.00000
Epoch 17: Val Loss 3633370.00000
Epoch 18: Val Loss 3629193.25000
Epoch 19: Val Loss 3615313.25000
Epoch 20: Val Loss 3712590.75000
Epoch 21: Val Loss 3622963.75000
Epoch 22: Val Loss 3629380.75000
Epoch 23: Val Loss 3606247.25000
Epoch 24: Val Loss 3604224.50000
Epoch 25: Val Loss 3605741.50000
Epoch 26: Val Loss 3587348.75000
Epoch 27: Val Loss 3591811.50000
Epoch 28: Val Loss 3595700.25000
Epoch 29: Val Loss 3577114.75000
Epoch 30: Val Loss 3587671.00000
Epoch 31: Val Loss 3584741.75000
Epoch 32: Val Loss 3570769.00000
Epoch 33: Val Loss 3554133.50000
Epoch 34: Val Loss 3582690.25000
Epoch 35: Val Loss 3569664.75000
Epoch 36: Val Loss 3555261.25000
Epoch 37: Val Loss 3559015.00000
Epoch 38: Val Loss 3573841.75000
Epoch 39: Val Loss 3566894.75000
Epoch 40: Val Loss 3560508.75000
Epoch 41: Val Loss 3577214.50000
Epoch 42: Val Loss 3564484.00000
Epoch 43: Val Loss 3547376.50000
Epoch 44: Val Loss 3545080.25000
Epoch 45: Val Loss 3588314.25000
Epoch 46: Val Loss 3544295.75000
Epoch 47: Val Loss 3554358.75000
Epoch 48: Val Loss 3561790.75000
Epoch 49: Val Loss 3606960.25000
Epoch 50: Val Loss 3548023.75000
Epoch 51: Val Loss 3535170.00000
Epoch 52: Val Loss 3585029.25000
Epoch 53: Val Loss 3580567.25000
Epoch 54: Val Loss 3553571.25000
Epoch 55: Val Loss 3551110.50000
Epoch 56: Val Loss 3540503.25000
Epoch 57: Val Loss 3518441.25000
Epoch 58: Val Loss 3530653.50000
Epoch 59: Val Loss 3548376.00000
Epoch 60: Val Loss 3523814.25000
Epoch 61: Val Loss 3553598.75000
Epoch 62: Val Loss 3520077.00000
Epoch 63: Val Loss 3533350.50000
Epoch 64: Val Loss 3518468.50000
Epoch 65: Val Loss 3518900.00000
Epoch 66: Val Loss 3558124.00000
Epoch 67: Val Loss 3626311.00000
Epoch 68: Val Loss 3525593.75000
Epoch 69: Val Loss 3522490.50000
Epoch 70: Val Loss 3512187.00000
Epoch 71: Val Loss 3560173.50000
Epoch 72: Val Loss 3539261.00000
Epoch 73: Val Loss 3545325.00000
Epoch 74: Val Loss 3531148.75000
Epoch 75: Val Loss 3512563.25000
Epoch 76: Val Loss 3525365.25000
Epoch 77: Val Loss 3512505.00000
Epoch 78: Val Loss 3514763.25000
Epoch 79: Val Loss 3518861.75000
Epoch 80: Val Loss 3510865.50000
Epoch 81: Val Loss 3512817.00000
Epoch 82: Val Loss 3505169.75000
Epoch 83: Val Loss 3506680.50000
Epoch 84: Val Loss 3542528.00000
Epoch 85: Val Loss 3533469.00000
Epoch 86: Val Loss 3510479.25000
Epoch 87: Val Loss 3527884.50000
Epoch 88: Val Loss 3538968.00000
Epoch 89: Val Loss 3566839.00000
Epoch 90: Val Loss 3555110.50000
Epoch 91: Val Loss 3511807.25000
Epoch 92: Val Loss 3506743.75000
Epoch 93: Val Loss 3511050.75000
Epoch 94: Val Loss 3493222.25000
Epoch 95: Val Loss 3506590.50000
Epoch 96: Val Loss 3499801.75000
Epoch 97: Val Loss 3513583.00000
Epoch 98: Val Loss 3508881.50000
Epoch 99: Val Loss 3509723.75000
Saved Losses
{'MSE - mean': 3504128.9623987023, 'MSE - std': 0.0, 'R2 - mean': 0.589436641428723, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4279951.00000
Epoch 1: Val Loss 3916545.00000
Epoch 2: Val Loss 3788322.25000
Epoch 3: Val Loss 3737327.25000
Epoch 4: Val Loss 3708944.50000
Epoch 5: Val Loss 3682245.75000
Epoch 6: Val Loss 3657342.25000
Epoch 7: Val Loss 3630340.00000
Epoch 8: Val Loss 3604101.00000
Epoch 9: Val Loss 3586864.00000
Epoch 10: Val Loss 3582518.50000
Epoch 11: Val Loss 3572582.50000
Epoch 12: Val Loss 3556663.75000
Epoch 13: Val Loss 3541926.00000
Epoch 14: Val Loss 3534215.00000
Epoch 15: Val Loss 3529052.50000
Epoch 16: Val Loss 3562077.00000
Epoch 17: Val Loss 3530171.00000
Epoch 18: Val Loss 3543470.00000
Epoch 19: Val Loss 3520505.50000
Epoch 20: Val Loss 3497515.75000
Epoch 21: Val Loss 3510913.00000
Epoch 22: Val Loss 3483329.50000
Epoch 23: Val Loss 3479989.50000
Epoch 24: Val Loss 3530330.25000
Epoch 25: Val Loss 3493103.25000
Epoch 26: Val Loss 3473844.00000
Epoch 27: Val Loss 3459302.50000
Epoch 28: Val Loss 3455220.00000
Epoch 29: Val Loss 3463279.75000
Epoch 30: Val Loss 3464958.75000
Epoch 31: Val Loss 3468492.25000
Epoch 32: Val Loss 3476810.00000
Epoch 33: Val Loss 3463879.75000
Epoch 34: Val Loss 3459788.25000
Epoch 35: Val Loss 3445750.75000
Epoch 36: Val Loss 3443645.25000
Epoch 37: Val Loss 3444345.25000
Epoch 38: Val Loss 3522420.00000
Epoch 39: Val Loss 3508009.75000
Epoch 40: Val Loss 3437438.00000
Epoch 41: Val Loss 3429918.75000
Epoch 42: Val Loss 3452776.00000
Epoch 43: Val Loss 3497361.50000
Epoch 44: Val Loss 3446195.25000
Epoch 45: Val Loss 3433088.25000
Epoch 46: Val Loss 3454304.75000
Epoch 47: Val Loss 3441761.25000
Epoch 48: Val Loss 3441038.25000
Epoch 49: Val Loss 3417969.75000
Epoch 50: Val Loss 3434636.25000
Epoch 51: Val Loss 3448926.25000
Epoch 52: Val Loss 3444214.00000
Epoch 53: Val Loss 3452610.00000
Epoch 54: Val Loss 3458863.75000
Epoch 55: Val Loss 3444375.75000
Epoch 56: Val Loss 3440206.00000
Epoch 57: Val Loss 3420070.25000
Epoch 58: Val Loss 3442875.50000
Epoch 59: Val Loss 3434487.25000
Epoch 60: Val Loss 3430263.00000
Epoch 61: Val Loss 3423721.50000
Epoch 62: Val Loss 3411598.00000
Epoch 63: Val Loss 3434505.50000
Epoch 64: Val Loss 3451271.25000
Epoch 65: Val Loss 3435265.50000
Epoch 66: Val Loss 3422516.50000
Epoch 67: Val Loss 3416005.75000
Epoch 68: Val Loss 3416605.25000
Epoch 69: Val Loss 3455485.75000
Epoch 70: Val Loss 3432296.00000
Epoch 71: Val Loss 3424285.75000
Epoch 72: Val Loss 3481494.25000
Epoch 73: Val Loss 3491276.25000
Epoch 74: Val Loss 3405021.75000
Epoch 75: Val Loss 3409177.00000
Epoch 76: Val Loss 3412979.50000
Epoch 77: Val Loss 3437238.25000
Epoch 78: Val Loss 3455078.75000
Epoch 79: Val Loss 3412446.00000
Epoch 80: Val Loss 3433072.50000
Epoch 81: Val Loss 3415694.75000
Epoch 82: Val Loss 3409268.50000
Epoch 83: Val Loss 3421961.50000
Epoch 84: Val Loss 3439768.50000
Epoch 85: Val Loss 3399901.25000
Epoch 86: Val Loss 3448979.25000
Epoch 87: Val Loss 3413476.50000
Epoch 88: Val Loss 3419827.00000
Epoch 89: Val Loss 3421485.25000
Epoch 90: Val Loss 3426822.00000
Epoch 91: Val Loss 3399931.00000
Epoch 92: Val Loss 3430766.00000
Epoch 93: Val Loss 3391407.50000
Epoch 94: Val Loss 3393632.50000
Epoch 95: Val Loss 3410767.75000
Epoch 96: Val Loss 3404536.25000
Epoch 97: Val Loss 3413167.25000
Epoch 98: Val Loss 3430182.50000
Epoch 99: Val Loss 3422363.00000
Saved Losses
{'MSE - mean': 3453672.757925772, 'MSE - std': 50456.20447292994, 'R2 - mean': 0.5822272707903713, 'R2 - std': 0.007209370638351753} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5009369.00000
Epoch 1: Val Loss 4553987.00000
Epoch 2: Val Loss 4465410.50000
Epoch 3: Val Loss 4397551.00000
Epoch 4: Val Loss 4339522.00000
Epoch 5: Val Loss 4314882.00000
Epoch 6: Val Loss 4283980.00000
Epoch 7: Val Loss 4295915.50000
Epoch 8: Val Loss 4250481.00000
Epoch 9: Val Loss 4234943.00000
Epoch 10: Val Loss 4411785.50000
Epoch 11: Val Loss 4195979.50000
Epoch 12: Val Loss 4181592.00000
Epoch 13: Val Loss 4163836.75000
Epoch 14: Val Loss 4165189.75000
Epoch 15: Val Loss 4142673.75000
Epoch 16: Val Loss 4141730.25000
Epoch 17: Val Loss 4126395.75000
Epoch 18: Val Loss 4131948.75000
Epoch 19: Val Loss 4140061.00000
Epoch 20: Val Loss 4110110.00000
Epoch 21: Val Loss 4110731.00000
Epoch 22: Val Loss 4092481.50000
Epoch 23: Val Loss 4094472.75000
Epoch 24: Val Loss 4085067.75000
Epoch 25: Val Loss 4084876.25000
Epoch 26: Val Loss 4081022.75000
Epoch 27: Val Loss 4083908.50000
Epoch 28: Val Loss 4065010.25000
Epoch 29: Val Loss 4067458.25000
Epoch 30: Val Loss 4066198.50000
Epoch 31: Val Loss 4122311.00000
Epoch 32: Val Loss 4081938.75000
Epoch 33: Val Loss 4048148.75000
Epoch 34: Val Loss 4050376.00000
Epoch 35: Val Loss 4103342.00000
Epoch 36: Val Loss 4032430.25000
Epoch 37: Val Loss 4056338.75000
Epoch 38: Val Loss 4028058.00000
Epoch 39: Val Loss 4026901.25000
Epoch 40: Val Loss 4084456.25000
Epoch 41: Val Loss 4026095.75000
Epoch 42: Val Loss 4044630.25000
Epoch 43: Val Loss 4042398.00000
Epoch 44: Val Loss 4022259.00000
Epoch 45: Val Loss 4018918.25000
Epoch 46: Val Loss 4017719.00000
Epoch 47: Val Loss 4018756.50000
Epoch 48: Val Loss 4038764.75000
Epoch 49: Val Loss 4006284.25000
Epoch 50: Val Loss 4027072.50000
Epoch 51: Val Loss 4046675.25000
Epoch 52: Val Loss 4013467.75000
Epoch 53: Val Loss 3996940.75000
Epoch 54: Val Loss 4094085.75000
Epoch 55: Val Loss 4000616.25000
Epoch 56: Val Loss 4006546.25000
Epoch 57: Val Loss 3998554.50000
Epoch 58: Val Loss 3994545.50000
Epoch 59: Val Loss 4013082.00000
Epoch 60: Val Loss 4023262.25000
Epoch 61: Val Loss 4031051.00000
Epoch 62: Val Loss 4001958.50000
Epoch 63: Val Loss 3997093.75000
Epoch 64: Val Loss 4005753.25000
Epoch 65: Val Loss 3994493.00000
Epoch 66: Val Loss 3999144.75000
Epoch 67: Val Loss 4001690.00000
Epoch 68: Val Loss 3993017.25000
Epoch 69: Val Loss 4023722.00000
Epoch 70: Val Loss 4007207.00000
Epoch 71: Val Loss 4005476.00000
Epoch 72: Val Loss 3982384.00000
Epoch 73: Val Loss 3997723.75000
Epoch 74: Val Loss 4008600.75000
Epoch 75: Val Loss 3981912.25000
Epoch 76: Val Loss 4039915.75000
Epoch 77: Val Loss 3988763.25000
Epoch 78: Val Loss 3979401.50000
Epoch 79: Val Loss 3994868.75000
Epoch 80: Val Loss 3978126.75000
Epoch 81: Val Loss 3987864.00000
Epoch 82: Val Loss 3998945.00000
Epoch 83: Val Loss 3977917.50000
Epoch 84: Val Loss 3990029.00000
Epoch 85: Val Loss 4026791.00000
Epoch 86: Val Loss 4000256.50000
Epoch 87: Val Loss 4051986.25000
Epoch 88: Val Loss 4006405.25000
Epoch 89: Val Loss 3971776.00000
Epoch 90: Val Loss 4001905.50000
Epoch 91: Val Loss 3999332.75000
Epoch 92: Val Loss 4013155.50000
Epoch 93: Val Loss 4026176.00000
Epoch 94: Val Loss 3992432.50000
Epoch 95: Val Loss 3977800.75000
Epoch 96: Val Loss 3974958.75000
Epoch 97: Val Loss 3970898.75000
Epoch 98: Val Loss 3989962.00000
Epoch 99: Val Loss 3988407.50000
Saved Losses
{'MSE - mean': 3630378.158829361, 'MSE - std': 253272.21810443222, 'R2 - mean': 0.5729320401881097, 'R2 - std': 0.014403216327121451} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4607755.50000
Epoch 1: Val Loss 4221916.00000
Epoch 2: Val Loss 4123165.50000
Epoch 3: Val Loss 4061933.00000
Epoch 4: Val Loss 4040064.50000
Epoch 5: Val Loss 4075892.75000
Epoch 6: Val Loss 3975381.75000
Epoch 7: Val Loss 3954903.50000
Epoch 8: Val Loss 3935813.25000
Epoch 9: Val Loss 3921672.00000
Epoch 10: Val Loss 3917617.75000
Epoch 11: Val Loss 3877589.75000
Epoch 12: Val Loss 3881965.00000
Epoch 13: Val Loss 3860678.25000
Epoch 14: Val Loss 3895324.25000
Epoch 15: Val Loss 3839386.00000
Epoch 16: Val Loss 3839928.25000
Epoch 17: Val Loss 3867323.75000
Epoch 18: Val Loss 3866804.50000
Epoch 19: Val Loss 3814670.00000
Epoch 20: Val Loss 3815597.50000
Epoch 21: Val Loss 3806380.25000
Epoch 22: Val Loss 3824638.00000
Epoch 23: Val Loss 3810496.00000
Epoch 24: Val Loss 3795615.25000
Epoch 25: Val Loss 3786241.00000
Epoch 26: Val Loss 3786273.00000
Epoch 27: Val Loss 3777102.75000
Epoch 28: Val Loss 3787014.25000
Epoch 29: Val Loss 3780059.25000
Epoch 30: Val Loss 3780215.00000
Epoch 31: Val Loss 3815595.75000
Epoch 32: Val Loss 3796698.00000
Epoch 33: Val Loss 3751180.25000
Epoch 34: Val Loss 3764843.25000
Epoch 35: Val Loss 3759187.00000
Epoch 36: Val Loss 3821626.00000
Epoch 37: Val Loss 3775660.75000
Epoch 38: Val Loss 3814394.50000
Epoch 39: Val Loss 3746136.25000
Epoch 40: Val Loss 3737472.50000
Epoch 41: Val Loss 5340271.50000
Epoch 42: Val Loss 3747824.00000
Epoch 43: Val Loss 3734981.75000
Epoch 44: Val Loss 3747115.75000
Epoch 45: Val Loss 3765284.50000
Epoch 46: Val Loss 3773072.00000
Epoch 47: Val Loss 3733857.00000
Epoch 48: Val Loss 3736926.75000
Epoch 49: Val Loss 3764912.50000
Epoch 50: Val Loss 3739401.25000
Epoch 51: Val Loss 3726460.25000
Epoch 52: Val Loss 3720106.00000
Epoch 53: Val Loss 3736349.50000
Epoch 54: Val Loss 3740344.25000
Epoch 55: Val Loss 3732213.25000
Epoch 56: Val Loss 3717979.25000
Epoch 57: Val Loss 3714209.00000
Epoch 58: Val Loss 3720804.75000
Epoch 59: Val Loss 3726359.75000
Epoch 60: Val Loss 3737858.75000
Epoch 61: Val Loss 3713770.00000
Epoch 62: Val Loss 3709252.00000
Epoch 63: Val Loss 3721960.75000
Epoch 64: Val Loss 3715357.50000
Epoch 65: Val Loss 3698903.75000
Epoch 66: Val Loss 3710334.75000
Epoch 67: Val Loss 3713043.50000
Epoch 68: Val Loss 3716508.25000
Epoch 69: Val Loss 3703112.75000
Epoch 70: Val Loss 3727606.25000
Epoch 71: Val Loss 3715199.75000
Epoch 72: Val Loss 3692895.75000
Epoch 73: Val Loss 3733365.75000
Epoch 74: Val Loss 3775322.00000
Epoch 75: Val Loss 3702506.50000
Epoch 76: Val Loss 3705099.00000
Epoch 77: Val Loss 3719833.50000
Epoch 78: Val Loss 3698654.75000
Epoch 79: Val Loss 3696311.75000
Epoch 80: Val Loss 3751972.50000
Epoch 81: Val Loss 3700875.00000
Epoch 82: Val Loss 3690939.25000
Epoch 83: Val Loss 3710447.25000
Epoch 84: Val Loss 3692465.00000
Epoch 85: Val Loss 3702660.75000
Epoch 86: Val Loss 3694166.25000
Epoch 87: Val Loss 3692106.00000
Epoch 88: Val Loss 3691220.00000
Epoch 89: Val Loss 3696890.00000
Epoch 90: Val Loss 3733305.25000
Epoch 91: Val Loss 3694536.25000
Epoch 92: Val Loss 3708990.00000
Epoch 93: Val Loss 3687684.75000
Epoch 94: Val Loss 3712879.75000
Epoch 95: Val Loss 3698916.00000
Epoch 96: Val Loss 3714574.75000
Epoch 97: Val Loss 3692047.25000
Epoch 98: Val Loss 3685364.75000
Epoch 99: Val Loss 3697362.25000
Saved Losses
{'MSE - mean': 3646274.748723744, 'MSE - std': 221061.56847915667, 'R2 - mean': 0.5721470668349253, 'R2 - std': 0.012547431208021114} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4137345.00000
Epoch 1: Val Loss 3751458.75000
Epoch 2: Val Loss 3653103.25000
Epoch 3: Val Loss 3593376.50000
Epoch 4: Val Loss 3567366.25000
Epoch 5: Val Loss 3546294.75000
Epoch 6: Val Loss 3509695.75000
Epoch 7: Val Loss 3513976.00000
Epoch 8: Val Loss 3483651.75000
Epoch 9: Val Loss 3506824.25000
Epoch 10: Val Loss 3463999.75000
Epoch 11: Val Loss 3451606.50000
Epoch 12: Val Loss 3444943.75000
Epoch 13: Val Loss 3432463.75000
Epoch 14: Val Loss 3471009.50000
Epoch 15: Val Loss 3434460.50000
Epoch 16: Val Loss 3433884.50000
Epoch 17: Val Loss 3412755.25000
Epoch 18: Val Loss 3442249.00000
Epoch 19: Val Loss 3405003.00000
Epoch 20: Val Loss 3425442.00000
Epoch 21: Val Loss 3449350.50000
Epoch 22: Val Loss 3436610.00000
Epoch 23: Val Loss 3437247.75000
Epoch 24: Val Loss 3420623.50000
Epoch 25: Val Loss 3427613.50000
Epoch 26: Val Loss 3405995.75000
Epoch 27: Val Loss 3390940.25000
Epoch 28: Val Loss 3387753.50000
Epoch 29: Val Loss 3389075.00000
Epoch 30: Val Loss 3396014.00000
Epoch 31: Val Loss 3410760.50000
Epoch 32: Val Loss 3411082.00000
Epoch 33: Val Loss 3399825.75000
Epoch 34: Val Loss 3395991.25000
Epoch 35: Val Loss 3409276.00000
Epoch 36: Val Loss 3381995.50000
Epoch 37: Val Loss 3366351.50000
Epoch 38: Val Loss 3417022.25000
Epoch 39: Val Loss 3409003.50000
Epoch 40: Val Loss 3399257.00000
Epoch 41: Val Loss 3375942.75000
Epoch 42: Val Loss 3373426.00000
Epoch 43: Val Loss 3445334.25000
Epoch 44: Val Loss 3385964.50000
Epoch 45: Val Loss 3379217.50000
Epoch 46: Val Loss 3389362.25000
Epoch 47: Val Loss 3364130.50000
Epoch 48: Val Loss 3368237.25000
Epoch 49: Val Loss 3411005.00000
Epoch 50: Val Loss 3357340.75000
Epoch 51: Val Loss 3356802.75000
Epoch 52: Val Loss 3370877.50000
Epoch 53: Val Loss 3367917.50000
Epoch 54: Val Loss 3376466.50000
Epoch 55: Val Loss 3359015.75000
Epoch 56: Val Loss 3371878.50000
Epoch 57: Val Loss 3365707.25000
Epoch 58: Val Loss 3366238.75000
Epoch 59: Val Loss 3360356.25000
Epoch 60: Val Loss 3352503.75000
Epoch 61: Val Loss 3410548.50000
Epoch 62: Val Loss 3351742.50000
Epoch 63: Val Loss 3357924.75000
Epoch 64: Val Loss 3392295.75000
Epoch 65: Val Loss 3370905.50000
Epoch 66: Val Loss 3427838.75000
Epoch 67: Val Loss 3348164.25000
Epoch 68: Val Loss 3352743.00000
Epoch 69: Val Loss 3349199.25000
Epoch 70: Val Loss 3377284.00000
Epoch 71: Val Loss 3367371.00000
Epoch 72: Val Loss 3381885.25000
Epoch 73: Val Loss 3366474.00000
Epoch 74: Val Loss 3360069.50000
Epoch 75: Val Loss 3354890.25000
Epoch 76: Val Loss 3388820.25000
Epoch 77: Val Loss 3365073.25000
Epoch 78: Val Loss 3344041.50000
Epoch 79: Val Loss 3345311.00000
Epoch 80: Val Loss 3358147.75000
Epoch 81: Val Loss 3358183.00000
Epoch 82: Val Loss 3347671.00000
Epoch 83: Val Loss 3340851.25000
Epoch 84: Val Loss 3367469.50000
Epoch 85: Val Loss 3387814.00000
Epoch 86: Val Loss 3385941.00000
Epoch 87: Val Loss 3371417.50000
Epoch 88: Val Loss 3356529.75000
Epoch 89: Val Loss 3346614.75000
Epoch 90: Val Loss 3359998.00000
Epoch 91: Val Loss 3375762.50000
Epoch 92: Val Loss 3361894.50000
Epoch 93: Val Loss 3362375.75000
Epoch 94: Val Loss 3392349.50000
Epoch 95: Val Loss 3347436.00000
Epoch 96: Val Loss 3330346.75000
Epoch 97: Val Loss 3342696.75000
Epoch 98: Val Loss 3352229.25000
Epoch 99: Val Loss 3348191.75000
Saved Losses
{'MSE - mean': 3584789.694026989, 'MSE - std': 232843.77047931484, 'R2 - mean': 0.5752624882384827, 'R2 - std': 0.012836425749522037} 
 

Saving model.....
Results After CV: {'MSE - mean': 3584789.694026989, 'MSE - std': 232843.77047931484, 'R2 - mean': 0.5752624882384827, 'R2 - std': 0.012836425749522037}
Train time: 7715.721494688629
Inference time: 6.933550942176953
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 30 finished with value: 3584789.694026989 and parameters: {'dim': 64, 'depth': 6, 'heads': 8, 'weight_decay': -1, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3820002.25000
Epoch 1: Val Loss 3824854.50000
Epoch 2: Val Loss 3679342.25000
Epoch 3: Val Loss 3677828.75000
Epoch 4: Val Loss 3583564.25000
Epoch 5: Val Loss 3543679.00000
Epoch 6: Val Loss 3475116.75000
Epoch 7: Val Loss 3496444.75000
Epoch 8: Val Loss 3448952.25000
Epoch 9: Val Loss 3476732.75000
Epoch 10: Val Loss 3439014.25000
Epoch 11: Val Loss 3537471.25000
Epoch 12: Val Loss 3451395.00000
Epoch 13: Val Loss 3437740.50000
Epoch 14: Val Loss 3567428.25000
Epoch 15: Val Loss 3561290.00000
Epoch 16: Val Loss 3665146.00000
Epoch 17: Val Loss 3798003.00000
Epoch 18: Val Loss 3793117.50000
Epoch 19: Val Loss 3899835.00000
Epoch 20: Val Loss 3886410.50000
Epoch 21: Val Loss 3963054.25000
Epoch 22: Val Loss 3951818.00000
Epoch 23: Val Loss 4014662.50000
Epoch 24: Val Loss 4013604.00000
Epoch 25: Val Loss 4039515.00000
Epoch 26: Val Loss 4159619.25000
Epoch 27: Val Loss 4175234.25000
Epoch 28: Val Loss 4165475.25000
Epoch 29: Val Loss 4205339.50000
Epoch 30: Val Loss 4446956.00000
Epoch 31: Val Loss 4512607.00000
Epoch 32: Val Loss 4296351.50000
Epoch 33: Val Loss 4441643.50000
Epoch 34: Val Loss 4322280.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3447739.36408059, 'MSE - std': 0.0, 'R2 - mean': 0.596043562327582, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3690471.75000
Epoch 1: Val Loss 3657440.00000
Epoch 2: Val Loss 3578593.50000
Epoch 3: Val Loss 3525055.50000
Epoch 4: Val Loss 3492687.75000
Epoch 5: Val Loss 3462040.00000
Epoch 6: Val Loss 3485031.50000
Epoch 7: Val Loss 3429972.00000
Epoch 8: Val Loss 3399453.00000
Epoch 9: Val Loss 3432660.00000
Epoch 10: Val Loss 3446209.50000
Epoch 11: Val Loss 3515526.25000
Epoch 12: Val Loss 3465904.25000
Epoch 13: Val Loss 3489508.75000
Epoch 14: Val Loss 3467763.50000
Epoch 15: Val Loss 3568202.00000
Epoch 16: Val Loss 3556933.00000
Epoch 17: Val Loss 3625769.50000
Epoch 18: Val Loss 3727369.25000
Epoch 19: Val Loss 3696007.75000
Epoch 20: Val Loss 3778307.50000
Epoch 21: Val Loss 3768596.00000
Epoch 22: Val Loss 3892927.25000
Epoch 23: Val Loss 3905983.25000
Epoch 24: Val Loss 3943835.00000
Epoch 25: Val Loss 4003115.25000
Epoch 26: Val Loss 4054253.00000
Epoch 27: Val Loss 4170385.75000
Epoch 28: Val Loss 4120944.00000
Epoch 29: Val Loss 4141472.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3426405.8580316524, 'MSE - std': 21333.506048937794, 'R2 - mean': 0.5854148583378369, 'R2 - std': 0.010628703989745136} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4346403.50000
Epoch 1: Val Loss 4230790.50000
Epoch 2: Val Loss 4206641.50000
Epoch 3: Val Loss 4188763.25000
Epoch 4: Val Loss 4042490.50000
Epoch 5: Val Loss 4046553.25000
Epoch 6: Val Loss 4138733.50000
Epoch 7: Val Loss 3926109.00000
Epoch 8: Val Loss 4194018.25000
Epoch 9: Val Loss 3887195.25000
Epoch 10: Val Loss 3882476.75000
Epoch 11: Val Loss 3910391.50000
Epoch 12: Val Loss 3883525.25000
Epoch 13: Val Loss 3870120.25000
Epoch 14: Val Loss 3904702.75000
Epoch 15: Val Loss 3882884.50000
Epoch 16: Val Loss 3950219.75000
Epoch 17: Val Loss 3982391.50000
Epoch 18: Val Loss 4063816.25000
Epoch 19: Val Loss 4175687.50000
Epoch 20: Val Loss 4144332.25000
Epoch 21: Val Loss 4204195.00000
Epoch 22: Val Loss 4359999.00000
Epoch 23: Val Loss 4391933.50000
Epoch 24: Val Loss 4355052.00000
Epoch 25: Val Loss 4479627.00000
Epoch 26: Val Loss 4508526.50000
Epoch 27: Val Loss 4545124.50000
Epoch 28: Val Loss 4547190.50000
Epoch 29: Val Loss 4653708.00000
Epoch 30: Val Loss 4631980.00000
Epoch 31: Val Loss 4708141.00000
Epoch 32: Val Loss 4817869.00000
Epoch 33: Val Loss 4851813.00000
Epoch 34: Val Loss 4787773.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3578384.106334202, 'MSE - std': 215634.38555677838, 'R2 - mean': 0.5788400394796595, 'R2 - std': 0.01271885942357948} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4022536.75000
Epoch 1: Val Loss 4012178.25000
Epoch 2: Val Loss 3938646.50000
Epoch 3: Val Loss 3850210.25000
Epoch 4: Val Loss 3779719.00000
Epoch 5: Val Loss 3769441.50000
Epoch 6: Val Loss 3824675.50000
Epoch 7: Val Loss 3796147.50000
Epoch 8: Val Loss 3780070.25000
Epoch 9: Val Loss 3782194.25000
Epoch 10: Val Loss 3792989.00000
Epoch 11: Val Loss 3878209.75000
Epoch 12: Val Loss 4008674.25000
Epoch 13: Val Loss 3842160.00000
Epoch 14: Val Loss 3882028.75000
Epoch 15: Val Loss 4017344.00000
Epoch 16: Val Loss 4007912.25000
Epoch 17: Val Loss 4066440.25000
Epoch 18: Val Loss 4105971.50000
Epoch 19: Val Loss 4201401.00000
Epoch 20: Val Loss 4232567.50000
Epoch 21: Val Loss 4305683.50000
Epoch 22: Val Loss 4378406.50000
Epoch 23: Val Loss 4410030.50000
Epoch 24: Val Loss 4450409.50000
Epoch 25: Val Loss 4477404.00000
Epoch 26: Val Loss 4556886.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3628749.9149413016, 'MSE - std': 206115.9508766314, 'R2 - mean': 0.5740775370990965, 'R2 - std': 0.01376122543788104} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3627974.50000
Epoch 1: Val Loss 3522907.50000
Epoch 2: Val Loss 3450459.00000
Epoch 3: Val Loss 3829133.00000
Epoch 4: Val Loss 3438436.50000
Epoch 5: Val Loss 3580010.00000
Epoch 6: Val Loss 3435128.25000
Epoch 7: Val Loss 3433496.25000
Epoch 8: Val Loss 3424118.75000
Epoch 9: Val Loss 3399921.25000
Epoch 10: Val Loss 3456247.75000
Epoch 11: Val Loss 3429640.25000
Epoch 12: Val Loss 3459239.75000
Epoch 13: Val Loss 3480300.25000
Epoch 14: Val Loss 3534928.25000
Epoch 15: Val Loss 3497312.50000
Epoch 16: Val Loss 3553041.25000
Epoch 17: Val Loss 3630557.00000
Epoch 18: Val Loss 3651809.75000
Epoch 19: Val Loss 3676314.50000
Epoch 20: Val Loss 3804354.25000
Epoch 21: Val Loss 3869353.50000
Epoch 22: Val Loss 3893933.50000
Epoch 23: Val Loss 3966483.00000
Epoch 24: Val Loss 3996962.75000
Epoch 25: Val Loss 4062900.50000
Epoch 26: Val Loss 4087469.00000
Epoch 27: Val Loss 4114980.00000
Epoch 28: Val Loss 4179276.25000
Epoch 29: Val Loss 4149678.75000
Epoch 30: Val Loss 4256569.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3585276.5890120105, 'MSE - std': 203830.19509886156, 'R2 - mean': 0.5750155925350032, 'R2 - std': 0.012450576390074651} 
 

Saving model.....
Results After CV: {'MSE - mean': 3585276.5890120105, 'MSE - std': 203830.19509886156, 'R2 - mean': 0.5750155925350032, 'R2 - std': 0.012450576390074651}
Train time: 2363.3844064347677
Inference time: 6.621568106999621
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 31 finished with value: 3585276.5890120105 and parameters: {'dim': 256, 'depth': 1, 'heads': 4, 'weight_decay': -2, 'learning_rate': -3, 'dropout': 0.4}. Best is trial 22 with value: 3551246.41642021.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4525461.50000
Epoch 1: Val Loss 4110676.00000
Epoch 2: Val Loss 3991077.25000
Epoch 3: Val Loss 3918043.25000
Epoch 4: Val Loss 3889148.75000
Epoch 5: Val Loss 3823806.25000
Epoch 6: Val Loss 3789650.25000
Epoch 7: Val Loss 3738135.00000
Epoch 8: Val Loss 3712374.25000
Epoch 9: Val Loss 3687043.00000
Epoch 10: Val Loss 3666287.25000
Epoch 11: Val Loss 3644726.50000
Epoch 12: Val Loss 3638500.75000
Epoch 13: Val Loss 3606865.50000
Epoch 14: Val Loss 3605139.00000
Epoch 15: Val Loss 3587319.50000
Epoch 16: Val Loss 3570309.25000
Epoch 17: Val Loss 3575808.75000
Epoch 18: Val Loss 3592740.75000
Epoch 19: Val Loss 3555461.25000
Epoch 20: Val Loss 3549294.25000
Epoch 21: Val Loss 3581099.25000
Epoch 22: Val Loss 3517020.75000
Epoch 23: Val Loss 3577487.50000
Epoch 24: Val Loss 3554644.75000
Epoch 25: Val Loss 3549627.50000
Epoch 26: Val Loss 3530929.00000
Epoch 27: Val Loss 3509763.00000
Epoch 28: Val Loss 3494343.75000
Epoch 29: Val Loss 3600827.50000
Epoch 30: Val Loss 3490560.25000
Epoch 31: Val Loss 3484450.25000
Epoch 32: Val Loss 3491113.50000
Epoch 33: Val Loss 3491108.50000
Epoch 34: Val Loss 3469668.50000
Epoch 35: Val Loss 3467835.75000
Epoch 36: Val Loss 3452598.50000
Epoch 37: Val Loss 3449009.50000
Epoch 38: Val Loss 3461270.00000
Epoch 39: Val Loss 3461198.50000
Epoch 40: Val Loss 3436873.50000
Epoch 41: Val Loss 3483781.00000
Epoch 42: Val Loss 3442890.50000
Epoch 43: Val Loss 3432345.25000
Epoch 44: Val Loss 3462685.50000
Epoch 45: Val Loss 3446923.50000
Epoch 46: Val Loss 3423105.75000
Epoch 47: Val Loss 3428939.25000
Epoch 48: Val Loss 3561875.00000
Epoch 49: Val Loss 3481682.75000
Epoch 50: Val Loss 3429477.25000
Epoch 51: Val Loss 3430283.25000
Epoch 52: Val Loss 3412264.25000
Epoch 53: Val Loss 3423811.00000
Epoch 54: Val Loss 3442144.50000
Epoch 55: Val Loss 3429830.00000
Epoch 56: Val Loss 3458959.25000
Epoch 57: Val Loss 3408284.50000
Epoch 58: Val Loss 3400736.50000
Epoch 59: Val Loss 3443322.75000
Epoch 60: Val Loss 3442179.75000
Epoch 61: Val Loss 3423811.75000
Epoch 62: Val Loss 3423297.75000
Epoch 63: Val Loss 3415173.75000
Epoch 64: Val Loss 3472532.25000
Epoch 65: Val Loss 3454575.75000
Epoch 66: Val Loss 3458657.25000
Epoch 67: Val Loss 3468960.75000
Epoch 68: Val Loss 3501062.25000
Epoch 69: Val Loss 3449688.75000
Epoch 70: Val Loss 3439099.00000
Epoch 71: Val Loss 3461058.50000
Epoch 72: Val Loss 3506823.00000
Epoch 73: Val Loss 3423996.25000
Epoch 74: Val Loss 3444089.25000
Epoch 75: Val Loss 3464823.00000
Epoch 76: Val Loss 3498033.25000
Epoch 77: Val Loss 3468391.75000
Epoch 78: Val Loss 3466029.75000
Epoch 79: Val Loss 3461334.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3410958.304394711, 'MSE - std': 0.0, 'R2 - mean': 0.6003530371096141, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4225253.50000
Epoch 1: Val Loss 3889272.00000
Epoch 2: Val Loss 3780747.00000
Epoch 3: Val Loss 3736190.25000
Epoch 4: Val Loss 3686183.75000
Epoch 5: Val Loss 3649061.25000
Epoch 6: Val Loss 3619340.25000
Epoch 7: Val Loss 3611910.00000
Epoch 8: Val Loss 3595379.50000
Epoch 9: Val Loss 3592004.00000
Epoch 10: Val Loss 3557253.00000
Epoch 11: Val Loss 3549015.00000
Epoch 12: Val Loss 3518615.75000
Epoch 13: Val Loss 3526051.25000
Epoch 14: Val Loss 3511078.25000
Epoch 15: Val Loss 3516990.25000
Epoch 16: Val Loss 3499127.25000
Epoch 17: Val Loss 3497871.25000
Epoch 18: Val Loss 3493609.50000
Epoch 19: Val Loss 3482614.25000
Epoch 20: Val Loss 3488660.00000
Epoch 21: Val Loss 3453082.75000
Epoch 22: Val Loss 3478165.50000
Epoch 23: Val Loss 3500635.75000
Epoch 24: Val Loss 3442936.75000
Epoch 25: Val Loss 3438267.00000
Epoch 26: Val Loss 3446205.50000
Epoch 27: Val Loss 3455838.00000
Epoch 28: Val Loss 3467088.50000
Epoch 29: Val Loss 3465218.25000
Epoch 30: Val Loss 3429190.75000
Epoch 31: Val Loss 3421459.25000
Epoch 32: Val Loss 3425934.25000
Epoch 33: Val Loss 3494474.50000
Epoch 34: Val Loss 3420191.00000
Epoch 35: Val Loss 3415331.50000
Epoch 36: Val Loss 3508109.75000
Epoch 37: Val Loss 3396740.50000
Epoch 38: Val Loss 3395249.50000
Epoch 39: Val Loss 3454719.00000
Epoch 40: Val Loss 3495307.75000
Epoch 41: Val Loss 3432535.75000
Epoch 42: Val Loss 3416332.00000
Epoch 43: Val Loss 3425113.50000
Epoch 44: Val Loss 3443922.75000
Epoch 45: Val Loss 3390229.50000
Epoch 46: Val Loss 3394976.25000
Epoch 47: Val Loss 3408996.25000
Epoch 48: Val Loss 3403021.25000
Epoch 49: Val Loss 3416027.25000
Epoch 50: Val Loss 3403591.25000
Epoch 51: Val Loss 3403652.50000
Epoch 52: Val Loss 3396275.75000
Epoch 53: Val Loss 3422761.25000
Epoch 54: Val Loss 3399065.50000
Epoch 55: Val Loss 3409215.75000
Epoch 56: Val Loss 3415731.00000
Epoch 57: Val Loss 3444268.50000
Epoch 58: Val Loss 3418881.50000
Epoch 59: Val Loss 3438959.75000
Epoch 60: Val Loss 3438811.00000
Epoch 61: Val Loss 3449347.00000
Epoch 62: Val Loss 3478074.00000
Epoch 63: Val Loss 3436262.25000
Epoch 64: Val Loss 3443885.75000
Epoch 65: Val Loss 3433338.75000
Epoch 66: Val Loss 3415184.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3404930.7002538303, 'MSE - std': 6027.604140880285, 'R2 - mean': 0.5879547935663769, 'R2 - std': 0.012398243543237097} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5063935.00000
Epoch 1: Val Loss 4561624.00000
Epoch 2: Val Loss 4439275.50000
Epoch 3: Val Loss 4395612.00000
Epoch 4: Val Loss 4316627.50000
Epoch 5: Val Loss 4276828.00000
Epoch 6: Val Loss 4241310.50000
Epoch 7: Val Loss 4227311.00000
Epoch 8: Val Loss 4192014.75000
Epoch 9: Val Loss 4195258.50000
Epoch 10: Val Loss 4180990.25000
Epoch 11: Val Loss 4131703.50000
Epoch 12: Val Loss 4148734.00000
Epoch 13: Val Loss 4106481.50000
Epoch 14: Val Loss 4083026.25000
Epoch 15: Val Loss 4097407.75000
Epoch 16: Val Loss 6104678.50000
Epoch 17: Val Loss 4056629.25000
Epoch 18: Val Loss 4041481.50000
Epoch 19: Val Loss 4038791.00000
Epoch 20: Val Loss 4028724.75000
Epoch 21: Val Loss 4029438.75000
Epoch 22: Val Loss 4034870.50000
Epoch 23: Val Loss 4032220.75000
Epoch 24: Val Loss 3988736.50000
Epoch 25: Val Loss 3984693.25000
Epoch 26: Val Loss 3976783.25000
Epoch 27: Val Loss 4005765.25000
Epoch 28: Val Loss 3987031.50000
Epoch 29: Val Loss 3956621.50000
Epoch 30: Val Loss 3979599.75000
Epoch 31: Val Loss 3960797.00000
Epoch 32: Val Loss 3971658.50000
Epoch 33: Val Loss 3940485.25000
Epoch 34: Val Loss 3924694.50000
Epoch 35: Val Loss 3931786.00000
Epoch 36: Val Loss 3918476.25000
Epoch 37: Val Loss 3922329.50000
Epoch 38: Val Loss 3948692.75000
Epoch 39: Val Loss 3917559.00000
Epoch 40: Val Loss 3905619.50000
Epoch 41: Val Loss 3889600.00000
Epoch 42: Val Loss 3932882.25000
Epoch 43: Val Loss 3902574.00000
Epoch 44: Val Loss 3942646.25000
Epoch 45: Val Loss 3959415.50000
Epoch 46: Val Loss 3918399.75000
Epoch 47: Val Loss 3876054.25000
Epoch 48: Val Loss 3895865.25000
Epoch 49: Val Loss 3877423.75000
Epoch 50: Val Loss 3876705.75000
Epoch 51: Val Loss 3870637.00000
Epoch 52: Val Loss 3873380.00000
Epoch 53: Val Loss 3855208.75000
Epoch 54: Val Loss 3845829.75000
Epoch 55: Val Loss 3857702.25000
Epoch 56: Val Loss 3867022.00000
Epoch 57: Val Loss 3846125.50000
Epoch 58: Val Loss 3836890.50000
Epoch 59: Val Loss 3852913.00000
Epoch 60: Val Loss 3884830.25000
Epoch 61: Val Loss 3832252.25000
Epoch 62: Val Loss 3852501.75000
Epoch 63: Val Loss 3840168.75000
Epoch 64: Val Loss 3842139.25000
Epoch 65: Val Loss 3852874.50000
Epoch 66: Val Loss 3848835.50000
Epoch 67: Val Loss 3859816.75000
Epoch 68: Val Loss 3848807.00000
Epoch 69: Val Loss 3868848.00000
Epoch 70: Val Loss 3838587.25000
Epoch 71: Val Loss 3839905.00000
Epoch 72: Val Loss 3853724.75000
Epoch 73: Val Loss 3833647.75000
Epoch 74: Val Loss 3905462.25000
Epoch 75: Val Loss 3865759.25000
Epoch 76: Val Loss 3871189.25000
Epoch 77: Val Loss 3878301.50000
Epoch 78: Val Loss 3945556.00000
Epoch 79: Val Loss 3868677.25000
Epoch 80: Val Loss 3873822.25000
Epoch 81: Val Loss 3881288.75000
Epoch 82: Val Loss 3918417.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551985.3386602798, 'MSE - std': 208024.88960415934, 'R2 - mean': 0.5818849180906401, 'R2 - std': 0.0132726939699588} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4632509.00000
Epoch 1: Val Loss 4227189.50000
Epoch 2: Val Loss 4138526.25000
Epoch 3: Val Loss 4104196.00000
Epoch 4: Val Loss 4077674.50000
Epoch 5: Val Loss 4005100.75000
Epoch 6: Val Loss 3961509.25000
Epoch 7: Val Loss 3967307.75000
Epoch 8: Val Loss 3917606.25000
Epoch 9: Val Loss 3917441.75000
Epoch 10: Val Loss 3886239.75000
Epoch 11: Val Loss 3888683.25000
Epoch 12: Val Loss 3864649.25000
Epoch 13: Val Loss 3871775.75000
Epoch 14: Val Loss 3836297.25000
Epoch 15: Val Loss 3838149.75000
Epoch 16: Val Loss 3820887.50000
Epoch 17: Val Loss 3814423.00000
Epoch 18: Val Loss 3835052.25000
Epoch 19: Val Loss 3793997.50000
Epoch 20: Val Loss 3778305.75000
Epoch 21: Val Loss 3776349.50000
Epoch 22: Val Loss 3816988.75000
Epoch 23: Val Loss 3764431.75000
Epoch 24: Val Loss 3776209.00000
Epoch 25: Val Loss 3757679.25000
Epoch 26: Val Loss 3762048.00000
Epoch 27: Val Loss 3755904.50000
Epoch 28: Val Loss 3746420.75000
Epoch 29: Val Loss 3805972.75000
Epoch 30: Val Loss 3747080.25000
Epoch 31: Val Loss 3741169.50000
Epoch 32: Val Loss 3724531.50000
Epoch 33: Val Loss 3752781.50000
Epoch 34: Val Loss 3770608.00000
Epoch 35: Val Loss 3707102.75000
Epoch 36: Val Loss 3706345.25000
Epoch 37: Val Loss 3761294.00000
Epoch 38: Val Loss 3703644.25000
Epoch 39: Val Loss 3703424.00000
Epoch 40: Val Loss 3710030.75000
Epoch 41: Val Loss 3749677.50000
Epoch 42: Val Loss 3753931.75000
Epoch 43: Val Loss 3734293.25000
Epoch 44: Val Loss 3722409.50000
Epoch 45: Val Loss 3712511.25000
Epoch 46: Val Loss 3733970.75000
Epoch 47: Val Loss 3716673.00000
Epoch 48: Val Loss 3737964.75000
Epoch 49: Val Loss 3718143.25000
Epoch 50: Val Loss 3707204.50000
Epoch 51: Val Loss 3706730.50000
Epoch 52: Val Loss 3738703.75000
Epoch 53: Val Loss 3727376.00000
Epoch 54: Val Loss 3722235.75000
Epoch 55: Val Loss 3751829.75000
Epoch 56: Val Loss 3768500.00000
Epoch 57: Val Loss 3719203.50000
Epoch 58: Val Loss 3755131.75000
Epoch 59: Val Loss 3742469.25000
Epoch 60: Val Loss 3731133.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3592159.336918616, 'MSE - std': 193125.90822906038, 'R2 - mean': 0.5783167741650295, 'R2 - std': 0.013050603707750642} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4150716.75000
Epoch 1: Val Loss 3731457.00000
Epoch 2: Val Loss 3622360.25000
Epoch 3: Val Loss 3563464.25000
Epoch 4: Val Loss 3537363.25000
Epoch 5: Val Loss 3514273.00000
Epoch 6: Val Loss 3491748.50000
Epoch 7: Val Loss 3474079.00000
Epoch 8: Val Loss 3449283.50000
Epoch 9: Val Loss 3481335.75000
Epoch 10: Val Loss 3450422.25000
Epoch 11: Val Loss 3426133.50000
Epoch 12: Val Loss 3409024.50000
Epoch 13: Val Loss 3422993.50000
Epoch 14: Val Loss 3453241.00000
Epoch 15: Val Loss 3409627.25000
Epoch 16: Val Loss 3431611.25000
Epoch 17: Val Loss 3394744.25000
Epoch 18: Val Loss 3387726.50000
Epoch 19: Val Loss 3384532.50000
Epoch 20: Val Loss 3410967.00000
Epoch 21: Val Loss 3377940.75000
Epoch 22: Val Loss 3449967.25000
Epoch 23: Val Loss 3393867.25000
Epoch 24: Val Loss 3416375.75000
Epoch 25: Val Loss 3422672.75000
Epoch 26: Val Loss 3399383.00000
Epoch 27: Val Loss 3390272.00000
Epoch 28: Val Loss 3404715.00000
Epoch 29: Val Loss 3376550.75000
Epoch 30: Val Loss 3393657.50000
Epoch 31: Val Loss 3428553.00000
Epoch 32: Val Loss 3453424.00000
Epoch 33: Val Loss 3382518.00000
Epoch 34: Val Loss 3368436.50000
Epoch 35: Val Loss 3413662.25000
Epoch 36: Val Loss 3442584.00000
Epoch 37: Val Loss 3419412.50000
Epoch 38: Val Loss 3456754.00000
Epoch 39: Val Loss 3387284.00000
Epoch 40: Val Loss 3404510.50000
Epoch 41: Val Loss 3411411.75000
Epoch 42: Val Loss 3426838.25000
Epoch 43: Val Loss 3423457.25000
Epoch 44: Val Loss 3374202.25000
Epoch 45: Val Loss 3385104.00000
Epoch 46: Val Loss 3444781.50000
Epoch 47: Val Loss 3385739.75000
Epoch 48: Val Loss 3382367.25000
Epoch 49: Val Loss 3455143.00000
Epoch 50: Val Loss 3384650.00000
Epoch 51: Val Loss 3375031.75000
Epoch 52: Val Loss 3382994.25000
Epoch 53: Val Loss 3412932.50000
Epoch 54: Val Loss 3424412.25000
Epoch 55: Val Loss 3465770.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3548593.5110861138, 'MSE - std': 193468.38983490618, 'R2 - mean': 0.5793220332115748, 'R2 - std': 0.011844694538570809} 
 

Saving model.....
Results After CV: {'MSE - mean': 3548593.5110861138, 'MSE - std': 193468.38983490618, 'R2 - mean': 0.5793220332115748, 'R2 - std': 0.011844694538570809}
Train time: 5345.111398646189
Inference time: 6.841889482387342
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 32 finished with value: 3548593.5110861138 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 32 with value: 3548593.5110861138.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4482892.00000
Epoch 1: Val Loss 4072459.00000
Epoch 2: Val Loss 3963504.50000
Epoch 3: Val Loss 3911637.75000
Epoch 4: Val Loss 3837537.00000
Epoch 5: Val Loss 3802790.50000
Epoch 6: Val Loss 3764949.25000
Epoch 7: Val Loss 3728063.75000
Epoch 8: Val Loss 3705823.25000
Epoch 9: Val Loss 3681783.00000
Epoch 10: Val Loss 3671751.00000
Epoch 11: Val Loss 3639736.75000
Epoch 12: Val Loss 3642234.50000
Epoch 13: Val Loss 3614082.75000
Epoch 14: Val Loss 3613267.50000
Epoch 15: Val Loss 3612241.50000
Epoch 16: Val Loss 3593029.75000
Epoch 17: Val Loss 3577167.75000
Epoch 18: Val Loss 3575655.50000
Epoch 19: Val Loss 3558976.25000
Epoch 20: Val Loss 3547173.50000
Epoch 21: Val Loss 3583596.50000
Epoch 22: Val Loss 3526207.50000
Epoch 23: Val Loss 3531700.75000
Epoch 24: Val Loss 3508165.00000
Epoch 25: Val Loss 3516896.50000
Epoch 26: Val Loss 3499151.00000
Epoch 27: Val Loss 3504566.25000
Epoch 28: Val Loss 3489909.25000
Epoch 29: Val Loss 3511874.00000
Epoch 30: Val Loss 3484153.25000
Epoch 31: Val Loss 3491445.25000
Epoch 32: Val Loss 3477054.00000
Epoch 33: Val Loss 3465241.00000
Epoch 34: Val Loss 3538020.00000
Epoch 35: Val Loss 3469277.25000
Epoch 36: Val Loss 3458106.00000
Epoch 37: Val Loss 3477509.25000
Epoch 38: Val Loss 3453098.75000
Epoch 39: Val Loss 3456007.25000
Epoch 40: Val Loss 3439468.25000
Epoch 41: Val Loss 3440718.25000
Epoch 42: Val Loss 3435016.00000
Epoch 43: Val Loss 3464429.25000
Epoch 44: Val Loss 3455776.50000
Epoch 45: Val Loss 3480063.75000
Epoch 46: Val Loss 3448520.25000
Epoch 47: Val Loss 3424835.00000
Epoch 48: Val Loss 3433588.75000
Epoch 49: Val Loss 3442693.00000
Epoch 50: Val Loss 3430208.25000
Epoch 51: Val Loss 3431783.75000
Epoch 52: Val Loss 3469590.25000
Epoch 53: Val Loss 3440541.25000
Epoch 54: Val Loss 3432394.00000
Epoch 55: Val Loss 3444587.25000
Epoch 56: Val Loss 3427094.25000
Epoch 57: Val Loss 3406440.25000
Epoch 58: Val Loss 3430436.50000
Epoch 59: Val Loss 3438567.75000
Epoch 60: Val Loss 3434527.25000
Epoch 61: Val Loss 3427806.50000
Epoch 62: Val Loss 3414816.25000
Epoch 63: Val Loss 3431593.75000
Epoch 64: Val Loss 3420663.50000
Epoch 65: Val Loss 3437773.75000
Epoch 66: Val Loss 3452853.25000
Epoch 67: Val Loss 3416055.25000
Epoch 68: Val Loss 3479400.75000
Epoch 69: Val Loss 3454756.50000
Epoch 70: Val Loss 3462813.25000
Epoch 71: Val Loss 3535239.75000
Epoch 72: Val Loss 3471390.00000
Epoch 73: Val Loss 3463967.25000
Epoch 74: Val Loss 3480766.25000
Epoch 75: Val Loss 3479379.75000
Epoch 76: Val Loss 3540306.75000
Epoch 77: Val Loss 3522566.50000
Epoch 78: Val Loss 3537214.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3419995.819420833, 'MSE - std': 0.0, 'R2 - mean': 0.5992941512746238, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4199315.00000
Epoch 1: Val Loss 3862230.50000
Epoch 2: Val Loss 3779834.00000
Epoch 3: Val Loss 3780101.25000
Epoch 4: Val Loss 3694006.50000
Epoch 5: Val Loss 3669356.25000
Epoch 6: Val Loss 3641137.75000
Epoch 7: Val Loss 3629297.75000
Epoch 8: Val Loss 3611697.00000
Epoch 9: Val Loss 3597861.75000
Epoch 10: Val Loss 3588374.00000
Epoch 11: Val Loss 3556254.75000
Epoch 12: Val Loss 3554743.00000
Epoch 13: Val Loss 3526443.00000
Epoch 14: Val Loss 3532926.25000
Epoch 15: Val Loss 3528308.00000
Epoch 16: Val Loss 3521711.50000
Epoch 17: Val Loss 3488460.75000
Epoch 18: Val Loss 3482803.00000
Epoch 19: Val Loss 3481256.25000
Epoch 20: Val Loss 3502894.25000
Epoch 21: Val Loss 3536613.25000
Epoch 22: Val Loss 3473308.75000
Epoch 23: Val Loss 3454404.25000
Epoch 24: Val Loss 3495442.25000
Epoch 25: Val Loss 3441452.25000
Epoch 26: Val Loss 3426332.50000
Epoch 27: Val Loss 3430442.50000
Epoch 28: Val Loss 3450387.25000
Epoch 29: Val Loss 3442406.25000
Epoch 30: Val Loss 3427000.50000
Epoch 31: Val Loss 3428533.25000
Epoch 32: Val Loss 3430933.75000
Epoch 33: Val Loss 3428763.50000
Epoch 34: Val Loss 3487650.75000
Epoch 35: Val Loss 3411779.75000
Epoch 36: Val Loss 3461431.50000
Epoch 37: Val Loss 3433651.75000
Epoch 38: Val Loss 3419828.00000
Epoch 39: Val Loss 3425398.25000
Epoch 40: Val Loss 3442296.75000
Epoch 41: Val Loss 3435189.00000
Epoch 42: Val Loss 3479389.25000
Epoch 43: Val Loss 3420455.75000
Epoch 44: Val Loss 3412499.00000
Epoch 45: Val Loss 3413875.50000
Epoch 46: Val Loss 3390403.25000
Epoch 47: Val Loss 3396932.50000
Epoch 48: Val Loss 3459658.00000
Epoch 49: Val Loss 3404779.00000
Epoch 50: Val Loss 3410300.75000
Epoch 51: Val Loss 3451046.25000
Epoch 52: Val Loss 3446561.00000
Epoch 53: Val Loss 3476652.50000
Epoch 54: Val Loss 3423619.00000
Epoch 55: Val Loss 3449138.50000
Epoch 56: Val Loss 3394142.25000
Epoch 57: Val Loss 3410476.00000
Epoch 58: Val Loss 3449569.75000
Epoch 59: Val Loss 3403428.50000
Epoch 60: Val Loss 3424421.00000
Epoch 61: Val Loss 3422631.00000
Epoch 62: Val Loss 3475894.00000
Epoch 63: Val Loss 3462109.25000
Epoch 64: Val Loss 3406560.75000
Epoch 65: Val Loss 3409122.50000
Epoch 66: Val Loss 3416676.50000
Epoch 67: Val Loss 3447785.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407666.3795759324, 'MSE - std': 12329.439844900975, 'R2 - mean': 0.5876480153844004, 'R2 - std': 0.011646135890223397} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4953922.50000
Epoch 1: Val Loss 4558389.00000
Epoch 2: Val Loss 4459881.00000
Epoch 3: Val Loss 4370329.00000
Epoch 4: Val Loss 4337804.50000
Epoch 5: Val Loss 4367617.00000
Epoch 6: Val Loss 4250070.50000
Epoch 7: Val Loss 4262248.50000
Epoch 8: Val Loss 4178956.75000
Epoch 9: Val Loss 4205609.00000
Epoch 10: Val Loss 4154866.75000
Epoch 11: Val Loss 4153552.50000
Epoch 12: Val Loss 4109831.50000
Epoch 13: Val Loss 4139479.50000
Epoch 14: Val Loss 4103213.00000
Epoch 15: Val Loss 4159592.75000
Epoch 16: Val Loss 4073052.75000
Epoch 17: Val Loss 4046769.75000
Epoch 18: Val Loss 4068461.50000
Epoch 19: Val Loss 4037903.75000
Epoch 20: Val Loss 4045954.25000
Epoch 21: Val Loss 4004148.00000
Epoch 22: Val Loss 4005641.25000
Epoch 23: Val Loss 4019415.50000
Epoch 24: Val Loss 4004580.50000
Epoch 25: Val Loss 3980004.75000
Epoch 26: Val Loss 3999237.25000
Epoch 27: Val Loss 4000193.00000
Epoch 28: Val Loss 3976435.50000
Epoch 29: Val Loss 3971635.50000
Epoch 30: Val Loss 3961412.50000
Epoch 31: Val Loss 3966473.25000
Epoch 32: Val Loss 3944472.75000
Epoch 33: Val Loss 4041942.50000
Epoch 34: Val Loss 3934525.50000
Epoch 35: Val Loss 3927484.75000
Epoch 36: Val Loss 3923710.75000
Epoch 37: Val Loss 3956712.00000
Epoch 38: Val Loss 3914788.50000
Epoch 39: Val Loss 3907908.00000
Epoch 40: Val Loss 3903567.25000
Epoch 41: Val Loss 3896325.75000
Epoch 42: Val Loss 3893682.75000
Epoch 43: Val Loss 3901240.00000
Epoch 44: Val Loss 3898855.00000
Epoch 45: Val Loss 3889807.25000
Epoch 46: Val Loss 3879664.50000
Epoch 47: Val Loss 4321441.50000
Epoch 48: Val Loss 3867835.25000
Epoch 49: Val Loss 3874743.50000
Epoch 50: Val Loss 3871625.25000
Epoch 51: Val Loss 3857204.75000
Epoch 52: Val Loss 3860836.50000
Epoch 53: Val Loss 3875507.00000
Epoch 54: Val Loss 3861982.00000
Epoch 55: Val Loss 3857872.50000
Epoch 56: Val Loss 3889293.00000
Epoch 57: Val Loss 3874331.25000
Epoch 58: Val Loss 3841268.00000
Epoch 59: Val Loss 3863663.25000
Epoch 60: Val Loss 3864620.25000
Epoch 61: Val Loss 3861515.25000
Epoch 62: Val Loss 3850452.50000
Epoch 63: Val Loss 3875067.00000
Epoch 64: Val Loss 3843652.00000
Epoch 65: Val Loss 3851296.00000
Epoch 66: Val Loss 3856721.75000
Epoch 67: Val Loss 3840894.75000
Epoch 68: Val Loss 3885284.50000
Epoch 69: Val Loss 3846870.25000
Epoch 70: Val Loss 3847052.75000
Epoch 71: Val Loss 3888719.75000
Epoch 72: Val Loss 3855220.00000
Epoch 73: Val Loss 3841873.50000
Epoch 74: Val Loss 3855786.00000
Epoch 75: Val Loss 3889624.00000
Epoch 76: Val Loss 3842682.00000
Epoch 77: Val Loss 3866596.00000
Epoch 78: Val Loss 3892379.00000
Epoch 79: Val Loss 3847516.25000
Epoch 80: Val Loss 3889909.75000
Epoch 81: Val Loss 3866340.75000
Epoch 82: Val Loss 3874379.25000
Epoch 83: Val Loss 3880634.00000
Epoch 84: Val Loss 3879800.75000
Epoch 85: Val Loss 3892273.75000
Epoch 86: Val Loss 3879351.50000
Epoch 87: Val Loss 3904322.75000
Epoch 88: Val Loss 3883578.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3557656.8336177156, 'MSE - std': 212357.28383688716, 'R2 - mean': 0.5812499639006437, 'R2 - std': 0.013125996331452451} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4605650.50000
Epoch 1: Val Loss 4229007.00000
Epoch 2: Val Loss 4118571.75000
Epoch 3: Val Loss 4095263.25000
Epoch 4: Val Loss 4021886.00000
Epoch 5: Val Loss 3998275.00000
Epoch 6: Val Loss 3977727.75000
Epoch 7: Val Loss 3961214.25000
Epoch 8: Val Loss 3935344.00000
Epoch 9: Val Loss 3912014.75000
Epoch 10: Val Loss 3890957.00000
Epoch 11: Val Loss 3879790.00000
Epoch 12: Val Loss 3844141.50000
Epoch 13: Val Loss 3834369.50000
Epoch 14: Val Loss 3830479.75000
Epoch 15: Val Loss 3829652.75000
Epoch 16: Val Loss 3856802.75000
Epoch 17: Val Loss 3790126.00000
Epoch 18: Val Loss 3789642.00000
Epoch 19: Val Loss 3784974.75000
Epoch 20: Val Loss 3778274.25000
Epoch 21: Val Loss 3763895.50000
Epoch 22: Val Loss 3806132.75000
Epoch 23: Val Loss 3747579.00000
Epoch 24: Val Loss 3751510.50000
Epoch 25: Val Loss 3741886.00000
Epoch 26: Val Loss 3853953.75000
Epoch 27: Val Loss 3744666.00000
Epoch 28: Val Loss 3723584.00000
Epoch 29: Val Loss 3727214.25000
Epoch 30: Val Loss 3818772.75000
Epoch 31: Val Loss 3720178.25000
Epoch 32: Val Loss 3733915.25000
Epoch 33: Val Loss 3729885.50000
Epoch 34: Val Loss 3775697.00000
Epoch 35: Val Loss 3789620.50000
Epoch 36: Val Loss 3721580.25000
Epoch 37: Val Loss 3737824.00000
Epoch 38: Val Loss 3714314.50000
Epoch 39: Val Loss 3723874.75000
Epoch 40: Val Loss 3705331.50000
Epoch 41: Val Loss 3704333.00000
Epoch 42: Val Loss 3718617.50000
Epoch 43: Val Loss 3738212.75000
Epoch 44: Val Loss 3722465.00000
Epoch 45: Val Loss 3699444.50000
Epoch 46: Val Loss 3713865.25000
Epoch 47: Val Loss 3746466.75000
Epoch 48: Val Loss 3703881.25000
Epoch 49: Val Loss 3728821.75000
Epoch 50: Val Loss 3747888.50000
Epoch 51: Val Loss 3713643.75000
Epoch 52: Val Loss 3721839.25000
Epoch 53: Val Loss 3699942.25000
Epoch 54: Val Loss 3713176.25000
Epoch 55: Val Loss 3744472.25000
Epoch 56: Val Loss 3713945.25000
Epoch 57: Val Loss 3743266.75000
Epoch 58: Val Loss 3786187.25000
Epoch 59: Val Loss 3785126.50000
Epoch 60: Val Loss 3751460.00000
Epoch 61: Val Loss 3806422.25000
Epoch 62: Val Loss 3723865.50000
Epoch 63: Val Loss 3821127.50000
Epoch 64: Val Loss 3763729.50000
Epoch 65: Val Loss 3766013.50000
Epoch 66: Val Loss 3789267.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595391.159322001, 'MSE - std': 195175.17774554848, 'R2 - mean': 0.577959559631586, 'R2 - std': 0.012716096709740663} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4100821.75000
Epoch 1: Val Loss 3713569.75000
Epoch 2: Val Loss 3632648.75000
Epoch 3: Val Loss 3576053.25000
Epoch 4: Val Loss 3549542.00000
Epoch 5: Val Loss 3518852.25000
Epoch 6: Val Loss 3502001.75000
Epoch 7: Val Loss 3509628.75000
Epoch 8: Val Loss 3494594.00000
Epoch 9: Val Loss 3493146.25000
Epoch 10: Val Loss 3448251.00000
Epoch 11: Val Loss 3467956.50000
Epoch 12: Val Loss 3437740.50000
Epoch 13: Val Loss 3433286.25000
Epoch 14: Val Loss 3457809.75000
Epoch 15: Val Loss 3417848.50000
Epoch 16: Val Loss 3409367.50000
Epoch 17: Val Loss 3426105.00000
Epoch 18: Val Loss 3422278.50000
Epoch 19: Val Loss 3406873.75000
Epoch 20: Val Loss 3409427.25000
Epoch 21: Val Loss 3407024.25000
Epoch 22: Val Loss 3391836.75000
Epoch 23: Val Loss 3401907.50000
Epoch 24: Val Loss 3385428.75000
Epoch 25: Val Loss 3418909.00000
Epoch 26: Val Loss 3429991.50000
Epoch 27: Val Loss 3405898.50000
Epoch 28: Val Loss 3412330.25000
Epoch 29: Val Loss 3422465.75000
Epoch 30: Val Loss 3444510.00000
Epoch 31: Val Loss 3404024.25000
Epoch 32: Val Loss 3436354.75000
Epoch 33: Val Loss 3456058.00000
Epoch 34: Val Loss 3412265.75000
Epoch 35: Val Loss 3432238.50000
Epoch 36: Val Loss 3451953.25000
Epoch 37: Val Loss 3428875.75000
Epoch 38: Val Loss 3434627.25000
Epoch 39: Val Loss 3425959.25000
Epoch 40: Val Loss 3400595.50000
Epoch 41: Val Loss 3409529.50000
Epoch 42: Val Loss 3377700.75000
Epoch 43: Val Loss 3396999.25000
Epoch 44: Val Loss 3432942.25000
Epoch 45: Val Loss 3499032.25000
Epoch 46: Val Loss 3425114.00000
Epoch 47: Val Loss 3405927.50000
Epoch 48: Val Loss 3412486.75000
Epoch 49: Val Loss 3395497.50000
Epoch 50: Val Loss 3392478.50000
Epoch 51: Val Loss 3430365.75000
Epoch 52: Val Loss 3404659.25000
Epoch 53: Val Loss 3406973.00000
Epoch 54: Val Loss 3419534.25000
Epoch 55: Val Loss 3441019.25000
Epoch 56: Val Loss 3430100.50000
Epoch 57: Val Loss 3404484.00000
Epoch 58: Val Loss 3427192.25000
Epoch 59: Val Loss 3420168.50000
Epoch 60: Val Loss 3467160.50000
Epoch 61: Val Loss 3462574.25000
Epoch 62: Val Loss 3397820.50000
Epoch 63: Val Loss 3449314.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554398.271515871, 'MSE - std': 192863.54608673218, 'R2 - mean': 0.5786387472282867, 'R2 - std': 0.01145445221698665} 
 

Saving model.....
Results After CV: {'MSE - mean': 3554398.271515871, 'MSE - std': 192863.54608673218, 'R2 - mean': 0.5786387472282867, 'R2 - std': 0.01145445221698665}
Train time: 5681.847610756592
Inference time: 6.835236111399718
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 33 finished with value: 3554398.271515871 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 32 with value: 3548593.5110861138.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4458480.00000
Epoch 1: Val Loss 4069370.00000
Epoch 2: Val Loss 3950388.50000
Epoch 3: Val Loss 3885535.25000
Epoch 4: Val Loss 3857917.00000
Epoch 5: Val Loss 3780410.50000
Epoch 6: Val Loss 3773286.50000
Epoch 7: Val Loss 3740423.50000
Epoch 8: Val Loss 3693135.75000
Epoch 9: Val Loss 3667407.75000
Epoch 10: Val Loss 3705765.25000
Epoch 11: Val Loss 3634378.50000
Epoch 12: Val Loss 3633532.25000
Epoch 13: Val Loss 3602345.50000
Epoch 14: Val Loss 3603767.00000
Epoch 15: Val Loss 3587988.75000
Epoch 16: Val Loss 3574703.00000
Epoch 17: Val Loss 3583149.00000
Epoch 18: Val Loss 3561878.75000
Epoch 19: Val Loss 3563012.50000
Epoch 20: Val Loss 3530162.75000
Epoch 21: Val Loss 3548111.50000
Epoch 22: Val Loss 3539174.00000
Epoch 23: Val Loss 3520444.25000
Epoch 24: Val Loss 3515018.50000
Epoch 25: Val Loss 3494116.50000
Epoch 26: Val Loss 3510209.50000
Epoch 27: Val Loss 3485470.75000
Epoch 28: Val Loss 3501548.75000
Epoch 29: Val Loss 3528608.25000
Epoch 30: Val Loss 3504088.50000
Epoch 31: Val Loss 3473216.50000
Epoch 32: Val Loss 3465153.00000
Epoch 33: Val Loss 3477399.75000
Epoch 34: Val Loss 3473356.75000
Epoch 35: Val Loss 3451416.00000
Epoch 36: Val Loss 3458039.00000
Epoch 37: Val Loss 3482490.00000
Epoch 38: Val Loss 3465536.50000
Epoch 39: Val Loss 3446000.25000
Epoch 40: Val Loss 3451336.50000
Epoch 41: Val Loss 3457125.25000
Epoch 42: Val Loss 3429853.00000
Epoch 43: Val Loss 3430182.75000
Epoch 44: Val Loss 3439545.50000
Epoch 45: Val Loss 3439901.25000
Epoch 46: Val Loss 3759104.00000
Epoch 47: Val Loss 3432106.25000
Epoch 48: Val Loss 3448245.25000
Epoch 49: Val Loss 3428512.25000
Epoch 50: Val Loss 3462331.25000
Epoch 51: Val Loss 3427084.25000
Epoch 52: Val Loss 3431074.75000
Epoch 53: Val Loss 3423173.00000
Epoch 54: Val Loss 3519164.00000
Epoch 55: Val Loss 3415656.00000
Epoch 56: Val Loss 3420627.25000
Epoch 57: Val Loss 3399823.50000
Epoch 58: Val Loss 3464084.50000
Epoch 59: Val Loss 3445728.75000
Epoch 60: Val Loss 3483782.50000
Epoch 61: Val Loss 3430534.75000
Epoch 62: Val Loss 3411561.25000
Epoch 63: Val Loss 3437417.50000
Epoch 64: Val Loss 3420786.00000
Epoch 65: Val Loss 3431601.00000
Epoch 66: Val Loss 3447098.50000
Epoch 67: Val Loss 3454031.25000
Epoch 68: Val Loss 3430559.25000
Epoch 69: Val Loss 3424537.75000
Epoch 70: Val Loss 3434327.25000
Epoch 71: Val Loss 3498101.25000
Epoch 72: Val Loss 3507621.75000
Epoch 73: Val Loss 3438620.75000
Epoch 74: Val Loss 3475310.50000
Epoch 75: Val Loss 3597252.50000
Epoch 76: Val Loss 3522601.50000
Epoch 77: Val Loss 3566424.25000
Epoch 78: Val Loss 3507312.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3413539.3805506933, 'MSE - std': 0.0, 'R2 - mean': 0.6000506237833069, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4245806.50000
Epoch 1: Val Loss 3878439.50000
Epoch 2: Val Loss 3783830.50000
Epoch 3: Val Loss 3735163.25000
Epoch 4: Val Loss 3707854.25000
Epoch 5: Val Loss 3763537.50000
Epoch 6: Val Loss 3653566.00000
Epoch 7: Val Loss 3647918.00000
Epoch 8: Val Loss 3655845.25000
Epoch 9: Val Loss 3676386.25000
Epoch 10: Val Loss 3563299.00000
Epoch 11: Val Loss 3554650.50000
Epoch 12: Val Loss 3552201.50000
Epoch 13: Val Loss 3519462.25000
Epoch 14: Val Loss 3531819.00000
Epoch 15: Val Loss 3504449.25000
Epoch 16: Val Loss 3505830.50000
Epoch 17: Val Loss 3491241.25000
Epoch 18: Val Loss 3483543.75000
Epoch 19: Val Loss 3485456.75000
Epoch 20: Val Loss 3470994.50000
Epoch 21: Val Loss 3462064.00000
Epoch 22: Val Loss 3458521.00000
Epoch 23: Val Loss 3460506.25000
Epoch 24: Val Loss 3476639.00000
Epoch 25: Val Loss 3452320.00000
Epoch 26: Val Loss 3460989.00000
Epoch 27: Val Loss 3437589.75000
Epoch 28: Val Loss 3424454.25000
Epoch 29: Val Loss 3424520.25000
Epoch 30: Val Loss 3429783.25000
Epoch 31: Val Loss 3547599.25000
Epoch 32: Val Loss 3472625.50000
Epoch 33: Val Loss 3432149.75000
Epoch 34: Val Loss 3406385.50000
Epoch 35: Val Loss 3407787.00000
Epoch 36: Val Loss 3440737.50000
Epoch 37: Val Loss 3402868.50000
Epoch 38: Val Loss 3390024.50000
Epoch 39: Val Loss 3400674.75000
Epoch 40: Val Loss 3384205.00000
Epoch 41: Val Loss 3436367.25000
Epoch 42: Val Loss 3403289.25000
Epoch 43: Val Loss 3392050.25000
Epoch 44: Val Loss 3385870.25000
Epoch 45: Val Loss 3420350.25000
Epoch 46: Val Loss 3401138.25000
Epoch 47: Val Loss 3407359.00000
Epoch 48: Val Loss 3479936.50000
Epoch 49: Val Loss 3398624.75000
Epoch 50: Val Loss 3406950.50000
Epoch 51: Val Loss 3423468.25000
Epoch 52: Val Loss 3411083.50000
Epoch 53: Val Loss 3424177.50000
Epoch 54: Val Loss 3398161.75000
Epoch 55: Val Loss 3390135.25000
Epoch 56: Val Loss 3403699.50000
Epoch 57: Val Loss 3389247.75000
Epoch 58: Val Loss 3392906.75000
Epoch 59: Val Loss 3406446.50000
Epoch 60: Val Loss 3408251.00000
Epoch 61: Val Loss 3471835.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3404510.3637352744, 'MSE - std': 9029.016815418843, 'R2 - mean': 0.5880172350996273, 'R2 - std': 0.012033388683679591} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4978038.00000
Epoch 1: Val Loss 4572319.00000
Epoch 2: Val Loss 4431628.00000
Epoch 3: Val Loss 4386450.50000
Epoch 4: Val Loss 4339100.00000
Epoch 5: Val Loss 4300884.00000
Epoch 6: Val Loss 4287070.00000
Epoch 7: Val Loss 4238542.50000
Epoch 8: Val Loss 4211736.50000
Epoch 9: Val Loss 4231727.50000
Epoch 10: Val Loss 4166487.00000
Epoch 11: Val Loss 4170665.25000
Epoch 12: Val Loss 4200192.50000
Epoch 13: Val Loss 4128254.00000
Epoch 14: Val Loss 4097758.25000
Epoch 15: Val Loss 4100897.75000
Epoch 16: Val Loss 4123797.75000
Epoch 17: Val Loss 4085288.75000
Epoch 18: Val Loss 4062323.25000
Epoch 19: Val Loss 4049000.00000
Epoch 20: Val Loss 4052619.75000
Epoch 21: Val Loss 4049916.25000
Epoch 22: Val Loss 4023585.75000
Epoch 23: Val Loss 4028516.00000
Epoch 24: Val Loss 4014973.50000
Epoch 25: Val Loss 4040493.50000
Epoch 26: Val Loss 3998498.75000
Epoch 27: Val Loss 3993479.00000
Epoch 28: Val Loss 3987147.25000
Epoch 29: Val Loss 3970227.00000
Epoch 30: Val Loss 3972600.25000
Epoch 31: Val Loss 3951709.00000
Epoch 32: Val Loss 3948566.50000
Epoch 33: Val Loss 3962136.25000
Epoch 34: Val Loss 3943575.00000
Epoch 35: Val Loss 3932855.00000
Epoch 36: Val Loss 3944333.50000
Epoch 37: Val Loss 3952836.00000
Epoch 38: Val Loss 3961589.25000
Epoch 39: Val Loss 3924944.50000
Epoch 40: Val Loss 3918065.75000
Epoch 41: Val Loss 3919198.25000
Epoch 42: Val Loss 3907102.00000
Epoch 43: Val Loss 3983726.75000
Epoch 44: Val Loss 3906410.50000
Epoch 45: Val Loss 3886559.25000
Epoch 46: Val Loss 3890945.75000
Epoch 47: Val Loss 3900785.00000
Epoch 48: Val Loss 3902304.00000
Epoch 49: Val Loss 3937195.75000
Epoch 50: Val Loss 3893553.50000
Epoch 51: Val Loss 3883968.00000
Epoch 52: Val Loss 3878195.00000
Epoch 53: Val Loss 3851298.25000
Epoch 54: Val Loss 3858188.75000
Epoch 55: Val Loss 3903701.75000
Epoch 56: Val Loss 3863040.00000
Epoch 57: Val Loss 3851241.25000
Epoch 58: Val Loss 3877572.00000
Epoch 59: Val Loss 3861517.50000
Epoch 60: Val Loss 3857697.50000
Epoch 61: Val Loss 3860012.75000
Epoch 62: Val Loss 3859294.25000
Epoch 63: Val Loss 3847071.75000
Epoch 64: Val Loss 3869743.75000
Epoch 65: Val Loss 3847248.50000
Epoch 66: Val Loss 3842289.75000
Epoch 67: Val Loss 3865222.25000
Epoch 68: Val Loss 3872175.25000
Epoch 69: Val Loss 4014726.50000
Epoch 70: Val Loss 3855788.75000
Epoch 71: Val Loss 3884875.25000
Epoch 72: Val Loss 3894625.75000
Epoch 73: Val Loss 3887838.00000
Epoch 74: Val Loss 3908185.25000
Epoch 75: Val Loss 3850475.25000
Epoch 76: Val Loss 3861755.75000
Epoch 77: Val Loss 3877851.25000
Epoch 78: Val Loss 3884532.00000
Epoch 79: Val Loss 3880312.75000
Epoch 80: Val Loss 3899999.25000
Epoch 81: Val Loss 3893983.25000
Epoch 82: Val Loss 3881873.00000
Epoch 83: Val Loss 3913151.25000
Epoch 84: Val Loss 3883416.75000
Epoch 85: Val Loss 3961457.00000
Epoch 86: Val Loss 3899127.50000
Epoch 87: Val Loss 3892643.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553655.599118328, 'MSE - std': 211052.0107415118, 'R2 - mean': 0.5817083489858068, 'R2 - std': 0.013271738775909713} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4578105.50000
Epoch 1: Val Loss 4206389.50000
Epoch 2: Val Loss 4137296.00000
Epoch 3: Val Loss 4067592.75000
Epoch 4: Val Loss 4030291.00000
Epoch 5: Val Loss 3998937.25000
Epoch 6: Val Loss 3975292.75000
Epoch 7: Val Loss 3972394.50000
Epoch 8: Val Loss 3931602.75000
Epoch 9: Val Loss 3927713.00000
Epoch 10: Val Loss 3917516.25000
Epoch 11: Val Loss 3874342.50000
Epoch 12: Val Loss 3874981.25000
Epoch 13: Val Loss 3856109.50000
Epoch 14: Val Loss 3839969.00000
Epoch 15: Val Loss 3835082.50000
Epoch 16: Val Loss 3839688.00000
Epoch 17: Val Loss 3808113.75000
Epoch 18: Val Loss 3817922.25000
Epoch 19: Val Loss 3818890.50000
Epoch 20: Val Loss 3792177.00000
Epoch 21: Val Loss 3831765.25000
Epoch 22: Val Loss 3786006.25000
Epoch 23: Val Loss 3826532.00000
Epoch 24: Val Loss 3767458.75000
Epoch 25: Val Loss 3755820.25000
Epoch 26: Val Loss 3755246.25000
Epoch 27: Val Loss 3770768.00000
Epoch 28: Val Loss 3751502.75000
Epoch 29: Val Loss 3739025.75000
Epoch 30: Val Loss 3738648.25000
Epoch 31: Val Loss 3782089.25000
Epoch 32: Val Loss 3741386.50000
Epoch 33: Val Loss 3757121.75000
Epoch 34: Val Loss 3733695.25000
Epoch 35: Val Loss 3736376.75000
Epoch 36: Val Loss 3732446.75000
Epoch 37: Val Loss 3717889.50000
Epoch 38: Val Loss 3738196.50000
Epoch 39: Val Loss 3712057.25000
Epoch 40: Val Loss 3714732.75000
Epoch 41: Val Loss 3714942.00000
Epoch 42: Val Loss 3755607.75000
Epoch 43: Val Loss 3729537.50000
Epoch 44: Val Loss 3711896.25000
Epoch 45: Val Loss 3724130.75000
Epoch 46: Val Loss 3723073.00000
Epoch 47: Val Loss 3724440.75000
Epoch 48: Val Loss 3777380.75000
Epoch 49: Val Loss 3713227.00000
Epoch 50: Val Loss 3696226.25000
Epoch 51: Val Loss 3707206.50000
Epoch 52: Val Loss 3711721.50000
Epoch 53: Val Loss 3745413.25000
Epoch 54: Val Loss 3731348.75000
Epoch 55: Val Loss 3730855.75000
Epoch 56: Val Loss 3734890.50000
Epoch 57: Val Loss 3734235.00000
Epoch 58: Val Loss 3738733.50000
Epoch 59: Val Loss 3816387.50000
Epoch 60: Val Loss 3787985.75000
Epoch 61: Val Loss 3732584.25000
Epoch 62: Val Loss 3876680.25000
Epoch 63: Val Loss 3744378.00000
Epoch 64: Val Loss 3786846.75000
Epoch 65: Val Loss 3784234.50000
Epoch 66: Val Loss 3767377.75000
Epoch 67: Val Loss 3753381.25000
Epoch 68: Val Loss 3898333.50000
Epoch 69: Val Loss 3788944.00000
Epoch 70: Val Loss 3770827.00000
Epoch 71: Val Loss 3756497.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3592057.6267042104, 'MSE - std': 194502.85498328024, 'R2 - mean': 0.5783420846142191, 'R2 - std': 0.012887959305501023} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4145510.25000
Epoch 1: Val Loss 3715519.75000
Epoch 2: Val Loss 3632584.75000
Epoch 3: Val Loss 3581886.25000
Epoch 4: Val Loss 3603384.25000
Epoch 5: Val Loss 3530905.00000
Epoch 6: Val Loss 3536119.75000
Epoch 7: Val Loss 3487677.00000
Epoch 8: Val Loss 3465294.75000
Epoch 9: Val Loss 3452157.00000
Epoch 10: Val Loss 3444645.00000
Epoch 11: Val Loss 3452086.50000
Epoch 12: Val Loss 3441314.00000
Epoch 13: Val Loss 3426785.00000
Epoch 14: Val Loss 3454858.50000
Epoch 15: Val Loss 3416417.50000
Epoch 16: Val Loss 3419298.75000
Epoch 17: Val Loss 3428846.25000
Epoch 18: Val Loss 3482234.50000
Epoch 19: Val Loss 3388748.75000
Epoch 20: Val Loss 3400461.25000
Epoch 21: Val Loss 3454420.50000
Epoch 22: Val Loss 3452926.25000
Epoch 23: Val Loss 3431596.00000
Epoch 24: Val Loss 3392596.50000
Epoch 25: Val Loss 3388335.75000
Epoch 26: Val Loss 3419337.00000
Epoch 27: Val Loss 3397301.50000
Epoch 28: Val Loss 3410596.50000
Epoch 29: Val Loss 3412909.25000
Epoch 30: Val Loss 3389510.00000
Epoch 31: Val Loss 3409788.50000
Epoch 32: Val Loss 3412287.00000
Epoch 33: Val Loss 3395557.25000
Epoch 34: Val Loss 3390610.00000
Epoch 35: Val Loss 3375517.00000
Epoch 36: Val Loss 3375774.25000
Epoch 37: Val Loss 3431251.25000
Epoch 38: Val Loss 3433495.50000
Epoch 39: Val Loss 3392615.00000
Epoch 40: Val Loss 3363473.25000
Epoch 41: Val Loss 3399123.75000
Epoch 42: Val Loss 3384525.50000
Epoch 43: Val Loss 3414069.50000
Epoch 44: Val Loss 3422144.75000
Epoch 45: Val Loss 3444579.25000
Epoch 46: Val Loss 3445863.50000
Epoch 47: Val Loss 3510391.75000
Epoch 48: Val Loss 3452571.25000
Epoch 49: Val Loss 3413934.25000
Epoch 50: Val Loss 3423218.50000
Epoch 51: Val Loss 3407223.75000
Epoch 52: Val Loss 3387871.75000
Epoch 53: Val Loss 3404762.00000
Epoch 54: Val Loss 3443526.50000
Epoch 55: Val Loss 3444183.75000
Epoch 56: Val Loss 3428669.00000
Epoch 57: Val Loss 3470973.50000
Epoch 58: Val Loss 3443491.25000
Epoch 59: Val Loss 3421864.00000
Epoch 60: Val Loss 3475009.25000
Epoch 61: Val Loss 3410390.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3548099.6336374814, 'MSE - std': 194921.28948664368, 'R2 - mean': 0.5793932175607861, 'R2 - std': 0.011717470628665301} 
 

Saving model.....
Results After CV: {'MSE - mean': 3548099.6336374814, 'MSE - std': 194921.28948664368, 'R2 - mean': 0.5793932175607861, 'R2 - std': 0.011717470628665301}
Train time: 5456.310397676052
Inference time: 6.6817977939965205
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 34 finished with value: 3548099.6336374814 and parameters: {'dim': 256, 'depth': 1, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.5}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4529824.00000
Epoch 1: Val Loss 4101053.00000
Epoch 2: Val Loss 3971514.00000
Epoch 3: Val Loss 3922100.00000
Epoch 4: Val Loss 3844380.75000
Epoch 5: Val Loss 3819245.00000
Epoch 6: Val Loss 3796124.75000
Epoch 7: Val Loss 3744406.50000
Epoch 8: Val Loss 3740415.25000
Epoch 9: Val Loss 3696335.25000
Epoch 10: Val Loss 3698792.75000
Epoch 11: Val Loss 3667145.50000
Epoch 12: Val Loss 3656648.25000
Epoch 13: Val Loss 3630413.00000
Epoch 14: Val Loss 3633362.75000
Epoch 15: Val Loss 3599522.25000
Epoch 16: Val Loss 3618174.25000
Epoch 17: Val Loss 3608179.00000
Epoch 18: Val Loss 3565652.25000
Epoch 19: Val Loss 3552886.50000
Epoch 20: Val Loss 3554492.25000
Epoch 21: Val Loss 3544104.50000
Epoch 22: Val Loss 3542341.25000
Epoch 23: Val Loss 3527470.25000
Epoch 24: Val Loss 3531883.25000
Epoch 25: Val Loss 3509649.00000
Epoch 26: Val Loss 3490060.75000
Epoch 27: Val Loss 3518927.00000
Epoch 28: Val Loss 3503655.75000
Epoch 29: Val Loss 3490631.75000
Epoch 30: Val Loss 3477544.75000
Epoch 31: Val Loss 3479491.75000
Epoch 32: Val Loss 3499120.00000
Epoch 33: Val Loss 3479650.75000
Epoch 34: Val Loss 3456615.25000
Epoch 35: Val Loss 3457257.25000
Epoch 36: Val Loss 3466510.00000
Epoch 37: Val Loss 3457042.75000
Epoch 38: Val Loss 3450285.25000
Epoch 39: Val Loss 3434421.25000
Epoch 40: Val Loss 3447074.75000
Epoch 41: Val Loss 3491391.75000
Epoch 42: Val Loss 3476006.25000
Epoch 43: Val Loss 3446721.00000
Epoch 44: Val Loss 3459162.50000
Epoch 45: Val Loss 3442692.25000
Epoch 46: Val Loss 3429043.50000
Epoch 47: Val Loss 3481849.50000
Epoch 48: Val Loss 3442953.25000
Epoch 49: Val Loss 3425113.75000
Epoch 50: Val Loss 3440767.75000
Epoch 51: Val Loss 3444856.00000
Epoch 52: Val Loss 3411649.00000
Epoch 53: Val Loss 3460996.25000
Epoch 54: Val Loss 3484865.50000
Epoch 55: Val Loss 3428347.50000
Epoch 56: Val Loss 3423450.25000
Epoch 57: Val Loss 3427797.00000
Epoch 58: Val Loss 3442467.00000
Epoch 59: Val Loss 3438100.00000
Epoch 60: Val Loss 3428688.75000
Epoch 61: Val Loss 3436133.00000
Epoch 62: Val Loss 3427135.75000
Epoch 63: Val Loss 3447670.25000
Epoch 64: Val Loss 3438242.25000
Epoch 65: Val Loss 3420700.50000
Epoch 66: Val Loss 3466443.00000
Epoch 67: Val Loss 3447621.00000
Epoch 68: Val Loss 3451649.75000
Epoch 69: Val Loss 3440766.50000
Epoch 70: Val Loss 3514227.25000
Epoch 71: Val Loss 3487791.75000
Epoch 72: Val Loss 3463810.25000
Epoch 73: Val Loss 3512529.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3424139.5548293185, 'MSE - std': 0.0, 'R2 - mean': 0.5988086480455492, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4197360.00000
Epoch 1: Val Loss 3880723.00000
Epoch 2: Val Loss 3793998.25000
Epoch 3: Val Loss 3722424.75000
Epoch 4: Val Loss 3690650.00000
Epoch 5: Val Loss 3689350.50000
Epoch 6: Val Loss 3624405.00000
Epoch 7: Val Loss 3668698.00000
Epoch 8: Val Loss 3591197.75000
Epoch 9: Val Loss 3592432.75000
Epoch 10: Val Loss 3556158.25000
Epoch 11: Val Loss 3565416.25000
Epoch 12: Val Loss 3532647.75000
Epoch 13: Val Loss 3523583.25000
Epoch 14: Val Loss 3505440.50000
Epoch 15: Val Loss 3520429.25000
Epoch 16: Val Loss 3528130.75000
Epoch 17: Val Loss 3480738.75000
Epoch 18: Val Loss 3481079.25000
Epoch 19: Val Loss 3488253.50000
Epoch 20: Val Loss 3453702.00000
Epoch 21: Val Loss 3470015.00000
Epoch 22: Val Loss 3453857.00000
Epoch 23: Val Loss 3459450.50000
Epoch 24: Val Loss 3437736.25000
Epoch 25: Val Loss 3456986.50000
Epoch 26: Val Loss 3442943.25000
Epoch 27: Val Loss 3426733.50000
Epoch 28: Val Loss 3421044.75000
Epoch 29: Val Loss 3421669.25000
Epoch 30: Val Loss 3441489.75000
Epoch 31: Val Loss 3416336.00000
Epoch 32: Val Loss 3460012.75000
Epoch 33: Val Loss 3448938.25000
Epoch 34: Val Loss 3408986.50000
Epoch 35: Val Loss 3446646.25000
Epoch 36: Val Loss 3435417.50000
Epoch 37: Val Loss 3462245.00000
Epoch 38: Val Loss 3396749.50000
Epoch 39: Val Loss 3392727.75000
Epoch 40: Val Loss 3405812.25000
Epoch 41: Val Loss 3402423.00000
Epoch 42: Val Loss 3407817.75000
Epoch 43: Val Loss 3382922.00000
Epoch 44: Val Loss 3546814.25000
Epoch 45: Val Loss 3410397.50000
Epoch 46: Val Loss 3409254.50000
Epoch 47: Val Loss 3401869.00000
Epoch 48: Val Loss 3406714.25000
Epoch 49: Val Loss 3415907.00000
Epoch 50: Val Loss 3385573.00000
Epoch 51: Val Loss 3470621.75000
Epoch 52: Val Loss 3391825.50000
Epoch 53: Val Loss 3428939.00000
Epoch 54: Val Loss 3412237.75000
Epoch 55: Val Loss 3423472.00000
Epoch 56: Val Loss 3396345.75000
Epoch 57: Val Loss 3432159.75000
Epoch 58: Val Loss 3404010.75000
Epoch 59: Val Loss 3433402.50000
Epoch 60: Val Loss 3406152.00000
Epoch 61: Val Loss 3394746.50000
Epoch 62: Val Loss 3399999.25000
Epoch 63: Val Loss 3424825.25000
Epoch 64: Val Loss 3460074.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407883.3805767363, 'MSE - std': 16256.174252582481, 'R2 - mean': 0.5876368932104774, 'R2 - std': 0.011171754835071823} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4960574.00000
Epoch 1: Val Loss 4525399.50000
Epoch 2: Val Loss 4438012.50000
Epoch 3: Val Loss 4392383.00000
Epoch 4: Val Loss 4331178.50000
Epoch 5: Val Loss 4330608.00000
Epoch 6: Val Loss 4260735.00000
Epoch 7: Val Loss 4234041.00000
Epoch 8: Val Loss 4216908.00000
Epoch 9: Val Loss 4171160.00000
Epoch 10: Val Loss 4148855.50000
Epoch 11: Val Loss 4131966.00000
Epoch 12: Val Loss 4133283.25000
Epoch 13: Val Loss 4107574.50000
Epoch 14: Val Loss 4106507.25000
Epoch 15: Val Loss 4115505.75000
Epoch 16: Val Loss 4142686.75000
Epoch 17: Val Loss 4060647.50000
Epoch 18: Val Loss 4039966.75000
Epoch 19: Val Loss 4061521.50000
Epoch 20: Val Loss 4025242.00000
Epoch 21: Val Loss 4012596.75000
Epoch 22: Val Loss 4023844.00000
Epoch 23: Val Loss 4053677.00000
Epoch 24: Val Loss 4009257.25000
Epoch 25: Val Loss 4008807.50000
Epoch 26: Val Loss 4005652.00000
Epoch 27: Val Loss 3993441.00000
Epoch 28: Val Loss 3980110.00000
Epoch 29: Val Loss 3990190.00000
Epoch 30: Val Loss 3974868.00000
Epoch 31: Val Loss 3970731.75000
Epoch 32: Val Loss 3956712.25000
Epoch 33: Val Loss 3943259.00000
Epoch 34: Val Loss 3927110.25000
Epoch 35: Val Loss 3959157.25000
Epoch 36: Val Loss 3933608.75000
Epoch 37: Val Loss 3933227.00000
Epoch 38: Val Loss 3917112.25000
Epoch 39: Val Loss 3925597.00000
Epoch 40: Val Loss 3930988.75000
Epoch 41: Val Loss 3919837.00000
Epoch 42: Val Loss 3889359.75000
Epoch 43: Val Loss 3898935.50000
Epoch 44: Val Loss 3932277.75000
Epoch 45: Val Loss 3889843.50000
Epoch 46: Val Loss 3904089.50000
Epoch 47: Val Loss 3876224.50000
Epoch 48: Val Loss 3892833.50000
Epoch 49: Val Loss 3880898.75000
Epoch 50: Val Loss 3872508.75000
Epoch 51: Val Loss 3876523.75000
Epoch 52: Val Loss 3862300.75000
Epoch 53: Val Loss 3875719.50000
Epoch 54: Val Loss 3860591.75000
Epoch 55: Val Loss 3875672.00000
Epoch 56: Val Loss 3858544.00000
Epoch 57: Val Loss 3876151.00000
Epoch 58: Val Loss 3900264.25000
Epoch 59: Val Loss 3858769.50000
Epoch 60: Val Loss 3914656.00000
Epoch 61: Val Loss 3864037.75000
Epoch 62: Val Loss 3844414.75000
Epoch 63: Val Loss 3854510.00000
Epoch 64: Val Loss 3847010.25000
Epoch 65: Val Loss 3871500.75000
Epoch 66: Val Loss 3834954.00000
Epoch 67: Val Loss 3853910.50000
Epoch 68: Val Loss 3865320.00000
Epoch 69: Val Loss 3837869.00000
Epoch 70: Val Loss 3850273.50000
Epoch 71: Val Loss 3849243.00000
Epoch 72: Val Loss 3850292.00000
Epoch 73: Val Loss 3864792.75000
Epoch 74: Val Loss 3866973.00000
Epoch 75: Val Loss 3924444.75000
Epoch 76: Val Loss 3857216.50000
Epoch 77: Val Loss 3904182.50000
Epoch 78: Val Loss 3862991.75000
Epoch 79: Val Loss 3891033.25000
Epoch 80: Val Loss 3902814.25000
Epoch 81: Val Loss 3896629.25000
Epoch 82: Val Loss 3872608.50000
Epoch 83: Val Loss 3899540.00000
Epoch 84: Val Loss 3927109.75000
Epoch 85: Val Loss 3884758.50000
Epoch 86: Val Loss 3905816.25000
Epoch 87: Val Loss 3909636.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3555957.62119807, 'MSE - std': 209828.82771135835, 'R2 - mean': 0.5814488202201412, 'R2 - std': 0.012640802930619404} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4634906.00000
Epoch 1: Val Loss 4211759.00000
Epoch 2: Val Loss 4119412.00000
Epoch 3: Val Loss 4059742.75000
Epoch 4: Val Loss 4002887.00000
Epoch 5: Val Loss 3992294.25000
Epoch 6: Val Loss 3970323.00000
Epoch 7: Val Loss 3929386.00000
Epoch 8: Val Loss 3900627.00000
Epoch 9: Val Loss 3900133.75000
Epoch 10: Val Loss 3890611.50000
Epoch 11: Val Loss 3847705.50000
Epoch 12: Val Loss 3864948.00000
Epoch 13: Val Loss 3820516.75000
Epoch 14: Val Loss 3811182.75000
Epoch 15: Val Loss 3825517.50000
Epoch 16: Val Loss 3813269.75000
Epoch 17: Val Loss 3814459.75000
Epoch 18: Val Loss 3819600.00000
Epoch 19: Val Loss 3794734.75000
Epoch 20: Val Loss 3775862.50000
Epoch 21: Val Loss 3748454.50000
Epoch 22: Val Loss 3759342.00000
Epoch 23: Val Loss 3757658.00000
Epoch 24: Val Loss 3748280.75000
Epoch 25: Val Loss 3749378.25000
Epoch 26: Val Loss 3737781.75000
Epoch 27: Val Loss 3728340.50000
Epoch 28: Val Loss 3740428.25000
Epoch 29: Val Loss 3739132.75000
Epoch 30: Val Loss 3719176.75000
Epoch 31: Val Loss 3726643.50000
Epoch 32: Val Loss 3767233.75000
Epoch 33: Val Loss 3741819.25000
Epoch 34: Val Loss 3712346.50000
Epoch 35: Val Loss 3710134.50000
Epoch 36: Val Loss 3790975.25000
Epoch 37: Val Loss 3742482.25000
Epoch 38: Val Loss 3722477.00000
Epoch 39: Val Loss 3697225.25000
Epoch 40: Val Loss 3722367.25000
Epoch 41: Val Loss 3702057.50000
Epoch 42: Val Loss 3749930.00000
Epoch 43: Val Loss 3740802.75000
Epoch 44: Val Loss 3703670.25000
Epoch 45: Val Loss 3711271.50000
Epoch 46: Val Loss 3705071.75000
Epoch 47: Val Loss 3735253.75000
Epoch 48: Val Loss 3754866.75000
Epoch 49: Val Loss 3694624.00000
Epoch 50: Val Loss 3783937.50000
Epoch 51: Val Loss 3731732.75000
Epoch 52: Val Loss 3725790.00000
Epoch 53: Val Loss 3720544.50000
Epoch 54: Val Loss 3709626.00000
Epoch 55: Val Loss 3740276.50000
Epoch 56: Val Loss 3731445.75000
Epoch 57: Val Loss 3734140.75000
Epoch 58: Val Loss 3763048.25000
Epoch 59: Val Loss 3781383.00000
Epoch 60: Val Loss 3745390.00000
Epoch 61: Val Loss 3769258.50000
Epoch 62: Val Loss 3741527.50000
Epoch 63: Val Loss 3755084.75000
Epoch 64: Val Loss 3762900.75000
Epoch 65: Val Loss 3831589.75000
Epoch 66: Val Loss 3887350.25000
Epoch 67: Val Loss 3813951.75000
Epoch 68: Val Loss 3773087.25000
Epoch 69: Val Loss 3762718.25000
Epoch 70: Val Loss 3809576.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591080.4189796196, 'MSE - std': 191629.6831810069, 'R2 - mean': 0.5784623201711615, 'R2 - std': 0.012107847524466734} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4178113.50000
Epoch 1: Val Loss 3737245.00000
Epoch 2: Val Loss 3648299.75000
Epoch 3: Val Loss 3597226.75000
Epoch 4: Val Loss 3577003.00000
Epoch 5: Val Loss 3536386.00000
Epoch 6: Val Loss 3510582.50000
Epoch 7: Val Loss 3505658.25000
Epoch 8: Val Loss 3522952.00000
Epoch 9: Val Loss 3479279.25000
Epoch 10: Val Loss 3477068.25000
Epoch 11: Val Loss 3450965.25000
Epoch 12: Val Loss 3455141.75000
Epoch 13: Val Loss 3491006.00000
Epoch 14: Val Loss 3433250.50000
Epoch 15: Val Loss 3447881.50000
Epoch 16: Val Loss 3431488.00000
Epoch 17: Val Loss 3519607.75000
Epoch 18: Val Loss 3447631.25000
Epoch 19: Val Loss 3411386.00000
Epoch 20: Val Loss 3427093.75000
Epoch 21: Val Loss 3433193.25000
Epoch 22: Val Loss 3409426.00000
Epoch 23: Val Loss 3469091.00000
Epoch 24: Val Loss 3419741.00000
Epoch 25: Val Loss 3392071.50000
Epoch 26: Val Loss 3411811.00000
Epoch 27: Val Loss 3429192.75000
Epoch 28: Val Loss 3396874.00000
Epoch 29: Val Loss 3396672.00000
Epoch 30: Val Loss 3399677.75000
Epoch 31: Val Loss 3483527.75000
Epoch 32: Val Loss 3440497.75000
Epoch 33: Val Loss 3387538.75000
Epoch 34: Val Loss 3422994.00000
Epoch 35: Val Loss 3455043.00000
Epoch 36: Val Loss 3410310.75000
Epoch 37: Val Loss 3383785.50000
Epoch 38: Val Loss 3421387.00000
Epoch 39: Val Loss 3396415.00000
Epoch 40: Val Loss 3494047.00000
Epoch 41: Val Loss 3402216.75000
Epoch 42: Val Loss 3375268.50000
Epoch 43: Val Loss 3375817.75000
Epoch 44: Val Loss 3437543.00000
Epoch 45: Val Loss 3395574.75000
Epoch 46: Val Loss 3442371.25000
Epoch 47: Val Loss 3398915.75000
Epoch 48: Val Loss 3432592.25000
Epoch 49: Val Loss 3383586.50000
Epoch 50: Val Loss 3413891.25000
Epoch 51: Val Loss 3473748.00000
Epoch 52: Val Loss 3392199.00000
Epoch 53: Val Loss 3411163.25000
Epoch 54: Val Loss 3388976.50000
Epoch 55: Val Loss 3412801.00000
Epoch 56: Val Loss 3394762.50000
Epoch 57: Val Loss 3386076.25000
Epoch 58: Val Loss 3441164.00000
Epoch 59: Val Loss 3460237.75000
Epoch 60: Val Loss 3440394.25000
Epoch 61: Val Loss 3402615.75000
Epoch 62: Val Loss 3408587.00000
Epoch 63: Val Loss 3418406.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3550025.1686057323, 'MSE - std': 190051.78955719632, 'R2 - mean': 0.5791551127638124, 'R2 - std': 0.010917867174788104} 
 

Saving model.....
Results After CV: {'MSE - mean': 3550025.1686057323, 'MSE - std': 190051.78955719632, 'R2 - mean': 0.5791551127638124, 'R2 - std': 0.010917867174788104}
Train time: 5467.356910064421
Inference time: 6.784948674612679
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 35 finished with value: 3550025.1686057323 and parameters: {'dim': 256, 'depth': 6, 'heads': 8, 'weight_decay': -4, 'learning_rate': -4, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4502107.00000
Epoch 1: Val Loss 4078092.75000
Epoch 2: Val Loss 3949108.50000
Epoch 3: Val Loss 3895594.50000
Epoch 4: Val Loss 3845065.50000
Epoch 5: Val Loss 3810084.50000
Epoch 6: Val Loss 3780484.00000
Epoch 7: Val Loss 3767107.00000
Epoch 8: Val Loss 3721806.75000
Epoch 9: Val Loss 3718783.25000
Epoch 10: Val Loss 3685954.75000
Epoch 11: Val Loss 3779123.00000
Epoch 12: Val Loss 3666067.00000
Epoch 13: Val Loss 3638334.75000
Epoch 14: Val Loss 3623324.75000
Epoch 15: Val Loss 3623028.00000
Epoch 16: Val Loss 3594964.75000
Epoch 17: Val Loss 3642269.00000
Epoch 18: Val Loss 3570706.50000
Epoch 19: Val Loss 3747703.50000
Epoch 20: Val Loss 3571092.75000
Epoch 21: Val Loss 3550032.75000
Epoch 22: Val Loss 3543174.75000
Epoch 23: Val Loss 3762352.50000
Epoch 24: Val Loss 3543809.50000
Epoch 25: Val Loss 3528055.00000
Epoch 26: Val Loss 3574185.25000
Epoch 27: Val Loss 3541632.25000
Epoch 28: Val Loss 3513428.75000
Epoch 29: Val Loss 3498779.00000
Epoch 30: Val Loss 3487462.75000
Epoch 31: Val Loss 3495285.25000
Epoch 32: Val Loss 3473803.75000
Epoch 33: Val Loss 3473371.75000
Epoch 34: Val Loss 3473278.25000
Epoch 35: Val Loss 3488107.00000
Epoch 36: Val Loss 3454597.50000
Epoch 37: Val Loss 3478794.00000
Epoch 38: Val Loss 3477889.75000
Epoch 39: Val Loss 3449710.25000
Epoch 40: Val Loss 3464755.75000
Epoch 41: Val Loss 3456400.50000
Epoch 42: Val Loss 3450449.75000
Epoch 43: Val Loss 3459681.00000
Epoch 44: Val Loss 3466680.50000
Epoch 45: Val Loss 3433137.50000
Epoch 46: Val Loss 3445014.75000
Epoch 47: Val Loss 3512775.50000
Epoch 48: Val Loss 3445004.75000
Epoch 49: Val Loss 3462036.75000
Epoch 50: Val Loss 3433800.00000
Epoch 51: Val Loss 3440432.25000
Epoch 52: Val Loss 3456171.75000
Epoch 53: Val Loss 3437077.25000
Epoch 54: Val Loss 3449364.25000
Epoch 55: Val Loss 3437683.75000
Epoch 56: Val Loss 3456248.25000
Epoch 57: Val Loss 3496572.75000
Epoch 58: Val Loss 3532220.00000
Epoch 59: Val Loss 3436506.00000
Epoch 60: Val Loss 3435123.00000
Epoch 61: Val Loss 3419280.50000
Epoch 62: Val Loss 3470073.25000
Epoch 63: Val Loss 3432291.00000
Epoch 64: Val Loss 3457202.25000
Epoch 65: Val Loss 3454524.25000
Epoch 66: Val Loss 3488532.00000
Epoch 67: Val Loss 3474188.25000
Epoch 68: Val Loss 3467649.75000
Epoch 69: Val Loss 3472962.00000
Epoch 70: Val Loss 3493846.00000
Epoch 71: Val Loss 3444353.50000
Epoch 72: Val Loss 3472245.25000
Epoch 73: Val Loss 3477918.25000
Epoch 74: Val Loss 3492417.75000
Epoch 75: Val Loss 3478646.25000
Epoch 76: Val Loss 3473532.25000
Epoch 77: Val Loss 3513336.75000
Epoch 78: Val Loss 3491769.50000
Epoch 79: Val Loss 3489496.25000
Epoch 80: Val Loss 3529763.25000
Epoch 81: Val Loss 3532082.25000
Epoch 82: Val Loss 3533718.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3428970.750194975, 'MSE - std': 0.0, 'R2 - mean': 0.5982425981608211, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4218281.00000
Epoch 1: Val Loss 3878121.50000
Epoch 2: Val Loss 3806388.00000
Epoch 3: Val Loss 3747390.25000
Epoch 4: Val Loss 3716708.00000
Epoch 5: Val Loss 3694385.75000
Epoch 6: Val Loss 3669336.25000
Epoch 7: Val Loss 3767440.00000
Epoch 8: Val Loss 3626149.25000
Epoch 9: Val Loss 3622096.50000
Epoch 10: Val Loss 3622749.25000
Epoch 11: Val Loss 3579604.75000
Epoch 12: Val Loss 3606110.25000
Epoch 13: Val Loss 3569299.25000
Epoch 14: Val Loss 3562986.00000
Epoch 15: Val Loss 3538899.75000
Epoch 16: Val Loss 3540894.00000
Epoch 17: Val Loss 3560334.25000
Epoch 18: Val Loss 3501621.25000
Epoch 19: Val Loss 3504775.00000
Epoch 20: Val Loss 3508942.25000
Epoch 21: Val Loss 3488651.25000
Epoch 22: Val Loss 3494878.00000
Epoch 23: Val Loss 3487402.25000
Epoch 24: Val Loss 3474449.00000
Epoch 25: Val Loss 3595161.75000
Epoch 26: Val Loss 3491547.25000
Epoch 27: Val Loss 3466070.00000
Epoch 28: Val Loss 3480210.00000
Epoch 29: Val Loss 3502500.50000
Epoch 30: Val Loss 3434181.75000
Epoch 31: Val Loss 3421445.25000
Epoch 32: Val Loss 3427049.50000
Epoch 33: Val Loss 3441079.25000
Epoch 34: Val Loss 3434541.00000
Epoch 35: Val Loss 3481942.50000
Epoch 36: Val Loss 3445548.00000
Epoch 37: Val Loss 3472323.50000
Epoch 38: Val Loss 3414489.25000
Epoch 39: Val Loss 3438876.50000
Epoch 40: Val Loss 3414687.50000
Epoch 41: Val Loss 3456129.00000
Epoch 42: Val Loss 3414881.25000
Epoch 43: Val Loss 3405594.25000
Epoch 44: Val Loss 3442860.25000
Epoch 45: Val Loss 3421344.50000
Epoch 46: Val Loss 3399236.50000
Epoch 47: Val Loss 3452718.50000
Epoch 48: Val Loss 3473002.00000
Epoch 49: Val Loss 3402584.50000
Epoch 50: Val Loss 3406773.75000
Epoch 51: Val Loss 3395615.50000
Epoch 52: Val Loss 3420354.75000
Epoch 53: Val Loss 3439685.00000
Epoch 54: Val Loss 3400689.25000
Epoch 55: Val Loss 3433637.50000
Epoch 56: Val Loss 3417058.00000
Epoch 57: Val Loss 3427133.25000
Epoch 58: Val Loss 3406244.75000
Epoch 59: Val Loss 3424024.25000
Epoch 60: Val Loss 3408640.75000
Epoch 61: Val Loss 3440970.25000
Epoch 62: Val Loss 3409402.50000
Epoch 63: Val Loss 3388770.25000
Epoch 64: Val Loss 3414186.75000
Epoch 65: Val Loss 3416009.50000
Epoch 66: Val Loss 3413839.75000
Epoch 67: Val Loss 3403261.75000
Epoch 68: Val Loss 3405969.50000
Epoch 69: Val Loss 3410570.75000
Epoch 70: Val Loss 3415907.50000
Epoch 71: Val Loss 3443797.75000
Epoch 72: Val Loss 3431491.00000
Epoch 73: Val Loss 3483620.00000
Epoch 74: Val Loss 3409944.00000
Epoch 75: Val Loss 3432884.75000
Epoch 76: Val Loss 3425123.50000
Epoch 77: Val Loss 3441714.00000
Epoch 78: Val Loss 3433017.25000
Epoch 79: Val Loss 3476434.00000
Epoch 80: Val Loss 3452414.75000
Epoch 81: Val Loss 3481972.75000
Epoch 82: Val Loss 3440887.75000
Epoch 83: Val Loss 3475529.75000
Epoch 84: Val Loss 3450711.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3412962.1232173117, 'MSE - std': 16008.62697766372, 'R2 - mean': 0.5870213037901948, 'R2 - std': 0.011221294370626356} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4913929.50000
Epoch 1: Val Loss 4542164.50000
Epoch 2: Val Loss 4450105.00000
Epoch 3: Val Loss 4369227.00000
Epoch 4: Val Loss 4315977.00000
Epoch 5: Val Loss 4267364.00000
Epoch 6: Val Loss 4250540.00000
Epoch 7: Val Loss 4215928.50000
Epoch 8: Val Loss 4181581.00000
Epoch 9: Val Loss 4164341.75000
Epoch 10: Val Loss 4160087.00000
Epoch 11: Val Loss 4145563.25000
Epoch 12: Val Loss 4114867.50000
Epoch 13: Val Loss 4082360.25000
Epoch 14: Val Loss 4077059.50000
Epoch 15: Val Loss 4064408.00000
Epoch 16: Val Loss 4060866.75000
Epoch 17: Val Loss 4068122.50000
Epoch 18: Val Loss 4056096.50000
Epoch 19: Val Loss 4051262.25000
Epoch 20: Val Loss 4035913.50000
Epoch 21: Val Loss 4006613.75000
Epoch 22: Val Loss 4139075.50000
Epoch 23: Val Loss 3995918.25000
Epoch 24: Val Loss 3981077.25000
Epoch 25: Val Loss 4008414.25000
Epoch 26: Val Loss 3979742.25000
Epoch 27: Val Loss 3994867.50000
Epoch 28: Val Loss 3977925.75000
Epoch 29: Val Loss 3953282.25000
Epoch 30: Val Loss 3950622.00000
Epoch 31: Val Loss 3942699.25000
Epoch 32: Val Loss 3933034.50000
Epoch 33: Val Loss 3961314.75000
Epoch 34: Val Loss 3946242.25000
Epoch 35: Val Loss 3952451.00000
Epoch 36: Val Loss 3929332.75000
Epoch 37: Val Loss 3922317.50000
Epoch 38: Val Loss 3895783.50000
Epoch 39: Val Loss 3915252.00000
Epoch 40: Val Loss 3891996.25000
Epoch 41: Val Loss 3886292.00000
Epoch 42: Val Loss 3902272.00000
Epoch 43: Val Loss 3931935.75000
Epoch 44: Val Loss 3883497.50000
Epoch 45: Val Loss 3898268.75000
Epoch 46: Val Loss 3892607.25000
Epoch 47: Val Loss 3867342.25000
Epoch 48: Val Loss 3895154.75000
Epoch 49: Val Loss 3870742.50000
Epoch 50: Val Loss 3873138.25000
Epoch 51: Val Loss 3880136.00000
Epoch 52: Val Loss 3863593.50000
Epoch 53: Val Loss 3853540.75000
Epoch 54: Val Loss 3855130.50000
Epoch 55: Val Loss 3865082.00000
Epoch 56: Val Loss 3866536.00000
Epoch 57: Val Loss 3850916.50000
Epoch 58: Val Loss 3859148.25000
Epoch 59: Val Loss 3865858.25000
Epoch 60: Val Loss 3851657.25000
Epoch 61: Val Loss 3862302.25000
Epoch 62: Val Loss 3888290.25000
Epoch 63: Val Loss 3875351.00000
Epoch 64: Val Loss 3858861.00000
Epoch 65: Val Loss 3853705.50000
Epoch 66: Val Loss 3889785.25000
Epoch 67: Val Loss 3848890.50000
Epoch 68: Val Loss 3855460.50000
Epoch 69: Val Loss 3898696.00000
Epoch 70: Val Loss 3867296.50000
Epoch 71: Val Loss 3846654.25000
Epoch 72: Val Loss 3919956.75000
Epoch 73: Val Loss 3873957.25000
Epoch 74: Val Loss 3866767.75000
Epoch 75: Val Loss 3869755.25000
Epoch 76: Val Loss 3870107.75000
Epoch 77: Val Loss 3887054.00000
Epoch 78: Val Loss 3908924.75000
Epoch 79: Val Loss 3909023.25000
Epoch 80: Val Loss 3943115.75000
Epoch 81: Val Loss 3909052.75000
Epoch 82: Val Loss 3884674.25000
Epoch 83: Val Loss 3890653.50000
Epoch 84: Val Loss 3901211.25000
Epoch 85: Val Loss 3908650.50000
Epoch 86: Val Loss 3922649.25000
Epoch 87: Val Loss 3904964.50000
Epoch 88: Val Loss 3950507.25000
Epoch 89: Val Loss 3913962.00000
Epoch 90: Val Loss 3921094.50000
Epoch 91: Val Loss 3972522.50000
Epoch 92: Val Loss 3990483.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3563028.2273593196, 'MSE - std': 212627.6604376608, 'R2 - mean': 0.5806262186339618, 'R2 - std': 0.012873973481891463} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4556443.50000
Epoch 1: Val Loss 4217433.00000
Epoch 2: Val Loss 4113121.75000
Epoch 3: Val Loss 4053739.75000
Epoch 4: Val Loss 4003967.25000
Epoch 5: Val Loss 3977732.00000
Epoch 6: Val Loss 3943981.00000
Epoch 7: Val Loss 3924416.00000
Epoch 8: Val Loss 3913051.75000
Epoch 9: Val Loss 3893507.00000
Epoch 10: Val Loss 3935823.75000
Epoch 11: Val Loss 3854665.25000
Epoch 12: Val Loss 3886286.25000
Epoch 13: Val Loss 3816462.25000
Epoch 14: Val Loss 3829771.00000
Epoch 15: Val Loss 3798400.50000
Epoch 16: Val Loss 3809245.50000
Epoch 17: Val Loss 3827548.75000
Epoch 18: Val Loss 3773617.50000
Epoch 19: Val Loss 3781492.50000
Epoch 20: Val Loss 3772075.00000
Epoch 21: Val Loss 3751346.25000
Epoch 22: Val Loss 3858456.75000
Epoch 23: Val Loss 3767017.25000
Epoch 24: Val Loss 3730207.75000
Epoch 25: Val Loss 3754898.75000
Epoch 26: Val Loss 3787068.75000
Epoch 27: Val Loss 3722019.00000
Epoch 28: Val Loss 3751695.25000
Epoch 29: Val Loss 3721897.50000
Epoch 30: Val Loss 3746444.75000
Epoch 31: Val Loss 3721677.00000
Epoch 32: Val Loss 3753051.00000
Epoch 33: Val Loss 3718623.25000
Epoch 34: Val Loss 3699450.00000
Epoch 35: Val Loss 3716988.25000
Epoch 36: Val Loss 3726605.50000
Epoch 37: Val Loss 5046127.50000
Epoch 38: Val Loss 3703181.00000
Epoch 39: Val Loss 3731031.75000
Epoch 40: Val Loss 3744539.00000
Epoch 41: Val Loss 3681727.75000
Epoch 42: Val Loss 3707460.00000
Epoch 43: Val Loss 3727319.00000
Epoch 44: Val Loss 3714721.50000
Epoch 45: Val Loss 3720286.25000
Epoch 46: Val Loss 3773787.75000
Epoch 47: Val Loss 3737348.75000
Epoch 48: Val Loss 3702891.25000
Epoch 49: Val Loss 3733086.75000
Epoch 50: Val Loss 3734903.75000
Epoch 51: Val Loss 3767435.25000
Epoch 52: Val Loss 3752648.75000
Epoch 53: Val Loss 3725105.75000
Epoch 54: Val Loss 3827988.75000
Epoch 55: Val Loss 3707347.00000
Epoch 56: Val Loss 3731249.50000
Epoch 57: Val Loss 3755688.75000
Epoch 58: Val Loss 3752330.50000
Epoch 59: Val Loss 3730090.00000
Epoch 60: Val Loss 3744754.25000
Epoch 61: Val Loss 3766763.25000
Epoch 62: Val Loss 3802562.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3595859.4842887446, 'MSE - std': 192721.47203177083, 'R2 - mean': 0.5779063823710814, 'R2 - std': 0.01210359131828113} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4169176.25000
Epoch 1: Val Loss 3711900.75000
Epoch 2: Val Loss 3627553.75000
Epoch 3: Val Loss 3562359.75000
Epoch 4: Val Loss 3550296.50000
Epoch 5: Val Loss 3519115.75000
Epoch 6: Val Loss 3488260.75000
Epoch 7: Val Loss 3487649.50000
Epoch 8: Val Loss 3528303.25000
Epoch 9: Val Loss 3463161.00000
Epoch 10: Val Loss 3475281.25000
Epoch 11: Val Loss 3428458.75000
Epoch 12: Val Loss 3468769.25000
Epoch 13: Val Loss 3425472.50000
Epoch 14: Val Loss 3428935.25000
Epoch 15: Val Loss 3412358.25000
Epoch 16: Val Loss 3396227.75000
Epoch 17: Val Loss 3402184.50000
Epoch 18: Val Loss 3435235.00000
Epoch 19: Val Loss 3425735.00000
Epoch 20: Val Loss 3402976.75000
Epoch 21: Val Loss 3398630.00000
Epoch 22: Val Loss 3394541.75000
Epoch 23: Val Loss 3477500.75000
Epoch 24: Val Loss 3394976.50000
Epoch 25: Val Loss 3422780.00000
Epoch 26: Val Loss 3395277.00000
Epoch 27: Val Loss 3410001.50000
Epoch 28: Val Loss 3382550.75000
Epoch 29: Val Loss 3447499.75000
Epoch 30: Val Loss 3396052.50000
Epoch 31: Val Loss 3384505.50000
Epoch 32: Val Loss 3396867.75000
Epoch 33: Val Loss 3444419.00000
Epoch 34: Val Loss 3484845.25000
Epoch 35: Val Loss 3477324.00000
Epoch 36: Val Loss 3461575.00000
Epoch 37: Val Loss 3372999.75000
Epoch 38: Val Loss 3421557.00000
Epoch 39: Val Loss 3407526.25000
Epoch 40: Val Loss 3377017.50000
Epoch 41: Val Loss 3414875.75000
Epoch 42: Val Loss 3436976.00000
Epoch 43: Val Loss 3390636.00000
Epoch 44: Val Loss 3397142.75000
Epoch 45: Val Loss 3425099.50000
Epoch 46: Val Loss 3378559.25000
Epoch 47: Val Loss 3418896.25000
Epoch 48: Val Loss 3407314.00000
Epoch 49: Val Loss 3393654.75000
Epoch 50: Val Loss 3418356.75000
Epoch 51: Val Loss 3382862.25000
Epoch 52: Val Loss 3413682.00000
Epoch 53: Val Loss 3425694.25000
Epoch 54: Val Loss 3443158.25000
Epoch 55: Val Loss 3396530.25000
Epoch 56: Val Loss 3413383.50000
Epoch 57: Val Loss 3435346.25000
Epoch 58: Val Loss 3449381.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553317.254199615, 'MSE - std': 192230.63748918852, 'R2 - mean': 0.57877595013783, 'R2 - std': 0.010964585292834804} 
 

Saving model.....
Results After CV: {'MSE - mean': 3553317.254199615, 'MSE - std': 192230.63748918852, 'R2 - mean': 0.57877595013783, 'R2 - std': 0.010964585292834804}
Train time: 5979.1478623883795
Inference time: 6.936294725630432
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 36 finished with value: 3553317.254199615 and parameters: {'dim': 256, 'depth': 6, 'heads': 8, 'weight_decay': -4, 'learning_rate': -4, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4473327.00000
Epoch 1: Val Loss 4059181.00000
Epoch 2: Val Loss 3941854.25000
Epoch 3: Val Loss 3913213.00000
Epoch 4: Val Loss 3849333.75000
Epoch 5: Val Loss 3797319.00000
Epoch 6: Val Loss 3788684.75000
Epoch 7: Val Loss 3776222.25000
Epoch 8: Val Loss 3729945.25000
Epoch 9: Val Loss 3701791.25000
Epoch 10: Val Loss 3672712.75000
Epoch 11: Val Loss 3667738.50000
Epoch 12: Val Loss 3638196.75000
Epoch 13: Val Loss 3649340.75000
Epoch 14: Val Loss 3621088.75000
Epoch 15: Val Loss 3607820.75000
Epoch 16: Val Loss 3610477.75000
Epoch 17: Val Loss 3580523.75000
Epoch 18: Val Loss 3566433.75000
Epoch 19: Val Loss 3587556.25000
Epoch 20: Val Loss 3554114.00000
Epoch 21: Val Loss 3550041.75000
Epoch 22: Val Loss 3559035.25000
Epoch 23: Val Loss 3523814.50000
Epoch 24: Val Loss 3523886.50000
Epoch 25: Val Loss 3543059.75000
Epoch 26: Val Loss 3519987.75000
Epoch 27: Val Loss 3507186.00000
Epoch 28: Val Loss 3508396.00000
Epoch 29: Val Loss 3488572.25000
Epoch 30: Val Loss 3502320.75000
Epoch 31: Val Loss 3472740.50000
Epoch 32: Val Loss 3510198.25000
Epoch 33: Val Loss 3484811.00000
Epoch 34: Val Loss 3468635.00000
Epoch 35: Val Loss 3472347.75000
Epoch 36: Val Loss 3450457.00000
Epoch 37: Val Loss 3451036.25000
Epoch 38: Val Loss 3446598.00000
Epoch 39: Val Loss 3451313.00000
Epoch 40: Val Loss 3458451.00000
Epoch 41: Val Loss 3485148.75000
Epoch 42: Val Loss 3460782.50000
Epoch 43: Val Loss 3455882.75000
Epoch 44: Val Loss 3428999.75000
Epoch 45: Val Loss 3461460.25000
Epoch 46: Val Loss 3448776.50000
Epoch 47: Val Loss 3449879.75000
Epoch 48: Val Loss 3488153.00000
Epoch 49: Val Loss 3455447.00000
Epoch 50: Val Loss 3443946.75000
Epoch 51: Val Loss 3435014.25000
Epoch 52: Val Loss 3420673.50000
Epoch 53: Val Loss 3436413.50000
Epoch 54: Val Loss 3433336.75000
Epoch 55: Val Loss 3452646.25000
Epoch 56: Val Loss 3409937.75000
Epoch 57: Val Loss 3418066.50000
Epoch 58: Val Loss 3446374.25000
Epoch 59: Val Loss 3423852.25000
Epoch 60: Val Loss 3448407.75000
Epoch 61: Val Loss 3468842.00000
Epoch 62: Val Loss 3447803.00000
Epoch 63: Val Loss 3460218.25000
Epoch 64: Val Loss 3467997.50000
Epoch 65: Val Loss 3445319.25000
Epoch 66: Val Loss 3462679.00000
Epoch 67: Val Loss 3461395.00000
Epoch 68: Val Loss 3467160.75000
Epoch 69: Val Loss 3460619.00000
Epoch 70: Val Loss 3460004.50000
Epoch 71: Val Loss 3487234.25000
Epoch 72: Val Loss 3448210.00000
Epoch 73: Val Loss 3456807.75000
Epoch 74: Val Loss 3452781.75000
Epoch 75: Val Loss 3505918.25000
Epoch 76: Val Loss 3464353.00000
Epoch 77: Val Loss 3487479.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3424948.0247393968, 'MSE - std': 0.0, 'R2 - mean': 0.5987139231866335, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4244651.00000
Epoch 1: Val Loss 3864952.25000
Epoch 2: Val Loss 3787976.25000
Epoch 3: Val Loss 3731130.50000
Epoch 4: Val Loss 3709055.25000
Epoch 5: Val Loss 3673516.25000
Epoch 6: Val Loss 3638795.25000
Epoch 7: Val Loss 3623051.00000
Epoch 8: Val Loss 3600899.25000
Epoch 9: Val Loss 3620604.50000
Epoch 10: Val Loss 3559991.50000
Epoch 11: Val Loss 3559707.50000
Epoch 12: Val Loss 3539351.00000
Epoch 13: Val Loss 3538730.75000
Epoch 14: Val Loss 3516530.25000
Epoch 15: Val Loss 3510394.75000
Epoch 16: Val Loss 3499024.75000
Epoch 17: Val Loss 3485906.00000
Epoch 18: Val Loss 3505190.50000
Epoch 19: Val Loss 3496532.50000
Epoch 20: Val Loss 3483997.50000
Epoch 21: Val Loss 3487494.25000
Epoch 22: Val Loss 3473386.50000
Epoch 23: Val Loss 3454344.75000
Epoch 24: Val Loss 3458953.00000
Epoch 25: Val Loss 3449921.50000
Epoch 26: Val Loss 3448554.50000
Epoch 27: Val Loss 3508890.50000
Epoch 28: Val Loss 3488840.75000
Epoch 29: Val Loss 3491327.75000
Epoch 30: Val Loss 3428322.25000
Epoch 31: Val Loss 3442652.50000
Epoch 32: Val Loss 3454946.25000
Epoch 33: Val Loss 3429442.50000
Epoch 34: Val Loss 3426633.75000
Epoch 35: Val Loss 3418753.50000
Epoch 36: Val Loss 3430542.00000
Epoch 37: Val Loss 3448182.00000
Epoch 38: Val Loss 3415375.25000
Epoch 39: Val Loss 3422246.50000
Epoch 40: Val Loss 3405643.00000
Epoch 41: Val Loss 3494203.00000
Epoch 42: Val Loss 3411230.50000
Epoch 43: Val Loss 3421917.25000
Epoch 44: Val Loss 3413446.25000
Epoch 45: Val Loss 3392220.50000
Epoch 46: Val Loss 3427655.00000
Epoch 47: Val Loss 3397364.75000
Epoch 48: Val Loss 3403832.25000
Epoch 49: Val Loss 3394753.25000
Epoch 50: Val Loss 3425672.25000
Epoch 51: Val Loss 3404961.50000
Epoch 52: Val Loss 3468581.25000
Epoch 53: Val Loss 3397580.50000
Epoch 54: Val Loss 3414683.25000
Epoch 55: Val Loss 3426831.25000
Epoch 56: Val Loss 3392418.25000
Epoch 57: Val Loss 3411401.50000
Epoch 58: Val Loss 3398993.00000
Epoch 59: Val Loss 3406035.50000
Epoch 60: Val Loss 3421698.75000
Epoch 61: Val Loss 3396543.75000
Epoch 62: Val Loss 3404789.00000
Epoch 63: Val Loss 3429047.00000
Epoch 64: Val Loss 3377100.75000
Epoch 65: Val Loss 3423872.75000
Epoch 66: Val Loss 3382209.50000
Epoch 67: Val Loss 3388197.25000
Epoch 68: Val Loss 3479230.25000
Epoch 69: Val Loss 3426538.25000
Epoch 70: Val Loss 3394722.75000
Epoch 71: Val Loss 3426212.00000
Epoch 72: Val Loss 3454651.75000
Epoch 73: Val Loss 3457369.25000
Epoch 74: Val Loss 3498649.25000
Epoch 75: Val Loss 3435877.25000
Epoch 76: Val Loss 3432761.75000
Epoch 77: Val Loss 3511108.25000
Epoch 78: Val Loss 3441459.00000
Epoch 79: Val Loss 3440616.00000
Epoch 80: Val Loss 3456011.00000
Epoch 81: Val Loss 3444818.75000
Epoch 82: Val Loss 3439425.50000
Epoch 83: Val Loss 3464534.75000
Epoch 84: Val Loss 3464532.00000
Epoch 85: Val Loss 3446811.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407469.869273044, 'MSE - std': 17478.155466352357, 'R2 - mean': 0.5876916481504904, 'R2 - std': 0.011022275036143114} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4987806.00000
Epoch 1: Val Loss 4572802.00000
Epoch 2: Val Loss 4524882.00000
Epoch 3: Val Loss 4391996.50000
Epoch 4: Val Loss 4381602.00000
Epoch 5: Val Loss 4294796.00000
Epoch 6: Val Loss 4252351.50000
Epoch 7: Val Loss 4265266.50000
Epoch 8: Val Loss 4218815.00000
Epoch 9: Val Loss 4190012.25000
Epoch 10: Val Loss 4175234.75000
Epoch 11: Val Loss 4138268.75000
Epoch 12: Val Loss 4128435.25000
Epoch 13: Val Loss 4113789.00000
Epoch 14: Val Loss 4126350.75000
Epoch 15: Val Loss 4108254.25000
Epoch 16: Val Loss 4089163.00000
Epoch 17: Val Loss 4066853.25000
Epoch 18: Val Loss 4064132.50000
Epoch 19: Val Loss 4062548.00000
Epoch 20: Val Loss 4036545.00000
Epoch 21: Val Loss 4031321.50000
Epoch 22: Val Loss 4074657.50000
Epoch 23: Val Loss 4013671.00000
Epoch 24: Val Loss 4051030.25000
Epoch 25: Val Loss 4005904.00000
Epoch 26: Val Loss 4011710.00000
Epoch 27: Val Loss 4029077.25000
Epoch 28: Val Loss 3996492.25000
Epoch 29: Val Loss 3983457.75000
Epoch 30: Val Loss 3980009.25000
Epoch 31: Val Loss 3980426.00000
Epoch 32: Val Loss 3959908.75000
Epoch 33: Val Loss 3958777.25000
Epoch 34: Val Loss 3959447.00000
Epoch 35: Val Loss 4003439.75000
Epoch 36: Val Loss 3953375.25000
Epoch 37: Val Loss 3935293.00000
Epoch 38: Val Loss 3954974.75000
Epoch 39: Val Loss 3938009.50000
Epoch 40: Val Loss 3941744.00000
Epoch 41: Val Loss 4022184.75000
Epoch 42: Val Loss 3933470.25000
Epoch 43: Val Loss 3908657.75000
Epoch 44: Val Loss 3934705.75000
Epoch 45: Val Loss 3913469.00000
Epoch 46: Val Loss 3943057.50000
Epoch 47: Val Loss 3902587.00000
Epoch 48: Val Loss 3884620.75000
Epoch 49: Val Loss 3881728.50000
Epoch 50: Val Loss 3916022.25000
Epoch 51: Val Loss 3882832.50000
Epoch 52: Val Loss 3889408.00000
Epoch 53: Val Loss 4292819.00000
Epoch 54: Val Loss 3922772.00000
Epoch 55: Val Loss 3888322.75000
Epoch 56: Val Loss 3894292.50000
Epoch 57: Val Loss 3894002.25000
Epoch 58: Val Loss 3870748.75000
Epoch 59: Val Loss 3886837.25000
Epoch 60: Val Loss 3860390.25000
Epoch 61: Val Loss 3892475.00000
Epoch 62: Val Loss 3860980.75000
Epoch 63: Val Loss 3877207.00000
Epoch 64: Val Loss 3888880.00000
Epoch 65: Val Loss 3857044.00000
Epoch 66: Val Loss 3867992.25000
Epoch 67: Val Loss 3863678.00000
Epoch 68: Val Loss 3847048.00000
Epoch 69: Val Loss 3869172.75000
Epoch 70: Val Loss 3851867.00000
Epoch 71: Val Loss 3853429.25000
Epoch 72: Val Loss 3857185.75000
Epoch 73: Val Loss 3890206.25000
Epoch 74: Val Loss 3859682.25000
Epoch 75: Val Loss 3849559.00000
Epoch 76: Val Loss 3848605.00000
Epoch 77: Val Loss 3870206.25000
Epoch 78: Val Loss 3847259.00000
Epoch 79: Val Loss 3851799.50000
Epoch 80: Val Loss 3865076.00000
Epoch 81: Val Loss 3851092.00000
Epoch 82: Val Loss 3880942.75000
Epoch 83: Val Loss 3866562.25000
Epoch 84: Val Loss 3867025.50000
Epoch 85: Val Loss 3848950.25000
Epoch 86: Val Loss 3853118.75000
Epoch 87: Val Loss 3867229.00000
Epoch 88: Val Loss 3863050.50000
Epoch 89: Val Loss 3874361.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3556595.1843113005, 'MSE - std': 211377.3319197741, 'R2 - mean': 0.581383161500348, 'R2 - std': 0.012672320450952896} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4597621.00000
Epoch 1: Val Loss 4219960.50000
Epoch 2: Val Loss 4120704.50000
Epoch 3: Val Loss 4134145.75000
Epoch 4: Val Loss 4023722.00000
Epoch 5: Val Loss 3989625.25000
Epoch 6: Val Loss 3962611.50000
Epoch 7: Val Loss 3946285.00000
Epoch 8: Val Loss 3927185.50000
Epoch 9: Val Loss 3891538.25000
Epoch 10: Val Loss 3873538.75000
Epoch 11: Val Loss 3872742.25000
Epoch 12: Val Loss 3844202.50000
Epoch 13: Val Loss 3851907.50000
Epoch 14: Val Loss 3846063.75000
Epoch 15: Val Loss 3813618.75000
Epoch 16: Val Loss 3820457.50000
Epoch 17: Val Loss 3797414.50000
Epoch 18: Val Loss 3811215.25000
Epoch 19: Val Loss 3800760.75000
Epoch 20: Val Loss 3845530.50000
Epoch 21: Val Loss 3845292.25000
Epoch 22: Val Loss 3761896.75000
Epoch 23: Val Loss 3758898.75000
Epoch 24: Val Loss 3760871.00000
Epoch 25: Val Loss 3737302.50000
Epoch 26: Val Loss 3744673.75000
Epoch 27: Val Loss 3743607.75000
Epoch 28: Val Loss 3733126.50000
Epoch 29: Val Loss 3754357.25000
Epoch 30: Val Loss 3755970.25000
Epoch 31: Val Loss 3752163.50000
Epoch 32: Val Loss 3719032.75000
Epoch 33: Val Loss 3714515.50000
Epoch 34: Val Loss 3723250.25000
Epoch 35: Val Loss 3706207.25000
Epoch 36: Val Loss 3745240.25000
Epoch 37: Val Loss 3741311.75000
Epoch 38: Val Loss 3715412.50000
Epoch 39: Val Loss 3742676.50000
Epoch 40: Val Loss 3713076.75000
Epoch 41: Val Loss 3758111.25000
Epoch 42: Val Loss 3768060.25000
Epoch 43: Val Loss 3700686.25000
Epoch 44: Val Loss 3692909.50000
Epoch 45: Val Loss 3697504.00000
Epoch 46: Val Loss 3698811.00000
Epoch 47: Val Loss 3720577.00000
Epoch 48: Val Loss 3731499.00000
Epoch 49: Val Loss 3699961.25000
Epoch 50: Val Loss 3739281.75000
Epoch 51: Val Loss 3718871.00000
Epoch 52: Val Loss 3761944.25000
Epoch 53: Val Loss 3721844.75000
Epoch 54: Val Loss 3714440.25000
Epoch 55: Val Loss 3731553.50000
Epoch 56: Val Loss 3779488.50000
Epoch 57: Val Loss 3784962.25000
Epoch 58: Val Loss 3723537.75000
Epoch 59: Val Loss 3764428.75000
Epoch 60: Val Loss 3748769.00000
Epoch 61: Val Loss 3757544.25000
Epoch 62: Val Loss 3784710.50000
Epoch 63: Val Loss 3736809.50000
Epoch 64: Val Loss 3750194.75000
Epoch 65: Val Loss 3720937.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591890.06371019, 'MSE - std': 192996.0307169248, 'R2 - mean': 0.578374472071363, 'R2 - std': 0.012148967670093892} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4163487.25000
Epoch 1: Val Loss 3742914.75000
Epoch 2: Val Loss 3634911.75000
Epoch 3: Val Loss 3576869.50000
Epoch 4: Val Loss 3585110.25000
Epoch 5: Val Loss 3518199.75000
Epoch 6: Val Loss 3492948.75000
Epoch 7: Val Loss 3504795.25000
Epoch 8: Val Loss 3456299.00000
Epoch 9: Val Loss 3439969.00000
Epoch 10: Val Loss 3467891.00000
Epoch 11: Val Loss 3493788.50000
Epoch 12: Val Loss 3422860.50000
Epoch 13: Val Loss 3422562.25000
Epoch 14: Val Loss 3474546.50000
Epoch 15: Val Loss 3432388.50000
Epoch 16: Val Loss 3407357.00000
Epoch 17: Val Loss 3418103.00000
Epoch 18: Val Loss 3393614.00000
Epoch 19: Val Loss 3394392.25000
Epoch 20: Val Loss 3411573.25000
Epoch 21: Val Loss 3398557.00000
Epoch 22: Val Loss 3396289.50000
Epoch 23: Val Loss 3430513.50000
Epoch 24: Val Loss 3401807.25000
Epoch 25: Val Loss 3386922.00000
Epoch 26: Val Loss 3404486.25000
Epoch 27: Val Loss 3387262.50000
Epoch 28: Val Loss 3418649.00000
Epoch 29: Val Loss 3444113.50000
Epoch 30: Val Loss 3393372.25000
Epoch 31: Val Loss 3394314.25000
Epoch 32: Val Loss 3395309.25000
Epoch 33: Val Loss 3393333.25000
Epoch 34: Val Loss 3408831.50000
Epoch 35: Val Loss 3410040.25000
Epoch 36: Val Loss 3387121.50000
Epoch 37: Val Loss 3421274.00000
Epoch 38: Val Loss 3444469.25000
Epoch 39: Val Loss 3405538.00000
Epoch 40: Val Loss 3384395.50000
Epoch 41: Val Loss 3400366.75000
Epoch 42: Val Loss 3386410.00000
Epoch 43: Val Loss 3377790.75000
Epoch 44: Val Loss 3384997.25000
Epoch 45: Val Loss 3369315.50000
Epoch 46: Val Loss 3393168.25000
Epoch 47: Val Loss 3479471.50000
Epoch 48: Val Loss 3440675.25000
Epoch 49: Val Loss 3417502.50000
Epoch 50: Val Loss 3424761.50000
Epoch 51: Val Loss 3391702.75000
Epoch 52: Val Loss 3374284.50000
Epoch 53: Val Loss 3416577.50000
Epoch 54: Val Loss 3460254.25000
Epoch 55: Val Loss 3418591.00000
Epoch 56: Val Loss 3379129.50000
Epoch 57: Val Loss 3397987.25000
Epoch 58: Val Loss 3422047.50000
Epoch 59: Val Loss 3420177.50000
Epoch 60: Val Loss 3449437.00000
Epoch 61: Val Loss 3407691.00000
Epoch 62: Val Loss 3385314.50000
Epoch 63: Val Loss 3428302.50000
Epoch 64: Val Loss 3407717.75000
Epoch 65: Val Loss 3402467.00000
Epoch 66: Val Loss 3457464.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3549185.0182960406, 'MSE - std': 192595.06201688742, 'R2 - mean': 0.5792685536243363, 'R2 - std': 0.0110125137753674} 
 

Saving model.....
Results After CV: {'MSE - mean': 3549185.0182960406, 'MSE - std': 192595.06201688742, 'R2 - mean': 0.5792685536243363, 'R2 - std': 0.0110125137753674}
Train time: 6039.509617763804
Inference time: 6.897130616381764
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 37 finished with value: 3549185.0182960406 and parameters: {'dim': 32, 'depth': 6, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 17777422.00000
Epoch 1: Val Loss 17648492.00000
Epoch 2: Val Loss 17180604.00000
Epoch 3: Val Loss 16724652.00000
Epoch 4: Val Loss 16120755.00000
Epoch 5: Val Loss 15329808.00000
Epoch 6: Val Loss 14410995.00000
Epoch 7: Val Loss 13499309.00000
Epoch 8: Val Loss 12365862.00000
Epoch 9: Val Loss 11365009.00000
Epoch 10: Val Loss 10405521.00000
Epoch 11: Val Loss 9585171.00000
Epoch 12: Val Loss 8997221.00000
Epoch 13: Val Loss 8739032.00000
Epoch 14: Val Loss 8584189.00000
Epoch 15: Val Loss 8586981.00000
Epoch 16: Val Loss 8502089.00000
Epoch 17: Val Loss 8461078.00000
Epoch 18: Val Loss 8657976.00000
Epoch 19: Val Loss 8391117.00000
Epoch 20: Val Loss 8362576.00000
Epoch 21: Val Loss 8371102.50000
Epoch 22: Val Loss 8347162.00000
Epoch 23: Val Loss 8281452.50000
Epoch 24: Val Loss 8257638.50000
Epoch 25: Val Loss 8306943.50000
Epoch 26: Val Loss 8181774.00000
Epoch 27: Val Loss 8172054.50000
Epoch 28: Val Loss 8120207.00000
Epoch 29: Val Loss 8106379.50000
Epoch 30: Val Loss 8083915.50000
Epoch 31: Val Loss 8014157.00000
Epoch 32: Val Loss 7990086.00000
Epoch 33: Val Loss 7959124.00000
Epoch 34: Val Loss 8049647.00000
Epoch 35: Val Loss 7873056.00000
Epoch 36: Val Loss 7839439.00000
Epoch 37: Val Loss 7788672.00000
Epoch 38: Val Loss 7741988.50000
Epoch 39: Val Loss 7714691.00000
Epoch 40: Val Loss 7687362.00000
Epoch 41: Val Loss 7630038.00000
Epoch 42: Val Loss 7571625.50000
Epoch 43: Val Loss 7529880.50000
Epoch 44: Val Loss 7553414.00000
Epoch 45: Val Loss 7432406.50000
Epoch 46: Val Loss 7379443.00000
Epoch 47: Val Loss 7313220.50000
Epoch 48: Val Loss 7271178.50000
Epoch 49: Val Loss 7272506.00000
Epoch 50: Val Loss 7155430.00000
Epoch 51: Val Loss 7141085.50000
Epoch 52: Val Loss 7037865.50000
Epoch 53: Val Loss 6978087.50000
Epoch 54: Val Loss 6924835.50000
Epoch 55: Val Loss 6857951.50000
Epoch 56: Val Loss 6774648.00000
Epoch 57: Val Loss 6748995.50000
Epoch 58: Val Loss 6644372.00000
Epoch 59: Val Loss 6559836.50000
Epoch 60: Val Loss 6501896.50000
Epoch 61: Val Loss 6481151.50000
Epoch 62: Val Loss 6364619.00000
Epoch 63: Val Loss 6285625.00000
Epoch 64: Val Loss 6226714.00000
Epoch 65: Val Loss 6160417.50000
Epoch 66: Val Loss 6109856.00000
Epoch 67: Val Loss 6016465.00000
Epoch 68: Val Loss 5969410.50000
Epoch 69: Val Loss 5898643.00000
Epoch 70: Val Loss 5856837.00000
Epoch 71: Val Loss 5789656.00000
Epoch 72: Val Loss 5714650.00000
Epoch 73: Val Loss 5677877.50000
Epoch 74: Val Loss 5613786.50000
Epoch 75: Val Loss 5568726.00000
Epoch 76: Val Loss 5548022.00000
Epoch 77: Val Loss 5473915.50000
Epoch 78: Val Loss 5425168.50000
Epoch 79: Val Loss 5386246.50000
Epoch 80: Val Loss 5350673.50000
Epoch 81: Val Loss 5327508.00000
Epoch 82: Val Loss 5274015.50000
Epoch 83: Val Loss 5246572.00000
Epoch 84: Val Loss 5196978.50000
Epoch 85: Val Loss 5169446.50000
Epoch 86: Val Loss 5138326.00000
Epoch 87: Val Loss 5131903.50000
Epoch 88: Val Loss 5084035.50000
Epoch 89: Val Loss 5048094.50000
Epoch 90: Val Loss 5039807.50000
Epoch 91: Val Loss 4998572.50000
Epoch 92: Val Loss 4995654.00000
Epoch 93: Val Loss 4948292.00000
Epoch 94: Val Loss 4934066.00000
Epoch 95: Val Loss 4908633.00000
Epoch 96: Val Loss 4885956.00000
Epoch 97: Val Loss 4884200.00000
Epoch 98: Val Loss 4852518.50000
Epoch 99: Val Loss 4821387.50000
Saved Losses
{'MSE - mean': 4834562.674529509, 'MSE - std': 0.0, 'R2 - mean': 0.43355558252073034, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 17051180.00000
Epoch 1: Val Loss 16793674.00000
Epoch 2: Val Loss 16379885.00000
Epoch 3: Val Loss 15852297.00000
Epoch 4: Val Loss 15157027.00000
Epoch 5: Val Loss 14373082.00000
Epoch 6: Val Loss 13363942.00000
Epoch 7: Val Loss 12372886.00000
Epoch 8: Val Loss 11263746.00000
Epoch 9: Val Loss 10478016.00000
Epoch 10: Val Loss 9373225.00000
Epoch 11: Val Loss 8675943.00000
Epoch 12: Val Loss 8267846.50000
Epoch 13: Val Loss 8064739.50000
Epoch 14: Val Loss 8016188.50000
Epoch 15: Val Loss 7956179.00000
Epoch 16: Val Loss 7958166.50000
Epoch 17: Val Loss 7914968.50000
Epoch 18: Val Loss 7881958.00000
Epoch 19: Val Loss 7843727.00000
Epoch 20: Val Loss 7817944.50000
Epoch 21: Val Loss 7809255.00000
Epoch 22: Val Loss 7769795.50000
Epoch 23: Val Loss 7747107.00000
Epoch 24: Val Loss 7709421.00000
Epoch 25: Val Loss 7660290.00000
Epoch 26: Val Loss 7644003.50000
Epoch 27: Val Loss 7625039.00000
Epoch 28: Val Loss 7570296.50000
Epoch 29: Val Loss 7537605.50000
Epoch 30: Val Loss 7515746.00000
Epoch 31: Val Loss 7474928.50000
Epoch 32: Val Loss 7524500.00000
Epoch 33: Val Loss 7400230.00000
Epoch 34: Val Loss 7388469.00000
Epoch 35: Val Loss 7340441.50000
Epoch 36: Val Loss 7273209.50000
Epoch 37: Val Loss 7224026.50000
Epoch 38: Val Loss 7243868.50000
Epoch 39: Val Loss 7150039.50000
Epoch 40: Val Loss 7199906.00000
Epoch 41: Val Loss 7074434.00000
Epoch 42: Val Loss 7019966.50000
Epoch 43: Val Loss 6956241.50000
Epoch 44: Val Loss 6911306.00000
Epoch 45: Val Loss 6845827.00000
Epoch 46: Val Loss 6796243.00000
Epoch 47: Val Loss 6744511.50000
Epoch 48: Val Loss 6685329.00000
Epoch 49: Val Loss 6633343.50000
Epoch 50: Val Loss 6562889.50000
Epoch 51: Val Loss 6510528.50000
Epoch 52: Val Loss 6450279.00000
Epoch 53: Val Loss 6391656.00000
Epoch 54: Val Loss 6339931.00000
Epoch 55: Val Loss 6263376.50000
Epoch 56: Val Loss 6170008.00000
Epoch 57: Val Loss 6138886.00000
Epoch 58: Val Loss 6074820.50000
Epoch 59: Val Loss 5972886.00000
Epoch 60: Val Loss 5917216.50000
Epoch 61: Val Loss 5837983.00000
Epoch 62: Val Loss 5762466.00000
Epoch 63: Val Loss 5694844.50000
Epoch 64: Val Loss 5632028.50000
Epoch 65: Val Loss 5573234.50000
Epoch 66: Val Loss 5512355.50000
Epoch 67: Val Loss 5505269.00000
Epoch 68: Val Loss 5392336.00000
Epoch 69: Val Loss 5337209.00000
Epoch 70: Val Loss 5290957.00000
Epoch 71: Val Loss 5265040.00000
Epoch 72: Val Loss 5184180.00000
Epoch 73: Val Loss 5145750.50000
Epoch 74: Val Loss 5116763.00000
Epoch 75: Val Loss 5044971.50000
Epoch 76: Val Loss 5016158.50000
Epoch 77: Val Loss 5000090.00000
Epoch 78: Val Loss 4938664.00000
Epoch 79: Val Loss 4904199.50000
Epoch 80: Val Loss 4867156.50000
Epoch 81: Val Loss 4866016.00000
Epoch 82: Val Loss 4811388.00000
Epoch 83: Val Loss 4783711.50000
Epoch 84: Val Loss 4767396.00000
Epoch 85: Val Loss 4719415.50000
Epoch 86: Val Loss 4744824.50000
Epoch 87: Val Loss 4668330.50000
Epoch 88: Val Loss 4655458.50000
Epoch 89: Val Loss 4627644.00000
Epoch 90: Val Loss 4616986.50000
Epoch 91: Val Loss 4590953.00000
Epoch 92: Val Loss 4561111.00000
Epoch 93: Val Loss 4552434.50000
Epoch 94: Val Loss 4526134.00000
Epoch 95: Val Loss 4511160.50000
Epoch 96: Val Loss 4509262.50000
Epoch 97: Val Loss 4476733.00000
Epoch 98: Val Loss 4456857.00000
Epoch 99: Val Loss 4482469.00000
Saved Losses
{'MSE - mean': 4650464.706653124, 'MSE - std': 184097.9678763845, 'R2 - mean': 0.43790545305862616, 'R2 - std': 0.004349870537895817} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 18059124.00000
Epoch 1: Val Loss 17807320.00000
Epoch 2: Val Loss 17455710.00000
Epoch 3: Val Loss 16895746.00000
Epoch 4: Val Loss 16221082.00000
Epoch 5: Val Loss 15309171.00000
Epoch 6: Val Loss 14315772.00000
Epoch 7: Val Loss 13253811.00000
Epoch 8: Val Loss 12198998.00000
Epoch 9: Val Loss 11160129.00000
Epoch 10: Val Loss 10239209.00000
Epoch 11: Val Loss 9565370.00000
Epoch 12: Val Loss 9184484.00000
Epoch 13: Val Loss 8996777.00000
Epoch 14: Val Loss 8920436.00000
Epoch 15: Val Loss 8901568.00000
Epoch 16: Val Loss 8859582.00000
Epoch 17: Val Loss 8851475.00000
Epoch 18: Val Loss 8813565.00000
Epoch 19: Val Loss 8795537.00000
Epoch 20: Val Loss 8749037.00000
Epoch 21: Val Loss 8731777.00000
Epoch 22: Val Loss 8722156.00000
Epoch 23: Val Loss 8687743.00000
Epoch 24: Val Loss 8634957.00000
Epoch 25: Val Loss 8595891.00000
Epoch 26: Val Loss 8633802.00000
Epoch 27: Val Loss 8550626.00000
Epoch 28: Val Loss 8557162.00000
Epoch 29: Val Loss 8443610.00000
Epoch 30: Val Loss 8395666.00000
Epoch 31: Val Loss 8367180.50000
Epoch 32: Val Loss 8431870.00000
Epoch 33: Val Loss 8349557.00000
Epoch 34: Val Loss 8251522.00000
Epoch 35: Val Loss 8257928.00000
Epoch 36: Val Loss 8152431.00000
Epoch 37: Val Loss 8127715.00000
Epoch 38: Val Loss 8142597.50000
Epoch 39: Val Loss 8049527.50000
Epoch 40: Val Loss 7967056.50000
Epoch 41: Val Loss 7923706.00000
Epoch 42: Val Loss 7867472.00000
Epoch 43: Val Loss 7803900.50000
Epoch 44: Val Loss 7748169.00000
Epoch 45: Val Loss 7731627.50000
Epoch 46: Val Loss 7621570.00000
Epoch 47: Val Loss 7572128.00000
Epoch 48: Val Loss 7519577.50000
Epoch 49: Val Loss 7436412.50000
Epoch 50: Val Loss 7375725.00000
Epoch 51: Val Loss 7306819.00000
Epoch 52: Val Loss 7245395.00000
Epoch 53: Val Loss 7200790.50000
Epoch 54: Val Loss 7124379.00000
Epoch 55: Val Loss 7024981.50000
Epoch 56: Val Loss 6960702.50000
Epoch 57: Val Loss 6869935.50000
Epoch 58: Val Loss 6812121.00000
Epoch 59: Val Loss 6759897.00000
Epoch 60: Val Loss 6686402.50000
Epoch 61: Val Loss 6655650.00000
Epoch 62: Val Loss 6523544.00000
Epoch 63: Val Loss 6451318.50000
Epoch 64: Val Loss 6405315.50000
Epoch 65: Val Loss 6337927.50000
Epoch 66: Val Loss 6281298.00000
Epoch 67: Val Loss 6242894.50000
Epoch 68: Val Loss 6151702.00000
Epoch 69: Val Loss 6097812.50000
Epoch 70: Val Loss 6057766.00000
Epoch 71: Val Loss 5997131.50000
Epoch 72: Val Loss 5934561.00000
Epoch 73: Val Loss 5947042.00000
Epoch 74: Val Loss 5877753.50000
Epoch 75: Val Loss 5807634.50000
Epoch 76: Val Loss 5762696.50000
Epoch 77: Val Loss 5727886.00000
Epoch 78: Val Loss 5704623.50000
Epoch 79: Val Loss 5658226.50000
Epoch 80: Val Loss 5633760.50000
Epoch 81: Val Loss 5602471.00000
Epoch 82: Val Loss 5607968.50000
Epoch 83: Val Loss 5533868.50000
Epoch 84: Val Loss 5504178.50000
Epoch 85: Val Loss 5476089.50000
Epoch 86: Val Loss 5447332.00000
Epoch 87: Val Loss 5452446.00000
Epoch 88: Val Loss 5403091.50000
Epoch 89: Val Loss 5369482.50000
Epoch 90: Val Loss 5393163.50000
Epoch 91: Val Loss 5329617.50000
Epoch 92: Val Loss 5304874.50000
Epoch 93: Val Loss 5302936.50000
Epoch 94: Val Loss 5284196.00000
Epoch 95: Val Loss 5260924.50000
Epoch 96: Val Loss 5267910.00000
Epoch 97: Val Loss 5218853.50000
Epoch 98: Val Loss 5197891.00000
Epoch 99: Val Loss 5188587.00000
Saved Losses
{'MSE - mean': 4832867.254559209, 'MSE - std': 298556.6727039824, 'R2 - mean': 0.43145260105850297, 'R2 - std': 0.00979248931589703} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 17806888.00000
Epoch 1: Val Loss 17559088.00000
Epoch 2: Val Loss 17210450.00000
Epoch 3: Val Loss 16782986.00000
Epoch 4: Val Loss 16171996.00000
Epoch 5: Val Loss 15213143.00000
Epoch 6: Val Loss 14323285.00000
Epoch 7: Val Loss 13300293.00000
Epoch 8: Val Loss 12251951.00000
Epoch 9: Val Loss 11177013.00000
Epoch 10: Val Loss 10259835.00000
Epoch 11: Val Loss 9482317.00000
Epoch 12: Val Loss 9005479.00000
Epoch 13: Val Loss 8683425.00000
Epoch 14: Val Loss 8589096.00000
Epoch 15: Val Loss 8549010.00000
Epoch 16: Val Loss 8545343.00000
Epoch 17: Val Loss 8508147.00000
Epoch 18: Val Loss 8573356.00000
Epoch 19: Val Loss 8434550.00000
Epoch 20: Val Loss 8457566.00000
Epoch 21: Val Loss 8410670.00000
Epoch 22: Val Loss 8456193.00000
Epoch 23: Val Loss 8353614.00000
Epoch 24: Val Loss 8279085.00000
Epoch 25: Val Loss 8243328.00000
Epoch 26: Val Loss 8246529.00000
Epoch 27: Val Loss 8177223.00000
Epoch 28: Val Loss 8200725.00000
Epoch 29: Val Loss 8128253.50000
Epoch 30: Val Loss 8079971.50000
Epoch 31: Val Loss 8074270.50000
Epoch 32: Val Loss 8019156.00000
Epoch 33: Val Loss 7984237.00000
Epoch 34: Val Loss 7937552.00000
Epoch 35: Val Loss 7889616.00000
Epoch 36: Val Loss 7865112.50000
Epoch 37: Val Loss 7819266.00000
Epoch 38: Val Loss 7778351.00000
Epoch 39: Val Loss 7739740.00000
Epoch 40: Val Loss 7702892.50000
Epoch 41: Val Loss 7647305.50000
Epoch 42: Val Loss 7598304.00000
Epoch 43: Val Loss 7538109.50000
Epoch 44: Val Loss 7504726.50000
Epoch 45: Val Loss 7432975.50000
Epoch 46: Val Loss 7391063.50000
Epoch 47: Val Loss 7324066.00000
Epoch 48: Val Loss 7268393.00000
Epoch 49: Val Loss 7214409.50000
Epoch 50: Val Loss 7324094.50000
Epoch 51: Val Loss 7087839.50000
Epoch 52: Val Loss 7016517.00000
Epoch 53: Val Loss 6949151.50000
Epoch 54: Val Loss 6879982.50000
Epoch 55: Val Loss 6811277.00000
Epoch 56: Val Loss 6751679.00000
Epoch 57: Val Loss 6678690.00000
Epoch 58: Val Loss 6615285.00000
Epoch 59: Val Loss 6579628.00000
Epoch 60: Val Loss 6485451.50000
Epoch 61: Val Loss 6411342.00000
Epoch 62: Val Loss 6351378.50000
Epoch 63: Val Loss 6271655.50000
Epoch 64: Val Loss 6209153.00000
Epoch 65: Val Loss 6134109.00000
Epoch 66: Val Loss 6080328.50000
Epoch 67: Val Loss 5998364.50000
Epoch 68: Val Loss 6028902.00000
Epoch 69: Val Loss 5903873.00000
Epoch 70: Val Loss 5841243.00000
Epoch 71: Val Loss 5764210.00000
Epoch 72: Val Loss 5717237.50000
Epoch 73: Val Loss 5667419.50000
Epoch 74: Val Loss 5641302.00000
Epoch 75: Val Loss 5566110.50000
Epoch 76: Val Loss 5524192.50000
Epoch 77: Val Loss 5486028.00000
Epoch 78: Val Loss 5444937.00000
Epoch 79: Val Loss 5404559.50000
Epoch 80: Val Loss 5466185.00000
Epoch 81: Val Loss 5320579.50000
Epoch 82: Val Loss 5286933.50000
Epoch 83: Val Loss 5358204.00000
Epoch 84: Val Loss 5224929.00000
Epoch 85: Val Loss 5192878.50000
Epoch 86: Val Loss 5178576.00000
Epoch 87: Val Loss 5133866.00000
Epoch 88: Val Loss 5116179.00000
Epoch 89: Val Loss 5085392.00000
Epoch 90: Val Loss 5070332.00000
Epoch 91: Val Loss 5036909.00000
Epoch 92: Val Loss 5015249.50000
Epoch 93: Val Loss 4993138.50000
Epoch 94: Val Loss 4964821.00000
Epoch 95: Val Loss 4995337.00000
Epoch 96: Val Loss 4976767.50000
Epoch 97: Val Loss 4931760.50000
Epoch 98: Val Loss 4888854.00000
Epoch 99: Val Loss 4904188.50000
Saved Losses
{'MSE - mean': 4850800.581971366, 'MSE - std': 260416.73872520082, 'R2 - mean': 0.43078910247311575, 'R2 - std': 0.008558056226147418} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 17171794.00000
Epoch 1: Val Loss 17109610.00000
Epoch 2: Val Loss 16549058.00000
Epoch 3: Val Loss 16143625.00000
Epoch 4: Val Loss 15531596.00000
Epoch 5: Val Loss 14753118.00000
Epoch 6: Val Loss 13760704.00000
Epoch 7: Val Loss 12788549.00000
Epoch 8: Val Loss 11710348.00000
Epoch 9: Val Loss 10790455.00000
Epoch 10: Val Loss 9773119.00000
Epoch 11: Val Loss 9005573.00000
Epoch 12: Val Loss 8451784.00000
Epoch 13: Val Loss 8251152.00000
Epoch 14: Val Loss 8103412.00000
Epoch 15: Val Loss 8098563.50000
Epoch 16: Val Loss 8052752.00000
Epoch 17: Val Loss 8004718.00000
Epoch 18: Val Loss 8009929.50000
Epoch 19: Val Loss 7963583.50000
Epoch 20: Val Loss 7942531.00000
Epoch 21: Val Loss 7952483.00000
Epoch 22: Val Loss 7880537.50000
Epoch 23: Val Loss 7836766.50000
Epoch 24: Val Loss 7801931.50000
Epoch 25: Val Loss 7787049.00000
Epoch 26: Val Loss 7758652.50000
Epoch 27: Val Loss 7708899.00000
Epoch 28: Val Loss 7683869.50000
Epoch 29: Val Loss 7649198.00000
Epoch 30: Val Loss 7605789.50000
Epoch 31: Val Loss 7583120.50000
Epoch 32: Val Loss 7549628.50000
Epoch 33: Val Loss 7505010.50000
Epoch 34: Val Loss 7464119.50000
Epoch 35: Val Loss 7435223.50000
Epoch 36: Val Loss 7392556.50000
Epoch 37: Val Loss 7441901.00000
Epoch 38: Val Loss 7321654.50000
Epoch 39: Val Loss 7277862.00000
Epoch 40: Val Loss 7239583.00000
Epoch 41: Val Loss 7311496.00000
Epoch 42: Val Loss 7156992.00000
Epoch 43: Val Loss 7112474.50000
Epoch 44: Val Loss 7070552.00000
Epoch 45: Val Loss 7001911.50000
Epoch 46: Val Loss 6932031.50000
Epoch 47: Val Loss 6876515.00000
Epoch 48: Val Loss 6835561.00000
Epoch 49: Val Loss 6787350.50000
Epoch 50: Val Loss 6703414.00000
Epoch 51: Val Loss 6664406.00000
Epoch 52: Val Loss 6610600.50000
Epoch 53: Val Loss 6590786.00000
Epoch 54: Val Loss 6485671.50000
Epoch 55: Val Loss 6395409.00000
Epoch 56: Val Loss 6335981.00000
Epoch 57: Val Loss 6269074.50000
Epoch 58: Val Loss 6281217.50000
Epoch 59: Val Loss 6138956.50000
Epoch 60: Val Loss 6144353.50000
Epoch 61: Val Loss 6000281.00000
Epoch 62: Val Loss 5935229.00000
Epoch 63: Val Loss 5865711.50000
Epoch 64: Val Loss 5784101.50000
Epoch 65: Val Loss 5719511.50000
Epoch 66: Val Loss 5693345.50000
Epoch 67: Val Loss 5589176.00000
Epoch 68: Val Loss 5569997.50000
Epoch 69: Val Loss 5461612.00000
Epoch 70: Val Loss 5410174.50000
Epoch 71: Val Loss 5352441.00000
Epoch 72: Val Loss 5306617.50000
Epoch 73: Val Loss 5235595.50000
Epoch 74: Val Loss 5188118.50000
Epoch 75: Val Loss 5132876.00000
Epoch 76: Val Loss 5089517.50000
Epoch 77: Val Loss 5045926.50000
Epoch 78: Val Loss 5014600.00000
Epoch 79: Val Loss 4985126.00000
Epoch 80: Val Loss 4921505.00000
Epoch 81: Val Loss 4890420.00000
Epoch 82: Val Loss 4859676.00000
Epoch 83: Val Loss 4825430.50000
Epoch 84: Val Loss 4787634.50000
Epoch 85: Val Loss 4767057.50000
Epoch 86: Val Loss 4732545.00000
Epoch 87: Val Loss 4702463.00000
Epoch 88: Val Loss 4666711.50000
Epoch 89: Val Loss 4637980.00000
Epoch 90: Val Loss 4628303.00000
Epoch 91: Val Loss 4605335.00000
Epoch 92: Val Loss 4575996.50000
Epoch 93: Val Loss 4535327.00000
Epoch 94: Val Loss 4522974.00000
Epoch 95: Val Loss 4488732.00000
Epoch 96: Val Loss 4474439.50000
Epoch 97: Val Loss 4475193.50000
Epoch 98: Val Loss 4441285.00000
Epoch 99: Val Loss 4422461.00000
Saved Losses
{'MSE - mean': 4766123.44097834, 'MSE - std': 287983.289573591, 'R2 - mean': 0.43529325163896376, 'R2 - std': 0.011821239356715418} 
 

Saving model.....
Results After CV: {'MSE - mean': 4766123.44097834, 'MSE - std': 287983.289573591, 'R2 - mean': 0.43529325163896376, 'R2 - std': 0.011821239356715418}
Train time: 7738.597110906592
Inference time: 6.921068791206926
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 38 finished with value: 4766123.44097834 and parameters: {'dim': 32, 'depth': 6, 'heads': 2, 'weight_decay': -1, 'learning_rate': -6, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3973393.75000
Epoch 1: Val Loss 3726238.75000
Epoch 2: Val Loss 3691246.75000
Epoch 3: Val Loss 3600219.00000
Epoch 4: Val Loss 3557683.50000
Epoch 5: Val Loss 3510880.25000
Epoch 6: Val Loss 3472150.75000
Epoch 7: Val Loss 3450694.75000
Epoch 8: Val Loss 3463268.50000
Epoch 9: Val Loss 3432795.75000
Epoch 10: Val Loss 3419750.25000
Epoch 11: Val Loss 3460274.25000
Epoch 12: Val Loss 3441797.25000
Epoch 13: Val Loss 3494942.50000
Epoch 14: Val Loss 3508724.75000
Epoch 15: Val Loss 3638407.50000
Epoch 16: Val Loss 3593428.25000
Epoch 17: Val Loss 3692721.75000
Epoch 18: Val Loss 3767131.75000
Epoch 19: Val Loss 3919412.50000
Epoch 20: Val Loss 3860915.50000
Epoch 21: Val Loss 3895686.50000
Epoch 22: Val Loss 3920254.75000
Epoch 23: Val Loss 3996740.75000
Epoch 24: Val Loss 4015134.25000
Epoch 25: Val Loss 3978851.50000
Epoch 26: Val Loss 4147766.25000
Epoch 27: Val Loss 4091491.25000
Epoch 28: Val Loss 4249633.50000
Epoch 29: Val Loss 4299829.00000
Epoch 30: Val Loss 4278624.00000
Epoch 31: Val Loss 4223649.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3408121.2519142437, 'MSE - std': 0.0, 'R2 - mean': 0.6006854420545583, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3681506.75000
Epoch 1: Val Loss 3632659.50000
Epoch 2: Val Loss 3560501.75000
Epoch 3: Val Loss 3541154.75000
Epoch 4: Val Loss 3532915.50000
Epoch 5: Val Loss 3452011.00000
Epoch 6: Val Loss 3435523.25000
Epoch 7: Val Loss 3507348.25000
Epoch 8: Val Loss 3425551.75000
Epoch 9: Val Loss 3405617.75000
Epoch 10: Val Loss 3412396.50000
Epoch 11: Val Loss 3424601.25000
Epoch 12: Val Loss 3549668.75000
Epoch 13: Val Loss 3481819.00000
Epoch 14: Val Loss 3471300.50000
Epoch 15: Val Loss 3604214.25000
Epoch 16: Val Loss 3587248.00000
Epoch 17: Val Loss 3559384.50000
Epoch 18: Val Loss 3709069.50000
Epoch 19: Val Loss 3628981.75000
Epoch 20: Val Loss 3705027.00000
Epoch 21: Val Loss 3751092.00000
Epoch 22: Val Loss 3827375.75000
Epoch 23: Val Loss 3920655.25000
Epoch 24: Val Loss 3887458.75000
Epoch 25: Val Loss 4023428.75000
Epoch 26: Val Loss 4080274.75000
Epoch 27: Val Loss 4074841.50000
Epoch 28: Val Loss 4014384.50000
Epoch 29: Val Loss 4182780.75000
Epoch 30: Val Loss 4137000.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3405953.563408097, 'MSE - std': 2167.688506146893, 'R2 - mean': 0.5878161236408912, 'R2 - std': 0.012869318413667119} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4354349.50000
Epoch 1: Val Loss 4243011.00000
Epoch 2: Val Loss 4183875.50000
Epoch 3: Val Loss 4066669.00000
Epoch 4: Val Loss 4039870.00000
Epoch 5: Val Loss 4015721.25000
Epoch 6: Val Loss 3973435.75000
Epoch 7: Val Loss 3919703.00000
Epoch 8: Val Loss 4044272.00000
Epoch 9: Val Loss 3947579.00000
Epoch 10: Val Loss 3920361.25000
Epoch 11: Val Loss 3875061.75000
Epoch 12: Val Loss 3895767.00000
Epoch 13: Val Loss 3895659.00000
Epoch 14: Val Loss 3891687.00000
Epoch 15: Val Loss 3918395.00000
Epoch 16: Val Loss 3996747.00000
Epoch 17: Val Loss 4025089.00000
Epoch 18: Val Loss 4118603.75000
Epoch 19: Val Loss 4142487.50000
Epoch 20: Val Loss 4206246.00000
Epoch 21: Val Loss 4238071.00000
Epoch 22: Val Loss 4336272.00000
Epoch 23: Val Loss 4436949.50000
Epoch 24: Val Loss 4517804.00000
Epoch 25: Val Loss 4483821.00000
Epoch 26: Val Loss 4625743.00000
Epoch 27: Val Loss 4666379.50000
Epoch 28: Val Loss 4596437.00000
Epoch 29: Val Loss 4848600.00000
Epoch 30: Val Loss 4759180.00000
Epoch 31: Val Loss 4810605.50000
Epoch 32: Val Loss 4853958.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3565061.7146120793, 'MSE - std': 225019.86610387336, 'R2 - mean': 0.5804059274753662, 'R2 - std': 0.01484031396943319} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4041934.00000
Epoch 1: Val Loss 3935752.75000
Epoch 2: Val Loss 3855229.50000
Epoch 3: Val Loss 3859055.75000
Epoch 4: Val Loss 3831517.00000
Epoch 5: Val Loss 3779275.00000
Epoch 6: Val Loss 3775618.25000
Epoch 7: Val Loss 3753688.75000
Epoch 8: Val Loss 3969804.75000
Epoch 9: Val Loss 3828344.75000
Epoch 10: Val Loss 3759246.00000
Epoch 11: Val Loss 3932242.25000
Epoch 12: Val Loss 3857754.50000
Epoch 13: Val Loss 3876980.50000
Epoch 14: Val Loss 3996151.50000
Epoch 15: Val Loss 3979646.75000
Epoch 16: Val Loss 4164733.50000
Epoch 17: Val Loss 4079422.00000
Epoch 18: Val Loss 4231165.00000
Epoch 19: Val Loss 4252662.00000
Epoch 20: Val Loss 4188088.00000
Epoch 21: Val Loss 4341572.00000
Epoch 22: Val Loss 4277942.50000
Epoch 23: Val Loss 4416796.00000
Epoch 24: Val Loss 4476132.50000
Epoch 25: Val Loss 4530902.50000
Epoch 26: Val Loss 4522608.00000
Epoch 27: Val Loss 4576268.00000
Epoch 28: Val Loss 4555346.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3612772.962542647, 'MSE - std': 211670.84032367362, 'R2 - mean': 0.5759489988370371, 'R2 - std': 0.01499229227619955} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3575825.25000
Epoch 1: Val Loss 3546367.50000
Epoch 2: Val Loss 3974857.25000
Epoch 3: Val Loss 3741728.50000
Epoch 4: Val Loss 3578966.00000
Epoch 5: Val Loss 3468092.00000
Epoch 6: Val Loss 3486358.00000
Epoch 7: Val Loss 3688450.25000
Epoch 8: Val Loss 3451273.50000
Epoch 9: Val Loss 3529019.75000
Epoch 10: Val Loss 3423076.50000
Epoch 11: Val Loss 3506821.25000
Epoch 12: Val Loss 3699720.75000
Epoch 13: Val Loss 3662754.25000
Epoch 14: Val Loss 3458927.75000
Epoch 15: Val Loss 3464510.75000
Epoch 16: Val Loss 3598844.75000
Epoch 17: Val Loss 3543882.25000
Epoch 18: Val Loss 3641505.00000
Epoch 19: Val Loss 3650655.75000
Epoch 20: Val Loss 3727679.75000
Epoch 21: Val Loss 3760196.00000
Epoch 22: Val Loss 3812678.25000
Epoch 23: Val Loss 3790072.25000
Epoch 24: Val Loss 3969412.00000
Epoch 25: Val Loss 3860443.75000
Epoch 26: Val Loss 4054257.00000
Epoch 27: Val Loss 4085323.00000
Epoch 28: Val Loss 4053477.25000
Epoch 29: Val Loss 4156795.25000
Epoch 30: Val Loss 4300889.00000
Epoch 31: Val Loss 4214213.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3574285.4658692544, 'MSE - std': 204374.13073919545, 'R2 - mean': 0.5762916813911524, 'R2 - std': 0.01342701707333293} 
 

Saving model.....
Results After CV: {'MSE - mean': 3574285.4658692544, 'MSE - std': 204374.13073919545, 'R2 - mean': 0.5762916813911524, 'R2 - std': 0.01342701707333293}
Train time: 2340.0915924252013
Inference time: 6.543954798788763
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 39 finished with value: 3574285.4658692544 and parameters: {'dim': 32, 'depth': 6, 'heads': 8, 'weight_decay': -2, 'learning_rate': -3, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4518165.00000
Epoch 1: Val Loss 4060439.50000
Epoch 2: Val Loss 3951726.75000
Epoch 3: Val Loss 3890079.25000
Epoch 4: Val Loss 3843353.50000
Epoch 5: Val Loss 3813933.50000
Epoch 6: Val Loss 3773165.50000
Epoch 7: Val Loss 3748075.00000
Epoch 8: Val Loss 3712572.25000
Epoch 9: Val Loss 3691347.00000
Epoch 10: Val Loss 3676777.25000
Epoch 11: Val Loss 3652816.00000
Epoch 12: Val Loss 3636505.25000
Epoch 13: Val Loss 3631906.25000
Epoch 14: Val Loss 3617616.25000
Epoch 15: Val Loss 3592050.00000
Epoch 16: Val Loss 3583089.75000
Epoch 17: Val Loss 3584545.50000
Epoch 18: Val Loss 3580238.25000
Epoch 19: Val Loss 3570497.50000
Epoch 20: Val Loss 3638517.75000
Epoch 21: Val Loss 3604030.25000
Epoch 22: Val Loss 3533128.75000
Epoch 23: Val Loss 3522623.00000
Epoch 24: Val Loss 3534505.50000
Epoch 25: Val Loss 3533625.50000
Epoch 26: Val Loss 3521067.75000
Epoch 27: Val Loss 3535400.00000
Epoch 28: Val Loss 3491609.50000
Epoch 29: Val Loss 3491716.75000
Epoch 30: Val Loss 3491305.50000
Epoch 31: Val Loss 3485965.50000
Epoch 32: Val Loss 3519783.75000
Epoch 33: Val Loss 3474484.25000
Epoch 34: Val Loss 3473848.75000
Epoch 35: Val Loss 3471611.25000
Epoch 36: Val Loss 3481349.50000
Epoch 37: Val Loss 3465851.50000
Epoch 38: Val Loss 3443985.50000
Epoch 39: Val Loss 3483636.50000
Epoch 40: Val Loss 3471589.25000
Epoch 41: Val Loss 3515355.00000
Epoch 42: Val Loss 3452615.50000
Epoch 43: Val Loss 3437427.25000
Epoch 44: Val Loss 3469367.50000
Epoch 45: Val Loss 3445531.25000
Epoch 46: Val Loss 3467133.00000
Epoch 47: Val Loss 3452264.00000
Epoch 48: Val Loss 3432168.75000
Epoch 49: Val Loss 3423318.25000
Epoch 50: Val Loss 3445021.25000
Epoch 51: Val Loss 3416519.75000
Epoch 52: Val Loss 3463895.00000
Epoch 53: Val Loss 3452622.50000
Epoch 54: Val Loss 3433174.75000
Epoch 55: Val Loss 3442369.50000
Epoch 56: Val Loss 3489083.00000
Epoch 57: Val Loss 3425230.00000
Epoch 58: Val Loss 3445004.75000
Epoch 59: Val Loss 3515376.50000
Epoch 60: Val Loss 3450673.25000
Epoch 61: Val Loss 3416140.00000
Epoch 62: Val Loss 3488173.00000
Epoch 63: Val Loss 3426096.25000
Epoch 64: Val Loss 3443381.00000
Epoch 65: Val Loss 3438710.50000
Epoch 66: Val Loss 3434092.25000
Epoch 67: Val Loss 3446212.50000
Epoch 68: Val Loss 3453294.50000
Epoch 69: Val Loss 3425172.50000
Epoch 70: Val Loss 3467310.25000
Epoch 71: Val Loss 3450081.50000
Epoch 72: Val Loss 3441777.00000
Epoch 73: Val Loss 3469045.25000
Epoch 74: Val Loss 3448296.50000
Epoch 75: Val Loss 3458059.00000
Epoch 76: Val Loss 3461881.25000
Epoch 77: Val Loss 3481674.50000
Epoch 78: Val Loss 3501194.00000
Epoch 79: Val Loss 3552251.00000
Epoch 80: Val Loss 3452540.75000
Epoch 81: Val Loss 3441892.25000
Epoch 82: Val Loss 3485831.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3429170.8374871495, 'MSE - std': 0.0, 'R2 - mean': 0.5982191548139684, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4215517.00000
Epoch 1: Val Loss 3861043.00000
Epoch 2: Val Loss 3779073.50000
Epoch 3: Val Loss 3735841.00000
Epoch 4: Val Loss 3690832.50000
Epoch 5: Val Loss 3684255.25000
Epoch 6: Val Loss 3622845.00000
Epoch 7: Val Loss 3603261.00000
Epoch 8: Val Loss 3603438.75000
Epoch 9: Val Loss 3559630.75000
Epoch 10: Val Loss 3552624.75000
Epoch 11: Val Loss 3553156.75000
Epoch 12: Val Loss 3535082.25000
Epoch 13: Val Loss 3536606.75000
Epoch 14: Val Loss 3513091.50000
Epoch 15: Val Loss 3495791.75000
Epoch 16: Val Loss 3505139.50000
Epoch 17: Val Loss 3533454.75000
Epoch 18: Val Loss 3478475.75000
Epoch 19: Val Loss 3496930.00000
Epoch 20: Val Loss 3476509.25000
Epoch 21: Val Loss 3464999.75000
Epoch 22: Val Loss 3482170.50000
Epoch 23: Val Loss 3457083.25000
Epoch 24: Val Loss 3451113.25000
Epoch 25: Val Loss 3499277.50000
Epoch 26: Val Loss 3482501.00000
Epoch 27: Val Loss 3483529.50000
Epoch 28: Val Loss 3437254.00000
Epoch 29: Val Loss 3416942.25000
Epoch 30: Val Loss 3427510.25000
Epoch 31: Val Loss 3409039.75000
Epoch 32: Val Loss 3440415.75000
Epoch 33: Val Loss 3407096.00000
Epoch 34: Val Loss 3410997.25000
Epoch 35: Val Loss 3412179.00000
Epoch 36: Val Loss 3500198.75000
Epoch 37: Val Loss 3430055.25000
Epoch 38: Val Loss 3463528.75000
Epoch 39: Val Loss 3491108.50000
Epoch 40: Val Loss 3387479.00000
Epoch 41: Val Loss 3520686.75000
Epoch 42: Val Loss 3404196.50000
Epoch 43: Val Loss 3410633.25000
Epoch 44: Val Loss 3389390.75000
Epoch 45: Val Loss 3399644.75000
Epoch 46: Val Loss 3434756.25000
Epoch 47: Val Loss 3474739.00000
Epoch 48: Val Loss 3417418.75000
Epoch 49: Val Loss 3421826.00000
Epoch 50: Val Loss 3409817.50000
Epoch 51: Val Loss 3402470.75000
Epoch 52: Val Loss 3476227.00000
Epoch 53: Val Loss 3419713.25000
Epoch 54: Val Loss 3388893.75000
Epoch 55: Val Loss 3423075.25000
Epoch 56: Val Loss 3415119.75000
Epoch 57: Val Loss 3391529.75000
Epoch 58: Val Loss 3405696.00000
Epoch 59: Val Loss 3399467.75000
Epoch 60: Val Loss 3388465.00000
Epoch 61: Val Loss 3415778.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3412402.8310100557, 'MSE - std': 16768.006477093557, 'R2 - mean': 0.5870919177339875, 'R2 - std': 0.011127237079980923} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4964396.00000
Epoch 1: Val Loss 4551160.00000
Epoch 2: Val Loss 4481150.50000
Epoch 3: Val Loss 4385822.00000
Epoch 4: Val Loss 4476677.50000
Epoch 5: Val Loss 4294256.00000
Epoch 6: Val Loss 4263347.00000
Epoch 7: Val Loss 4245467.50000
Epoch 8: Val Loss 4211193.00000
Epoch 9: Val Loss 4200809.50000
Epoch 10: Val Loss 4171705.25000
Epoch 11: Val Loss 4139130.00000
Epoch 12: Val Loss 4133089.50000
Epoch 13: Val Loss 4133952.50000
Epoch 14: Val Loss 4109884.75000
Epoch 15: Val Loss 4129457.00000
Epoch 16: Val Loss 4078816.00000
Epoch 17: Val Loss 4061546.00000
Epoch 18: Val Loss 4057946.00000
Epoch 19: Val Loss 4054024.00000
Epoch 20: Val Loss 4049315.50000
Epoch 21: Val Loss 4024292.00000
Epoch 22: Val Loss 4042227.50000
Epoch 23: Val Loss 4018442.50000
Epoch 24: Val Loss 4030637.50000
Epoch 25: Val Loss 3991650.75000
Epoch 26: Val Loss 4016344.75000
Epoch 27: Val Loss 4024844.75000
Epoch 28: Val Loss 3978096.50000
Epoch 29: Val Loss 3975915.75000
Epoch 30: Val Loss 3989266.75000
Epoch 31: Val Loss 3960302.25000
Epoch 32: Val Loss 3983840.50000
Epoch 33: Val Loss 3959538.75000
Epoch 34: Val Loss 3945666.75000
Epoch 35: Val Loss 3968470.25000
Epoch 36: Val Loss 3936356.00000
Epoch 37: Val Loss 3969400.75000
Epoch 38: Val Loss 3929276.25000
Epoch 39: Val Loss 3916943.75000
Epoch 40: Val Loss 3961455.25000
Epoch 41: Val Loss 3909477.25000
Epoch 42: Val Loss 3934618.00000
Epoch 43: Val Loss 3907105.00000
Epoch 44: Val Loss 3900828.75000
Epoch 45: Val Loss 3894512.50000
Epoch 46: Val Loss 3893401.50000
Epoch 47: Val Loss 3918527.25000
Epoch 48: Val Loss 3898276.75000
Epoch 49: Val Loss 3874513.00000
Epoch 50: Val Loss 3879689.50000
Epoch 51: Val Loss 3866457.25000
Epoch 52: Val Loss 3884555.00000
Epoch 53: Val Loss 3869557.75000
Epoch 54: Val Loss 3874853.75000
Epoch 55: Val Loss 3888832.50000
Epoch 56: Val Loss 3877832.75000
Epoch 57: Val Loss 3864366.25000
Epoch 58: Val Loss 3889137.00000
Epoch 59: Val Loss 3858302.75000
Epoch 60: Val Loss 3854702.25000
Epoch 61: Val Loss 3874916.00000
Epoch 62: Val Loss 3854949.75000
Epoch 63: Val Loss 3865732.00000
Epoch 64: Val Loss 3845396.50000
Epoch 65: Val Loss 3855662.00000
Epoch 66: Val Loss 3889479.00000
Epoch 67: Val Loss 3871984.50000
Epoch 68: Val Loss 3849140.50000
Epoch 69: Val Loss 3859501.50000
Epoch 70: Val Loss 3848512.50000
Epoch 71: Val Loss 3858105.25000
Epoch 72: Val Loss 3914138.00000
Epoch 73: Val Loss 3859818.00000
Epoch 74: Val Loss 3881909.75000
Epoch 75: Val Loss 3843989.75000
Epoch 76: Val Loss 3857876.00000
Epoch 77: Val Loss 3841672.00000
Epoch 78: Val Loss 3838593.75000
Epoch 79: Val Loss 3850744.00000
Epoch 80: Val Loss 3845345.75000
Epoch 81: Val Loss 3861691.75000
Epoch 82: Val Loss 3849070.00000
Epoch 83: Val Loss 3890158.75000
Epoch 84: Val Loss 3853448.25000
Epoch 85: Val Loss 3874644.00000
Epoch 86: Val Loss 3854910.25000
Epoch 87: Val Loss 3871044.00000
Epoch 88: Val Loss 3863392.50000
Epoch 89: Val Loss 3874078.25000
Epoch 90: Val Loss 3879200.50000
Epoch 91: Val Loss 3917260.75000
Epoch 92: Val Loss 3886785.00000
Epoch 93: Val Loss 3881601.75000
Epoch 94: Val Loss 3889072.50000
Epoch 95: Val Loss 3898251.75000
Epoch 96: Val Loss 3900255.25000
Epoch 97: Val Loss 3917861.75000
Epoch 98: Val Loss 3900468.50000
Epoch 99: Val Loss 3911989.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3558162.389254628, 'MSE - std': 206589.30675807814, 'R2 - mean': 0.5811759148135235, 'R2 - std': 0.012350780722931897} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4602659.50000
Epoch 1: Val Loss 4207056.00000
Epoch 2: Val Loss 4120850.25000
Epoch 3: Val Loss 4060815.25000
Epoch 4: Val Loss 4105111.50000
Epoch 5: Val Loss 4019056.00000
Epoch 6: Val Loss 4011571.00000
Epoch 7: Val Loss 3963266.25000
Epoch 8: Val Loss 3936291.50000
Epoch 9: Val Loss 3964684.75000
Epoch 10: Val Loss 3896687.75000
Epoch 11: Val Loss 3886481.00000
Epoch 12: Val Loss 3856089.25000
Epoch 13: Val Loss 3871501.00000
Epoch 14: Val Loss 3861123.50000
Epoch 15: Val Loss 3831382.50000
Epoch 16: Val Loss 3861665.50000
Epoch 17: Val Loss 3820292.50000
Epoch 18: Val Loss 3818894.00000
Epoch 19: Val Loss 3796074.50000
Epoch 20: Val Loss 3817627.00000
Epoch 21: Val Loss 3781453.00000
Epoch 22: Val Loss 3798338.25000
Epoch 23: Val Loss 3791817.25000
Epoch 24: Val Loss 3804688.00000
Epoch 25: Val Loss 3751857.50000
Epoch 26: Val Loss 3752964.00000
Epoch 27: Val Loss 3752253.00000
Epoch 28: Val Loss 3770128.50000
Epoch 29: Val Loss 3736247.50000
Epoch 30: Val Loss 3755646.25000
Epoch 31: Val Loss 3750111.75000
Epoch 32: Val Loss 3740223.25000
Epoch 33: Val Loss 3715449.50000
Epoch 34: Val Loss 3747508.00000
Epoch 35: Val Loss 3782114.25000
Epoch 36: Val Loss 3718551.50000
Epoch 37: Val Loss 3717680.50000
Epoch 38: Val Loss 3706864.00000
Epoch 39: Val Loss 3717334.50000
Epoch 40: Val Loss 3732481.50000
Epoch 41: Val Loss 3713970.25000
Epoch 42: Val Loss 3711280.00000
Epoch 43: Val Loss 3732031.75000
Epoch 44: Val Loss 3748918.25000
Epoch 45: Val Loss 3704349.00000
Epoch 46: Val Loss 3744702.00000
Epoch 47: Val Loss 3732215.00000
Epoch 48: Val Loss 3712718.00000
Epoch 49: Val Loss 3707446.25000
Epoch 50: Val Loss 3710351.75000
Epoch 51: Val Loss 3725662.75000
Epoch 52: Val Loss 3738306.75000
Epoch 53: Val Loss 3760923.75000
Epoch 54: Val Loss 3743028.50000
Epoch 55: Val Loss 3753988.50000
Epoch 56: Val Loss 3713148.25000
Epoch 57: Val Loss 3720562.75000
Epoch 58: Val Loss 3736535.00000
Epoch 59: Val Loss 3777489.75000
Epoch 60: Val Loss 3735563.25000
Epoch 61: Val Loss 3714339.00000
Epoch 62: Val Loss 3743292.25000
Epoch 63: Val Loss 3732873.50000
Epoch 64: Val Loss 3770354.25000
Epoch 65: Val Loss 3775697.00000
Epoch 66: Val Loss 3760824.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3596000.175486236, 'MSE - std': 190537.26787905267, 'R2 - mean': 0.5778772540066998, 'R2 - std': 0.012126410338797057} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4121996.25000
Epoch 1: Val Loss 3731290.00000
Epoch 2: Val Loss 3617202.25000
Epoch 3: Val Loss 3588286.25000
Epoch 4: Val Loss 3535847.75000
Epoch 5: Val Loss 3564873.50000
Epoch 6: Val Loss 3501243.00000
Epoch 7: Val Loss 3490095.50000
Epoch 8: Val Loss 3484273.00000
Epoch 9: Val Loss 3467647.00000
Epoch 10: Val Loss 3443409.25000
Epoch 11: Val Loss 3450156.00000
Epoch 12: Val Loss 3426187.25000
Epoch 13: Val Loss 3442073.50000
Epoch 14: Val Loss 3407932.75000
Epoch 15: Val Loss 3424688.00000
Epoch 16: Val Loss 3436341.75000
Epoch 17: Val Loss 3412224.00000
Epoch 18: Val Loss 3399279.25000
Epoch 19: Val Loss 3411347.75000
Epoch 20: Val Loss 3443889.75000
Epoch 21: Val Loss 3428138.00000
Epoch 22: Val Loss 3435639.75000
Epoch 23: Val Loss 3462556.50000
Epoch 24: Val Loss 3399804.25000
Epoch 25: Val Loss 3386796.75000
Epoch 26: Val Loss 3432248.75000
Epoch 27: Val Loss 3455985.75000
Epoch 28: Val Loss 3388796.25000
Epoch 29: Val Loss 3408207.00000
Epoch 30: Val Loss 3376568.75000
Epoch 31: Val Loss 3402593.00000
Epoch 32: Val Loss 3422842.50000
Epoch 33: Val Loss 3407162.50000
Epoch 34: Val Loss 3427716.50000
Epoch 35: Val Loss 3397974.25000
Epoch 36: Val Loss 3382887.75000
Epoch 37: Val Loss 3425715.50000
Epoch 38: Val Loss 3405348.25000
Epoch 39: Val Loss 3418471.25000
Epoch 40: Val Loss 3409740.50000
Epoch 41: Val Loss 3395643.00000
Epoch 42: Val Loss 3412844.50000
Epoch 43: Val Loss 3377945.25000
Epoch 44: Val Loss 3413786.75000
Epoch 45: Val Loss 3380939.50000
Epoch 46: Val Loss 3400680.75000
Epoch 47: Val Loss 3378936.75000
Epoch 48: Val Loss 3397664.25000
Epoch 49: Val Loss 3398408.00000
Epoch 50: Val Loss 3405567.25000
Epoch 51: Val Loss 3405734.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554705.017957927, 'MSE - std': 189379.83129626626, 'R2 - mean': 0.5785951864436314, 'R2 - std': 0.010940821271728258} 
 

Saving model.....
Results After CV: {'MSE - mean': 3554705.017957927, 'MSE - std': 189379.83129626626, 'R2 - mean': 0.5785951864436314, 'R2 - std': 0.010940821271728258}
Train time: 5474.035315143597
Inference time: 6.640645963628776
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 40 finished with value: 3554705.017957927 and parameters: {'dim': 32, 'depth': 6, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8830805.00000
Epoch 1: Val Loss 8250192.00000
Epoch 2: Val Loss 7846404.50000
Epoch 3: Val Loss 7289895.00000
Epoch 4: Val Loss 6615073.50000
Epoch 5: Val Loss 5833245.00000
Epoch 6: Val Loss 5307933.50000
Epoch 7: Val Loss 4965295.50000
Epoch 8: Val Loss 4773686.50000
Epoch 9: Val Loss 4613346.50000
Epoch 10: Val Loss 4523946.50000
Epoch 11: Val Loss 4450108.00000
Epoch 12: Val Loss 4395803.00000
Epoch 13: Val Loss 4338397.00000
Epoch 14: Val Loss 4329197.00000
Epoch 15: Val Loss 4282070.00000
Epoch 16: Val Loss 4261870.50000
Epoch 17: Val Loss 4236666.00000
Epoch 18: Val Loss 4193088.50000
Epoch 19: Val Loss 4232050.50000
Epoch 20: Val Loss 4140772.00000
Epoch 21: Val Loss 4156064.50000
Epoch 22: Val Loss 4112160.50000
Epoch 23: Val Loss 4101875.25000
Epoch 24: Val Loss 4079588.75000
Epoch 25: Val Loss 4073845.25000
Epoch 26: Val Loss 4090175.75000
Epoch 27: Val Loss 4052096.00000
Epoch 28: Val Loss 4039284.50000
Epoch 29: Val Loss 4013887.25000
Epoch 30: Val Loss 4015662.75000
Epoch 31: Val Loss 4002398.00000
Epoch 32: Val Loss 3994896.00000
Epoch 33: Val Loss 3976941.00000
Epoch 34: Val Loss 3975825.00000
Epoch 35: Val Loss 3974100.00000
Epoch 36: Val Loss 3961159.50000
Epoch 37: Val Loss 3946334.00000
Epoch 38: Val Loss 3956204.75000
Epoch 39: Val Loss 3929094.25000
Epoch 40: Val Loss 3923599.25000
Epoch 41: Val Loss 3916794.50000
Epoch 42: Val Loss 3914845.00000
Epoch 43: Val Loss 3900366.00000
Epoch 44: Val Loss 3896198.25000
Epoch 45: Val Loss 3915039.25000
Epoch 46: Val Loss 3878197.75000
Epoch 47: Val Loss 3890186.00000
Epoch 48: Val Loss 3869255.50000
Epoch 49: Val Loss 3865354.00000
Epoch 50: Val Loss 3867673.50000
Epoch 51: Val Loss 3868064.50000
Epoch 52: Val Loss 3845525.75000
Epoch 53: Val Loss 3841518.25000
Epoch 54: Val Loss 3848455.00000
Epoch 55: Val Loss 3831158.50000
Epoch 56: Val Loss 3822342.25000
Epoch 57: Val Loss 3817888.00000
Epoch 58: Val Loss 3847348.00000
Epoch 59: Val Loss 3813911.50000
Epoch 60: Val Loss 3805953.00000
Epoch 61: Val Loss 3797230.25000
Epoch 62: Val Loss 3817019.75000
Epoch 63: Val Loss 3794046.00000
Epoch 64: Val Loss 3795870.75000
Epoch 65: Val Loss 3797134.75000
Epoch 66: Val Loss 3779674.50000
Epoch 67: Val Loss 3773726.75000
Epoch 68: Val Loss 3789427.50000
Epoch 69: Val Loss 3786188.25000
Epoch 70: Val Loss 3766637.50000
Epoch 71: Val Loss 3758445.00000
Epoch 72: Val Loss 3764830.25000
Epoch 73: Val Loss 3767925.25000
Epoch 74: Val Loss 3762621.00000
Epoch 75: Val Loss 3764904.75000
Epoch 76: Val Loss 3759484.75000
Epoch 77: Val Loss 3739776.50000
Epoch 78: Val Loss 3737461.75000
Epoch 79: Val Loss 3738615.00000
Epoch 80: Val Loss 3741014.50000
Epoch 81: Val Loss 3735712.00000
Epoch 82: Val Loss 3732735.75000
Epoch 83: Val Loss 3748094.75000
Epoch 84: Val Loss 3739771.75000
Epoch 85: Val Loss 3724708.50000
Epoch 86: Val Loss 3720494.25000
Epoch 87: Val Loss 3723041.50000
Epoch 88: Val Loss 3784866.75000
Epoch 89: Val Loss 3722192.50000
Epoch 90: Val Loss 3715526.25000
Epoch 91: Val Loss 3733895.50000
Epoch 92: Val Loss 3708158.00000
Epoch 93: Val Loss 3721816.25000
Epoch 94: Val Loss 3700766.00000
Epoch 95: Val Loss 3701845.25000
Epoch 96: Val Loss 3706659.50000
Epoch 97: Val Loss 3706035.00000
Epoch 98: Val Loss 3706784.50000
Epoch 99: Val Loss 3710293.25000
Saved Losses
{'MSE - mean': 3714686.5921414997, 'MSE - std': 0.0, 'R2 - mean': 0.564766531233682, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8237242.00000
Epoch 1: Val Loss 7731577.50000
Epoch 2: Val Loss 7390345.00000
Epoch 3: Val Loss 6840283.00000
Epoch 4: Val Loss 6171583.50000
Epoch 5: Val Loss 5483411.00000
Epoch 6: Val Loss 4979130.00000
Epoch 7: Val Loss 4667167.00000
Epoch 8: Val Loss 4496811.50000
Epoch 9: Val Loss 4386802.50000
Epoch 10: Val Loss 4258739.50000
Epoch 11: Val Loss 4207160.50000
Epoch 12: Val Loss 4145575.50000
Epoch 13: Val Loss 4126093.50000
Epoch 14: Val Loss 4058855.00000
Epoch 15: Val Loss 4030472.75000
Epoch 16: Val Loss 4026557.50000
Epoch 17: Val Loss 3984828.25000
Epoch 18: Val Loss 3952505.50000
Epoch 19: Val Loss 3938638.75000
Epoch 20: Val Loss 3922682.00000
Epoch 21: Val Loss 3897412.00000
Epoch 22: Val Loss 3899649.00000
Epoch 23: Val Loss 3871664.00000
Epoch 24: Val Loss 3867777.00000
Epoch 25: Val Loss 3855406.25000
Epoch 26: Val Loss 3846407.50000
Epoch 27: Val Loss 3835335.00000
Epoch 28: Val Loss 3817337.25000
Epoch 29: Val Loss 3844313.25000
Epoch 30: Val Loss 3874878.25000
Epoch 31: Val Loss 3828185.25000
Epoch 32: Val Loss 3831230.00000
Epoch 33: Val Loss 3808621.00000
Epoch 34: Val Loss 3782863.25000
Epoch 35: Val Loss 3792343.00000
Epoch 36: Val Loss 3793434.50000
Epoch 37: Val Loss 3762009.25000
Epoch 38: Val Loss 3780486.50000
Epoch 39: Val Loss 3748509.00000
Epoch 40: Val Loss 3747591.50000
Epoch 41: Val Loss 3746633.25000
Epoch 42: Val Loss 3735461.75000
Epoch 43: Val Loss 3746902.25000
Epoch 44: Val Loss 3728153.50000
Epoch 45: Val Loss 3737511.00000
Epoch 46: Val Loss 3725353.25000
Epoch 47: Val Loss 3717464.75000
Epoch 48: Val Loss 3715356.75000
Epoch 49: Val Loss 3704586.00000
Epoch 50: Val Loss 3726276.50000
Epoch 51: Val Loss 3709889.75000
Epoch 52: Val Loss 3707259.00000
Epoch 53: Val Loss 3689493.75000
Epoch 54: Val Loss 3699198.25000
Epoch 55: Val Loss 3709358.00000
Epoch 56: Val Loss 3682802.25000
Epoch 57: Val Loss 3695281.50000
Epoch 58: Val Loss 3684339.50000
Epoch 59: Val Loss 3675998.75000
Epoch 60: Val Loss 3669690.50000
Epoch 61: Val Loss 3666751.75000
Epoch 62: Val Loss 3669540.75000
Epoch 63: Val Loss 3663245.00000
Epoch 64: Val Loss 3675133.50000
Epoch 65: Val Loss 3651952.50000
Epoch 66: Val Loss 3644617.50000
Epoch 67: Val Loss 3660137.25000
Epoch 68: Val Loss 3643556.75000
Epoch 69: Val Loss 3643534.25000
Epoch 70: Val Loss 3641092.00000
Epoch 71: Val Loss 3640534.50000
Epoch 72: Val Loss 3631599.75000
Epoch 73: Val Loss 3638559.25000
Epoch 74: Val Loss 3631862.50000
Epoch 75: Val Loss 3629083.25000
Epoch 76: Val Loss 3634356.75000
Epoch 77: Val Loss 3652394.00000
Epoch 78: Val Loss 3621099.75000
Epoch 79: Val Loss 3625082.75000
Epoch 80: Val Loss 3648776.25000
Epoch 81: Val Loss 3622888.75000
Epoch 82: Val Loss 3614186.75000
Epoch 83: Val Loss 3608881.75000
Epoch 84: Val Loss 3633062.25000
Epoch 85: Val Loss 3611136.75000
Epoch 86: Val Loss 3609600.50000
Epoch 87: Val Loss 3613733.00000
Epoch 88: Val Loss 3601014.50000
Epoch 89: Val Loss 3606836.75000
Epoch 90: Val Loss 3603657.75000
Epoch 91: Val Loss 3608950.75000
Epoch 92: Val Loss 3590341.00000
Epoch 93: Val Loss 3589057.50000
Epoch 94: Val Loss 3601796.75000
Epoch 95: Val Loss 3592217.75000
Epoch 96: Val Loss 3680213.25000
Epoch 97: Val Loss 3591657.25000
Epoch 98: Val Loss 3637694.75000
Epoch 99: Val Loss 3596529.25000
Saved Losses
{'MSE - mean': 3657790.505381372, 'MSE - std': 56896.08676012768, 'R2 - mean': 0.5575495462045547, 'R2 - std': 0.007216985029127376} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9094697.00000
Epoch 1: Val Loss 8805902.00000
Epoch 2: Val Loss 8417454.00000
Epoch 3: Val Loss 7673227.50000
Epoch 4: Val Loss 6998014.50000
Epoch 5: Val Loss 6242969.50000
Epoch 6: Val Loss 5743762.50000
Epoch 7: Val Loss 5432137.50000
Epoch 8: Val Loss 5221410.50000
Epoch 9: Val Loss 5121413.50000
Epoch 10: Val Loss 4984777.00000
Epoch 11: Val Loss 4889990.50000
Epoch 12: Val Loss 4821496.50000
Epoch 13: Val Loss 4766731.50000
Epoch 14: Val Loss 4728255.50000
Epoch 15: Val Loss 4753557.50000
Epoch 16: Val Loss 4667755.00000
Epoch 17: Val Loss 4631368.50000
Epoch 18: Val Loss 4609156.00000
Epoch 19: Val Loss 4587563.00000
Epoch 20: Val Loss 4572543.00000
Epoch 21: Val Loss 4557110.00000
Epoch 22: Val Loss 4542825.50000
Epoch 23: Val Loss 4512543.00000
Epoch 24: Val Loss 4502491.00000
Epoch 25: Val Loss 4492809.00000
Epoch 26: Val Loss 4497849.00000
Epoch 27: Val Loss 4468365.00000
Epoch 28: Val Loss 4481789.00000
Epoch 29: Val Loss 4470847.50000
Epoch 30: Val Loss 4442113.00000
Epoch 31: Val Loss 4466678.50000
Epoch 32: Val Loss 4444671.50000
Epoch 33: Val Loss 4419813.50000
Epoch 34: Val Loss 4430125.00000
Epoch 35: Val Loss 4421890.50000
Epoch 36: Val Loss 4401274.50000
Epoch 37: Val Loss 4395452.00000
Epoch 38: Val Loss 4382893.00000
Epoch 39: Val Loss 4409031.50000
Epoch 40: Val Loss 4383963.00000
Epoch 41: Val Loss 4372316.00000
Epoch 42: Val Loss 4372774.50000
Epoch 43: Val Loss 4377449.50000
Epoch 44: Val Loss 4350105.00000
Epoch 45: Val Loss 4352203.00000
Epoch 46: Val Loss 4355719.50000
Epoch 47: Val Loss 4342784.50000
Epoch 48: Val Loss 4348755.00000
Epoch 49: Val Loss 4345617.00000
Epoch 50: Val Loss 4337075.50000
Epoch 51: Val Loss 4318175.50000
Epoch 52: Val Loss 4317147.50000
Epoch 53: Val Loss 4367185.00000
Epoch 54: Val Loss 4310620.00000
Epoch 55: Val Loss 4359997.00000
Epoch 56: Val Loss 4295577.50000
Epoch 57: Val Loss 4294482.50000
Epoch 58: Val Loss 4300135.00000
Epoch 59: Val Loss 4290770.00000
Epoch 60: Val Loss 4290638.00000
Epoch 61: Val Loss 4294452.00000
Epoch 62: Val Loss 4312775.00000
Epoch 63: Val Loss 4296621.50000
Epoch 64: Val Loss 4275424.00000
Epoch 65: Val Loss 4267512.00000
Epoch 66: Val Loss 4402182.00000
Epoch 67: Val Loss 4264713.50000
Epoch 68: Val Loss 4259521.50000
Epoch 69: Val Loss 4272200.00000
Epoch 70: Val Loss 4252122.00000
Epoch 71: Val Loss 4247099.50000
Epoch 72: Val Loss 4254244.50000
Epoch 73: Val Loss 4295189.50000
Epoch 74: Val Loss 4248736.00000
Epoch 75: Val Loss 4241243.00000
Epoch 76: Val Loss 4243041.50000
Epoch 77: Val Loss 4244960.50000
Epoch 78: Val Loss 4233511.00000
Epoch 79: Val Loss 4231363.50000
Epoch 80: Val Loss 4228819.50000
Epoch 81: Val Loss 4238703.50000
Epoch 82: Val Loss 4234858.50000
Epoch 83: Val Loss 4224270.50000
Epoch 84: Val Loss 4230733.00000
Epoch 85: Val Loss 4217640.50000
Epoch 86: Val Loss 4209814.50000
Epoch 87: Val Loss 4215903.50000
Epoch 88: Val Loss 4219825.00000
Epoch 89: Val Loss 4224817.50000
Epoch 90: Val Loss 4216828.00000
Epoch 91: Val Loss 4206238.50000
Epoch 92: Val Loss 4201634.50000
Epoch 93: Val Loss 4203100.00000
Epoch 94: Val Loss 4225140.50000
Epoch 95: Val Loss 4191883.75000
Epoch 96: Val Loss 4209723.00000
Epoch 97: Val Loss 4196739.00000
Epoch 98: Val Loss 4211439.00000
Epoch 99: Val Loss 4213306.50000
Saved Losses
{'MSE - mean': 3842348.011156934, 'MSE - std': 265105.7443146111, 'R2 - mean': 0.547990411375961, 'R2 - std': 0.01474711381761061} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8806955.00000
Epoch 1: Val Loss 8272959.50000
Epoch 2: Val Loss 7863026.50000
Epoch 3: Val Loss 7387787.50000
Epoch 4: Val Loss 6605351.00000
Epoch 5: Val Loss 5889491.50000
Epoch 6: Val Loss 5400078.00000
Epoch 7: Val Loss 5074561.00000
Epoch 8: Val Loss 4842531.50000
Epoch 9: Val Loss 4735127.50000
Epoch 10: Val Loss 4604093.50000
Epoch 11: Val Loss 4535554.50000
Epoch 12: Val Loss 4472104.50000
Epoch 13: Val Loss 4426788.00000
Epoch 14: Val Loss 4399322.50000
Epoch 15: Val Loss 4364452.00000
Epoch 16: Val Loss 4347607.50000
Epoch 17: Val Loss 4303405.50000
Epoch 18: Val Loss 4305214.00000
Epoch 19: Val Loss 4284382.00000
Epoch 20: Val Loss 4274926.00000
Epoch 21: Val Loss 4241743.50000
Epoch 22: Val Loss 4295456.00000
Epoch 23: Val Loss 4232987.00000
Epoch 24: Val Loss 4192675.50000
Epoch 25: Val Loss 4185161.50000
Epoch 26: Val Loss 4172878.75000
Epoch 27: Val Loss 4167335.00000
Epoch 28: Val Loss 4165021.00000
Epoch 29: Val Loss 4147964.25000
Epoch 30: Val Loss 4138990.25000
Epoch 31: Val Loss 4141432.00000
Epoch 32: Val Loss 4120618.00000
Epoch 33: Val Loss 4115854.00000
Epoch 34: Val Loss 4119936.00000
Epoch 35: Val Loss 4108696.25000
Epoch 36: Val Loss 4116014.00000
Epoch 37: Val Loss 4096463.25000
Epoch 38: Val Loss 4106459.00000
Epoch 39: Val Loss 4081696.50000
Epoch 40: Val Loss 4082201.50000
Epoch 41: Val Loss 4077525.75000
Epoch 42: Val Loss 4071455.25000
Epoch 43: Val Loss 4072387.50000
Epoch 44: Val Loss 4076823.50000
Epoch 45: Val Loss 4063971.50000
Epoch 46: Val Loss 4044801.00000
Epoch 47: Val Loss 4057757.00000
Epoch 48: Val Loss 4031576.00000
Epoch 49: Val Loss 4046700.25000
Epoch 50: Val Loss 4033413.75000
Epoch 51: Val Loss 4031580.75000
Epoch 52: Val Loss 4020501.25000
Epoch 53: Val Loss 4029641.25000
Epoch 54: Val Loss 4016559.75000
Epoch 55: Val Loss 4004537.50000
Epoch 56: Val Loss 4011478.50000
Epoch 57: Val Loss 4003421.00000
Epoch 58: Val Loss 3995247.25000
Epoch 59: Val Loss 3990812.25000
Epoch 60: Val Loss 3994619.25000
Epoch 61: Val Loss 3986054.25000
Epoch 62: Val Loss 3980015.25000
Epoch 63: Val Loss 3974760.00000
Epoch 64: Val Loss 3972775.50000
Epoch 65: Val Loss 3979350.50000
Epoch 66: Val Loss 3974447.75000
Epoch 67: Val Loss 3969257.25000
Epoch 68: Val Loss 3967579.00000
Epoch 69: Val Loss 3964132.75000
Epoch 70: Val Loss 3987529.25000
Epoch 71: Val Loss 3960351.75000
Epoch 72: Val Loss 3953258.00000
Epoch 73: Val Loss 5821304.50000
Epoch 74: Val Loss 3966563.00000
Epoch 75: Val Loss 3957372.75000
Epoch 76: Val Loss 3957995.00000
Epoch 77: Val Loss 3940078.75000
Epoch 78: Val Loss 3957998.00000
Epoch 79: Val Loss 3940292.50000
Epoch 80: Val Loss 3947274.00000
Epoch 81: Val Loss 3936180.75000
Epoch 82: Val Loss 3941628.25000
Epoch 83: Val Loss 4029732.00000
Epoch 84: Val Loss 3924833.50000
Epoch 85: Val Loss 3915880.00000
Epoch 86: Val Loss 3938928.50000
Epoch 87: Val Loss 3919146.50000
Epoch 88: Val Loss 3914147.50000
Epoch 89: Val Loss 3945668.75000
Epoch 90: Val Loss 3938971.00000
Epoch 91: Val Loss 3905326.75000
Epoch 92: Val Loss 3927112.25000
Epoch 93: Val Loss 3902451.50000
Epoch 94: Val Loss 3906109.00000
Epoch 95: Val Loss 3905797.25000
Epoch 96: Val Loss 3915279.25000
Epoch 97: Val Loss 3898719.75000
Epoch 98: Val Loss 3901225.50000
Epoch 99: Val Loss 3935949.50000
Saved Losses
{'MSE - mean': 3859523.541397162, 'MSE - std': 231507.64192257647, 'R2 - mean': 0.5471202690958069, 'R2 - std': 0.012859994837685856} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8340852.00000
Epoch 1: Val Loss 7824622.00000
Epoch 2: Val Loss 7426573.00000
Epoch 3: Val Loss 6934578.00000
Epoch 4: Val Loss 6210793.00000
Epoch 5: Val Loss 5509410.50000
Epoch 6: Val Loss 4957625.50000
Epoch 7: Val Loss 4634645.50000
Epoch 8: Val Loss 4405869.00000
Epoch 9: Val Loss 4250820.00000
Epoch 10: Val Loss 4139639.00000
Epoch 11: Val Loss 4071120.50000
Epoch 12: Val Loss 4023371.25000
Epoch 13: Val Loss 3968168.00000
Epoch 14: Val Loss 3927228.75000
Epoch 15: Val Loss 3892941.50000
Epoch 16: Val Loss 3872874.00000
Epoch 17: Val Loss 3832920.00000
Epoch 18: Val Loss 3801095.00000
Epoch 19: Val Loss 3779952.00000
Epoch 20: Val Loss 3756191.75000
Epoch 21: Val Loss 3741255.75000
Epoch 22: Val Loss 3730048.00000
Epoch 23: Val Loss 3756610.75000
Epoch 24: Val Loss 3697122.25000
Epoch 25: Val Loss 3697923.50000
Epoch 26: Val Loss 3687762.25000
Epoch 27: Val Loss 3681228.25000
Epoch 28: Val Loss 3659595.75000
Epoch 29: Val Loss 3650404.50000
Epoch 30: Val Loss 3665159.00000
Epoch 31: Val Loss 3654401.50000
Epoch 32: Val Loss 3670014.00000
Epoch 33: Val Loss 3625825.75000
Epoch 34: Val Loss 3636331.75000
Epoch 35: Val Loss 3623942.25000
Epoch 36: Val Loss 3624203.75000
Epoch 37: Val Loss 3603190.25000
Epoch 38: Val Loss 3606764.75000
Epoch 39: Val Loss 3603467.00000
Epoch 40: Val Loss 3587018.25000
Epoch 41: Val Loss 3586349.75000
Epoch 42: Val Loss 3582420.00000
Epoch 43: Val Loss 3572619.00000
Epoch 44: Val Loss 3590033.50000
Epoch 45: Val Loss 3572293.75000
Epoch 46: Val Loss 3563092.75000
Epoch 47: Val Loss 3562656.75000
Epoch 48: Val Loss 3560256.50000
Epoch 49: Val Loss 3550449.00000
Epoch 50: Val Loss 3544132.75000
Epoch 51: Val Loss 3648443.00000
Epoch 52: Val Loss 3572741.50000
Epoch 53: Val Loss 3536269.25000
Epoch 54: Val Loss 3583428.25000
Epoch 55: Val Loss 3543515.00000
Epoch 56: Val Loss 3528839.50000
Epoch 57: Val Loss 3528706.50000
Epoch 58: Val Loss 3569048.00000
Epoch 59: Val Loss 3543180.75000
Epoch 60: Val Loss 3513671.75000
Epoch 61: Val Loss 3519967.75000
Epoch 62: Val Loss 3537992.00000
Epoch 63: Val Loss 3513417.25000
Epoch 64: Val Loss 3511149.00000
Epoch 65: Val Loss 3500913.50000
Epoch 66: Val Loss 3503670.50000
Epoch 67: Val Loss 3520845.00000
Epoch 68: Val Loss 3492058.00000
Epoch 69: Val Loss 3489730.75000
Epoch 70: Val Loss 3490014.25000
Epoch 71: Val Loss 3486713.00000
Epoch 72: Val Loss 3493820.75000
Epoch 73: Val Loss 3488685.25000
Epoch 74: Val Loss 3490707.00000
Epoch 75: Val Loss 3490680.75000
Epoch 76: Val Loss 3475829.00000
Epoch 77: Val Loss 3478002.50000
Epoch 78: Val Loss 3685031.50000
Epoch 79: Val Loss 3475087.25000
Epoch 80: Val Loss 3478154.25000
Epoch 81: Val Loss 3487387.00000
Epoch 82: Val Loss 3483512.50000
Epoch 83: Val Loss 3478790.00000
Epoch 84: Val Loss 3480651.00000
Epoch 85: Val Loss 3464532.50000
Epoch 86: Val Loss 3472013.75000
Epoch 87: Val Loss 3466614.25000
Epoch 88: Val Loss 3491910.25000
Epoch 89: Val Loss 3475524.50000
Epoch 90: Val Loss 3458126.25000
Epoch 91: Val Loss 3456527.75000
Epoch 92: Val Loss 3471371.00000
Epoch 93: Val Loss 3459247.50000
Epoch 94: Val Loss 3451126.50000
Epoch 95: Val Loss 3462304.50000
Epoch 96: Val Loss 3446825.50000
Epoch 97: Val Loss 3456489.75000
Epoch 98: Val Loss 3460016.75000
Epoch 99: Val Loss 3449018.00000
Saved Losses
{'MSE - mean': 3779343.042423828, 'MSE - std': 261901.27964042607, 'R2 - mean': 0.5522832093976504, 'R2 - std': 0.01545727608674458} 
 

Saving model.....
Results After CV: {'MSE - mean': 3779343.042423828, 'MSE - std': 261901.27964042607, 'R2 - mean': 0.5522832093976504, 'R2 - std': 0.01545727608674458}
Train time: 7774.584036116209
Inference time: 6.930265950993634
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 41 finished with value: 3779343.042423828 and parameters: {'dim': 32, 'depth': 6, 'heads': 2, 'weight_decay': -1, 'learning_rate': -5, 'dropout': 0}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4513499.50000
Epoch 1: Val Loss 4093620.50000
Epoch 2: Val Loss 3949205.25000
Epoch 3: Val Loss 3882333.00000
Epoch 4: Val Loss 3845671.00000
Epoch 5: Val Loss 3823797.75000
Epoch 6: Val Loss 3749261.50000
Epoch 7: Val Loss 3734212.75000
Epoch 8: Val Loss 3690355.00000
Epoch 9: Val Loss 3678931.50000
Epoch 10: Val Loss 3678478.00000
Epoch 11: Val Loss 3663225.50000
Epoch 12: Val Loss 3617532.25000
Epoch 13: Val Loss 3599819.00000
Epoch 14: Val Loss 3609011.75000
Epoch 15: Val Loss 3595730.25000
Epoch 16: Val Loss 3573311.75000
Epoch 17: Val Loss 3562779.50000
Epoch 18: Val Loss 3561214.25000
Epoch 19: Val Loss 3576011.25000
Epoch 20: Val Loss 3533990.00000
Epoch 21: Val Loss 3528140.25000
Epoch 22: Val Loss 3515457.25000
Epoch 23: Val Loss 3516946.75000
Epoch 24: Val Loss 3506034.25000
Epoch 25: Val Loss 3490471.50000
Epoch 26: Val Loss 3556797.50000
Epoch 27: Val Loss 3489122.25000
Epoch 28: Val Loss 3512447.75000
Epoch 29: Val Loss 3489915.50000
Epoch 30: Val Loss 3508437.50000
Epoch 31: Val Loss 3477497.75000
Epoch 32: Val Loss 3466999.25000
Epoch 33: Val Loss 3460690.50000
Epoch 34: Val Loss 3529478.75000
Epoch 35: Val Loss 3480165.25000
Epoch 36: Val Loss 3464591.00000
Epoch 37: Val Loss 3473302.75000
Epoch 38: Val Loss 3432934.25000
Epoch 39: Val Loss 3446452.25000
Epoch 40: Val Loss 3439043.25000
Epoch 41: Val Loss 3470840.75000
Epoch 42: Val Loss 3436041.00000
Epoch 43: Val Loss 3434123.00000
Epoch 44: Val Loss 3455547.25000
Epoch 45: Val Loss 3442683.25000
Epoch 46: Val Loss 3441745.00000
Epoch 47: Val Loss 3450200.75000
Epoch 48: Val Loss 3443382.25000
Epoch 49: Val Loss 3460117.50000
Epoch 50: Val Loss 3421017.50000
Epoch 51: Val Loss 3409317.25000
Epoch 52: Val Loss 3434495.50000
Epoch 53: Val Loss 3458836.50000
Epoch 54: Val Loss 3419045.00000
Epoch 55: Val Loss 3481576.50000
Epoch 56: Val Loss 3488660.75000
Epoch 57: Val Loss 3420308.50000
Epoch 58: Val Loss 3429325.25000
Epoch 59: Val Loss 3452783.75000
Epoch 60: Val Loss 3414998.25000
Epoch 61: Val Loss 3421555.25000
Epoch 62: Val Loss 3474981.50000
Epoch 63: Val Loss 3466017.00000
Epoch 64: Val Loss 3434484.00000
Epoch 65: Val Loss 3471600.25000
Epoch 66: Val Loss 3421998.50000
Epoch 67: Val Loss 3455861.00000
Epoch 68: Val Loss 3431418.00000
Epoch 69: Val Loss 3472145.50000
Epoch 70: Val Loss 3455512.00000
Epoch 71: Val Loss 3460842.50000
Epoch 72: Val Loss 3450897.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3414882.564959304, 'MSE - std': 0.0, 'R2 - mean': 0.5998932487814456, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4205057.50000
Epoch 1: Val Loss 3868525.00000
Epoch 2: Val Loss 3779784.75000
Epoch 3: Val Loss 3727159.75000
Epoch 4: Val Loss 3675863.00000
Epoch 5: Val Loss 3668588.75000
Epoch 6: Val Loss 3620123.00000
Epoch 7: Val Loss 3657177.50000
Epoch 8: Val Loss 3632472.75000
Epoch 9: Val Loss 3640352.00000
Epoch 10: Val Loss 3567470.00000
Epoch 11: Val Loss 3554499.00000
Epoch 12: Val Loss 3534158.25000
Epoch 13: Val Loss 3574494.25000
Epoch 14: Val Loss 3515245.50000
Epoch 15: Val Loss 3540193.25000
Epoch 16: Val Loss 3506384.00000
Epoch 17: Val Loss 3483976.50000
Epoch 18: Val Loss 3486999.75000
Epoch 19: Val Loss 3466916.00000
Epoch 20: Val Loss 3479567.50000
Epoch 21: Val Loss 3487601.50000
Epoch 22: Val Loss 3486453.75000
Epoch 23: Val Loss 3448878.75000
Epoch 24: Val Loss 3520484.25000
Epoch 25: Val Loss 3439580.50000
Epoch 26: Val Loss 3478042.75000
Epoch 27: Val Loss 3439443.00000
Epoch 28: Val Loss 3439182.25000
Epoch 29: Val Loss 3426538.25000
Epoch 30: Val Loss 3434086.75000
Epoch 31: Val Loss 3424126.25000
Epoch 32: Val Loss 3448449.25000
Epoch 33: Val Loss 3412100.50000
Epoch 34: Val Loss 3409252.25000
Epoch 35: Val Loss 3442017.50000
Epoch 36: Val Loss 3412210.25000
Epoch 37: Val Loss 3433092.25000
Epoch 38: Val Loss 3503366.75000
Epoch 39: Val Loss 3419032.50000
Epoch 40: Val Loss 3418259.00000
Epoch 41: Val Loss 3428761.25000
Epoch 42: Val Loss 3410211.00000
Epoch 43: Val Loss 3432020.50000
Epoch 44: Val Loss 3419533.50000
Epoch 45: Val Loss 3399417.50000
Epoch 46: Val Loss 3391053.00000
Epoch 47: Val Loss 3409545.25000
Epoch 48: Val Loss 3385618.00000
Epoch 49: Val Loss 3404801.75000
Epoch 50: Val Loss 3454180.00000
Epoch 51: Val Loss 3435712.00000
Epoch 52: Val Loss 3418937.25000
Epoch 53: Val Loss 3392060.50000
Epoch 54: Val Loss 3414183.50000
Epoch 55: Val Loss 3430599.00000
Epoch 56: Val Loss 3462703.25000
Epoch 57: Val Loss 3423675.25000
Epoch 58: Val Loss 3388985.00000
Epoch 59: Val Loss 3458948.75000
Epoch 60: Val Loss 3598667.00000
Epoch 61: Val Loss 3523843.25000
Epoch 62: Val Loss 3397396.50000
Epoch 63: Val Loss 3428065.50000
Epoch 64: Val Loss 3400485.75000
Epoch 65: Val Loss 3425880.75000
Epoch 66: Val Loss 3434327.50000
Epoch 67: Val Loss 3431351.00000
Epoch 68: Val Loss 3408276.50000
Epoch 69: Val Loss 3474298.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3403809.5877753356, 'MSE - std': 11072.977183968527, 'R2 - mean': 0.5881099242639909, 'R2 - std': 0.011783324517454619} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5017174.00000
Epoch 1: Val Loss 4555793.00000
Epoch 2: Val Loss 4432275.50000
Epoch 3: Val Loss 4388066.50000
Epoch 4: Val Loss 4340313.50000
Epoch 5: Val Loss 4288498.50000
Epoch 6: Val Loss 4254444.00000
Epoch 7: Val Loss 4234648.00000
Epoch 8: Val Loss 4274217.00000
Epoch 9: Val Loss 4171446.50000
Epoch 10: Val Loss 4172372.75000
Epoch 11: Val Loss 4142244.50000
Epoch 12: Val Loss 4136715.00000
Epoch 13: Val Loss 4124116.00000
Epoch 14: Val Loss 4102091.00000
Epoch 15: Val Loss 4123286.50000
Epoch 16: Val Loss 4085177.25000
Epoch 17: Val Loss 4057678.75000
Epoch 18: Val Loss 4055748.00000
Epoch 19: Val Loss 4045819.00000
Epoch 20: Val Loss 4050337.50000
Epoch 21: Val Loss 4060691.25000
Epoch 22: Val Loss 4052635.25000
Epoch 23: Val Loss 4025412.75000
Epoch 24: Val Loss 4003695.75000
Epoch 25: Val Loss 3997329.00000
Epoch 26: Val Loss 3985878.25000
Epoch 27: Val Loss 4025009.75000
Epoch 28: Val Loss 3972301.50000
Epoch 29: Val Loss 3965704.00000
Epoch 30: Val Loss 3955374.00000
Epoch 31: Val Loss 3944912.00000
Epoch 32: Val Loss 3961345.50000
Epoch 33: Val Loss 3997201.75000
Epoch 34: Val Loss 3941620.50000
Epoch 35: Val Loss 3938459.75000
Epoch 36: Val Loss 3959779.00000
Epoch 37: Val Loss 3931569.50000
Epoch 38: Val Loss 3923722.50000
Epoch 39: Val Loss 3920620.25000
Epoch 40: Val Loss 3919953.00000
Epoch 41: Val Loss 3963707.00000
Epoch 42: Val Loss 3927213.50000
Epoch 43: Val Loss 3889779.00000
Epoch 44: Val Loss 3921797.25000
Epoch 45: Val Loss 3921285.25000
Epoch 46: Val Loss 3885256.25000
Epoch 47: Val Loss 3942257.00000
Epoch 48: Val Loss 3869608.00000
Epoch 49: Val Loss 3887451.25000
Epoch 50: Val Loss 3891285.75000
Epoch 51: Val Loss 3879225.25000
Epoch 52: Val Loss 3863922.75000
Epoch 53: Val Loss 3873710.00000
Epoch 54: Val Loss 3882447.75000
Epoch 55: Val Loss 3929000.00000
Epoch 56: Val Loss 3857044.00000
Epoch 57: Val Loss 3849626.00000
Epoch 58: Val Loss 3903373.00000
Epoch 59: Val Loss 3913757.50000
Epoch 60: Val Loss 3877458.75000
Epoch 61: Val Loss 3879075.00000
Epoch 62: Val Loss 3849131.75000
Epoch 63: Val Loss 3867180.75000
Epoch 64: Val Loss 3852313.50000
Epoch 65: Val Loss 3869942.25000
Epoch 66: Val Loss 3858771.00000
Epoch 67: Val Loss 3842108.25000
Epoch 68: Val Loss 3851437.00000
Epoch 69: Val Loss 3872440.25000
Epoch 70: Val Loss 3844269.50000
Epoch 71: Val Loss 3848253.00000
Epoch 72: Val Loss 3896369.50000
Epoch 73: Val Loss 3890925.00000
Epoch 74: Val Loss 3865098.50000
Epoch 75: Val Loss 3872670.00000
Epoch 76: Val Loss 3863252.75000
Epoch 77: Val Loss 3856452.50000
Epoch 78: Val Loss 3910937.25000
Epoch 79: Val Loss 3899246.00000
Epoch 80: Val Loss 3884081.00000
Epoch 81: Val Loss 3860949.75000
Epoch 82: Val Loss 3890311.50000
Epoch 83: Val Loss 3872958.00000
Epoch 84: Val Loss 3889724.75000
Epoch 85: Val Loss 3879569.50000
Epoch 86: Val Loss 3882607.25000
Epoch 87: Val Loss 3908450.75000
Epoch 88: Val Loss 3885085.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3554396.692072499, 'MSE - std': 213154.1519894789, 'R2 - mean': 0.5816349742637293, 'R2 - std': 0.013282110003090883} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4654659.00000
Epoch 1: Val Loss 4204095.00000
Epoch 2: Val Loss 4133001.25000
Epoch 3: Val Loss 4077855.25000
Epoch 4: Val Loss 4040068.75000
Epoch 5: Val Loss 3985324.25000
Epoch 6: Val Loss 3967607.00000
Epoch 7: Val Loss 3940183.50000
Epoch 8: Val Loss 3912342.50000
Epoch 9: Val Loss 3897450.00000
Epoch 10: Val Loss 3876028.25000
Epoch 11: Val Loss 3879142.25000
Epoch 12: Val Loss 3948777.25000
Epoch 13: Val Loss 3825747.50000
Epoch 14: Val Loss 3848850.25000
Epoch 15: Val Loss 3813247.75000
Epoch 16: Val Loss 3837291.75000
Epoch 17: Val Loss 3810450.75000
Epoch 18: Val Loss 3810111.25000
Epoch 19: Val Loss 3804668.25000
Epoch 20: Val Loss 3772956.75000
Epoch 21: Val Loss 3782606.00000
Epoch 22: Val Loss 3760264.75000
Epoch 23: Val Loss 3764546.25000
Epoch 24: Val Loss 3757815.50000
Epoch 25: Val Loss 3814832.00000
Epoch 26: Val Loss 3732761.50000
Epoch 27: Val Loss 3732170.00000
Epoch 28: Val Loss 3766930.75000
Epoch 29: Val Loss 3749431.00000
Epoch 30: Val Loss 3750513.75000
Epoch 31: Val Loss 3718591.25000
Epoch 32: Val Loss 3720500.00000
Epoch 33: Val Loss 3712350.75000
Epoch 34: Val Loss 3737866.50000
Epoch 35: Val Loss 3709564.75000
Epoch 36: Val Loss 3712163.50000
Epoch 37: Val Loss 3796365.50000
Epoch 38: Val Loss 3755861.75000
Epoch 39: Val Loss 3732452.50000
Epoch 40: Val Loss 3736148.00000
Epoch 41: Val Loss 3714478.75000
Epoch 42: Val Loss 3697108.00000
Epoch 43: Val Loss 3700449.75000
Epoch 44: Val Loss 3716324.50000
Epoch 45: Val Loss 3727684.00000
Epoch 46: Val Loss 3722751.75000
Epoch 47: Val Loss 3761871.75000
Epoch 48: Val Loss 3751180.25000
Epoch 49: Val Loss 3705715.50000
Epoch 50: Val Loss 3733024.00000
Epoch 51: Val Loss 3724959.75000
Epoch 52: Val Loss 3719056.50000
Epoch 53: Val Loss 3705829.25000
Epoch 54: Val Loss 3722185.25000
Epoch 55: Val Loss 3733043.00000
Epoch 56: Val Loss 3724896.00000
Epoch 57: Val Loss 3710703.25000
Epoch 58: Val Loss 3732269.00000
Epoch 59: Val Loss 3728093.00000
Epoch 60: Val Loss 3743109.75000
Epoch 61: Val Loss 3732264.25000
Epoch 62: Val Loss 3763072.00000
Epoch 63: Val Loss 3733428.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3592882.990168513, 'MSE - std': 196264.1200173153, 'R2 - mean': 0.5782556618695492, 'R2 - std': 0.012906203600324625} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4134907.00000
Epoch 1: Val Loss 3712973.50000
Epoch 2: Val Loss 3620420.00000
Epoch 3: Val Loss 3571420.00000
Epoch 4: Val Loss 3555041.50000
Epoch 5: Val Loss 3519607.50000
Epoch 6: Val Loss 3503246.50000
Epoch 7: Val Loss 3491985.50000
Epoch 8: Val Loss 3470747.00000
Epoch 9: Val Loss 3464326.00000
Epoch 10: Val Loss 3450193.50000
Epoch 11: Val Loss 3440448.25000
Epoch 12: Val Loss 3448627.00000
Epoch 13: Val Loss 3430639.75000
Epoch 14: Val Loss 3411753.50000
Epoch 15: Val Loss 3422051.50000
Epoch 16: Val Loss 3424367.50000
Epoch 17: Val Loss 3417460.50000
Epoch 18: Val Loss 3401115.75000
Epoch 19: Val Loss 3417007.75000
Epoch 20: Val Loss 3403019.00000
Epoch 21: Val Loss 3420627.00000
Epoch 22: Val Loss 3400086.25000
Epoch 23: Val Loss 3410077.50000
Epoch 24: Val Loss 3466443.00000
Epoch 25: Val Loss 3419791.25000
Epoch 26: Val Loss 3445580.50000
Epoch 27: Val Loss 3469071.25000
Epoch 28: Val Loss 3383688.25000
Epoch 29: Val Loss 3445241.25000
Epoch 30: Val Loss 3388555.00000
Epoch 31: Val Loss 3393922.25000
Epoch 32: Val Loss 3433649.00000
Epoch 33: Val Loss 3426250.25000
Epoch 34: Val Loss 3451131.75000
Epoch 35: Val Loss 3401239.50000
Epoch 36: Val Loss 3494789.50000
Epoch 37: Val Loss 3433858.00000
Epoch 38: Val Loss 3425831.50000
Epoch 39: Val Loss 3430290.75000
Epoch 40: Val Loss 3390241.25000
Epoch 41: Val Loss 3393172.50000
Epoch 42: Val Loss 3384250.75000
Epoch 43: Val Loss 3494473.75000
Epoch 44: Val Loss 3368789.50000
Epoch 45: Val Loss 3384776.50000
Epoch 46: Val Loss 3405354.00000
Epoch 47: Val Loss 3405349.50000
Epoch 48: Val Loss 3436845.00000
Epoch 49: Val Loss 3415713.25000
Epoch 50: Val Loss 3442551.00000
Epoch 51: Val Loss 3366085.25000
Epoch 52: Val Loss 3362794.50000
Epoch 53: Val Loss 3429376.25000
Epoch 54: Val Loss 3397478.25000
Epoch 55: Val Loss 3431204.50000
Epoch 56: Val Loss 3417332.50000
Epoch 57: Val Loss 3458773.25000
Epoch 58: Val Loss 3426475.00000
Epoch 59: Val Loss 3442338.75000
Epoch 60: Val Loss 3385726.75000
Epoch 61: Val Loss 3390461.50000
Epoch 62: Val Loss 3440821.00000
Epoch 63: Val Loss 3499285.25000
Epoch 64: Val Loss 3429671.25000
Epoch 65: Val Loss 3445199.00000
Epoch 66: Val Loss 3421991.25000
Epoch 67: Val Loss 3438963.75000
Epoch 68: Val Loss 3466248.25000
Epoch 69: Val Loss 3409919.75000
Epoch 70: Val Loss 3471356.50000
Epoch 71: Val Loss 3480703.75000
Epoch 72: Val Loss 3502168.50000
Epoch 73: Val Loss 3471902.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3550127.6801248267, 'MSE - std': 195263.28378029467, 'R2 - mean': 0.5791551910632793, 'R2 - std': 0.01168300835315616} 
 

Saving model.....
Results After CV: {'MSE - mean': 3550127.6801248267, 'MSE - std': 195263.28378029467, 'R2 - mean': 0.5791551910632793, 'R2 - std': 0.01168300835315616}
Train time: 5786.165541639202
Inference time: 6.901342840213329
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 42 finished with value: 3550127.6801248267 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -3, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 34 with value: 3548099.6336374814.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4486093.00000
Epoch 1: Val Loss 4074084.50000
Epoch 2: Val Loss 3977118.75000
Epoch 3: Val Loss 3893664.00000
Epoch 4: Val Loss 3841392.50000
Epoch 5: Val Loss 3789616.50000
Epoch 6: Val Loss 3761548.75000
Epoch 7: Val Loss 3720430.25000
Epoch 8: Val Loss 3703207.00000
Epoch 9: Val Loss 3697122.75000
Epoch 10: Val Loss 3653674.50000
Epoch 11: Val Loss 3637931.75000
Epoch 12: Val Loss 3614383.25000
Epoch 13: Val Loss 3609199.25000
Epoch 14: Val Loss 3592704.25000
Epoch 15: Val Loss 3595057.00000
Epoch 16: Val Loss 3575536.75000
Epoch 17: Val Loss 3593907.00000
Epoch 18: Val Loss 3555704.25000
Epoch 19: Val Loss 3532646.25000
Epoch 20: Val Loss 3575804.50000
Epoch 21: Val Loss 3521881.75000
Epoch 22: Val Loss 3517405.00000
Epoch 23: Val Loss 3513139.25000
Epoch 24: Val Loss 3508188.25000
Epoch 25: Val Loss 3504123.00000
Epoch 26: Val Loss 3508403.75000
Epoch 27: Val Loss 3520645.00000
Epoch 28: Val Loss 3488726.25000
Epoch 29: Val Loss 3493371.25000
Epoch 30: Val Loss 3493644.50000
Epoch 31: Val Loss 3472060.25000
Epoch 32: Val Loss 3491554.25000
Epoch 33: Val Loss 3515905.25000
Epoch 34: Val Loss 3487413.00000
Epoch 35: Val Loss 3460987.75000
Epoch 36: Val Loss 3478759.00000
Epoch 37: Val Loss 3456767.50000
Epoch 38: Val Loss 3462545.50000
Epoch 39: Val Loss 3448819.25000
Epoch 40: Val Loss 3437906.00000
Epoch 41: Val Loss 3439488.25000
Epoch 42: Val Loss 3428959.25000
Epoch 43: Val Loss 3426584.00000
Epoch 44: Val Loss 3430177.50000
Epoch 45: Val Loss 3505879.00000
Epoch 46: Val Loss 3435402.75000
Epoch 47: Val Loss 3423144.50000
Epoch 48: Val Loss 3450789.00000
Epoch 49: Val Loss 3452328.75000
Epoch 50: Val Loss 3441657.50000
Epoch 51: Val Loss 3444949.25000
Epoch 52: Val Loss 3410009.50000
Epoch 53: Val Loss 3413652.00000
Epoch 54: Val Loss 3409893.25000
Epoch 55: Val Loss 3427367.75000
Epoch 56: Val Loss 3429242.50000
Epoch 57: Val Loss 3467180.75000
Epoch 58: Val Loss 3427570.50000
Epoch 59: Val Loss 3439174.25000
Epoch 60: Val Loss 3425311.75000
Epoch 61: Val Loss 3421760.50000
Epoch 62: Val Loss 3458496.25000
Epoch 63: Val Loss 3438013.25000
Epoch 64: Val Loss 3435857.00000
Epoch 65: Val Loss 3475124.50000
Epoch 66: Val Loss 3443127.75000
Epoch 67: Val Loss 3440141.00000
Epoch 68: Val Loss 3545322.50000
Epoch 69: Val Loss 3429667.00000
Epoch 70: Val Loss 3487484.50000
Epoch 71: Val Loss 3436214.75000
Epoch 72: Val Loss 3450634.25000
Epoch 73: Val Loss 3542614.50000
Epoch 74: Val Loss 3449414.25000
Epoch 75: Val Loss 3484517.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3417872.4926121235, 'MSE - std': 0.0, 'R2 - mean': 0.599542932125809, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4212744.50000
Epoch 1: Val Loss 3900590.75000
Epoch 2: Val Loss 3776896.50000
Epoch 3: Val Loss 3731407.25000
Epoch 4: Val Loss 3713767.75000
Epoch 5: Val Loss 3662066.25000
Epoch 6: Val Loss 3618241.75000
Epoch 7: Val Loss 3609625.25000
Epoch 8: Val Loss 3589537.25000
Epoch 9: Val Loss 3565086.75000
Epoch 10: Val Loss 3559450.75000
Epoch 11: Val Loss 3565747.00000
Epoch 12: Val Loss 3601046.25000
Epoch 13: Val Loss 3564988.75000
Epoch 14: Val Loss 3511780.25000
Epoch 15: Val Loss 3542764.00000
Epoch 16: Val Loss 3507761.75000
Epoch 17: Val Loss 3480001.50000
Epoch 18: Val Loss 3500735.50000
Epoch 19: Val Loss 3468369.50000
Epoch 20: Val Loss 3532770.75000
Epoch 21: Val Loss 3493509.00000
Epoch 22: Val Loss 3478955.25000
Epoch 23: Val Loss 3464626.50000
Epoch 24: Val Loss 3446854.25000
Epoch 25: Val Loss 3473959.75000
Epoch 26: Val Loss 3478723.75000
Epoch 27: Val Loss 3428343.00000
Epoch 28: Val Loss 3414127.25000
Epoch 29: Val Loss 3447576.75000
Epoch 30: Val Loss 3409490.25000
Epoch 31: Val Loss 3423748.25000
Epoch 32: Val Loss 3550207.75000
Epoch 33: Val Loss 3493218.25000
Epoch 34: Val Loss 3563088.00000
Epoch 35: Val Loss 3408169.25000
Epoch 36: Val Loss 3425046.00000
Epoch 37: Val Loss 3409156.50000
Epoch 38: Val Loss 3403157.75000
Epoch 39: Val Loss 3407158.50000
Epoch 40: Val Loss 3411805.50000
Epoch 41: Val Loss 3409104.75000
Epoch 42: Val Loss 3387538.75000
Epoch 43: Val Loss 3400339.00000
Epoch 44: Val Loss 3421204.25000
Epoch 45: Val Loss 3433895.50000
Epoch 46: Val Loss 3437442.50000
Epoch 47: Val Loss 3394401.25000
Epoch 48: Val Loss 3396674.00000
Epoch 49: Val Loss 3398495.75000
Epoch 50: Val Loss 3400204.25000
Epoch 51: Val Loss 3421868.25000
Epoch 52: Val Loss 3401926.25000
Epoch 53: Val Loss 3384858.50000
Epoch 54: Val Loss 3401604.00000
Epoch 55: Val Loss 3454959.25000
Epoch 56: Val Loss 3394027.00000
Epoch 57: Val Loss 3383495.50000
Epoch 58: Val Loss 3370791.25000
Epoch 59: Val Loss 3392160.00000
Epoch 60: Val Loss 3380049.75000
Epoch 61: Val Loss 3409528.25000
Epoch 62: Val Loss 3383484.00000
Epoch 63: Val Loss 3396670.25000
Epoch 64: Val Loss 3428141.75000
Epoch 65: Val Loss 3428553.00000
Epoch 66: Val Loss 3418616.75000
Epoch 67: Val Loss 3387724.50000
Epoch 68: Val Loss 3396417.00000
Epoch 69: Val Loss 3405079.75000
Epoch 70: Val Loss 3433877.75000
Epoch 71: Val Loss 3417248.75000
Epoch 72: Val Loss 3389488.25000
Epoch 73: Val Loss 3468223.50000
Epoch 74: Val Loss 3428867.00000
Epoch 75: Val Loss 3453914.75000
Epoch 76: Val Loss 3496721.50000
Epoch 77: Val Loss 3423533.50000
Epoch 78: Val Loss 3398827.00000
Epoch 79: Val Loss 3423714.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3399373.392505441, 'MSE - std': 18499.10010668263, 'R2 - mean': 0.5886754288965483, 'R2 - std': 0.010867503229260667} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5034912.00000
Epoch 1: Val Loss 4582752.00000
Epoch 2: Val Loss 4439506.50000
Epoch 3: Val Loss 4369628.50000
Epoch 4: Val Loss 4353913.50000
Epoch 5: Val Loss 4286615.50000
Epoch 6: Val Loss 4247259.00000
Epoch 7: Val Loss 4227095.00000
Epoch 8: Val Loss 4204761.00000
Epoch 9: Val Loss 4178984.25000
Epoch 10: Val Loss 4150932.00000
Epoch 11: Val Loss 4129701.75000
Epoch 12: Val Loss 4113992.25000
Epoch 13: Val Loss 4110728.00000
Epoch 14: Val Loss 4131609.50000
Epoch 15: Val Loss 4077647.25000
Epoch 16: Val Loss 4071761.75000
Epoch 17: Val Loss 4061512.00000
Epoch 18: Val Loss 4099844.50000
Epoch 19: Val Loss 4069822.00000
Epoch 20: Val Loss 4068133.25000
Epoch 21: Val Loss 4028608.50000
Epoch 22: Val Loss 4032150.25000
Epoch 23: Val Loss 4017093.25000
Epoch 24: Val Loss 4041227.00000
Epoch 25: Val Loss 4017300.50000
Epoch 26: Val Loss 3984127.25000
Epoch 27: Val Loss 3997902.75000
Epoch 28: Val Loss 3983940.00000
Epoch 29: Val Loss 4015649.00000
Epoch 30: Val Loss 3971056.50000
Epoch 31: Val Loss 4132503.50000
Epoch 32: Val Loss 3989748.00000
Epoch 33: Val Loss 3958584.75000
Epoch 34: Val Loss 3994525.50000
Epoch 35: Val Loss 3954285.50000
Epoch 36: Val Loss 3937679.75000
Epoch 37: Val Loss 3973633.75000
Epoch 38: Val Loss 3924756.50000
Epoch 39: Val Loss 3942453.25000
Epoch 40: Val Loss 3911316.50000
Epoch 41: Val Loss 4023242.00000
Epoch 42: Val Loss 3913341.50000
Epoch 43: Val Loss 3909275.75000
Epoch 44: Val Loss 3912723.00000
Epoch 45: Val Loss 3902688.50000
Epoch 46: Val Loss 3900106.50000
Epoch 47: Val Loss 3889312.50000
Epoch 48: Val Loss 3886832.00000
Epoch 49: Val Loss 3894534.25000
Epoch 50: Val Loss 3879059.00000
Epoch 51: Val Loss 3879153.75000
Epoch 52: Val Loss 3878020.75000
Epoch 53: Val Loss 4171268.50000
Epoch 54: Val Loss 3872237.50000
Epoch 55: Val Loss 3864657.00000
Epoch 56: Val Loss 3870874.00000
Epoch 57: Val Loss 3893972.50000
Epoch 58: Val Loss 3891251.50000
Epoch 59: Val Loss 3872241.00000
Epoch 60: Val Loss 3867428.00000
Epoch 61: Val Loss 3853133.50000
Epoch 62: Val Loss 3849810.25000
Epoch 63: Val Loss 3865508.75000
Epoch 64: Val Loss 3855609.25000
Epoch 65: Val Loss 3845519.25000
Epoch 66: Val Loss 3863645.50000
Epoch 67: Val Loss 3866577.00000
Epoch 68: Val Loss 3865891.00000
Epoch 69: Val Loss 3853681.50000
Epoch 70: Val Loss 3869457.00000
Epoch 71: Val Loss 3850365.00000
Epoch 72: Val Loss 3840107.75000
Epoch 73: Val Loss 3853529.50000
Epoch 74: Val Loss 3866988.75000
Epoch 75: Val Loss 3856194.25000
Epoch 76: Val Loss 3882164.00000
Epoch 77: Val Loss 3857887.25000
Epoch 78: Val Loss 3879163.75000
Epoch 79: Val Loss 3849718.50000
Epoch 80: Val Loss 3898392.25000
Epoch 81: Val Loss 3870394.00000
Epoch 82: Val Loss 3866829.00000
Epoch 83: Val Loss 3897456.50000
Epoch 84: Val Loss 3897720.75000
Epoch 85: Val Loss 3872629.75000
Epoch 86: Val Loss 3855887.75000
Epoch 87: Val Loss 3861089.00000
Epoch 88: Val Loss 3860548.50000
Epoch 89: Val Loss 3877900.75000
Epoch 90: Val Loss 3877229.50000
Epoch 91: Val Loss 3885272.25000
Epoch 92: Val Loss 3897566.25000
Epoch 93: Val Loss 3873396.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3550695.3510296266, 'MSE - std': 214533.94774027908, 'R2 - mean': 0.582095193428191, 'R2 - std': 0.012858230124323041} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4616784.00000
Epoch 1: Val Loss 4215065.50000
Epoch 2: Val Loss 4129368.75000
Epoch 3: Val Loss 4079554.25000
Epoch 4: Val Loss 4022292.50000
Epoch 5: Val Loss 4004598.25000
Epoch 6: Val Loss 3974002.25000
Epoch 7: Val Loss 3947936.50000
Epoch 8: Val Loss 3920433.75000
Epoch 9: Val Loss 3899587.50000
Epoch 10: Val Loss 3962776.75000
Epoch 11: Val Loss 3887085.00000
Epoch 12: Val Loss 3919877.25000
Epoch 13: Val Loss 3854630.50000
Epoch 14: Val Loss 3853993.25000
Epoch 15: Val Loss 3824199.00000
Epoch 16: Val Loss 3820179.00000
Epoch 17: Val Loss 3794939.00000
Epoch 18: Val Loss 3806674.25000
Epoch 19: Val Loss 3779768.00000
Epoch 20: Val Loss 3783780.75000
Epoch 21: Val Loss 3794042.50000
Epoch 22: Val Loss 3804462.75000
Epoch 23: Val Loss 3761902.75000
Epoch 24: Val Loss 3823371.25000
Epoch 25: Val Loss 3769568.00000
Epoch 26: Val Loss 3778260.50000
Epoch 27: Val Loss 3744403.00000
Epoch 28: Val Loss 3735510.50000
Epoch 29: Val Loss 3742413.50000
Epoch 30: Val Loss 3766536.25000
Epoch 31: Val Loss 3734699.75000
Epoch 32: Val Loss 3739533.00000
Epoch 33: Val Loss 3713836.75000
Epoch 34: Val Loss 3716780.25000
Epoch 35: Val Loss 3766944.50000
Epoch 36: Val Loss 3721897.25000
Epoch 37: Val Loss 3714020.50000
Epoch 38: Val Loss 3743818.00000
Epoch 39: Val Loss 3708312.75000
Epoch 40: Val Loss 3723572.75000
Epoch 41: Val Loss 3730261.75000
Epoch 42: Val Loss 3688153.25000
Epoch 43: Val Loss 3699673.50000
Epoch 44: Val Loss 3697856.50000
Epoch 45: Val Loss 3690876.75000
Epoch 46: Val Loss 3712279.00000
Epoch 47: Val Loss 3733632.00000
Epoch 48: Val Loss 3725205.25000
Epoch 49: Val Loss 3721400.25000
Epoch 50: Val Loss 3699943.75000
Epoch 51: Val Loss 3734923.75000
Epoch 52: Val Loss 3703586.25000
Epoch 53: Val Loss 3711693.00000
Epoch 54: Val Loss 3719766.50000
Epoch 55: Val Loss 3704067.50000
Epoch 56: Val Loss 3710072.75000
Epoch 57: Val Loss 3755399.75000
Epoch 58: Val Loss 3706970.00000
Epoch 59: Val Loss 3741400.75000
Epoch 60: Val Loss 3761678.25000
Epoch 61: Val Loss 3757958.25000
Epoch 62: Val Loss 3700942.00000
Epoch 63: Val Loss 3741256.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3587298.5877321255, 'MSE - std': 196310.98252789915, 'R2 - mean': 0.5789278987660885, 'R2 - std': 0.012413534060745366} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4115942.50000
Epoch 1: Val Loss 3724433.50000
Epoch 2: Val Loss 3628398.75000
Epoch 3: Val Loss 3589549.00000
Epoch 4: Val Loss 3556446.25000
Epoch 5: Val Loss 3517075.00000
Epoch 6: Val Loss 3483145.50000
Epoch 7: Val Loss 3463267.00000
Epoch 8: Val Loss 3469001.00000
Epoch 9: Val Loss 3472339.25000
Epoch 10: Val Loss 3438355.50000
Epoch 11: Val Loss 3448420.00000
Epoch 12: Val Loss 3440519.50000
Epoch 13: Val Loss 3429551.75000
Epoch 14: Val Loss 3418272.25000
Epoch 15: Val Loss 3434086.00000
Epoch 16: Val Loss 3429077.75000
Epoch 17: Val Loss 3483785.50000
Epoch 18: Val Loss 3548678.25000
Epoch 19: Val Loss 3422571.50000
Epoch 20: Val Loss 3463022.00000
Epoch 21: Val Loss 3401824.75000
Epoch 22: Val Loss 3403587.00000
Epoch 23: Val Loss 3413784.50000
Epoch 24: Val Loss 3423676.50000
Epoch 25: Val Loss 3416097.00000
Epoch 26: Val Loss 3415984.25000
Epoch 27: Val Loss 3404818.75000
Epoch 28: Val Loss 3416817.50000
Epoch 29: Val Loss 3404925.75000
Epoch 30: Val Loss 3414905.75000
Epoch 31: Val Loss 3388117.00000
Epoch 32: Val Loss 3393475.25000
Epoch 33: Val Loss 3406227.75000
Epoch 34: Val Loss 3412684.25000
Epoch 35: Val Loss 3405762.75000
Epoch 36: Val Loss 3375879.75000
Epoch 37: Val Loss 3394493.75000
Epoch 38: Val Loss 3387843.50000
Epoch 39: Val Loss 3373218.75000
Epoch 40: Val Loss 3390705.75000
Epoch 41: Val Loss 3395367.00000
Epoch 42: Val Loss 3427948.25000
Epoch 43: Val Loss 3435420.00000
Epoch 44: Val Loss 3430483.00000
Epoch 45: Val Loss 3443329.25000
Epoch 46: Val Loss 3453661.25000
Epoch 47: Val Loss 3410326.00000
Epoch 48: Val Loss 3390906.25000
Epoch 49: Val Loss 3457591.50000
Epoch 50: Val Loss 3416524.75000
Epoch 51: Val Loss 3439992.50000
Epoch 52: Val Loss 3392178.75000
Epoch 53: Val Loss 3390826.00000
Epoch 54: Val Loss 3394385.25000
Epoch 55: Val Loss 3409076.00000
Epoch 56: Val Loss 3407466.00000
Epoch 57: Val Loss 3398277.75000
Epoch 58: Val Loss 3375092.00000
Epoch 59: Val Loss 3439776.25000
Epoch 60: Val Loss 3451945.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3546744.9497103365, 'MSE - std': 193413.52516322234, 'R2 - mean': 0.5795590322460772, 'R2 - std': 0.011174523711553808} 
 

Saving model.....
Results After CV: {'MSE - mean': 3546744.9497103365, 'MSE - std': 193413.52516322234, 'R2 - mean': 0.5795590322460772, 'R2 - std': 0.011174523711553808}
Train time: 5758.78681402416
Inference time: 6.645241135987453
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 43 finished with value: 3546744.9497103365 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 43 with value: 3546744.9497103365.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4528979.50000
Epoch 1: Val Loss 4118816.50000
Epoch 2: Val Loss 3983378.25000
Epoch 3: Val Loss 3912713.25000
Epoch 4: Val Loss 3854142.25000
Epoch 5: Val Loss 3815975.50000
Epoch 6: Val Loss 3778293.25000
Epoch 7: Val Loss 3783113.25000
Epoch 8: Val Loss 3737036.75000
Epoch 9: Val Loss 3702065.50000
Epoch 10: Val Loss 3686158.25000
Epoch 11: Val Loss 3673440.00000
Epoch 12: Val Loss 3642916.00000
Epoch 13: Val Loss 3662591.75000
Epoch 14: Val Loss 3623833.25000
Epoch 15: Val Loss 3656228.50000
Epoch 16: Val Loss 3633226.00000
Epoch 17: Val Loss 3592517.00000
Epoch 18: Val Loss 3561869.75000
Epoch 19: Val Loss 3598409.50000
Epoch 20: Val Loss 3549529.50000
Epoch 21: Val Loss 3547198.00000
Epoch 22: Val Loss 3526357.00000
Epoch 23: Val Loss 3588723.00000
Epoch 24: Val Loss 3535022.00000
Epoch 25: Val Loss 3509705.50000
Epoch 26: Val Loss 3522515.25000
Epoch 27: Val Loss 3506835.00000
Epoch 28: Val Loss 3496880.25000
Epoch 29: Val Loss 3483061.25000
Epoch 30: Val Loss 3477105.50000
Epoch 31: Val Loss 3481341.75000
Epoch 32: Val Loss 3486958.25000
Epoch 33: Val Loss 3508414.50000
Epoch 34: Val Loss 3459672.75000
Epoch 35: Val Loss 3490422.00000
Epoch 36: Val Loss 3461926.50000
Epoch 37: Val Loss 3454643.50000
Epoch 38: Val Loss 3484114.25000
Epoch 39: Val Loss 3452330.25000
Epoch 40: Val Loss 3437417.50000
Epoch 41: Val Loss 3469002.25000
Epoch 42: Val Loss 3437218.25000
Epoch 43: Val Loss 3448572.25000
Epoch 44: Val Loss 3463005.25000
Epoch 45: Val Loss 3512282.75000
Epoch 46: Val Loss 3430885.75000
Epoch 47: Val Loss 3477447.50000
Epoch 48: Val Loss 3459820.50000
Epoch 49: Val Loss 3464220.25000
Epoch 50: Val Loss 3419045.50000
Epoch 51: Val Loss 3424883.75000
Epoch 52: Val Loss 3441578.50000
Epoch 53: Val Loss 3426093.00000
Epoch 54: Val Loss 3423185.75000
Epoch 55: Val Loss 3427184.50000
Epoch 56: Val Loss 3447852.50000
Epoch 57: Val Loss 3452202.00000
Epoch 58: Val Loss 3425638.50000
Epoch 59: Val Loss 3469158.50000
Epoch 60: Val Loss 3463305.00000
Epoch 61: Val Loss 3424848.75000
Epoch 62: Val Loss 3407256.75000
Epoch 63: Val Loss 3415108.75000
Epoch 64: Val Loss 3450276.50000
Epoch 65: Val Loss 3433955.50000
Epoch 66: Val Loss 3483103.50000
Epoch 67: Val Loss 3442200.25000
Epoch 68: Val Loss 3423654.75000
Epoch 69: Val Loss 3463525.25000
Epoch 70: Val Loss 3424552.75000
Epoch 71: Val Loss 3454415.50000
Epoch 72: Val Loss 3450374.50000
Epoch 73: Val Loss 3433861.75000
Epoch 74: Val Loss 3458490.75000
Epoch 75: Val Loss 3476281.50000
Epoch 76: Val Loss 3468520.50000
Epoch 77: Val Loss 3463617.00000
Epoch 78: Val Loss 3480235.25000
Epoch 79: Val Loss 3493144.25000
Epoch 80: Val Loss 3478832.25000
Epoch 81: Val Loss 3476064.50000
Epoch 82: Val Loss 3511581.50000
Epoch 83: Val Loss 3440337.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3416199.058130597, 'MSE - std': 0.0, 'R2 - mean': 0.5997390010743142, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4220617.00000
Epoch 1: Val Loss 3878608.00000
Epoch 2: Val Loss 3794906.50000
Epoch 3: Val Loss 3741840.00000
Epoch 4: Val Loss 3680089.25000
Epoch 5: Val Loss 3662711.75000
Epoch 6: Val Loss 3686595.50000
Epoch 7: Val Loss 3603176.00000
Epoch 8: Val Loss 3592624.25000
Epoch 9: Val Loss 3571181.75000
Epoch 10: Val Loss 3577501.25000
Epoch 11: Val Loss 3552892.25000
Epoch 12: Val Loss 3557830.00000
Epoch 13: Val Loss 3528084.75000
Epoch 14: Val Loss 3513963.75000
Epoch 15: Val Loss 3507904.00000
Epoch 16: Val Loss 3513724.00000
Epoch 17: Val Loss 3491594.75000
Epoch 18: Val Loss 3490476.25000
Epoch 19: Val Loss 3482007.25000
Epoch 20: Val Loss 3467807.75000
Epoch 21: Val Loss 3535526.75000
Epoch 22: Val Loss 3489132.75000
Epoch 23: Val Loss 3467503.50000
Epoch 24: Val Loss 3490370.75000
Epoch 25: Val Loss 3463780.25000
Epoch 26: Val Loss 3448266.00000
Epoch 27: Val Loss 3433385.50000
Epoch 28: Val Loss 3434430.00000
Epoch 29: Val Loss 3433648.75000
Epoch 30: Val Loss 3486017.50000
Epoch 31: Val Loss 3461004.00000
Epoch 32: Val Loss 3422988.50000
Epoch 33: Val Loss 3425874.75000
Epoch 34: Val Loss 3433737.50000
Epoch 35: Val Loss 3427803.25000
Epoch 36: Val Loss 3427254.50000
Epoch 37: Val Loss 3448822.25000
Epoch 38: Val Loss 3424372.00000
Epoch 39: Val Loss 3415756.75000
Epoch 40: Val Loss 3389827.50000
Epoch 41: Val Loss 3507562.75000
Epoch 42: Val Loss 3417850.25000
Epoch 43: Val Loss 3414965.50000
Epoch 44: Val Loss 3436553.00000
Epoch 45: Val Loss 3411433.25000
Epoch 46: Val Loss 3385078.25000
Epoch 47: Val Loss 3412787.25000
Epoch 48: Val Loss 3457078.50000
Epoch 49: Val Loss 3393273.50000
Epoch 50: Val Loss 3382123.25000
Epoch 51: Val Loss 3404940.25000
Epoch 52: Val Loss 3447991.75000
Epoch 53: Val Loss 3377869.75000
Epoch 54: Val Loss 3388374.00000
Epoch 55: Val Loss 3398368.25000
Epoch 56: Val Loss 3407512.00000
Epoch 57: Val Loss 3386884.00000
Epoch 58: Val Loss 3444981.75000
Epoch 59: Val Loss 3430713.50000
Epoch 60: Val Loss 3428984.50000
Epoch 61: Val Loss 3393700.25000
Epoch 62: Val Loss 3394618.75000
Epoch 63: Val Loss 3380739.00000
Epoch 64: Val Loss 3414795.00000
Epoch 65: Val Loss 3393484.25000
Epoch 66: Val Loss 3407801.00000
Epoch 67: Val Loss 3457814.00000
Epoch 68: Val Loss 3394243.00000
Epoch 69: Val Loss 3410219.25000
Epoch 70: Val Loss 3375125.00000
Epoch 71: Val Loss 3406267.50000
Epoch 72: Val Loss 3435228.75000
Epoch 73: Val Loss 3391390.00000
Epoch 74: Val Loss 3451981.00000
Epoch 75: Val Loss 3423158.00000
Epoch 76: Val Loss 3417848.50000
Epoch 77: Val Loss 3448008.00000
Epoch 78: Val Loss 3423745.50000
Epoch 79: Val Loss 3526309.25000
Epoch 80: Val Loss 3399609.75000
Epoch 81: Val Loss 3451725.50000
Epoch 82: Val Loss 3438005.50000
Epoch 83: Val Loss 3474236.00000
Epoch 84: Val Loss 3457934.25000
Epoch 85: Val Loss 3536269.00000
Epoch 86: Val Loss 3474203.25000
Epoch 87: Val Loss 3482338.50000
Epoch 88: Val Loss 3432490.50000
Epoch 89: Val Loss 3432522.50000
Epoch 90: Val Loss 3460969.75000
Epoch 91: Val Loss 3474261.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3401505.5615545874, 'MSE - std': 14693.496576009784, 'R2 - mean': 0.5884027189559574, 'R2 - std': 0.0113362821183568} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4959566.00000
Epoch 1: Val Loss 4563886.00000
Epoch 2: Val Loss 4439191.00000
Epoch 3: Val Loss 4375337.00000
Epoch 4: Val Loss 4754588.00000
Epoch 5: Val Loss 4273418.00000
Epoch 6: Val Loss 4251438.50000
Epoch 7: Val Loss 4256271.00000
Epoch 8: Val Loss 4208976.00000
Epoch 9: Val Loss 4183796.00000
Epoch 10: Val Loss 4156504.00000
Epoch 11: Val Loss 4167972.75000
Epoch 12: Val Loss 4150470.25000
Epoch 13: Val Loss 4108718.75000
Epoch 14: Val Loss 4116495.75000
Epoch 15: Val Loss 4103059.25000
Epoch 16: Val Loss 4087207.50000
Epoch 17: Val Loss 4083294.25000
Epoch 18: Val Loss 4087397.75000
Epoch 19: Val Loss 4060856.75000
Epoch 20: Val Loss 4030801.00000
Epoch 21: Val Loss 4024181.75000
Epoch 22: Val Loss 4021541.75000
Epoch 23: Val Loss 4009914.00000
Epoch 24: Val Loss 4013558.25000
Epoch 25: Val Loss 4005811.00000
Epoch 26: Val Loss 3995342.75000
Epoch 27: Val Loss 3990617.50000
Epoch 28: Val Loss 3975328.50000
Epoch 29: Val Loss 3994788.75000
Epoch 30: Val Loss 4012129.75000
Epoch 31: Val Loss 3951396.50000
Epoch 32: Val Loss 3960371.50000
Epoch 33: Val Loss 3939335.50000
Epoch 34: Val Loss 3946503.50000
Epoch 35: Val Loss 3935224.75000
Epoch 36: Val Loss 3931033.25000
Epoch 37: Val Loss 3968915.50000
Epoch 38: Val Loss 3941534.25000
Epoch 39: Val Loss 3914549.75000
Epoch 40: Val Loss 3916184.00000
Epoch 41: Val Loss 3905054.00000
Epoch 42: Val Loss 3916743.50000
Epoch 43: Val Loss 3938180.50000
Epoch 44: Val Loss 3900393.25000
Epoch 45: Val Loss 3938137.25000
Epoch 46: Val Loss 3892865.00000
Epoch 47: Val Loss 3875319.00000
Epoch 48: Val Loss 3880345.25000
Epoch 49: Val Loss 3951940.75000
Epoch 50: Val Loss 3875726.25000
Epoch 51: Val Loss 3900049.50000
Epoch 52: Val Loss 3869483.75000
Epoch 53: Val Loss 3867511.50000
Epoch 54: Val Loss 3871749.75000
Epoch 55: Val Loss 3903058.75000
Epoch 56: Val Loss 3868207.75000
Epoch 57: Val Loss 3866685.50000
Epoch 58: Val Loss 3878365.50000
Epoch 59: Val Loss 3858852.00000
Epoch 60: Val Loss 3862739.50000
Epoch 61: Val Loss 3887894.25000
Epoch 62: Val Loss 3847205.25000
Epoch 63: Val Loss 3838446.75000
Epoch 64: Val Loss 3875810.25000
Epoch 65: Val Loss 3854404.75000
Epoch 66: Val Loss 3856374.50000
Epoch 67: Val Loss 3854987.00000
Epoch 68: Val Loss 3853700.50000
Epoch 69: Val Loss 3837374.00000
Epoch 70: Val Loss 3840628.00000
Epoch 71: Val Loss 3975746.25000
Epoch 72: Val Loss 3846231.50000
Epoch 73: Val Loss 3860046.00000
Epoch 74: Val Loss 3844257.50000
Epoch 75: Val Loss 3849041.50000
Epoch 76: Val Loss 3854900.75000
Epoch 77: Val Loss 3860825.50000
Epoch 78: Val Loss 3869886.75000
Epoch 79: Val Loss 3858183.50000
Epoch 80: Val Loss 3861226.00000
Epoch 81: Val Loss 3866642.25000
Epoch 82: Val Loss 3861988.50000
Epoch 83: Val Loss 3864336.50000
Epoch 84: Val Loss 3873811.50000
Epoch 85: Val Loss 3887073.75000
Epoch 86: Val Loss 3880143.25000
Epoch 87: Val Loss 3861473.50000
Epoch 88: Val Loss 3873347.00000
Epoch 89: Val Loss 3882845.50000
Epoch 90: Val Loss 3912652.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3549331.204087015, 'MSE - std': 209400.98791872026, 'R2 - mean': 0.5822250054584607, 'R2 - std': 0.012728019600823906} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4590390.50000
Epoch 1: Val Loss 4232199.00000
Epoch 2: Val Loss 4121227.00000
Epoch 3: Val Loss 4083368.75000
Epoch 4: Val Loss 4056811.00000
Epoch 5: Val Loss 4009046.50000
Epoch 6: Val Loss 3974971.25000
Epoch 7: Val Loss 3970929.00000
Epoch 8: Val Loss 3963033.50000
Epoch 9: Val Loss 3941097.25000
Epoch 10: Val Loss 3917153.50000
Epoch 11: Val Loss 3887427.50000
Epoch 12: Val Loss 3872476.25000
Epoch 13: Val Loss 3861462.25000
Epoch 14: Val Loss 3846731.75000
Epoch 15: Val Loss 3864081.50000
Epoch 16: Val Loss 3840502.50000
Epoch 17: Val Loss 3839459.00000
Epoch 18: Val Loss 3842232.25000
Epoch 19: Val Loss 3789982.75000
Epoch 20: Val Loss 3808667.00000
Epoch 21: Val Loss 3793904.00000
Epoch 22: Val Loss 3847863.50000
Epoch 23: Val Loss 3775735.50000
Epoch 24: Val Loss 3757326.25000
Epoch 25: Val Loss 3750816.50000
Epoch 26: Val Loss 3757089.00000
Epoch 27: Val Loss 3750499.00000
Epoch 28: Val Loss 3760966.25000
Epoch 29: Val Loss 3773815.00000
Epoch 30: Val Loss 3764576.50000
Epoch 31: Val Loss 3723989.25000
Epoch 32: Val Loss 3723845.25000
Epoch 33: Val Loss 3764254.00000
Epoch 34: Val Loss 3734689.00000
Epoch 35: Val Loss 3740662.25000
Epoch 36: Val Loss 3761799.50000
Epoch 37: Val Loss 3718516.00000
Epoch 38: Val Loss 3774964.75000
Epoch 39: Val Loss 3725962.00000
Epoch 40: Val Loss 3701191.75000
Epoch 41: Val Loss 3731474.75000
Epoch 42: Val Loss 3702208.50000
Epoch 43: Val Loss 3719835.75000
Epoch 44: Val Loss 3703222.50000
Epoch 45: Val Loss 3718455.00000
Epoch 46: Val Loss 3718580.50000
Epoch 47: Val Loss 3729875.00000
Epoch 48: Val Loss 3725053.50000
Epoch 49: Val Loss 3718571.75000
Epoch 50: Val Loss 3694923.75000
Epoch 51: Val Loss 3783996.75000
Epoch 52: Val Loss 3695373.50000
Epoch 53: Val Loss 3706596.50000
Epoch 54: Val Loss 3694932.00000
Epoch 55: Val Loss 3706212.50000
Epoch 56: Val Loss 3763964.75000
Epoch 57: Val Loss 3706316.25000
Epoch 58: Val Loss 3707854.75000
Epoch 59: Val Loss 3708649.50000
Epoch 60: Val Loss 3714321.50000
Epoch 61: Val Loss 3725263.25000
Epoch 62: Val Loss 3725855.25000
Epoch 63: Val Loss 3722733.50000
Epoch 64: Val Loss 3741037.00000
Epoch 65: Val Loss 3737454.25000
Epoch 66: Val Loss 3736384.00000
Epoch 67: Val Loss 3747536.00000
Epoch 68: Val Loss 3770858.00000
Epoch 69: Val Loss 3776470.25000
Epoch 70: Val Loss 3773052.75000
Epoch 71: Val Loss 3758977.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3588691.1887527634, 'MSE - std': 193737.46536141634, 'R2 - mean': 0.5787439183400612, 'R2 - std': 0.012564066411670943} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4087124.75000
Epoch 1: Val Loss 3708681.50000
Epoch 2: Val Loss 3611120.25000
Epoch 3: Val Loss 3570886.50000
Epoch 4: Val Loss 3537652.50000
Epoch 5: Val Loss 3527815.75000
Epoch 6: Val Loss 3524943.75000
Epoch 7: Val Loss 3492316.00000
Epoch 8: Val Loss 3477480.50000
Epoch 9: Val Loss 3474830.25000
Epoch 10: Val Loss 3451985.50000
Epoch 11: Val Loss 3459579.75000
Epoch 12: Val Loss 3443795.00000
Epoch 13: Val Loss 3427261.75000
Epoch 14: Val Loss 3436661.75000
Epoch 15: Val Loss 3452509.50000
Epoch 16: Val Loss 3427117.50000
Epoch 17: Val Loss 3420182.25000
Epoch 18: Val Loss 3428218.75000
Epoch 19: Val Loss 3480955.50000
Epoch 20: Val Loss 3407569.25000
Epoch 21: Val Loss 3427120.75000
Epoch 22: Val Loss 3419204.00000
Epoch 23: Val Loss 3415248.75000
Epoch 24: Val Loss 3434656.25000
Epoch 25: Val Loss 3390750.50000
Epoch 26: Val Loss 3397833.75000
Epoch 27: Val Loss 3458887.75000
Epoch 28: Val Loss 3416488.00000
Epoch 29: Val Loss 3430831.25000
Epoch 30: Val Loss 3458424.25000
Epoch 31: Val Loss 3418518.00000
Epoch 32: Val Loss 3374479.75000
Epoch 33: Val Loss 3415492.75000
Epoch 34: Val Loss 3394510.00000
Epoch 35: Val Loss 3407283.25000
Epoch 36: Val Loss 3410683.25000
Epoch 37: Val Loss 3411631.50000
Epoch 38: Val Loss 3404178.75000
Epoch 39: Val Loss 3461108.50000
Epoch 40: Val Loss 3415501.25000
Epoch 41: Val Loss 3401332.75000
Epoch 42: Val Loss 3415726.75000
Epoch 43: Val Loss 3388385.00000
Epoch 44: Val Loss 3445149.50000
Epoch 45: Val Loss 3502629.50000
Epoch 46: Val Loss 3434273.50000
Epoch 47: Val Loss 3421397.50000
Epoch 48: Val Loss 3414690.75000
Epoch 49: Val Loss 3421104.50000
Epoch 50: Val Loss 3382310.25000
Epoch 51: Val Loss 3408820.25000
Epoch 52: Val Loss 3418151.00000
Epoch 53: Val Loss 3403685.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3547232.3748400947, 'MSE - std': 192100.74802538886, 'R2 - mean': 0.5794892263533948, 'R2 - std': 0.011336072863935702} 
 

Saving model.....
Results After CV: {'MSE - mean': 3547232.3748400947, 'MSE - std': 192100.74802538886, 'R2 - mean': 0.5794892263533948, 'R2 - std': 0.011336072863935702}
Train time: 5915.407383009396
Inference time: 6.6561736092204224
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 44 finished with value: 3547232.3748400947 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 43 with value: 3546744.9497103365.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4474679.50000
Epoch 1: Val Loss 4084503.50000
Epoch 2: Val Loss 3984070.50000
Epoch 3: Val Loss 3933565.50000
Epoch 4: Val Loss 3912872.00000
Epoch 5: Val Loss 3836708.75000
Epoch 6: Val Loss 3804281.50000
Epoch 7: Val Loss 3775363.00000
Epoch 8: Val Loss 3740711.00000
Epoch 9: Val Loss 3706496.00000
Epoch 10: Val Loss 3679735.75000
Epoch 11: Val Loss 3651918.00000
Epoch 12: Val Loss 3644701.50000
Epoch 13: Val Loss 3641731.50000
Epoch 14: Val Loss 3622780.75000
Epoch 15: Val Loss 3635923.00000
Epoch 16: Val Loss 3610134.00000
Epoch 17: Val Loss 3624567.75000
Epoch 18: Val Loss 3576939.00000
Epoch 19: Val Loss 3585298.25000
Epoch 20: Val Loss 3547110.75000
Epoch 21: Val Loss 3553318.25000
Epoch 22: Val Loss 3555615.50000
Epoch 23: Val Loss 3547340.75000
Epoch 24: Val Loss 3530010.75000
Epoch 25: Val Loss 3552291.00000
Epoch 26: Val Loss 3556046.25000
Epoch 27: Val Loss 3555429.00000
Epoch 28: Val Loss 3553431.75000
Epoch 29: Val Loss 3504251.25000
Epoch 30: Val Loss 3489056.00000
Epoch 31: Val Loss 3493612.75000
Epoch 32: Val Loss 3514034.75000
Epoch 33: Val Loss 3486160.00000
Epoch 34: Val Loss 3486816.25000
Epoch 35: Val Loss 3475558.25000
Epoch 36: Val Loss 3487372.50000
Epoch 37: Val Loss 3467433.75000
Epoch 38: Val Loss 3498552.00000
Epoch 39: Val Loss 3462103.25000
Epoch 40: Val Loss 3444639.75000
Epoch 41: Val Loss 3468211.00000
Epoch 42: Val Loss 3470338.50000
Epoch 43: Val Loss 3436958.75000
Epoch 44: Val Loss 3436245.25000
Epoch 45: Val Loss 3455130.00000
Epoch 46: Val Loss 3430291.75000
Epoch 47: Val Loss 3443157.75000
Epoch 48: Val Loss 3442729.50000
Epoch 49: Val Loss 3441621.50000
Epoch 50: Val Loss 3435191.75000
Epoch 51: Val Loss 3448381.25000
Epoch 52: Val Loss 3419133.00000
Epoch 53: Val Loss 3422289.75000
Epoch 54: Val Loss 3500039.25000
Epoch 55: Val Loss 3410630.25000
Epoch 56: Val Loss 3465017.25000
Epoch 57: Val Loss 3419999.75000
Epoch 58: Val Loss 3430814.75000
Epoch 59: Val Loss 3425749.25000
Epoch 60: Val Loss 3465535.75000
Epoch 61: Val Loss 3435365.00000
Epoch 62: Val Loss 3438944.00000
Epoch 63: Val Loss 3417581.25000
Epoch 64: Val Loss 3445470.25000
Epoch 65: Val Loss 3430433.50000
Epoch 66: Val Loss 3441830.75000
Epoch 67: Val Loss 3420826.25000
Epoch 68: Val Loss 3448118.25000
Epoch 69: Val Loss 3473865.75000
Epoch 70: Val Loss 3446161.25000
Epoch 71: Val Loss 3423395.00000
Epoch 72: Val Loss 3451353.00000
Epoch 73: Val Loss 3454036.00000
Epoch 74: Val Loss 3443809.50000
Epoch 75: Val Loss 3425001.25000
Epoch 76: Val Loss 3437998.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3419461.991671663, 'MSE - std': 0.0, 'R2 - mean': 0.5993566975210518, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4212402.00000
Epoch 1: Val Loss 3876517.75000
Epoch 2: Val Loss 3776475.00000
Epoch 3: Val Loss 3710832.00000
Epoch 4: Val Loss 3688214.50000
Epoch 5: Val Loss 3767502.75000
Epoch 6: Val Loss 3651703.00000
Epoch 7: Val Loss 3606161.75000
Epoch 8: Val Loss 3587300.50000
Epoch 9: Val Loss 3594455.25000
Epoch 10: Val Loss 3581327.75000
Epoch 11: Val Loss 3565397.25000
Epoch 12: Val Loss 3533881.25000
Epoch 13: Val Loss 3520045.25000
Epoch 14: Val Loss 3529766.25000
Epoch 15: Val Loss 3571091.75000
Epoch 16: Val Loss 3514990.25000
Epoch 17: Val Loss 3478117.25000
Epoch 18: Val Loss 3472169.25000
Epoch 19: Val Loss 3469221.50000
Epoch 20: Val Loss 3455440.75000
Epoch 21: Val Loss 3491483.25000
Epoch 22: Val Loss 3444764.75000
Epoch 23: Val Loss 3444340.50000
Epoch 24: Val Loss 3471482.50000
Epoch 25: Val Loss 3436252.75000
Epoch 26: Val Loss 3440718.00000
Epoch 27: Val Loss 3435061.50000
Epoch 28: Val Loss 3426909.50000
Epoch 29: Val Loss 3827401.25000
Epoch 30: Val Loss 3413313.50000
Epoch 31: Val Loss 3414078.50000
Epoch 32: Val Loss 3433909.25000
Epoch 33: Val Loss 3414133.00000
Epoch 34: Val Loss 3449324.00000
Epoch 35: Val Loss 3416690.00000
Epoch 36: Val Loss 3488017.75000
Epoch 37: Val Loss 3404495.75000
Epoch 38: Val Loss 3404895.75000
Epoch 39: Val Loss 3450646.75000
Epoch 40: Val Loss 3393094.25000
Epoch 41: Val Loss 3405001.75000
Epoch 42: Val Loss 3434868.25000
Epoch 43: Val Loss 3430081.00000
Epoch 44: Val Loss 3394491.00000
Epoch 45: Val Loss 3400574.75000
Epoch 46: Val Loss 3407054.00000
Epoch 47: Val Loss 3456702.75000
Epoch 48: Val Loss 3398578.00000
Epoch 49: Val Loss 3392946.50000
Epoch 50: Val Loss 3385043.00000
Epoch 51: Val Loss 3431434.75000
Epoch 52: Val Loss 3445335.75000
Epoch 53: Val Loss 3405286.00000
Epoch 54: Val Loss 3414273.50000
Epoch 55: Val Loss 3379316.50000
Epoch 56: Val Loss 3383588.25000
Epoch 57: Val Loss 3395016.00000
Epoch 58: Val Loss 3380327.50000
Epoch 59: Val Loss 3415711.75000
Epoch 60: Val Loss 3401218.00000
Epoch 61: Val Loss 3392868.50000
Epoch 62: Val Loss 3392844.50000
Epoch 63: Val Loss 3381329.75000
Epoch 64: Val Loss 3398335.75000
Epoch 65: Val Loss 3397213.00000
Epoch 66: Val Loss 3399450.00000
Epoch 67: Val Loss 3423853.25000
Epoch 68: Val Loss 3392622.50000
Epoch 69: Val Loss 3403298.25000
Epoch 70: Val Loss 3401841.50000
Epoch 71: Val Loss 3402360.25000
Epoch 72: Val Loss 3410875.50000
Epoch 73: Val Loss 3418274.25000
Epoch 74: Val Loss 3413401.50000
Epoch 75: Val Loss 3411526.00000
Epoch 76: Val Loss 3430055.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3404098.0331423436, 'MSE - std': 15363.958529319149, 'R2 - mean': 0.5880915601686723, 'R2 - std': 0.011265137352379495} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4978549.50000
Epoch 1: Val Loss 4553431.50000
Epoch 2: Val Loss 4439891.50000
Epoch 3: Val Loss 4411566.50000
Epoch 4: Val Loss 4358799.00000
Epoch 5: Val Loss 4302139.00000
Epoch 6: Val Loss 4285861.50000
Epoch 7: Val Loss 4232465.50000
Epoch 8: Val Loss 4228297.00000
Epoch 9: Val Loss 4195849.00000
Epoch 10: Val Loss 4179012.00000
Epoch 11: Val Loss 4150367.25000
Epoch 12: Val Loss 4136160.00000
Epoch 13: Val Loss 4172842.50000
Epoch 14: Val Loss 4119412.75000
Epoch 15: Val Loss 4111976.00000
Epoch 16: Val Loss 4083533.50000
Epoch 17: Val Loss 4120775.50000
Epoch 18: Val Loss 4077591.00000
Epoch 19: Val Loss 4080929.00000
Epoch 20: Val Loss 4075740.75000
Epoch 21: Val Loss 4059304.25000
Epoch 22: Val Loss 4021427.50000
Epoch 23: Val Loss 4049850.00000
Epoch 24: Val Loss 4009233.00000
Epoch 25: Val Loss 4024222.75000
Epoch 26: Val Loss 4006738.75000
Epoch 27: Val Loss 3985922.25000
Epoch 28: Val Loss 3985472.00000
Epoch 29: Val Loss 3980228.00000
Epoch 30: Val Loss 3981624.75000
Epoch 31: Val Loss 3996122.50000
Epoch 32: Val Loss 3958766.25000
Epoch 33: Val Loss 3967011.50000
Epoch 34: Val Loss 3952027.75000
Epoch 35: Val Loss 3951720.25000
Epoch 36: Val Loss 3988739.50000
Epoch 37: Val Loss 3939648.00000
Epoch 38: Val Loss 3957733.75000
Epoch 39: Val Loss 3960909.00000
Epoch 40: Val Loss 3924342.25000
Epoch 41: Val Loss 3923621.75000
Epoch 42: Val Loss 3930940.75000
Epoch 43: Val Loss 3914361.50000
Epoch 44: Val Loss 3916319.25000
Epoch 45: Val Loss 3897300.00000
Epoch 46: Val Loss 3912448.00000
Epoch 47: Val Loss 3961497.25000
Epoch 48: Val Loss 3899438.25000
Epoch 49: Val Loss 3893348.50000
Epoch 50: Val Loss 3885668.75000
Epoch 51: Val Loss 3881478.25000
Epoch 52: Val Loss 3879493.75000
Epoch 53: Val Loss 3875237.25000
Epoch 54: Val Loss 3878771.50000
Epoch 55: Val Loss 3876987.25000
Epoch 56: Val Loss 3868072.00000
Epoch 57: Val Loss 3858870.50000
Epoch 58: Val Loss 3930262.50000
Epoch 59: Val Loss 3860536.00000
Epoch 60: Val Loss 3866447.75000
Epoch 61: Val Loss 3886677.25000
Epoch 62: Val Loss 3886571.00000
Epoch 63: Val Loss 3858040.25000
Epoch 64: Val Loss 3879680.00000
Epoch 65: Val Loss 3842219.25000
Epoch 66: Val Loss 3862563.00000
Epoch 67: Val Loss 3869658.50000
Epoch 68: Val Loss 3862544.00000
Epoch 69: Val Loss 3860721.75000
Epoch 70: Val Loss 3855892.50000
Epoch 71: Val Loss 3842763.00000
Epoch 72: Val Loss 3846982.50000
Epoch 73: Val Loss 3854677.75000
Epoch 74: Val Loss 3851463.00000
Epoch 75: Val Loss 3854984.75000
Epoch 76: Val Loss 3860865.75000
Epoch 77: Val Loss 3849267.50000
Epoch 78: Val Loss 3900123.25000
Epoch 79: Val Loss 3865604.00000
Epoch 80: Val Loss 3845357.50000
Epoch 81: Val Loss 3855110.25000
Epoch 82: Val Loss 3860250.00000
Epoch 83: Val Loss 3864750.75000
Epoch 84: Val Loss 3886995.50000
Epoch 85: Val Loss 3879794.25000
Epoch 86: Val Loss 3879838.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3555552.536598261, 'MSE - std': 214556.0549490134, 'R2 - mean': 0.5815149414089241, 'R2 - std': 0.013080750806718198} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4573800.50000
Epoch 1: Val Loss 4234130.50000
Epoch 2: Val Loss 4138850.25000
Epoch 3: Val Loss 4134126.75000
Epoch 4: Val Loss 4022413.50000
Epoch 5: Val Loss 4017617.75000
Epoch 6: Val Loss 3977134.75000
Epoch 7: Val Loss 3940570.00000
Epoch 8: Val Loss 3995031.50000
Epoch 9: Val Loss 3904684.25000
Epoch 10: Val Loss 3903701.75000
Epoch 11: Val Loss 3982069.75000
Epoch 12: Val Loss 3870885.25000
Epoch 13: Val Loss 3848926.75000
Epoch 14: Val Loss 3843335.50000
Epoch 15: Val Loss 3834199.50000
Epoch 16: Val Loss 3816848.00000
Epoch 17: Val Loss 3814180.75000
Epoch 18: Val Loss 3824280.75000
Epoch 19: Val Loss 3816442.00000
Epoch 20: Val Loss 3789851.75000
Epoch 21: Val Loss 3777127.00000
Epoch 22: Val Loss 3775646.25000
Epoch 23: Val Loss 3794574.00000
Epoch 24: Val Loss 3753080.25000
Epoch 25: Val Loss 3751419.25000
Epoch 26: Val Loss 3747068.75000
Epoch 27: Val Loss 3748020.00000
Epoch 28: Val Loss 3735995.75000
Epoch 29: Val Loss 3749934.00000
Epoch 30: Val Loss 3747059.00000
Epoch 31: Val Loss 3736573.50000
Epoch 32: Val Loss 3744379.00000
Epoch 33: Val Loss 3730493.00000
Epoch 34: Val Loss 3733165.00000
Epoch 35: Val Loss 3721717.75000
Epoch 36: Val Loss 3716072.75000
Epoch 37: Val Loss 3726239.25000
Epoch 38: Val Loss 3700115.00000
Epoch 39: Val Loss 3737275.75000
Epoch 40: Val Loss 3734202.00000
Epoch 41: Val Loss 3707564.75000
Epoch 42: Val Loss 3691464.25000
Epoch 43: Val Loss 3715332.00000
Epoch 44: Val Loss 3708393.25000
Epoch 45: Val Loss 3710722.75000
Epoch 46: Val Loss 3713735.50000
Epoch 47: Val Loss 3706933.75000
Epoch 48: Val Loss 3700687.25000
Epoch 49: Val Loss 3743404.75000
Epoch 50: Val Loss 3693769.50000
Epoch 51: Val Loss 3694557.50000
Epoch 52: Val Loss 3709088.00000
Epoch 53: Val Loss 3714877.50000
Epoch 54: Val Loss 3712681.50000
Epoch 55: Val Loss 3706430.00000
Epoch 56: Val Loss 3725870.75000
Epoch 57: Val Loss 3722651.25000
Epoch 58: Val Loss 3704157.50000
Epoch 59: Val Loss 3726379.75000
Epoch 60: Val Loss 3724579.50000
Epoch 61: Val Loss 3725342.75000
Epoch 62: Val Loss 3710767.75000
Epoch 63: Val Loss 3703606.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591495.4382596654, 'MSE - std': 195962.75685952997, 'R2 - mean': 0.5784281941011975, 'R2 - std': 0.012526514202916493} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4106571.25000
Epoch 1: Val Loss 3728493.00000
Epoch 2: Val Loss 3624366.00000
Epoch 3: Val Loss 3602001.25000
Epoch 4: Val Loss 3549801.50000
Epoch 5: Val Loss 3504206.50000
Epoch 6: Val Loss 3509870.25000
Epoch 7: Val Loss 3482282.00000
Epoch 8: Val Loss 3456465.50000
Epoch 9: Val Loss 3461901.75000
Epoch 10: Val Loss 3447247.75000
Epoch 11: Val Loss 3447552.75000
Epoch 12: Val Loss 3424961.75000
Epoch 13: Val Loss 3410346.75000
Epoch 14: Val Loss 3455860.75000
Epoch 15: Val Loss 3423780.75000
Epoch 16: Val Loss 3406800.25000
Epoch 17: Val Loss 3470912.75000
Epoch 18: Val Loss 3394672.50000
Epoch 19: Val Loss 3419823.00000
Epoch 20: Val Loss 3403419.00000
Epoch 21: Val Loss 3396810.25000
Epoch 22: Val Loss 3394758.25000
Epoch 23: Val Loss 3401126.25000
Epoch 24: Val Loss 3433864.00000
Epoch 25: Val Loss 3417529.50000
Epoch 26: Val Loss 3424071.75000
Epoch 27: Val Loss 3440356.50000
Epoch 28: Val Loss 3380373.50000
Epoch 29: Val Loss 3413660.50000
Epoch 30: Val Loss 3410633.75000
Epoch 31: Val Loss 3428619.50000
Epoch 32: Val Loss 3372838.00000
Epoch 33: Val Loss 3414587.00000
Epoch 34: Val Loss 3457970.75000
Epoch 35: Val Loss 3407114.75000
Epoch 36: Val Loss 3381314.25000
Epoch 37: Val Loss 3406321.50000
Epoch 38: Val Loss 3397314.25000
Epoch 39: Val Loss 3411113.25000
Epoch 40: Val Loss 3410555.50000
Epoch 41: Val Loss 3391900.50000
Epoch 42: Val Loss 3457015.75000
Epoch 43: Val Loss 3377793.25000
Epoch 44: Val Loss 3397480.25000
Epoch 45: Val Loss 3403669.50000
Epoch 46: Val Loss 3568260.75000
Epoch 47: Val Loss 3478721.75000
Epoch 48: Val Loss 3406013.50000
Epoch 49: Val Loss 3416274.50000
Epoch 50: Val Loss 3396949.00000
Epoch 51: Val Loss 3418894.25000
Epoch 52: Val Loss 3412113.75000
Epoch 53: Val Loss 3384780.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3549707.9901860156, 'MSE - std': 194180.03225569247, 'R2 - mean': 0.5792079733317831, 'R2 - std': 0.011312076248616139} 
 

Saving model.....
Results After CV: {'MSE - mean': 3549707.9901860156, 'MSE - std': 194180.03225569247, 'R2 - mean': 0.5792079733317831, 'R2 - std': 0.011312076248616139}
Train time: 5341.255229097418
Inference time: 6.586791335209273
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 45 finished with value: 3549707.9901860156 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 43 with value: 3546744.9497103365.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4517318.00000
Epoch 1: Val Loss 4080126.00000
Epoch 2: Val Loss 3986756.00000
Epoch 3: Val Loss 3935272.75000
Epoch 4: Val Loss 3851920.00000
Epoch 5: Val Loss 3814034.75000
Epoch 6: Val Loss 3770492.25000
Epoch 7: Val Loss 3830782.75000
Epoch 8: Val Loss 3717279.75000
Epoch 9: Val Loss 3688940.75000
Epoch 10: Val Loss 3667074.75000
Epoch 11: Val Loss 3663121.50000
Epoch 12: Val Loss 3633339.25000
Epoch 13: Val Loss 3641108.00000
Epoch 14: Val Loss 3605378.00000
Epoch 15: Val Loss 3603990.25000
Epoch 16: Val Loss 3587740.75000
Epoch 17: Val Loss 3593241.50000
Epoch 18: Val Loss 3589039.75000
Epoch 19: Val Loss 3609221.75000
Epoch 20: Val Loss 3549606.25000
Epoch 21: Val Loss 3559290.00000
Epoch 22: Val Loss 3546747.50000
Epoch 23: Val Loss 3523157.25000
Epoch 24: Val Loss 3516679.75000
Epoch 25: Val Loss 3515691.50000
Epoch 26: Val Loss 3529275.75000
Epoch 27: Val Loss 3504195.25000
Epoch 28: Val Loss 3510255.25000
Epoch 29: Val Loss 3497360.75000
Epoch 30: Val Loss 3480630.00000
Epoch 31: Val Loss 3485149.00000
Epoch 32: Val Loss 3489173.00000
Epoch 33: Val Loss 3529109.25000
Epoch 34: Val Loss 3470455.75000
Epoch 35: Val Loss 3471846.00000
Epoch 36: Val Loss 3487386.75000
Epoch 37: Val Loss 3450336.25000
Epoch 38: Val Loss 3453502.00000
Epoch 39: Val Loss 3457359.50000
Epoch 40: Val Loss 3460881.75000
Epoch 41: Val Loss 3490003.75000
Epoch 42: Val Loss 3444332.25000
Epoch 43: Val Loss 3452427.75000
Epoch 44: Val Loss 3441855.25000
Epoch 45: Val Loss 3436606.00000
Epoch 46: Val Loss 3545156.75000
Epoch 47: Val Loss 3446590.25000
Epoch 48: Val Loss 3423931.50000
Epoch 49: Val Loss 3421457.50000
Epoch 50: Val Loss 3429105.00000
Epoch 51: Val Loss 3427443.25000
Epoch 52: Val Loss 3477472.00000
Epoch 53: Val Loss 3432595.50000
Epoch 54: Val Loss 3458736.75000
Epoch 55: Val Loss 3426357.25000
Epoch 56: Val Loss 3423155.75000
Epoch 57: Val Loss 3438123.50000
Epoch 58: Val Loss 3433735.00000
Epoch 59: Val Loss 3426692.75000
Epoch 60: Val Loss 3486541.75000
Epoch 61: Val Loss 3441113.75000
Epoch 62: Val Loss 3468271.50000
Epoch 63: Val Loss 3426345.75000
Epoch 64: Val Loss 3426086.25000
Epoch 65: Val Loss 3433636.50000
Epoch 66: Val Loss 3440285.75000
Epoch 67: Val Loss 3443268.00000
Epoch 68: Val Loss 3451136.50000
Epoch 69: Val Loss 3414353.50000
Epoch 70: Val Loss 3484129.25000
Epoch 71: Val Loss 3430347.50000
Epoch 72: Val Loss 3581447.50000
Epoch 73: Val Loss 3441565.25000
Epoch 74: Val Loss 3468287.25000
Epoch 75: Val Loss 3466487.50000
Epoch 76: Val Loss 3451096.25000
Epoch 77: Val Loss 3477620.50000
Epoch 78: Val Loss 3476899.00000
Epoch 79: Val Loss 3466286.50000
Epoch 80: Val Loss 3485016.00000
Epoch 81: Val Loss 3443576.50000
Epoch 82: Val Loss 3494554.75000
Epoch 83: Val Loss 3501190.25000
Epoch 84: Val Loss 3508394.50000
Epoch 85: Val Loss 3457193.50000
Epoch 86: Val Loss 3495604.75000
Epoch 87: Val Loss 3498091.50000
Epoch 88: Val Loss 3495667.75000
Epoch 89: Val Loss 3571977.50000
Epoch 90: Val Loss 3527414.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3423790.7079149596, 'MSE - std': 0.0, 'R2 - mean': 0.5988495209022058, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4272914.00000
Epoch 1: Val Loss 3869633.75000
Epoch 2: Val Loss 3795476.00000
Epoch 3: Val Loss 3752550.25000
Epoch 4: Val Loss 3698740.00000
Epoch 5: Val Loss 3681189.75000
Epoch 6: Val Loss 3650748.25000
Epoch 7: Val Loss 3615525.25000
Epoch 8: Val Loss 3618667.25000
Epoch 9: Val Loss 3568523.00000
Epoch 10: Val Loss 3636006.50000
Epoch 11: Val Loss 3569802.25000
Epoch 12: Val Loss 3555818.50000
Epoch 13: Val Loss 3568943.75000
Epoch 14: Val Loss 3520385.50000
Epoch 15: Val Loss 3786475.25000
Epoch 16: Val Loss 3528041.50000
Epoch 17: Val Loss 3502429.00000
Epoch 18: Val Loss 3502917.50000
Epoch 19: Val Loss 3484848.00000
Epoch 20: Val Loss 3529141.25000
Epoch 21: Val Loss 3466138.25000
Epoch 22: Val Loss 3494777.50000
Epoch 23: Val Loss 3461028.25000
Epoch 24: Val Loss 3475914.25000
Epoch 25: Val Loss 3457070.75000
Epoch 26: Val Loss 3440995.75000
Epoch 27: Val Loss 3437255.00000
Epoch 28: Val Loss 3465283.25000
Epoch 29: Val Loss 3472534.00000
Epoch 30: Val Loss 3429373.75000
Epoch 31: Val Loss 3468519.25000
Epoch 32: Val Loss 3403313.50000
Epoch 33: Val Loss 3426313.50000
Epoch 34: Val Loss 3439918.50000
Epoch 35: Val Loss 3423616.50000
Epoch 36: Val Loss 3416476.75000
Epoch 37: Val Loss 3464631.75000
Epoch 38: Val Loss 3404847.75000
Epoch 39: Val Loss 3411628.25000
Epoch 40: Val Loss 3411970.00000
Epoch 41: Val Loss 3460764.50000
Epoch 42: Val Loss 3451832.75000
Epoch 43: Val Loss 3408143.00000
Epoch 44: Val Loss 3438381.75000
Epoch 45: Val Loss 3401352.75000
Epoch 46: Val Loss 3387445.75000
Epoch 47: Val Loss 3406868.50000
Epoch 48: Val Loss 3401217.00000
Epoch 49: Val Loss 3508255.00000
Epoch 50: Val Loss 3445853.00000
Epoch 51: Val Loss 3397097.25000
Epoch 52: Val Loss 3386801.00000
Epoch 53: Val Loss 3400862.25000
Epoch 54: Val Loss 3414727.75000
Epoch 55: Val Loss 3409276.00000
Epoch 56: Val Loss 3396342.25000
Epoch 57: Val Loss 3383416.25000
Epoch 58: Val Loss 3397745.50000
Epoch 59: Val Loss 3406168.25000
Epoch 60: Val Loss 3407175.75000
Epoch 61: Val Loss 3410357.25000
Epoch 62: Val Loss 3393606.25000
Epoch 63: Val Loss 3382858.75000
Epoch 64: Val Loss 3390993.50000
Epoch 65: Val Loss 3427545.50000
Epoch 66: Val Loss 3408565.75000
Epoch 67: Val Loss 3401781.50000
Epoch 68: Val Loss 3423927.25000
Epoch 69: Val Loss 3405524.75000
Epoch 70: Val Loss 3438501.00000
Epoch 71: Val Loss 3400819.00000
Epoch 72: Val Loss 3391867.50000
Epoch 73: Val Loss 3397132.25000
Epoch 74: Val Loss 3454274.25000
Epoch 75: Val Loss 3427207.75000
Epoch 76: Val Loss 3448223.75000
Epoch 77: Val Loss 3407235.00000
Epoch 78: Val Loss 3432559.25000
Epoch 79: Val Loss 3416597.50000
Epoch 80: Val Loss 3520742.00000
Epoch 81: Val Loss 3405145.50000
Epoch 82: Val Loss 3440544.50000
Epoch 83: Val Loss 3441619.00000
Epoch 84: Val Loss 3414860.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3406964.469199859, 'MSE - std': 16826.238715100568, 'R2 - mean': 0.5877502987562435, 'R2 - std': 0.011099222145962262} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4956364.00000
Epoch 1: Val Loss 4572433.00000
Epoch 2: Val Loss 4458023.00000
Epoch 3: Val Loss 4368473.00000
Epoch 4: Val Loss 4329731.00000
Epoch 5: Val Loss 4311263.50000
Epoch 6: Val Loss 4288841.50000
Epoch 7: Val Loss 4230597.00000
Epoch 8: Val Loss 4247508.50000
Epoch 9: Val Loss 4201265.50000
Epoch 10: Val Loss 4173833.50000
Epoch 11: Val Loss 4143521.50000
Epoch 12: Val Loss 4126882.75000
Epoch 13: Val Loss 4104625.75000
Epoch 14: Val Loss 4110058.50000
Epoch 15: Val Loss 4087640.75000
Epoch 16: Val Loss 4066684.75000
Epoch 17: Val Loss 4073111.50000
Epoch 18: Val Loss 4055334.25000
Epoch 19: Val Loss 4044244.75000
Epoch 20: Val Loss 4054335.25000
Epoch 21: Val Loss 4039450.00000
Epoch 22: Val Loss 4009554.75000
Epoch 23: Val Loss 4023310.00000
Epoch 24: Val Loss 4006281.50000
Epoch 25: Val Loss 4027021.00000
Epoch 26: Val Loss 4025779.50000
Epoch 27: Val Loss 3979178.50000
Epoch 28: Val Loss 3978569.50000
Epoch 29: Val Loss 3961608.25000
Epoch 30: Val Loss 3960435.00000
Epoch 31: Val Loss 3964724.75000
Epoch 32: Val Loss 4066680.00000
Epoch 33: Val Loss 3960756.00000
Epoch 34: Val Loss 3987349.75000
Epoch 35: Val Loss 3945268.00000
Epoch 36: Val Loss 3936249.25000
Epoch 37: Val Loss 3924788.00000
Epoch 38: Val Loss 3960066.25000
Epoch 39: Val Loss 4064481.50000
Epoch 40: Val Loss 3944118.50000
Epoch 41: Val Loss 3922439.00000
Epoch 42: Val Loss 3928819.00000
Epoch 43: Val Loss 3913966.00000
Epoch 44: Val Loss 3927015.00000
Epoch 45: Val Loss 3901415.00000
Epoch 46: Val Loss 3899044.50000
Epoch 47: Val Loss 3925198.25000
Epoch 48: Val Loss 3886976.50000
Epoch 49: Val Loss 3907041.00000
Epoch 50: Val Loss 3900750.75000
Epoch 51: Val Loss 3909324.75000
Epoch 52: Val Loss 3878959.75000
Epoch 53: Val Loss 3890974.00000
Epoch 54: Val Loss 3867063.00000
Epoch 55: Val Loss 3868636.75000
Epoch 56: Val Loss 3883246.00000
Epoch 57: Val Loss 3940802.75000
Epoch 58: Val Loss 3935884.75000
Epoch 59: Val Loss 3869038.25000
Epoch 60: Val Loss 3889777.00000
Epoch 61: Val Loss 3853412.75000
Epoch 62: Val Loss 3872454.25000
Epoch 63: Val Loss 3924710.25000
Epoch 64: Val Loss 3852362.50000
Epoch 65: Val Loss 3930229.25000
Epoch 66: Val Loss 3892689.75000
Epoch 67: Val Loss 3852555.75000
Epoch 68: Val Loss 3854131.00000
Epoch 69: Val Loss 3858620.25000
Epoch 70: Val Loss 3886277.75000
Epoch 71: Val Loss 3863029.25000
Epoch 72: Val Loss 3868735.75000
Epoch 73: Val Loss 3954494.00000
Epoch 74: Val Loss 3857003.25000
Epoch 75: Val Loss 3863220.00000
Epoch 76: Val Loss 3856179.00000
Epoch 77: Val Loss 3863051.75000
Epoch 78: Val Loss 3874362.00000
Epoch 79: Val Loss 3858357.75000
Epoch 80: Val Loss 3870155.00000
Epoch 81: Val Loss 3861765.75000
Epoch 82: Val Loss 3848589.00000
Epoch 83: Val Loss 3925424.50000
Epoch 84: Val Loss 3894708.00000
Epoch 85: Val Loss 3862366.75000
Epoch 86: Val Loss 3865804.25000
Epoch 87: Val Loss 3924455.00000
Epoch 88: Val Loss 3937374.25000
Epoch 89: Val Loss 3878832.50000
Epoch 90: Val Loss 3880944.50000
Epoch 91: Val Loss 3877578.50000
Epoch 92: Val Loss 3899922.25000
Epoch 93: Val Loss 3886455.00000
Epoch 94: Val Loss 3891704.75000
Epoch 95: Val Loss 3939342.00000
Epoch 96: Val Loss 3911079.00000
Epoch 97: Val Loss 3912311.50000
Epoch 98: Val Loss 3886780.75000
Epoch 99: Val Loss 3952741.25000
Saved Losses
{'MSE - mean': 3559400.4534228463, 'MSE - std': 216014.36706446187, 'R2 - mean': 0.5810707500606397, 'R2 - std': 0.013090501507486162} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4583019.00000
Epoch 1: Val Loss 4215311.50000
Epoch 2: Val Loss 4089588.50000
Epoch 3: Val Loss 4050789.25000
Epoch 4: Val Loss 4002281.25000
Epoch 5: Val Loss 3964505.25000
Epoch 6: Val Loss 3950888.25000
Epoch 7: Val Loss 3921342.75000
Epoch 8: Val Loss 3885151.75000
Epoch 9: Val Loss 3870068.00000
Epoch 10: Val Loss 3851594.00000
Epoch 11: Val Loss 3839794.75000
Epoch 12: Val Loss 3838439.00000
Epoch 13: Val Loss 3834079.25000
Epoch 14: Val Loss 3812124.75000
Epoch 15: Val Loss 3822067.00000
Epoch 16: Val Loss 3790581.25000
Epoch 17: Val Loss 3791331.50000
Epoch 18: Val Loss 3763502.00000
Epoch 19: Val Loss 3765968.50000
Epoch 20: Val Loss 3767494.50000
Epoch 21: Val Loss 3758221.00000
Epoch 22: Val Loss 3766437.25000
Epoch 23: Val Loss 3745799.00000
Epoch 24: Val Loss 3755454.25000
Epoch 25: Val Loss 3753787.25000
Epoch 26: Val Loss 3762233.50000
Epoch 27: Val Loss 3740263.75000
Epoch 28: Val Loss 3760045.00000
Epoch 29: Val Loss 3728266.50000
Epoch 30: Val Loss 3720243.50000
Epoch 31: Val Loss 3740248.25000
Epoch 32: Val Loss 3714383.25000
Epoch 33: Val Loss 3703505.00000
Epoch 34: Val Loss 3710463.25000
Epoch 35: Val Loss 3768354.75000
Epoch 36: Val Loss 3734134.50000
Epoch 37: Val Loss 3723997.00000
Epoch 38: Val Loss 3708922.50000
Epoch 39: Val Loss 3719834.50000
Epoch 40: Val Loss 3707317.75000
Epoch 41: Val Loss 3731483.00000
Epoch 42: Val Loss 3680335.25000
Epoch 43: Val Loss 3736293.25000
Epoch 44: Val Loss 3715287.75000
Epoch 45: Val Loss 3717758.00000
Epoch 46: Val Loss 3693627.25000
Epoch 47: Val Loss 3694788.00000
Epoch 48: Val Loss 3743684.75000
Epoch 49: Val Loss 3721931.25000
Epoch 50: Val Loss 3722984.25000
Epoch 51: Val Loss 3731418.00000
Epoch 52: Val Loss 3697329.50000
Epoch 53: Val Loss 3693193.50000
Epoch 54: Val Loss 3738998.25000
Epoch 55: Val Loss 3717118.00000
Epoch 56: Val Loss 3881004.75000
Epoch 57: Val Loss 3721708.75000
Epoch 58: Val Loss 3721936.50000
Epoch 59: Val Loss 3722798.25000
Epoch 60: Val Loss 3797663.75000
Epoch 61: Val Loss 3736430.75000
Epoch 62: Val Loss 3760398.25000
Epoch 63: Val Loss 3762527.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3593308.4938922697, 'MSE - std': 196076.3134831007, 'R2 - mean': 0.578220000966088, 'R2 - std': 0.012365323832734205} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4156081.50000
Epoch 1: Val Loss 3739791.75000
Epoch 2: Val Loss 3638570.50000
Epoch 3: Val Loss 3596317.25000
Epoch 4: Val Loss 3545433.00000
Epoch 5: Val Loss 3558456.25000
Epoch 6: Val Loss 3558880.00000
Epoch 7: Val Loss 3528541.75000
Epoch 8: Val Loss 3467307.75000
Epoch 9: Val Loss 3472953.50000
Epoch 10: Val Loss 3464102.00000
Epoch 11: Val Loss 3460609.25000
Epoch 12: Val Loss 3463063.75000
Epoch 13: Val Loss 3435502.00000
Epoch 14: Val Loss 3418764.75000
Epoch 15: Val Loss 3415367.25000
Epoch 16: Val Loss 3423085.75000
Epoch 17: Val Loss 3420855.75000
Epoch 18: Val Loss 3404520.00000
Epoch 19: Val Loss 3408019.25000
Epoch 20: Val Loss 3420811.00000
Epoch 21: Val Loss 3406926.75000
Epoch 22: Val Loss 3466206.00000
Epoch 23: Val Loss 3391923.00000
Epoch 24: Val Loss 3428477.75000
Epoch 25: Val Loss 3455384.25000
Epoch 26: Val Loss 3394714.25000
Epoch 27: Val Loss 3378378.25000
Epoch 28: Val Loss 3392675.00000
Epoch 29: Val Loss 3388234.25000
Epoch 30: Val Loss 3435196.25000
Epoch 31: Val Loss 3401991.75000
Epoch 32: Val Loss 3432489.25000
Epoch 33: Val Loss 3392531.50000
Epoch 34: Val Loss 3418751.25000
Epoch 35: Val Loss 3388899.25000
Epoch 36: Val Loss 3491461.75000
Epoch 37: Val Loss 3395361.50000
Epoch 38: Val Loss 3390568.75000
Epoch 39: Val Loss 3396388.75000
Epoch 40: Val Loss 3409549.00000
Epoch 41: Val Loss 3392130.25000
Epoch 42: Val Loss 3393336.50000
Epoch 43: Val Loss 3397505.50000
Epoch 44: Val Loss 3389835.00000
Epoch 45: Val Loss 3394314.00000
Epoch 46: Val Loss 3392226.50000
Epoch 47: Val Loss 3396971.50000
Epoch 48: Val Loss 3408863.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553093.7899638666, 'MSE - std': 192939.43665175073, 'R2 - mean': 0.5788024442309582, 'R2 - std': 0.011121058736373892} 
 

Saving model.....
Results After CV: {'MSE - mean': 3553093.7899638666, 'MSE - std': 192939.43665175073, 'R2 - mean': 0.5788024442309582, 'R2 - std': 0.011121058736373892}
Train time: 5775.240061882813
Inference time: 6.5298030294012275
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 46 finished with value: 3553093.7899638666 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 43 with value: 3546744.9497103365.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4572270.50000
Epoch 1: Val Loss 4118765.50000
Epoch 2: Val Loss 4054476.75000
Epoch 3: Val Loss 3946983.00000
Epoch 4: Val Loss 3887868.75000
Epoch 5: Val Loss 3848712.00000
Epoch 6: Val Loss 3816076.75000
Epoch 7: Val Loss 3821531.00000
Epoch 8: Val Loss 3779043.50000
Epoch 9: Val Loss 3783425.00000
Epoch 10: Val Loss 3755235.50000
Epoch 11: Val Loss 3738123.25000
Epoch 12: Val Loss 3735584.50000
Epoch 13: Val Loss 3695783.75000
Epoch 14: Val Loss 3678358.50000
Epoch 15: Val Loss 3670902.25000
Epoch 16: Val Loss 3693416.25000
Epoch 17: Val Loss 3665771.25000
Epoch 18: Val Loss 3722479.75000
Epoch 19: Val Loss 3662905.50000
Epoch 20: Val Loss 3645551.25000
Epoch 21: Val Loss 3671667.50000
Epoch 22: Val Loss 3624851.50000
Epoch 23: Val Loss 3634262.50000
Epoch 24: Val Loss 3613437.00000
Epoch 25: Val Loss 3612355.00000
Epoch 26: Val Loss 3620545.50000
Epoch 27: Val Loss 3605357.25000
Epoch 28: Val Loss 3603534.75000
Epoch 29: Val Loss 3636718.00000
Epoch 30: Val Loss 3627218.25000
Epoch 31: Val Loss 3588251.25000
Epoch 32: Val Loss 3591342.75000
Epoch 33: Val Loss 3595084.50000
Epoch 34: Val Loss 3580568.00000
Epoch 35: Val Loss 3587433.00000
Epoch 36: Val Loss 3604391.25000
Epoch 37: Val Loss 3573139.75000
Epoch 38: Val Loss 3585206.25000
Epoch 39: Val Loss 3586720.75000
Epoch 40: Val Loss 3586792.50000
Epoch 41: Val Loss 3588436.50000
Epoch 42: Val Loss 3564850.75000
Epoch 43: Val Loss 3600543.25000
Epoch 44: Val Loss 3570980.25000
Epoch 45: Val Loss 3576543.75000
Epoch 46: Val Loss 3575414.00000
Epoch 47: Val Loss 3589465.25000
Epoch 48: Val Loss 3570121.75000
Epoch 49: Val Loss 3559814.00000
Epoch 50: Val Loss 3560902.50000
Epoch 51: Val Loss 3556620.75000
Epoch 52: Val Loss 3563126.25000
Epoch 53: Val Loss 3549294.50000
Epoch 54: Val Loss 3559782.25000
Epoch 55: Val Loss 3581469.25000
Epoch 56: Val Loss 3547351.00000
Epoch 57: Val Loss 3561308.50000
Epoch 58: Val Loss 3552468.75000
Epoch 59: Val Loss 3539866.75000
Epoch 60: Val Loss 3544276.75000
Epoch 61: Val Loss 3560434.00000
Epoch 62: Val Loss 3563337.25000
Epoch 63: Val Loss 3548688.75000
Epoch 64: Val Loss 3534190.75000
Epoch 65: Val Loss 3539023.00000
Epoch 66: Val Loss 3541390.50000
Epoch 67: Val Loss 3556602.25000
Epoch 68: Val Loss 3539261.25000
Epoch 69: Val Loss 3530263.50000
Epoch 70: Val Loss 3564089.50000
Epoch 71: Val Loss 3545686.00000
Epoch 72: Val Loss 3545473.50000
Epoch 73: Val Loss 3528231.75000
Epoch 74: Val Loss 3533166.00000
Epoch 75: Val Loss 3560535.50000
Epoch 76: Val Loss 3530506.75000
Epoch 77: Val Loss 3527530.00000
Epoch 78: Val Loss 3540977.50000
Epoch 79: Val Loss 3529368.00000
Epoch 80: Val Loss 3541573.75000
Epoch 81: Val Loss 3549822.25000
Epoch 82: Val Loss 3523926.25000
Epoch 83: Val Loss 3585169.50000
Epoch 84: Val Loss 3517141.75000
Epoch 85: Val Loss 3542251.25000
Epoch 86: Val Loss 3524176.25000
Epoch 87: Val Loss 3550334.25000
Epoch 88: Val Loss 3543339.00000
Epoch 89: Val Loss 3564474.25000
Epoch 90: Val Loss 3526557.75000
Epoch 91: Val Loss 3531468.75000
Epoch 92: Val Loss 3528718.75000
Epoch 93: Val Loss 3534560.50000
Epoch 94: Val Loss 3535437.25000
Epoch 95: Val Loss 3514573.00000
Epoch 96: Val Loss 3506348.75000
Epoch 97: Val Loss 3516533.75000
Epoch 98: Val Loss 3518829.00000
Epoch 99: Val Loss 3513800.25000
Saved Losses
{'MSE - mean': 3522184.547577527, 'MSE - std': 0.0, 'R2 - mean': 0.5873211480289271, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4260515.50000
Epoch 1: Val Loss 3912922.00000
Epoch 2: Val Loss 3790397.50000
Epoch 3: Val Loss 3756131.00000
Epoch 4: Val Loss 3718125.00000
Epoch 5: Val Loss 3661995.75000
Epoch 6: Val Loss 3638162.75000
Epoch 7: Val Loss 3634190.25000
Epoch 8: Val Loss 3608438.25000
Epoch 9: Val Loss 3620022.25000
Epoch 10: Val Loss 3577935.75000
Epoch 11: Val Loss 3561734.75000
Epoch 12: Val Loss 3575892.50000
Epoch 13: Val Loss 3540303.00000
Epoch 14: Val Loss 3541657.25000
Epoch 15: Val Loss 3576518.50000
Epoch 16: Val Loss 3535573.75000
Epoch 17: Val Loss 3508630.50000
Epoch 18: Val Loss 3497896.25000
Epoch 19: Val Loss 3550961.50000
Epoch 20: Val Loss 3502688.50000
Epoch 21: Val Loss 3508283.00000
Epoch 22: Val Loss 3485968.00000
Epoch 23: Val Loss 3499564.50000
Epoch 24: Val Loss 3494835.00000
Epoch 25: Val Loss 3493124.50000
Epoch 26: Val Loss 3494987.75000
Epoch 27: Val Loss 3541174.50000
Epoch 28: Val Loss 3501516.75000
Epoch 29: Val Loss 3484945.25000
Epoch 30: Val Loss 3476601.00000
Epoch 31: Val Loss 3470334.25000
Epoch 32: Val Loss 3467010.75000
Epoch 33: Val Loss 3464308.25000
Epoch 34: Val Loss 3471356.75000
Epoch 35: Val Loss 3449106.00000
Epoch 36: Val Loss 3443406.50000
Epoch 37: Val Loss 3511773.25000
Epoch 38: Val Loss 3443159.00000
Epoch 39: Val Loss 3466779.00000
Epoch 40: Val Loss 3437739.75000
Epoch 41: Val Loss 3513933.50000
Epoch 42: Val Loss 3436582.00000
Epoch 43: Val Loss 3474431.25000
Epoch 44: Val Loss 3429904.25000
Epoch 45: Val Loss 3444555.50000
Epoch 46: Val Loss 3461510.50000
Epoch 47: Val Loss 3430154.50000
Epoch 48: Val Loss 3446612.50000
Epoch 49: Val Loss 3549032.75000
Epoch 50: Val Loss 3481866.50000
Epoch 51: Val Loss 3439546.25000
Epoch 52: Val Loss 3444445.00000
Epoch 53: Val Loss 3434488.00000
Epoch 54: Val Loss 3437412.00000
Epoch 55: Val Loss 3452734.25000
Epoch 56: Val Loss 3434673.50000
Epoch 57: Val Loss 3422225.50000
Epoch 58: Val Loss 3414245.25000
Epoch 59: Val Loss 3461857.75000
Epoch 60: Val Loss 3450694.25000
Epoch 61: Val Loss 3412124.25000
Epoch 62: Val Loss 3423618.50000
Epoch 63: Val Loss 3417675.00000
Epoch 64: Val Loss 3424333.00000
Epoch 65: Val Loss 3427404.50000
Epoch 66: Val Loss 3419505.50000
Epoch 67: Val Loss 3428530.50000
Epoch 68: Val Loss 3416244.75000
Epoch 69: Val Loss 3443363.00000
Epoch 70: Val Loss 3427900.75000
Epoch 71: Val Loss 3447539.00000
Epoch 72: Val Loss 3421836.00000
Epoch 73: Val Loss 3413253.00000
Epoch 74: Val Loss 3410263.75000
Epoch 75: Val Loss 3418384.25000
Epoch 76: Val Loss 3433470.50000
Epoch 77: Val Loss 3429417.50000
Epoch 78: Val Loss 3430781.25000
Epoch 79: Val Loss 3414008.50000
Epoch 80: Val Loss 3429209.25000
Epoch 81: Val Loss 3432478.25000
Epoch 82: Val Loss 3470672.75000
Epoch 83: Val Loss 3406512.50000
Epoch 84: Val Loss 3420994.25000
Epoch 85: Val Loss 3431798.50000
Epoch 86: Val Loss 3395061.75000
Epoch 87: Val Loss 3444715.50000
Epoch 88: Val Loss 3394068.00000
Epoch 89: Val Loss 3407453.75000
Epoch 90: Val Loss 3409075.00000
Epoch 91: Val Loss 3392834.50000
Epoch 92: Val Loss 3390263.75000
Epoch 93: Val Loss 3404081.75000
Epoch 94: Val Loss 3408285.00000
Epoch 95: Val Loss 3405955.50000
Epoch 96: Val Loss 3403624.25000
Epoch 97: Val Loss 3452140.25000
Epoch 98: Val Loss 3393891.00000
Epoch 99: Val Loss 3402076.50000
Saved Losses
{'MSE - mean': 3461138.88055362, 'MSE - std': 61045.66702390695, 'R2 - mean': 0.5813645401199005, 'R2 - std': 0.005956607909026634} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 5057772.00000
Epoch 1: Val Loss 4610367.00000
Epoch 2: Val Loss 4454011.50000
Epoch 3: Val Loss 4440271.50000
Epoch 4: Val Loss 4363442.00000
Epoch 5: Val Loss 4319172.50000
Epoch 6: Val Loss 4313711.00000
Epoch 7: Val Loss 4297651.00000
Epoch 8: Val Loss 4255050.00000
Epoch 9: Val Loss 4242940.00000
Epoch 10: Val Loss 4262383.50000
Epoch 11: Val Loss 4210277.50000
Epoch 12: Val Loss 4223061.00000
Epoch 13: Val Loss 4240641.00000
Epoch 14: Val Loss 4168476.25000
Epoch 15: Val Loss 4157272.00000
Epoch 16: Val Loss 4146694.25000
Epoch 17: Val Loss 4141950.00000
Epoch 18: Val Loss 4163637.75000
Epoch 19: Val Loss 4115073.50000
Epoch 20: Val Loss 4120525.00000
Epoch 21: Val Loss 4251461.50000
Epoch 22: Val Loss 4102718.00000
Epoch 23: Val Loss 4099544.00000
Epoch 24: Val Loss 4088446.25000
Epoch 25: Val Loss 4092368.50000
Epoch 26: Val Loss 4078203.75000
Epoch 27: Val Loss 4108856.25000
Epoch 28: Val Loss 4081660.25000
Epoch 29: Val Loss 4060817.50000
Epoch 30: Val Loss 4060884.00000
Epoch 31: Val Loss 4074288.00000
Epoch 32: Val Loss 4057627.00000
Epoch 33: Val Loss 4053706.00000
Epoch 34: Val Loss 4067928.75000
Epoch 35: Val Loss 4061201.50000
Epoch 36: Val Loss 4064840.75000
Epoch 37: Val Loss 4057604.75000
Epoch 38: Val Loss 4057735.50000
Epoch 39: Val Loss 4048978.25000
Epoch 40: Val Loss 4062951.50000
Epoch 41: Val Loss 4057185.75000
Epoch 42: Val Loss 4049531.75000
Epoch 43: Val Loss 4020634.00000
Epoch 44: Val Loss 4038413.50000
Epoch 45: Val Loss 4024392.00000
Epoch 46: Val Loss 4066523.75000
Epoch 47: Val Loss 4062010.00000
Epoch 48: Val Loss 4063162.00000
Epoch 49: Val Loss 4022648.75000
Epoch 50: Val Loss 4015110.25000
Epoch 51: Val Loss 4032987.00000
Epoch 52: Val Loss 4037240.00000
Epoch 53: Val Loss 4047658.50000
Epoch 54: Val Loss 4040682.00000
Epoch 55: Val Loss 4019475.00000
Epoch 56: Val Loss 4009246.75000
Epoch 57: Val Loss 4002830.75000
Epoch 58: Val Loss 4041352.75000
Epoch 59: Val Loss 4031793.75000
Epoch 60: Val Loss 4036760.00000
Epoch 61: Val Loss 4027675.25000
Epoch 62: Val Loss 4006559.75000
Epoch 63: Val Loss 4005114.50000
Epoch 64: Val Loss 4010878.75000
Epoch 65: Val Loss 4034350.75000
Epoch 66: Val Loss 4029441.00000
Epoch 67: Val Loss 3998246.25000
Epoch 68: Val Loss 4041384.25000
Epoch 69: Val Loss 4002792.00000
Epoch 70: Val Loss 4006948.50000
Epoch 71: Val Loss 4021037.50000
Epoch 72: Val Loss 4001005.00000
Epoch 73: Val Loss 3989097.50000
Epoch 74: Val Loss 4010480.50000
Epoch 75: Val Loss 3991523.50000
Epoch 76: Val Loss 4034942.25000
Epoch 77: Val Loss 3991635.50000
Epoch 78: Val Loss 4010348.75000
Epoch 79: Val Loss 3999285.25000
Epoch 80: Val Loss 3999742.25000
Epoch 81: Val Loss 4001733.25000
Epoch 82: Val Loss 4016932.50000
Epoch 83: Val Loss 4000167.50000
Epoch 84: Val Loss 3985624.25000
Epoch 85: Val Loss 3982154.00000
Epoch 86: Val Loss 3983763.50000
Epoch 87: Val Loss 3989446.50000
Epoch 88: Val Loss 3998785.00000
Epoch 89: Val Loss 3995048.25000
Epoch 90: Val Loss 3969553.75000
Epoch 91: Val Loss 3993846.25000
Epoch 92: Val Loss 3985822.00000
Epoch 93: Val Loss 4023954.75000
Epoch 94: Val Loss 3975535.75000
Epoch 95: Val Loss 3977422.75000
Epoch 96: Val Loss 3986030.25000
Epoch 97: Val Loss 3983118.00000
Epoch 98: Val Loss 3981604.75000
Epoch 99: Val Loss 3974117.75000
Saved Losses
{'MSE - mean': 3636333.947476592, 'MSE - std': 252727.13597188497, 'R2 - mean': 0.5722474377344066, 'R2 - std': 0.013780320400353893} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4616860.00000
Epoch 1: Val Loss 4249353.00000
Epoch 2: Val Loss 4143235.50000
Epoch 3: Val Loss 4065795.25000
Epoch 4: Val Loss 4202648.00000
Epoch 5: Val Loss 3992826.50000
Epoch 6: Val Loss 3970488.75000
Epoch 7: Val Loss 3955232.50000
Epoch 8: Val Loss 3926348.25000
Epoch 9: Val Loss 3930736.50000
Epoch 10: Val Loss 3904188.25000
Epoch 11: Val Loss 3876554.50000
Epoch 12: Val Loss 3857003.75000
Epoch 13: Val Loss 3863869.50000
Epoch 14: Val Loss 3860685.00000
Epoch 15: Val Loss 3830812.25000
Epoch 16: Val Loss 3839320.00000
Epoch 17: Val Loss 3861758.00000
Epoch 18: Val Loss 3811880.75000
Epoch 19: Val Loss 3806305.75000
Epoch 20: Val Loss 3827814.50000
Epoch 21: Val Loss 3798890.00000
Epoch 22: Val Loss 3794841.50000
Epoch 23: Val Loss 3798932.00000
Epoch 24: Val Loss 3819533.50000
Epoch 25: Val Loss 3784722.75000
Epoch 26: Val Loss 3810636.25000
Epoch 27: Val Loss 3836860.25000
Epoch 28: Val Loss 3866038.25000
Epoch 29: Val Loss 3768378.00000
Epoch 30: Val Loss 3767853.50000
Epoch 31: Val Loss 3769970.25000
Epoch 32: Val Loss 3812955.00000
Epoch 33: Val Loss 3834440.75000
Epoch 34: Val Loss 3782692.00000
Epoch 35: Val Loss 3748476.25000
Epoch 36: Val Loss 3750032.00000
Epoch 37: Val Loss 3767135.25000
Epoch 38: Val Loss 3761857.00000
Epoch 39: Val Loss 3752113.75000
Epoch 40: Val Loss 3745625.50000
Epoch 41: Val Loss 3740146.75000
Epoch 42: Val Loss 3737973.25000
Epoch 43: Val Loss 3740167.50000
Epoch 44: Val Loss 3753460.50000
Epoch 45: Val Loss 3739478.50000
Epoch 46: Val Loss 3723453.00000
Epoch 47: Val Loss 3736592.50000
Epoch 48: Val Loss 3755316.00000
Epoch 49: Val Loss 3739190.25000
Epoch 50: Val Loss 3728463.25000
Epoch 51: Val Loss 3741408.00000
Epoch 52: Val Loss 3752373.25000
Epoch 53: Val Loss 3747575.00000
Epoch 54: Val Loss 3721259.25000
Epoch 55: Val Loss 3729393.00000
Epoch 56: Val Loss 3718888.25000
Epoch 57: Val Loss 3747010.75000
Epoch 58: Val Loss 3725569.00000
Epoch 59: Val Loss 3731563.00000
Epoch 60: Val Loss 3748318.75000
Epoch 61: Val Loss 3711901.50000
Epoch 62: Val Loss 3762493.00000
Epoch 63: Val Loss 3714479.75000
Epoch 64: Val Loss 3707331.50000
Epoch 65: Val Loss 3742397.00000
Epoch 66: Val Loss 3731858.25000
Epoch 67: Val Loss 3716403.00000
Epoch 68: Val Loss 3751593.50000
Epoch 69: Val Loss 3730990.75000
Epoch 70: Val Loss 3743963.25000
Epoch 71: Val Loss 3735857.00000
Epoch 72: Val Loss 3720321.00000
Epoch 73: Val Loss 3717027.50000
Epoch 74: Val Loss 3711237.25000
Epoch 75: Val Loss 3741429.75000
Epoch 76: Val Loss 3710694.50000
Epoch 77: Val Loss 3717171.50000
Epoch 78: Val Loss 3734048.50000
Epoch 79: Val Loss 3730464.50000
Epoch 80: Val Loss 3724162.75000
Epoch 81: Val Loss 3767075.50000
Epoch 82: Val Loss 3694508.75000
Epoch 83: Val Loss 3696270.00000
Epoch 84: Val Loss 3694366.25000
Epoch 85: Val Loss 3713183.25000
Epoch 86: Val Loss 3737865.50000
Epoch 87: Val Loss 3713643.00000
Epoch 88: Val Loss 3697124.50000
Epoch 89: Val Loss 3697942.50000
Epoch 90: Val Loss 3695138.25000
Epoch 91: Val Loss 3711777.75000
Epoch 92: Val Loss 3707949.00000
Epoch 93: Val Loss 3716578.75000
Epoch 94: Val Loss 3709221.25000
Epoch 95: Val Loss 3730145.75000
Epoch 96: Val Loss 3688010.50000
Epoch 97: Val Loss 3686234.50000
Epoch 98: Val Loss 3712932.50000
Epoch 99: Val Loss 3728929.75000
Saved Losses
{'MSE - mean': 3652210.852785231, 'MSE - std': 220588.944212878, 'R2 - mean': 0.5714625011965804, 'R2 - std': 0.01201129879977812} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4110122.50000
Epoch 1: Val Loss 3710596.00000
Epoch 2: Val Loss 3654708.75000
Epoch 3: Val Loss 3610823.25000
Epoch 4: Val Loss 3547302.25000
Epoch 5: Val Loss 3537644.75000
Epoch 6: Val Loss 3509800.50000
Epoch 7: Val Loss 3491572.25000
Epoch 8: Val Loss 3498383.00000
Epoch 9: Val Loss 3490095.75000
Epoch 10: Val Loss 3463723.25000
Epoch 11: Val Loss 3456871.75000
Epoch 12: Val Loss 3447887.25000
Epoch 13: Val Loss 3441007.75000
Epoch 14: Val Loss 3422746.50000
Epoch 15: Val Loss 3475578.25000
Epoch 16: Val Loss 3432123.75000
Epoch 17: Val Loss 3425265.50000
Epoch 18: Val Loss 3426180.75000
Epoch 19: Val Loss 3461710.50000
Epoch 20: Val Loss 3407902.00000
Epoch 21: Val Loss 3417599.50000
Epoch 22: Val Loss 3404419.00000
Epoch 23: Val Loss 3404882.75000
Epoch 24: Val Loss 3410267.25000
Epoch 25: Val Loss 3390462.50000
Epoch 26: Val Loss 3411684.75000
Epoch 27: Val Loss 3477362.25000
Epoch 28: Val Loss 3420625.50000
Epoch 29: Val Loss 3406702.50000
Epoch 30: Val Loss 3399502.75000
Epoch 31: Val Loss 3407911.25000
Epoch 32: Val Loss 3390382.75000
Epoch 33: Val Loss 3405337.75000
Epoch 34: Val Loss 3391636.50000
Epoch 35: Val Loss 3375014.75000
Epoch 36: Val Loss 3387191.50000
Epoch 37: Val Loss 3391720.25000
Epoch 38: Val Loss 3378251.75000
Epoch 39: Val Loss 3381118.25000
Epoch 40: Val Loss 3420638.25000
Epoch 41: Val Loss 3412943.75000
Epoch 42: Val Loss 3389017.50000
Epoch 43: Val Loss 3379291.00000
Epoch 44: Val Loss 3382873.00000
Epoch 45: Val Loss 3403563.25000
Epoch 46: Val Loss 3383571.00000
Epoch 47: Val Loss 3367997.25000
Epoch 48: Val Loss 3406912.00000
Epoch 49: Val Loss 3393895.75000
Epoch 50: Val Loss 3380355.25000
Epoch 51: Val Loss 3366684.25000
Epoch 52: Val Loss 3366956.00000
Epoch 53: Val Loss 3423140.50000
Epoch 54: Val Loss 3376773.50000
Epoch 55: Val Loss 3376780.00000
Epoch 56: Val Loss 3354731.75000
Epoch 57: Val Loss 3371838.25000
Epoch 58: Val Loss 3364926.75000
Epoch 59: Val Loss 3364755.25000
Epoch 60: Val Loss 3372984.25000
Epoch 61: Val Loss 3363748.50000
Epoch 62: Val Loss 3366043.25000
Epoch 63: Val Loss 3357974.25000
Epoch 64: Val Loss 3348284.00000
Epoch 65: Val Loss 3362599.50000
Epoch 66: Val Loss 3363310.25000
Epoch 67: Val Loss 3346104.25000
Epoch 68: Val Loss 3370465.75000
Epoch 69: Val Loss 3467172.50000
Epoch 70: Val Loss 3370842.25000
Epoch 71: Val Loss 3346415.25000
Epoch 72: Val Loss 3343841.50000
Epoch 73: Val Loss 3386467.50000
Epoch 74: Val Loss 3354579.00000
Epoch 75: Val Loss 3364203.25000
Epoch 76: Val Loss 3344732.50000
Epoch 77: Val Loss 3336519.00000
Epoch 78: Val Loss 3371159.50000
Epoch 79: Val Loss 3351174.25000
Epoch 80: Val Loss 3366190.25000
Epoch 81: Val Loss 3349616.25000
Epoch 82: Val Loss 3336071.25000
Epoch 83: Val Loss 3346398.25000
Epoch 84: Val Loss 3351759.25000
Epoch 85: Val Loss 3335531.75000
Epoch 86: Val Loss 3362207.75000
Epoch 87: Val Loss 3341156.50000
Epoch 88: Val Loss 3361328.25000
Epoch 89: Val Loss 3363695.25000
Epoch 90: Val Loss 3350415.50000
Epoch 91: Val Loss 3353955.75000
Epoch 92: Val Loss 3344338.00000
Epoch 93: Val Loss 3348167.00000
Epoch 94: Val Loss 3333714.50000
Epoch 95: Val Loss 3353931.00000
Epoch 96: Val Loss 3358664.50000
Epoch 97: Val Loss 3344452.25000
Epoch 98: Val Loss 3362104.25000
Epoch 99: Val Loss 3331870.25000
Saved Losses
{'MSE - mean': 3589690.9289171756, 'MSE - std': 233586.2782122092, 'R2 - mean': 0.5746960235893372, 'R2 - std': 0.012539525802193762} 
 

Saving model.....
Results After CV: {'MSE - mean': 3589690.9289171756, 'MSE - std': 233586.2782122092, 'R2 - mean': 0.5746960235893372, 'R2 - std': 0.012539525802193762}
Train time: 7308.3253078381995
Inference time: 6.608482627989725
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 47 finished with value: 3589690.9289171756 and parameters: {'dim': 32, 'depth': 2, 'heads': 4, 'weight_decay': -1, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 43 with value: 3546744.9497103365.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4471096.00000
Epoch 1: Val Loss 4067650.25000
Epoch 2: Val Loss 3955363.50000
Epoch 3: Val Loss 3917075.00000
Epoch 4: Val Loss 3837304.75000
Epoch 5: Val Loss 3813445.25000
Epoch 6: Val Loss 3768268.75000
Epoch 7: Val Loss 3737255.75000
Epoch 8: Val Loss 3721651.50000
Epoch 9: Val Loss 3716640.00000
Epoch 10: Val Loss 3686278.50000
Epoch 11: Val Loss 3702517.25000
Epoch 12: Val Loss 3655077.25000
Epoch 13: Val Loss 3636069.25000
Epoch 14: Val Loss 3605481.50000
Epoch 15: Val Loss 3599665.50000
Epoch 16: Val Loss 3611122.50000
Epoch 17: Val Loss 3570129.50000
Epoch 18: Val Loss 3573259.75000
Epoch 19: Val Loss 3559446.00000
Epoch 20: Val Loss 3592450.75000
Epoch 21: Val Loss 3537677.50000
Epoch 22: Val Loss 3538764.75000
Epoch 23: Val Loss 3557623.50000
Epoch 24: Val Loss 3529903.25000
Epoch 25: Val Loss 3517593.25000
Epoch 26: Val Loss 3514655.00000
Epoch 27: Val Loss 3497917.00000
Epoch 28: Val Loss 3493514.75000
Epoch 29: Val Loss 3483132.50000
Epoch 30: Val Loss 3485455.00000
Epoch 31: Val Loss 3486026.25000
Epoch 32: Val Loss 3510320.75000
Epoch 33: Val Loss 3467137.00000
Epoch 34: Val Loss 3512517.25000
Epoch 35: Val Loss 3484446.50000
Epoch 36: Val Loss 3463749.50000
Epoch 37: Val Loss 3486974.25000
Epoch 38: Val Loss 3478796.75000
Epoch 39: Val Loss 3450633.50000
Epoch 40: Val Loss 3462770.75000
Epoch 41: Val Loss 3443549.75000
Epoch 42: Val Loss 3454380.00000
Epoch 43: Val Loss 3433342.00000
Epoch 44: Val Loss 3457758.75000
Epoch 45: Val Loss 3436779.00000
Epoch 46: Val Loss 3438317.00000
Epoch 47: Val Loss 3473459.75000
Epoch 48: Val Loss 3466847.75000
Epoch 49: Val Loss 3423676.00000
Epoch 50: Val Loss 3432200.25000
Epoch 51: Val Loss 3430871.00000
Epoch 52: Val Loss 3467471.75000
Epoch 53: Val Loss 3426082.50000
Epoch 54: Val Loss 3452395.00000
Epoch 55: Val Loss 3530606.25000
Epoch 56: Val Loss 3434991.75000
Epoch 57: Val Loss 3434591.75000
Epoch 58: Val Loss 3442629.00000
Epoch 59: Val Loss 3431691.25000
Epoch 60: Val Loss 3434647.50000
Epoch 61: Val Loss 3439627.75000
Epoch 62: Val Loss 3432745.00000
Epoch 63: Val Loss 3409001.25000
Epoch 64: Val Loss 3583727.75000
Epoch 65: Val Loss 3469205.50000
Epoch 66: Val Loss 3431495.25000
Epoch 67: Val Loss 3419683.75000
Epoch 68: Val Loss 3442294.25000
Epoch 69: Val Loss 3450388.25000
Epoch 70: Val Loss 3486959.75000
Epoch 71: Val Loss 3515843.25000
Epoch 72: Val Loss 3450296.75000
Epoch 73: Val Loss 3452378.00000
Epoch 74: Val Loss 3440447.25000
Epoch 75: Val Loss 3446433.00000
Epoch 76: Val Loss 3476657.50000
Epoch 77: Val Loss 3469102.25000
Epoch 78: Val Loss 3452542.25000
Epoch 79: Val Loss 3478078.50000
Epoch 80: Val Loss 3463059.50000
Epoch 81: Val Loss 3453091.00000
Epoch 82: Val Loss 3453760.75000
Epoch 83: Val Loss 3501347.50000
Epoch 84: Val Loss 3464709.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3414858.454282134, 'MSE - std': 0.0, 'R2 - mean': 0.5998960737233077, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4314097.00000
Epoch 1: Val Loss 3879386.50000
Epoch 2: Val Loss 3770502.25000
Epoch 3: Val Loss 3759868.25000
Epoch 4: Val Loss 3722411.75000
Epoch 5: Val Loss 3690061.00000
Epoch 6: Val Loss 3642975.25000
Epoch 7: Val Loss 3679559.00000
Epoch 8: Val Loss 3610085.50000
Epoch 9: Val Loss 3600023.75000
Epoch 10: Val Loss 3581193.75000
Epoch 11: Val Loss 3583382.50000
Epoch 12: Val Loss 3553374.75000
Epoch 13: Val Loss 3556737.50000
Epoch 14: Val Loss 3533972.50000
Epoch 15: Val Loss 3542678.00000
Epoch 16: Val Loss 3516726.75000
Epoch 17: Val Loss 3524123.50000
Epoch 18: Val Loss 3519292.50000
Epoch 19: Val Loss 3495301.50000
Epoch 20: Val Loss 3524218.25000
Epoch 21: Val Loss 3524888.50000
Epoch 22: Val Loss 3507610.25000
Epoch 23: Val Loss 3484148.75000
Epoch 24: Val Loss 3469844.50000
Epoch 25: Val Loss 3471783.75000
Epoch 26: Val Loss 3450701.00000
Epoch 27: Val Loss 3467309.00000
Epoch 28: Val Loss 3546589.75000
Epoch 29: Val Loss 3450366.50000
Epoch 30: Val Loss 3470821.00000
Epoch 31: Val Loss 3463029.00000
Epoch 32: Val Loss 3476092.50000
Epoch 33: Val Loss 3428952.25000
Epoch 34: Val Loss 3433096.00000
Epoch 35: Val Loss 3425968.75000
Epoch 36: Val Loss 3458921.25000
Epoch 37: Val Loss 3421216.00000
Epoch 38: Val Loss 3412770.00000
Epoch 39: Val Loss 3436725.25000
Epoch 40: Val Loss 3408820.00000
Epoch 41: Val Loss 3399681.50000
Epoch 42: Val Loss 3419095.25000
Epoch 43: Val Loss 3416020.25000
Epoch 44: Val Loss 3452763.00000
Epoch 45: Val Loss 3406336.25000
Epoch 46: Val Loss 3401681.50000
Epoch 47: Val Loss 3466419.00000
Epoch 48: Val Loss 3442825.00000
Epoch 49: Val Loss 3388085.25000
Epoch 50: Val Loss 3400036.25000
Epoch 51: Val Loss 3400910.75000
Epoch 52: Val Loss 3393508.25000
Epoch 53: Val Loss 3404815.50000
Epoch 54: Val Loss 3391154.50000
Epoch 55: Val Loss 3458192.25000
Epoch 56: Val Loss 3437449.50000
Epoch 57: Val Loss 3419919.25000
Epoch 58: Val Loss 3397580.25000
Epoch 59: Val Loss 3391172.50000
Epoch 60: Val Loss 3396372.50000
Epoch 61: Val Loss 3431198.00000
Epoch 62: Val Loss 3390836.50000
Epoch 63: Val Loss 3417697.50000
Epoch 64: Val Loss 3402329.50000
Epoch 65: Val Loss 3395334.25000
Epoch 66: Val Loss 3428185.50000
Epoch 67: Val Loss 3391917.50000
Epoch 68: Val Loss 3389967.00000
Epoch 69: Val Loss 3409375.75000
Epoch 70: Val Loss 3436508.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3401309.2354529295, 'MSE - std': 13549.218829204328, 'R2 - mean': 0.5884220667929774, 'R2 - std': 0.011474006930330294} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4937592.50000
Epoch 1: Val Loss 4565717.50000
Epoch 2: Val Loss 4418157.50000
Epoch 3: Val Loss 4362431.00000
Epoch 4: Val Loss 4387475.50000
Epoch 5: Val Loss 4312826.50000
Epoch 6: Val Loss 4232279.00000
Epoch 7: Val Loss 4232348.00000
Epoch 8: Val Loss 4181548.25000
Epoch 9: Val Loss 4216777.50000
Epoch 10: Val Loss 4145234.25000
Epoch 11: Val Loss 4142257.00000
Epoch 12: Val Loss 4104285.00000
Epoch 13: Val Loss 4126798.00000
Epoch 14: Val Loss 4074655.25000
Epoch 15: Val Loss 4079409.00000
Epoch 16: Val Loss 4082063.25000
Epoch 17: Val Loss 4069786.50000
Epoch 18: Val Loss 4043784.25000
Epoch 19: Val Loss 4055934.25000
Epoch 20: Val Loss 4040469.75000
Epoch 21: Val Loss 4023622.50000
Epoch 22: Val Loss 4010649.25000
Epoch 23: Val Loss 4006045.50000
Epoch 24: Val Loss 4006428.25000
Epoch 25: Val Loss 3990680.00000
Epoch 26: Val Loss 3988526.75000
Epoch 27: Val Loss 3981972.50000
Epoch 28: Val Loss 3986224.50000
Epoch 29: Val Loss 3981037.00000
Epoch 30: Val Loss 3953488.50000
Epoch 31: Val Loss 3998806.25000
Epoch 32: Val Loss 3976131.50000
Epoch 33: Val Loss 3940456.75000
Epoch 34: Val Loss 3964385.75000
Epoch 35: Val Loss 3951824.50000
Epoch 36: Val Loss 3948445.00000
Epoch 37: Val Loss 3920486.25000
Epoch 38: Val Loss 3945997.50000
Epoch 39: Val Loss 3930898.25000
Epoch 40: Val Loss 3910360.25000
Epoch 41: Val Loss 3894296.00000
Epoch 42: Val Loss 3898736.00000
Epoch 43: Val Loss 3914660.00000
Epoch 44: Val Loss 3887248.00000
Epoch 45: Val Loss 3912275.50000
Epoch 46: Val Loss 3882836.50000
Epoch 47: Val Loss 3913630.25000
Epoch 48: Val Loss 3888985.50000
Epoch 49: Val Loss 3900047.75000
Epoch 50: Val Loss 3870046.25000
Epoch 51: Val Loss 3917164.25000
Epoch 52: Val Loss 3867737.50000
Epoch 53: Val Loss 3867697.50000
Epoch 54: Val Loss 3859350.25000
Epoch 55: Val Loss 3856961.75000
Epoch 56: Val Loss 3873071.25000
Epoch 57: Val Loss 3884212.75000
Epoch 58: Val Loss 3867417.50000
Epoch 59: Val Loss 3851390.25000
Epoch 60: Val Loss 3853011.00000
Epoch 61: Val Loss 3856090.50000
Epoch 62: Val Loss 3907302.50000
Epoch 63: Val Loss 3865869.50000
Epoch 64: Val Loss 3856618.50000
Epoch 65: Val Loss 3848775.00000
Epoch 66: Val Loss 3846721.75000
Epoch 67: Val Loss 3840848.50000
Epoch 68: Val Loss 3842204.75000
Epoch 69: Val Loss 3865293.50000
Epoch 70: Val Loss 3852290.25000
Epoch 71: Val Loss 3876113.75000
Epoch 72: Val Loss 3852049.00000
Epoch 73: Val Loss 3891875.00000
Epoch 74: Val Loss 3841575.50000
Epoch 75: Val Loss 3860678.50000
Epoch 76: Val Loss 3856508.75000
Epoch 77: Val Loss 3857216.50000
Epoch 78: Val Loss 3852362.50000
Epoch 79: Val Loss 3862196.75000
Epoch 80: Val Loss 3848660.75000
Epoch 81: Val Loss 3847573.75000
Epoch 82: Val Loss 3847252.75000
Epoch 83: Val Loss 3908110.75000
Epoch 84: Val Loss 3897511.00000
Epoch 85: Val Loss 3904482.25000
Epoch 86: Val Loss 3872741.75000
Epoch 87: Val Loss 3924354.25000
Epoch 88: Val Loss 3871740.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3552617.033472188, 'MSE - std': 214267.32610641886, 'R2 - mean': 0.5818556831866181, 'R2 - std': 0.013191032712537682} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4541351.00000
Epoch 1: Val Loss 4187926.25000
Epoch 2: Val Loss 4087692.75000
Epoch 3: Val Loss 4043611.00000
Epoch 4: Val Loss 3996979.00000
Epoch 5: Val Loss 4022849.00000
Epoch 6: Val Loss 3959490.75000
Epoch 7: Val Loss 3930984.00000
Epoch 8: Val Loss 3906582.50000
Epoch 9: Val Loss 3905396.00000
Epoch 10: Val Loss 3877457.75000
Epoch 11: Val Loss 3854500.75000
Epoch 12: Val Loss 3830156.25000
Epoch 13: Val Loss 3819682.25000
Epoch 14: Val Loss 3870552.00000
Epoch 15: Val Loss 3826534.50000
Epoch 16: Val Loss 3798616.75000
Epoch 17: Val Loss 3783208.75000
Epoch 18: Val Loss 3820229.75000
Epoch 19: Val Loss 3759468.75000
Epoch 20: Val Loss 3768205.00000
Epoch 21: Val Loss 3854117.75000
Epoch 22: Val Loss 3775531.00000
Epoch 23: Val Loss 3805533.50000
Epoch 24: Val Loss 3770733.50000
Epoch 25: Val Loss 3743574.50000
Epoch 26: Val Loss 3728500.00000
Epoch 27: Val Loss 3723924.75000
Epoch 28: Val Loss 3723669.75000
Epoch 29: Val Loss 3718311.75000
Epoch 30: Val Loss 3730062.25000
Epoch 31: Val Loss 3718311.75000
Epoch 32: Val Loss 3704004.75000
Epoch 33: Val Loss 3701621.75000
Epoch 34: Val Loss 3695673.50000
Epoch 35: Val Loss 3731572.00000
Epoch 36: Val Loss 3730855.50000
Epoch 37: Val Loss 3706144.00000
Epoch 38: Val Loss 3697406.00000
Epoch 39: Val Loss 3703361.00000
Epoch 40: Val Loss 3687668.00000
Epoch 41: Val Loss 3697390.25000
Epoch 42: Val Loss 3707362.75000
Epoch 43: Val Loss 3721198.25000
Epoch 44: Val Loss 3763184.00000
Epoch 45: Val Loss 3690527.75000
Epoch 46: Val Loss 3707357.00000
Epoch 47: Val Loss 3756196.50000
Epoch 48: Val Loss 3776949.75000
Epoch 49: Val Loss 3741571.00000
Epoch 50: Val Loss 3691024.50000
Epoch 51: Val Loss 3716662.50000
Epoch 52: Val Loss 3690571.75000
Epoch 53: Val Loss 3724395.75000
Epoch 54: Val Loss 3726555.75000
Epoch 55: Val Loss 3757461.75000
Epoch 56: Val Loss 3773821.00000
Epoch 57: Val Loss 3701334.25000
Epoch 58: Val Loss 3692090.00000
Epoch 59: Val Loss 3807241.25000
Epoch 60: Val Loss 3711339.00000
Epoch 61: Val Loss 3727906.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3588630.242068488, 'MSE - std': 195764.4473794918, 'R2 - mean': 0.5787610312333358, 'R2 - std': 0.01261876064252315} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4090155.25000
Epoch 1: Val Loss 3720020.50000
Epoch 2: Val Loss 3606931.75000
Epoch 3: Val Loss 3664913.00000
Epoch 4: Val Loss 3546480.75000
Epoch 5: Val Loss 3527811.50000
Epoch 6: Val Loss 3520151.75000
Epoch 7: Val Loss 3505375.00000
Epoch 8: Val Loss 3519075.75000
Epoch 9: Val Loss 3474287.75000
Epoch 10: Val Loss 3520583.75000
Epoch 11: Val Loss 3448457.25000
Epoch 12: Val Loss 3460069.50000
Epoch 13: Val Loss 3469890.00000
Epoch 14: Val Loss 3429142.00000
Epoch 15: Val Loss 3517463.50000
Epoch 16: Val Loss 3435319.50000
Epoch 17: Val Loss 3452550.75000
Epoch 18: Val Loss 3494815.00000
Epoch 19: Val Loss 3416672.75000
Epoch 20: Val Loss 3393256.50000
Epoch 21: Val Loss 3421830.50000
Epoch 22: Val Loss 3407104.25000
Epoch 23: Val Loss 3396892.50000
Epoch 24: Val Loss 3399431.50000
Epoch 25: Val Loss 3402099.50000
Epoch 26: Val Loss 3409766.75000
Epoch 27: Val Loss 3420677.75000
Epoch 28: Val Loss 3398019.75000
Epoch 29: Val Loss 3405709.00000
Epoch 30: Val Loss 3431810.50000
Epoch 31: Val Loss 3412538.75000
Epoch 32: Val Loss 3387138.00000
Epoch 33: Val Loss 3438699.00000
Epoch 34: Val Loss 3456141.50000
Epoch 35: Val Loss 3408254.25000
Epoch 36: Val Loss 3372220.75000
Epoch 37: Val Loss 3425789.50000
Epoch 38: Val Loss 3398809.50000
Epoch 39: Val Loss 3386723.50000
Epoch 40: Val Loss 3393060.25000
Epoch 41: Val Loss 3385764.00000
Epoch 42: Val Loss 3411948.00000
Epoch 43: Val Loss 3449343.75000
Epoch 44: Val Loss 3375769.50000
Epoch 45: Val Loss 3400669.50000
Epoch 46: Val Loss 3389911.75000
Epoch 47: Val Loss 3405825.50000
Epoch 48: Val Loss 3564958.75000
Epoch 49: Val Loss 3426187.25000
Epoch 50: Val Loss 3407831.75000
Epoch 51: Val Loss 3388704.00000
Epoch 52: Val Loss 3417010.50000
Epoch 53: Val Loss 3468044.25000
Epoch 54: Val Loss 3395586.75000
Epoch 55: Val Loss 3400207.75000
Epoch 56: Val Loss 3384858.75000
Epoch 57: Val Loss 3386864.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3546437.0810431303, 'MSE - std': 194370.84769966255, 'R2 - mean': 0.5795950978021948, 'R2 - std': 0.011409170184013643} 
 

Saving model.....
Results After CV: {'MSE - mean': 3546437.0810431303, 'MSE - std': 194370.84769966255, 'R2 - mean': 0.5795950978021948, 'R2 - std': 0.011409170184013643}
Train time: 5140.780183754209
Inference time: 6.275296979723498
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 48 finished with value: 3546437.0810431303 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.1}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3839670.50000
Epoch 1: Val Loss 3871872.00000
Epoch 2: Val Loss 3747802.00000
Epoch 3: Val Loss 3753507.00000
Epoch 4: Val Loss 3577787.50000
Epoch 5: Val Loss 3556626.50000
Epoch 6: Val Loss 3540977.25000
Epoch 7: Val Loss 3528416.25000
Epoch 8: Val Loss 3484937.50000
Epoch 9: Val Loss 3500444.75000
Epoch 10: Val Loss 3496672.00000
Epoch 11: Val Loss 3588357.25000
Epoch 12: Val Loss 3459591.25000
Epoch 13: Val Loss 3573032.75000
Epoch 14: Val Loss 3516974.25000
Epoch 15: Val Loss 3570377.50000
Epoch 16: Val Loss 3608388.50000
Epoch 17: Val Loss 3649301.25000
Epoch 18: Val Loss 3731189.75000
Epoch 19: Val Loss 3717415.75000
Epoch 20: Val Loss 3939407.75000
Epoch 21: Val Loss 3821409.50000
Epoch 22: Val Loss 3962362.50000
Epoch 23: Val Loss 3962690.75000
Epoch 24: Val Loss 4127542.25000
Epoch 25: Val Loss 4093873.00000
Epoch 26: Val Loss 4190241.75000
Epoch 27: Val Loss 4108378.50000
Epoch 28: Val Loss 4211847.50000
Epoch 29: Val Loss 4378098.00000
Epoch 30: Val Loss 4403189.00000
Epoch 31: Val Loss 4282420.00000
Epoch 32: Val Loss 4406159.00000
Epoch 33: Val Loss 4527000.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3468475.7366886972, 'MSE - std': 0.0, 'R2 - mean': 0.5936139728707083, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3684992.00000
Epoch 1: Val Loss 3657368.75000
Epoch 2: Val Loss 3635271.50000
Epoch 3: Val Loss 3582110.00000
Epoch 4: Val Loss 3542523.00000
Epoch 5: Val Loss 3468364.75000
Epoch 6: Val Loss 3495715.25000
Epoch 7: Val Loss 3566284.25000
Epoch 8: Val Loss 3501637.25000
Epoch 9: Val Loss 3465552.50000
Epoch 10: Val Loss 3536492.75000
Epoch 11: Val Loss 3437593.25000
Epoch 12: Val Loss 3451208.50000
Epoch 13: Val Loss 3419672.75000
Epoch 14: Val Loss 3502843.50000
Epoch 15: Val Loss 3499422.25000
Epoch 16: Val Loss 3586910.25000
Epoch 17: Val Loss 3591655.25000
Epoch 18: Val Loss 3755192.75000
Epoch 19: Val Loss 3660403.50000
Epoch 20: Val Loss 3788177.75000
Epoch 21: Val Loss 3837794.25000
Epoch 22: Val Loss 3821499.00000
Epoch 23: Val Loss 3868393.25000
Epoch 24: Val Loss 3944614.50000
Epoch 25: Val Loss 3980043.75000
Epoch 26: Val Loss 3999456.50000
Epoch 27: Val Loss 4050242.75000
Epoch 28: Val Loss 4101291.25000
Epoch 29: Val Loss 4154183.00000
Epoch 30: Val Loss 4164764.75000
Epoch 31: Val Loss 4246414.00000
Epoch 32: Val Loss 4297944.50000
Epoch 33: Val Loss 4286388.50000
Epoch 34: Val Loss 4381493.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3450944.896880079, 'MSE - std': 17530.83980861795, 'R2 - mean': 0.5824304557762359, 'R2 - std': 0.01118351709447235} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4329574.50000
Epoch 1: Val Loss 4217852.50000
Epoch 2: Val Loss 4168832.00000
Epoch 3: Val Loss 4107759.75000
Epoch 4: Val Loss 4043513.25000
Epoch 5: Val Loss 4017272.00000
Epoch 6: Val Loss 3980865.75000
Epoch 7: Val Loss 4003515.75000
Epoch 8: Val Loss 3887678.00000
Epoch 9: Val Loss 3969536.00000
Epoch 10: Val Loss 3883652.75000
Epoch 11: Val Loss 3891775.75000
Epoch 12: Val Loss 3863598.75000
Epoch 13: Val Loss 3907663.25000
Epoch 14: Val Loss 3930670.00000
Epoch 15: Val Loss 3923553.50000
Epoch 16: Val Loss 3939585.50000
Epoch 17: Val Loss 4053158.25000
Epoch 18: Val Loss 4093573.75000
Epoch 19: Val Loss 4142699.00000
Epoch 20: Val Loss 4283709.00000
Epoch 21: Val Loss 4280836.00000
Epoch 22: Val Loss 4364439.50000
Epoch 23: Val Loss 4364556.00000
Epoch 24: Val Loss 4478879.00000
Epoch 25: Val Loss 4450494.00000
Epoch 26: Val Loss 4539897.00000
Epoch 27: Val Loss 4591971.50000
Epoch 28: Val Loss 4641740.00000
Epoch 29: Val Loss 4741728.00000
Epoch 30: Val Loss 4717925.50000
Epoch 31: Val Loss 4715055.00000
Epoch 32: Val Loss 4863557.50000
Epoch 33: Val Loss 4772427.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3593557.9458962716, 'MSE - std': 202192.60717358903, 'R2 - mean': 0.5769830594618623, 'R2 - std': 0.011946922460614637} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4017694.25000
Epoch 1: Val Loss 3993041.00000
Epoch 2: Val Loss 3872560.00000
Epoch 3: Val Loss 3934555.75000
Epoch 4: Val Loss 3793170.25000
Epoch 5: Val Loss 3809090.75000
Epoch 6: Val Loss 3787419.25000
Epoch 7: Val Loss 3801424.50000
Epoch 8: Val Loss 3745123.00000
Epoch 9: Val Loss 3884174.25000
Epoch 10: Val Loss 3761871.25000
Epoch 11: Val Loss 3881733.25000
Epoch 12: Val Loss 3821164.25000
Epoch 13: Val Loss 3984967.50000
Epoch 14: Val Loss 3876208.00000
Epoch 15: Val Loss 3925900.75000
Epoch 16: Val Loss 4004866.25000
Epoch 17: Val Loss 4118803.25000
Epoch 18: Val Loss 4212378.00000
Epoch 19: Val Loss 4128261.75000
Epoch 20: Val Loss 4215147.50000
Epoch 21: Val Loss 4385835.50000
Epoch 22: Val Loss 4349682.50000
Epoch 23: Val Loss 4428721.50000
Epoch 24: Val Loss 4409132.00000
Epoch 25: Val Loss 4510985.00000
Epoch 26: Val Loss 4570767.00000
Epoch 27: Val Loss 4585420.50000
Epoch 28: Val Loss 4504672.50000
Epoch 29: Val Loss 4565804.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3634022.16309053, 'MSE - std': 188609.24265839235, 'R2 - mean': 0.5733961695437572, 'R2 - std': 0.012068307879059423} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 3624136.50000
Epoch 1: Val Loss 3619608.00000
Epoch 2: Val Loss 3548867.50000
Epoch 3: Val Loss 3488039.75000
Epoch 4: Val Loss 3438263.75000
Epoch 5: Val Loss 3444222.25000
Epoch 6: Val Loss 3456024.75000
Epoch 7: Val Loss 3445830.25000
Epoch 8: Val Loss 3420828.00000
Epoch 9: Val Loss 3425990.50000
Epoch 10: Val Loss 3517469.00000
Epoch 11: Val Loss 3443239.50000
Epoch 12: Val Loss 3435157.75000
Epoch 13: Val Loss 3479740.25000
Epoch 14: Val Loss 3522080.25000
Epoch 15: Val Loss 3492888.00000
Epoch 16: Val Loss 3575621.50000
Epoch 17: Val Loss 3602885.25000
Epoch 18: Val Loss 3655516.25000
Epoch 19: Val Loss 3617600.00000
Epoch 20: Val Loss 3749888.50000
Epoch 21: Val Loss 3772748.25000
Epoch 22: Val Loss 3793536.00000
Epoch 23: Val Loss 3861254.25000
Epoch 24: Val Loss 3900745.50000
Epoch 25: Val Loss 3930922.50000
Epoch 26: Val Loss 3896945.50000
Epoch 27: Val Loss 3981997.00000
Epoch 28: Val Loss 4064266.00000
Epoch 29: Val Loss 4214243.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591248.374878779, 'MSE - std': 189148.47333476602, 'R2 - mean': 0.5742539189210152, 'R2 - std': 0.010929692586150853} 
 

Saving model.....
Results After CV: {'MSE - mean': 3591248.374878779, 'MSE - std': 189148.47333476602, 'R2 - mean': 0.5742539189210152, 'R2 - std': 0.010929692586150853}
Train time: 2275.1736069751905
Inference time: 6.183769116783514
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 49 finished with value: 3591248.374878779 and parameters: {'dim': 32, 'depth': 2, 'heads': 2, 'weight_decay': -2, 'learning_rate': -3, 'dropout': 0.1}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8908664.00000
Epoch 1: Val Loss 8415516.00000
Epoch 2: Val Loss 7891444.00000
Epoch 3: Val Loss 7459991.50000
Epoch 4: Val Loss 6774728.00000
Epoch 5: Val Loss 6081866.00000
Epoch 6: Val Loss 5472416.00000
Epoch 7: Val Loss 5074603.50000
Epoch 8: Val Loss 4850708.00000
Epoch 9: Val Loss 4679824.50000
Epoch 10: Val Loss 4562171.00000
Epoch 11: Val Loss 4469076.00000
Epoch 12: Val Loss 4393894.50000
Epoch 13: Val Loss 4336255.00000
Epoch 14: Val Loss 4293692.00000
Epoch 15: Val Loss 4246688.00000
Epoch 16: Val Loss 4208224.50000
Epoch 17: Val Loss 4192350.25000
Epoch 18: Val Loss 4169219.50000
Epoch 19: Val Loss 4135890.25000
Epoch 20: Val Loss 4125077.25000
Epoch 21: Val Loss 4096833.75000
Epoch 22: Val Loss 4091332.50000
Epoch 23: Val Loss 4069270.50000
Epoch 24: Val Loss 4082337.00000
Epoch 25: Val Loss 4050270.25000
Epoch 26: Val Loss 4022461.50000
Epoch 27: Val Loss 4031431.00000
Epoch 28: Val Loss 4023952.00000
Epoch 29: Val Loss 4021255.50000
Epoch 30: Val Loss 3989518.75000
Epoch 31: Val Loss 4021932.25000
Epoch 32: Val Loss 4012380.25000
Epoch 33: Val Loss 3964784.50000
Epoch 34: Val Loss 4015568.00000
Epoch 35: Val Loss 3955236.00000
Epoch 36: Val Loss 3944318.00000
Epoch 37: Val Loss 3942336.00000
Epoch 38: Val Loss 3939639.00000
Epoch 39: Val Loss 3926200.75000
Epoch 40: Val Loss 3917140.00000
Epoch 41: Val Loss 3938388.50000
Epoch 42: Val Loss 3908161.50000
Epoch 43: Val Loss 3901014.50000
Epoch 44: Val Loss 3897684.00000
Epoch 45: Val Loss 3898156.75000
Epoch 46: Val Loss 3992053.25000
Epoch 47: Val Loss 3879428.00000
Epoch 48: Val Loss 3871611.00000
Epoch 49: Val Loss 3878367.75000
Epoch 50: Val Loss 3867071.75000
Epoch 51: Val Loss 3862657.00000
Epoch 52: Val Loss 3855169.75000
Epoch 53: Val Loss 3849663.75000
Epoch 54: Val Loss 3850030.75000
Epoch 55: Val Loss 3843066.00000
Epoch 56: Val Loss 3836710.25000
Epoch 57: Val Loss 3851615.75000
Epoch 58: Val Loss 3849248.50000
Epoch 59: Val Loss 3845997.50000
Epoch 60: Val Loss 3824401.50000
Epoch 61: Val Loss 3830582.25000
Epoch 62: Val Loss 3837928.75000
Epoch 63: Val Loss 3845435.25000
Epoch 64: Val Loss 3823163.25000
Epoch 65: Val Loss 3822920.25000
Epoch 66: Val Loss 3812716.75000
Epoch 67: Val Loss 3807006.75000
Epoch 68: Val Loss 3797451.25000
Epoch 69: Val Loss 3791460.75000
Epoch 70: Val Loss 3809112.00000
Epoch 71: Val Loss 3805748.75000
Epoch 72: Val Loss 3794492.25000
Epoch 73: Val Loss 3788792.75000
Epoch 74: Val Loss 3791442.25000
Epoch 75: Val Loss 3780516.50000
Epoch 76: Val Loss 3773301.75000
Epoch 77: Val Loss 3769609.50000
Epoch 78: Val Loss 3767900.75000
Epoch 79: Val Loss 3772846.75000
Epoch 80: Val Loss 3773417.50000
Epoch 81: Val Loss 3779473.00000
Epoch 82: Val Loss 3767086.00000
Epoch 83: Val Loss 3765143.75000
Epoch 84: Val Loss 3756092.25000
Epoch 85: Val Loss 3754410.00000
Epoch 86: Val Loss 3760458.50000
Epoch 87: Val Loss 3753609.25000
Epoch 88: Val Loss 3755511.50000
Epoch 89: Val Loss 3777222.50000
Epoch 90: Val Loss 3796512.50000
Epoch 91: Val Loss 3743111.00000
Epoch 92: Val Loss 3741153.00000
Epoch 93: Val Loss 3782408.00000
Epoch 94: Val Loss 3745740.75000
Epoch 95: Val Loss 3738998.50000
Epoch 96: Val Loss 3730388.75000
Epoch 97: Val Loss 3745208.25000
Epoch 98: Val Loss 3737201.50000
Epoch 99: Val Loss 3726632.25000
Saved Losses
{'MSE - mean': 3737363.7906132797, 'MSE - std': 0.0, 'R2 - mean': 0.5621095437576309, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8287468.50000
Epoch 1: Val Loss 7759749.50000
Epoch 2: Val Loss 7363439.00000
Epoch 3: Val Loss 6866660.50000
Epoch 4: Val Loss 6199086.00000
Epoch 5: Val Loss 5516968.00000
Epoch 6: Val Loss 4996829.50000
Epoch 7: Val Loss 4726632.50000
Epoch 8: Val Loss 4507762.50000
Epoch 9: Val Loss 4433448.50000
Epoch 10: Val Loss 4268914.00000
Epoch 11: Val Loss 4198469.00000
Epoch 12: Val Loss 4178768.50000
Epoch 13: Val Loss 4108926.00000
Epoch 14: Val Loss 4089019.00000
Epoch 15: Val Loss 4108734.75000
Epoch 16: Val Loss 4033169.75000
Epoch 17: Val Loss 3996936.75000
Epoch 18: Val Loss 3972213.75000
Epoch 19: Val Loss 3956825.50000
Epoch 20: Val Loss 3959758.75000
Epoch 21: Val Loss 3908408.25000
Epoch 22: Val Loss 3933544.75000
Epoch 23: Val Loss 3901585.50000
Epoch 24: Val Loss 3896463.75000
Epoch 25: Val Loss 3867609.25000
Epoch 26: Val Loss 3853906.25000
Epoch 27: Val Loss 3860975.75000
Epoch 28: Val Loss 3845489.75000
Epoch 29: Val Loss 3840076.25000
Epoch 30: Val Loss 3918994.75000
Epoch 31: Val Loss 3804796.25000
Epoch 32: Val Loss 3815705.25000
Epoch 33: Val Loss 3843093.75000
Epoch 34: Val Loss 3801337.25000
Epoch 35: Val Loss 3792022.25000
Epoch 36: Val Loss 3792685.50000
Epoch 37: Val Loss 3780402.75000
Epoch 38: Val Loss 3779653.25000
Epoch 39: Val Loss 3769984.50000
Epoch 40: Val Loss 3780457.50000
Epoch 41: Val Loss 3756683.75000
Epoch 42: Val Loss 3927927.00000
Epoch 43: Val Loss 3751893.25000
Epoch 44: Val Loss 3761775.25000
Epoch 45: Val Loss 3738773.25000
Epoch 46: Val Loss 3727769.25000
Epoch 47: Val Loss 3725140.75000
Epoch 48: Val Loss 3728218.50000
Epoch 49: Val Loss 3723615.25000
Epoch 50: Val Loss 3740910.00000
Epoch 51: Val Loss 3707320.75000
Epoch 52: Val Loss 3705223.00000
Epoch 53: Val Loss 3706932.50000
Epoch 54: Val Loss 3721464.75000
Epoch 55: Val Loss 3697350.25000
Epoch 56: Val Loss 3708946.75000
Epoch 57: Val Loss 3725347.00000
Epoch 58: Val Loss 3713798.25000
Epoch 59: Val Loss 3699399.75000
Epoch 60: Val Loss 3686217.50000
Epoch 61: Val Loss 3693000.25000
Epoch 62: Val Loss 3686522.00000
Epoch 63: Val Loss 3715294.25000
Epoch 64: Val Loss 3669381.75000
Epoch 65: Val Loss 3676022.25000
Epoch 66: Val Loss 3670756.00000
Epoch 67: Val Loss 3700029.50000
Epoch 68: Val Loss 3664359.00000
Epoch 69: Val Loss 3667742.75000
Epoch 70: Val Loss 3674246.50000
Epoch 71: Val Loss 3655692.25000
Epoch 72: Val Loss 3670163.00000
Epoch 73: Val Loss 3647672.75000
Epoch 74: Val Loss 3655241.50000
Epoch 75: Val Loss 3641573.25000
Epoch 76: Val Loss 3656843.25000
Epoch 77: Val Loss 3670961.75000
Epoch 78: Val Loss 3641383.50000
Epoch 79: Val Loss 3644430.00000
Epoch 80: Val Loss 3638011.75000
Epoch 81: Val Loss 3637791.75000
Epoch 82: Val Loss 3642693.25000
Epoch 83: Val Loss 3628834.25000
Epoch 84: Val Loss 3629954.75000
Epoch 85: Val Loss 3628469.25000
Epoch 86: Val Loss 3629011.50000
Epoch 87: Val Loss 3615987.75000
Epoch 88: Val Loss 3663999.25000
Epoch 89: Val Loss 3622017.75000
Epoch 90: Val Loss 3654061.50000
Epoch 91: Val Loss 3613130.00000
Epoch 92: Val Loss 3610630.50000
Epoch 93: Val Loss 3604785.00000
Epoch 94: Val Loss 3606797.50000
Epoch 95: Val Loss 3624374.25000
Epoch 96: Val Loss 3605975.50000
Epoch 97: Val Loss 3610531.00000
Epoch 98: Val Loss 3638517.75000
Epoch 99: Val Loss 3602764.25000
Saved Losses
{'MSE - mean': 3674902.628895429, 'MSE - std': 62461.16171785048, 'R2 - mean': 0.555500074405709, 'R2 - std': 0.006609469351921804} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 9117962.00000
Epoch 1: Val Loss 8658908.00000
Epoch 2: Val Loss 8226048.00000
Epoch 3: Val Loss 7669826.00000
Epoch 4: Val Loss 7032601.50000
Epoch 5: Val Loss 6239653.00000
Epoch 6: Val Loss 5751086.50000
Epoch 7: Val Loss 5439120.50000
Epoch 8: Val Loss 5230249.00000
Epoch 9: Val Loss 5086393.50000
Epoch 10: Val Loss 5012262.50000
Epoch 11: Val Loss 4906958.50000
Epoch 12: Val Loss 4861825.00000
Epoch 13: Val Loss 4798937.00000
Epoch 14: Val Loss 4844050.00000
Epoch 15: Val Loss 4720908.50000
Epoch 16: Val Loss 4707546.50000
Epoch 17: Val Loss 4696511.50000
Epoch 18: Val Loss 4658121.00000
Epoch 19: Val Loss 4622120.00000
Epoch 20: Val Loss 4591833.00000
Epoch 21: Val Loss 4606115.00000
Epoch 22: Val Loss 4568489.50000
Epoch 23: Val Loss 4544556.00000
Epoch 24: Val Loss 4539680.50000
Epoch 25: Val Loss 4531633.00000
Epoch 26: Val Loss 4503316.50000
Epoch 27: Val Loss 4514012.00000
Epoch 28: Val Loss 4492079.00000
Epoch 29: Val Loss 4501543.00000
Epoch 30: Val Loss 4476706.50000
Epoch 31: Val Loss 4462821.50000
Epoch 32: Val Loss 4450864.00000
Epoch 33: Val Loss 4445179.00000
Epoch 34: Val Loss 4448696.50000
Epoch 35: Val Loss 4426011.50000
Epoch 36: Val Loss 4425846.00000
Epoch 37: Val Loss 4451474.50000
Epoch 38: Val Loss 4457611.50000
Epoch 39: Val Loss 4408110.50000
Epoch 40: Val Loss 4400007.50000
Epoch 41: Val Loss 4405412.50000
Epoch 42: Val Loss 4400349.00000
Epoch 43: Val Loss 4380038.50000
Epoch 44: Val Loss 4374531.00000
Epoch 45: Val Loss 4384415.00000
Epoch 46: Val Loss 4362511.00000
Epoch 47: Val Loss 4365868.00000
Epoch 48: Val Loss 4345066.50000
Epoch 49: Val Loss 4342006.50000
Epoch 50: Val Loss 4365205.50000
Epoch 51: Val Loss 4381609.00000
Epoch 52: Val Loss 4341595.00000
Epoch 53: Val Loss 4331900.00000
Epoch 54: Val Loss 4326991.00000
Epoch 55: Val Loss 4324237.00000
Epoch 56: Val Loss 4316602.00000
Epoch 57: Val Loss 4326225.50000
Epoch 58: Val Loss 4324229.50000
Epoch 59: Val Loss 4303268.00000
Epoch 60: Val Loss 4297958.00000
Epoch 61: Val Loss 4289268.50000
Epoch 62: Val Loss 4290998.00000
Epoch 63: Val Loss 4277952.00000
Epoch 64: Val Loss 4283064.00000
Epoch 65: Val Loss 4281943.00000
Epoch 66: Val Loss 4301181.00000
Epoch 67: Val Loss 4272410.50000
Epoch 68: Val Loss 4278059.00000
Epoch 69: Val Loss 4273546.00000
Epoch 70: Val Loss 4261974.00000
Epoch 71: Val Loss 4269666.00000
Epoch 72: Val Loss 4255306.50000
Epoch 73: Val Loss 4266415.50000
Epoch 74: Val Loss 4253305.00000
Epoch 75: Val Loss 4248596.50000
Epoch 76: Val Loss 4268494.00000
Epoch 77: Val Loss 4241594.50000
Epoch 78: Val Loss 4256527.00000
Epoch 79: Val Loss 4242765.00000
Epoch 80: Val Loss 4234674.00000
Epoch 81: Val Loss 4233468.00000
Epoch 82: Val Loss 4258805.50000
Epoch 83: Val Loss 4230788.50000
Epoch 84: Val Loss 4250062.00000
Epoch 85: Val Loss 4225567.00000
Epoch 86: Val Loss 4229855.00000
Epoch 87: Val Loss 4222528.50000
Epoch 88: Val Loss 4219081.00000
Epoch 89: Val Loss 4229555.00000
Epoch 90: Val Loss 4223058.50000
Epoch 91: Val Loss 4218041.50000
Epoch 92: Val Loss 4239338.50000
Epoch 93: Val Loss 4222023.00000
Epoch 94: Val Loss 4243315.50000
Epoch 95: Val Loss 4204144.50000
Epoch 96: Val Loss 4213722.50000
Epoch 97: Val Loss 4212301.50000
Epoch 98: Val Loss 4214048.50000
Epoch 99: Val Loss 4207266.00000
Saved Losses
{'MSE - mean': 3856049.532397495, 'MSE - std': 261207.45097629947, 'R2 - mean': 0.5463675344682275, 'R2 - std': 0.01399749840133539} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8754118.00000
Epoch 1: Val Loss 8272308.00000
Epoch 2: Val Loss 7839816.00000
Epoch 3: Val Loss 7286665.00000
Epoch 4: Val Loss 6584772.50000
Epoch 5: Val Loss 5837766.00000
Epoch 6: Val Loss 5316240.00000
Epoch 7: Val Loss 4998702.50000
Epoch 8: Val Loss 4835578.00000
Epoch 9: Val Loss 4652675.50000
Epoch 10: Val Loss 4550739.50000
Epoch 11: Val Loss 4467763.50000
Epoch 12: Val Loss 4432389.50000
Epoch 13: Val Loss 4361731.50000
Epoch 14: Val Loss 4400912.50000
Epoch 15: Val Loss 4293870.00000
Epoch 16: Val Loss 4277621.50000
Epoch 17: Val Loss 4253104.00000
Epoch 18: Val Loss 4213539.50000
Epoch 19: Val Loss 4212694.00000
Epoch 20: Val Loss 4198289.00000
Epoch 21: Val Loss 4175943.00000
Epoch 22: Val Loss 4192955.75000
Epoch 23: Val Loss 4154817.00000
Epoch 24: Val Loss 4147009.00000
Epoch 25: Val Loss 4148025.50000
Epoch 26: Val Loss 4149745.00000
Epoch 27: Val Loss 4125227.25000
Epoch 28: Val Loss 4111397.25000
Epoch 29: Val Loss 4136627.50000
Epoch 30: Val Loss 4118036.75000
Epoch 31: Val Loss 4107967.25000
Epoch 32: Val Loss 4086612.50000
Epoch 33: Val Loss 4085585.50000
Epoch 34: Val Loss 4080250.00000
Epoch 35: Val Loss 4068539.75000
Epoch 36: Val Loss 4067177.50000
Epoch 37: Val Loss 4065019.75000
Epoch 38: Val Loss 4066151.00000
Epoch 39: Val Loss 4071941.25000
Epoch 40: Val Loss 4054833.75000
Epoch 41: Val Loss 4056155.00000
Epoch 42: Val Loss 4036948.50000
Epoch 43: Val Loss 4059369.50000
Epoch 44: Val Loss 4043870.00000
Epoch 45: Val Loss 4044972.25000
Epoch 46: Val Loss 4026575.75000
Epoch 47: Val Loss 4051369.25000
Epoch 48: Val Loss 4023408.00000
Epoch 49: Val Loss 4035607.50000
Epoch 50: Val Loss 4022650.00000
Epoch 51: Val Loss 4020829.50000
Epoch 52: Val Loss 4012195.50000
Epoch 53: Val Loss 4013236.00000
Epoch 54: Val Loss 4017288.75000
Epoch 55: Val Loss 4006441.50000
Epoch 56: Val Loss 3996232.00000
Epoch 57: Val Loss 4019050.50000
Epoch 58: Val Loss 3994023.50000
Epoch 59: Val Loss 3982836.00000
Epoch 60: Val Loss 3995311.75000
Epoch 61: Val Loss 3994580.50000
Epoch 62: Val Loss 3990751.25000
Epoch 63: Val Loss 3980707.00000
Epoch 64: Val Loss 3970173.00000
Epoch 65: Val Loss 3969313.50000
Epoch 66: Val Loss 3966971.00000
Epoch 67: Val Loss 3981696.00000
Epoch 68: Val Loss 3983969.00000
Epoch 69: Val Loss 3955568.00000
Epoch 70: Val Loss 3961323.00000
Epoch 71: Val Loss 3985000.75000
Epoch 72: Val Loss 3960404.50000
Epoch 73: Val Loss 3964989.00000
Epoch 74: Val Loss 3952385.00000
Epoch 75: Val Loss 3953611.25000
Epoch 76: Val Loss 4063048.25000
Epoch 77: Val Loss 3950790.25000
Epoch 78: Val Loss 3942973.00000
Epoch 79: Val Loss 3939916.25000
Epoch 80: Val Loss 3956654.25000
Epoch 81: Val Loss 3942544.00000
Epoch 82: Val Loss 3929050.50000
Epoch 83: Val Loss 3932822.50000
Epoch 84: Val Loss 3934424.00000
Epoch 85: Val Loss 3924344.75000
Epoch 86: Val Loss 3924689.00000
Epoch 87: Val Loss 3935059.00000
Epoch 88: Val Loss 3921955.00000
Epoch 89: Val Loss 3946686.00000
Epoch 90: Val Loss 3945191.50000
Epoch 91: Val Loss 3916869.75000
Epoch 92: Val Loss 3914798.75000
Epoch 93: Val Loss 3917118.00000
Epoch 94: Val Loss 3935851.75000
Epoch 95: Val Loss 3919429.75000
Epoch 96: Val Loss 3914013.00000
Epoch 97: Val Loss 3913893.25000
Epoch 98: Val Loss 3907138.75000
Epoch 99: Val Loss 3900795.75000
Saved Losses
{'MSE - mean': 3871525.00610657, 'MSE - std': 227794.79843427663, 'R2 - mean': 0.5457021761230252, 'R2 - std': 0.012176845909517424} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 8367657.00000
Epoch 1: Val Loss 7825040.50000
Epoch 2: Val Loss 7443688.00000
Epoch 3: Val Loss 6969484.50000
Epoch 4: Val Loss 6274378.50000
Epoch 5: Val Loss 5567712.00000
Epoch 6: Val Loss 4990348.00000
Epoch 7: Val Loss 4644339.50000
Epoch 8: Val Loss 4399434.00000
Epoch 9: Val Loss 4253070.50000
Epoch 10: Val Loss 4131989.75000
Epoch 11: Val Loss 4058789.25000
Epoch 12: Val Loss 3987217.00000
Epoch 13: Val Loss 3943781.25000
Epoch 14: Val Loss 3894664.00000
Epoch 15: Val Loss 3857387.75000
Epoch 16: Val Loss 3818672.50000
Epoch 17: Val Loss 3793728.50000
Epoch 18: Val Loss 3774684.25000
Epoch 19: Val Loss 3749671.50000
Epoch 20: Val Loss 3739745.50000
Epoch 21: Val Loss 3723966.25000
Epoch 22: Val Loss 3712373.75000
Epoch 23: Val Loss 3687834.50000
Epoch 24: Val Loss 3672280.25000
Epoch 25: Val Loss 3692929.00000
Epoch 26: Val Loss 3660973.50000
Epoch 27: Val Loss 3646255.25000
Epoch 28: Val Loss 3643013.25000
Epoch 29: Val Loss 3648344.25000
Epoch 30: Val Loss 3635738.50000
Epoch 31: Val Loss 3635084.25000
Epoch 32: Val Loss 3649803.00000
Epoch 33: Val Loss 3646279.50000
Epoch 34: Val Loss 3664180.50000
Epoch 35: Val Loss 3608299.00000
Epoch 36: Val Loss 3834885.25000
Epoch 37: Val Loss 3602587.75000
Epoch 38: Val Loss 3611116.25000
Epoch 39: Val Loss 3591022.00000
Epoch 40: Val Loss 3583362.75000
Epoch 41: Val Loss 3578992.25000
Epoch 42: Val Loss 3594034.25000
Epoch 43: Val Loss 3567988.00000
Epoch 44: Val Loss 3564113.75000
Epoch 45: Val Loss 3574227.00000
Epoch 46: Val Loss 3558829.00000
Epoch 47: Val Loss 3562556.75000
Epoch 48: Val Loss 3547983.50000
Epoch 49: Val Loss 3555588.75000
Epoch 50: Val Loss 3547160.00000
Epoch 51: Val Loss 3571158.25000
Epoch 52: Val Loss 3547441.50000
Epoch 53: Val Loss 3542818.00000
Epoch 54: Val Loss 3548261.50000
Epoch 55: Val Loss 3548158.25000
Epoch 56: Val Loss 3536338.75000
Epoch 57: Val Loss 3523908.75000
Epoch 58: Val Loss 3528549.50000
Epoch 59: Val Loss 3522981.50000
Epoch 60: Val Loss 3533030.25000
Epoch 61: Val Loss 3530803.25000
Epoch 62: Val Loss 3561034.25000
Epoch 63: Val Loss 3541891.00000
Epoch 64: Val Loss 3518828.00000
Epoch 65: Val Loss 3515497.25000
Epoch 66: Val Loss 3506051.00000
Epoch 67: Val Loss 3514694.25000
Epoch 68: Val Loss 3528084.75000
Epoch 69: Val Loss 3519000.25000
Epoch 70: Val Loss 3519212.00000
Epoch 71: Val Loss 3529924.00000
Epoch 72: Val Loss 3498498.00000
Epoch 73: Val Loss 3520423.75000
Epoch 74: Val Loss 3501777.50000
Epoch 75: Val Loss 3503466.75000
Epoch 76: Val Loss 3499954.75000
Epoch 77: Val Loss 3550580.75000
Epoch 78: Val Loss 3495443.00000
Epoch 79: Val Loss 3499047.75000
Epoch 80: Val Loss 3495455.25000
Epoch 81: Val Loss 3504010.50000
Epoch 82: Val Loss 3494457.25000
Epoch 83: Val Loss 3485934.25000
Epoch 84: Val Loss 3480430.25000
Epoch 85: Val Loss 3488457.50000
Epoch 86: Val Loss 3486831.75000
Epoch 87: Val Loss 3488045.50000
Epoch 88: Val Loss 3481894.50000
Epoch 89: Val Loss 3479614.75000
Epoch 90: Val Loss 3513758.50000
Epoch 91: Val Loss 3488778.50000
Epoch 92: Val Loss 3495166.75000
Epoch 93: Val Loss 3490976.00000
Epoch 94: Val Loss 3475692.50000
Epoch 95: Val Loss 3473218.50000
Epoch 96: Val Loss 3478655.75000
Epoch 97: Val Loss 3504985.50000
Epoch 98: Val Loss 3474422.50000
Epoch 99: Val Loss 3474045.75000
Saved Losses
{'MSE - mean': 3793583.3094478236, 'MSE - std': 256538.5126392258, 'R2 - mean': 0.5505759069109344, 'R2 - std': 0.01461620567094481} 
 

Saving model.....
Results After CV: {'MSE - mean': 3793583.3094478236, 'MSE - std': 256538.5126392258, 'R2 - mean': 0.5505759069109344, 'R2 - std': 0.01461620567094481}
Train time: 6919.910062988801
Inference time: 6.179391087032855
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 50 finished with value: 3793583.3094478236 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -1, 'learning_rate': -5, 'dropout': 0.1}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4551940.50000
Epoch 1: Val Loss 4093080.00000
Epoch 2: Val Loss 3977841.50000
Epoch 3: Val Loss 3905454.25000
Epoch 4: Val Loss 3945754.50000
Epoch 5: Val Loss 3824789.75000
Epoch 6: Val Loss 3800286.00000
Epoch 7: Val Loss 3779384.75000
Epoch 8: Val Loss 3736526.25000
Epoch 9: Val Loss 3717295.25000
Epoch 10: Val Loss 3684448.00000
Epoch 11: Val Loss 3702427.00000
Epoch 12: Val Loss 3677690.00000
Epoch 13: Val Loss 3650887.75000
Epoch 14: Val Loss 3626513.25000
Epoch 15: Val Loss 3617653.75000
Epoch 16: Val Loss 3625567.00000
Epoch 17: Val Loss 3603290.00000
Epoch 18: Val Loss 3589858.75000
Epoch 19: Val Loss 3579457.50000
Epoch 20: Val Loss 3584972.75000
Epoch 21: Val Loss 3565082.50000
Epoch 22: Val Loss 3545712.75000
Epoch 23: Val Loss 3533606.75000
Epoch 24: Val Loss 3539097.50000
Epoch 25: Val Loss 3538958.50000
Epoch 26: Val Loss 3536066.25000
Epoch 27: Val Loss 3520107.25000
Epoch 28: Val Loss 3535883.00000
Epoch 29: Val Loss 3510887.75000
Epoch 30: Val Loss 3511456.50000
Epoch 31: Val Loss 3500056.25000
Epoch 32: Val Loss 3501888.50000
Epoch 33: Val Loss 3511108.50000
Epoch 34: Val Loss 3517067.50000
Epoch 35: Val Loss 3476121.00000
Epoch 36: Val Loss 3503372.50000
Epoch 37: Val Loss 3488958.50000
Epoch 38: Val Loss 3458877.50000
Epoch 39: Val Loss 3472923.50000
Epoch 40: Val Loss 3464671.25000
Epoch 41: Val Loss 3456288.25000
Epoch 42: Val Loss 3463777.00000
Epoch 43: Val Loss 3481523.00000
Epoch 44: Val Loss 3457509.25000
Epoch 45: Val Loss 3454378.25000
Epoch 46: Val Loss 3446091.00000
Epoch 47: Val Loss 3449828.50000
Epoch 48: Val Loss 3450214.00000
Epoch 49: Val Loss 3710277.25000
Epoch 50: Val Loss 3447905.50000
Epoch 51: Val Loss 3440652.50000
Epoch 52: Val Loss 3458572.50000
Epoch 53: Val Loss 3439926.75000
Epoch 54: Val Loss 3487314.75000
Epoch 55: Val Loss 3432860.50000
Epoch 56: Val Loss 3463403.50000
Epoch 57: Val Loss 3453159.75000
Epoch 58: Val Loss 3418955.00000
Epoch 59: Val Loss 3448975.50000
Epoch 60: Val Loss 3442740.00000
Epoch 61: Val Loss 3442853.00000
Epoch 62: Val Loss 3443739.50000
Epoch 63: Val Loss 3460790.25000
Epoch 64: Val Loss 3516326.25000
Epoch 65: Val Loss 3422502.25000
Epoch 66: Val Loss 3438430.25000
Epoch 67: Val Loss 3431487.00000
Epoch 68: Val Loss 3444021.50000
Epoch 69: Val Loss 3419228.00000
Epoch 70: Val Loss 3416178.25000
Epoch 71: Val Loss 3435805.25000
Epoch 72: Val Loss 3449315.50000
Epoch 73: Val Loss 3452154.50000
Epoch 74: Val Loss 3437375.00000
Epoch 75: Val Loss 3448321.25000
Epoch 76: Val Loss 3457483.00000
Epoch 77: Val Loss 3490410.50000
Epoch 78: Val Loss 3425466.75000
Epoch 79: Val Loss 3462834.50000
Epoch 80: Val Loss 3424698.50000
Epoch 81: Val Loss 3578780.75000
Epoch 82: Val Loss 3510236.25000
Epoch 83: Val Loss 3467434.50000
Epoch 84: Val Loss 3472705.75000
Epoch 85: Val Loss 3441009.50000
Epoch 86: Val Loss 3486726.50000
Epoch 87: Val Loss 3440498.25000
Epoch 88: Val Loss 3549347.50000
Epoch 89: Val Loss 3525522.25000
Epoch 90: Val Loss 3484893.00000
Epoch 91: Val Loss 3464982.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3431246.509388201, 'MSE - std': 0.0, 'R2 - mean': 0.5979759574784443, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4251487.00000
Epoch 1: Val Loss 3894220.75000
Epoch 2: Val Loss 3807164.75000
Epoch 3: Val Loss 3748248.75000
Epoch 4: Val Loss 3706766.75000
Epoch 5: Val Loss 3675302.25000
Epoch 6: Val Loss 3699492.75000
Epoch 7: Val Loss 3615466.00000
Epoch 8: Val Loss 3650574.00000
Epoch 9: Val Loss 3571640.50000
Epoch 10: Val Loss 3555565.75000
Epoch 11: Val Loss 3593758.50000
Epoch 12: Val Loss 3560393.75000
Epoch 13: Val Loss 3532149.25000
Epoch 14: Val Loss 3516643.00000
Epoch 15: Val Loss 3508721.75000
Epoch 16: Val Loss 3535484.75000
Epoch 17: Val Loss 3487278.50000
Epoch 18: Val Loss 3482661.25000
Epoch 19: Val Loss 3506786.75000
Epoch 20: Val Loss 3494771.75000
Epoch 21: Val Loss 3474198.00000
Epoch 22: Val Loss 3473740.25000
Epoch 23: Val Loss 3495835.75000
Epoch 24: Val Loss 3471084.50000
Epoch 25: Val Loss 3445805.75000
Epoch 26: Val Loss 3460201.50000
Epoch 27: Val Loss 3450627.50000
Epoch 28: Val Loss 3433508.50000
Epoch 29: Val Loss 3434072.00000
Epoch 30: Val Loss 3435888.00000
Epoch 31: Val Loss 3401484.75000
Epoch 32: Val Loss 3422452.75000
Epoch 33: Val Loss 3414123.00000
Epoch 34: Val Loss 3490800.25000
Epoch 35: Val Loss 3446992.75000
Epoch 36: Val Loss 3393494.25000
Epoch 37: Val Loss 3455071.75000
Epoch 38: Val Loss 3458183.50000
Epoch 39: Val Loss 3397504.75000
Epoch 40: Val Loss 3482864.00000
Epoch 41: Val Loss 3391488.50000
Epoch 42: Val Loss 3387743.25000
Epoch 43: Val Loss 3411107.00000
Epoch 44: Val Loss 3421483.00000
Epoch 45: Val Loss 3413951.00000
Epoch 46: Val Loss 3405690.00000
Epoch 47: Val Loss 3411413.00000
Epoch 48: Val Loss 3432147.00000
Epoch 49: Val Loss 3394535.25000
Epoch 50: Val Loss 3416038.25000
Epoch 51: Val Loss 3472078.25000
Epoch 52: Val Loss 3392022.50000
Epoch 53: Val Loss 3395611.00000
Epoch 54: Val Loss 3382634.00000
Epoch 55: Val Loss 3409587.50000
Epoch 56: Val Loss 3511499.00000
Epoch 57: Val Loss 3442283.00000
Epoch 58: Val Loss 3436518.50000
Epoch 59: Val Loss 3381763.00000
Epoch 60: Val Loss 3399751.25000
Epoch 61: Val Loss 3401267.00000
Epoch 62: Val Loss 3418418.25000
Epoch 63: Val Loss 3395803.75000
Epoch 64: Val Loss 3402679.75000
Epoch 65: Val Loss 3414082.75000
Epoch 66: Val Loss 3429444.25000
Epoch 67: Val Loss 3413268.75000
Epoch 68: Val Loss 3404697.00000
Epoch 69: Val Loss 3378377.50000
Epoch 70: Val Loss 3418638.25000
Epoch 71: Val Loss 3485452.25000
Epoch 72: Val Loss 3389359.50000
Epoch 73: Val Loss 3414671.00000
Epoch 74: Val Loss 3436668.75000
Epoch 75: Val Loss 3396809.75000
Epoch 76: Val Loss 3436502.00000
Epoch 77: Val Loss 3437269.50000
Epoch 78: Val Loss 3432544.25000
Epoch 79: Val Loss 3401180.75000
Epoch 80: Val Loss 3418265.00000
Epoch 81: Val Loss 3429565.75000
Epoch 82: Val Loss 3442795.00000
Epoch 83: Val Loss 3429180.25000
Epoch 84: Val Loss 3422617.25000
Epoch 85: Val Loss 3407636.75000
Epoch 86: Val Loss 3439111.00000
Epoch 87: Val Loss 3452921.50000
Epoch 88: Val Loss 3429758.25000
Epoch 89: Val Loss 3467075.00000
Epoch 90: Val Loss 3508038.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3411189.631608161, 'MSE - std': 20056.877780039795, 'R2 - mean': 0.5872514206993065, 'R2 - std': 0.010724536779137928} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4967071.00000
Epoch 1: Val Loss 4554958.00000
Epoch 2: Val Loss 4418187.50000
Epoch 3: Val Loss 4361552.00000
Epoch 4: Val Loss 4301503.00000
Epoch 5: Val Loss 4292862.50000
Epoch 6: Val Loss 4291558.00000
Epoch 7: Val Loss 4225768.50000
Epoch 8: Val Loss 4182180.00000
Epoch 9: Val Loss 4156733.50000
Epoch 10: Val Loss 4182891.75000
Epoch 11: Val Loss 4152232.75000
Epoch 12: Val Loss 4114851.50000
Epoch 13: Val Loss 4105053.50000
Epoch 14: Val Loss 4147408.50000
Epoch 15: Val Loss 4077513.25000
Epoch 16: Val Loss 4109424.00000
Epoch 17: Val Loss 4072934.25000
Epoch 18: Val Loss 4075617.00000
Epoch 19: Val Loss 4046804.50000
Epoch 20: Val Loss 4033806.25000
Epoch 21: Val Loss 4016969.50000
Epoch 22: Val Loss 4013140.50000
Epoch 23: Val Loss 4008054.50000
Epoch 24: Val Loss 4028913.75000
Epoch 25: Val Loss 3976110.75000
Epoch 26: Val Loss 3975707.25000
Epoch 27: Val Loss 3980677.75000
Epoch 28: Val Loss 3971981.50000
Epoch 29: Val Loss 3962921.25000
Epoch 30: Val Loss 3985816.00000
Epoch 31: Val Loss 3969236.50000
Epoch 32: Val Loss 3933796.00000
Epoch 33: Val Loss 3963761.75000
Epoch 34: Val Loss 3951114.00000
Epoch 35: Val Loss 3934564.75000
Epoch 36: Val Loss 3926525.50000
Epoch 37: Val Loss 3920291.00000
Epoch 38: Val Loss 3908229.25000
Epoch 39: Val Loss 4071041.00000
Epoch 40: Val Loss 4000721.75000
Epoch 41: Val Loss 3956348.75000
Epoch 42: Val Loss 3896571.25000
Epoch 43: Val Loss 3893553.00000
Epoch 44: Val Loss 3889514.50000
Epoch 45: Val Loss 3896126.25000
Epoch 46: Val Loss 3880058.00000
Epoch 47: Val Loss 3898184.25000
Epoch 48: Val Loss 3895417.25000
Epoch 49: Val Loss 3883616.00000
Epoch 50: Val Loss 3920483.50000
Epoch 51: Val Loss 3895634.75000
Epoch 52: Val Loss 3865941.75000
Epoch 53: Val Loss 3868711.00000
Epoch 54: Val Loss 3886368.00000
Epoch 55: Val Loss 3872350.25000
Epoch 56: Val Loss 3868859.75000
Epoch 57: Val Loss 3858606.75000
Epoch 58: Val Loss 3843075.00000
Epoch 59: Val Loss 3857625.25000
Epoch 60: Val Loss 3852783.25000
Epoch 61: Val Loss 3850602.00000
Epoch 62: Val Loss 3857009.00000
Epoch 63: Val Loss 3869297.00000
Epoch 64: Val Loss 3866850.75000
Epoch 65: Val Loss 3866261.25000
Epoch 66: Val Loss 3876562.75000
Epoch 67: Val Loss 3847636.00000
Epoch 68: Val Loss 3855975.00000
Epoch 69: Val Loss 3887428.00000
Epoch 70: Val Loss 3859134.25000
Epoch 71: Val Loss 3844830.00000
Epoch 72: Val Loss 3852858.50000
Epoch 73: Val Loss 3875435.75000
Epoch 74: Val Loss 3859839.25000
Epoch 75: Val Loss 3876475.75000
Epoch 76: Val Loss 3871940.00000
Epoch 77: Val Loss 3851722.00000
Epoch 78: Val Loss 3862951.00000
Epoch 79: Val Loss 3904954.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3559425.271181284, 'MSE - std': 210275.52221667298, 'R2 - mean': 0.5810504952974379, 'R2 - std': 0.012392742947539843} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4674233.00000
Epoch 1: Val Loss 4206927.00000
Epoch 2: Val Loss 4152923.75000
Epoch 3: Val Loss 4062578.75000
Epoch 4: Val Loss 4020083.00000
Epoch 5: Val Loss 4005364.75000
Epoch 6: Val Loss 3961735.00000
Epoch 7: Val Loss 3943220.50000
Epoch 8: Val Loss 3940367.25000
Epoch 9: Val Loss 3919953.50000
Epoch 10: Val Loss 3919299.50000
Epoch 11: Val Loss 3891300.00000
Epoch 12: Val Loss 3891851.25000
Epoch 13: Val Loss 3876770.25000
Epoch 14: Val Loss 3850907.00000
Epoch 15: Val Loss 3825092.75000
Epoch 16: Val Loss 3862379.25000
Epoch 17: Val Loss 3821343.25000
Epoch 18: Val Loss 3808432.00000
Epoch 19: Val Loss 3799158.25000
Epoch 20: Val Loss 3801718.50000
Epoch 21: Val Loss 3875118.75000
Epoch 22: Val Loss 3786275.00000
Epoch 23: Val Loss 3797912.75000
Epoch 24: Val Loss 3807813.25000
Epoch 25: Val Loss 3823316.75000
Epoch 26: Val Loss 3792018.25000
Epoch 27: Val Loss 3811142.50000
Epoch 28: Val Loss 3751948.25000
Epoch 29: Val Loss 3755375.25000
Epoch 30: Val Loss 3751464.25000
Epoch 31: Val Loss 3739220.50000
Epoch 32: Val Loss 3782958.25000
Epoch 33: Val Loss 3744085.75000
Epoch 34: Val Loss 3771032.75000
Epoch 35: Val Loss 3755228.75000
Epoch 36: Val Loss 3732423.50000
Epoch 37: Val Loss 3757909.75000
Epoch 38: Val Loss 3714009.25000
Epoch 39: Val Loss 3711410.75000
Epoch 40: Val Loss 3741425.50000
Epoch 41: Val Loss 3721453.50000
Epoch 42: Val Loss 3721754.50000
Epoch 43: Val Loss 3703799.00000
Epoch 44: Val Loss 3716158.75000
Epoch 45: Val Loss 3696085.75000
Epoch 46: Val Loss 3728963.00000
Epoch 47: Val Loss 3749002.50000
Epoch 48: Val Loss 3710191.75000
Epoch 49: Val Loss 3689317.25000
Epoch 50: Val Loss 3743312.00000
Epoch 51: Val Loss 3723070.25000
Epoch 52: Val Loss 3744670.75000
Epoch 53: Val Loss 3780157.50000
Epoch 54: Val Loss 3723121.75000
Epoch 55: Val Loss 3719581.50000
Epoch 56: Val Loss 3723862.25000
Epoch 57: Val Loss 3720015.75000
Epoch 58: Val Loss 3703193.25000
Epoch 59: Val Loss 3773601.00000
Epoch 60: Val Loss 3709254.50000
Epoch 61: Val Loss 3733300.50000
Epoch 62: Val Loss 3709122.75000
Epoch 63: Val Loss 3718109.00000
Epoch 64: Val Loss 3719640.25000
Epoch 65: Val Loss 3749197.00000
Epoch 66: Val Loss 3764401.75000
Epoch 67: Val Loss 3765944.25000
Epoch 68: Val Loss 3749077.75000
Epoch 69: Val Loss 3813112.75000
Epoch 70: Val Loss 3746812.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3594509.928352099, 'MSE - std': 191975.6389206758, 'R2 - mean': 0.5780670557432926, 'R2 - std': 0.011911666258024659} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4138918.50000
Epoch 1: Val Loss 3709783.50000
Epoch 2: Val Loss 3626513.00000
Epoch 3: Val Loss 3610494.75000
Epoch 4: Val Loss 3646004.75000
Epoch 5: Val Loss 3531188.50000
Epoch 6: Val Loss 3494313.75000
Epoch 7: Val Loss 3490704.25000
Epoch 8: Val Loss 3463917.00000
Epoch 9: Val Loss 3464119.75000
Epoch 10: Val Loss 3468528.75000
Epoch 11: Val Loss 3432906.00000
Epoch 12: Val Loss 3447564.50000
Epoch 13: Val Loss 3425398.25000
Epoch 14: Val Loss 3428809.50000
Epoch 15: Val Loss 3440260.25000
Epoch 16: Val Loss 3405927.75000
Epoch 17: Val Loss 3394994.50000
Epoch 18: Val Loss 3414375.00000
Epoch 19: Val Loss 3378780.75000
Epoch 20: Val Loss 3392123.00000
Epoch 21: Val Loss 3437084.00000
Epoch 22: Val Loss 3429679.75000
Epoch 23: Val Loss 3398095.75000
Epoch 24: Val Loss 3414514.00000
Epoch 25: Val Loss 3397190.25000
Epoch 26: Val Loss 3416947.00000
Epoch 27: Val Loss 3375204.25000
Epoch 28: Val Loss 3384317.00000
Epoch 29: Val Loss 3403561.50000
Epoch 30: Val Loss 3382610.25000
Epoch 31: Val Loss 3422813.50000
Epoch 32: Val Loss 3396010.50000
Epoch 33: Val Loss 3367852.50000
Epoch 34: Val Loss 3389463.75000
Epoch 35: Val Loss 3424170.50000
Epoch 36: Val Loss 3415003.00000
Epoch 37: Val Loss 3467703.75000
Epoch 38: Val Loss 3501294.00000
Epoch 39: Val Loss 3409173.75000
Epoch 40: Val Loss 3426058.50000
Epoch 41: Val Loss 3394024.75000
Epoch 42: Val Loss 3416819.25000
Epoch 43: Val Loss 3419002.25000
Epoch 44: Val Loss 3415084.75000
Epoch 45: Val Loss 3376559.50000
Epoch 46: Val Loss 3426817.75000
Epoch 47: Val Loss 3377931.25000
Epoch 48: Val Loss 3389007.75000
Epoch 49: Val Loss 3395289.50000
Epoch 50: Val Loss 3385347.25000
Epoch 51: Val Loss 3480769.00000
Epoch 52: Val Loss 3407137.50000
Epoch 53: Val Loss 3415870.75000
Epoch 54: Val Loss 3385872.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551469.337009641, 'MSE - std': 192077.2937221766, 'R2 - mean': 0.578999353895413, 'R2 - std': 0.010816050749318752} 
 

Saving model.....
Results After CV: {'MSE - mean': 3551469.337009641, 'MSE - std': 192077.2937221766, 'R2 - mean': 0.578999353895413, 'R2 - std': 0.010816050749318752}
Train time: 5321.92739814464
Inference time: 6.1504794369451705
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 51 finished with value: 3551469.337009641 and parameters: {'dim': 64, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.1}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4455473.00000
Epoch 1: Val Loss 4087447.50000
Epoch 2: Val Loss 3955269.25000
Epoch 3: Val Loss 3908492.75000
Epoch 4: Val Loss 3837417.50000
Epoch 5: Val Loss 3818615.00000
Epoch 6: Val Loss 3796776.00000
Epoch 7: Val Loss 3748210.25000
Epoch 8: Val Loss 3741719.75000
Epoch 9: Val Loss 3702618.50000
Epoch 10: Val Loss 3696362.50000
Epoch 11: Val Loss 3671080.25000
Epoch 12: Val Loss 3647070.25000
Epoch 13: Val Loss 3636779.75000
Epoch 14: Val Loss 3669910.25000
Epoch 15: Val Loss 3631321.25000
Epoch 16: Val Loss 3595909.75000
Epoch 17: Val Loss 3588020.75000
Epoch 18: Val Loss 3582546.25000
Epoch 19: Val Loss 3571326.75000
Epoch 20: Val Loss 3552524.25000
Epoch 21: Val Loss 3557315.25000
Epoch 22: Val Loss 3552279.00000
Epoch 23: Val Loss 3559862.50000
Epoch 24: Val Loss 3536583.75000
Epoch 25: Val Loss 3545850.75000
Epoch 26: Val Loss 3519181.50000
Epoch 27: Val Loss 3503517.75000
Epoch 28: Val Loss 3524179.00000
Epoch 29: Val Loss 3502921.25000
Epoch 30: Val Loss 3480069.25000
Epoch 31: Val Loss 3486026.00000
Epoch 32: Val Loss 3492433.50000
Epoch 33: Val Loss 3528685.75000
Epoch 34: Val Loss 3484049.75000
Epoch 35: Val Loss 3482180.75000
Epoch 36: Val Loss 3455386.25000
Epoch 37: Val Loss 3450881.00000
Epoch 38: Val Loss 3452340.50000
Epoch 39: Val Loss 3450445.00000
Epoch 40: Val Loss 3452207.75000
Epoch 41: Val Loss 3468490.75000
Epoch 42: Val Loss 3453693.75000
Epoch 43: Val Loss 3447582.50000
Epoch 44: Val Loss 3454121.00000
Epoch 45: Val Loss 3445647.00000
Epoch 46: Val Loss 3438479.50000
Epoch 47: Val Loss 3443908.50000
Epoch 48: Val Loss 3542646.50000
Epoch 49: Val Loss 3442066.00000
Epoch 50: Val Loss 3437100.25000
Epoch 51: Val Loss 3484794.00000
Epoch 52: Val Loss 3438258.25000
Epoch 53: Val Loss 3405225.50000
Epoch 54: Val Loss 3414766.75000
Epoch 55: Val Loss 3426538.00000
Epoch 56: Val Loss 3418076.25000
Epoch 57: Val Loss 3430295.25000
Epoch 58: Val Loss 3434528.25000
Epoch 59: Val Loss 3429178.75000
Epoch 60: Val Loss 3457489.00000
Epoch 61: Val Loss 3429921.50000
Epoch 62: Val Loss 3450129.00000
Epoch 63: Val Loss 3428313.00000
Epoch 64: Val Loss 3431783.00000
Epoch 65: Val Loss 3464721.25000
Epoch 66: Val Loss 3418587.75000
Epoch 67: Val Loss 3497502.75000
Epoch 68: Val Loss 3430342.50000
Epoch 69: Val Loss 3472807.25000
Epoch 70: Val Loss 3449996.50000
Epoch 71: Val Loss 3432645.00000
Epoch 72: Val Loss 3475747.75000
Epoch 73: Val Loss 3424666.75000
Epoch 74: Val Loss 3463540.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3422142.7498107445, 'MSE - std': 0.0, 'R2 - mean': 0.5990426048957778, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4257325.50000
Epoch 1: Val Loss 3875948.75000
Epoch 2: Val Loss 3773816.00000
Epoch 3: Val Loss 3720909.50000
Epoch 4: Val Loss 3703034.50000
Epoch 5: Val Loss 3649185.50000
Epoch 6: Val Loss 3632974.00000
Epoch 7: Val Loss 3674971.75000
Epoch 8: Val Loss 3590628.75000
Epoch 9: Val Loss 3576756.50000
Epoch 10: Val Loss 3566745.50000
Epoch 11: Val Loss 3657397.75000
Epoch 12: Val Loss 3591782.25000
Epoch 13: Val Loss 3531750.00000
Epoch 14: Val Loss 3519104.00000
Epoch 15: Val Loss 3504892.25000
Epoch 16: Val Loss 3513764.00000
Epoch 17: Val Loss 3502671.25000
Epoch 18: Val Loss 3516646.50000
Epoch 19: Val Loss 3472734.75000
Epoch 20: Val Loss 3493591.75000
Epoch 21: Val Loss 3476290.75000
Epoch 22: Val Loss 3538700.00000
Epoch 23: Val Loss 3463723.00000
Epoch 24: Val Loss 3455274.50000
Epoch 25: Val Loss 3482759.00000
Epoch 26: Val Loss 3454783.25000
Epoch 27: Val Loss 3438853.00000
Epoch 28: Val Loss 3438339.50000
Epoch 29: Val Loss 3430795.00000
Epoch 30: Val Loss 3448361.50000
Epoch 31: Val Loss 3432671.75000
Epoch 32: Val Loss 3493841.25000
Epoch 33: Val Loss 3414886.50000
Epoch 34: Val Loss 3420139.25000
Epoch 35: Val Loss 3409422.00000
Epoch 36: Val Loss 3444108.50000
Epoch 37: Val Loss 3408616.50000
Epoch 38: Val Loss 3395609.50000
Epoch 39: Val Loss 3420519.25000
Epoch 40: Val Loss 3402385.50000
Epoch 41: Val Loss 3408827.75000
Epoch 42: Val Loss 3382214.50000
Epoch 43: Val Loss 3390302.50000
Epoch 44: Val Loss 3415561.50000
Epoch 45: Val Loss 3413610.75000
Epoch 46: Val Loss 3404187.00000
Epoch 47: Val Loss 3394133.25000
Epoch 48: Val Loss 3404953.00000
Epoch 49: Val Loss 3399629.50000
Epoch 50: Val Loss 3393005.25000
Epoch 51: Val Loss 3400597.75000
Epoch 52: Val Loss 3395186.00000
Epoch 53: Val Loss 3517948.50000
Epoch 54: Val Loss 3402235.00000
Epoch 55: Val Loss 3408294.50000
Epoch 56: Val Loss 3420238.00000
Epoch 57: Val Loss 3422297.75000
Epoch 58: Val Loss 3392838.75000
Epoch 59: Val Loss 3523329.00000
Epoch 60: Val Loss 3397802.75000
Epoch 61: Val Loss 3410884.00000
Epoch 62: Val Loss 3471601.50000
Epoch 63: Val Loss 3387279.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3405656.8716788855, 'MSE - std': 16485.878131859004, 'R2 - mean': 0.5879072333813551, 'R2 - std': 0.011135371514422676} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4934169.50000
Epoch 1: Val Loss 4530946.50000
Epoch 2: Val Loss 4452080.00000
Epoch 3: Val Loss 4378184.50000
Epoch 4: Val Loss 4332901.00000
Epoch 5: Val Loss 4600009.00000
Epoch 6: Val Loss 4256726.00000
Epoch 7: Val Loss 4222825.50000
Epoch 8: Val Loss 4193497.25000
Epoch 9: Val Loss 4189588.00000
Epoch 10: Val Loss 4171451.25000
Epoch 11: Val Loss 4161940.75000
Epoch 12: Val Loss 4130830.25000
Epoch 13: Val Loss 4109974.50000
Epoch 14: Val Loss 4101608.25000
Epoch 15: Val Loss 4091988.00000
Epoch 16: Val Loss 4113911.00000
Epoch 17: Val Loss 4076173.50000
Epoch 18: Val Loss 4053259.25000
Epoch 19: Val Loss 4057943.00000
Epoch 20: Val Loss 4049965.00000
Epoch 21: Val Loss 4083009.50000
Epoch 22: Val Loss 4026951.50000
Epoch 23: Val Loss 4008284.25000
Epoch 24: Val Loss 4087610.00000
Epoch 25: Val Loss 3992828.25000
Epoch 26: Val Loss 3982481.50000
Epoch 27: Val Loss 3985262.75000
Epoch 28: Val Loss 4032822.50000
Epoch 29: Val Loss 3971534.25000
Epoch 30: Val Loss 3991508.75000
Epoch 31: Val Loss 3951624.75000
Epoch 32: Val Loss 3944616.25000
Epoch 33: Val Loss 3982091.00000
Epoch 34: Val Loss 3945989.75000
Epoch 35: Val Loss 3939751.50000
Epoch 36: Val Loss 3931234.75000
Epoch 37: Val Loss 3925810.25000
Epoch 38: Val Loss 3911521.50000
Epoch 39: Val Loss 3909804.75000
Epoch 40: Val Loss 3908880.50000
Epoch 41: Val Loss 3944607.75000
Epoch 42: Val Loss 3933744.50000
Epoch 43: Val Loss 3916874.00000
Epoch 44: Val Loss 3899427.00000
Epoch 45: Val Loss 3873389.50000
Epoch 46: Val Loss 3887275.25000
Epoch 47: Val Loss 3880844.75000
Epoch 48: Val Loss 3927287.50000
Epoch 49: Val Loss 3903306.00000
Epoch 50: Val Loss 3860353.50000
Epoch 51: Val Loss 3983972.75000
Epoch 52: Val Loss 3851576.00000
Epoch 53: Val Loss 3868588.25000
Epoch 54: Val Loss 3865774.75000
Epoch 55: Val Loss 3896004.00000
Epoch 56: Val Loss 3853320.75000
Epoch 57: Val Loss 3843878.25000
Epoch 58: Val Loss 3888027.25000
Epoch 59: Val Loss 3857300.75000
Epoch 60: Val Loss 3859114.00000
Epoch 61: Val Loss 3869032.75000
Epoch 62: Val Loss 3870337.75000
Epoch 63: Val Loss 3886815.25000
Epoch 64: Val Loss 3849353.50000
Epoch 65: Val Loss 3843320.25000
Epoch 66: Val Loss 3874255.25000
Epoch 67: Val Loss 3838789.75000
Epoch 68: Val Loss 3850969.50000
Epoch 69: Val Loss 3853445.25000
Epoch 70: Val Loss 3837876.75000
Epoch 71: Val Loss 3878940.25000
Epoch 72: Val Loss 3855593.25000
Epoch 73: Val Loss 3843358.75000
Epoch 74: Val Loss 3920462.25000
Epoch 75: Val Loss 3867002.50000
Epoch 76: Val Loss 3854507.75000
Epoch 77: Val Loss 3885212.25000
Epoch 78: Val Loss 3865351.00000
Epoch 79: Val Loss 3857624.00000
Epoch 80: Val Loss 3877778.75000
Epoch 81: Val Loss 3865370.50000
Epoch 82: Val Loss 3861642.50000
Epoch 83: Val Loss 3891680.50000
Epoch 84: Val Loss 3870784.00000
Epoch 85: Val Loss 3879058.25000
Epoch 86: Val Loss 3949408.50000
Epoch 87: Val Loss 3900512.50000
Epoch 88: Val Loss 3911975.50000
Epoch 89: Val Loss 3878757.25000
Epoch 90: Val Loss 3891281.50000
Epoch 91: Val Loss 3889442.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3553652.9788922933, 'MSE - std': 209730.50553626526, 'R2 - mean': 0.5817208126442922, 'R2 - std': 0.012617762701105161} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4572237.00000
Epoch 1: Val Loss 4223049.00000
Epoch 2: Val Loss 4132375.50000
Epoch 3: Val Loss 4083716.75000
Epoch 4: Val Loss 4016961.50000
Epoch 5: Val Loss 4000720.50000
Epoch 6: Val Loss 3950353.75000
Epoch 7: Val Loss 3928750.00000
Epoch 8: Val Loss 3917766.25000
Epoch 9: Val Loss 3895828.00000
Epoch 10: Val Loss 3895942.25000
Epoch 11: Val Loss 3851794.75000
Epoch 12: Val Loss 3832067.00000
Epoch 13: Val Loss 3850221.00000
Epoch 14: Val Loss 3813105.50000
Epoch 15: Val Loss 3829809.75000
Epoch 16: Val Loss 3819554.25000
Epoch 17: Val Loss 3798357.25000
Epoch 18: Val Loss 3789357.50000
Epoch 19: Val Loss 3779663.75000
Epoch 20: Val Loss 3764462.25000
Epoch 21: Val Loss 3768276.50000
Epoch 22: Val Loss 3782110.25000
Epoch 23: Val Loss 3761316.00000
Epoch 24: Val Loss 3756114.75000
Epoch 25: Val Loss 3746447.25000
Epoch 26: Val Loss 3738901.25000
Epoch 27: Val Loss 3728366.75000
Epoch 28: Val Loss 3776772.00000
Epoch 29: Val Loss 3744282.00000
Epoch 30: Val Loss 3793219.50000
Epoch 31: Val Loss 3767480.00000
Epoch 32: Val Loss 3723242.00000
Epoch 33: Val Loss 3710452.75000
Epoch 34: Val Loss 3716037.25000
Epoch 35: Val Loss 3697127.00000
Epoch 36: Val Loss 3728777.50000
Epoch 37: Val Loss 3728529.75000
Epoch 38: Val Loss 3707605.75000
Epoch 39: Val Loss 3728876.75000
Epoch 40: Val Loss 3710740.50000
Epoch 41: Val Loss 3717338.50000
Epoch 42: Val Loss 3771576.00000
Epoch 43: Val Loss 3695911.00000
Epoch 44: Val Loss 3731753.25000
Epoch 45: Val Loss 3709120.00000
Epoch 46: Val Loss 3710135.00000
Epoch 47: Val Loss 3704096.50000
Epoch 48: Val Loss 3707507.50000
Epoch 49: Val Loss 3777334.25000
Epoch 50: Val Loss 3706679.00000
Epoch 51: Val Loss 3691730.25000
Epoch 52: Val Loss 3753825.00000
Epoch 53: Val Loss 3708048.00000
Epoch 54: Val Loss 3736953.25000
Epoch 55: Val Loss 3716146.75000
Epoch 56: Val Loss 3714098.75000
Epoch 57: Val Loss 3708670.75000
Epoch 58: Val Loss 3710010.00000
Epoch 59: Val Loss 3710482.75000
Epoch 60: Val Loss 3688455.00000
Epoch 61: Val Loss 3840155.25000
Epoch 62: Val Loss 3704711.75000
Epoch 63: Val Loss 3706910.75000
Epoch 64: Val Loss 3700693.75000
Epoch 65: Val Loss 3689837.00000
Epoch 66: Val Loss 3720007.50000
Epoch 67: Val Loss 3726428.25000
Epoch 68: Val Loss 3705659.75000
Epoch 69: Val Loss 3791230.75000
Epoch 70: Val Loss 3758099.50000
Epoch 71: Val Loss 3736813.00000
Epoch 72: Val Loss 3730050.25000
Epoch 73: Val Loss 3752261.75000
Epoch 74: Val Loss 3729774.00000
Epoch 75: Val Loss 3732702.75000
Epoch 76: Val Loss 3785908.00000
Epoch 77: Val Loss 3759562.00000
Epoch 78: Val Loss 3777185.75000
Epoch 79: Val Loss 3774220.25000
Epoch 80: Val Loss 3796232.00000
Epoch 81: Val Loss 3755060.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3589533.281996049, 'MSE - std': 191969.6647046745, 'R2 - mean': 0.5786451946508521, 'R2 - std': 0.012156653725872456} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4108890.00000
Epoch 1: Val Loss 3746795.00000
Epoch 2: Val Loss 3616221.25000
Epoch 3: Val Loss 3573139.50000
Epoch 4: Val Loss 3531684.00000
Epoch 5: Val Loss 3527377.75000
Epoch 6: Val Loss 3494080.25000
Epoch 7: Val Loss 3618065.50000
Epoch 8: Val Loss 3460328.00000
Epoch 9: Val Loss 3453668.00000
Epoch 10: Val Loss 3446680.50000
Epoch 11: Val Loss 3475936.00000
Epoch 12: Val Loss 3450839.50000
Epoch 13: Val Loss 3441144.25000
Epoch 14: Val Loss 3412493.00000
Epoch 15: Val Loss 3428541.75000
Epoch 16: Val Loss 3416370.75000
Epoch 17: Val Loss 3458516.00000
Epoch 18: Val Loss 3399083.50000
Epoch 19: Val Loss 3407348.00000
Epoch 20: Val Loss 3402227.00000
Epoch 21: Val Loss 3407449.50000
Epoch 22: Val Loss 3401927.75000
Epoch 23: Val Loss 3396303.00000
Epoch 24: Val Loss 3391305.25000
Epoch 25: Val Loss 3454815.50000
Epoch 26: Val Loss 3462568.75000
Epoch 27: Val Loss 3411273.50000
Epoch 28: Val Loss 3413367.75000
Epoch 29: Val Loss 3434330.25000
Epoch 30: Val Loss 3410249.75000
Epoch 31: Val Loss 3393319.25000
Epoch 32: Val Loss 3404975.50000
Epoch 33: Val Loss 3441656.50000
Epoch 34: Val Loss 3397656.50000
Epoch 35: Val Loss 3414539.25000
Epoch 36: Val Loss 3385309.25000
Epoch 37: Val Loss 3570602.00000
Epoch 38: Val Loss 3427435.00000
Epoch 39: Val Loss 3393031.75000
Epoch 40: Val Loss 3400703.75000
Epoch 41: Val Loss 3363514.00000
Epoch 42: Val Loss 3387879.00000
Epoch 43: Val Loss 3405324.00000
Epoch 44: Val Loss 3413815.25000
Epoch 45: Val Loss 3522727.75000
Epoch 46: Val Loss 3424641.50000
Epoch 47: Val Loss 3425810.25000
Epoch 48: Val Loss 3407994.25000
Epoch 49: Val Loss 3423197.50000
Epoch 50: Val Loss 3426550.75000
Epoch 51: Val Loss 3439642.25000
Epoch 52: Val Loss 3444554.25000
Epoch 53: Val Loss 3462345.00000
Epoch 54: Val Loss 3469136.25000
Epoch 55: Val Loss 3416276.25000
Epoch 56: Val Loss 3375203.00000
Epoch 57: Val Loss 3404765.00000
Epoch 58: Val Loss 3451931.25000
Epoch 59: Val Loss 3408857.00000
Epoch 60: Val Loss 3399416.75000
Epoch 61: Val Loss 3391785.50000
Epoch 62: Val Loss 3414722.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3546695.437851999, 'MSE - std': 191891.1287608156, 'R2 - mean': 0.5795597317960118, 'R2 - std': 0.011026010003991608} 
 

Saving model.....
Results After CV: {'MSE - mean': 3546695.437851999, 'MSE - std': 191891.1287608156, 'R2 - mean': 0.5795597317960118, 'R2 - std': 0.011026010003991608}
Train time: 5235.624989261525
Inference time: 6.234101347578689
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 52 finished with value: 3546695.437851999 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4491579.50000
Epoch 1: Val Loss 4069005.50000
Epoch 2: Val Loss 3947898.50000
Epoch 3: Val Loss 3892235.25000
Epoch 4: Val Loss 3865077.75000
Epoch 5: Val Loss 3861885.00000
Epoch 6: Val Loss 3788889.50000
Epoch 7: Val Loss 3760221.00000
Epoch 8: Val Loss 3748232.75000
Epoch 9: Val Loss 3720590.00000
Epoch 10: Val Loss 3679412.00000
Epoch 11: Val Loss 3671848.75000
Epoch 12: Val Loss 3656670.25000
Epoch 13: Val Loss 3639333.25000
Epoch 14: Val Loss 3633478.50000
Epoch 15: Val Loss 3601078.25000
Epoch 16: Val Loss 3593457.50000
Epoch 17: Val Loss 3584551.75000
Epoch 18: Val Loss 3564211.50000
Epoch 19: Val Loss 3564121.25000
Epoch 20: Val Loss 3568533.00000
Epoch 21: Val Loss 3547106.00000
Epoch 22: Val Loss 3534673.25000
Epoch 23: Val Loss 3528394.00000
Epoch 24: Val Loss 3578401.25000
Epoch 25: Val Loss 3504560.25000
Epoch 26: Val Loss 3522113.50000
Epoch 27: Val Loss 3541650.25000
Epoch 28: Val Loss 3538327.50000
Epoch 29: Val Loss 3477762.00000
Epoch 30: Val Loss 3484051.00000
Epoch 31: Val Loss 3525587.25000
Epoch 32: Val Loss 3506721.00000
Epoch 33: Val Loss 3475529.50000
Epoch 34: Val Loss 3471136.75000
Epoch 35: Val Loss 3466152.00000
Epoch 36: Val Loss 3463623.50000
Epoch 37: Val Loss 3462838.00000
Epoch 38: Val Loss 3466954.00000
Epoch 39: Val Loss 3448950.00000
Epoch 40: Val Loss 3451397.00000
Epoch 41: Val Loss 3437125.75000
Epoch 42: Val Loss 3498504.50000
Epoch 43: Val Loss 3485126.25000
Epoch 44: Val Loss 3427944.75000
Epoch 45: Val Loss 3430084.50000
Epoch 46: Val Loss 3580835.50000
Epoch 47: Val Loss 3433406.50000
Epoch 48: Val Loss 3476174.75000
Epoch 49: Val Loss 3423157.25000
Epoch 50: Val Loss 3429381.00000
Epoch 51: Val Loss 3412702.50000
Epoch 52: Val Loss 3433403.25000
Epoch 53: Val Loss 3458728.50000
Epoch 54: Val Loss 3445501.25000
Epoch 55: Val Loss 3426660.00000
Epoch 56: Val Loss 3465844.50000
Epoch 57: Val Loss 3417940.50000
Epoch 58: Val Loss 3443529.75000
Epoch 59: Val Loss 3428246.75000
Epoch 60: Val Loss 3475899.50000
Epoch 61: Val Loss 3457476.50000
Epoch 62: Val Loss 3435142.50000
Epoch 63: Val Loss 3419316.25000
Epoch 64: Val Loss 3522249.50000
Epoch 65: Val Loss 3483671.50000
Epoch 66: Val Loss 3443902.75000
Epoch 67: Val Loss 3500941.75000
Epoch 68: Val Loss 3436709.50000
Epoch 69: Val Loss 3438851.00000
Epoch 70: Val Loss 3441176.50000
Epoch 71: Val Loss 3473930.50000
Epoch 72: Val Loss 3585385.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3425082.811814096, 'MSE - std': 0.0, 'R2 - mean': 0.5986981307786844, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4225999.00000
Epoch 1: Val Loss 3978376.75000
Epoch 2: Val Loss 3778491.25000
Epoch 3: Val Loss 3817213.00000
Epoch 4: Val Loss 3699026.25000
Epoch 5: Val Loss 3659886.00000
Epoch 6: Val Loss 3645774.75000
Epoch 7: Val Loss 3611527.75000
Epoch 8: Val Loss 3603023.75000
Epoch 9: Val Loss 3586690.00000
Epoch 10: Val Loss 3603045.00000
Epoch 11: Val Loss 3568515.00000
Epoch 12: Val Loss 3568220.75000
Epoch 13: Val Loss 3520193.50000
Epoch 14: Val Loss 3512491.25000
Epoch 15: Val Loss 3509991.50000
Epoch 16: Val Loss 3489759.00000
Epoch 17: Val Loss 3517842.50000
Epoch 18: Val Loss 3477843.50000
Epoch 19: Val Loss 3498220.25000
Epoch 20: Val Loss 3480017.75000
Epoch 21: Val Loss 3480213.00000
Epoch 22: Val Loss 3459770.50000
Epoch 23: Val Loss 3443716.50000
Epoch 24: Val Loss 3451984.00000
Epoch 25: Val Loss 3469454.75000
Epoch 26: Val Loss 3456418.50000
Epoch 27: Val Loss 3451363.75000
Epoch 28: Val Loss 3471833.50000
Epoch 29: Val Loss 3425075.50000
Epoch 30: Val Loss 3421589.75000
Epoch 31: Val Loss 3446614.00000
Epoch 32: Val Loss 3458566.25000
Epoch 33: Val Loss 3418882.75000
Epoch 34: Val Loss 3429403.25000
Epoch 35: Val Loss 3439249.50000
Epoch 36: Val Loss 3411959.75000
Epoch 37: Val Loss 3412043.00000
Epoch 38: Val Loss 3505887.00000
Epoch 39: Val Loss 3545118.00000
Epoch 40: Val Loss 3398857.25000
Epoch 41: Val Loss 3407432.75000
Epoch 42: Val Loss 3434615.75000
Epoch 43: Val Loss 3416867.50000
Epoch 44: Val Loss 3402672.25000
Epoch 45: Val Loss 3410816.75000
Epoch 46: Val Loss 3378437.25000
Epoch 47: Val Loss 3429702.75000
Epoch 48: Val Loss 3413550.50000
Epoch 49: Val Loss 3394668.75000
Epoch 50: Val Loss 3431682.00000
Epoch 51: Val Loss 3395258.00000
Epoch 52: Val Loss 3409306.25000
Epoch 53: Val Loss 3380864.25000
Epoch 54: Val Loss 3405597.25000
Epoch 55: Val Loss 3408801.50000
Epoch 56: Val Loss 3383496.75000
Epoch 57: Val Loss 3411372.00000
Epoch 58: Val Loss 3382336.50000
Epoch 59: Val Loss 3405422.00000
Epoch 60: Val Loss 3406790.75000
Epoch 61: Val Loss 3384360.50000
Epoch 62: Val Loss 3395759.75000
Epoch 63: Val Loss 3381959.75000
Epoch 64: Val Loss 3389898.00000
Epoch 65: Val Loss 3381787.75000
Epoch 66: Val Loss 3396224.00000
Epoch 67: Val Loss 3432948.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3407421.088428395, 'MSE - std': 17661.723385700956, 'R2 - mean': 0.5876982594079233, 'R2 - std': 0.010999871370761083} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4968408.50000
Epoch 1: Val Loss 4600065.50000
Epoch 2: Val Loss 4462036.50000
Epoch 3: Val Loss 4389010.00000
Epoch 4: Val Loss 4345073.50000
Epoch 5: Val Loss 4280336.50000
Epoch 6: Val Loss 4265299.50000
Epoch 7: Val Loss 4241342.00000
Epoch 8: Val Loss 4214391.50000
Epoch 9: Val Loss 4217890.50000
Epoch 10: Val Loss 4166490.50000
Epoch 11: Val Loss 4148207.75000
Epoch 12: Val Loss 4132996.00000
Epoch 13: Val Loss 4122894.75000
Epoch 14: Val Loss 4096955.00000
Epoch 15: Val Loss 4101265.75000
Epoch 16: Val Loss 4086935.50000
Epoch 17: Val Loss 4060450.75000
Epoch 18: Val Loss 4058003.25000
Epoch 19: Val Loss 4082457.50000
Epoch 20: Val Loss 4041207.00000
Epoch 21: Val Loss 4042211.00000
Epoch 22: Val Loss 4036158.75000
Epoch 23: Val Loss 4039748.00000
Epoch 24: Val Loss 4025825.50000
Epoch 25: Val Loss 4012043.75000
Epoch 26: Val Loss 4028278.50000
Epoch 27: Val Loss 3996058.50000
Epoch 28: Val Loss 4036852.00000
Epoch 29: Val Loss 4004432.50000
Epoch 30: Val Loss 3966539.00000
Epoch 31: Val Loss 3984824.25000
Epoch 32: Val Loss 3969054.00000
Epoch 33: Val Loss 3977145.50000
Epoch 34: Val Loss 3973266.25000
Epoch 35: Val Loss 3959624.75000
Epoch 36: Val Loss 3947415.50000
Epoch 37: Val Loss 3937486.75000
Epoch 38: Val Loss 3930289.50000
Epoch 39: Val Loss 3942073.25000
Epoch 40: Val Loss 4069118.75000
Epoch 41: Val Loss 3937111.50000
Epoch 42: Val Loss 3929526.50000
Epoch 43: Val Loss 3911481.50000
Epoch 44: Val Loss 3901121.00000
Epoch 45: Val Loss 3930950.25000
Epoch 46: Val Loss 3930957.50000
Epoch 47: Val Loss 3928155.75000
Epoch 48: Val Loss 3916070.25000
Epoch 49: Val Loss 3900792.75000
Epoch 50: Val Loss 3942882.75000
Epoch 51: Val Loss 3920869.25000
Epoch 52: Val Loss 3922620.25000
Epoch 53: Val Loss 3885140.50000
Epoch 54: Val Loss 3906958.25000
Epoch 55: Val Loss 3909090.25000
Epoch 56: Val Loss 3873666.25000
Epoch 57: Val Loss 3881463.00000
Epoch 58: Val Loss 3878496.50000
Epoch 59: Val Loss 3861884.75000
Epoch 60: Val Loss 3870121.50000
Epoch 61: Val Loss 3890693.25000
Epoch 62: Val Loss 3860388.75000
Epoch 63: Val Loss 3908450.75000
Epoch 64: Val Loss 3876714.00000
Epoch 65: Val Loss 3882354.75000
Epoch 66: Val Loss 3870107.25000
Epoch 67: Val Loss 3861358.00000
Epoch 68: Val Loss 3859654.50000
Epoch 69: Val Loss 3873379.00000
Epoch 70: Val Loss 3840123.00000
Epoch 71: Val Loss 3839729.75000
Epoch 72: Val Loss 3863600.50000
Epoch 73: Val Loss 3886772.50000
Epoch 74: Val Loss 3945485.50000
Epoch 75: Val Loss 3909005.50000
Epoch 76: Val Loss 3842139.00000
Epoch 77: Val Loss 3850612.50000
Epoch 78: Val Loss 3858634.50000
Epoch 79: Val Loss 3846337.50000
Epoch 80: Val Loss 3862878.00000
Epoch 81: Val Loss 3851709.50000
Epoch 82: Val Loss 3868621.50000
Epoch 83: Val Loss 3863287.50000
Epoch 84: Val Loss 3856928.00000
Epoch 85: Val Loss 3861720.00000
Epoch 86: Val Loss 3863317.25000
Epoch 87: Val Loss 3853800.00000
Epoch 88: Val Loss 3863943.50000
Epoch 89: Val Loss 3946153.50000
Epoch 90: Val Loss 3867640.75000
Epoch 91: Val Loss 3852028.75000
Epoch 92: Val Loss 3883278.25000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3556880.9905605395, 'MSE - std': 211859.58165571807, 'R2 - mean': 0.5813519584280474, 'R2 - std': 0.012697080466385732} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4571844.50000
Epoch 1: Val Loss 4208361.00000
Epoch 2: Val Loss 4118996.75000
Epoch 3: Val Loss 4048348.75000
Epoch 4: Val Loss 4057165.50000
Epoch 5: Val Loss 3994143.25000
Epoch 6: Val Loss 3982779.75000
Epoch 7: Val Loss 3987500.25000
Epoch 8: Val Loss 3975326.75000
Epoch 9: Val Loss 3883180.25000
Epoch 10: Val Loss 3903055.25000
Epoch 11: Val Loss 3874037.75000
Epoch 12: Val Loss 3855582.00000
Epoch 13: Val Loss 3836117.75000
Epoch 14: Val Loss 3825530.00000
Epoch 15: Val Loss 3796555.00000
Epoch 16: Val Loss 3811763.00000
Epoch 17: Val Loss 3813461.25000
Epoch 18: Val Loss 3810580.00000
Epoch 19: Val Loss 3816554.50000
Epoch 20: Val Loss 3755885.50000
Epoch 21: Val Loss 3802620.75000
Epoch 22: Val Loss 3745106.75000
Epoch 23: Val Loss 3740800.50000
Epoch 24: Val Loss 3738353.50000
Epoch 25: Val Loss 3744387.00000
Epoch 26: Val Loss 3724457.50000
Epoch 27: Val Loss 3738752.00000
Epoch 28: Val Loss 3743126.25000
Epoch 29: Val Loss 3741627.75000
Epoch 30: Val Loss 3751004.75000
Epoch 31: Val Loss 3726074.50000
Epoch 32: Val Loss 3777695.25000
Epoch 33: Val Loss 3707963.25000
Epoch 34: Val Loss 3787657.50000
Epoch 35: Val Loss 3721068.75000
Epoch 36: Val Loss 3710822.50000
Epoch 37: Val Loss 3736027.00000
Epoch 38: Val Loss 3712047.75000
Epoch 39: Val Loss 3686137.25000
Epoch 40: Val Loss 3697328.50000
Epoch 41: Val Loss 3710912.50000
Epoch 42: Val Loss 3730171.00000
Epoch 43: Val Loss 3737371.00000
Epoch 44: Val Loss 3782114.25000
Epoch 45: Val Loss 3680209.50000
Epoch 46: Val Loss 3691779.00000
Epoch 47: Val Loss 3700197.25000
Epoch 48: Val Loss 3740687.75000
Epoch 49: Val Loss 3721108.00000
Epoch 50: Val Loss 3718539.00000
Epoch 51: Val Loss 3706861.50000
Epoch 52: Val Loss 3681160.75000
Epoch 53: Val Loss 3708545.00000
Epoch 54: Val Loss 3712411.25000
Epoch 55: Val Loss 3696556.75000
Epoch 56: Val Loss 3757325.50000
Epoch 57: Val Loss 3734273.50000
Epoch 58: Val Loss 3719542.25000
Epoch 59: Val Loss 3711448.25000
Epoch 60: Val Loss 3710060.75000
Epoch 61: Val Loss 3755079.00000
Epoch 62: Val Loss 3702580.75000
Epoch 63: Val Loss 3727430.50000
Epoch 64: Val Loss 3775350.50000
Epoch 65: Val Loss 3737401.25000
Epoch 66: Val Loss 3766638.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3591948.8131692084, 'MSE - std': 193268.2547705159, 'R2 - mean': 0.5783691919203734, 'R2 - std': 0.012149180112061507} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4146784.50000
Epoch 1: Val Loss 3727019.00000
Epoch 2: Val Loss 3624243.25000
Epoch 3: Val Loss 3586230.25000
Epoch 4: Val Loss 3540297.50000
Epoch 5: Val Loss 3542936.25000
Epoch 6: Val Loss 3506284.25000
Epoch 7: Val Loss 3492637.25000
Epoch 8: Val Loss 3518934.50000
Epoch 9: Val Loss 3468382.50000
Epoch 10: Val Loss 3455232.25000
Epoch 11: Val Loss 3466374.25000
Epoch 12: Val Loss 3433115.00000
Epoch 13: Val Loss 3424642.75000
Epoch 14: Val Loss 3438253.25000
Epoch 15: Val Loss 3437694.75000
Epoch 16: Val Loss 3459886.75000
Epoch 17: Val Loss 3428541.50000
Epoch 18: Val Loss 3450993.50000
Epoch 19: Val Loss 3405860.00000
Epoch 20: Val Loss 3440365.25000
Epoch 21: Val Loss 3397467.00000
Epoch 22: Val Loss 3416660.75000
Epoch 23: Val Loss 3396139.75000
Epoch 24: Val Loss 3398343.75000
Epoch 25: Val Loss 3411964.50000
Epoch 26: Val Loss 3429692.00000
Epoch 27: Val Loss 3388993.25000
Epoch 28: Val Loss 3404511.25000
Epoch 29: Val Loss 3409585.25000
Epoch 30: Val Loss 3434168.50000
Epoch 31: Val Loss 3387491.75000
Epoch 32: Val Loss 3413125.00000
Epoch 33: Val Loss 3403954.50000
Epoch 34: Val Loss 3411148.75000
Epoch 35: Val Loss 3387571.75000
Epoch 36: Val Loss 3405374.00000
Epoch 37: Val Loss 3436376.00000
Epoch 38: Val Loss 3390380.50000
Epoch 39: Val Loss 3431062.00000
Epoch 40: Val Loss 3415933.50000
Epoch 41: Val Loss 3395981.00000
Epoch 42: Val Loss 3551317.75000
Epoch 43: Val Loss 3418138.00000
Epoch 44: Val Loss 3395545.25000
Epoch 45: Val Loss 3461752.25000
Epoch 46: Val Loss 3461824.75000
Epoch 47: Val Loss 3437344.00000
Epoch 48: Val Loss 3426941.75000
Epoch 49: Val Loss 3405742.25000
Epoch 50: Val Loss 3406949.75000
Epoch 51: Val Loss 3441220.00000
Epoch 52: Val Loss 3403462.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3551699.587042241, 'MSE - std': 190688.47751479867, 'R2 - mean': 0.5789596379834906, 'R2 - std': 0.010930533753209466} 
 

Saving model.....
Results After CV: {'MSE - mean': 3551699.587042241, 'MSE - std': 190688.47751479867, 'R2 - mean': 0.5789596379834906, 'R2 - std': 0.010930533753209466}
Train time: 5210.534629102051
Inference time: 6.412451356649399
Finished cross validation
Hyperparam was saved!!! Hurrah!!!
Trial 53 finished with value: 3551699.587042241 and parameters: {'dim': 32, 'depth': 2, 'heads': 8, 'weight_decay': -2, 'learning_rate': -4, 'dropout': 0.4}. Best is trial 48 with value: 3546437.0810431303.
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4464421.50000
Epoch 1: Val Loss 4070694.50000
Epoch 2: Val Loss 3977640.75000
Epoch 3: Val Loss 3903018.00000
Epoch 4: Val Loss 3852076.75000
Epoch 5: Val Loss 3805525.75000
Epoch 6: Val Loss 3821218.75000
Epoch 7: Val Loss 3751677.00000
Epoch 8: Val Loss 3716974.75000
Epoch 9: Val Loss 3702495.25000
Epoch 10: Val Loss 3692021.75000
Epoch 11: Val Loss 3647914.00000
Epoch 12: Val Loss 3637556.75000
Epoch 13: Val Loss 3665742.25000
Epoch 14: Val Loss 3612345.00000
Epoch 15: Val Loss 3602757.50000
Epoch 16: Val Loss 3574854.75000
Epoch 17: Val Loss 3576796.50000
Epoch 18: Val Loss 3565506.25000
Epoch 19: Val Loss 3573030.75000
Epoch 20: Val Loss 3540616.25000
Epoch 21: Val Loss 3568452.50000
Epoch 22: Val Loss 3532607.00000
Epoch 23: Val Loss 3521560.75000
Epoch 24: Val Loss 3553534.75000
Epoch 25: Val Loss 3506354.50000
Epoch 26: Val Loss 3531297.00000
Epoch 27: Val Loss 3487638.25000
Epoch 28: Val Loss 3483086.50000
Epoch 29: Val Loss 3485123.25000
Epoch 30: Val Loss 3505228.75000
Epoch 31: Val Loss 3487960.75000
Epoch 32: Val Loss 3474805.50000
Epoch 33: Val Loss 3469090.25000
Epoch 34: Val Loss 3459556.75000
Epoch 35: Val Loss 3505749.00000
Epoch 36: Val Loss 3459581.25000
Epoch 37: Val Loss 3453907.25000
Epoch 38: Val Loss 3473892.25000
Epoch 39: Val Loss 3469163.00000
Epoch 40: Val Loss 3517903.25000
Epoch 41: Val Loss 3432303.75000
Epoch 42: Val Loss 3452448.50000
Epoch 43: Val Loss 3444546.50000
Epoch 44: Val Loss 3473290.00000
Epoch 45: Val Loss 3435534.00000
Epoch 46: Val Loss 3442961.75000
Epoch 47: Val Loss 3429425.00000
Epoch 48: Val Loss 3444769.00000
Epoch 49: Val Loss 3527987.75000
Epoch 50: Val Loss 3454534.75000
Epoch 51: Val Loss 3429120.25000
Epoch 52: Val Loss 3414598.50000
Epoch 53: Val Loss 3487297.00000
Epoch 54: Val Loss 3409762.00000
Epoch 55: Val Loss 3428684.50000
Epoch 56: Val Loss 3436099.25000
Epoch 57: Val Loss 3424268.50000
Epoch 58: Val Loss 3426846.25000
Epoch 59: Val Loss 3412919.00000
Epoch 60: Val Loss 3434839.75000
Epoch 61: Val Loss 3434986.00000
Epoch 62: Val Loss 3704620.75000
Epoch 63: Val Loss 3414047.75000
Epoch 64: Val Loss 3438451.25000
Epoch 65: Val Loss 3414008.25000
Epoch 66: Val Loss 3439570.00000
Epoch 67: Val Loss 3506094.75000
Epoch 68: Val Loss 3415189.00000
Epoch 69: Val Loss 3436578.75000
Epoch 70: Val Loss 3450695.00000
Epoch 71: Val Loss 3437886.75000
Epoch 72: Val Loss 3475179.00000
Epoch 73: Val Loss 3458980.00000
Epoch 74: Val Loss 3449711.25000
Epoch 75: Val Loss 3420958.00000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3418251.2321512606, 'MSE - std': 0.0, 'R2 - mean': 0.5994985568819522, 'R2 - std': 0.0} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4201949.00000
Epoch 1: Val Loss 3859996.75000
Epoch 2: Val Loss 3775351.50000
Epoch 3: Val Loss 3747339.75000
Epoch 4: Val Loss 3689188.50000
Epoch 5: Val Loss 3671343.25000
Epoch 6: Val Loss 3662993.00000
Epoch 7: Val Loss 3662596.50000
Epoch 8: Val Loss 3634174.25000
Epoch 9: Val Loss 3594673.75000
Epoch 10: Val Loss 3579531.50000
Epoch 11: Val Loss 3570676.75000
Epoch 12: Val Loss 3559511.00000
Epoch 13: Val Loss 3571371.00000
Epoch 14: Val Loss 3522154.25000
Epoch 15: Val Loss 3517153.75000
Epoch 16: Val Loss 3534502.25000
Epoch 17: Val Loss 3531453.75000
Epoch 18: Val Loss 3485300.75000
Epoch 19: Val Loss 3498561.50000
Epoch 20: Val Loss 3465165.25000
Epoch 21: Val Loss 3467830.75000
Epoch 22: Val Loss 3468046.50000
Epoch 23: Val Loss 3467452.50000
Epoch 24: Val Loss 3539721.25000
Epoch 25: Val Loss 3449427.50000
Epoch 26: Val Loss 3451567.25000
Epoch 27: Val Loss 3449334.75000
Epoch 28: Val Loss 3425979.50000
Epoch 29: Val Loss 3424315.00000
Epoch 30: Val Loss 3438933.25000
Epoch 31: Val Loss 3442961.50000
Epoch 32: Val Loss 3413263.75000
Epoch 33: Val Loss 3461150.00000
Epoch 34: Val Loss 3436025.50000
Epoch 35: Val Loss 3437057.25000
Epoch 36: Val Loss 3474727.75000
Epoch 37: Val Loss 3432763.00000
Epoch 38: Val Loss 3427465.50000
Epoch 39: Val Loss 3460561.50000
Epoch 40: Val Loss 3437272.25000
Epoch 41: Val Loss 3406032.00000
Epoch 42: Val Loss 3387084.50000
Epoch 43: Val Loss 3406947.75000
Epoch 44: Val Loss 3431361.50000
Epoch 45: Val Loss 3409023.50000
Epoch 46: Val Loss 3424618.25000
Epoch 47: Val Loss 3411874.25000
Epoch 48: Val Loss 3409347.00000
Epoch 49: Val Loss 3382602.25000
Epoch 50: Val Loss 3425469.75000
Epoch 51: Val Loss 3380930.00000
Epoch 52: Val Loss 3409025.75000
Epoch 53: Val Loss 3400342.75000
Epoch 54: Val Loss 3453009.75000
Epoch 55: Val Loss 3395828.75000
Epoch 56: Val Loss 3406366.50000
Epoch 57: Val Loss 3390695.00000
Epoch 58: Val Loss 3415632.75000
Epoch 59: Val Loss 3394177.00000
Epoch 60: Val Loss 3402277.00000
Epoch 61: Val Loss 3384322.75000
Epoch 62: Val Loss 3408431.75000
Epoch 63: Val Loss 3386756.25000
Epoch 64: Val Loss 3428575.75000
Epoch 65: Val Loss 3480334.75000
Epoch 66: Val Loss 3432973.75000
Epoch 67: Val Loss 3408396.25000
Epoch 68: Val Loss 3392690.00000
Epoch 69: Val Loss 3412590.50000
Epoch 70: Val Loss 3411127.50000
Epoch 71: Val Loss 3524685.25000
Epoch 72: Val Loss 3419152.75000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3403811.5494055673, 'MSE - std': 14439.682745693019, 'R2 - mean': 0.5881226671991266, 'R2 - std': 0.011375889682825546} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4936345.50000
Epoch 1: Val Loss 4537415.50000
Epoch 2: Val Loss 4438198.50000
Epoch 3: Val Loss 4382422.50000
Epoch 4: Val Loss 4315281.00000
Epoch 5: Val Loss 4308031.00000
Epoch 6: Val Loss 4261447.00000
Epoch 7: Val Loss 4231392.50000
Epoch 8: Val Loss 4265424.50000
Epoch 9: Val Loss 4181787.25000
Epoch 10: Val Loss 4192555.75000
Epoch 11: Val Loss 4162001.50000
Epoch 12: Val Loss 4505538.50000
Epoch 13: Val Loss 4132447.75000
Epoch 14: Val Loss 4088489.25000
Epoch 15: Val Loss 4097847.00000
Epoch 16: Val Loss 4080820.00000
Epoch 17: Val Loss 4067897.25000
Epoch 18: Val Loss 4053239.50000
Epoch 19: Val Loss 4062793.50000
Epoch 20: Val Loss 4064719.25000
Epoch 21: Val Loss 4033453.50000
Epoch 22: Val Loss 4047746.25000
Epoch 23: Val Loss 4006414.75000
Epoch 24: Val Loss 4005556.75000
Epoch 25: Val Loss 4023577.25000
Epoch 26: Val Loss 3983699.50000
Epoch 27: Val Loss 3992946.25000
Epoch 28: Val Loss 3996617.25000
Epoch 29: Val Loss 4001627.00000
Epoch 30: Val Loss 3952424.00000
Epoch 31: Val Loss 3957826.75000
Epoch 32: Val Loss 3974532.00000
Epoch 33: Val Loss 3967236.75000
Epoch 34: Val Loss 3947196.75000
Epoch 35: Val Loss 3928652.25000
Epoch 36: Val Loss 3966400.50000
Epoch 37: Val Loss 3915319.00000
Epoch 38: Val Loss 3936795.25000
Epoch 39: Val Loss 3947153.50000
Epoch 40: Val Loss 3939660.75000
Epoch 41: Val Loss 3908558.00000
Epoch 42: Val Loss 3901658.00000
Epoch 43: Val Loss 3911109.25000
Epoch 44: Val Loss 3893579.25000
Epoch 45: Val Loss 3892392.75000
Epoch 46: Val Loss 3891220.75000
Epoch 47: Val Loss 3891993.50000
Epoch 48: Val Loss 3887179.25000
Epoch 49: Val Loss 3905183.25000
Epoch 50: Val Loss 4407612.00000
Epoch 51: Val Loss 3881163.25000
Epoch 52: Val Loss 3857904.00000
Epoch 53: Val Loss 3854567.00000
Epoch 54: Val Loss 3861256.25000
Epoch 55: Val Loss 3872726.25000
Epoch 56: Val Loss 4016942.00000
Epoch 57: Val Loss 3856280.75000
Epoch 58: Val Loss 3860852.50000
Epoch 59: Val Loss 3862133.25000
Epoch 60: Val Loss 3870388.50000
Epoch 61: Val Loss 3865698.25000
Epoch 62: Val Loss 3848878.25000
Epoch 63: Val Loss 3876782.25000
Epoch 64: Val Loss 3851705.50000
Epoch 65: Val Loss 3880908.75000
Epoch 66: Val Loss 3864034.75000
Epoch 67: Val Loss 3852333.00000
Epoch 68: Val Loss 3878577.00000
Epoch 69: Val Loss 3846622.75000
Epoch 70: Val Loss 3866475.00000
Epoch 71: Val Loss 3889631.75000
Epoch 72: Val Loss 3867084.75000
Epoch 73: Val Loss 3869964.75000
Epoch 74: Val Loss 3875920.50000
Epoch 75: Val Loss 3925719.00000
Epoch 76: Val Loss 3851319.50000
Epoch 77: Val Loss 3848137.25000
Epoch 78: Val Loss 3896934.25000
Epoch 79: Val Loss 3878475.25000
Epoch 80: Val Loss 3865161.50000
Epoch 81: Val Loss 3865127.50000
Epoch 82: Val Loss 3979972.75000
Epoch 83: Val Loss 3881743.75000
Epoch 84: Val Loss 3878955.00000
Epoch 85: Val Loss 3906548.50000
Epoch 86: Val Loss 3902926.00000
Epoch 87: Val Loss 3893204.50000
Epoch 88: Val Loss 3866246.50000
Epoch 89: Val Loss 3889018.00000
Epoch 90: Val Loss 3906103.50000
Validation loss has not improved for 20 steps!
Early stopping applies.
Saved Losses
{'MSE - mean': 3556300.1654640962, 'MSE - std': 215973.51461098573, 'R2 - mean': 0.5814306781275752, 'R2 - std': 0.013260442910579569} 
 

In get_device
()
On Device: cuda
Using dim 8 and batch size 64
On Device: cuda
Epoch 0: Val Loss 4637888.00000
Epoch 1: Val Loss 4214904.50000
Epoch 2: Val Loss 4127236.00000
Epoch 3: Val Loss 4059124.50000
Epoch 4: Val Loss 4026178.75000
Epoch 5: Val Loss 4019222.25000
Epoch 6: Val Loss 3961389.50000
Epoch 7: Val Loss 3937449.50000
Epoch 8: Val Loss 3939252.00000
Epoch 9: Val Loss 3917935.75000
Epoch 10: Val Loss 3892925.50000
Epoch 11: Val Loss 3863244.75000
Epoch 12: Val Loss 3968854.50000
Epoch 13: Val Loss 3851716.75000
Epoch 14: Val Loss 3839425.50000
Epoch 15: Val Loss 3815959.00000
Epoch 16: Val Loss 3805354.50000
Epoch 17: Val Loss 3801316.00000
Epoch 18: Val Loss 3794695.50000
Epoch 19: Val Loss 3782819.50000
