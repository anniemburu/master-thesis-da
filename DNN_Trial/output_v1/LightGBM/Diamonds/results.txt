2025-01-23 12:18:11.532788
LightGBM - Diamonds

MSE - mean: 564969.53882
MSE - std: 25854.30088
R2 - mean: 0.96451
R2 - std: 0.00117

Train time: 6.449481
Test time: 0.168881

Best Parameters: {'num_leaves': 404, 'lambda_l1': 2.4825170229355064e-05, 'lambda_l2': 5.783966590223838, 'learning_rate': 0.022462343234724586, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:18.134357
LightGBM - Diamonds

MSE - mean: 840305.46119
MSE - std: 31439.82080
R2 - mean: 0.94721
R2 - std: 0.00134

Train time: 5.386758
Test time: 0.166442

Best Parameters: {'num_leaves': 279, 'lambda_l1': 5.8178506419632796e-05, 'lambda_l2': 7.184537874226516, 'learning_rate': 0.018461421147527125, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:23.752791
LightGBM - Diamonds

MSE - mean: 743981.62267
MSE - std: 28773.53757
R2 - mean: 0.95326
R2 - std: 0.00118

Train time: 5.966096
Test time: 0.166426

Best Parameters: {'num_leaves': 314, 'lambda_l1': 4.356022345573829e-05, 'lambda_l2': 4.302548868466736, 'learning_rate': 0.019315626105074545, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:29.000128
LightGBM - Diamonds

MSE - mean: 975363.39729
MSE - std: 33845.63139
R2 - mean: 0.93872
R2 - std: 0.00140

Train time: 5.553301
Test time: 0.159187

Best Parameters: {'num_leaves': 246, 'lambda_l1': 0.0001227283930632423, 'lambda_l2': 7.3566231405012035, 'learning_rate': 0.017186992705204258, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:33.859964
LightGBM - Diamonds

MSE - mean: 661369.69665
MSE - std: 27543.89068
R2 - mean: 0.95845
R2 - std: 0.00120

Train time: 6.440637
Test time: 0.169038

Best Parameters: {'num_leaves': 379, 'lambda_l1': 7.394101944243828e-05, 'lambda_l2': 5.1139079266239715, 'learning_rate': 0.020573805641908367, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:39.641308
LightGBM - Diamonds

MSE - mean: 1164869.66426
MSE - std: 36971.87149
R2 - mean: 0.92681
R2 - std: 0.00143

Train time: 6.054625
Test time: 0.145031

Best Parameters: {'num_leaves': 470, 'lambda_l1': 3.067448175880909e-05, 'lambda_l2': 9.831065200832407, 'learning_rate': 0.015903820730045315, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:46.291653
LightGBM - Diamonds

MSE - mean: 877667.05753
MSE - std: 31868.20383
R2 - mean: 0.94486
R2 - std: 0.00122

Train time: 5.885257
Test time: 0.166959

Best Parameters: {'num_leaves': 299, 'lambda_l1': 0.0002627025838509271, 'lambda_l2': 3.1660602722449345, 'learning_rate': 0.017731643532420568, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:50.795195
LightGBM - Diamonds

MSE - mean: 781630.82355
MSE - std: 30317.55331
R2 - mean: 0.95090
R2 - std: 0.00130

Train time: 5.894662
Test time: 0.167225

Best Parameters: {'num_leaves': 376, 'lambda_l1': 5.185686317976814e-05, 'lambda_l2': 6.7903413973111615, 'learning_rate': 0.019081711718802873, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:18:57.571969
LightGBM - Diamonds

MSE - mean: 1009968.10891
MSE - std: 34173.40389
R2 - mean: 0.93655
R2 - std: 0.00134

Train time: 6.656223
Test time: 0.174074

Best Parameters: {'num_leaves': 525, 'lambda_l1': 1.9714809853597132e-05, 'lambda_l2': 4.46565723424985, 'learning_rate': 0.016684040128415494, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:02.294470
LightGBM - Diamonds

MSE - mean: 680622.01412
MSE - std: 26914.55034
R2 - mean: 0.95724
R2 - std: 0.00116

Train time: 4.418704
Test time: 0.151523

Best Parameters: {'num_leaves': 179, 'lambda_l1': 1.4487519394356589e-05, 'lambda_l2': 9.89115823194157, 'learning_rate': 0.0207923755665853, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:04.631959
LightGBM - Diamonds

MSE - mean: 291374.96519
MSE - std: 19585.65022
R2 - mean: 0.98170
R2 - std: 0.00105

Train time: 2.963508
Test time: 0.078029

Best Parameters: {'num_leaves': 248, 'lambda_l1': 9.533496496098146e-05, 'lambda_l2': 2.896883019334357, 'learning_rate': 0.1805523241278459, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:09.465089
LightGBM - Diamonds

MSE - mean: 789991.14143
MSE - std: 30829.99853
R2 - mean: 0.95037
R2 - std: 0.00133

Train time: 5.725697
Test time: 0.161062

Best Parameters: {'num_leaves': 343, 'lambda_l1': 3.6477172950109295e-05, 'lambda_l2': 7.237486534896726, 'learning_rate': 0.019017101332332344, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:15.158233
LightGBM - Diamonds

MSE - mean: 504265.88536
MSE - std: 25000.18470
R2 - mean: 0.96833
R2 - std: 0.00117

Train time: 6.870421
Test time: 0.167154

Best Parameters: {'num_leaves': 337, 'lambda_l1': 3.096785376239033e-05, 'lambda_l2': 1.0659714187884042e-06, 'learning_rate': 0.02324944204244623, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:20.288278
LightGBM - Diamonds

MSE - mean: 646802.65667
MSE - std: 26839.97886
R2 - mean: 0.95937
R2 - std: 0.00118

Train time: 5.228858
Test time: 0.171705

Best Parameters: {'num_leaves': 294, 'lambda_l1': 2.7128982664108516e-05, 'lambda_l2': 9.971808580967846, 'learning_rate': 0.021355763199099504, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:26.344781
LightGBM - Diamonds

MSE - mean: 897665.11880
MSE - std: 31354.94933
R2 - mean: 0.94360
R2 - std: 0.00126

Train time: 6.626454
Test time: 0.155350

Best Parameters: {'num_leaves': 431, 'lambda_l1': 5.6993575037339416e-05, 'lambda_l2': 4.9127365649835175, 'learning_rate': 0.017690849274522004, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:32.038309
LightGBM - Diamonds

MSE - mean: 720870.18751
MSE - std: 28663.26615
R2 - mean: 0.95471
R2 - std: 0.00124

Train time: 7.540179
Test time: 0.167632

Best Parameters: {'num_leaves': 367, 'lambda_l1': 4.0433124798134294e-05, 'lambda_l2': 6.649394412971337, 'learning_rate': 0.019851646021906377, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:37.719990
LightGBM - Diamonds

MSE - mean: 1249073.50407
MSE - std: 38039.97579
R2 - mean: 0.92152
R2 - std: 0.00144

Train time: 5.192776
Test time: 0.150561

Best Parameters: {'num_leaves': 490, 'lambda_l1': 1.641675144054286e-05, 'lambda_l2': 9.969431021451088, 'learning_rate': 0.015374443828616979, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:42.991004
LightGBM - Diamonds

MSE - mean: 850204.72079
MSE - std: 30955.67339
R2 - mean: 0.94659
R2 - std: 0.00124

Train time: 6.607477
Test time: 0.159924

Best Parameters: {'num_leaves': 222, 'lambda_l1': 7.02629356476382e-05, 'lambda_l2': 4.140051277934431, 'learning_rate': 0.018107470370046622, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:43.725612
LightGBM - Diamonds

MSE - mean: 2240363.32118
MSE - std: 51567.00680
R2 - mean: 0.85921
R2 - std: 0.00259

Train time: 0.563607
Test time: 0.063633

Best Parameters: {'num_leaves': 4, 'lambda_l1': 2.5660975912093706e-05, 'lambda_l2': 6.040607336033997, 'learning_rate': 0.0167632236861106, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:48.425921
LightGBM - Diamonds

MSE - mean: 439834.66717
MSE - std: 22765.66568
R2 - mean: 0.97237
R2 - std: 0.00112

Train time: 6.242977
Test time: 0.159100

Best Parameters: {'num_leaves': 275, 'lambda_l1': 1.1145341160982918e-05, 'lambda_l2': 0.005374178421995927, 'learning_rate': 0.025487713959434253, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:19:56.889890
LightGBM - Diamonds

MSE - mean: 566846.77338
MSE - std: 25186.71956
R2 - mean: 0.96439
R2 - std: 0.00108

Train time: 9.706442
Test time: 0.181684

Best Parameters: {'num_leaves': 337, 'lambda_l1': 4.564518015890812e-05, 'lambda_l2': 3.414579323824321, 'learning_rate': 0.022074874283466824, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:03.823901
LightGBM - Diamonds

MSE - mean: 1323959.97164
MSE - std: 39875.78038
R2 - mean: 0.91682
R2 - std: 0.00152

Train time: 8.475306
Test time: 0.153307

Best Parameters: {'num_leaves': 388, 'lambda_l1': 6.57712561977851e-05, 'lambda_l2': 6.861190625580243, 'learning_rate': 0.01479085605161211, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:09.548758
LightGBM - Diamonds

MSE - mean: 1213981.73314
MSE - std: 37881.41858
R2 - mean: 0.92373
R2 - std: 0.00147

Train time: 6.854910
Test time: 0.150385

Best Parameters: {'num_leaves': 412, 'lambda_l1': 0.00013637655225698844, 'lambda_l2': 6.754142641713807, 'learning_rate': 0.015420176061860568, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:18.306797
LightGBM - Diamonds

MSE - mean: 722332.73197
MSE - std: 29224.19978
R2 - mean: 0.95462
R2 - std: 0.00124

Train time: 9.962699
Test time: 0.173619

Best Parameters: {'num_leaves': 312, 'lambda_l1': 8.940353025118184e-05, 'lambda_l2': 5.015048709569465, 'learning_rate': 0.019683199458812882, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:26.673182
LightGBM - Diamonds

MSE - mean: 1053300.97048
MSE - std: 35034.89975
R2 - mean: 0.93382
R2 - std: 0.00140

Train time: 9.825999
Test time: 0.153684

Best Parameters: {'num_leaves': 454, 'lambda_l1': 3.216722337328786e-05, 'lambda_l2': 9.925661378611009, 'learning_rate': 0.016711575122899877, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:32.867419
LightGBM - Diamonds

MSE - mean: 824074.85000
MSE - std: 30259.09177
R2 - mean: 0.94823
R2 - std: 0.00123

Train time: 6.983662
Test time: 0.169961

Best Parameters: {'num_leaves': 579, 'lambda_l1': 5.747288172856544e-05, 'lambda_l2': 4.601142914098174, 'learning_rate': 0.018406516121550632, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:38.516473
LightGBM - Diamonds

MSE - mean: 300899.86225
MSE - std: 20831.75179
R2 - mean: 0.98110
R2 - std: 0.00115

Train time: 4.713534
Test time: 0.070755

Best Parameters: {'num_leaves': 399, 'lambda_l1': 1.849882030232534e-05, 'lambda_l2': 2.201184369984264, 'learning_rate': 0.2837190118343997, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:42.417853
LightGBM - Diamonds

MSE - mean: 1447585.53655
MSE - std: 41956.07543
R2 - mean: 0.90905
R2 - std: 0.00158

Train time: 5.105056
Test time: 0.155454

Best Parameters: {'num_leaves': 260, 'lambda_l1': 0.00020474058714885815, 'lambda_l2': 6.942098200959853, 'learning_rate': 0.014152953757630406, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:47.527428
LightGBM - Diamonds

MSE - mean: 1124668.86697
MSE - std: 36884.84095
R2 - mean: 0.92934
R2 - std: 0.00132

Train time: 6.546093
Test time: 0.168875

Best Parameters: {'num_leaves': 351, 'lambda_l1': 9.653615923758105e-05, 'lambda_l2': 3.0413389325295883, 'learning_rate': 0.015756344651336702, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:55.052225
LightGBM - Diamonds

MSE - mean: 687345.52294
MSE - std: 28207.29367
R2 - mean: 0.95682
R2 - std: 0.00120

Train time: 8.524383
Test time: 0.174806

Best Parameters: {'num_leaves': 529, 'lambda_l1': 3.686561846931495e-05, 'lambda_l2': 5.089900857444933, 'learning_rate': 0.020158950009851892, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:20:59.967738
LightGBM - Diamonds

MSE - mean: 938568.53407
MSE - std: 33213.39826
R2 - mean: 0.94103
R2 - std: 0.00137

Train time: 5.975616
Test time: 0.162383

Best Parameters: {'num_leaves': 292, 'lambda_l1': 2.387137760091102e-05, 'lambda_l2': 7.045129383441893, 'learning_rate': 0.017483287281379743, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:05.928883
LightGBM - Diamonds

MSE - mean: 602041.01229
MSE - std: 26178.51156
R2 - mean: 0.96218
R2 - std: 0.00115

Train time: 7.529665
Test time: 0.177184

Best Parameters: {'num_leaves': 678, 'lambda_l1': 0.00019014088728406552, 'lambda_l2': 4.758376598339191, 'learning_rate': 0.021547715893024583, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:12.471191
LightGBM - Diamonds

MSE - mean: 631639.21150
MSE - std: 25804.20194
R2 - mean: 0.96032
R2 - std: 0.00109

Train time: 7.576475
Test time: 0.178922

Best Parameters: {'num_leaves': 520, 'lambda_l1': 0.00012412425743890237, 'lambda_l2': 3.7991926731977186, 'learning_rate': 0.020883634254510557, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:19.186755
LightGBM - Diamonds

MSE - mean: 772071.29213
MSE - std: 30169.17012
R2 - mean: 0.95150
R2 - std: 0.00130

Train time: 6.989056
Test time: 0.164396

Best Parameters: {'num_leaves': 421, 'lambda_l1': 6.408926685569165e-05, 'lambda_l2': 6.467059889261062, 'learning_rate': 0.01917289947066355, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:23.592884
LightGBM - Diamonds

MSE - mean: 839831.68098
MSE - std: 32015.81883
R2 - mean: 0.94724
R2 - std: 0.00137

Train time: 5.820800
Test time: 0.172275

Best Parameters: {'num_leaves': 347, 'lambda_l1': 0.15711432486364668, 'lambda_l2': 7.285717937193828, 'learning_rate': 0.01846327825407644, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:31.688885
LightGBM - Diamonds

MSE - mean: 662204.52571
MSE - std: 27432.86890
R2 - mean: 0.95840
R2 - std: 0.00116

Train time: 9.234830
Test time: 0.174918

Best Parameters: {'num_leaves': 512, 'lambda_l1': 5.113394507468845e-05, 'lambda_l2': 4.684104562509571, 'learning_rate': 0.020495234870115214, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:40.696804
LightGBM - Diamonds

MSE - mean: 558294.33134
MSE - std: 25476.22677
R2 - mean: 0.96493
R2 - std: 0.00114

Train time: 10.985979
Test time: 0.178488

Best Parameters: {'num_leaves': 387, 'lambda_l1': 0.00016345280309805477, 'lambda_l2': 9.600699142830472, 'learning_rate': 0.023157804346260195, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:47.061834
LightGBM - Diamonds

MSE - mean: 916511.45903
MSE - std: 32699.77217
R2 - mean: 0.94242
R2 - std: 0.00124

Train time: 7.117023
Test time: 0.169109

Best Parameters: {'num_leaves': 305, 'lambda_l1': 0.0005687186119878162, 'lambda_l2': 2.907291267141727, 'learning_rate': 0.017346960445578943, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:21:53.770028
LightGBM - Diamonds

MSE - mean: 769858.46549
MSE - std: 29375.10568
R2 - mean: 0.95164
R2 - std: 0.00122

Train time: 7.071995
Test time: 0.172199

Best Parameters: {'num_leaves': 643, 'lambda_l1': 8.585569018735734e-05, 'lambda_l2': 4.996770912338239, 'learning_rate': 0.019058768157286382, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:00.830557
LightGBM - Diamonds

MSE - mean: 1122779.70626
MSE - std: 35803.72186
R2 - mean: 0.92946
R2 - std: 0.00140

Train time: 8.030187
Test time: 0.156024

Best Parameters: {'num_leaves': 252, 'lambda_l1': 3.989626059723727e-05, 'lambda_l2': 9.761069199282764, 'learning_rate': 0.01618896553597859, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:07.360247
LightGBM - Diamonds

MSE - mean: 658251.91043
MSE - std: 26078.39782
R2 - mean: 0.95865
R2 - std: 0.00107

Train time: 8.391356
Test time: 0.180268

Best Parameters: {'num_leaves': 488, 'lambda_l1': 1.3695736995384204e-05, 'lambda_l2': 1.624718477688231, 'learning_rate': 0.020156235467382988, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:12.970519
LightGBM - Diamonds

MSE - mean: 850302.91316
MSE - std: 30744.54124
R2 - mean: 0.94658
R2 - std: 0.00127

Train time: 5.149328
Test time: 0.151945

Best Parameters: {'num_leaves': 274, 'lambda_l1': 6.655583905271265e-05, 'lambda_l2': 9.852302847771963, 'learning_rate': 0.018554196305421513, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:18.481080
LightGBM - Diamonds

MSE - mean: 879548.88557
MSE - std: 31471.32852
R2 - mean: 0.94474
R2 - std: 0.00129

Train time: 5.885102
Test time: 0.163486

Best Parameters: {'num_leaves': 336, 'lambda_l1': 3.049070415369528e-05, 'lambda_l2': 5.710778220493947, 'learning_rate': 0.017936017733394732, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:22.221935
LightGBM - Diamonds

MSE - mean: 773459.99660
MSE - std: 29765.59887
R2 - mean: 0.95141
R2 - std: 0.00129

Train time: 4.902900
Test time: 0.155405

Best Parameters: {'num_leaves': 220, 'lambda_l1': 4.973569311847444e-05, 'lambda_l2': 6.666215993096053, 'learning_rate': 0.019191755567314582, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:28.450672
LightGBM - Diamonds

MSE - mean: 975426.18946
MSE - std: 33198.93482
R2 - mean: 0.93872
R2 - std: 0.00127

Train time: 6.700038
Test time: 0.164830

Best Parameters: {'num_leaves': 380, 'lambda_l1': 0.00012359001084699138, 'lambda_l2': 3.9293363182381342, 'learning_rate': 0.016923079555601014, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:34.927586
LightGBM - Diamonds

MSE - mean: 648144.84125
MSE - std: 27607.39218
R2 - mean: 0.95928
R2 - std: 0.00125

Train time: 5.529100
Test time: 0.169244

Best Parameters: {'num_leaves': 283, 'lambda_l1': 2.0679687592938813e-05, 'lambda_l2': 6.817699162965224, 'learning_rate': 0.021004868838610337, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:39.033432
LightGBM - Diamonds

MSE - mean: 869829.61046
MSE - std: 31707.71238
R2 - mean: 0.94535
R2 - std: 0.00131

Train time: 5.408921
Test time: 0.159791

Best Parameters: {'num_leaves': 443, 'lambda_l1': 7.950283708772459e-05, 'lambda_l2': 9.968593507401984, 'learning_rate': 0.018357961596315368, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:45.931850
LightGBM - Diamonds

MSE - mean: 1258829.80483
MSE - std: 39213.95665
R2 - mean: 0.92091
R2 - std: 0.00137

Train time: 7.801452
Test time: 0.161616

Best Parameters: {'num_leaves': 329, 'lambda_l1': 1.2030340896601034e-08, 'lambda_l2': 3.66073137104697, 'learning_rate': 0.014968169949902252, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:53.561700
LightGBM - Diamonds

MSE - mean: 1082056.33747
MSE - std: 35713.70198
R2 - mean: 0.93202
R2 - std: 0.00143

Train time: 7.524111
Test time: 0.153579

Best Parameters: {'num_leaves': 244, 'lambda_l1': 0.00031797976717447133, 'lambda_l2': 5.202057966466008, 'learning_rate': 0.01620750942011736, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:22:59.879977
LightGBM - Diamonds

MSE - mean: 688138.04636
MSE - std: 28042.52213
R2 - mean: 0.95677
R2 - std: 0.00116

Train time: 7.299984
Test time: 0.172989

Best Parameters: {'num_leaves': 393, 'lambda_l1': 2.898570564873803e-05, 'lambda_l2': 2.5150799528172736, 'learning_rate': 0.019846287954300216, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:04.085473
LightGBM - Diamonds

MSE - mean: 943591.88177
MSE - std: 33071.23932
R2 - mean: 0.94072
R2 - std: 0.00137

Train time: 5.523434
Test time: 0.159160

Best Parameters: {'num_leaves': 303, 'lambda_l1': 4.93503457466592e-05, 'lambda_l2': 6.626461067230686, 'learning_rate': 0.01740468593749675, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:13.239152
LightGBM - Diamonds

MSE - mean: 555560.04768
MSE - std: 24818.15022
R2 - mean: 0.96510
R2 - std: 0.00109

Train time: 8.009686
Test time: 0.185732

Best Parameters: {'num_leaves': 584, 'lambda_l1': 0.00013292261223296685, 'lambda_l2': 3.662383782421217, 'learning_rate': 0.022335360723001102, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:17.797797
LightGBM - Diamonds

MSE - mean: 826558.35749
MSE - std: 31703.64916
R2 - mean: 0.94807
R2 - std: 0.00136

Train time: 5.946267
Test time: 0.164876

Best Parameters: {'num_leaves': 460, 'lambda_l1': 1.795682593115538e-05, 'lambda_l2': 7.158983828621693, 'learning_rate': 0.018595014073137434, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:26.669277
LightGBM - Diamonds

MSE - mean: 656426.94346
MSE - std: 27124.41769
R2 - mean: 0.95876
R2 - std: 0.00118

Train time: 10.029524
Test time: 0.182309

Best Parameters: {'num_leaves': 342, 'lambda_l1': 6.186869249418036e-05, 'lambda_l2': 4.909566431865691, 'learning_rate': 0.020625321870130116, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:31.309537
LightGBM - Diamonds

MSE - mean: 1160860.63549
MSE - std: 37034.36905
R2 - mean: 0.92707
R2 - std: 0.00145

Train time: 4.461252
Test time: 0.153728

Best Parameters: {'num_leaves': 203, 'lambda_l1': 3.649034166094242e-05, 'lambda_l2': 9.912799196557485, 'learning_rate': 0.01593853342785942, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:36.211352
LightGBM - Diamonds

MSE - mean: 913733.92208
MSE - std: 32804.86022
R2 - mean: 0.94260
R2 - std: 0.00126

Train time: 5.853521
Test time: 0.172553

Best Parameters: {'num_leaves': 277, 'lambda_l1': 1.1499869435526696e-05, 'lambda_l2': 2.7754934932515565, 'learning_rate': 0.01736533374688226, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:41.920169
LightGBM - Diamonds

MSE - mean: 1579693.72936
MSE - std: 45781.18812
R2 - mean: 0.90075
R2 - std: 0.00163

Train time: 5.914261
Test time: 0.144329

Best Parameters: {'num_leaves': 383, 'lambda_l1': 2.407668780921054e-05, 'lambda_l2': 5.068004778500761, 'learning_rate': 0.013458851173973736, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:48.358698
LightGBM - Diamonds

MSE - mean: 802346.94696
MSE - std: 30469.70211
R2 - mean: 0.94959
R2 - std: 0.00129

Train time: 6.742795
Test time: 0.160399

Best Parameters: {'num_leaves': 462, 'lambda_l1': 9.09325391930003e-05, 'lambda_l2': 9.984843444611121, 'learning_rate': 0.019108507748822275, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:55.398713
LightGBM - Diamonds

MSE - mean: 484695.86900
MSE - std: 23411.63275
R2 - mean: 0.96956
R2 - std: 0.00106

Train time: 8.728497
Test time: 0.191259

Best Parameters: {'num_leaves': 801, 'lambda_l1': 5.2895359553827935e-05, 'lambda_l2': 3.60946927732051, 'learning_rate': 0.02419884003850038, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:23:59.464466
LightGBM - Diamonds

MSE - mean: 1254988.64558
MSE - std: 38516.11270
R2 - mean: 0.92115
R2 - std: 0.00150

Train time: 5.341236
Test time: 0.151552

Best Parameters: {'num_leaves': 313, 'lambda_l1': 3.158464527672556e-05, 'lambda_l2': 7.114728907888993, 'learning_rate': 0.01519576692037732, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:09.168828
LightGBM - Diamonds

MSE - mean: 582378.28477
MSE - std: 26065.77752
R2 - mean: 0.96342
R2 - std: 0.00112

Train time: 10.969087
Test time: 0.188751

Best Parameters: {'num_leaves': 573, 'lambda_l1': 1.608877823022981e-05, 'lambda_l2': 2.28296233080776, 'learning_rate': 0.02154342464518184, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:13.708228
LightGBM - Diamonds

MSE - mean: 296644.42893
MSE - std: 18626.32345
R2 - mean: 0.98137
R2 - std: 0.00097

Train time: 5.165944
Test time: 0.184937

Best Parameters: {'num_leaves': 249, 'lambda_l1': 7.69044309680826e-05, 'lambda_l2': 5.110287275464007, 'learning_rate': 0.048520326934074647, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:18.345540
LightGBM - Diamonds

MSE - mean: 717756.76099
MSE - std: 28785.21504
R2 - mean: 0.95491
R2 - std: 0.00125

Train time: 6.061120
Test time: 0.169275

Best Parameters: {'num_leaves': 415, 'lambda_l1': 0.00015151635048970527, 'lambda_l2': 6.894095920220604, 'learning_rate': 0.019909977263301164, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:27.011264
LightGBM - Diamonds

MSE - mean: 986911.08219
MSE - std: 33187.18449
R2 - mean: 0.93800
R2 - std: 0.00125

Train time: 9.848728
Test time: 0.160473

Best Parameters: {'num_leaves': 363, 'lambda_l1': 4.0695086091156105e-05, 'lambda_l2': 3.838041119288727, 'learning_rate': 0.016826964204529938, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:32.385860
LightGBM - Diamonds

MSE - mean: 862945.50734
MSE - std: 31588.43610
R2 - mean: 0.94579
R2 - std: 0.00132

Train time: 6.240916
Test time: 0.161688

Best Parameters: {'num_leaves': 288, 'lambda_l1': 9.387305366406772e-06, 'lambda_l2': 6.95501193258761, 'learning_rate': 0.018198313379479567, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:39.549901
LightGBM - Diamonds

MSE - mean: 1407356.33621
MSE - std: 41501.24184
R2 - mean: 0.91158
R2 - std: 0.00150

Train time: 7.709895
Test time: 0.154451

Best Parameters: {'num_leaves': 487, 'lambda_l1': 2.2487000838533287e-05, 'lambda_l2': 9.95628825890593, 'learning_rate': 0.014487011430077955, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:49.142103
LightGBM - Diamonds

MSE - mean: 289537.96658
MSE - std: 19569.54491
R2 - mean: 0.98182
R2 - std: 0.00102

Train time: 10.117626
Test time: 0.216737

Best Parameters: {'num_leaves': 337, 'lambda_l1': 0.00022723816624705857, 'lambda_l2': 4.951418709644023, 'learning_rate': 0.059370960059025944, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:24:53.381342
LightGBM - Diamonds

MSE - mean: 558365.56669
MSE - std: 25717.61167
R2 - mean: 0.96493
R2 - std: 0.00114

Train time: 5.073023
Test time: 0.160267

Best Parameters: {'num_leaves': 222, 'lambda_l1': 0.00011069155552434677, 'lambda_l2': 2.8004735816770374, 'learning_rate': 0.02222029040044558, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:03.662487
LightGBM - Diamonds

MSE - mean: 678401.64436
MSE - std: 27178.98296
R2 - mean: 0.95738
R2 - std: 0.00117

Train time: 12.546552
Test time: 0.204989

Best Parameters: {'num_leaves': 673, 'lambda_l1': 5.329755986530328e-05, 'lambda_l2': 0.0001313327754446828, 'learning_rate': 0.019744389936926433, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:13.237797
LightGBM - Diamonds

MSE - mean: 998524.13407
MSE - std: 33887.51491
R2 - mean: 0.93727
R2 - std: 0.00125

Train time: 12.072707
Test time: 0.170366

Best Parameters: {'num_leaves': 405, 'lambda_l1': 3.08881450512318e-05, 'lambda_l2': 1.9003443652149608, 'learning_rate': 0.016564869174325144, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:22.895266
LightGBM - Diamonds

MSE - mean: 883763.80734
MSE - std: 31503.41449
R2 - mean: 0.94448
R2 - std: 0.00128

Train time: 11.955954
Test time: 0.151477

Best Parameters: {'num_leaves': 276, 'lambda_l1': 9.991001374913003, 'lambda_l2': 4.993318080824084, 'learning_rate': 0.01784045229481783, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:28.339350
LightGBM - Diamonds

MSE - mean: 660183.19176
MSE - std: 26740.66878
R2 - mean: 0.95853
R2 - std: 0.00117

Train time: 6.516015
Test time: 0.170885

Best Parameters: {'num_leaves': 553, 'lambda_l1': 7.596513046217964e-05, 'lambda_l2': 6.695190179851372, 'learning_rate': 0.020760269784527514, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:35.393521
LightGBM - Diamonds

MSE - mean: 772440.10034
MSE - std: 30476.63419
R2 - mean: 0.95147
R2 - std: 0.00131

Train time: 8.232707
Test time: 0.164896

Best Parameters: {'num_leaves': 342, 'lambda_l1': 1.834146624867859e-05, 'lambda_l2': 4.711735656222376e-05, 'learning_rate': 0.018567192974947785, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:44.149361
LightGBM - Diamonds

MSE - mean: 289239.56386
MSE - std: 20058.86988
R2 - mean: 0.98183
R2 - std: 0.00107

Train time: 10.491470
Test time: 0.161297

Best Parameters: {'num_leaves': 437, 'lambda_l1': 3.988308635490223e-05, 'lambda_l2': 3.398100710552081, 'learning_rate': 0.1151564714352116, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:49.960430
LightGBM - Diamonds

MSE - mean: 1178910.68680
MSE - std: 37564.60052
R2 - mean: 0.92593
R2 - std: 0.00148

Train time: 5.063286
Test time: 0.147597

Best Parameters: {'num_leaves': 252, 'lambda_l1': 1.0504740639550806e-05, 'lambda_l2': 7.256342312506353, 'learning_rate': 0.01567102366563467, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:25:54.497979
LightGBM - Diamonds

MSE - mean: 896580.37745
MSE - std: 31416.59991
R2 - mean: 0.94367
R2 - std: 0.00123

Train time: 6.031834
Test time: 0.154260

Best Parameters: {'num_leaves': 310, 'lambda_l1': 2.5282415291627363e-05, 'lambda_l2': 4.145762614387204, 'learning_rate': 0.01763651609644669, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:00.072266
LightGBM - Diamonds

MSE - mean: 772576.69694
MSE - std: 30026.73189
R2 - mean: 0.95147
R2 - std: 0.00128

Train time: 5.465617
Test time: 0.150717

Best Parameters: {'num_leaves': 373, 'lambda_l1': 5.6182354202720856e-05, 'lambda_l2': 9.848697153302824, 'learning_rate': 0.019467225721176297, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:04.131543
LightGBM - Diamonds

MSE - mean: 292604.21641
MSE - std: 19404.28436
R2 - mean: 0.98162
R2 - std: 0.00102

Train time: 1.956006
Test time: 0.147391

Best Parameters: {'num_leaves': 61, 'lambda_l1': 0.00011219610206812841, 'lambda_l2': 5.757019198381584, 'learning_rate': 0.13788075384163348, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:09.998898
LightGBM - Diamonds

MSE - mean: 1388854.56503
MSE - std: 40653.83734
R2 - mean: 0.91274
R2 - std: 0.00133

Train time: 7.271440
Test time: 0.159593

Best Parameters: {'num_leaves': 506, 'lambda_l1': 9.370387242262313e-08, 'lambda_l2': 2.470213943739925, 'learning_rate': 0.014198240137197097, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:15.481164
LightGBM - Diamonds

MSE - mean: 513597.01296
MSE - std: 24084.13240
R2 - mean: 0.96774
R2 - std: 0.00106

Train time: 7.146414
Test time: 0.178748

Best Parameters: {'num_leaves': 424, 'lambda_l1': 1.513262645020238e-05, 'lambda_l2': 3.8111013479754616, 'learning_rate': 0.023418239797099134, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:24.810477
LightGBM - Diamonds

MSE - mean: 1029863.26418
MSE - std: 34763.86969
R2 - mean: 0.93530
R2 - std: 0.00141

Train time: 11.782107
Test time: 0.157577

Best Parameters: {'num_leaves': 303, 'lambda_l1': 7.38935319443846e-06, 'lambda_l2': 6.788354440626368, 'learning_rate': 0.016699032479745392, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:29.623716
LightGBM - Diamonds

MSE - mean: 604610.35092
MSE - std: 27174.32685
R2 - mean: 0.96202
R2 - std: 0.00126

Train time: 4.682478
Test time: 0.148424

Best Parameters: {'num_leaves': 195, 'lambda_l1': 0.00016609928793984293, 'lambda_l2': 0.11752017023873103, 'learning_rate': 0.021006864410954933, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:33.765736
LightGBM - Diamonds

MSE - mean: 832836.15488
MSE - std: 30825.64843
R2 - mean: 0.94768
R2 - std: 0.00127

Train time: 5.312699
Test time: 0.155794

Best Parameters: {'num_leaves': 246, 'lambda_l1': 4.4903105261003595e-05, 'lambda_l2': 4.741581325553406, 'learning_rate': 0.018341117769055823, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:40.340945
LightGBM - Diamonds

MSE - mean: 1165602.18880
MSE - std: 37206.28698
R2 - mean: 0.92677
R2 - std: 0.00147

Train time: 7.843457
Test time: 0.148396

Best Parameters: {'num_leaves': 369, 'lambda_l1': 7.728709763284644e-05, 'lambda_l2': 6.781974183300931, 'learning_rate': 0.01573033754362098, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:47.972773
LightGBM - Diamonds

MSE - mean: 701605.55686
MSE - std: 28462.37256
R2 - mean: 0.95593
R2 - std: 0.00116

Train time: 7.865317
Test time: 0.169243

Best Parameters: {'num_leaves': 543, 'lambda_l1': 2.7680635201391095e-05, 'lambda_l2': 3.1705398910341636, 'learning_rate': 0.01974208788282715, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:26:55.342015
LightGBM - Diamonds

MSE - mean: 919420.71750
MSE - std: 33105.36466
R2 - mean: 0.94224
R2 - std: 0.00127

Train time: 9.197984
Test time: 0.186397

Best Parameters: {'num_leaves': 720, 'lambda_l1': 0.00032113173075262806, 'lambda_l2': 1.5108860464499336, 'learning_rate': 0.017173165400567715, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:02.281676
LightGBM - Diamonds

MSE - mean: 595254.65423
MSE - std: 26534.97090
R2 - mean: 0.96261
R2 - std: 0.00121

Train time: 5.909957
Test time: 0.168602

Best Parameters: {'num_leaves': 337, 'lambda_l1': 3.751974882064343e-05, 'lambda_l2': 7.123392210136809, 'learning_rate': 0.022011584748636483, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:07.034194
LightGBM - Diamonds

MSE - mean: 808996.55852
MSE - std: 30988.95690
R2 - mean: 0.94918
R2 - std: 0.00131

Train time: 5.710794
Test time: 0.165230

Best Parameters: {'num_leaves': 449, 'lambda_l1': 1.9340266604341906e-05, 'lambda_l2': 9.477207589921946, 'learning_rate': 0.018989447805805325, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:12.769412
LightGBM - Diamonds

MSE - mean: 1053767.30762
MSE - std: 35150.76664
R2 - mean: 0.93380
R2 - std: 0.00138

Train time: 6.122962
Test time: 0.162353

Best Parameters: {'num_leaves': 278, 'lambda_l1': 6.857330252482635e-05, 'lambda_l2': 4.597618338422158, 'learning_rate': 0.016368410638214696, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:22.168275
LightGBM - Diamonds

MSE - mean: 1337102.07576
MSE - std: 39740.46805
R2 - mean: 0.91599
R2 - std: 0.00147

Train time: 12.058221
Test time: 0.145333

Best Parameters: {'num_leaves': 627, 'lambda_l1': 0.00010418042519131987, 'lambda_l2': 9.91637866499164, 'learning_rate': 0.014860697653425878, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:31.979296
LightGBM - Diamonds

MSE - mean: 304278.38523
MSE - std: 20075.37795
R2 - mean: 0.98089
R2 - std: 0.00107

Train time: 12.202814
Test time: 0.196524

Best Parameters: {'num_leaves': 393, 'lambda_l1': 1.2637730408916585e-05, 'lambda_l2': 2.006555882104693, 'learning_rate': 0.04058536508438552, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:36.173196
LightGBM - Diamonds

MSE - mean: 1666665.58600
MSE - std: 47455.81730
R2 - mean: 0.89528
R2 - std: 0.00174

Train time: 3.863835
Test time: 0.136477

Best Parameters: {'num_leaves': 156, 'lambda_l1': 4.181075427130331e-05, 'lambda_l2': 0.0015793876706453962, 'learning_rate': 0.012858870099382372, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:41.852329
LightGBM - Diamonds

MSE - mean: 840612.24134
MSE - std: 30715.47680
R2 - mean: 0.94719
R2 - std: 0.00120

Train time: 5.339647
Test time: 0.152525

Best Parameters: {'num_leaves': 225, 'lambda_l1': 2.8534781741996753e-05, 'lambda_l2': 3.2008391321955294, 'learning_rate': 0.018122391016811894, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:46.377330
LightGBM - Diamonds

MSE - mean: 679817.85816
MSE - std: 27863.70734
R2 - mean: 0.95729
R2 - std: 0.00121

Train time: 6.004359
Test time: 0.164885

Best Parameters: {'num_leaves': 319, 'lambda_l1': 0.0002070270701034281, 'lambda_l2': 5.256020606564722, 'learning_rate': 0.020298112376246968, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:51.073793
LightGBM - Diamonds

MSE - mean: 947111.12425
MSE - std: 33535.64414
R2 - mean: 0.94050
R2 - std: 0.00138

Train time: 6.240491
Test time: 0.161758

Best Parameters: {'num_leaves': 475, 'lambda_l1': 3.214870208932026e-07, 'lambda_l2': 5.491328911175129, 'learning_rate': 0.01728950902089043, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:27:57.473031
LightGBM - Diamonds

MSE - mean: 655971.02516
MSE - std: 27607.09591
R2 - mean: 0.95879
R2 - std: 0.00120

Train time: 6.548259
Test time: 0.161361

Best Parameters: {'num_leaves': 363, 'lambda_l1': 5.892344651053577e-05, 'lambda_l2': 9.994314579427645, 'learning_rate': 0.02119924589636842, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:28:02.631713
LightGBM - Diamonds

MSE - mean: 708829.54663
MSE - std: 29504.50988
R2 - mean: 0.95547
R2 - std: 0.00131

Train time: 6.162128
Test time: 0.159022

Best Parameters: {'num_leaves': 281, 'lambda_l1': 3.5839540993845316, 'lambda_l2': 0.05090774961142382, 'learning_rate': 0.01937372475466757, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:28:09.813271
LightGBM - Diamonds

MSE - mean: 528611.44479
MSE - std: 24780.40328
R2 - mean: 0.96680
R2 - std: 0.00109

Train time: 9.363502
Test time: 0.183776

Best Parameters: {'num_leaves': 426, 'lambda_l1': 2.2378871753731124e-05, 'lambda_l2': 2.9092786571675777, 'learning_rate': 0.022855987420622587, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:28:11.004130
LightGBM - Diamonds

MSE - mean: 1371709.27021
MSE - std: 42229.39498
R2 - mean: 0.91382
R2 - std: 0.00155

Train time: 1.176101
Test time: 0.101707

Best Parameters: {'num_leaves': 21, 'lambda_l1': 7.220523943886578e-05, 'lambda_l2': 4.4659031699196285, 'learning_rate': 0.015353171208184099, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:28:16.506237
LightGBM - Diamonds

MSE - mean: 840876.25591
MSE - std: 31699.02195
R2 - mean: 0.94717
R2 - std: 0.00135

Train time: 6.017624
Test time: 0.166452

Best Parameters: {'num_leaves': 560, 'lambda_l1': 0.00011544579432323179, 'lambda_l2': 7.178084528288113, 'learning_rate': 0.018442438707196702, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


2025-01-23 12:28:22.281229
LightGBM - Diamonds

MSE - mean: 1235002.71651
MSE - std: 38537.77187
R2 - mean: 0.92241
R2 - std: 0.00151

Train time: 5.861871
Test time: 0.150382

Best Parameters: {'num_leaves': 399, 'lambda_l1': 1.9505926742432896e-05, 'lambda_l2': 7.303012684671594, 'learning_rate': 0.0153210456997647, 'verbosity': -1, 'objective': 'regression', 'metric': 'mse'}


